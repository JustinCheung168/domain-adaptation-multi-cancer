{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eccd410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\samue\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2.6.0+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "Device count: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 4070\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import branched_resnet_v2 as br\n",
    "from transformers import Trainer, TrainingArguments, set_seed\n",
    "import datetime\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "# Set device and verify CUDA availability\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30ab4ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "D21_MODELS = [\"data\\D21_cv_results\\parabolic_increasing_lambda_scheduler_fold_0_final_model_2025-09-26_01-45-15\\model.safetensors\",\n",
    "             \"data\\D21_cv_results\\parabolic_increasing_lambda_scheduler_fold_1_final_model_2025-09-26_01-45-15\\model.safetensors\",\n",
    "             \"data\\D21_cv_results\\parabolic_increasing_lambda_scheduler_fold_2_final_model_2025-09-26_01-45-15\\model.safetensors\",\n",
    "             \"data\\D21_cv_results\\parabolic_increasing_lambda_scheduler_fold_3_final_model_2025-09-26_01-45-15\\model.safetensors\",\n",
    "             \"data\\D21_cv_results\\parabolic_increasing_lambda_scheduler_fold_4_final_model_2025-09-26_21-33-12\\model.safetensors\"]\n",
    "\n",
    "D20_MODELS = [\"data\\D20_cv_results\\parabolic_increasing_lambda_scheduler_fold_0_final_model_2025-09-27_02-25-33\\model.safetensors\",\n",
    "              \"data\\D20_cv_results\\parabolic_increasing_lambda_scheduler_fold_1_final_model_2025-09-27_02-25-33\\model.safetensors\",\n",
    "              \"data\\D20_cv_results\\parabolic_increasing_lambda_scheduler_fold_2_final_model_2025-09-27_02-25-33\\model.safetensors\",\n",
    "              \"data\\D20_cv_results\\parabolic_increasing_lambda_scheduler_fold_3_final_model_2025-09-27_02-25-33\\model.safetensors\",\n",
    "              \"data\\D20_cv_results\\parabolic_increasing_lambda_scheduler_fold_4_final_model_2025-09-27_02-25-33\\model.safetensors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5be669d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(columns=['eval_loss', 'eval_accuracy_branch1', 'eval_accuracy_branch2', 'eval_f1_branch1', 'eval_f1_branch2', 'eval_precision_branch1', 'eval_precision_branch2', 'eval_recall_branch1', 'eval_recall_branch2'])\n",
    "\n",
    "def build_row(results, dataset_name):\n",
    "    row = {'Dataset': dataset_name,\n",
    "           'eval_loss': None,\n",
    "           'eval_accuracy_branch1': None,\n",
    "           'eval_accuracy_branch2': None,\n",
    "           'eval_f1_branch1': None,\n",
    "           'eval_f1_branch2': None,\n",
    "           'eval_precision_branch1': None,\n",
    "           'eval_precision_branch2': None,\n",
    "           'eval_recall_branch1': None,\n",
    "           'eval_recall_branch2': None}\n",
    "    row.update(results)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "715ef94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test datasets\n",
    "\n",
    "test_ds1 = br.dataset_load('data/test/preprocessed_undistorted_test_v2.npz')\n",
    "test_ds2 = br.dataset_load('data/test/preprocessed_all_distortions_test_v2.npz')\n",
    "test_ds3 = br.dataset_load('data/test/preprocessed_ring_artifact_test_v2.npz')\n",
    "test_ds4 = br.dataset_load('data/test/preprocessed_rotate_test_v2.npz')\n",
    "test_ds5 = br.dataset_load('data/test/preprocessed_uniform_rotate_test_v2.npz')\n",
    "test_ds6 = br.dataset_load('data/test/preprocessed_uniform_test_v2.npz')\n",
    "\n",
    "test_names = ['undistorted', 'all_distortions', 'ring_artifact', 'rotate', 'uniform_rotate', 'uniform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58cdcd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from safetensors.torch import load_file\n",
    "\n",
    "# fold = 1\n",
    "# for model_path in D21_MODELS:\n",
    "#     print(f\"Evaluating D21 model from fold {fold}: {model_path}\")\n",
    "#     fold += 1\n",
    "\n",
    "#     state_dict = load_file(model_path, device=\"cpu\")\n",
    "\n",
    "#     config = br.ResNetConfig()\n",
    "#     model = br.ResNetForMultiLabel(config, num_d1_classes=11, num_d2_classes=2)\n",
    "#     model.load_state_dict(state_dict)\n",
    "#     model.eval()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(test_ds1)\n",
    "#         results = br.compute_metrics(outputs, test_ds1)\n",
    "#         metrics_df = metrics_df.append(build_row(results, 'test_ds1'), ignore_index=True)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(test_ds2)\n",
    "#         results = br.compute_metrics(outputs, test_ds2)\n",
    "#         metrics_df = metrics_df.append(build_row(results, 'test_ds2'), ignore_index=True)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(test_ds3)\n",
    "#         results = br.compute_metrics(outputs, test_ds3)\n",
    "#         metrics_df = metrics_df.append(build_row(results, 'test_ds3'), ignore_index=True)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(test_ds4)\n",
    "#         results = br.compute_metrics(outputs, test_ds4)\n",
    "#         metrics_df = metrics_df.append(build_row(results, 'test_ds4'), ignore_index=True)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(test_ds5)\n",
    "#         results = br.compute_metrics(outputs, test_ds5)\n",
    "#         metrics_df = metrics_df.append(build_row(results, 'test_ds5'), ignore_index=True)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(test_ds6)\n",
    "#         results = br.compute_metrics(outputs, test_ds6)\n",
    "#         metrics_df = metrics_df.append(build_row(results, 'test_ds6'), ignore_index=True)\n",
    "\n",
    "# # Save metrics to CSV\n",
    "# metrics_df.to_csv('data/D21_cv_results/D21_cv_test_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5df5c919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parabolic_increasing_lambda_scheduler(epoch, total_epochs, start_value=0.0, end_value=1.0):\n",
    "    progress = epoch / total_epochs\n",
    "    return start_value + (end_value - start_value) * (progress ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a1dca04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating D21 model from fold 1: data\\D21_cv_results\\parabolic_increasing_lambda_scheduler_fold_0_final_model_2025-09-26_01-45-15\\model.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_45540\\3814535156.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test dataset 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7782' max='556' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [556/556 05:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test dataset 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_45540\\3814535156.py:43: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test dataset 3\n",
      "Evaluating on test dataset 4\n",
      "Evaluating on test dataset 5\n",
      "Evaluating on test dataset 6\n",
      "Evaluating D21 model from fold 2: data\\D21_cv_results\\parabolic_increasing_lambda_scheduler_fold_1_final_model_2025-09-26_01-45-15\\model.safetensors\n",
      "Evaluating on test dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_45540\\3814535156.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7782' max='556' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [556/556 05:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test dataset 2\n",
      "Evaluating on test dataset 3\n",
      "Evaluating on test dataset 4\n",
      "Evaluating on test dataset 5\n",
      "Evaluating on test dataset 6\n",
      "Evaluating D21 model from fold 3: data\\D21_cv_results\\parabolic_increasing_lambda_scheduler_fold_2_final_model_2025-09-26_01-45-15\\model.safetensors\n",
      "Evaluating on test dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_45540\\3814535156.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7782' max='556' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [556/556 05:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test dataset 2\n",
      "Evaluating on test dataset 3\n",
      "Evaluating on test dataset 4\n",
      "Evaluating on test dataset 5\n",
      "Evaluating on test dataset 6\n",
      "Evaluating D21 model from fold 4: data\\D21_cv_results\\parabolic_increasing_lambda_scheduler_fold_3_final_model_2025-09-26_01-45-15\\model.safetensors\n",
      "Evaluating on test dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_45540\\3814535156.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7782' max='556' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [556/556 05:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test dataset 2\n",
      "Evaluating on test dataset 3\n",
      "Evaluating on test dataset 4\n",
      "Evaluating on test dataset 5\n",
      "Evaluating on test dataset 6\n",
      "Evaluating D21 model from fold 5: data\\D21_cv_results\\parabolic_increasing_lambda_scheduler_fold_4_final_model_2025-09-26_21-33-12\\model.safetensors\n",
      "Evaluating on test dataset 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_45540\\3814535156.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7782' max='556' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [556/556 05:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test dataset 2\n",
      "Evaluating on test dataset 3\n",
      "Evaluating on test dataset 4\n",
      "Evaluating on test dataset 5\n",
      "Evaluating on test dataset 6\n"
     ]
    }
   ],
   "source": [
    "from safetensors.torch import load_file\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "lambda_scheduler = parabolic_increasing_lambda_scheduler\n",
    "NUM_EPOCHS = 50\n",
    "fold = 1\n",
    "for model_path in D21_MODELS:\n",
    "    print(f\"Evaluating D21 model from fold {fold}: {model_path}\")\n",
    "    fold += 1\n",
    "\n",
    "    # Load safetensors weights\n",
    "    state_dict = load_file(model_path)\n",
    "\n",
    "    # Rebuild model and load weights\n",
    "    config = br.ResNetConfig()\n",
    "    model = br.ResNetForMultiLabel(config, num_d1_classes=11, num_d2_classes=2)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    # TrainingArguments (we only care about eval here)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results/fold_{fold}\",\n",
    "        per_device_eval_batch_size=32,\n",
    "        dataloader_drop_last=False,\n",
    "        report_to=\"none\",   # don’t log to W&B unless you want to\n",
    "    )\n",
    "\n",
    "    # Wrap with Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        tokenizer=None,  # if you need preprocessing, pass tokenizer\n",
    "        compute_metrics=br.make_metrics_fn(model),\n",
    "        callbacks=[br.LambdaUpdateCallback(model, lambda_scheduler, NUM_EPOCHS)]\n",
    "    )\n",
    "\n",
    "    # Evaluate on each test dataset\n",
    "    for i, dataset in enumerate([test_ds1, test_ds2, test_ds3, test_ds4, test_ds5, test_ds6]):\n",
    "        print(f\"Evaluating on test dataset {i+1}\")\n",
    "        results = trainer.evaluate(eval_dataset=dataset)\n",
    "        # Store results in your DataFrame\n",
    "        row = build_row(results, f'Fold_{fold}_{test_names[i]}')\n",
    "        metrics_df = pd.concat([metrics_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "# Save metrics to CSV\n",
    "metrics_df.to_csv(\"data/D21_cv_results/D21_cv_test_metrics_v2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c93bf0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating D20 model from fold 1: data\\D20_cv_results\\parabolic_increasing_lambda_scheduler_fold_0_final_model_2025-09-27_02-25-33\\model.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_45540\\2555795922.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7782' max='556' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [556/556 05:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_45540\\2555795922.py:39: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  metrics_df = pd.concat([metrics_df, pd.DataFrame([row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating D20 model from fold 2: data\\D20_cv_results\\parabolic_increasing_lambda_scheduler_fold_1_final_model_2025-09-27_02-25-33\\model.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_45540\\2555795922.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7782' max='556' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [556/556 05:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating D20 model from fold 3: data\\D20_cv_results\\parabolic_increasing_lambda_scheduler_fold_2_final_model_2025-09-27_02-25-33\\model.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_45540\\2555795922.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7782' max='556' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [556/556 05:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating D20 model from fold 4: data\\D20_cv_results\\parabolic_increasing_lambda_scheduler_fold_3_final_model_2025-09-27_02-25-33\\model.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_45540\\2555795922.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7782' max='556' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [556/556 05:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating D20 model from fold 5: data\\D20_cv_results\\parabolic_increasing_lambda_scheduler_fold_4_final_model_2025-09-27_02-25-33\\model.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_45540\\2555795922.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7782' max='556' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [556/556 05:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_df = None\n",
    "metrics_df = pd.DataFrame(columns=['eval_loss', 'eval_accuracy_branch1', 'eval_accuracy_branch2', 'eval_f1_branch1', 'eval_f1_branch2', 'eval_precision_branch1', 'eval_precision_branch2', 'eval_recall_branch1', 'eval_recall_branch2'])\n",
    "fold = 1\n",
    "for model_path in D20_MODELS:\n",
    "    print(f\"Evaluating D20 model from fold {fold}: {model_path}\")\n",
    "    fold += 1\n",
    "\n",
    "    # Load safetensors weights\n",
    "    state_dict = load_file(model_path)\n",
    "\n",
    "    # Rebuild model and load weights\n",
    "    config = br.ResNetConfig()\n",
    "    model = br.ResNetForMultiLabel(config, num_d1_classes=11, num_d2_classes=2)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    # TrainingArguments (we only care about eval here)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results/fold_{fold}\",\n",
    "        per_device_eval_batch_size=32,\n",
    "        dataloader_drop_last=False,\n",
    "        report_to=\"none\",   # don’t log to W&B unless you want to\n",
    "    )\n",
    "\n",
    "    # Wrap with Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        tokenizer=None,  # if you need preprocessing, pass tokenizer\n",
    "        compute_metrics=br.make_metrics_fn(model),\n",
    "        callbacks=[br.LambdaUpdateCallback(model, lambda_scheduler, NUM_EPOCHS)]\n",
    "    )\n",
    "\n",
    "    # Evaluate on each test dataset\n",
    "    for i, dataset in enumerate([test_ds1, test_ds2, test_ds3, test_ds4, test_ds5, test_ds6]):\n",
    "        results = trainer.evaluate(eval_dataset=dataset)\n",
    "        # Store results in your DataFrame\n",
    "        row = build_row(results, f'Fold_{fold}_{test_names[i]}')\n",
    "        metrics_df = pd.concat([metrics_df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "# Save metrics to CSV\n",
    "metrics_df.to_csv(\"data/D20_cv_results/D20_cv_test_metrics_v2.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
