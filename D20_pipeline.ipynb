{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b93199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34561 ['original', 'label', 'Uniform_Noise', 'Rotate_90deg']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<numpy.lib.npyio.NpzFile at 0x2ada6336810>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data = np.load('distorted_data/concatenated_data.npz')\n",
    "data = np.load('datasets/training.npz')\n",
    "print(len(data['original']), list(data.keys()))\n",
    "data\n",
    "\n",
    "# # load the data from every file in the distorted_data directory\n",
    "\n",
    "# import os\n",
    "# data_dir = 'distorted_data'\n",
    "\n",
    "# data = []\n",
    "# for filename in os.listdir(data_dir):\n",
    "#     if filename.endswith('.npz'):\n",
    "#         file_path = os.path.join(data_dir, filename)\n",
    "#         loaded_data = np.load(file_path)\n",
    "#         data.append(loaded_data)\n",
    "\n",
    "# # concatenate the data from all files\n",
    "# all_data = {}\n",
    "# for key in data[0].keys():\n",
    "#     all_data[key] = np.concatenate([d[key] for d in data], axis=0)\n",
    "\n",
    "# # check the shape of the concatenated data\n",
    "# for key, value in all_data.items():\n",
    "#     print(f\"{key}: {value.shape}\")\n",
    "\n",
    "# # save the concatenated data to a new npz file\n",
    "# output_file = 'distorted_data/concatenated_data.npz'\n",
    "# np.savez(output_file, **all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe4780cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def import_data(directory, save_path=None, save=False):\n",
    "\n",
    "    data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.npz'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            loaded_data = np.load(file_path)\n",
    "            data.append(loaded_data)\n",
    "\n",
    "    # concatenate the data from all files\n",
    "    all_data = {}\n",
    "    for key in data[0].keys():\n",
    "        all_data[key] = np.concatenate([d[key] for d in data], axis=0)\n",
    "\n",
    "    # check the shape of the concatenated data\n",
    "    for key, value in all_data.items():\n",
    "        print(f\"{key}: {value.shape}\")  \n",
    "\n",
    "    if save:\n",
    "        if save_path is None:\n",
    "            save_path = f'datasets/{directory}_concatenated_data.npz'\n",
    "        np.savez(save_path, **all_data)\n",
    "        print(f\"Data saved to {save_path}\")\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c19c8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: (34561, 224, 224)\n",
      "label: (34561, 1)\n",
      "Uniform_Noise: (34561, 224, 224)\n",
      "Rotate_90deg: (34561, 224, 224)\n",
      "Data saved to datasets/train.npz\n",
      "original: (6491, 224, 224)\n",
      "label: (6491, 1)\n",
      "Uniform_Noise: (6491, 224, 224)\n",
      "Rotate_90deg: (6491, 224, 224)\n",
      "Data saved to datasets/validation.npz\n",
      "original: (17778, 224, 224)\n",
      "label: (17778, 1)\n",
      "Uniform_Noise: (17778, 224, 224)\n",
      "Rotate_90deg: (17778, 224, 224)\n",
      "Data saved to datasets/test.npz\n"
     ]
    }
   ],
   "source": [
    "train_data = import_data('imported_distorted/train', save_path='datasets/train.npz', save=True)\n",
    "val_data =  import_data('imported_distorted/val', save_path='datasets/validation.npz', save=True)\n",
    "test_data = import_data('imported_distorted/test', save_path='datasets/test.npz', save=True)\n",
    "\n",
    "# Shuffle the training data\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Shuffle the data\n",
    "train_indices = np.random.permutation(len(train_data['original']))\n",
    "val_indices = np.random.permutation(len(val_data['original']))\n",
    "test_indices = np.random.permutation(len(test_data['original']))\n",
    "\n",
    "\n",
    "for key in train_data.keys():\n",
    "    train_data[key] = train_data[key][train_indices]\n",
    "\n",
    "for key in val_data.keys():\n",
    "    val_data[key] = val_data[key][val_indices]\n",
    "\n",
    "for key in test_data.keys():\n",
    "    test_data[key] = test_data[key][test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6103238d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['original', 'label', 'Uniform_Noise', 'Rotate_90deg'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea25448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys = list(data.keys())\n",
    "\n",
    "# images = [data[keys[0]], data[keys[2]], data[keys[3]]]\n",
    "# labels = data[keys[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb92491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28add875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image, mean=0.5, std=0.5):\n",
    "    \"\"\"\n",
    "    Normalize an image tensor to have a mean and standard deviation.\n",
    "    \"\"\"\n",
    "    return (image - mean) / std\n",
    "\n",
    "def normalize_images(images, mean=0.5, std=0.5):\n",
    "    \"\"\"\n",
    "    Normalize a list of images.\n",
    "    \"\"\"\n",
    "    return [normalize_image(image, mean, std) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73144dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_images = []\n",
    "# for image in images:\n",
    "#     normalized_images.append(normalize_images(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ac6181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_images(images, labels, n=3):\n",
    "    \"\"\"\n",
    "    Plot a sample of images with their corresponding labels.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(n):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.imshow(images[i][0], cmap='gray')\n",
    "        plt.title(f'Label: {labels[i]}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# plot_sample_images(images, labels)\n",
    "# plot_sample_images(normalized_images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2176bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45a63724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_images[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "662d4f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(normalized_images[0][0])\n",
    "# normalized_images[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4670a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero_labels = np.zeros_like(labels)\n",
    "# one_labels = np.ones_like(labels)\n",
    "\n",
    "# print(zero_labels.shape, one_labels.shape)\n",
    "\n",
    "# domain_labels = np.concatenate((zero_labels, one_labels, one_labels), axis=0)\n",
    "# print(domain_labels.shape)\n",
    "\n",
    "# expanded_labels = np.concatenate((labels, labels, labels), axis=0)\n",
    "# print(expanded_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be8a8da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # concatenate the matrices in the images list\n",
    "# concatenated_images = np.concatenate(normalized_images, axis=0)\n",
    "# concatenated_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc65456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\samue\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from branched_resnet import CustomImageDataset\n",
    "\n",
    "def preprocess_data(data, distortions = [3], include_original=True):\n",
    "\n",
    "    keys = list(data.keys())\n",
    "\n",
    "    if include_original:\n",
    "        images = [data[keys[0]]]\n",
    "    else:\n",
    "        images = []\n",
    "\n",
    "    for distortion in distortions:\n",
    "        images.append(data[keys[distortion]])\n",
    "\n",
    "    labels = data[keys[1]]\n",
    "\n",
    "    normalized_images = []\n",
    "    for image in images:\n",
    "        normalized_images.append(normalize_images(image))\n",
    "\n",
    "    zero_labels = np.zeros_like(labels)\n",
    "    one_labels = np.ones_like(labels)\n",
    "\n",
    "    if include_original:\n",
    "        domain_label_list = [zero_labels]\n",
    "        expanded_label_list = [labels]\n",
    "    else:\n",
    "        domain_label_list = []\n",
    "        expanded_label_list = []\n",
    "\n",
    "    for _ in distortions:\n",
    "        domain_label_list.append(one_labels)\n",
    "        expanded_label_list.append(labels)\n",
    "\n",
    "    domain_labels = np.concatenate(domain_label_list, axis=0)\n",
    "    expanded_labels = np.concatenate(expanded_label_list, axis=0)\n",
    "\n",
    "    print(f\"Domain labels shape: {domain_labels.shape}\")\n",
    "    print(f\"Expanded labels shape: {expanded_labels.shape}\")\n",
    "\n",
    "    concatenated_images = np.concatenate(normalized_images, axis=0)\n",
    "\n",
    "    # Shuffle the concatenated images and labels\n",
    "    seed = 42\n",
    "    np.random.seed(seed)\n",
    "    shuffled_indices = np.random.permutation(len(concatenated_images))\n",
    "    concatenated_images = concatenated_images[shuffled_indices]\n",
    "    expanded_labels = expanded_labels[shuffled_indices]\n",
    "    domain_labels = domain_labels[shuffled_indices]\n",
    "\n",
    "    dataset = CustomImageDataset(images=concatenated_images, labels1=expanded_labels, labels2=domain_labels)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7eb8ae09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet.embedder.embedder.convolution.weight tensor(-0.0003) True\n"
     ]
    }
   ],
   "source": [
    "# import branched_resnet_v2 as br \n",
    "# from branched_resnet_v2 import CustomImageDataset\n",
    "import branched_resnet as br \n",
    "from branched_resnet import CustomImageDataset\n",
    "\n",
    "from transformers import Trainer, TrainingArguments, PreTrainedModel, ResNetConfig\n",
    "\n",
    "config = ResNetConfig()\n",
    "model = br.ResNetForMultiLabel(config=config, num_d1_classes=11, num_d2_classes=2)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.data.mean(), param.requires_grad)\n",
    "    break\n",
    "\n",
    "#train_ds = CustomImageDataset(images=concatenated_images, labels1=expanded_labels, labels2=domain_labels)\n",
    "\n",
    "# vars(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c4d5720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain labels shape: (69122, 1)\n",
      "Expanded labels shape: (69122, 1)\n",
      "Domain labels shape: (6491, 1)\n",
      "Expanded labels shape: (6491, 1)\n"
     ]
    }
   ],
   "source": [
    "train_ds = preprocess_data(train_data, distortions=[3])\n",
    "val_ds = preprocess_data(val_data, distortions=[])\n",
    "#test_ds = preprocess_data(test_data, distortions=[2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ac07506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "branched_resnet.CustomImageDataset"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3612c3ff",
   "metadata": {},
   "source": [
    "# D20\n",
    "\n",
    "Train on undistorted and rotate 90\n",
    "\n",
    "Test on the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a365111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msamuelsavine\u001b[0m (\u001b[33msamuelsavine-johns-hopkins-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.21.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\samue\\ML_Deep_Learning\\research\\wandb\\run-20250805_154159-i3ibizj3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/samuelsavine-johns-hopkins-university/huggingface/runs/i3ibizj3' target=\"_blank\">./D20_Experiment</a></strong> to <a href='https://wandb.ai/samuelsavine-johns-hopkins-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/samuelsavine-johns-hopkins-university/huggingface' target=\"_blank\">https://wandb.ai/samuelsavine-johns-hopkins-university/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/samuelsavine-johns-hopkins-university/huggingface/runs/i3ibizj3' target=\"_blank\">https://wandb.ai/samuelsavine-johns-hopkins-university/huggingface/runs/i3ibizj3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48474' max='108050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 48474/108050 2:05:52 < 2:34:42, 6.42 it/s, Epoch 22.43/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Branch1</th>\n",
       "      <th>Precision Branch1</th>\n",
       "      <th>Recall Branch1</th>\n",
       "      <th>F1 Branch1</th>\n",
       "      <th>Accuracy Branch2</th>\n",
       "      <th>Precision Branch2</th>\n",
       "      <th>Recall Branch2</th>\n",
       "      <th>F1 Branch2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.281200</td>\n",
       "      <td>0.474866</td>\n",
       "      <td>0.807118</td>\n",
       "      <td>0.815586</td>\n",
       "      <td>0.756908</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>0.520567</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.260283</td>\n",
       "      <td>0.342351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.211258</td>\n",
       "      <td>0.926051</td>\n",
       "      <td>0.918492</td>\n",
       "      <td>0.919917</td>\n",
       "      <td>0.918222</td>\n",
       "      <td>0.460330</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.230165</td>\n",
       "      <td>0.315223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.105900</td>\n",
       "      <td>0.098833</td>\n",
       "      <td>0.962101</td>\n",
       "      <td>0.954143</td>\n",
       "      <td>0.951623</td>\n",
       "      <td>0.951374</td>\n",
       "      <td>0.503929</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.251964</td>\n",
       "      <td>0.335075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.076785</td>\n",
       "      <td>0.969188</td>\n",
       "      <td>0.968340</td>\n",
       "      <td>0.965379</td>\n",
       "      <td>0.965931</td>\n",
       "      <td>0.678478</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.339239</td>\n",
       "      <td>0.404222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>0.066480</td>\n",
       "      <td>0.976583</td>\n",
       "      <td>0.976548</td>\n",
       "      <td>0.976862</td>\n",
       "      <td>0.976570</td>\n",
       "      <td>0.622092</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.311046</td>\n",
       "      <td>0.383512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.134409</td>\n",
       "      <td>0.960561</td>\n",
       "      <td>0.963831</td>\n",
       "      <td>0.960202</td>\n",
       "      <td>0.959106</td>\n",
       "      <td>0.704976</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.352488</td>\n",
       "      <td>0.413482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.096466</td>\n",
       "      <td>0.977353</td>\n",
       "      <td>0.977464</td>\n",
       "      <td>0.978059</td>\n",
       "      <td>0.977561</td>\n",
       "      <td>0.564474</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.282237</td>\n",
       "      <td>0.360807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.143214</td>\n",
       "      <td>0.967493</td>\n",
       "      <td>0.969762</td>\n",
       "      <td>0.968031</td>\n",
       "      <td>0.967834</td>\n",
       "      <td>0.750578</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.375289</td>\n",
       "      <td>0.428760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.102475</td>\n",
       "      <td>0.973656</td>\n",
       "      <td>0.973735</td>\n",
       "      <td>0.974062</td>\n",
       "      <td>0.973608</td>\n",
       "      <td>0.614081</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.307041</td>\n",
       "      <td>0.380452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.382400</td>\n",
       "      <td>0.114574</td>\n",
       "      <td>0.972115</td>\n",
       "      <td>0.970764</td>\n",
       "      <td>0.971581</td>\n",
       "      <td>0.970655</td>\n",
       "      <td>0.553844</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.276922</td>\n",
       "      <td>0.356435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.125426</td>\n",
       "      <td>0.972423</td>\n",
       "      <td>0.973021</td>\n",
       "      <td>0.974505</td>\n",
       "      <td>0.973351</td>\n",
       "      <td>0.721460</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.360730</td>\n",
       "      <td>0.419098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.188866</td>\n",
       "      <td>0.959945</td>\n",
       "      <td>0.968227</td>\n",
       "      <td>0.965881</td>\n",
       "      <td>0.965963</td>\n",
       "      <td>0.756124</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.378062</td>\n",
       "      <td>0.430564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.092913</td>\n",
       "      <td>0.978894</td>\n",
       "      <td>0.978701</td>\n",
       "      <td>0.979159</td>\n",
       "      <td>0.978682</td>\n",
       "      <td>0.677708</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.338854</td>\n",
       "      <td>0.403949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.134082</td>\n",
       "      <td>0.977969</td>\n",
       "      <td>0.978849</td>\n",
       "      <td>0.978869</td>\n",
       "      <td>0.978172</td>\n",
       "      <td>0.651363</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.325682</td>\n",
       "      <td>0.394440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.084201</td>\n",
       "      <td>0.981821</td>\n",
       "      <td>0.980727</td>\n",
       "      <td>0.981161</td>\n",
       "      <td>0.980754</td>\n",
       "      <td>0.749961</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.374981</td>\n",
       "      <td>0.428559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.081733</td>\n",
       "      <td>0.980897</td>\n",
       "      <td>0.982784</td>\n",
       "      <td>0.982199</td>\n",
       "      <td>0.982242</td>\n",
       "      <td>0.712679</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.356340</td>\n",
       "      <td>0.416119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.083066</td>\n",
       "      <td>0.980280</td>\n",
       "      <td>0.981172</td>\n",
       "      <td>0.980405</td>\n",
       "      <td>0.980580</td>\n",
       "      <td>0.694500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.347250</td>\n",
       "      <td>0.409855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.086402</td>\n",
       "      <td>0.982745</td>\n",
       "      <td>0.982515</td>\n",
       "      <td>0.983389</td>\n",
       "      <td>0.982635</td>\n",
       "      <td>0.710214</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.355107</td>\n",
       "      <td>0.415278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.064817</td>\n",
       "      <td>0.984594</td>\n",
       "      <td>0.983506</td>\n",
       "      <td>0.983864</td>\n",
       "      <td>0.983523</td>\n",
       "      <td>0.632260</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.316130</td>\n",
       "      <td>0.387353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.387600</td>\n",
       "      <td>0.071219</td>\n",
       "      <td>0.982899</td>\n",
       "      <td>0.984645</td>\n",
       "      <td>0.984005</td>\n",
       "      <td>0.984147</td>\n",
       "      <td>0.704052</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.352026</td>\n",
       "      <td>0.413163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.069844</td>\n",
       "      <td>0.983824</td>\n",
       "      <td>0.984612</td>\n",
       "      <td>0.984379</td>\n",
       "      <td>0.984360</td>\n",
       "      <td>0.686181</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.343090</td>\n",
       "      <td>0.406944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.074370</td>\n",
       "      <td>0.984594</td>\n",
       "      <td>0.985022</td>\n",
       "      <td>0.985524</td>\n",
       "      <td>0.985116</td>\n",
       "      <td>0.660145</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.330072</td>\n",
       "      <td>0.397643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment to train the model\n",
    "trainer = br.train_model(train_dataset=train_ds, eval_dataset= val_ds, model=model, output_dir= \"./D20_Experiment\", num_epochs=50, batch_size=32)\n",
    "trainer.save_model('branched_resnet_model_D20_0805')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddee630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to Load the model from checkpoint\n",
    "# from safetensors.torch import load_file\n",
    "\n",
    "# model_path = 'branched_resnet_model_D20_0728/model.safetensors'\n",
    "\n",
    "# state_dict = load_file(model_path)\n",
    "# model.load_state_dict(state_dict)\n",
    "\n",
    "# trainer = br.train_model(train_dataset=train_ds, eval_dataset= val_ds, model=model, output_dir= \"./D20_Experiment\", num_epochs=50, batch_size=32, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7108d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain labels shape: (53334, 1)\n",
      "Expanded labels shape: (53334, 1)\n",
      "Domain labels shape: (35556, 1)\n",
      "Expanded labels shape: (35556, 1)\n"
     ]
    }
   ],
   "source": [
    "# Clear up memory\n",
    "train_data = None\n",
    "val_data = None\n",
    "train_ds = None\n",
    "val_ds = None\n",
    "\n",
    "\n",
    "test_ds1 = preprocess_data(test_data, distortions=[2, 3])\n",
    "test_ds2 = preprocess_data(test_data, distortions=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddea3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain labels shape: (17778, 1)\n",
      "Expanded labels shape: (17778, 1)\n"
     ]
    }
   ],
   "source": [
    "baseline = preprocess_data(test_data, distortions=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d075d44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24449' max='2223' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2223/2223 05:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5975546836853027,\n",
       " 'eval_accuracy_branch1': 0.8327708403644954,\n",
       " 'eval_precision_branch1': 0.8229597767271883,\n",
       " 'eval_recall_branch1': 0.8139501221621718,\n",
       " 'eval_f1_branch1': 0.8072260616331811,\n",
       " 'eval_accuracy_branch2': 0.0,\n",
       " 'eval_precision_branch2': 0.0,\n",
       " 'eval_recall_branch2': 0.0,\n",
       " 'eval_f1_branch2': 0.0,\n",
       " 'eval_lambda': 0.9998891029505543,\n",
       " 'eval_runtime': 23.8902,\n",
       " 'eval_samples_per_second': 744.154,\n",
       " 'eval_steps_per_second': 93.051,\n",
       " 'epoch': 50.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undistorted only\n",
    "trainer.evaluate(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24977e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1995011568069458,\n",
       " 'eval_accuracy_branch1': 0.6783477706528669,\n",
       " 'eval_precision_branch1': 0.7372151583916294,\n",
       " 'eval_recall_branch1': 0.6379914916195644,\n",
       " 'eval_f1_branch1': 0.6632514640700186,\n",
       " 'eval_accuracy_branch2': 0.6666666666666666,\n",
       " 'eval_precision_branch2': 0.3333333333333333,\n",
       " 'eval_recall_branch2': 0.5,\n",
       " 'eval_f1_branch2': 0.4,\n",
       " 'eval_lambda': 0.9998891029505543,\n",
       " 'eval_runtime': 79.7963,\n",
       " 'eval_samples_per_second': 668.377,\n",
       " 'eval_steps_per_second': 83.55,\n",
       " 'epoch': 50.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All available distortions and undistorted\n",
    "trainer.evaluate(test_ds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c424f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2992423474788666,\n",
       " 'eval_accuracy_branch1': 0.5975925300933739,\n",
       " 'eval_precision_branch1': 0.6932316160579803,\n",
       " 'eval_recall_branch1': 0.5474103243172356,\n",
       " 'eval_f1_branch1': 0.5779630920888391,\n",
       " 'eval_accuracy_branch2': 0.5,\n",
       " 'eval_precision_branch2': 0.25,\n",
       " 'eval_recall_branch2': 0.5,\n",
       " 'eval_f1_branch2': 0.3333333333333333,\n",
       " 'eval_lambda': 0.9998891029505543,\n",
       " 'eval_runtime': 50.003,\n",
       " 'eval_samples_per_second': 711.077,\n",
       " 'eval_steps_per_second': 88.895,\n",
       " 'epoch': 50.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undistorted and unseen distortion \n",
    "trainer.evaluate(test_ds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6102847c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain labels shape: (35556, 1)\n",
      "Expanded labels shape: (35556, 1)\n",
      "Domain labels shape: (17778, 1)\n",
      "Expanded labels shape: (17778, 1)\n"
     ]
    }
   ],
   "source": [
    "test_ds3 = preprocess_data(test_data, distortions=[2, 3], include_original=False)\n",
    "test_ds4 = preprocess_data(test_data, distortions=[2], include_original=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd747f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 9.630689419282135e-06,\n",
       " 'eval_accuracy_branch1': 0.6011362357970526,\n",
       " 'eval_precision_branch1': 0.7015237344144287,\n",
       " 'eval_recall_branch1': 0.5500121763482607,\n",
       " 'eval_f1_branch1': 0.583522531170851,\n",
       " 'eval_accuracy_branch2': 1.0,\n",
       " 'eval_precision_branch2': 1.0,\n",
       " 'eval_recall_branch2': 1.0,\n",
       " 'eval_f1_branch2': 1.0,\n",
       " 'eval_lambda': 0.9998891029505543,\n",
       " 'eval_runtime': 50.4932,\n",
       " 'eval_samples_per_second': 704.174,\n",
       " 'eval_steps_per_second': 88.032,\n",
       " 'epoch': 50.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only the distortions\n",
    "trainer.evaluate(test_ds3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d96883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 5.294968445923587e-07,\n",
       " 'eval_accuracy_branch1': 0.36241421982225225,\n",
       " 'eval_precision_branch1': 0.3427846152144357,\n",
       " 'eval_recall_branch1': 0.2808705264722994,\n",
       " 'eval_f1_branch1': 0.2451630956357083,\n",
       " 'eval_accuracy_branch2': 1.0,\n",
       " 'eval_precision_branch2': 1.0,\n",
       " 'eval_recall_branch2': 1.0,\n",
       " 'eval_f1_branch2': 1.0,\n",
       " 'eval_lambda': 0.9998891029505543,\n",
       " 'eval_runtime': 24.8868,\n",
       " 'eval_samples_per_second': 714.355,\n",
       " 'eval_steps_per_second': 89.325,\n",
       " 'epoch': 50.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only the unseen distortion\n",
    "trainer.evaluate(test_ds4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5558660e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain labels shape: (17778, 1)\n",
      "Expanded labels shape: (17778, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.8731880118139088e-05,\n",
       " 'eval_accuracy_branch1': 0.8398582517718528,\n",
       " 'eval_precision_branch1': 0.8300696230904453,\n",
       " 'eval_recall_branch1': 0.819153826224222,\n",
       " 'eval_f1_branch1': 0.8159699729137998,\n",
       " 'eval_accuracy_branch2': 1.0,\n",
       " 'eval_precision_branch2': 1.0,\n",
       " 'eval_recall_branch2': 1.0,\n",
       " 'eval_f1_branch2': 1.0,\n",
       " 'eval_lambda': 0.9998891029505543,\n",
       " 'eval_runtime': 24.7723,\n",
       " 'eval_samples_per_second': 717.656,\n",
       " 'eval_steps_per_second': 89.737,\n",
       " 'epoch': 50.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rotate distortion \n",
    "test_ds5 = preprocess_data(test_data, distortions=[3], include_original=False)\n",
    "trainer.evaluate(test_ds5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d3e874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_npzs(data_dir):\n",
    "    combined_data = {}\n",
    "    order = ['first', 'second', 'third', 'fourth', 'fifth', 'sixth', 'seventh', 'eighth', 'ninth', 'tenth', 'last']\n",
    "    # Process files in the order specified by the 'order' list\n",
    "    for pos in order:\n",
    "        for filename in os.listdir(data_dir):\n",
    "            file_split = filename.split('_')\n",
    "            if pos in file_split and filename.endswith('.npz'):\n",
    "                print(f\"Processing file: {filename}\")\n",
    "                file_path = os.path.join(data_dir, filename)\n",
    "                data = np.load(file_path)\n",
    "                for key in data.files:\n",
    "                    if key in combined_data:\n",
    "                        combined_data[key] = np.concatenate((combined_data[key], data[key]), axis=0)\n",
    "                    else:\n",
    "                        combined_data[key] = data[key]\n",
    "    return combined_data\n",
    "\n",
    "def combine_data(orig_data, new_data):\n",
    "    combined_data = dict(orig_data)\n",
    "\n",
    "    combined_data['Ring_Artifact_v1'] = new_data['Ring_Artifact_v1']\n",
    "    combined_data['ring_labels'] = new_data['label']\n",
    "\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9187e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: test_subset_first_5000_RingArtifactv1_images.npz\n",
      "Processing file: test_subset_second_5000_RingArtifactv1_images.npz\n",
      "Processing file: test_subset_third_5000_RingArtifactv1_images.npz\n",
      "Processing file: test_subset_last_2778_RingArtifactv1_images.npz\n"
     ]
    }
   ],
   "source": [
    "# CT Ring distortion\n",
    "\n",
    "test_data = combine_npzs('ct-distortion/test')\n",
    "orig_test_data = np.load('datasets/test.npz')\n",
    "combined_test_data = combine_data(orig_test_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428163de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.7798231056076474e-05,\n",
       " 'eval_accuracy_branch1': 0.8062211722353471,\n",
       " 'eval_precision_branch1': 0.8045984775704382,\n",
       " 'eval_recall_branch1': 0.7922884085156024,\n",
       " 'eval_f1_branch1': 0.7884681875122503,\n",
       " 'eval_accuracy_branch2': 1.0,\n",
       " 'eval_precision_branch2': 1.0,\n",
       " 'eval_recall_branch2': 1.0,\n",
       " 'eval_f1_branch2': 1.0,\n",
       " 'eval_lambda': 0.9998891029505543,\n",
       " 'eval_runtime': 27.0664,\n",
       " 'eval_samples_per_second': 656.829,\n",
       " 'eval_steps_per_second': 82.131,\n",
       " 'epoch': 50.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ring Artifact only\n",
    "d6images = []\n",
    "for image in combined_test_data['Ring_Artifact_v1']:\n",
    "    d6images.append(normalize_image(image))\n",
    "\n",
    "d6labels = combined_test_data['ring_labels']\n",
    "d6domain_labels = np.ones_like(d6labels)\n",
    "test_ds6 = br.CustomImageDataset(images=d6images, labels1=d6labels, labels2=d6domain_labels)\n",
    "\n",
    "trainer.evaluate(test_ds6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
