{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2bec9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import ResNetConfig\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import transformers\n",
    "from torchvision import transforms\n",
    "from resnet import ResNetForMultiLabel\n",
    "from resnet import OrganAMNISTDataset, compute_metrics, train_model\n",
    "import random\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21076a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x162b86675d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SET SEEDS\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7924dd",
   "metadata": {},
   "source": [
    "#### Import NPZ by concatenating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "880ff3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def import_data(directory, save_path=None, save=False):\n",
    "\n",
    "    data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.npz'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            loaded_data = np.load(file_path)\n",
    "            data.append(loaded_data)\n",
    "\n",
    "    # concatenate the data from all files\n",
    "    all_data = {}\n",
    "    for key in data[0].keys():\n",
    "        all_data[key] = np.concatenate([d[key] for d in data], axis=0)\n",
    "\n",
    "    # check the shape of the concatenated data\n",
    "    for key, value in all_data.items():\n",
    "        print(f\"{key}: {value.shape}\")  \n",
    "\n",
    "    if save:\n",
    "        if save_path is None:\n",
    "            save_path = f'datasets/{directory}_concatenated_data.npz'\n",
    "        np.savez(save_path, **all_data)\n",
    "        print(f\"Data saved to {save_path}\")\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708a6047",
   "metadata": {},
   "source": [
    "### Image normalizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed459e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image, mean=0.5, std=0.5):\n",
    "    \"\"\"\n",
    "    Normalize an image tensor to have a mean and standard deviation.\n",
    "    \"\"\"\n",
    "    return (image - mean) / std\n",
    "\n",
    "def normalize_images(images, mean=0.5, std=0.5):\n",
    "    \"\"\"\n",
    "    Normalize a list of images.\n",
    "    \"\"\"\n",
    "    return [normalize_image(image, mean, std) for image in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb4c6db",
   "metadata": {},
   "source": [
    "### Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f44d030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modified CustomImageDataset Loader\n",
    "\n",
    "class ModifiedCustomImageDataset(Dataset):\n",
    "    def __init__(self, images, labels1,  transform=None):\n",
    "        self.images = images \n",
    "        self.labels1 = labels1\n",
    "\n",
    "        if transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Lambda(lambda x: x.repeat(3, 1, 1))  # Grayscale to 3-channel\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx].astype(np.float32)\n",
    "        label1 = int(self.labels1[idx])\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return {\n",
    "            \"pixel_values\": img,\n",
    "            \"labels\": int(label1) if torch.is_tensor(label1) else label1,\n",
    "        }\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55df27b7",
   "metadata": {},
   "source": [
    "#### Preprocessing functions for single distortion and multi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45c8c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modified\n",
    "\n",
    "def training_preprocess_data(data, float16=False, keylist=['original', 'Uniform_Noise', 'Rotate_90deg', 'Ring_Artifact_v1']):\n",
    "    \"\"\"\n",
    "    Modified to combine the original + distorted images into one set for training C model.\n",
    "    \"\"\"\n",
    "    keys = data.files \n",
    "    print(f'Keys found: {keys}')\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for key in keylist: #Iterate through the different distortions\n",
    "        if key == 'label':\n",
    "            continue\n",
    "        images.append(data[key])\n",
    "        labels.append(data['label'])\n",
    "    \n",
    "    normalized_images = []\n",
    "    for image in images:\n",
    "        normalized_images.append(normalize_images(image))\n",
    "        \n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    if float16:\n",
    "        normalized_images = np.concatenate(normalized_images, axis=0).astype(np.float16)\n",
    "    else:\n",
    "        normalized_images = np.concatenate(normalized_images, axis=0)\n",
    "    \n",
    "    \n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Images shape: {normalized_images.shape}\")\n",
    "\n",
    "    dataset = ModifiedCustomImageDataset(images=normalized_images, labels1=labels)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def validation_preprocess_data(data, key='original'):\n",
    "    \"\"\"\n",
    "    Modified from sam's implementation to preprocess 1 set of images. \n",
    "    \n",
    "    key : str (distortion name)\n",
    "    \"\"\"\n",
    "    keys = data.files \n",
    "    print(f'\\nGenerating {key} validataion set')\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    images.append(data[key])\n",
    "    labels.append(data['label'])\n",
    "    \n",
    "    normalized_images = []\n",
    "    for image in images:\n",
    "        normalized_images.append(normalize_images(image))\n",
    "        \n",
    "    labels = np.array(labels).squeeze()\n",
    "    normalized_images = np.array(normalized_images).squeeze()\n",
    "    \n",
    "    \n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Images shape: {normalized_images.shape}\")\n",
    "\n",
    "    dataset = ModifiedCustomImageDataset(images=normalized_images, labels1=labels)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96678fde",
   "metadata": {},
   "source": [
    "#### Preprocess validation data into distinct sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3cfb27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 'Uniform_Noise', 'Rotate_90deg', 'Ring_Artifact_v1']\n",
      "\n",
      "Generating Rotate_90deg validataion set\n",
      "Labels shape: (6491,)\n",
      "Images shape: (6491, 224, 224)\n",
      "\n",
      "Generating original validataion set\n",
      "Labels shape: (6491,)\n",
      "Images shape: (6491, 224, 224)\n",
      "\n",
      "Generating Uniform_Noise validataion set\n",
      "Labels shape: (6491,)\n",
      "Images shape: (6491, 224, 224)\n",
      "\n",
      "Generating Ring_Artifact_v1 validataion set\n",
      "Labels shape: (6491,)\n",
      "Images shape: (6491, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "val_set_loaded = np.load('val_concatenated_dataset_full.npz')\n",
    "key_list = [key for key in val_set_loaded.files if key != 'label']\n",
    "print(key_list)\n",
    "\n",
    "val_rotate_set = validation_preprocess_data(val_set_loaded, 'Rotate_90deg')\n",
    "val_original_set = validation_preprocess_data(val_set_loaded, 'original')\n",
    "val_noise_set = validation_preprocess_data(val_set_loaded, 'Uniform_Noise')\n",
    "val_ct_set = validation_preprocess_data(val_set_loaded, 'Ring_Artifact_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6652e28",
   "metadata": {},
   "source": [
    "### Preprocess training data into one set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a018b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys found: ['original', 'label', 'Uniform_Noise', 'Rotate_90deg', 'Ring_Artifact_v1']\n",
      "Labels shape: (103683, 1)\n",
      "Images shape: (103683, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "keylist=['original', 'Uniform_Noise', 'Rotate_90deg', 'Ring_Artifact_v1']\n",
    "keylist=['original', 'Uniform_Noise','Ring_Artifact_v1']\n",
    "train_set_loaded = np.load('training_concatenated_dataset_full.npz')\n",
    "training_set = training_preprocess_data(train_set_loaded, float16=True, keylist=keylist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41e8ed8",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84e9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join('C11_model', 'results')\n",
    "\n",
    "\n",
    "config = ResNetConfig()\n",
    "model = ResNetForMultiLabel(config)\n",
    "\n",
    "print(\"Starting training\")\n",
    "trainer = train_model(\n",
    "    train_dataset=training_set,\n",
    "    eval_dataset=val_original_set,\n",
    "    model=model,\n",
    "    output_dir=output_path,  # Checkpoints will go here\n",
    "    num_epochs=100,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"Saving final model\")\n",
    "trainer.save_model(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb25308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys found: ['original', 'label', 'Uniform_Noise', 'Rotate_90deg', 'Ring_Artifact_v1']\n",
      "Labels shape: (69122, 1)\n",
      "Images shape: (69122, 224, 224)\n",
      "Starting training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfb84132d3a4a33acec9b47add41c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/216100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1112, 'grad_norm': 91.74635314941406, 'learning_rate': 0.099, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff9cbdb872d4dec94ee03fd76c76f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6746246218681335, 'eval_accuracy': 0.7314743490987521, 'eval_precision': 0.7848419833368225, 'eval_recall': 0.7442682828283833, 'eval_f1': 0.7338933867561092, 'eval_runtime': 15.3194, 'eval_samples_per_second': 423.71, 'eval_steps_per_second': 53.005, 'epoch': 1.0}\n",
      "{'loss': 0.4656, 'grad_norm': 51.78986358642578, 'learning_rate': 0.098, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d36c7f8f8346d7a7c3ca5411980d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0267927646636963, 'eval_accuracy': 0.7710676321059929, 'eval_precision': 0.8610781937115337, 'eval_recall': 0.8041851458333054, 'eval_f1': 0.7780737687800126, 'eval_runtime': 9.8318, 'eval_samples_per_second': 660.204, 'eval_steps_per_second': 82.589, 'epoch': 2.0}\n",
      "{'loss': 0.2781, 'grad_norm': 89.80549621582031, 'learning_rate': 0.097, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40be17adb1424fdb972cbb9d157e9f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11012283712625504, 'eval_accuracy': 0.9599445385918964, 'eval_precision': 0.956443224751045, 'eval_recall': 0.9585391379318888, 'eval_f1': 0.957171332609201, 'eval_runtime': 10.092, 'eval_samples_per_second': 643.185, 'eval_steps_per_second': 80.46, 'epoch': 3.0}\n",
      "{'loss': 0.1934, 'grad_norm': 113.8421401977539, 'learning_rate': 0.096, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108341318d294d1685ea81099d4f711d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2521253824234009, 'eval_accuracy': 0.9084886766291789, 'eval_precision': 0.9109704104929105, 'eval_recall': 0.8967134908569391, 'eval_f1': 0.8960745253690695, 'eval_runtime': 10.1539, 'eval_samples_per_second': 639.261, 'eval_steps_per_second': 79.969, 'epoch': 4.0}\n",
      "{'loss': 0.1362, 'grad_norm': 34.817928314208984, 'learning_rate': 0.095, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae2513c80514b27ac6ea4819edf20b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13106010854244232, 'eval_accuracy': 0.9554768140502233, 'eval_precision': 0.9622655600545343, 'eval_recall': 0.9626704917343627, 'eval_f1': 0.9615730728239417, 'eval_runtime': 9.8994, 'eval_samples_per_second': 655.693, 'eval_steps_per_second': 82.025, 'epoch': 5.0}\n",
      "{'loss': 0.104, 'grad_norm': 70.72021484375, 'learning_rate': 0.094, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6816fae20a443319ee08368b0c8fdfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1973087638616562, 'eval_accuracy': 0.9536281004467725, 'eval_precision': 0.9585319591742691, 'eval_recall': 0.9546408607505833, 'eval_f1': 0.9530401920855962, 'eval_runtime': 10.1546, 'eval_samples_per_second': 639.216, 'eval_steps_per_second': 79.964, 'epoch': 6.0}\n",
      "{'loss': 0.0813, 'grad_norm': 123.73053741455078, 'learning_rate': 0.09300000000000001, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc81f4ac1d2d454c8c71f3efb9b69f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2792467474937439, 'eval_accuracy': 0.9422276998921584, 'eval_precision': 0.9509828829142264, 'eval_recall': 0.9468301350657872, 'eval_f1': 0.944651514803036, 'eval_runtime': 9.9616, 'eval_samples_per_second': 651.599, 'eval_steps_per_second': 81.513, 'epoch': 7.0}\n",
      "{'loss': 0.0626, 'grad_norm': 99.90606689453125, 'learning_rate': 0.09200000000000001, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232054bfac5c4893af214bb6f7c6e09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1345997005701065, 'eval_accuracy': 0.9690340471421969, 'eval_precision': 0.966896365595315, 'eval_recall': 0.9647403806926342, 'eval_f1': 0.9654872897214735, 'eval_runtime': 10.1235, 'eval_samples_per_second': 641.183, 'eval_steps_per_second': 80.21, 'epoch': 8.0}\n",
      "{'loss': 0.0509, 'grad_norm': 198.91490173339844, 'learning_rate': 0.09100000000000001, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137976d770254d93ae2795c382c5a1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1765868067741394, 'eval_accuracy': 0.9588661223232168, 'eval_precision': 0.9692923835109785, 'eval_recall': 0.9593203767117157, 'eval_f1': 0.963199463797888, 'eval_runtime': 10.183, 'eval_samples_per_second': 637.436, 'eval_steps_per_second': 79.741, 'epoch': 9.0}\n",
      "{'loss': 0.0409, 'grad_norm': 251.77304077148438, 'learning_rate': 0.09000000000000001, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ec5599c94f468983663c0eb3445b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.225211039185524, 'eval_accuracy': 0.9488522569711909, 'eval_precision': 0.95364185661765, 'eval_recall': 0.9463694220507591, 'eval_f1': 0.9466562913687298, 'eval_runtime': 10.9362, 'eval_samples_per_second': 593.533, 'eval_steps_per_second': 74.249, 'epoch': 10.0}\n",
      "{'loss': 0.0292, 'grad_norm': 136.08534240722656, 'learning_rate': 0.08900000000000001, 'epoch': 11.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f57da6a35e54d5b9467668dd15cdbf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11855398863554001, 'eval_accuracy': 0.9750423663534125, 'eval_precision': 0.9765433129768973, 'eval_recall': 0.9754954282706817, 'eval_f1': 0.9754694841584239, 'eval_runtime': 11.2946, 'eval_samples_per_second': 574.7, 'eval_steps_per_second': 71.893, 'epoch': 11.0}\n",
      "{'loss': 0.023, 'grad_norm': 103.93693542480469, 'learning_rate': 0.08800000000000001, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616f4ca92ac548a59573d3e067a07893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15797245502471924, 'eval_accuracy': 0.9639500847327068, 'eval_precision': 0.9622593185743366, 'eval_recall': 0.9657963943101393, 'eval_f1': 0.9635249687419383, 'eval_runtime': 11.0752, 'eval_samples_per_second': 586.082, 'eval_steps_per_second': 73.317, 'epoch': 12.0}\n",
      "{'loss': 0.0169, 'grad_norm': 206.48959350585938, 'learning_rate': 0.08700000000000001, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a7d3ce61044a919def518c242b50c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16111551225185394, 'eval_accuracy': 0.9619473116623016, 'eval_precision': 0.965153542694564, 'eval_recall': 0.9646992919280997, 'eval_f1': 0.9644123286525759, 'eval_runtime': 11.1228, 'eval_samples_per_second': 583.575, 'eval_steps_per_second': 73.003, 'epoch': 13.0}\n",
      "{'loss': 0.015, 'grad_norm': 123.8583984375, 'learning_rate': 0.08600000000000001, 'epoch': 14.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6c368f9d9240ca9daaaaf0c43c081d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19145958125591278, 'eval_accuracy': 0.9607148359266677, 'eval_precision': 0.9693130513649674, 'eval_recall': 0.9692820036856183, 'eval_f1': 0.9685222678591859, 'eval_runtime': 10.9343, 'eval_samples_per_second': 593.637, 'eval_steps_per_second': 74.262, 'epoch': 14.0}\n",
      "{'loss': 0.0126, 'grad_norm': 52.01276779174805, 'learning_rate': 0.085, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d35bef07264ff9a87b6f15166fa82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0962800607085228, 'eval_accuracy': 0.9813588044985364, 'eval_precision': 0.9789538844354078, 'eval_recall': 0.9803740652462892, 'eval_f1': 0.9794225167791953, 'eval_runtime': 10.9253, 'eval_samples_per_second': 594.125, 'eval_steps_per_second': 74.323, 'epoch': 15.0}\n",
      "{'loss': 0.0101, 'grad_norm': 196.5611114501953, 'learning_rate': 0.084, 'epoch': 16.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8812abd3e748998c2adea57c316e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10940303653478622, 'eval_accuracy': 0.9808966260976737, 'eval_precision': 0.9787273830155805, 'eval_recall': 0.9797999022632978, 'eval_f1': 0.9790548968613166, 'eval_runtime': 10.9826, 'eval_samples_per_second': 591.026, 'eval_steps_per_second': 73.935, 'epoch': 16.0}\n",
      "{'loss': 0.0072, 'grad_norm': 5.167089462280273, 'learning_rate': 0.083, 'epoch': 17.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80a6ffaea374b8bbc0d26492e79a167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11583942174911499, 'eval_accuracy': 0.9764289015560006, 'eval_precision': 0.9730838604474129, 'eval_recall': 0.9748029335942451, 'eval_f1': 0.973136268919475, 'eval_runtime': 10.9142, 'eval_samples_per_second': 594.727, 'eval_steps_per_second': 74.398, 'epoch': 17.0}\n",
      "{'loss': 0.0068, 'grad_norm': 130.91151428222656, 'learning_rate': 0.082, 'epoch': 18.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6979ec360e0420b9763a4ddf78e73a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1582583785057068, 'eval_accuracy': 0.97350177168387, 'eval_precision': 0.9761296679016738, 'eval_recall': 0.9736894699913216, 'eval_f1': 0.9738427356319597, 'eval_runtime': 11.0294, 'eval_samples_per_second': 588.518, 'eval_steps_per_second': 73.621, 'epoch': 18.0}\n",
      "{'loss': 0.0058, 'grad_norm': 18.852920532226562, 'learning_rate': 0.08100000000000002, 'epoch': 19.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ea84b58cb54857ab1b6feeef1169e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09180068224668503, 'eval_accuracy': 0.9812047450315822, 'eval_precision': 0.9808044651657446, 'eval_recall': 0.9812886013480759, 'eval_f1': 0.980909945146178, 'eval_runtime': 10.8425, 'eval_samples_per_second': 598.665, 'eval_steps_per_second': 74.891, 'epoch': 19.0}\n",
      "{'loss': 0.0056, 'grad_norm': 122.7890396118164, 'learning_rate': 0.08000000000000002, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b4c5edb18c4193830631878ed6dfe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29844722151756287, 'eval_accuracy': 0.9559389924510862, 'eval_precision': 0.9620092851264609, 'eval_recall': 0.9594227095428064, 'eval_f1': 0.958194698238243, 'eval_runtime': 10.8603, 'eval_samples_per_second': 597.68, 'eval_steps_per_second': 74.768, 'epoch': 20.0}\n",
      "{'loss': 0.0048, 'grad_norm': 108.02734375, 'learning_rate': 0.07900000000000001, 'epoch': 21.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71004f6ee15b4ce5b55b0985fe115bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10927681624889374, 'eval_accuracy': 0.9816669234324449, 'eval_precision': 0.9797200756877497, 'eval_recall': 0.979774293351571, 'eval_f1': 0.9796015355123772, 'eval_runtime': 11.1527, 'eval_samples_per_second': 582.012, 'eval_steps_per_second': 72.808, 'epoch': 21.0}\n",
      "{'loss': 0.0036, 'grad_norm': 141.32801818847656, 'learning_rate': 0.07800000000000001, 'epoch': 22.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4197a0c71a94499b67c988ddbd4064a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08976449817419052, 'eval_accuracy': 0.9859805885071637, 'eval_precision': 0.9840075110228106, 'eval_recall': 0.9843214910013546, 'eval_f1': 0.9840804937042453, 'eval_runtime': 11.0078, 'eval_samples_per_second': 589.675, 'eval_steps_per_second': 73.766, 'epoch': 22.0}\n",
      "{'loss': 0.0027, 'grad_norm': 4.436644554138184, 'learning_rate': 0.07700000000000001, 'epoch': 23.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be3a34321ee4441aebc9f4e672770fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.102291040122509, 'eval_accuracy': 0.9781235556924973, 'eval_precision': 0.9753354689212742, 'eval_recall': 0.9769817111722042, 'eval_f1': 0.97591745649537, 'eval_runtime': 11.0411, 'eval_samples_per_second': 587.894, 'eval_steps_per_second': 73.543, 'epoch': 23.0}\n",
      "{'loss': 0.0026, 'grad_norm': 0.000385869963793084, 'learning_rate': 0.07600000000000001, 'epoch': 24.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7a2d4759204adfb7dab26159f0d6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12896493077278137, 'eval_accuracy': 0.9782776151594516, 'eval_precision': 0.9784043403110506, 'eval_recall': 0.9784245366265657, 'eval_f1': 0.978180281843127, 'eval_runtime': 10.8147, 'eval_samples_per_second': 600.204, 'eval_steps_per_second': 75.083, 'epoch': 24.0}\n",
      "{'loss': 0.0024, 'grad_norm': 0.012109609320759773, 'learning_rate': 0.07500000000000001, 'epoch': 25.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871bb3028fe748a788569c1e36786f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18925584852695465, 'eval_accuracy': 0.9701124634108766, 'eval_precision': 0.9712731234959201, 'eval_recall': 0.9717825268491033, 'eval_f1': 0.9701752664648481, 'eval_runtime': 11.2321, 'eval_samples_per_second': 577.896, 'eval_steps_per_second': 72.293, 'epoch': 25.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b30085c7379d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Starting training\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m trainer = train_model(\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_original_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Calvin\\Desktop\\DG\\domain-generalization-ct\\resnet.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(train_dataset, eval_dataset, model, output_dir, num_epochs, batch_size)\u001b[0m\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m     \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Calvin\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2123\u001b[1;33m             return inner_training_loop(\n\u001b[0m\u001b[0;32m   2124\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2125\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Calvin\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2481\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2483\u001b[1;33m                     if (\n\u001b[0m\u001b[0;32m   2484\u001b[0m                         \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2485\u001b[0m                         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "keylist=['original', 'Rotate_90deg']\n",
    "train_set_loaded = np.load('training_concatenated_dataset_full.npz')\n",
    "training_set = training_preprocess_data(train_set_loaded, float16=True, keylist=keylist)\n",
    "output_path = os.path.join('C10_model_r', 'results')\n",
    "\n",
    "\n",
    "config = ResNetConfig()\n",
    "model = ResNetForMultiLabel(config)\n",
    "\n",
    "print(\"Starting training\")\n",
    "trainer = train_model(\n",
    "    train_dataset=training_set,\n",
    "    eval_dataset=val_original_set,\n",
    "    model=model,\n",
    "    output_dir=output_path,  # Checkpoints will go here\n",
    "    num_epochs=100,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"Saving final model\")\n",
    "trainer.save_model(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec52d043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n",
      "Using GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20328f28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
