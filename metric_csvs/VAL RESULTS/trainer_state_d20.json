{
  "best_metric": 4.3608565647446085e-08,
  "best_model_checkpoint": "./results\\checkpoint-162050",
  "epoch": 50.0,
  "eval_steps": 500,
  "global_step": 162050,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0030854674483184203,
      "grad_norm": 21.539854049682617,
      "learning_rate": 4.9996914532551685e-05,
      "loss": 0.7639,
      "step": 10
    },
    {
      "epoch": 0.006170934896636841,
      "grad_norm": 24.918075561523438,
      "learning_rate": 4.999382906510337e-05,
      "loss": 0.7624,
      "step": 20
    },
    {
      "epoch": 0.009256402344955261,
      "grad_norm": 24.72603988647461,
      "learning_rate": 4.999074359765505e-05,
      "loss": 0.7208,
      "step": 30
    },
    {
      "epoch": 0.012341869793273681,
      "grad_norm": 22.99837875366211,
      "learning_rate": 4.9987658130206726e-05,
      "loss": 0.7059,
      "step": 40
    },
    {
      "epoch": 0.015427337241592102,
      "grad_norm": 19.90778160095215,
      "learning_rate": 4.998457266275841e-05,
      "loss": 0.7885,
      "step": 50
    },
    {
      "epoch": 0.018512804689910522,
      "grad_norm": 16.58116912841797,
      "learning_rate": 4.998148719531009e-05,
      "loss": 0.6818,
      "step": 60
    },
    {
      "epoch": 0.02159827213822894,
      "grad_norm": 10.378403663635254,
      "learning_rate": 4.997840172786177e-05,
      "loss": 0.5895,
      "step": 70
    },
    {
      "epoch": 0.024683739586547362,
      "grad_norm": 12.94185733795166,
      "learning_rate": 4.9975316260413455e-05,
      "loss": 0.6427,
      "step": 80
    },
    {
      "epoch": 0.02776920703486578,
      "grad_norm": 10.243913650512695,
      "learning_rate": 4.997223079296514e-05,
      "loss": 0.5663,
      "step": 90
    },
    {
      "epoch": 0.030854674483184203,
      "grad_norm": 12.367879867553711,
      "learning_rate": 4.996914532551682e-05,
      "loss": 0.5426,
      "step": 100
    },
    {
      "epoch": 0.033940141931502625,
      "grad_norm": 11.986776351928711,
      "learning_rate": 4.9966059858068496e-05,
      "loss": 0.4798,
      "step": 110
    },
    {
      "epoch": 0.037025609379821044,
      "grad_norm": 10.35914421081543,
      "learning_rate": 4.996297439062018e-05,
      "loss": 0.4724,
      "step": 120
    },
    {
      "epoch": 0.04011107682813946,
      "grad_norm": 13.548033714294434,
      "learning_rate": 4.995988892317186e-05,
      "loss": 0.5087,
      "step": 130
    },
    {
      "epoch": 0.04319654427645788,
      "grad_norm": 15.711309432983398,
      "learning_rate": 4.9956803455723544e-05,
      "loss": 0.555,
      "step": 140
    },
    {
      "epoch": 0.046282011724776306,
      "grad_norm": 8.737156867980957,
      "learning_rate": 4.9953717988275226e-05,
      "loss": 0.5015,
      "step": 150
    },
    {
      "epoch": 0.049367479173094725,
      "grad_norm": 9.291111946105957,
      "learning_rate": 4.995063252082691e-05,
      "loss": 0.534,
      "step": 160
    },
    {
      "epoch": 0.05245294662141314,
      "grad_norm": 15.080353736877441,
      "learning_rate": 4.994754705337859e-05,
      "loss": 0.4293,
      "step": 170
    },
    {
      "epoch": 0.05553841406973156,
      "grad_norm": 8.867287635803223,
      "learning_rate": 4.994446158593027e-05,
      "loss": 0.3715,
      "step": 180
    },
    {
      "epoch": 0.05862388151804999,
      "grad_norm": 17.6668643951416,
      "learning_rate": 4.9941376118481956e-05,
      "loss": 0.446,
      "step": 190
    },
    {
      "epoch": 0.061709348966368406,
      "grad_norm": 14.26965045928955,
      "learning_rate": 4.993829065103363e-05,
      "loss": 0.396,
      "step": 200
    },
    {
      "epoch": 0.06479481641468683,
      "grad_norm": 9.175837516784668,
      "learning_rate": 4.9935205183585314e-05,
      "loss": 0.4443,
      "step": 210
    },
    {
      "epoch": 0.06788028386300525,
      "grad_norm": 11.54881763458252,
      "learning_rate": 4.9932119716136997e-05,
      "loss": 0.3769,
      "step": 220
    },
    {
      "epoch": 0.07096575131132367,
      "grad_norm": 13.199764251708984,
      "learning_rate": 4.992903424868868e-05,
      "loss": 0.3597,
      "step": 230
    },
    {
      "epoch": 0.07405121875964209,
      "grad_norm": 12.540417671203613,
      "learning_rate": 4.992594878124036e-05,
      "loss": 0.4681,
      "step": 240
    },
    {
      "epoch": 0.0771366862079605,
      "grad_norm": 14.996253967285156,
      "learning_rate": 4.992286331379204e-05,
      "loss": 0.4169,
      "step": 250
    },
    {
      "epoch": 0.08022215365627892,
      "grad_norm": 10.996352195739746,
      "learning_rate": 4.9919777846343726e-05,
      "loss": 0.4901,
      "step": 260
    },
    {
      "epoch": 0.08330762110459734,
      "grad_norm": 11.5623140335083,
      "learning_rate": 4.991669237889541e-05,
      "loss": 0.4183,
      "step": 270
    },
    {
      "epoch": 0.08639308855291576,
      "grad_norm": 11.717171669006348,
      "learning_rate": 4.9913606911447085e-05,
      "loss": 0.4457,
      "step": 280
    },
    {
      "epoch": 0.08947855600123418,
      "grad_norm": 6.590251445770264,
      "learning_rate": 4.991052144399877e-05,
      "loss": 0.4261,
      "step": 290
    },
    {
      "epoch": 0.09256402344955261,
      "grad_norm": 5.533209323883057,
      "learning_rate": 4.990743597655045e-05,
      "loss": 0.3915,
      "step": 300
    },
    {
      "epoch": 0.09564949089787103,
      "grad_norm": 9.806930541992188,
      "learning_rate": 4.990435050910213e-05,
      "loss": 0.4289,
      "step": 310
    },
    {
      "epoch": 0.09873495834618945,
      "grad_norm": 8.020221710205078,
      "learning_rate": 4.990126504165381e-05,
      "loss": 0.4117,
      "step": 320
    },
    {
      "epoch": 0.10182042579450787,
      "grad_norm": 6.744877815246582,
      "learning_rate": 4.98981795742055e-05,
      "loss": 0.36,
      "step": 330
    },
    {
      "epoch": 0.10490589324282629,
      "grad_norm": 14.377557754516602,
      "learning_rate": 4.989509410675718e-05,
      "loss": 0.3831,
      "step": 340
    },
    {
      "epoch": 0.1079913606911447,
      "grad_norm": 14.39938735961914,
      "learning_rate": 4.9892008639308855e-05,
      "loss": 0.4419,
      "step": 350
    },
    {
      "epoch": 0.11107682813946312,
      "grad_norm": 10.656573295593262,
      "learning_rate": 4.988892317186054e-05,
      "loss": 0.4251,
      "step": 360
    },
    {
      "epoch": 0.11416229558778154,
      "grad_norm": 9.248702049255371,
      "learning_rate": 4.988583770441222e-05,
      "loss": 0.3787,
      "step": 370
    },
    {
      "epoch": 0.11724776303609998,
      "grad_norm": 11.614106178283691,
      "learning_rate": 4.98827522369639e-05,
      "loss": 0.3063,
      "step": 380
    },
    {
      "epoch": 0.1203332304844184,
      "grad_norm": 8.479427337646484,
      "learning_rate": 4.987966676951558e-05,
      "loss": 0.3812,
      "step": 390
    },
    {
      "epoch": 0.12341869793273681,
      "grad_norm": 10.24438762664795,
      "learning_rate": 4.987658130206727e-05,
      "loss": 0.3315,
      "step": 400
    },
    {
      "epoch": 0.12650416538105522,
      "grad_norm": 12.852489471435547,
      "learning_rate": 4.987349583461895e-05,
      "loss": 0.346,
      "step": 410
    },
    {
      "epoch": 0.12958963282937366,
      "grad_norm": 7.425551414489746,
      "learning_rate": 4.9870410367170626e-05,
      "loss": 0.3412,
      "step": 420
    },
    {
      "epoch": 0.13267510027769208,
      "grad_norm": 6.287721157073975,
      "learning_rate": 4.9867324899722315e-05,
      "loss": 0.2924,
      "step": 430
    },
    {
      "epoch": 0.1357605677260105,
      "grad_norm": 14.906290054321289,
      "learning_rate": 4.986423943227399e-05,
      "loss": 0.3279,
      "step": 440
    },
    {
      "epoch": 0.13884603517432892,
      "grad_norm": 8.849599838256836,
      "learning_rate": 4.986115396482567e-05,
      "loss": 0.2856,
      "step": 450
    },
    {
      "epoch": 0.14193150262264734,
      "grad_norm": 8.993465423583984,
      "learning_rate": 4.9858068497377356e-05,
      "loss": 0.3596,
      "step": 460
    },
    {
      "epoch": 0.14501697007096576,
      "grad_norm": 5.2501702308654785,
      "learning_rate": 4.985498302992904e-05,
      "loss": 0.2505,
      "step": 470
    },
    {
      "epoch": 0.14810243751928417,
      "grad_norm": 11.521885871887207,
      "learning_rate": 4.985189756248072e-05,
      "loss": 0.3238,
      "step": 480
    },
    {
      "epoch": 0.1511879049676026,
      "grad_norm": 15.69800090789795,
      "learning_rate": 4.9848812095032396e-05,
      "loss": 0.3849,
      "step": 490
    },
    {
      "epoch": 0.154273372415921,
      "grad_norm": 6.957537651062012,
      "learning_rate": 4.9845726627584086e-05,
      "loss": 0.3084,
      "step": 500
    },
    {
      "epoch": 0.15735883986423943,
      "grad_norm": 6.475297927856445,
      "learning_rate": 4.984264116013576e-05,
      "loss": 0.3265,
      "step": 510
    },
    {
      "epoch": 0.16044430731255785,
      "grad_norm": 11.083760261535645,
      "learning_rate": 4.9839555692687444e-05,
      "loss": 0.2931,
      "step": 520
    },
    {
      "epoch": 0.16352977476087627,
      "grad_norm": 6.7692108154296875,
      "learning_rate": 4.9836470225239126e-05,
      "loss": 0.2864,
      "step": 530
    },
    {
      "epoch": 0.16661524220919469,
      "grad_norm": 8.20155143737793,
      "learning_rate": 4.983338475779081e-05,
      "loss": 0.2754,
      "step": 540
    },
    {
      "epoch": 0.1697007096575131,
      "grad_norm": 13.074968338012695,
      "learning_rate": 4.983029929034249e-05,
      "loss": 0.2953,
      "step": 550
    },
    {
      "epoch": 0.17278617710583152,
      "grad_norm": 6.892662525177002,
      "learning_rate": 4.982721382289417e-05,
      "loss": 0.2276,
      "step": 560
    },
    {
      "epoch": 0.17587164455414994,
      "grad_norm": 7.539599895477295,
      "learning_rate": 4.9824128355445856e-05,
      "loss": 0.1973,
      "step": 570
    },
    {
      "epoch": 0.17895711200246836,
      "grad_norm": 11.130765914916992,
      "learning_rate": 4.982104288799753e-05,
      "loss": 0.2663,
      "step": 580
    },
    {
      "epoch": 0.1820425794507868,
      "grad_norm": 11.814481735229492,
      "learning_rate": 4.9817957420549214e-05,
      "loss": 0.2582,
      "step": 590
    },
    {
      "epoch": 0.18512804689910523,
      "grad_norm": 7.770637035369873,
      "learning_rate": 4.98148719531009e-05,
      "loss": 0.2637,
      "step": 600
    },
    {
      "epoch": 0.18821351434742364,
      "grad_norm": 7.501354694366455,
      "learning_rate": 4.981178648565258e-05,
      "loss": 0.2888,
      "step": 610
    },
    {
      "epoch": 0.19129898179574206,
      "grad_norm": 7.277084827423096,
      "learning_rate": 4.980870101820426e-05,
      "loss": 0.2398,
      "step": 620
    },
    {
      "epoch": 0.19438444924406048,
      "grad_norm": 7.512568473815918,
      "learning_rate": 4.980561555075594e-05,
      "loss": 0.234,
      "step": 630
    },
    {
      "epoch": 0.1974699166923789,
      "grad_norm": 15.183187484741211,
      "learning_rate": 4.980253008330763e-05,
      "loss": 0.2404,
      "step": 640
    },
    {
      "epoch": 0.20055538414069732,
      "grad_norm": 10.906001091003418,
      "learning_rate": 4.97994446158593e-05,
      "loss": 0.2447,
      "step": 650
    },
    {
      "epoch": 0.20364085158901574,
      "grad_norm": 10.27876091003418,
      "learning_rate": 4.9796359148410985e-05,
      "loss": 0.2921,
      "step": 660
    },
    {
      "epoch": 0.20672631903733416,
      "grad_norm": 8.492341041564941,
      "learning_rate": 4.9793273680962674e-05,
      "loss": 0.2548,
      "step": 670
    },
    {
      "epoch": 0.20981178648565257,
      "grad_norm": 8.871917724609375,
      "learning_rate": 4.979018821351435e-05,
      "loss": 0.2525,
      "step": 680
    },
    {
      "epoch": 0.212897253933971,
      "grad_norm": 5.8378825187683105,
      "learning_rate": 4.978710274606603e-05,
      "loss": 0.2755,
      "step": 690
    },
    {
      "epoch": 0.2159827213822894,
      "grad_norm": 19.461103439331055,
      "learning_rate": 4.9784017278617715e-05,
      "loss": 0.2758,
      "step": 700
    },
    {
      "epoch": 0.21906818883060783,
      "grad_norm": 15.999390602111816,
      "learning_rate": 4.97809318111694e-05,
      "loss": 0.246,
      "step": 710
    },
    {
      "epoch": 0.22215365627892625,
      "grad_norm": 10.704001426696777,
      "learning_rate": 4.977784634372107e-05,
      "loss": 0.3178,
      "step": 720
    },
    {
      "epoch": 0.22523912372724467,
      "grad_norm": 9.330255508422852,
      "learning_rate": 4.9774760876272755e-05,
      "loss": 0.2761,
      "step": 730
    },
    {
      "epoch": 0.22832459117556309,
      "grad_norm": 11.373574256896973,
      "learning_rate": 4.9771675408824445e-05,
      "loss": 0.2287,
      "step": 740
    },
    {
      "epoch": 0.23141005862388153,
      "grad_norm": 10.817360877990723,
      "learning_rate": 4.976858994137612e-05,
      "loss": 0.22,
      "step": 750
    },
    {
      "epoch": 0.23449552607219995,
      "grad_norm": 17.00019645690918,
      "learning_rate": 4.97655044739278e-05,
      "loss": 0.2555,
      "step": 760
    },
    {
      "epoch": 0.23758099352051837,
      "grad_norm": 10.07417106628418,
      "learning_rate": 4.9762419006479485e-05,
      "loss": 0.2911,
      "step": 770
    },
    {
      "epoch": 0.2406664609688368,
      "grad_norm": 10.171198844909668,
      "learning_rate": 4.975933353903117e-05,
      "loss": 0.2692,
      "step": 780
    },
    {
      "epoch": 0.2437519284171552,
      "grad_norm": 7.666544437408447,
      "learning_rate": 4.9756248071582844e-05,
      "loss": 0.2558,
      "step": 790
    },
    {
      "epoch": 0.24683739586547362,
      "grad_norm": 9.380486488342285,
      "learning_rate": 4.9753162604134526e-05,
      "loss": 0.2149,
      "step": 800
    },
    {
      "epoch": 0.24992286331379204,
      "grad_norm": 4.302642345428467,
      "learning_rate": 4.9750077136686215e-05,
      "loss": 0.2011,
      "step": 810
    },
    {
      "epoch": 0.25300833076211043,
      "grad_norm": 7.855818271636963,
      "learning_rate": 4.974699166923789e-05,
      "loss": 0.2795,
      "step": 820
    },
    {
      "epoch": 0.2560937982104289,
      "grad_norm": 4.704406261444092,
      "learning_rate": 4.9743906201789573e-05,
      "loss": 0.2366,
      "step": 830
    },
    {
      "epoch": 0.2591792656587473,
      "grad_norm": 5.60310173034668,
      "learning_rate": 4.9740820734341256e-05,
      "loss": 0.2379,
      "step": 840
    },
    {
      "epoch": 0.2622647331070657,
      "grad_norm": 6.1646246910095215,
      "learning_rate": 4.973773526689294e-05,
      "loss": 0.2016,
      "step": 850
    },
    {
      "epoch": 0.26535020055538416,
      "grad_norm": 5.664270877838135,
      "learning_rate": 4.9734649799444614e-05,
      "loss": 0.2039,
      "step": 860
    },
    {
      "epoch": 0.26843566800370255,
      "grad_norm": 10.523681640625,
      "learning_rate": 4.9731564331996297e-05,
      "loss": 0.2359,
      "step": 870
    },
    {
      "epoch": 0.271521135452021,
      "grad_norm": 5.728372573852539,
      "learning_rate": 4.9728478864547986e-05,
      "loss": 0.2097,
      "step": 880
    },
    {
      "epoch": 0.2746066029003394,
      "grad_norm": 7.829580783843994,
      "learning_rate": 4.972539339709966e-05,
      "loss": 0.223,
      "step": 890
    },
    {
      "epoch": 0.27769207034865784,
      "grad_norm": 8.348499298095703,
      "learning_rate": 4.9722307929651344e-05,
      "loss": 0.2193,
      "step": 900
    },
    {
      "epoch": 0.28077753779697623,
      "grad_norm": 3.494960308074951,
      "learning_rate": 4.9719222462203026e-05,
      "loss": 0.222,
      "step": 910
    },
    {
      "epoch": 0.2838630052452947,
      "grad_norm": 6.161359786987305,
      "learning_rate": 4.971613699475471e-05,
      "loss": 0.2196,
      "step": 920
    },
    {
      "epoch": 0.28694847269361307,
      "grad_norm": 5.313370227813721,
      "learning_rate": 4.9713051527306385e-05,
      "loss": 0.1894,
      "step": 930
    },
    {
      "epoch": 0.2900339401419315,
      "grad_norm": 5.110506534576416,
      "learning_rate": 4.9709966059858074e-05,
      "loss": 0.1943,
      "step": 940
    },
    {
      "epoch": 0.2931194075902499,
      "grad_norm": 6.630126953125,
      "learning_rate": 4.9706880592409756e-05,
      "loss": 0.2217,
      "step": 950
    },
    {
      "epoch": 0.29620487503856835,
      "grad_norm": 7.5201191902160645,
      "learning_rate": 4.970379512496143e-05,
      "loss": 0.1752,
      "step": 960
    },
    {
      "epoch": 0.29929034248688674,
      "grad_norm": 11.067693710327148,
      "learning_rate": 4.9700709657513115e-05,
      "loss": 0.1874,
      "step": 970
    },
    {
      "epoch": 0.3023758099352052,
      "grad_norm": 6.880926609039307,
      "learning_rate": 4.96976241900648e-05,
      "loss": 0.2358,
      "step": 980
    },
    {
      "epoch": 0.3054612773835236,
      "grad_norm": 8.182134628295898,
      "learning_rate": 4.969453872261648e-05,
      "loss": 0.1965,
      "step": 990
    },
    {
      "epoch": 0.308546744831842,
      "grad_norm": 4.936672687530518,
      "learning_rate": 4.9691453255168155e-05,
      "loss": 0.1969,
      "step": 1000
    },
    {
      "epoch": 0.31163221228016047,
      "grad_norm": 4.972494602203369,
      "learning_rate": 4.9688367787719844e-05,
      "loss": 0.2074,
      "step": 1010
    },
    {
      "epoch": 0.31471767972847886,
      "grad_norm": 10.93846607208252,
      "learning_rate": 4.968528232027153e-05,
      "loss": 0.2179,
      "step": 1020
    },
    {
      "epoch": 0.3178031471767973,
      "grad_norm": 6.235913276672363,
      "learning_rate": 4.96821968528232e-05,
      "loss": 0.1997,
      "step": 1030
    },
    {
      "epoch": 0.3208886146251157,
      "grad_norm": 7.719786167144775,
      "learning_rate": 4.9679111385374885e-05,
      "loss": 0.1793,
      "step": 1040
    },
    {
      "epoch": 0.32397408207343414,
      "grad_norm": 8.33140754699707,
      "learning_rate": 4.967602591792657e-05,
      "loss": 0.2176,
      "step": 1050
    },
    {
      "epoch": 0.32705954952175254,
      "grad_norm": 7.488930702209473,
      "learning_rate": 4.967294045047825e-05,
      "loss": 0.1911,
      "step": 1060
    },
    {
      "epoch": 0.330145016970071,
      "grad_norm": 8.522989273071289,
      "learning_rate": 4.9669854983029926e-05,
      "loss": 0.2481,
      "step": 1070
    },
    {
      "epoch": 0.33323048441838937,
      "grad_norm": 13.70817756652832,
      "learning_rate": 4.9666769515581615e-05,
      "loss": 0.2529,
      "step": 1080
    },
    {
      "epoch": 0.3363159518667078,
      "grad_norm": 8.349957466125488,
      "learning_rate": 4.96636840481333e-05,
      "loss": 0.1854,
      "step": 1090
    },
    {
      "epoch": 0.3394014193150262,
      "grad_norm": 8.247239112854004,
      "learning_rate": 4.966059858068497e-05,
      "loss": 0.2461,
      "step": 1100
    },
    {
      "epoch": 0.34248688676334466,
      "grad_norm": 6.919186115264893,
      "learning_rate": 4.9657513113236656e-05,
      "loss": 0.1945,
      "step": 1110
    },
    {
      "epoch": 0.34557235421166305,
      "grad_norm": 6.90193510055542,
      "learning_rate": 4.965442764578834e-05,
      "loss": 0.2041,
      "step": 1120
    },
    {
      "epoch": 0.3486578216599815,
      "grad_norm": 10.66347599029541,
      "learning_rate": 4.965134217834002e-05,
      "loss": 0.2464,
      "step": 1130
    },
    {
      "epoch": 0.3517432891082999,
      "grad_norm": 8.252853393554688,
      "learning_rate": 4.96482567108917e-05,
      "loss": 0.2287,
      "step": 1140
    },
    {
      "epoch": 0.35482875655661833,
      "grad_norm": 9.162557601928711,
      "learning_rate": 4.9645171243443386e-05,
      "loss": 0.1932,
      "step": 1150
    },
    {
      "epoch": 0.3579142240049367,
      "grad_norm": 8.723533630371094,
      "learning_rate": 4.964208577599507e-05,
      "loss": 0.2462,
      "step": 1160
    },
    {
      "epoch": 0.36099969145325517,
      "grad_norm": 6.277853012084961,
      "learning_rate": 4.9639000308546744e-05,
      "loss": 0.1845,
      "step": 1170
    },
    {
      "epoch": 0.3640851589015736,
      "grad_norm": 6.256616592407227,
      "learning_rate": 4.963591484109843e-05,
      "loss": 0.1658,
      "step": 1180
    },
    {
      "epoch": 0.367170626349892,
      "grad_norm": 9.857622146606445,
      "learning_rate": 4.963282937365011e-05,
      "loss": 0.2282,
      "step": 1190
    },
    {
      "epoch": 0.37025609379821045,
      "grad_norm": 8.250821113586426,
      "learning_rate": 4.962974390620179e-05,
      "loss": 0.1844,
      "step": 1200
    },
    {
      "epoch": 0.37334156124652884,
      "grad_norm": 3.202406406402588,
      "learning_rate": 4.9626658438753474e-05,
      "loss": 0.1706,
      "step": 1210
    },
    {
      "epoch": 0.3764270286948473,
      "grad_norm": 5.014209270477295,
      "learning_rate": 4.9623572971305156e-05,
      "loss": 0.1871,
      "step": 1220
    },
    {
      "epoch": 0.3795124961431657,
      "grad_norm": 4.985440254211426,
      "learning_rate": 4.962048750385684e-05,
      "loss": 0.1935,
      "step": 1230
    },
    {
      "epoch": 0.3825979635914841,
      "grad_norm": 11.016701698303223,
      "learning_rate": 4.9617402036408514e-05,
      "loss": 0.2108,
      "step": 1240
    },
    {
      "epoch": 0.3856834310398025,
      "grad_norm": 6.085229873657227,
      "learning_rate": 4.9614316568960204e-05,
      "loss": 0.1885,
      "step": 1250
    },
    {
      "epoch": 0.38876889848812096,
      "grad_norm": 8.848089218139648,
      "learning_rate": 4.961123110151188e-05,
      "loss": 0.2493,
      "step": 1260
    },
    {
      "epoch": 0.39185436593643935,
      "grad_norm": 4.288418292999268,
      "learning_rate": 4.960814563406356e-05,
      "loss": 0.183,
      "step": 1270
    },
    {
      "epoch": 0.3949398333847578,
      "grad_norm": 6.240124225616455,
      "learning_rate": 4.9605060166615244e-05,
      "loss": 0.2018,
      "step": 1280
    },
    {
      "epoch": 0.3980253008330762,
      "grad_norm": 7.071642875671387,
      "learning_rate": 4.960197469916693e-05,
      "loss": 0.214,
      "step": 1290
    },
    {
      "epoch": 0.40111076828139464,
      "grad_norm": 2.3441505432128906,
      "learning_rate": 4.959888923171861e-05,
      "loss": 0.1923,
      "step": 1300
    },
    {
      "epoch": 0.404196235729713,
      "grad_norm": 7.605021953582764,
      "learning_rate": 4.9595803764270285e-05,
      "loss": 0.2434,
      "step": 1310
    },
    {
      "epoch": 0.4072817031780315,
      "grad_norm": 5.662563323974609,
      "learning_rate": 4.9592718296821974e-05,
      "loss": 0.1768,
      "step": 1320
    },
    {
      "epoch": 0.4103671706263499,
      "grad_norm": 6.117793083190918,
      "learning_rate": 4.958963282937365e-05,
      "loss": 0.1848,
      "step": 1330
    },
    {
      "epoch": 0.4134526380746683,
      "grad_norm": 5.553462028503418,
      "learning_rate": 4.958654736192533e-05,
      "loss": 0.1445,
      "step": 1340
    },
    {
      "epoch": 0.41653810552298676,
      "grad_norm": 6.119046688079834,
      "learning_rate": 4.9583461894477015e-05,
      "loss": 0.2101,
      "step": 1350
    },
    {
      "epoch": 0.41962357297130515,
      "grad_norm": 4.6395955085754395,
      "learning_rate": 4.95803764270287e-05,
      "loss": 0.2074,
      "step": 1360
    },
    {
      "epoch": 0.4227090404196236,
      "grad_norm": 4.548567295074463,
      "learning_rate": 4.957729095958038e-05,
      "loss": 0.1619,
      "step": 1370
    },
    {
      "epoch": 0.425794507867942,
      "grad_norm": 7.996307373046875,
      "learning_rate": 4.9574205492132055e-05,
      "loss": 0.2093,
      "step": 1380
    },
    {
      "epoch": 0.42887997531626043,
      "grad_norm": 8.655308723449707,
      "learning_rate": 4.9571120024683745e-05,
      "loss": 0.2072,
      "step": 1390
    },
    {
      "epoch": 0.4319654427645788,
      "grad_norm": 3.900221824645996,
      "learning_rate": 4.956803455723542e-05,
      "loss": 0.1612,
      "step": 1400
    },
    {
      "epoch": 0.43505091021289727,
      "grad_norm": 6.294929504394531,
      "learning_rate": 4.95649490897871e-05,
      "loss": 0.1875,
      "step": 1410
    },
    {
      "epoch": 0.43813637766121566,
      "grad_norm": 8.196599006652832,
      "learning_rate": 4.956186362233879e-05,
      "loss": 0.1712,
      "step": 1420
    },
    {
      "epoch": 0.4412218451095341,
      "grad_norm": 5.2819905281066895,
      "learning_rate": 4.955877815489047e-05,
      "loss": 0.1706,
      "step": 1430
    },
    {
      "epoch": 0.4443073125578525,
      "grad_norm": 3.7714786529541016,
      "learning_rate": 4.955569268744215e-05,
      "loss": 0.1757,
      "step": 1440
    },
    {
      "epoch": 0.44739278000617094,
      "grad_norm": 5.478630065917969,
      "learning_rate": 4.955260721999383e-05,
      "loss": 0.1457,
      "step": 1450
    },
    {
      "epoch": 0.45047824745448933,
      "grad_norm": 6.989325523376465,
      "learning_rate": 4.9549521752545515e-05,
      "loss": 0.1724,
      "step": 1460
    },
    {
      "epoch": 0.4535637149028078,
      "grad_norm": 3.892709255218506,
      "learning_rate": 4.954643628509719e-05,
      "loss": 0.1973,
      "step": 1470
    },
    {
      "epoch": 0.45664918235112617,
      "grad_norm": 6.8816752433776855,
      "learning_rate": 4.9543350817648873e-05,
      "loss": 0.1846,
      "step": 1480
    },
    {
      "epoch": 0.4597346497994446,
      "grad_norm": 3.910928726196289,
      "learning_rate": 4.954026535020056e-05,
      "loss": 0.165,
      "step": 1490
    },
    {
      "epoch": 0.46282011724776306,
      "grad_norm": 6.632297992706299,
      "learning_rate": 4.953717988275224e-05,
      "loss": 0.1736,
      "step": 1500
    },
    {
      "epoch": 0.46590558469608145,
      "grad_norm": 5.244892120361328,
      "learning_rate": 4.953409441530392e-05,
      "loss": 0.17,
      "step": 1510
    },
    {
      "epoch": 0.4689910521443999,
      "grad_norm": 10.74063777923584,
      "learning_rate": 4.95310089478556e-05,
      "loss": 0.1856,
      "step": 1520
    },
    {
      "epoch": 0.4720765195927183,
      "grad_norm": 4.2172627449035645,
      "learning_rate": 4.9527923480407286e-05,
      "loss": 0.1959,
      "step": 1530
    },
    {
      "epoch": 0.47516198704103674,
      "grad_norm": 6.259178638458252,
      "learning_rate": 4.952483801295897e-05,
      "loss": 0.1676,
      "step": 1540
    },
    {
      "epoch": 0.47824745448935513,
      "grad_norm": 6.240847110748291,
      "learning_rate": 4.9521752545510644e-05,
      "loss": 0.1912,
      "step": 1550
    },
    {
      "epoch": 0.4813329219376736,
      "grad_norm": 6.478869438171387,
      "learning_rate": 4.951866707806233e-05,
      "loss": 0.166,
      "step": 1560
    },
    {
      "epoch": 0.48441838938599197,
      "grad_norm": 2.8346879482269287,
      "learning_rate": 4.951558161061401e-05,
      "loss": 0.153,
      "step": 1570
    },
    {
      "epoch": 0.4875038568343104,
      "grad_norm": 4.2374749183654785,
      "learning_rate": 4.951249614316569e-05,
      "loss": 0.212,
      "step": 1580
    },
    {
      "epoch": 0.4905893242826288,
      "grad_norm": 3.754333019256592,
      "learning_rate": 4.9509410675717374e-05,
      "loss": 0.1838,
      "step": 1590
    },
    {
      "epoch": 0.49367479173094725,
      "grad_norm": 5.178046703338623,
      "learning_rate": 4.9506325208269056e-05,
      "loss": 0.186,
      "step": 1600
    },
    {
      "epoch": 0.49676025917926564,
      "grad_norm": 3.315142869949341,
      "learning_rate": 4.950323974082074e-05,
      "loss": 0.1446,
      "step": 1610
    },
    {
      "epoch": 0.4998457266275841,
      "grad_norm": 7.464227199554443,
      "learning_rate": 4.9500154273372415e-05,
      "loss": 0.171,
      "step": 1620
    },
    {
      "epoch": 0.5029311940759025,
      "grad_norm": 7.511530876159668,
      "learning_rate": 4.9497068805924104e-05,
      "loss": 0.1767,
      "step": 1630
    },
    {
      "epoch": 0.5060166615242209,
      "grad_norm": 3.2921640872955322,
      "learning_rate": 4.949398333847578e-05,
      "loss": 0.2011,
      "step": 1640
    },
    {
      "epoch": 0.5091021289725394,
      "grad_norm": 3.4832355976104736,
      "learning_rate": 4.949089787102746e-05,
      "loss": 0.1692,
      "step": 1650
    },
    {
      "epoch": 0.5121875964208578,
      "grad_norm": 4.796008110046387,
      "learning_rate": 4.9487812403579144e-05,
      "loss": 0.1772,
      "step": 1660
    },
    {
      "epoch": 0.5152730638691762,
      "grad_norm": 3.370575189590454,
      "learning_rate": 4.948472693613083e-05,
      "loss": 0.1665,
      "step": 1670
    },
    {
      "epoch": 0.5183585313174947,
      "grad_norm": 3.9045751094818115,
      "learning_rate": 4.948164146868251e-05,
      "loss": 0.1547,
      "step": 1680
    },
    {
      "epoch": 0.521443998765813,
      "grad_norm": 3.6931259632110596,
      "learning_rate": 4.947855600123419e-05,
      "loss": 0.1683,
      "step": 1690
    },
    {
      "epoch": 0.5245294662141314,
      "grad_norm": 5.862268924713135,
      "learning_rate": 4.9475470533785874e-05,
      "loss": 0.1355,
      "step": 1700
    },
    {
      "epoch": 0.5276149336624498,
      "grad_norm": 9.393953323364258,
      "learning_rate": 4.947238506633755e-05,
      "loss": 0.142,
      "step": 1710
    },
    {
      "epoch": 0.5307004011107683,
      "grad_norm": 6.574726581573486,
      "learning_rate": 4.946929959888923e-05,
      "loss": 0.1708,
      "step": 1720
    },
    {
      "epoch": 0.5337858685590867,
      "grad_norm": 3.9802470207214355,
      "learning_rate": 4.9466214131440915e-05,
      "loss": 0.1662,
      "step": 1730
    },
    {
      "epoch": 0.5368713360074051,
      "grad_norm": 9.582436561584473,
      "learning_rate": 4.94631286639926e-05,
      "loss": 0.1667,
      "step": 1740
    },
    {
      "epoch": 0.5399568034557235,
      "grad_norm": 3.279055595397949,
      "learning_rate": 4.946004319654428e-05,
      "loss": 0.1521,
      "step": 1750
    },
    {
      "epoch": 0.543042270904042,
      "grad_norm": 11.86902904510498,
      "learning_rate": 4.945695772909596e-05,
      "loss": 0.243,
      "step": 1760
    },
    {
      "epoch": 0.5461277383523604,
      "grad_norm": 3.805748462677002,
      "learning_rate": 4.9453872261647645e-05,
      "loss": 0.1354,
      "step": 1770
    },
    {
      "epoch": 0.5492132058006788,
      "grad_norm": 7.453946113586426,
      "learning_rate": 4.945078679419932e-05,
      "loss": 0.1325,
      "step": 1780
    },
    {
      "epoch": 0.5522986732489972,
      "grad_norm": 5.699222564697266,
      "learning_rate": 4.9447701326751e-05,
      "loss": 0.1521,
      "step": 1790
    },
    {
      "epoch": 0.5553841406973157,
      "grad_norm": 2.6372852325439453,
      "learning_rate": 4.9444615859302686e-05,
      "loss": 0.1193,
      "step": 1800
    },
    {
      "epoch": 0.5584696081456341,
      "grad_norm": 6.762204647064209,
      "learning_rate": 4.944153039185437e-05,
      "loss": 0.1545,
      "step": 1810
    },
    {
      "epoch": 0.5615550755939525,
      "grad_norm": 5.471158027648926,
      "learning_rate": 4.943844492440605e-05,
      "loss": 0.1222,
      "step": 1820
    },
    {
      "epoch": 0.564640543042271,
      "grad_norm": 7.703410625457764,
      "learning_rate": 4.943535945695773e-05,
      "loss": 0.1502,
      "step": 1830
    },
    {
      "epoch": 0.5677260104905894,
      "grad_norm": 9.895483016967773,
      "learning_rate": 4.9432273989509416e-05,
      "loss": 0.1675,
      "step": 1840
    },
    {
      "epoch": 0.5708114779389077,
      "grad_norm": 7.657535076141357,
      "learning_rate": 4.942918852206109e-05,
      "loss": 0.1682,
      "step": 1850
    },
    {
      "epoch": 0.5738969453872261,
      "grad_norm": 6.105162620544434,
      "learning_rate": 4.9426103054612774e-05,
      "loss": 0.1598,
      "step": 1860
    },
    {
      "epoch": 0.5769824128355446,
      "grad_norm": 4.853404998779297,
      "learning_rate": 4.9423017587164456e-05,
      "loss": 0.1331,
      "step": 1870
    },
    {
      "epoch": 0.580067880283863,
      "grad_norm": 4.522270679473877,
      "learning_rate": 4.941993211971614e-05,
      "loss": 0.1207,
      "step": 1880
    },
    {
      "epoch": 0.5831533477321814,
      "grad_norm": 5.420522212982178,
      "learning_rate": 4.941684665226782e-05,
      "loss": 0.1214,
      "step": 1890
    },
    {
      "epoch": 0.5862388151804998,
      "grad_norm": 2.151580333709717,
      "learning_rate": 4.9413761184819504e-05,
      "loss": 0.1313,
      "step": 1900
    },
    {
      "epoch": 0.5893242826288183,
      "grad_norm": 5.8639912605285645,
      "learning_rate": 4.9410675717371186e-05,
      "loss": 0.126,
      "step": 1910
    },
    {
      "epoch": 0.5924097500771367,
      "grad_norm": 5.502881050109863,
      "learning_rate": 4.940759024992286e-05,
      "loss": 0.1425,
      "step": 1920
    },
    {
      "epoch": 0.5954952175254551,
      "grad_norm": 3.6721014976501465,
      "learning_rate": 4.940450478247455e-05,
      "loss": 0.1359,
      "step": 1930
    },
    {
      "epoch": 0.5985806849737735,
      "grad_norm": 8.730202674865723,
      "learning_rate": 4.940141931502623e-05,
      "loss": 0.184,
      "step": 1940
    },
    {
      "epoch": 0.601666152422092,
      "grad_norm": 3.998626470565796,
      "learning_rate": 4.939833384757791e-05,
      "loss": 0.1553,
      "step": 1950
    },
    {
      "epoch": 0.6047516198704104,
      "grad_norm": 4.611184597015381,
      "learning_rate": 4.939524838012959e-05,
      "loss": 0.1587,
      "step": 1960
    },
    {
      "epoch": 0.6078370873187288,
      "grad_norm": 6.038239479064941,
      "learning_rate": 4.9392162912681274e-05,
      "loss": 0.1841,
      "step": 1970
    },
    {
      "epoch": 0.6109225547670472,
      "grad_norm": 11.199738502502441,
      "learning_rate": 4.938907744523296e-05,
      "loss": 0.1854,
      "step": 1980
    },
    {
      "epoch": 0.6140080222153657,
      "grad_norm": 4.796965599060059,
      "learning_rate": 4.938599197778463e-05,
      "loss": 0.1939,
      "step": 1990
    },
    {
      "epoch": 0.617093489663684,
      "grad_norm": 5.190706253051758,
      "learning_rate": 4.938290651033632e-05,
      "loss": 0.1492,
      "step": 2000
    },
    {
      "epoch": 0.6201789571120024,
      "grad_norm": 1.9069240093231201,
      "learning_rate": 4.9379821042888004e-05,
      "loss": 0.1237,
      "step": 2010
    },
    {
      "epoch": 0.6232644245603209,
      "grad_norm": 4.952075481414795,
      "learning_rate": 4.937673557543968e-05,
      "loss": 0.143,
      "step": 2020
    },
    {
      "epoch": 0.6263498920086393,
      "grad_norm": 3.5634381771087646,
      "learning_rate": 4.937365010799136e-05,
      "loss": 0.149,
      "step": 2030
    },
    {
      "epoch": 0.6294353594569577,
      "grad_norm": 2.2134342193603516,
      "learning_rate": 4.9370564640543045e-05,
      "loss": 0.12,
      "step": 2040
    },
    {
      "epoch": 0.6325208269052761,
      "grad_norm": 4.065577507019043,
      "learning_rate": 4.936747917309473e-05,
      "loss": 0.1206,
      "step": 2050
    },
    {
      "epoch": 0.6356062943535946,
      "grad_norm": 3.434309959411621,
      "learning_rate": 4.93643937056464e-05,
      "loss": 0.1211,
      "step": 2060
    },
    {
      "epoch": 0.638691761801913,
      "grad_norm": 6.567366123199463,
      "learning_rate": 4.936130823819809e-05,
      "loss": 0.1628,
      "step": 2070
    },
    {
      "epoch": 0.6417772292502314,
      "grad_norm": 4.461123466491699,
      "learning_rate": 4.9358222770749775e-05,
      "loss": 0.1159,
      "step": 2080
    },
    {
      "epoch": 0.6448626966985498,
      "grad_norm": 3.974512815475464,
      "learning_rate": 4.935513730330145e-05,
      "loss": 0.1024,
      "step": 2090
    },
    {
      "epoch": 0.6479481641468683,
      "grad_norm": 4.499353408813477,
      "learning_rate": 4.935205183585313e-05,
      "loss": 0.1509,
      "step": 2100
    },
    {
      "epoch": 0.6510336315951867,
      "grad_norm": 6.907101631164551,
      "learning_rate": 4.9348966368404815e-05,
      "loss": 0.1557,
      "step": 2110
    },
    {
      "epoch": 0.6541190990435051,
      "grad_norm": 7.468085765838623,
      "learning_rate": 4.93458809009565e-05,
      "loss": 0.1339,
      "step": 2120
    },
    {
      "epoch": 0.6572045664918235,
      "grad_norm": 2.405057907104492,
      "learning_rate": 4.9342795433508173e-05,
      "loss": 0.1374,
      "step": 2130
    },
    {
      "epoch": 0.660290033940142,
      "grad_norm": 3.651822566986084,
      "learning_rate": 4.933970996605986e-05,
      "loss": 0.1102,
      "step": 2140
    },
    {
      "epoch": 0.6633755013884604,
      "grad_norm": 6.4771928787231445,
      "learning_rate": 4.9336624498611545e-05,
      "loss": 0.1539,
      "step": 2150
    },
    {
      "epoch": 0.6664609688367787,
      "grad_norm": 7.377394676208496,
      "learning_rate": 4.933353903116322e-05,
      "loss": 0.134,
      "step": 2160
    },
    {
      "epoch": 0.6695464362850972,
      "grad_norm": 4.793108940124512,
      "learning_rate": 4.933045356371491e-05,
      "loss": 0.1055,
      "step": 2170
    },
    {
      "epoch": 0.6726319037334156,
      "grad_norm": 3.519256114959717,
      "learning_rate": 4.9327368096266586e-05,
      "loss": 0.1263,
      "step": 2180
    },
    {
      "epoch": 0.675717371181734,
      "grad_norm": 9.83410358428955,
      "learning_rate": 4.932428262881827e-05,
      "loss": 0.1566,
      "step": 2190
    },
    {
      "epoch": 0.6788028386300524,
      "grad_norm": 5.097589492797852,
      "learning_rate": 4.932119716136995e-05,
      "loss": 0.1254,
      "step": 2200
    },
    {
      "epoch": 0.6818883060783709,
      "grad_norm": 5.246392726898193,
      "learning_rate": 4.931811169392163e-05,
      "loss": 0.1473,
      "step": 2210
    },
    {
      "epoch": 0.6849737735266893,
      "grad_norm": 6.695112228393555,
      "learning_rate": 4.9315026226473316e-05,
      "loss": 0.1348,
      "step": 2220
    },
    {
      "epoch": 0.6880592409750077,
      "grad_norm": 2.610771894454956,
      "learning_rate": 4.931194075902499e-05,
      "loss": 0.1082,
      "step": 2230
    },
    {
      "epoch": 0.6911447084233261,
      "grad_norm": 5.229327201843262,
      "learning_rate": 4.930885529157668e-05,
      "loss": 0.1151,
      "step": 2240
    },
    {
      "epoch": 0.6942301758716446,
      "grad_norm": 2.743910789489746,
      "learning_rate": 4.9305769824128356e-05,
      "loss": 0.1582,
      "step": 2250
    },
    {
      "epoch": 0.697315643319963,
      "grad_norm": 4.007831573486328,
      "learning_rate": 4.930268435668004e-05,
      "loss": 0.1212,
      "step": 2260
    },
    {
      "epoch": 0.7004011107682814,
      "grad_norm": 4.7136549949646,
      "learning_rate": 4.929959888923172e-05,
      "loss": 0.1166,
      "step": 2270
    },
    {
      "epoch": 0.7034865782165998,
      "grad_norm": 6.061555862426758,
      "learning_rate": 4.9296513421783404e-05,
      "loss": 0.0836,
      "step": 2280
    },
    {
      "epoch": 0.7065720456649183,
      "grad_norm": 7.176292896270752,
      "learning_rate": 4.9293427954335086e-05,
      "loss": 0.1256,
      "step": 2290
    },
    {
      "epoch": 0.7096575131132367,
      "grad_norm": 3.556570053100586,
      "learning_rate": 4.929034248688676e-05,
      "loss": 0.1234,
      "step": 2300
    },
    {
      "epoch": 0.712742980561555,
      "grad_norm": 3.736104965209961,
      "learning_rate": 4.928725701943845e-05,
      "loss": 0.1108,
      "step": 2310
    },
    {
      "epoch": 0.7158284480098734,
      "grad_norm": 5.548350811004639,
      "learning_rate": 4.928417155199013e-05,
      "loss": 0.1482,
      "step": 2320
    },
    {
      "epoch": 0.7189139154581919,
      "grad_norm": 2.596278667449951,
      "learning_rate": 4.928108608454181e-05,
      "loss": 0.1135,
      "step": 2330
    },
    {
      "epoch": 0.7219993829065103,
      "grad_norm": 4.091020584106445,
      "learning_rate": 4.927800061709349e-05,
      "loss": 0.0965,
      "step": 2340
    },
    {
      "epoch": 0.7250848503548287,
      "grad_norm": 4.202996730804443,
      "learning_rate": 4.9274915149645174e-05,
      "loss": 0.118,
      "step": 2350
    },
    {
      "epoch": 0.7281703178031472,
      "grad_norm": 2.788475275039673,
      "learning_rate": 4.927182968219686e-05,
      "loss": 0.1152,
      "step": 2360
    },
    {
      "epoch": 0.7312557852514656,
      "grad_norm": 9.536731719970703,
      "learning_rate": 4.926874421474853e-05,
      "loss": 0.1363,
      "step": 2370
    },
    {
      "epoch": 0.734341252699784,
      "grad_norm": 2.0113372802734375,
      "learning_rate": 4.926565874730022e-05,
      "loss": 0.1108,
      "step": 2380
    },
    {
      "epoch": 0.7374267201481024,
      "grad_norm": 6.316771507263184,
      "learning_rate": 4.92625732798519e-05,
      "loss": 0.1538,
      "step": 2390
    },
    {
      "epoch": 0.7405121875964209,
      "grad_norm": 2.6142163276672363,
      "learning_rate": 4.925948781240358e-05,
      "loss": 0.1395,
      "step": 2400
    },
    {
      "epoch": 0.7435976550447393,
      "grad_norm": 14.987590789794922,
      "learning_rate": 4.925640234495526e-05,
      "loss": 0.1236,
      "step": 2410
    },
    {
      "epoch": 0.7466831224930577,
      "grad_norm": 2.8221452236175537,
      "learning_rate": 4.9253316877506945e-05,
      "loss": 0.0885,
      "step": 2420
    },
    {
      "epoch": 0.7497685899413761,
      "grad_norm": 3.9294726848602295,
      "learning_rate": 4.925023141005863e-05,
      "loss": 0.1059,
      "step": 2430
    },
    {
      "epoch": 0.7528540573896946,
      "grad_norm": 5.15416955947876,
      "learning_rate": 4.924714594261031e-05,
      "loss": 0.1246,
      "step": 2440
    },
    {
      "epoch": 0.755939524838013,
      "grad_norm": 6.36623477935791,
      "learning_rate": 4.924406047516199e-05,
      "loss": 0.1331,
      "step": 2450
    },
    {
      "epoch": 0.7590249922863314,
      "grad_norm": 4.646439075469971,
      "learning_rate": 4.924097500771367e-05,
      "loss": 0.1362,
      "step": 2460
    },
    {
      "epoch": 0.7621104597346497,
      "grad_norm": 3.7809412479400635,
      "learning_rate": 4.923788954026535e-05,
      "loss": 0.117,
      "step": 2470
    },
    {
      "epoch": 0.7651959271829682,
      "grad_norm": 4.667619228363037,
      "learning_rate": 4.923480407281704e-05,
      "loss": 0.1237,
      "step": 2480
    },
    {
      "epoch": 0.7682813946312866,
      "grad_norm": 4.389898300170898,
      "learning_rate": 4.9231718605368716e-05,
      "loss": 0.1103,
      "step": 2490
    },
    {
      "epoch": 0.771366862079605,
      "grad_norm": 3.7731478214263916,
      "learning_rate": 4.92286331379204e-05,
      "loss": 0.1087,
      "step": 2500
    },
    {
      "epoch": 0.7744523295279235,
      "grad_norm": 2.887824058532715,
      "learning_rate": 4.922554767047208e-05,
      "loss": 0.1048,
      "step": 2510
    },
    {
      "epoch": 0.7775377969762419,
      "grad_norm": 5.738320350646973,
      "learning_rate": 4.922246220302376e-05,
      "loss": 0.1418,
      "step": 2520
    },
    {
      "epoch": 0.7806232644245603,
      "grad_norm": 4.457852363586426,
      "learning_rate": 4.921937673557544e-05,
      "loss": 0.11,
      "step": 2530
    },
    {
      "epoch": 0.7837087318728787,
      "grad_norm": 8.014531135559082,
      "learning_rate": 4.921629126812712e-05,
      "loss": 0.1302,
      "step": 2540
    },
    {
      "epoch": 0.7867941993211972,
      "grad_norm": 2.938640832901001,
      "learning_rate": 4.921320580067881e-05,
      "loss": 0.1124,
      "step": 2550
    },
    {
      "epoch": 0.7898796667695156,
      "grad_norm": 4.675080299377441,
      "learning_rate": 4.9210120333230486e-05,
      "loss": 0.1133,
      "step": 2560
    },
    {
      "epoch": 0.792965134217834,
      "grad_norm": 4.875875949859619,
      "learning_rate": 4.920703486578217e-05,
      "loss": 0.1035,
      "step": 2570
    },
    {
      "epoch": 0.7960506016661524,
      "grad_norm": 4.946611404418945,
      "learning_rate": 4.920394939833385e-05,
      "loss": 0.1331,
      "step": 2580
    },
    {
      "epoch": 0.7991360691144709,
      "grad_norm": 4.119841575622559,
      "learning_rate": 4.9200863930885534e-05,
      "loss": 0.1399,
      "step": 2590
    },
    {
      "epoch": 0.8022215365627893,
      "grad_norm": 4.168419361114502,
      "learning_rate": 4.919777846343721e-05,
      "loss": 0.1442,
      "step": 2600
    },
    {
      "epoch": 0.8053070040111077,
      "grad_norm": 6.426599979400635,
      "learning_rate": 4.919469299598889e-05,
      "loss": 0.1011,
      "step": 2610
    },
    {
      "epoch": 0.808392471459426,
      "grad_norm": 4.9320597648620605,
      "learning_rate": 4.919160752854058e-05,
      "loss": 0.116,
      "step": 2620
    },
    {
      "epoch": 0.8114779389077446,
      "grad_norm": 2.6654043197631836,
      "learning_rate": 4.918852206109226e-05,
      "loss": 0.1134,
      "step": 2630
    },
    {
      "epoch": 0.814563406356063,
      "grad_norm": 4.488969326019287,
      "learning_rate": 4.918543659364394e-05,
      "loss": 0.1499,
      "step": 2640
    },
    {
      "epoch": 0.8176488738043813,
      "grad_norm": 4.686694145202637,
      "learning_rate": 4.918235112619562e-05,
      "loss": 0.1365,
      "step": 2650
    },
    {
      "epoch": 0.8207343412526998,
      "grad_norm": 3.336008310317993,
      "learning_rate": 4.9179265658747304e-05,
      "loss": 0.0945,
      "step": 2660
    },
    {
      "epoch": 0.8238198087010182,
      "grad_norm": 5.373705863952637,
      "learning_rate": 4.917618019129898e-05,
      "loss": 0.1186,
      "step": 2670
    },
    {
      "epoch": 0.8269052761493366,
      "grad_norm": 2.7097954750061035,
      "learning_rate": 4.917309472385066e-05,
      "loss": 0.1265,
      "step": 2680
    },
    {
      "epoch": 0.829990743597655,
      "grad_norm": 10.92718505859375,
      "learning_rate": 4.917000925640235e-05,
      "loss": 0.1409,
      "step": 2690
    },
    {
      "epoch": 0.8330762110459735,
      "grad_norm": 6.346075057983398,
      "learning_rate": 4.916692378895403e-05,
      "loss": 0.1139,
      "step": 2700
    },
    {
      "epoch": 0.8361616784942919,
      "grad_norm": 3.888396978378296,
      "learning_rate": 4.916383832150571e-05,
      "loss": 0.1305,
      "step": 2710
    },
    {
      "epoch": 0.8392471459426103,
      "grad_norm": 3.991522789001465,
      "learning_rate": 4.916075285405739e-05,
      "loss": 0.0884,
      "step": 2720
    },
    {
      "epoch": 0.8423326133909287,
      "grad_norm": 3.7610273361206055,
      "learning_rate": 4.9157667386609075e-05,
      "loss": 0.0879,
      "step": 2730
    },
    {
      "epoch": 0.8454180808392472,
      "grad_norm": 3.684326171875,
      "learning_rate": 4.915458191916075e-05,
      "loss": 0.1177,
      "step": 2740
    },
    {
      "epoch": 0.8485035482875656,
      "grad_norm": 4.850315570831299,
      "learning_rate": 4.915149645171244e-05,
      "loss": 0.0908,
      "step": 2750
    },
    {
      "epoch": 0.851589015735884,
      "grad_norm": 10.055255889892578,
      "learning_rate": 4.914841098426412e-05,
      "loss": 0.1125,
      "step": 2760
    },
    {
      "epoch": 0.8546744831842024,
      "grad_norm": 2.535835027694702,
      "learning_rate": 4.91453255168158e-05,
      "loss": 0.1297,
      "step": 2770
    },
    {
      "epoch": 0.8577599506325209,
      "grad_norm": 2.994757890701294,
      "learning_rate": 4.914224004936748e-05,
      "loss": 0.0893,
      "step": 2780
    },
    {
      "epoch": 0.8608454180808393,
      "grad_norm": 4.9510884284973145,
      "learning_rate": 4.913915458191916e-05,
      "loss": 0.1176,
      "step": 2790
    },
    {
      "epoch": 0.8639308855291576,
      "grad_norm": 5.708808898925781,
      "learning_rate": 4.9136069114470845e-05,
      "loss": 0.1059,
      "step": 2800
    },
    {
      "epoch": 0.867016352977476,
      "grad_norm": 2.029954195022583,
      "learning_rate": 4.913298364702252e-05,
      "loss": 0.0866,
      "step": 2810
    },
    {
      "epoch": 0.8701018204257945,
      "grad_norm": 1.7664111852645874,
      "learning_rate": 4.912989817957421e-05,
      "loss": 0.092,
      "step": 2820
    },
    {
      "epoch": 0.8731872878741129,
      "grad_norm": 3.5942344665527344,
      "learning_rate": 4.912681271212589e-05,
      "loss": 0.09,
      "step": 2830
    },
    {
      "epoch": 0.8762727553224313,
      "grad_norm": 13.151703834533691,
      "learning_rate": 4.912372724467757e-05,
      "loss": 0.1217,
      "step": 2840
    },
    {
      "epoch": 0.8793582227707498,
      "grad_norm": 3.3051979541778564,
      "learning_rate": 4.912064177722925e-05,
      "loss": 0.0713,
      "step": 2850
    },
    {
      "epoch": 0.8824436902190682,
      "grad_norm": 5.063899517059326,
      "learning_rate": 4.911755630978093e-05,
      "loss": 0.0795,
      "step": 2860
    },
    {
      "epoch": 0.8855291576673866,
      "grad_norm": 10.321711540222168,
      "learning_rate": 4.9114470842332616e-05,
      "loss": 0.1152,
      "step": 2870
    },
    {
      "epoch": 0.888614625115705,
      "grad_norm": 2.5135107040405273,
      "learning_rate": 4.91113853748843e-05,
      "loss": 0.1349,
      "step": 2880
    },
    {
      "epoch": 0.8917000925640235,
      "grad_norm": 2.6320853233337402,
      "learning_rate": 4.910829990743598e-05,
      "loss": 0.0751,
      "step": 2890
    },
    {
      "epoch": 0.8947855600123419,
      "grad_norm": 3.3041880130767822,
      "learning_rate": 4.910521443998766e-05,
      "loss": 0.0835,
      "step": 2900
    },
    {
      "epoch": 0.8978710274606603,
      "grad_norm": 4.6532883644104,
      "learning_rate": 4.910212897253934e-05,
      "loss": 0.1254,
      "step": 2910
    },
    {
      "epoch": 0.9009564949089787,
      "grad_norm": 2.9894917011260986,
      "learning_rate": 4.909904350509102e-05,
      "loss": 0.0725,
      "step": 2920
    },
    {
      "epoch": 0.9040419623572972,
      "grad_norm": 2.721336841583252,
      "learning_rate": 4.9095958037642704e-05,
      "loss": 0.1109,
      "step": 2930
    },
    {
      "epoch": 0.9071274298056156,
      "grad_norm": 6.063370704650879,
      "learning_rate": 4.9092872570194386e-05,
      "loss": 0.1023,
      "step": 2940
    },
    {
      "epoch": 0.910212897253934,
      "grad_norm": 2.666926860809326,
      "learning_rate": 4.908978710274607e-05,
      "loss": 0.1353,
      "step": 2950
    },
    {
      "epoch": 0.9132983647022523,
      "grad_norm": 2.0320069789886475,
      "learning_rate": 4.908670163529775e-05,
      "loss": 0.0783,
      "step": 2960
    },
    {
      "epoch": 0.9163838321505708,
      "grad_norm": 4.352148056030273,
      "learning_rate": 4.9083616167849434e-05,
      "loss": 0.1194,
      "step": 2970
    },
    {
      "epoch": 0.9194692995988892,
      "grad_norm": 2.3080029487609863,
      "learning_rate": 4.908053070040111e-05,
      "loss": 0.1006,
      "step": 2980
    },
    {
      "epoch": 0.9225547670472076,
      "grad_norm": 3.47916579246521,
      "learning_rate": 4.90774452329528e-05,
      "loss": 0.1076,
      "step": 2990
    },
    {
      "epoch": 0.9256402344955261,
      "grad_norm": 2.068657636642456,
      "learning_rate": 4.9074359765504474e-05,
      "loss": 0.1059,
      "step": 3000
    },
    {
      "epoch": 0.9287257019438445,
      "grad_norm": 5.270626544952393,
      "learning_rate": 4.907127429805616e-05,
      "loss": 0.0894,
      "step": 3010
    },
    {
      "epoch": 0.9318111693921629,
      "grad_norm": 3.5043556690216064,
      "learning_rate": 4.906818883060784e-05,
      "loss": 0.1178,
      "step": 3020
    },
    {
      "epoch": 0.9348966368404813,
      "grad_norm": 2.532019853591919,
      "learning_rate": 4.906510336315952e-05,
      "loss": 0.0867,
      "step": 3030
    },
    {
      "epoch": 0.9379821042887998,
      "grad_norm": 4.792689800262451,
      "learning_rate": 4.9062017895711204e-05,
      "loss": 0.1266,
      "step": 3040
    },
    {
      "epoch": 0.9410675717371182,
      "grad_norm": 6.046197414398193,
      "learning_rate": 4.905893242826288e-05,
      "loss": 0.1007,
      "step": 3050
    },
    {
      "epoch": 0.9441530391854366,
      "grad_norm": 3.0755674839019775,
      "learning_rate": 4.905584696081457e-05,
      "loss": 0.0767,
      "step": 3060
    },
    {
      "epoch": 0.947238506633755,
      "grad_norm": 6.499452590942383,
      "learning_rate": 4.9052761493366245e-05,
      "loss": 0.1021,
      "step": 3070
    },
    {
      "epoch": 0.9503239740820735,
      "grad_norm": 5.857091903686523,
      "learning_rate": 4.904967602591793e-05,
      "loss": 0.1151,
      "step": 3080
    },
    {
      "epoch": 0.9534094415303919,
      "grad_norm": 6.737019062042236,
      "learning_rate": 4.904659055846961e-05,
      "loss": 0.1254,
      "step": 3090
    },
    {
      "epoch": 0.9564949089787103,
      "grad_norm": 2.4985265731811523,
      "learning_rate": 4.904350509102129e-05,
      "loss": 0.0969,
      "step": 3100
    },
    {
      "epoch": 0.9595803764270286,
      "grad_norm": 5.425036430358887,
      "learning_rate": 4.9040419623572975e-05,
      "loss": 0.1282,
      "step": 3110
    },
    {
      "epoch": 0.9626658438753471,
      "grad_norm": 8.050809860229492,
      "learning_rate": 4.903733415612465e-05,
      "loss": 0.1048,
      "step": 3120
    },
    {
      "epoch": 0.9657513113236655,
      "grad_norm": 2.021509885787964,
      "learning_rate": 4.903424868867634e-05,
      "loss": 0.0782,
      "step": 3130
    },
    {
      "epoch": 0.9688367787719839,
      "grad_norm": 6.67415189743042,
      "learning_rate": 4.9031163221228016e-05,
      "loss": 0.1051,
      "step": 3140
    },
    {
      "epoch": 0.9719222462203023,
      "grad_norm": 1.945505976676941,
      "learning_rate": 4.90280777537797e-05,
      "loss": 0.0869,
      "step": 3150
    },
    {
      "epoch": 0.9750077136686208,
      "grad_norm": 4.900770664215088,
      "learning_rate": 4.902499228633138e-05,
      "loss": 0.097,
      "step": 3160
    },
    {
      "epoch": 0.9780931811169392,
      "grad_norm": 2.4663803577423096,
      "learning_rate": 4.902190681888306e-05,
      "loss": 0.0826,
      "step": 3170
    },
    {
      "epoch": 0.9811786485652576,
      "grad_norm": 1.8033312559127808,
      "learning_rate": 4.9018821351434745e-05,
      "loss": 0.0735,
      "step": 3180
    },
    {
      "epoch": 0.9842641160135761,
      "grad_norm": 3.797743797302246,
      "learning_rate": 4.901573588398642e-05,
      "loss": 0.1085,
      "step": 3190
    },
    {
      "epoch": 0.9873495834618945,
      "grad_norm": 2.453827381134033,
      "learning_rate": 4.901265041653811e-05,
      "loss": 0.1109,
      "step": 3200
    },
    {
      "epoch": 0.9904350509102129,
      "grad_norm": 7.3219122886657715,
      "learning_rate": 4.9009564949089786e-05,
      "loss": 0.1282,
      "step": 3210
    },
    {
      "epoch": 0.9935205183585313,
      "grad_norm": 4.3668999671936035,
      "learning_rate": 4.900647948164147e-05,
      "loss": 0.1253,
      "step": 3220
    },
    {
      "epoch": 0.9966059858068498,
      "grad_norm": 1.7829992771148682,
      "learning_rate": 4.900339401419316e-05,
      "loss": 0.0827,
      "step": 3230
    },
    {
      "epoch": 0.9996914532551682,
      "grad_norm": 3.6306118965148926,
      "learning_rate": 4.9000308546744834e-05,
      "loss": 0.0649,
      "step": 3240
    },
    {
      "epoch": 1.0,
      "eval_accuracy_branch1": 0.9104481930499696,
      "eval_accuracy_branch2": 0.43377409990065874,
      "eval_f1_branch1": 0.9004537251331374,
      "eval_f1_branch2": 0.4335066132466133,
      "eval_loss": 0.07756094634532928,
      "eval_precision_branch1": 0.9036143058631585,
      "eval_precision_branch2": 0.4960058228950901,
      "eval_recall_branch1": 0.9018304544244184,
      "eval_recall_branch2": 0.49614449813373457,
      "eval_runtime": 133.3207,
      "eval_samples_per_second": 777.696,
      "eval_steps_per_second": 97.217,
      "step": 3241
    },
    {
      "epoch": 1.0027769207034867,
      "grad_norm": 1.9515092372894287,
      "learning_rate": 4.8997223079296516e-05,
      "loss": 0.1182,
      "step": 3250
    },
    {
      "epoch": 1.005862388151805,
      "grad_norm": 1.2913798093795776,
      "learning_rate": 4.89941376118482e-05,
      "loss": 0.0874,
      "step": 3260
    },
    {
      "epoch": 1.0089478556001235,
      "grad_norm": 4.71463680267334,
      "learning_rate": 4.899105214439988e-05,
      "loss": 0.0873,
      "step": 3270
    },
    {
      "epoch": 1.0120333230484417,
      "grad_norm": 3.1412436962127686,
      "learning_rate": 4.8987966676951563e-05,
      "loss": 0.0786,
      "step": 3280
    },
    {
      "epoch": 1.0151187904967602,
      "grad_norm": 2.370056390762329,
      "learning_rate": 4.898488120950324e-05,
      "loss": 0.1017,
      "step": 3290
    },
    {
      "epoch": 1.0182042579450787,
      "grad_norm": 2.2237014770507812,
      "learning_rate": 4.898179574205493e-05,
      "loss": 0.0879,
      "step": 3300
    },
    {
      "epoch": 1.021289725393397,
      "grad_norm": 3.141892910003662,
      "learning_rate": 4.8978710274606604e-05,
      "loss": 0.0812,
      "step": 3310
    },
    {
      "epoch": 1.0243751928417155,
      "grad_norm": 2.115049362182617,
      "learning_rate": 4.8975624807158287e-05,
      "loss": 0.1138,
      "step": 3320
    },
    {
      "epoch": 1.027460660290034,
      "grad_norm": 2.885697364807129,
      "learning_rate": 4.897253933970997e-05,
      "loss": 0.0901,
      "step": 3330
    },
    {
      "epoch": 1.0305461277383523,
      "grad_norm": 4.862074851989746,
      "learning_rate": 4.896945387226165e-05,
      "loss": 0.0873,
      "step": 3340
    },
    {
      "epoch": 1.0336315951866708,
      "grad_norm": 7.627163887023926,
      "learning_rate": 4.8966368404813334e-05,
      "loss": 0.1142,
      "step": 3350
    },
    {
      "epoch": 1.0367170626349893,
      "grad_norm": 2.3831968307495117,
      "learning_rate": 4.896328293736501e-05,
      "loss": 0.1028,
      "step": 3360
    },
    {
      "epoch": 1.0398025300833076,
      "grad_norm": 5.080348968505859,
      "learning_rate": 4.89601974699167e-05,
      "loss": 0.0878,
      "step": 3370
    },
    {
      "epoch": 1.042887997531626,
      "grad_norm": 5.2695231437683105,
      "learning_rate": 4.8957112002468375e-05,
      "loss": 0.0561,
      "step": 3380
    },
    {
      "epoch": 1.0459734649799444,
      "grad_norm": 2.839110851287842,
      "learning_rate": 4.895402653502006e-05,
      "loss": 0.0617,
      "step": 3390
    },
    {
      "epoch": 1.0490589324282629,
      "grad_norm": 7.663034915924072,
      "learning_rate": 4.895094106757174e-05,
      "loss": 0.0995,
      "step": 3400
    },
    {
      "epoch": 1.0521443998765814,
      "grad_norm": 4.072654724121094,
      "learning_rate": 4.894785560012342e-05,
      "loss": 0.081,
      "step": 3410
    },
    {
      "epoch": 1.0552298673248997,
      "grad_norm": 2.5939700603485107,
      "learning_rate": 4.8944770132675105e-05,
      "loss": 0.1079,
      "step": 3420
    },
    {
      "epoch": 1.0583153347732182,
      "grad_norm": 4.275012016296387,
      "learning_rate": 4.894168466522678e-05,
      "loss": 0.0918,
      "step": 3430
    },
    {
      "epoch": 1.0614008022215367,
      "grad_norm": 1.9700254201889038,
      "learning_rate": 4.893859919777847e-05,
      "loss": 0.0796,
      "step": 3440
    },
    {
      "epoch": 1.064486269669855,
      "grad_norm": 8.210965156555176,
      "learning_rate": 4.8935513730330145e-05,
      "loss": 0.1093,
      "step": 3450
    },
    {
      "epoch": 1.0675717371181734,
      "grad_norm": 2.0143749713897705,
      "learning_rate": 4.893242826288183e-05,
      "loss": 0.1231,
      "step": 3460
    },
    {
      "epoch": 1.070657204566492,
      "grad_norm": 2.336179733276367,
      "learning_rate": 4.892934279543351e-05,
      "loss": 0.0866,
      "step": 3470
    },
    {
      "epoch": 1.0737426720148102,
      "grad_norm": 6.954975605010986,
      "learning_rate": 4.892625732798519e-05,
      "loss": 0.0833,
      "step": 3480
    },
    {
      "epoch": 1.0768281394631287,
      "grad_norm": 2.5342843532562256,
      "learning_rate": 4.8923171860536875e-05,
      "loss": 0.1278,
      "step": 3490
    },
    {
      "epoch": 1.079913606911447,
      "grad_norm": 4.6058735847473145,
      "learning_rate": 4.892008639308856e-05,
      "loss": 0.0971,
      "step": 3500
    },
    {
      "epoch": 1.0829990743597655,
      "grad_norm": 5.202132225036621,
      "learning_rate": 4.891700092564024e-05,
      "loss": 0.1001,
      "step": 3510
    },
    {
      "epoch": 1.086084541808084,
      "grad_norm": 6.0380964279174805,
      "learning_rate": 4.8913915458191916e-05,
      "loss": 0.1177,
      "step": 3520
    },
    {
      "epoch": 1.0891700092564023,
      "grad_norm": 2.367382764816284,
      "learning_rate": 4.89108299907436e-05,
      "loss": 0.0865,
      "step": 3530
    },
    {
      "epoch": 1.0922554767047208,
      "grad_norm": 4.046882152557373,
      "learning_rate": 4.890774452329528e-05,
      "loss": 0.0862,
      "step": 3540
    },
    {
      "epoch": 1.0953409441530393,
      "grad_norm": 5.617076873779297,
      "learning_rate": 4.890465905584696e-05,
      "loss": 0.089,
      "step": 3550
    },
    {
      "epoch": 1.0984264116013576,
      "grad_norm": 3.481365919113159,
      "learning_rate": 4.8901573588398646e-05,
      "loss": 0.0969,
      "step": 3560
    },
    {
      "epoch": 1.101511879049676,
      "grad_norm": 2.534268379211426,
      "learning_rate": 4.889848812095033e-05,
      "loss": 0.099,
      "step": 3570
    },
    {
      "epoch": 1.1045973464979943,
      "grad_norm": 2.416677474975586,
      "learning_rate": 4.889540265350201e-05,
      "loss": 0.0772,
      "step": 3580
    },
    {
      "epoch": 1.1076828139463128,
      "grad_norm": 1.863430142402649,
      "learning_rate": 4.8892317186053686e-05,
      "loss": 0.0743,
      "step": 3590
    },
    {
      "epoch": 1.1107682813946314,
      "grad_norm": 2.7504231929779053,
      "learning_rate": 4.888923171860537e-05,
      "loss": 0.1279,
      "step": 3600
    },
    {
      "epoch": 1.1138537488429496,
      "grad_norm": 2.3988051414489746,
      "learning_rate": 4.888614625115705e-05,
      "loss": 0.0836,
      "step": 3610
    },
    {
      "epoch": 1.1169392162912681,
      "grad_norm": 4.812989234924316,
      "learning_rate": 4.8883060783708734e-05,
      "loss": 0.1015,
      "step": 3620
    },
    {
      "epoch": 1.1200246837395866,
      "grad_norm": 4.677794933319092,
      "learning_rate": 4.8879975316260416e-05,
      "loss": 0.1391,
      "step": 3630
    },
    {
      "epoch": 1.123110151187905,
      "grad_norm": 2.5224881172180176,
      "learning_rate": 4.88768898488121e-05,
      "loss": 0.0871,
      "step": 3640
    },
    {
      "epoch": 1.1261956186362234,
      "grad_norm": 3.722412586212158,
      "learning_rate": 4.887380438136378e-05,
      "loss": 0.0873,
      "step": 3650
    },
    {
      "epoch": 1.129281086084542,
      "grad_norm": 4.868941783905029,
      "learning_rate": 4.887071891391546e-05,
      "loss": 0.0756,
      "step": 3660
    },
    {
      "epoch": 1.1323665535328602,
      "grad_norm": 3.1495280265808105,
      "learning_rate": 4.886763344646714e-05,
      "loss": 0.0866,
      "step": 3670
    },
    {
      "epoch": 1.1354520209811787,
      "grad_norm": 4.2381696701049805,
      "learning_rate": 4.886454797901882e-05,
      "loss": 0.0717,
      "step": 3680
    },
    {
      "epoch": 1.138537488429497,
      "grad_norm": 1.6313869953155518,
      "learning_rate": 4.8861462511570504e-05,
      "loss": 0.091,
      "step": 3690
    },
    {
      "epoch": 1.1416229558778155,
      "grad_norm": 4.999921798706055,
      "learning_rate": 4.885837704412219e-05,
      "loss": 0.0841,
      "step": 3700
    },
    {
      "epoch": 1.144708423326134,
      "grad_norm": 4.204542636871338,
      "learning_rate": 4.885529157667387e-05,
      "loss": 0.0664,
      "step": 3710
    },
    {
      "epoch": 1.1477938907744523,
      "grad_norm": 6.688148021697998,
      "learning_rate": 4.885220610922555e-05,
      "loss": 0.0793,
      "step": 3720
    },
    {
      "epoch": 1.1508793582227708,
      "grad_norm": 3.154031276702881,
      "learning_rate": 4.884912064177723e-05,
      "loss": 0.0734,
      "step": 3730
    },
    {
      "epoch": 1.1539648256710893,
      "grad_norm": 4.508683681488037,
      "learning_rate": 4.884603517432892e-05,
      "loss": 0.0959,
      "step": 3740
    },
    {
      "epoch": 1.1570502931194075,
      "grad_norm": 5.288630962371826,
      "learning_rate": 4.88429497068806e-05,
      "loss": 0.0856,
      "step": 3750
    },
    {
      "epoch": 1.160135760567726,
      "grad_norm": 2.5796234607696533,
      "learning_rate": 4.8839864239432275e-05,
      "loss": 0.0802,
      "step": 3760
    },
    {
      "epoch": 1.1632212280160443,
      "grad_norm": 0.7799206376075745,
      "learning_rate": 4.883677877198396e-05,
      "loss": 0.0706,
      "step": 3770
    },
    {
      "epoch": 1.1663066954643628,
      "grad_norm": 3.530169725418091,
      "learning_rate": 4.883369330453564e-05,
      "loss": 0.0695,
      "step": 3780
    },
    {
      "epoch": 1.1693921629126813,
      "grad_norm": 3.164851427078247,
      "learning_rate": 4.883060783708732e-05,
      "loss": 0.09,
      "step": 3790
    },
    {
      "epoch": 1.1724776303609996,
      "grad_norm": 4.2776336669921875,
      "learning_rate": 4.8827522369639e-05,
      "loss": 0.0757,
      "step": 3800
    },
    {
      "epoch": 1.1755630978093181,
      "grad_norm": 3.3800010681152344,
      "learning_rate": 4.882443690219069e-05,
      "loss": 0.0742,
      "step": 3810
    },
    {
      "epoch": 1.1786485652576366,
      "grad_norm": 3.8661205768585205,
      "learning_rate": 4.882135143474237e-05,
      "loss": 0.0695,
      "step": 3820
    },
    {
      "epoch": 1.181734032705955,
      "grad_norm": 2.549783706665039,
      "learning_rate": 4.8818265967294045e-05,
      "loss": 0.0861,
      "step": 3830
    },
    {
      "epoch": 1.1848195001542734,
      "grad_norm": 1.9849376678466797,
      "learning_rate": 4.881518049984573e-05,
      "loss": 0.0948,
      "step": 3840
    },
    {
      "epoch": 1.187904967602592,
      "grad_norm": 4.645747184753418,
      "learning_rate": 4.881209503239741e-05,
      "loss": 0.0645,
      "step": 3850
    },
    {
      "epoch": 1.1909904350509102,
      "grad_norm": 2.5762078762054443,
      "learning_rate": 4.880900956494909e-05,
      "loss": 0.0884,
      "step": 3860
    },
    {
      "epoch": 1.1940759024992287,
      "grad_norm": 2.2949907779693604,
      "learning_rate": 4.880592409750077e-05,
      "loss": 0.0681,
      "step": 3870
    },
    {
      "epoch": 1.197161369947547,
      "grad_norm": 4.556665897369385,
      "learning_rate": 4.880283863005246e-05,
      "loss": 0.0577,
      "step": 3880
    },
    {
      "epoch": 1.2002468373958655,
      "grad_norm": 5.539999485015869,
      "learning_rate": 4.879975316260414e-05,
      "loss": 0.0847,
      "step": 3890
    },
    {
      "epoch": 1.203332304844184,
      "grad_norm": 6.434925556182861,
      "learning_rate": 4.8796667695155816e-05,
      "loss": 0.0799,
      "step": 3900
    },
    {
      "epoch": 1.2064177722925022,
      "grad_norm": 3.5919270515441895,
      "learning_rate": 4.87935822277075e-05,
      "loss": 0.0669,
      "step": 3910
    },
    {
      "epoch": 1.2095032397408207,
      "grad_norm": 3.66626238822937,
      "learning_rate": 4.879049676025918e-05,
      "loss": 0.0797,
      "step": 3920
    },
    {
      "epoch": 1.2125887071891392,
      "grad_norm": 1.037607192993164,
      "learning_rate": 4.8787411292810863e-05,
      "loss": 0.0802,
      "step": 3930
    },
    {
      "epoch": 1.2156741746374575,
      "grad_norm": 3.699004888534546,
      "learning_rate": 4.878432582536254e-05,
      "loss": 0.0564,
      "step": 3940
    },
    {
      "epoch": 1.218759642085776,
      "grad_norm": 1.3053139448165894,
      "learning_rate": 4.878124035791423e-05,
      "loss": 0.0583,
      "step": 3950
    },
    {
      "epoch": 1.2218451095340943,
      "grad_norm": 2.832073211669922,
      "learning_rate": 4.877815489046591e-05,
      "loss": 0.0835,
      "step": 3960
    },
    {
      "epoch": 1.2249305769824128,
      "grad_norm": 7.143989086151123,
      "learning_rate": 4.877506942301759e-05,
      "loss": 0.0923,
      "step": 3970
    },
    {
      "epoch": 1.2280160444307313,
      "grad_norm": 6.102818489074707,
      "learning_rate": 4.8771983955569276e-05,
      "loss": 0.0754,
      "step": 3980
    },
    {
      "epoch": 1.2311015118790496,
      "grad_norm": 2.948028802871704,
      "learning_rate": 4.876889848812095e-05,
      "loss": 0.0552,
      "step": 3990
    },
    {
      "epoch": 1.234186979327368,
      "grad_norm": 4.275085926055908,
      "learning_rate": 4.8765813020672634e-05,
      "loss": 0.0881,
      "step": 4000
    },
    {
      "epoch": 1.2372724467756866,
      "grad_norm": 3.730095386505127,
      "learning_rate": 4.8762727553224317e-05,
      "loss": 0.0907,
      "step": 4010
    },
    {
      "epoch": 1.2403579142240049,
      "grad_norm": 3.0192999839782715,
      "learning_rate": 4.8759642085776e-05,
      "loss": 0.0745,
      "step": 4020
    },
    {
      "epoch": 1.2434433816723234,
      "grad_norm": 0.6646193861961365,
      "learning_rate": 4.875655661832768e-05,
      "loss": 0.0865,
      "step": 4030
    },
    {
      "epoch": 1.2465288491206419,
      "grad_norm": 3.9204537868499756,
      "learning_rate": 4.875347115087936e-05,
      "loss": 0.1175,
      "step": 4040
    },
    {
      "epoch": 1.2496143165689602,
      "grad_norm": 0.8486559391021729,
      "learning_rate": 4.8750385683431046e-05,
      "loss": 0.0692,
      "step": 4050
    },
    {
      "epoch": 1.2526997840172787,
      "grad_norm": 2.6418545246124268,
      "learning_rate": 4.874730021598272e-05,
      "loss": 0.0875,
      "step": 4060
    },
    {
      "epoch": 1.2557852514655972,
      "grad_norm": 1.1949384212493896,
      "learning_rate": 4.8744214748534405e-05,
      "loss": 0.0717,
      "step": 4070
    },
    {
      "epoch": 1.2588707189139154,
      "grad_norm": 3.95473051071167,
      "learning_rate": 4.874112928108609e-05,
      "loss": 0.0706,
      "step": 4080
    },
    {
      "epoch": 1.261956186362234,
      "grad_norm": 3.5905697345733643,
      "learning_rate": 4.873804381363777e-05,
      "loss": 0.0699,
      "step": 4090
    },
    {
      "epoch": 1.2650416538105522,
      "grad_norm": 4.990018367767334,
      "learning_rate": 4.873495834618945e-05,
      "loss": 0.0804,
      "step": 4100
    },
    {
      "epoch": 1.2681271212588707,
      "grad_norm": 3.3224856853485107,
      "learning_rate": 4.873187287874113e-05,
      "loss": 0.0772,
      "step": 4110
    },
    {
      "epoch": 1.271212588707189,
      "grad_norm": 2.515841245651245,
      "learning_rate": 4.872878741129282e-05,
      "loss": 0.067,
      "step": 4120
    },
    {
      "epoch": 1.2742980561555075,
      "grad_norm": 3.7261962890625,
      "learning_rate": 4.872570194384449e-05,
      "loss": 0.0803,
      "step": 4130
    },
    {
      "epoch": 1.277383523603826,
      "grad_norm": 2.115576982498169,
      "learning_rate": 4.8722616476396175e-05,
      "loss": 0.0527,
      "step": 4140
    },
    {
      "epoch": 1.2804689910521443,
      "grad_norm": 2.1687679290771484,
      "learning_rate": 4.871953100894786e-05,
      "loss": 0.063,
      "step": 4150
    },
    {
      "epoch": 1.2835544585004628,
      "grad_norm": 3.3362865447998047,
      "learning_rate": 4.871644554149954e-05,
      "loss": 0.0658,
      "step": 4160
    },
    {
      "epoch": 1.2866399259487813,
      "grad_norm": 3.7654831409454346,
      "learning_rate": 4.871336007405122e-05,
      "loss": 0.0624,
      "step": 4170
    },
    {
      "epoch": 1.2897253933970996,
      "grad_norm": 3.803743600845337,
      "learning_rate": 4.87102746066029e-05,
      "loss": 0.0731,
      "step": 4180
    },
    {
      "epoch": 1.292810860845418,
      "grad_norm": 2.6891887187957764,
      "learning_rate": 4.870718913915459e-05,
      "loss": 0.0759,
      "step": 4190
    },
    {
      "epoch": 1.2958963282937366,
      "grad_norm": 3.8178117275238037,
      "learning_rate": 4.870410367170626e-05,
      "loss": 0.0645,
      "step": 4200
    },
    {
      "epoch": 1.2989817957420549,
      "grad_norm": 1.5925581455230713,
      "learning_rate": 4.8701018204257946e-05,
      "loss": 0.0725,
      "step": 4210
    },
    {
      "epoch": 1.3020672631903734,
      "grad_norm": 8.935535430908203,
      "learning_rate": 4.8697932736809635e-05,
      "loss": 0.0645,
      "step": 4220
    },
    {
      "epoch": 1.3051527306386919,
      "grad_norm": 4.530259132385254,
      "learning_rate": 4.869484726936131e-05,
      "loss": 0.0562,
      "step": 4230
    },
    {
      "epoch": 1.3082381980870101,
      "grad_norm": 1.176621913909912,
      "learning_rate": 4.869176180191299e-05,
      "loss": 0.0507,
      "step": 4240
    },
    {
      "epoch": 1.3113236655353286,
      "grad_norm": 4.925633907318115,
      "learning_rate": 4.8688676334464676e-05,
      "loss": 0.0791,
      "step": 4250
    },
    {
      "epoch": 1.3144091329836471,
      "grad_norm": 1.8643923997879028,
      "learning_rate": 4.868559086701636e-05,
      "loss": 0.055,
      "step": 4260
    },
    {
      "epoch": 1.3174946004319654,
      "grad_norm": 4.178254127502441,
      "learning_rate": 4.8682505399568034e-05,
      "loss": 0.0655,
      "step": 4270
    },
    {
      "epoch": 1.320580067880284,
      "grad_norm": 2.0590152740478516,
      "learning_rate": 4.8679419932119716e-05,
      "loss": 0.077,
      "step": 4280
    },
    {
      "epoch": 1.3236655353286022,
      "grad_norm": 2.304696798324585,
      "learning_rate": 4.8676334464671406e-05,
      "loss": 0.0415,
      "step": 4290
    },
    {
      "epoch": 1.3267510027769207,
      "grad_norm": 8.179930686950684,
      "learning_rate": 4.867324899722308e-05,
      "loss": 0.057,
      "step": 4300
    },
    {
      "epoch": 1.329836470225239,
      "grad_norm": 3.5996997356414795,
      "learning_rate": 4.8670163529774764e-05,
      "loss": 0.0835,
      "step": 4310
    },
    {
      "epoch": 1.3329219376735575,
      "grad_norm": 1.398635983467102,
      "learning_rate": 4.8667078062326446e-05,
      "loss": 0.0556,
      "step": 4320
    },
    {
      "epoch": 1.336007405121876,
      "grad_norm": 1.533737063407898,
      "learning_rate": 4.866399259487813e-05,
      "loss": 0.0709,
      "step": 4330
    },
    {
      "epoch": 1.3390928725701943,
      "grad_norm": 1.3884906768798828,
      "learning_rate": 4.8660907127429804e-05,
      "loss": 0.0647,
      "step": 4340
    },
    {
      "epoch": 1.3421783400185128,
      "grad_norm": 2.4741127490997314,
      "learning_rate": 4.865782165998149e-05,
      "loss": 0.0546,
      "step": 4350
    },
    {
      "epoch": 1.3452638074668313,
      "grad_norm": 2.1470367908477783,
      "learning_rate": 4.8654736192533176e-05,
      "loss": 0.0558,
      "step": 4360
    },
    {
      "epoch": 1.3483492749151496,
      "grad_norm": 2.966862440109253,
      "learning_rate": 4.865165072508485e-05,
      "loss": 0.0654,
      "step": 4370
    },
    {
      "epoch": 1.351434742363468,
      "grad_norm": 6.262266635894775,
      "learning_rate": 4.8648565257636534e-05,
      "loss": 0.0608,
      "step": 4380
    },
    {
      "epoch": 1.3545202098117866,
      "grad_norm": 3.1557326316833496,
      "learning_rate": 4.864547979018822e-05,
      "loss": 0.0667,
      "step": 4390
    },
    {
      "epoch": 1.3576056772601048,
      "grad_norm": 3.0340476036071777,
      "learning_rate": 4.86423943227399e-05,
      "loss": 0.0774,
      "step": 4400
    },
    {
      "epoch": 1.3606911447084233,
      "grad_norm": 6.29593563079834,
      "learning_rate": 4.8639308855291575e-05,
      "loss": 0.0895,
      "step": 4410
    },
    {
      "epoch": 1.3637766121567418,
      "grad_norm": 1.1771653890609741,
      "learning_rate": 4.863622338784326e-05,
      "loss": 0.0482,
      "step": 4420
    },
    {
      "epoch": 1.3668620796050601,
      "grad_norm": 3.1218788623809814,
      "learning_rate": 4.863313792039495e-05,
      "loss": 0.0657,
      "step": 4430
    },
    {
      "epoch": 1.3699475470533786,
      "grad_norm": 0.35920095443725586,
      "learning_rate": 4.863005245294662e-05,
      "loss": 0.108,
      "step": 4440
    },
    {
      "epoch": 1.3730330145016971,
      "grad_norm": 1.59725821018219,
      "learning_rate": 4.8626966985498305e-05,
      "loss": 0.0768,
      "step": 4450
    },
    {
      "epoch": 1.3761184819500154,
      "grad_norm": 3.534836769104004,
      "learning_rate": 4.862388151804999e-05,
      "loss": 0.0794,
      "step": 4460
    },
    {
      "epoch": 1.379203949398334,
      "grad_norm": 2.6138713359832764,
      "learning_rate": 4.862079605060167e-05,
      "loss": 0.0537,
      "step": 4470
    },
    {
      "epoch": 1.3822894168466522,
      "grad_norm": 3.8200087547302246,
      "learning_rate": 4.8617710583153346e-05,
      "loss": 0.0666,
      "step": 4480
    },
    {
      "epoch": 1.3853748842949707,
      "grad_norm": 3.5467607975006104,
      "learning_rate": 4.8614625115705035e-05,
      "loss": 0.0496,
      "step": 4490
    },
    {
      "epoch": 1.3884603517432892,
      "grad_norm": 2.7056326866149902,
      "learning_rate": 4.861153964825672e-05,
      "loss": 0.0588,
      "step": 4500
    },
    {
      "epoch": 1.3915458191916075,
      "grad_norm": 3.7865328788757324,
      "learning_rate": 4.860845418080839e-05,
      "loss": 0.0722,
      "step": 4510
    },
    {
      "epoch": 1.394631286639926,
      "grad_norm": 3.343846082687378,
      "learning_rate": 4.8605368713360075e-05,
      "loss": 0.0869,
      "step": 4520
    },
    {
      "epoch": 1.3977167540882443,
      "grad_norm": 0.5246736407279968,
      "learning_rate": 4.860228324591176e-05,
      "loss": 0.0559,
      "step": 4530
    },
    {
      "epoch": 1.4008022215365628,
      "grad_norm": 6.228460788726807,
      "learning_rate": 4.859919777846344e-05,
      "loss": 0.0733,
      "step": 4540
    },
    {
      "epoch": 1.4038876889848813,
      "grad_norm": 2.9501242637634277,
      "learning_rate": 4.8596112311015116e-05,
      "loss": 0.0594,
      "step": 4550
    },
    {
      "epoch": 1.4069731564331995,
      "grad_norm": 3.5834217071533203,
      "learning_rate": 4.8593026843566805e-05,
      "loss": 0.0701,
      "step": 4560
    },
    {
      "epoch": 1.410058623881518,
      "grad_norm": 2.9911365509033203,
      "learning_rate": 4.858994137611849e-05,
      "loss": 0.0517,
      "step": 4570
    },
    {
      "epoch": 1.4131440913298365,
      "grad_norm": 1.3858917951583862,
      "learning_rate": 4.8586855908670164e-05,
      "loss": 0.0416,
      "step": 4580
    },
    {
      "epoch": 1.4162295587781548,
      "grad_norm": 3.6539506912231445,
      "learning_rate": 4.8583770441221846e-05,
      "loss": 0.0977,
      "step": 4590
    },
    {
      "epoch": 1.4193150262264733,
      "grad_norm": 1.5686100721359253,
      "learning_rate": 4.858068497377353e-05,
      "loss": 0.0741,
      "step": 4600
    },
    {
      "epoch": 1.4224004936747918,
      "grad_norm": 4.509664535522461,
      "learning_rate": 4.857759950632521e-05,
      "loss": 0.0671,
      "step": 4610
    },
    {
      "epoch": 1.42548596112311,
      "grad_norm": 5.1846604347229,
      "learning_rate": 4.8574514038876893e-05,
      "loss": 0.0995,
      "step": 4620
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 3.459599494934082,
      "learning_rate": 4.8571428571428576e-05,
      "loss": 0.0841,
      "step": 4630
    },
    {
      "epoch": 1.431656896019747,
      "grad_norm": 4.279542446136475,
      "learning_rate": 4.856834310398026e-05,
      "loss": 0.0662,
      "step": 4640
    },
    {
      "epoch": 1.4347423634680654,
      "grad_norm": 1.2365195751190186,
      "learning_rate": 4.8565257636531934e-05,
      "loss": 0.0536,
      "step": 4650
    },
    {
      "epoch": 1.4378278309163839,
      "grad_norm": 2.8031904697418213,
      "learning_rate": 4.8562172169083617e-05,
      "loss": 0.0853,
      "step": 4660
    },
    {
      "epoch": 1.4409132983647024,
      "grad_norm": 4.905289173126221,
      "learning_rate": 4.85590867016353e-05,
      "loss": 0.042,
      "step": 4670
    },
    {
      "epoch": 1.4439987658130207,
      "grad_norm": 3.1881401538848877,
      "learning_rate": 4.855600123418698e-05,
      "loss": 0.0659,
      "step": 4680
    },
    {
      "epoch": 1.4470842332613392,
      "grad_norm": 0.7635283470153809,
      "learning_rate": 4.8552915766738664e-05,
      "loss": 0.0469,
      "step": 4690
    },
    {
      "epoch": 1.4501697007096574,
      "grad_norm": 2.764434814453125,
      "learning_rate": 4.8549830299290346e-05,
      "loss": 0.0773,
      "step": 4700
    },
    {
      "epoch": 1.453255168157976,
      "grad_norm": 1.7988048791885376,
      "learning_rate": 4.854674483184203e-05,
      "loss": 0.0624,
      "step": 4710
    },
    {
      "epoch": 1.4563406356062942,
      "grad_norm": 6.31785774230957,
      "learning_rate": 4.8543659364393705e-05,
      "loss": 0.0785,
      "step": 4720
    },
    {
      "epoch": 1.4594261030546127,
      "grad_norm": 3.2471461296081543,
      "learning_rate": 4.854057389694539e-05,
      "loss": 0.0816,
      "step": 4730
    },
    {
      "epoch": 1.4625115705029312,
      "grad_norm": 2.6186277866363525,
      "learning_rate": 4.853748842949707e-05,
      "loss": 0.0444,
      "step": 4740
    },
    {
      "epoch": 1.4655970379512495,
      "grad_norm": 1.2736870050430298,
      "learning_rate": 4.853440296204875e-05,
      "loss": 0.0533,
      "step": 4750
    },
    {
      "epoch": 1.468682505399568,
      "grad_norm": 3.4681410789489746,
      "learning_rate": 4.8531317494600435e-05,
      "loss": 0.0709,
      "step": 4760
    },
    {
      "epoch": 1.4717679728478865,
      "grad_norm": 2.2292261123657227,
      "learning_rate": 4.852823202715212e-05,
      "loss": 0.0462,
      "step": 4770
    },
    {
      "epoch": 1.4748534402962048,
      "grad_norm": 1.3476288318634033,
      "learning_rate": 4.85251465597038e-05,
      "loss": 0.0502,
      "step": 4780
    },
    {
      "epoch": 1.4779389077445233,
      "grad_norm": 3.3345792293548584,
      "learning_rate": 4.8522061092255475e-05,
      "loss": 0.0506,
      "step": 4790
    },
    {
      "epoch": 1.4810243751928418,
      "grad_norm": 4.116784572601318,
      "learning_rate": 4.8518975624807164e-05,
      "loss": 0.0577,
      "step": 4800
    },
    {
      "epoch": 1.48410984264116,
      "grad_norm": 1.3361347913742065,
      "learning_rate": 4.851589015735884e-05,
      "loss": 0.0682,
      "step": 4810
    },
    {
      "epoch": 1.4871953100894786,
      "grad_norm": 2.4963271617889404,
      "learning_rate": 4.851280468991052e-05,
      "loss": 0.0608,
      "step": 4820
    },
    {
      "epoch": 1.490280777537797,
      "grad_norm": 1.0653213262557983,
      "learning_rate": 4.8509719222462205e-05,
      "loss": 0.0832,
      "step": 4830
    },
    {
      "epoch": 1.4933662449861154,
      "grad_norm": 4.305393695831299,
      "learning_rate": 4.850663375501389e-05,
      "loss": 0.0698,
      "step": 4840
    },
    {
      "epoch": 1.4964517124344339,
      "grad_norm": 2.254547357559204,
      "learning_rate": 4.850354828756557e-05,
      "loss": 0.056,
      "step": 4850
    },
    {
      "epoch": 1.4995371798827524,
      "grad_norm": 1.5469715595245361,
      "learning_rate": 4.8500462820117246e-05,
      "loss": 0.0626,
      "step": 4860
    },
    {
      "epoch": 1.5026226473310706,
      "grad_norm": 1.1304823160171509,
      "learning_rate": 4.8497377352668935e-05,
      "loss": 0.0507,
      "step": 4870
    },
    {
      "epoch": 1.505708114779389,
      "grad_norm": 3.234585762023926,
      "learning_rate": 4.849429188522061e-05,
      "loss": 0.0608,
      "step": 4880
    },
    {
      "epoch": 1.5087935822277077,
      "grad_norm": 3.4761037826538086,
      "learning_rate": 4.849120641777229e-05,
      "loss": 0.0605,
      "step": 4890
    },
    {
      "epoch": 1.511879049676026,
      "grad_norm": 1.3069419860839844,
      "learning_rate": 4.8488120950323976e-05,
      "loss": 0.058,
      "step": 4900
    },
    {
      "epoch": 1.5149645171243442,
      "grad_norm": 6.1782636642456055,
      "learning_rate": 4.848503548287566e-05,
      "loss": 0.0753,
      "step": 4910
    },
    {
      "epoch": 1.5180499845726627,
      "grad_norm": 2.3556947708129883,
      "learning_rate": 4.848195001542734e-05,
      "loss": 0.0823,
      "step": 4920
    },
    {
      "epoch": 1.5211354520209812,
      "grad_norm": 2.327767848968506,
      "learning_rate": 4.8478864547979016e-05,
      "loss": 0.0759,
      "step": 4930
    },
    {
      "epoch": 1.5242209194692995,
      "grad_norm": 5.255636215209961,
      "learning_rate": 4.8475779080530706e-05,
      "loss": 0.0757,
      "step": 4940
    },
    {
      "epoch": 1.527306386917618,
      "grad_norm": 2.0182507038116455,
      "learning_rate": 4.847269361308238e-05,
      "loss": 0.055,
      "step": 4950
    },
    {
      "epoch": 1.5303918543659365,
      "grad_norm": 1.789859414100647,
      "learning_rate": 4.8469608145634064e-05,
      "loss": 0.0545,
      "step": 4960
    },
    {
      "epoch": 1.5334773218142548,
      "grad_norm": 2.211560010910034,
      "learning_rate": 4.8466522678185746e-05,
      "loss": 0.0651,
      "step": 4970
    },
    {
      "epoch": 1.5365627892625733,
      "grad_norm": 1.6025751829147339,
      "learning_rate": 4.846343721073743e-05,
      "loss": 0.0458,
      "step": 4980
    },
    {
      "epoch": 1.5396482567108918,
      "grad_norm": 1.561306118965149,
      "learning_rate": 4.846035174328911e-05,
      "loss": 0.0527,
      "step": 4990
    },
    {
      "epoch": 1.54273372415921,
      "grad_norm": 2.711649179458618,
      "learning_rate": 4.845726627584079e-05,
      "loss": 0.0814,
      "step": 5000
    },
    {
      "epoch": 1.5458191916075286,
      "grad_norm": 1.8282792568206787,
      "learning_rate": 4.8454180808392476e-05,
      "loss": 0.0528,
      "step": 5010
    },
    {
      "epoch": 1.548904659055847,
      "grad_norm": 5.360456943511963,
      "learning_rate": 4.845109534094415e-05,
      "loss": 0.0455,
      "step": 5020
    },
    {
      "epoch": 1.5519901265041653,
      "grad_norm": 1.8728879690170288,
      "learning_rate": 4.8448009873495834e-05,
      "loss": 0.0682,
      "step": 5030
    },
    {
      "epoch": 1.5550755939524838,
      "grad_norm": 2.544111967086792,
      "learning_rate": 4.8444924406047524e-05,
      "loss": 0.0425,
      "step": 5040
    },
    {
      "epoch": 1.5581610614008023,
      "grad_norm": 3.7525153160095215,
      "learning_rate": 4.84418389385992e-05,
      "loss": 0.097,
      "step": 5050
    },
    {
      "epoch": 1.5612465288491206,
      "grad_norm": 5.914276123046875,
      "learning_rate": 4.843875347115088e-05,
      "loss": 0.0787,
      "step": 5060
    },
    {
      "epoch": 1.564331996297439,
      "grad_norm": 1.107056975364685,
      "learning_rate": 4.8435668003702564e-05,
      "loss": 0.0523,
      "step": 5070
    },
    {
      "epoch": 1.5674174637457576,
      "grad_norm": 0.4825962781906128,
      "learning_rate": 4.843258253625425e-05,
      "loss": 0.0605,
      "step": 5080
    },
    {
      "epoch": 1.570502931194076,
      "grad_norm": 3.3162667751312256,
      "learning_rate": 4.842949706880593e-05,
      "loss": 0.0438,
      "step": 5090
    },
    {
      "epoch": 1.5735883986423942,
      "grad_norm": 1.6504194736480713,
      "learning_rate": 4.8426411601357605e-05,
      "loss": 0.0417,
      "step": 5100
    },
    {
      "epoch": 1.5766738660907127,
      "grad_norm": 2.2456018924713135,
      "learning_rate": 4.8423326133909294e-05,
      "loss": 0.0455,
      "step": 5110
    },
    {
      "epoch": 1.5797593335390312,
      "grad_norm": 2.557030439376831,
      "learning_rate": 4.842024066646097e-05,
      "loss": 0.055,
      "step": 5120
    },
    {
      "epoch": 1.5828448009873495,
      "grad_norm": 2.9539096355438232,
      "learning_rate": 4.841715519901265e-05,
      "loss": 0.0638,
      "step": 5130
    },
    {
      "epoch": 1.585930268435668,
      "grad_norm": 4.586945533752441,
      "learning_rate": 4.8414069731564335e-05,
      "loss": 0.0592,
      "step": 5140
    },
    {
      "epoch": 1.5890157358839865,
      "grad_norm": 1.088779091835022,
      "learning_rate": 4.841098426411602e-05,
      "loss": 0.0737,
      "step": 5150
    },
    {
      "epoch": 1.5921012033323048,
      "grad_norm": 0.509570300579071,
      "learning_rate": 4.84078987966677e-05,
      "loss": 0.0681,
      "step": 5160
    },
    {
      "epoch": 1.5951866707806233,
      "grad_norm": 3.6289725303649902,
      "learning_rate": 4.8404813329219375e-05,
      "loss": 0.0544,
      "step": 5170
    },
    {
      "epoch": 1.5982721382289418,
      "grad_norm": 2.6546571254730225,
      "learning_rate": 4.8401727861771065e-05,
      "loss": 0.063,
      "step": 5180
    },
    {
      "epoch": 1.60135760567726,
      "grad_norm": 5.079436779022217,
      "learning_rate": 4.839864239432274e-05,
      "loss": 0.071,
      "step": 5190
    },
    {
      "epoch": 1.6044430731255785,
      "grad_norm": 3.5348010063171387,
      "learning_rate": 4.839555692687442e-05,
      "loss": 0.0458,
      "step": 5200
    },
    {
      "epoch": 1.607528540573897,
      "grad_norm": 2.929870843887329,
      "learning_rate": 4.8392471459426105e-05,
      "loss": 0.0556,
      "step": 5210
    },
    {
      "epoch": 1.6106140080222153,
      "grad_norm": 1.2753386497497559,
      "learning_rate": 4.838938599197779e-05,
      "loss": 0.05,
      "step": 5220
    },
    {
      "epoch": 1.6136994754705338,
      "grad_norm": 1.769648551940918,
      "learning_rate": 4.838630052452947e-05,
      "loss": 0.0541,
      "step": 5230
    },
    {
      "epoch": 1.6167849429188523,
      "grad_norm": 1.0516715049743652,
      "learning_rate": 4.8383215057081146e-05,
      "loss": 0.0744,
      "step": 5240
    },
    {
      "epoch": 1.6198704103671706,
      "grad_norm": 3.170828342437744,
      "learning_rate": 4.8380129589632835e-05,
      "loss": 0.0705,
      "step": 5250
    },
    {
      "epoch": 1.622955877815489,
      "grad_norm": 2.882291078567505,
      "learning_rate": 4.837704412218451e-05,
      "loss": 0.0585,
      "step": 5260
    },
    {
      "epoch": 1.6260413452638076,
      "grad_norm": 0.6304813027381897,
      "learning_rate": 4.8373958654736193e-05,
      "loss": 0.044,
      "step": 5270
    },
    {
      "epoch": 1.629126812712126,
      "grad_norm": 3.7468295097351074,
      "learning_rate": 4.8370873187287876e-05,
      "loss": 0.0462,
      "step": 5280
    },
    {
      "epoch": 1.6322122801604442,
      "grad_norm": 1.4073083400726318,
      "learning_rate": 4.836778771983956e-05,
      "loss": 0.0576,
      "step": 5290
    },
    {
      "epoch": 1.6352977476087627,
      "grad_norm": 3.709810256958008,
      "learning_rate": 4.836470225239124e-05,
      "loss": 0.0803,
      "step": 5300
    },
    {
      "epoch": 1.6383832150570812,
      "grad_norm": 1.3466064929962158,
      "learning_rate": 4.836161678494292e-05,
      "loss": 0.0574,
      "step": 5310
    },
    {
      "epoch": 1.6414686825053995,
      "grad_norm": 2.468928813934326,
      "learning_rate": 4.8358531317494606e-05,
      "loss": 0.0512,
      "step": 5320
    },
    {
      "epoch": 1.644554149953718,
      "grad_norm": 4.385927677154541,
      "learning_rate": 4.835544585004628e-05,
      "loss": 0.048,
      "step": 5330
    },
    {
      "epoch": 1.6476396174020365,
      "grad_norm": 2.734193801879883,
      "learning_rate": 4.8352360382597964e-05,
      "loss": 0.0607,
      "step": 5340
    },
    {
      "epoch": 1.6507250848503547,
      "grad_norm": 1.4796395301818848,
      "learning_rate": 4.8349274915149646e-05,
      "loss": 0.0601,
      "step": 5350
    },
    {
      "epoch": 1.6538105522986732,
      "grad_norm": 1.7663413286209106,
      "learning_rate": 4.834618944770133e-05,
      "loss": 0.0543,
      "step": 5360
    },
    {
      "epoch": 1.6568960197469917,
      "grad_norm": 6.968080043792725,
      "learning_rate": 4.834310398025301e-05,
      "loss": 0.0678,
      "step": 5370
    },
    {
      "epoch": 1.65998148719531,
      "grad_norm": 0.436856210231781,
      "learning_rate": 4.8340018512804694e-05,
      "loss": 0.0462,
      "step": 5380
    },
    {
      "epoch": 1.6630669546436285,
      "grad_norm": 13.011641502380371,
      "learning_rate": 4.8336933045356376e-05,
      "loss": 0.0658,
      "step": 5390
    },
    {
      "epoch": 1.666152422091947,
      "grad_norm": 1.6609723567962646,
      "learning_rate": 4.833384757790805e-05,
      "loss": 0.0495,
      "step": 5400
    },
    {
      "epoch": 1.6692378895402653,
      "grad_norm": 0.88034588098526,
      "learning_rate": 4.8330762110459735e-05,
      "loss": 0.0455,
      "step": 5410
    },
    {
      "epoch": 1.6723233569885838,
      "grad_norm": 1.9421606063842773,
      "learning_rate": 4.832767664301142e-05,
      "loss": 0.0439,
      "step": 5420
    },
    {
      "epoch": 1.6754088244369023,
      "grad_norm": 2.530998706817627,
      "learning_rate": 4.83245911755631e-05,
      "loss": 0.0383,
      "step": 5430
    },
    {
      "epoch": 1.6784942918852206,
      "grad_norm": 8.247846603393555,
      "learning_rate": 4.832150570811478e-05,
      "loss": 0.0836,
      "step": 5440
    },
    {
      "epoch": 1.6815797593335389,
      "grad_norm": 2.2528600692749023,
      "learning_rate": 4.8318420240666464e-05,
      "loss": 0.0491,
      "step": 5450
    },
    {
      "epoch": 1.6846652267818576,
      "grad_norm": 3.8099050521850586,
      "learning_rate": 4.831533477321815e-05,
      "loss": 0.0532,
      "step": 5460
    },
    {
      "epoch": 1.6877506942301759,
      "grad_norm": 4.159979343414307,
      "learning_rate": 4.831224930576982e-05,
      "loss": 0.0638,
      "step": 5470
    },
    {
      "epoch": 1.6908361616784942,
      "grad_norm": 2.4972565174102783,
      "learning_rate": 4.8309163838321505e-05,
      "loss": 0.0703,
      "step": 5480
    },
    {
      "epoch": 1.6939216291268129,
      "grad_norm": 0.4128098487854004,
      "learning_rate": 4.8306078370873194e-05,
      "loss": 0.0317,
      "step": 5490
    },
    {
      "epoch": 1.6970070965751312,
      "grad_norm": 0.7379711270332336,
      "learning_rate": 4.830299290342487e-05,
      "loss": 0.052,
      "step": 5500
    },
    {
      "epoch": 1.7000925640234494,
      "grad_norm": 0.529647171497345,
      "learning_rate": 4.829990743597655e-05,
      "loss": 0.0545,
      "step": 5510
    },
    {
      "epoch": 1.703178031471768,
      "grad_norm": 2.5843052864074707,
      "learning_rate": 4.8296821968528235e-05,
      "loss": 0.1015,
      "step": 5520
    },
    {
      "epoch": 1.7062634989200864,
      "grad_norm": 2.740896463394165,
      "learning_rate": 4.829373650107992e-05,
      "loss": 0.0663,
      "step": 5530
    },
    {
      "epoch": 1.7093489663684047,
      "grad_norm": 4.745924472808838,
      "learning_rate": 4.829065103363159e-05,
      "loss": 0.0571,
      "step": 5540
    },
    {
      "epoch": 1.7124344338167232,
      "grad_norm": 6.102006435394287,
      "learning_rate": 4.828756556618328e-05,
      "loss": 0.0801,
      "step": 5550
    },
    {
      "epoch": 1.7155199012650417,
      "grad_norm": 3.2465147972106934,
      "learning_rate": 4.8284480098734965e-05,
      "loss": 0.0688,
      "step": 5560
    },
    {
      "epoch": 1.71860536871336,
      "grad_norm": 1.7894343137741089,
      "learning_rate": 4.828139463128664e-05,
      "loss": 0.0428,
      "step": 5570
    },
    {
      "epoch": 1.7216908361616785,
      "grad_norm": 1.8046725988388062,
      "learning_rate": 4.827830916383832e-05,
      "loss": 0.0631,
      "step": 5580
    },
    {
      "epoch": 1.724776303609997,
      "grad_norm": 2.5388572216033936,
      "learning_rate": 4.8275223696390006e-05,
      "loss": 0.0465,
      "step": 5590
    },
    {
      "epoch": 1.7278617710583153,
      "grad_norm": 7.834404468536377,
      "learning_rate": 4.827213822894169e-05,
      "loss": 0.0561,
      "step": 5600
    },
    {
      "epoch": 1.7309472385066338,
      "grad_norm": 3.661914825439453,
      "learning_rate": 4.8269052761493364e-05,
      "loss": 0.0666,
      "step": 5610
    },
    {
      "epoch": 1.7340327059549523,
      "grad_norm": 3.1263680458068848,
      "learning_rate": 4.826596729404505e-05,
      "loss": 0.041,
      "step": 5620
    },
    {
      "epoch": 1.7371181734032706,
      "grad_norm": 2.03206467628479,
      "learning_rate": 4.8262881826596735e-05,
      "loss": 0.0609,
      "step": 5630
    },
    {
      "epoch": 1.7402036408515889,
      "grad_norm": 1.0674432516098022,
      "learning_rate": 4.825979635914841e-05,
      "loss": 0.0623,
      "step": 5640
    },
    {
      "epoch": 1.7432891082999076,
      "grad_norm": 3.4290637969970703,
      "learning_rate": 4.8256710891700094e-05,
      "loss": 0.0525,
      "step": 5650
    },
    {
      "epoch": 1.7463745757482259,
      "grad_norm": 3.1897072792053223,
      "learning_rate": 4.8253625424251776e-05,
      "loss": 0.0846,
      "step": 5660
    },
    {
      "epoch": 1.7494600431965441,
      "grad_norm": 3.4192376136779785,
      "learning_rate": 4.825053995680346e-05,
      "loss": 0.0599,
      "step": 5670
    },
    {
      "epoch": 1.7525455106448629,
      "grad_norm": 3.364283561706543,
      "learning_rate": 4.8247454489355134e-05,
      "loss": 0.0702,
      "step": 5680
    },
    {
      "epoch": 1.7556309780931811,
      "grad_norm": 2.8700613975524902,
      "learning_rate": 4.8244369021906824e-05,
      "loss": 0.0433,
      "step": 5690
    },
    {
      "epoch": 1.7587164455414994,
      "grad_norm": 3.8365845680236816,
      "learning_rate": 4.8241283554458506e-05,
      "loss": 0.0675,
      "step": 5700
    },
    {
      "epoch": 1.761801912989818,
      "grad_norm": 0.49653199315071106,
      "learning_rate": 4.823819808701018e-05,
      "loss": 0.0616,
      "step": 5710
    },
    {
      "epoch": 1.7648873804381364,
      "grad_norm": 4.289795398712158,
      "learning_rate": 4.8235112619561864e-05,
      "loss": 0.0379,
      "step": 5720
    },
    {
      "epoch": 1.7679728478864547,
      "grad_norm": 1.4433541297912598,
      "learning_rate": 4.823202715211355e-05,
      "loss": 0.0506,
      "step": 5730
    },
    {
      "epoch": 1.7710583153347732,
      "grad_norm": 5.876363754272461,
      "learning_rate": 4.822894168466523e-05,
      "loss": 0.0496,
      "step": 5740
    },
    {
      "epoch": 1.7741437827830917,
      "grad_norm": 4.079113960266113,
      "learning_rate": 4.8225856217216905e-05,
      "loss": 0.0407,
      "step": 5750
    },
    {
      "epoch": 1.77722925023141,
      "grad_norm": 0.83266681432724,
      "learning_rate": 4.8222770749768594e-05,
      "loss": 0.0393,
      "step": 5760
    },
    {
      "epoch": 1.7803147176797285,
      "grad_norm": 4.544724464416504,
      "learning_rate": 4.821968528232028e-05,
      "loss": 0.054,
      "step": 5770
    },
    {
      "epoch": 1.783400185128047,
      "grad_norm": 2.431575298309326,
      "learning_rate": 4.821659981487195e-05,
      "loss": 0.0428,
      "step": 5780
    },
    {
      "epoch": 1.7864856525763653,
      "grad_norm": 2.0011119842529297,
      "learning_rate": 4.821351434742364e-05,
      "loss": 0.0616,
      "step": 5790
    },
    {
      "epoch": 1.7895711200246838,
      "grad_norm": 2.0954911708831787,
      "learning_rate": 4.821042887997532e-05,
      "loss": 0.0512,
      "step": 5800
    },
    {
      "epoch": 1.7926565874730023,
      "grad_norm": 1.130250334739685,
      "learning_rate": 4.8207343412527e-05,
      "loss": 0.0545,
      "step": 5810
    },
    {
      "epoch": 1.7957420549213206,
      "grad_norm": 4.5971245765686035,
      "learning_rate": 4.820425794507868e-05,
      "loss": 0.057,
      "step": 5820
    },
    {
      "epoch": 1.798827522369639,
      "grad_norm": 0.8255257606506348,
      "learning_rate": 4.8201172477630365e-05,
      "loss": 0.0343,
      "step": 5830
    },
    {
      "epoch": 1.8019129898179576,
      "grad_norm": 2.8487696647644043,
      "learning_rate": 4.819808701018205e-05,
      "loss": 0.0361,
      "step": 5840
    },
    {
      "epoch": 1.8049984572662758,
      "grad_norm": 2.4847593307495117,
      "learning_rate": 4.819500154273372e-05,
      "loss": 0.0385,
      "step": 5850
    },
    {
      "epoch": 1.8080839247145941,
      "grad_norm": 2.4232161045074463,
      "learning_rate": 4.819191607528541e-05,
      "loss": 0.0449,
      "step": 5860
    },
    {
      "epoch": 1.8111693921629128,
      "grad_norm": 0.9272669553756714,
      "learning_rate": 4.818883060783709e-05,
      "loss": 0.0487,
      "step": 5870
    },
    {
      "epoch": 1.8142548596112311,
      "grad_norm": 1.0678220987319946,
      "learning_rate": 4.818574514038877e-05,
      "loss": 0.0372,
      "step": 5880
    },
    {
      "epoch": 1.8173403270595494,
      "grad_norm": 1.9303977489471436,
      "learning_rate": 4.818265967294045e-05,
      "loss": 0.0383,
      "step": 5890
    },
    {
      "epoch": 1.820425794507868,
      "grad_norm": 0.36948150396347046,
      "learning_rate": 4.8179574205492135e-05,
      "loss": 0.0461,
      "step": 5900
    },
    {
      "epoch": 1.8235112619561864,
      "grad_norm": 1.5799403190612793,
      "learning_rate": 4.817648873804382e-05,
      "loss": 0.0727,
      "step": 5910
    },
    {
      "epoch": 1.8265967294045047,
      "grad_norm": 0.8535382747650146,
      "learning_rate": 4.8173403270595493e-05,
      "loss": 0.0508,
      "step": 5920
    },
    {
      "epoch": 1.8296821968528232,
      "grad_norm": 2.8822269439697266,
      "learning_rate": 4.817031780314718e-05,
      "loss": 0.0203,
      "step": 5930
    },
    {
      "epoch": 1.8327676643011417,
      "grad_norm": 0.6516503691673279,
      "learning_rate": 4.816723233569886e-05,
      "loss": 0.0472,
      "step": 5940
    },
    {
      "epoch": 1.83585313174946,
      "grad_norm": 1.6023268699645996,
      "learning_rate": 4.816414686825054e-05,
      "loss": 0.0725,
      "step": 5950
    },
    {
      "epoch": 1.8389385991977785,
      "grad_norm": 2.231808662414551,
      "learning_rate": 4.816106140080222e-05,
      "loss": 0.0531,
      "step": 5960
    },
    {
      "epoch": 1.842024066646097,
      "grad_norm": 1.6901062726974487,
      "learning_rate": 4.8157975933353906e-05,
      "loss": 0.0612,
      "step": 5970
    },
    {
      "epoch": 1.8451095340944152,
      "grad_norm": 1.1372092962265015,
      "learning_rate": 4.815489046590559e-05,
      "loss": 0.0824,
      "step": 5980
    },
    {
      "epoch": 1.8481950015427338,
      "grad_norm": 0.7244151830673218,
      "learning_rate": 4.8151804998457264e-05,
      "loss": 0.0658,
      "step": 5990
    },
    {
      "epoch": 1.8512804689910523,
      "grad_norm": 0.8931616544723511,
      "learning_rate": 4.814871953100895e-05,
      "loss": 0.0421,
      "step": 6000
    },
    {
      "epoch": 1.8543659364393705,
      "grad_norm": 2.435364007949829,
      "learning_rate": 4.814563406356063e-05,
      "loss": 0.0496,
      "step": 6010
    },
    {
      "epoch": 1.857451403887689,
      "grad_norm": 1.5558116436004639,
      "learning_rate": 4.814254859611231e-05,
      "loss": 0.0539,
      "step": 6020
    },
    {
      "epoch": 1.8605368713360075,
      "grad_norm": 2.3656046390533447,
      "learning_rate": 4.8139463128664e-05,
      "loss": 0.0483,
      "step": 6030
    },
    {
      "epoch": 1.8636223387843258,
      "grad_norm": 0.5441749095916748,
      "learning_rate": 4.8136377661215676e-05,
      "loss": 0.0317,
      "step": 6040
    },
    {
      "epoch": 1.866707806232644,
      "grad_norm": 2.807192087173462,
      "learning_rate": 4.813329219376736e-05,
      "loss": 0.0569,
      "step": 6050
    },
    {
      "epoch": 1.8697932736809628,
      "grad_norm": 3.0359554290771484,
      "learning_rate": 4.813020672631904e-05,
      "loss": 0.0609,
      "step": 6060
    },
    {
      "epoch": 1.872878741129281,
      "grad_norm": 1.2903251647949219,
      "learning_rate": 4.8127121258870724e-05,
      "loss": 0.0632,
      "step": 6070
    },
    {
      "epoch": 1.8759642085775994,
      "grad_norm": 2.5658318996429443,
      "learning_rate": 4.81240357914224e-05,
      "loss": 0.0349,
      "step": 6080
    },
    {
      "epoch": 1.8790496760259179,
      "grad_norm": 4.298587799072266,
      "learning_rate": 4.812095032397408e-05,
      "loss": 0.0522,
      "step": 6090
    },
    {
      "epoch": 1.8821351434742364,
      "grad_norm": 4.512303352355957,
      "learning_rate": 4.811786485652577e-05,
      "loss": 0.0552,
      "step": 6100
    },
    {
      "epoch": 1.8852206109225547,
      "grad_norm": 2.1855196952819824,
      "learning_rate": 4.811477938907745e-05,
      "loss": 0.0342,
      "step": 6110
    },
    {
      "epoch": 1.8883060783708732,
      "grad_norm": 1.2630748748779297,
      "learning_rate": 4.811169392162913e-05,
      "loss": 0.043,
      "step": 6120
    },
    {
      "epoch": 1.8913915458191917,
      "grad_norm": 0.5121752023696899,
      "learning_rate": 4.810860845418081e-05,
      "loss": 0.0514,
      "step": 6130
    },
    {
      "epoch": 1.89447701326751,
      "grad_norm": 2.098217725753784,
      "learning_rate": 4.8105522986732494e-05,
      "loss": 0.0399,
      "step": 6140
    },
    {
      "epoch": 1.8975624807158284,
      "grad_norm": 2.692822217941284,
      "learning_rate": 4.810243751928417e-05,
      "loss": 0.0628,
      "step": 6150
    },
    {
      "epoch": 1.900647948164147,
      "grad_norm": 2.251098155975342,
      "learning_rate": 4.809935205183585e-05,
      "loss": 0.0529,
      "step": 6160
    },
    {
      "epoch": 1.9037334156124652,
      "grad_norm": 3.3188445568084717,
      "learning_rate": 4.809626658438754e-05,
      "loss": 0.0558,
      "step": 6170
    },
    {
      "epoch": 1.9068188830607837,
      "grad_norm": 3.841602325439453,
      "learning_rate": 4.809318111693922e-05,
      "loss": 0.0583,
      "step": 6180
    },
    {
      "epoch": 1.9099043505091022,
      "grad_norm": 3.7341017723083496,
      "learning_rate": 4.80900956494909e-05,
      "loss": 0.0503,
      "step": 6190
    },
    {
      "epoch": 1.9129898179574205,
      "grad_norm": 0.7116650938987732,
      "learning_rate": 4.808701018204258e-05,
      "loss": 0.0485,
      "step": 6200
    },
    {
      "epoch": 1.916075285405739,
      "grad_norm": 4.758058071136475,
      "learning_rate": 4.8083924714594265e-05,
      "loss": 0.0586,
      "step": 6210
    },
    {
      "epoch": 1.9191607528540575,
      "grad_norm": 3.9792191982269287,
      "learning_rate": 4.808083924714594e-05,
      "loss": 0.0591,
      "step": 6220
    },
    {
      "epoch": 1.9222462203023758,
      "grad_norm": 1.8136999607086182,
      "learning_rate": 4.807775377969762e-05,
      "loss": 0.0623,
      "step": 6230
    },
    {
      "epoch": 1.925331687750694,
      "grad_norm": 2.2216262817382812,
      "learning_rate": 4.807466831224931e-05,
      "loss": 0.0583,
      "step": 6240
    },
    {
      "epoch": 1.9284171551990128,
      "grad_norm": 1.0484730005264282,
      "learning_rate": 4.807158284480099e-05,
      "loss": 0.0259,
      "step": 6250
    },
    {
      "epoch": 1.931502622647331,
      "grad_norm": 1.8741286993026733,
      "learning_rate": 4.806849737735267e-05,
      "loss": 0.0477,
      "step": 6260
    },
    {
      "epoch": 1.9345880900956494,
      "grad_norm": 2.5544633865356445,
      "learning_rate": 4.806541190990435e-05,
      "loss": 0.0498,
      "step": 6270
    },
    {
      "epoch": 1.9376735575439679,
      "grad_norm": 4.302611827850342,
      "learning_rate": 4.8062326442456036e-05,
      "loss": 0.0312,
      "step": 6280
    },
    {
      "epoch": 1.9407590249922864,
      "grad_norm": 1.3350088596343994,
      "learning_rate": 4.805924097500771e-05,
      "loss": 0.0536,
      "step": 6290
    },
    {
      "epoch": 1.9438444924406046,
      "grad_norm": 3.639340877532959,
      "learning_rate": 4.80561555075594e-05,
      "loss": 0.0499,
      "step": 6300
    },
    {
      "epoch": 1.9469299598889231,
      "grad_norm": 0.46388062834739685,
      "learning_rate": 4.805307004011108e-05,
      "loss": 0.0306,
      "step": 6310
    },
    {
      "epoch": 1.9500154273372416,
      "grad_norm": 1.937406301498413,
      "learning_rate": 4.804998457266276e-05,
      "loss": 0.0489,
      "step": 6320
    },
    {
      "epoch": 1.95310089478556,
      "grad_norm": 2.575456142425537,
      "learning_rate": 4.804689910521444e-05,
      "loss": 0.0595,
      "step": 6330
    },
    {
      "epoch": 1.9561863622338784,
      "grad_norm": 1.2110992670059204,
      "learning_rate": 4.8043813637766124e-05,
      "loss": 0.0345,
      "step": 6340
    },
    {
      "epoch": 1.959271829682197,
      "grad_norm": 2.4706966876983643,
      "learning_rate": 4.8040728170317806e-05,
      "loss": 0.0271,
      "step": 6350
    },
    {
      "epoch": 1.9623572971305152,
      "grad_norm": 0.2335628718137741,
      "learning_rate": 4.803764270286949e-05,
      "loss": 0.0449,
      "step": 6360
    },
    {
      "epoch": 1.9654427645788337,
      "grad_norm": 2.3650143146514893,
      "learning_rate": 4.803455723542117e-05,
      "loss": 0.0306,
      "step": 6370
    },
    {
      "epoch": 1.9685282320271522,
      "grad_norm": 1.5510032176971436,
      "learning_rate": 4.8031471767972854e-05,
      "loss": 0.0421,
      "step": 6380
    },
    {
      "epoch": 1.9716136994754705,
      "grad_norm": 0.9470149874687195,
      "learning_rate": 4.802838630052453e-05,
      "loss": 0.0526,
      "step": 6390
    },
    {
      "epoch": 1.974699166923789,
      "grad_norm": 0.9298089742660522,
      "learning_rate": 4.802530083307621e-05,
      "loss": 0.0288,
      "step": 6400
    },
    {
      "epoch": 1.9777846343721075,
      "grad_norm": 0.9840460419654846,
      "learning_rate": 4.8022215365627894e-05,
      "loss": 0.0552,
      "step": 6410
    },
    {
      "epoch": 1.9808701018204258,
      "grad_norm": 1.1555421352386475,
      "learning_rate": 4.801912989817958e-05,
      "loss": 0.0665,
      "step": 6420
    },
    {
      "epoch": 1.983955569268744,
      "grad_norm": 2.6329667568206787,
      "learning_rate": 4.801604443073126e-05,
      "loss": 0.0456,
      "step": 6430
    },
    {
      "epoch": 1.9870410367170628,
      "grad_norm": 0.41218674182891846,
      "learning_rate": 4.801295896328294e-05,
      "loss": 0.0314,
      "step": 6440
    },
    {
      "epoch": 1.990126504165381,
      "grad_norm": 3.852017641067505,
      "learning_rate": 4.8009873495834624e-05,
      "loss": 0.0455,
      "step": 6450
    },
    {
      "epoch": 1.9932119716136993,
      "grad_norm": 5.135928630828857,
      "learning_rate": 4.80067880283863e-05,
      "loss": 0.0527,
      "step": 6460
    },
    {
      "epoch": 1.9962974390620178,
      "grad_norm": 1.222574234008789,
      "learning_rate": 4.800370256093798e-05,
      "loss": 0.0345,
      "step": 6470
    },
    {
      "epoch": 1.9993829065103363,
      "grad_norm": 7.9899983406066895,
      "learning_rate": 4.8000617093489665e-05,
      "loss": 0.07,
      "step": 6480
    },
    {
      "epoch": 2.0,
      "eval_accuracy_branch1": 0.9691077611566024,
      "eval_accuracy_branch2": 0.497902259772576,
      "eval_f1_branch1": 0.96447848589627,
      "eval_f1_branch2": 0.49515394337433793,
      "eval_loss": 0.02361191064119339,
      "eval_precision_branch1": 0.9636592003520424,
      "eval_precision_branch2": 0.5298953006681771,
      "eval_recall_branch1": 0.965410850337491,
      "eval_recall_branch2": 0.5324715720031249,
      "eval_runtime": 139.1879,
      "eval_samples_per_second": 744.914,
      "eval_steps_per_second": 93.119,
      "step": 6482
    },
    {
      "epoch": 2.0024683739586546,
      "grad_norm": 2.8277249336242676,
      "learning_rate": 4.799753162604135e-05,
      "loss": 0.0495,
      "step": 6490
    },
    {
      "epoch": 2.0055538414069733,
      "grad_norm": 2.323442220687866,
      "learning_rate": 4.799444615859303e-05,
      "loss": 0.0429,
      "step": 6500
    },
    {
      "epoch": 2.0086393088552916,
      "grad_norm": 1.753510594367981,
      "learning_rate": 4.799136069114471e-05,
      "loss": 0.0315,
      "step": 6510
    },
    {
      "epoch": 2.01172477630361,
      "grad_norm": 2.2513821125030518,
      "learning_rate": 4.7988275223696395e-05,
      "loss": 0.0362,
      "step": 6520
    },
    {
      "epoch": 2.0148102437519286,
      "grad_norm": 0.4650845229625702,
      "learning_rate": 4.798518975624807e-05,
      "loss": 0.0428,
      "step": 6530
    },
    {
      "epoch": 2.017895711200247,
      "grad_norm": 2.7585182189941406,
      "learning_rate": 4.798210428879976e-05,
      "loss": 0.0461,
      "step": 6540
    },
    {
      "epoch": 2.020981178648565,
      "grad_norm": 2.518523931503296,
      "learning_rate": 4.7979018821351435e-05,
      "loss": 0.0272,
      "step": 6550
    },
    {
      "epoch": 2.0240666460968835,
      "grad_norm": 3.7325754165649414,
      "learning_rate": 4.797593335390312e-05,
      "loss": 0.0228,
      "step": 6560
    },
    {
      "epoch": 2.027152113545202,
      "grad_norm": 1.6034656763076782,
      "learning_rate": 4.79728478864548e-05,
      "loss": 0.0424,
      "step": 6570
    },
    {
      "epoch": 2.0302375809935205,
      "grad_norm": 5.432483673095703,
      "learning_rate": 4.796976241900648e-05,
      "loss": 0.0324,
      "step": 6580
    },
    {
      "epoch": 2.0333230484418388,
      "grad_norm": 1.8403364419937134,
      "learning_rate": 4.7966676951558165e-05,
      "loss": 0.0368,
      "step": 6590
    },
    {
      "epoch": 2.0364085158901575,
      "grad_norm": 10.322785377502441,
      "learning_rate": 4.796359148410984e-05,
      "loss": 0.0623,
      "step": 6600
    },
    {
      "epoch": 2.0394939833384758,
      "grad_norm": 4.789164066314697,
      "learning_rate": 4.796050601666153e-05,
      "loss": 0.0489,
      "step": 6610
    },
    {
      "epoch": 2.042579450786794,
      "grad_norm": 0.6697916388511658,
      "learning_rate": 4.7957420549213206e-05,
      "loss": 0.0412,
      "step": 6620
    },
    {
      "epoch": 2.0456649182351128,
      "grad_norm": 1.5982586145401,
      "learning_rate": 4.795433508176489e-05,
      "loss": 0.0369,
      "step": 6630
    },
    {
      "epoch": 2.048750385683431,
      "grad_norm": 0.10519486665725708,
      "learning_rate": 4.795124961431657e-05,
      "loss": 0.0387,
      "step": 6640
    },
    {
      "epoch": 2.0518358531317493,
      "grad_norm": 3.26643443107605,
      "learning_rate": 4.794816414686825e-05,
      "loss": 0.0323,
      "step": 6650
    },
    {
      "epoch": 2.054921320580068,
      "grad_norm": 1.7367615699768066,
      "learning_rate": 4.7945078679419936e-05,
      "loss": 0.0661,
      "step": 6660
    },
    {
      "epoch": 2.0580067880283863,
      "grad_norm": 3.1337497234344482,
      "learning_rate": 4.794199321197161e-05,
      "loss": 0.0207,
      "step": 6670
    },
    {
      "epoch": 2.0610922554767046,
      "grad_norm": 1.706834077835083,
      "learning_rate": 4.79389077445233e-05,
      "loss": 0.0406,
      "step": 6680
    },
    {
      "epoch": 2.0641777229250233,
      "grad_norm": 2.836500644683838,
      "learning_rate": 4.7935822277074976e-05,
      "loss": 0.0563,
      "step": 6690
    },
    {
      "epoch": 2.0672631903733416,
      "grad_norm": 1.2419633865356445,
      "learning_rate": 4.793273680962666e-05,
      "loss": 0.0408,
      "step": 6700
    },
    {
      "epoch": 2.07034865782166,
      "grad_norm": 7.340677261352539,
      "learning_rate": 4.792965134217834e-05,
      "loss": 0.0404,
      "step": 6710
    },
    {
      "epoch": 2.0734341252699786,
      "grad_norm": 2.0500214099884033,
      "learning_rate": 4.7926565874730024e-05,
      "loss": 0.0306,
      "step": 6720
    },
    {
      "epoch": 2.076519592718297,
      "grad_norm": 1.0753297805786133,
      "learning_rate": 4.7923480407281706e-05,
      "loss": 0.0347,
      "step": 6730
    },
    {
      "epoch": 2.079605060166615,
      "grad_norm": 0.27772414684295654,
      "learning_rate": 4.792039493983338e-05,
      "loss": 0.0154,
      "step": 6740
    },
    {
      "epoch": 2.0826905276149335,
      "grad_norm": 3.902806282043457,
      "learning_rate": 4.791730947238507e-05,
      "loss": 0.035,
      "step": 6750
    },
    {
      "epoch": 2.085775995063252,
      "grad_norm": 3.8726577758789062,
      "learning_rate": 4.791422400493675e-05,
      "loss": 0.0362,
      "step": 6760
    },
    {
      "epoch": 2.0888614625115705,
      "grad_norm": 3.269533634185791,
      "learning_rate": 4.791113853748843e-05,
      "loss": 0.035,
      "step": 6770
    },
    {
      "epoch": 2.0919469299598887,
      "grad_norm": 3.2255444526672363,
      "learning_rate": 4.790805307004012e-05,
      "loss": 0.0553,
      "step": 6780
    },
    {
      "epoch": 2.0950323974082075,
      "grad_norm": 5.1971540451049805,
      "learning_rate": 4.7904967602591794e-05,
      "loss": 0.0553,
      "step": 6790
    },
    {
      "epoch": 2.0981178648565257,
      "grad_norm": 3.2172346115112305,
      "learning_rate": 4.790188213514348e-05,
      "loss": 0.0321,
      "step": 6800
    },
    {
      "epoch": 2.101203332304844,
      "grad_norm": 2.9563610553741455,
      "learning_rate": 4.789879666769516e-05,
      "loss": 0.0604,
      "step": 6810
    },
    {
      "epoch": 2.1042887997531627,
      "grad_norm": 2.702134609222412,
      "learning_rate": 4.789571120024684e-05,
      "loss": 0.0428,
      "step": 6820
    },
    {
      "epoch": 2.107374267201481,
      "grad_norm": 1.7566505670547485,
      "learning_rate": 4.7892625732798524e-05,
      "loss": 0.0349,
      "step": 6830
    },
    {
      "epoch": 2.1104597346497993,
      "grad_norm": 3.090250015258789,
      "learning_rate": 4.78895402653502e-05,
      "loss": 0.0432,
      "step": 6840
    },
    {
      "epoch": 2.113545202098118,
      "grad_norm": 0.6706316471099854,
      "learning_rate": 4.788645479790189e-05,
      "loss": 0.0467,
      "step": 6850
    },
    {
      "epoch": 2.1166306695464363,
      "grad_norm": 2.3214902877807617,
      "learning_rate": 4.7883369330453565e-05,
      "loss": 0.0349,
      "step": 6860
    },
    {
      "epoch": 2.1197161369947546,
      "grad_norm": 4.684299945831299,
      "learning_rate": 4.788028386300525e-05,
      "loss": 0.0463,
      "step": 6870
    },
    {
      "epoch": 2.1228016044430733,
      "grad_norm": 4.568251609802246,
      "learning_rate": 4.787719839555693e-05,
      "loss": 0.0438,
      "step": 6880
    },
    {
      "epoch": 2.1258870718913916,
      "grad_norm": 2.4754865169525146,
      "learning_rate": 4.787411292810861e-05,
      "loss": 0.0349,
      "step": 6890
    },
    {
      "epoch": 2.12897253933971,
      "grad_norm": 3.149766683578491,
      "learning_rate": 4.7871027460660295e-05,
      "loss": 0.0205,
      "step": 6900
    },
    {
      "epoch": 2.1320580067880286,
      "grad_norm": 3.3798916339874268,
      "learning_rate": 4.786794199321197e-05,
      "loss": 0.0339,
      "step": 6910
    },
    {
      "epoch": 2.135143474236347,
      "grad_norm": 1.0885752439498901,
      "learning_rate": 4.786485652576366e-05,
      "loss": 0.0359,
      "step": 6920
    },
    {
      "epoch": 2.138228941684665,
      "grad_norm": 2.935561418533325,
      "learning_rate": 4.7861771058315336e-05,
      "loss": 0.0432,
      "step": 6930
    },
    {
      "epoch": 2.141314409132984,
      "grad_norm": 0.9121533632278442,
      "learning_rate": 4.785868559086702e-05,
      "loss": 0.032,
      "step": 6940
    },
    {
      "epoch": 2.144399876581302,
      "grad_norm": 4.261776447296143,
      "learning_rate": 4.78556001234187e-05,
      "loss": 0.0333,
      "step": 6950
    },
    {
      "epoch": 2.1474853440296204,
      "grad_norm": 0.7112972736358643,
      "learning_rate": 4.785251465597038e-05,
      "loss": 0.0238,
      "step": 6960
    },
    {
      "epoch": 2.1505708114779387,
      "grad_norm": 2.1976637840270996,
      "learning_rate": 4.7849429188522065e-05,
      "loss": 0.0491,
      "step": 6970
    },
    {
      "epoch": 2.1536562789262574,
      "grad_norm": 0.6126469969749451,
      "learning_rate": 4.784634372107374e-05,
      "loss": 0.0453,
      "step": 6980
    },
    {
      "epoch": 2.1567417463745757,
      "grad_norm": 4.465632438659668,
      "learning_rate": 4.784325825362543e-05,
      "loss": 0.0451,
      "step": 6990
    },
    {
      "epoch": 2.159827213822894,
      "grad_norm": 0.1824718564748764,
      "learning_rate": 4.7840172786177106e-05,
      "loss": 0.0367,
      "step": 7000
    },
    {
      "epoch": 2.1629126812712127,
      "grad_norm": 3.682584762573242,
      "learning_rate": 4.783708731872879e-05,
      "loss": 0.0414,
      "step": 7010
    },
    {
      "epoch": 2.165998148719531,
      "grad_norm": 0.8660305738449097,
      "learning_rate": 4.783400185128047e-05,
      "loss": 0.0222,
      "step": 7020
    },
    {
      "epoch": 2.1690836161678493,
      "grad_norm": 2.1545369625091553,
      "learning_rate": 4.7830916383832154e-05,
      "loss": 0.0399,
      "step": 7030
    },
    {
      "epoch": 2.172169083616168,
      "grad_norm": 6.094576358795166,
      "learning_rate": 4.7827830916383836e-05,
      "loss": 0.0489,
      "step": 7040
    },
    {
      "epoch": 2.1752545510644863,
      "grad_norm": 1.026426911354065,
      "learning_rate": 4.782474544893552e-05,
      "loss": 0.0427,
      "step": 7050
    },
    {
      "epoch": 2.1783400185128046,
      "grad_norm": 1.2075525522232056,
      "learning_rate": 4.78216599814872e-05,
      "loss": 0.0318,
      "step": 7060
    },
    {
      "epoch": 2.1814254859611233,
      "grad_norm": 4.23460054397583,
      "learning_rate": 4.781857451403888e-05,
      "loss": 0.0362,
      "step": 7070
    },
    {
      "epoch": 2.1845109534094416,
      "grad_norm": 4.386621952056885,
      "learning_rate": 4.781548904659056e-05,
      "loss": 0.0277,
      "step": 7080
    },
    {
      "epoch": 2.18759642085776,
      "grad_norm": 2.762863874435425,
      "learning_rate": 4.781240357914224e-05,
      "loss": 0.0287,
      "step": 7090
    },
    {
      "epoch": 2.1906818883060786,
      "grad_norm": 3.0246376991271973,
      "learning_rate": 4.7809318111693924e-05,
      "loss": 0.0231,
      "step": 7100
    },
    {
      "epoch": 2.193767355754397,
      "grad_norm": 3.8520874977111816,
      "learning_rate": 4.7806232644245607e-05,
      "loss": 0.0207,
      "step": 7110
    },
    {
      "epoch": 2.196852823202715,
      "grad_norm": 1.8445059061050415,
      "learning_rate": 4.780314717679729e-05,
      "loss": 0.0253,
      "step": 7120
    },
    {
      "epoch": 2.1999382906510334,
      "grad_norm": 0.36949652433395386,
      "learning_rate": 4.780006170934897e-05,
      "loss": 0.0474,
      "step": 7130
    },
    {
      "epoch": 2.203023758099352,
      "grad_norm": 1.8143277168273926,
      "learning_rate": 4.779697624190065e-05,
      "loss": 0.0434,
      "step": 7140
    },
    {
      "epoch": 2.2061092255476704,
      "grad_norm": 1.4743558168411255,
      "learning_rate": 4.779389077445233e-05,
      "loss": 0.0311,
      "step": 7150
    },
    {
      "epoch": 2.2091946929959887,
      "grad_norm": 5.384611129760742,
      "learning_rate": 4.779080530700401e-05,
      "loss": 0.0514,
      "step": 7160
    },
    {
      "epoch": 2.2122801604443074,
      "grad_norm": 5.721904754638672,
      "learning_rate": 4.7787719839555695e-05,
      "loss": 0.0469,
      "step": 7170
    },
    {
      "epoch": 2.2153656278926257,
      "grad_norm": 2.405468225479126,
      "learning_rate": 4.778463437210738e-05,
      "loss": 0.029,
      "step": 7180
    },
    {
      "epoch": 2.218451095340944,
      "grad_norm": 3.3369028568267822,
      "learning_rate": 4.778154890465906e-05,
      "loss": 0.0578,
      "step": 7190
    },
    {
      "epoch": 2.2215365627892627,
      "grad_norm": 0.9307798147201538,
      "learning_rate": 4.777846343721074e-05,
      "loss": 0.0364,
      "step": 7200
    },
    {
      "epoch": 2.224622030237581,
      "grad_norm": 5.6292619705200195,
      "learning_rate": 4.777537796976242e-05,
      "loss": 0.0687,
      "step": 7210
    },
    {
      "epoch": 2.2277074976858993,
      "grad_norm": 4.393047332763672,
      "learning_rate": 4.77722925023141e-05,
      "loss": 0.0533,
      "step": 7220
    },
    {
      "epoch": 2.230792965134218,
      "grad_norm": 2.313640832901001,
      "learning_rate": 4.776920703486579e-05,
      "loss": 0.0368,
      "step": 7230
    },
    {
      "epoch": 2.2338784325825363,
      "grad_norm": 1.247665286064148,
      "learning_rate": 4.7766121567417465e-05,
      "loss": 0.0188,
      "step": 7240
    },
    {
      "epoch": 2.2369639000308545,
      "grad_norm": 4.292677402496338,
      "learning_rate": 4.776303609996915e-05,
      "loss": 0.0441,
      "step": 7250
    },
    {
      "epoch": 2.2400493674791733,
      "grad_norm": 1.2326023578643799,
      "learning_rate": 4.775995063252083e-05,
      "loss": 0.0273,
      "step": 7260
    },
    {
      "epoch": 2.2431348349274915,
      "grad_norm": 3.1077096462249756,
      "learning_rate": 4.775686516507251e-05,
      "loss": 0.0422,
      "step": 7270
    },
    {
      "epoch": 2.24622030237581,
      "grad_norm": 0.15684521198272705,
      "learning_rate": 4.775377969762419e-05,
      "loss": 0.0382,
      "step": 7280
    },
    {
      "epoch": 2.2493057698241286,
      "grad_norm": 0.5992249846458435,
      "learning_rate": 4.775069423017587e-05,
      "loss": 0.0249,
      "step": 7290
    },
    {
      "epoch": 2.252391237272447,
      "grad_norm": 0.8287715315818787,
      "learning_rate": 4.774760876272756e-05,
      "loss": 0.0404,
      "step": 7300
    },
    {
      "epoch": 2.255476704720765,
      "grad_norm": 0.1540360152721405,
      "learning_rate": 4.7744523295279236e-05,
      "loss": 0.0147,
      "step": 7310
    },
    {
      "epoch": 2.258562172169084,
      "grad_norm": 0.5567266941070557,
      "learning_rate": 4.774143782783092e-05,
      "loss": 0.0344,
      "step": 7320
    },
    {
      "epoch": 2.261647639617402,
      "grad_norm": 3.300356149673462,
      "learning_rate": 4.77383523603826e-05,
      "loss": 0.026,
      "step": 7330
    },
    {
      "epoch": 2.2647331070657204,
      "grad_norm": 2.327073097229004,
      "learning_rate": 4.773526689293428e-05,
      "loss": 0.0593,
      "step": 7340
    },
    {
      "epoch": 2.267818574514039,
      "grad_norm": 1.1014901399612427,
      "learning_rate": 4.773218142548596e-05,
      "loss": 0.0293,
      "step": 7350
    },
    {
      "epoch": 2.2709040419623574,
      "grad_norm": 0.9169215559959412,
      "learning_rate": 4.772909595803765e-05,
      "loss": 0.0612,
      "step": 7360
    },
    {
      "epoch": 2.2739895094106757,
      "grad_norm": 1.349951148033142,
      "learning_rate": 4.772601049058933e-05,
      "loss": 0.0283,
      "step": 7370
    },
    {
      "epoch": 2.277074976858994,
      "grad_norm": 3.1126489639282227,
      "learning_rate": 4.7722925023141006e-05,
      "loss": 0.0344,
      "step": 7380
    },
    {
      "epoch": 2.2801604443073127,
      "grad_norm": 1.9997981786727905,
      "learning_rate": 4.771983955569269e-05,
      "loss": 0.0515,
      "step": 7390
    },
    {
      "epoch": 2.283245911755631,
      "grad_norm": 2.7096340656280518,
      "learning_rate": 4.771675408824437e-05,
      "loss": 0.0378,
      "step": 7400
    },
    {
      "epoch": 2.2863313792039492,
      "grad_norm": 0.34145045280456543,
      "learning_rate": 4.7713668620796054e-05,
      "loss": 0.0241,
      "step": 7410
    },
    {
      "epoch": 2.289416846652268,
      "grad_norm": 1.2037321329116821,
      "learning_rate": 4.771058315334773e-05,
      "loss": 0.0362,
      "step": 7420
    },
    {
      "epoch": 2.2925023141005862,
      "grad_norm": 2.349559783935547,
      "learning_rate": 4.770749768589942e-05,
      "loss": 0.0372,
      "step": 7430
    },
    {
      "epoch": 2.2955877815489045,
      "grad_norm": 1.7636100053787231,
      "learning_rate": 4.77044122184511e-05,
      "loss": 0.0417,
      "step": 7440
    },
    {
      "epoch": 2.2986732489972233,
      "grad_norm": 2.5856587886810303,
      "learning_rate": 4.770132675100278e-05,
      "loss": 0.0457,
      "step": 7450
    },
    {
      "epoch": 2.3017587164455415,
      "grad_norm": 0.558158278465271,
      "learning_rate": 4.769824128355446e-05,
      "loss": 0.0262,
      "step": 7460
    },
    {
      "epoch": 2.30484418389386,
      "grad_norm": 0.7269660234451294,
      "learning_rate": 4.769515581610614e-05,
      "loss": 0.0299,
      "step": 7470
    },
    {
      "epoch": 2.3079296513421785,
      "grad_norm": 3.9473211765289307,
      "learning_rate": 4.7692070348657824e-05,
      "loss": 0.0401,
      "step": 7480
    },
    {
      "epoch": 2.311015118790497,
      "grad_norm": 0.3764576315879822,
      "learning_rate": 4.76889848812095e-05,
      "loss": 0.0262,
      "step": 7490
    },
    {
      "epoch": 2.314100586238815,
      "grad_norm": 0.18007875978946686,
      "learning_rate": 4.768589941376119e-05,
      "loss": 0.0386,
      "step": 7500
    },
    {
      "epoch": 2.3171860536871334,
      "grad_norm": 1.6942691802978516,
      "learning_rate": 4.768281394631287e-05,
      "loss": 0.0312,
      "step": 7510
    },
    {
      "epoch": 2.320271521135452,
      "grad_norm": 1.8811166286468506,
      "learning_rate": 4.767972847886455e-05,
      "loss": 0.0264,
      "step": 7520
    },
    {
      "epoch": 2.3233569885837704,
      "grad_norm": 1.3067755699157715,
      "learning_rate": 4.767664301141623e-05,
      "loss": 0.0272,
      "step": 7530
    },
    {
      "epoch": 2.3264424560320887,
      "grad_norm": 0.4518890678882599,
      "learning_rate": 4.767355754396791e-05,
      "loss": 0.0366,
      "step": 7540
    },
    {
      "epoch": 2.3295279234804074,
      "grad_norm": 2.592318058013916,
      "learning_rate": 4.7670472076519595e-05,
      "loss": 0.0384,
      "step": 7550
    },
    {
      "epoch": 2.3326133909287257,
      "grad_norm": 0.3547065258026123,
      "learning_rate": 4.766738660907127e-05,
      "loss": 0.0336,
      "step": 7560
    },
    {
      "epoch": 2.335698858377044,
      "grad_norm": 2.394376754760742,
      "learning_rate": 4.766430114162296e-05,
      "loss": 0.0412,
      "step": 7570
    },
    {
      "epoch": 2.3387843258253627,
      "grad_norm": 1.8608092069625854,
      "learning_rate": 4.766121567417464e-05,
      "loss": 0.0359,
      "step": 7580
    },
    {
      "epoch": 2.341869793273681,
      "grad_norm": 1.086410641670227,
      "learning_rate": 4.765813020672632e-05,
      "loss": 0.0376,
      "step": 7590
    },
    {
      "epoch": 2.3449552607219992,
      "grad_norm": 0.2295149862766266,
      "learning_rate": 4.765504473927801e-05,
      "loss": 0.0354,
      "step": 7600
    },
    {
      "epoch": 2.348040728170318,
      "grad_norm": 0.5685696601867676,
      "learning_rate": 4.765195927182968e-05,
      "loss": 0.0367,
      "step": 7610
    },
    {
      "epoch": 2.3511261956186362,
      "grad_norm": 0.30432945489883423,
      "learning_rate": 4.7648873804381365e-05,
      "loss": 0.0218,
      "step": 7620
    },
    {
      "epoch": 2.3542116630669545,
      "grad_norm": 3.923668146133423,
      "learning_rate": 4.764578833693305e-05,
      "loss": 0.0262,
      "step": 7630
    },
    {
      "epoch": 2.3572971305152732,
      "grad_norm": 2.1594154834747314,
      "learning_rate": 4.764270286948473e-05,
      "loss": 0.0306,
      "step": 7640
    },
    {
      "epoch": 2.3603825979635915,
      "grad_norm": 3.636437177658081,
      "learning_rate": 4.763961740203641e-05,
      "loss": 0.034,
      "step": 7650
    },
    {
      "epoch": 2.36346806541191,
      "grad_norm": 2.2802622318267822,
      "learning_rate": 4.763653193458809e-05,
      "loss": 0.0412,
      "step": 7660
    },
    {
      "epoch": 2.3665535328602285,
      "grad_norm": 1.8845405578613281,
      "learning_rate": 4.763344646713978e-05,
      "loss": 0.0306,
      "step": 7670
    },
    {
      "epoch": 2.369639000308547,
      "grad_norm": 1.7318193912506104,
      "learning_rate": 4.7630360999691454e-05,
      "loss": 0.0201,
      "step": 7680
    },
    {
      "epoch": 2.372724467756865,
      "grad_norm": 1.2048847675323486,
      "learning_rate": 4.7627275532243136e-05,
      "loss": 0.037,
      "step": 7690
    },
    {
      "epoch": 2.375809935205184,
      "grad_norm": 0.51613450050354,
      "learning_rate": 4.762419006479482e-05,
      "loss": 0.0421,
      "step": 7700
    },
    {
      "epoch": 2.378895402653502,
      "grad_norm": 2.775362491607666,
      "learning_rate": 4.76211045973465e-05,
      "loss": 0.0292,
      "step": 7710
    },
    {
      "epoch": 2.3819808701018204,
      "grad_norm": 0.5434460043907166,
      "learning_rate": 4.7618019129898183e-05,
      "loss": 0.0552,
      "step": 7720
    },
    {
      "epoch": 2.385066337550139,
      "grad_norm": 2.3920695781707764,
      "learning_rate": 4.761493366244986e-05,
      "loss": 0.0381,
      "step": 7730
    },
    {
      "epoch": 2.3881518049984574,
      "grad_norm": 3.3202624320983887,
      "learning_rate": 4.761184819500155e-05,
      "loss": 0.0276,
      "step": 7740
    },
    {
      "epoch": 2.3912372724467756,
      "grad_norm": 4.984867095947266,
      "learning_rate": 4.7608762727553224e-05,
      "loss": 0.031,
      "step": 7750
    },
    {
      "epoch": 2.394322739895094,
      "grad_norm": 2.828803300857544,
      "learning_rate": 4.7605677260104907e-05,
      "loss": 0.0221,
      "step": 7760
    },
    {
      "epoch": 2.3974082073434126,
      "grad_norm": 3.2582123279571533,
      "learning_rate": 4.760259179265659e-05,
      "loss": 0.044,
      "step": 7770
    },
    {
      "epoch": 2.400493674791731,
      "grad_norm": 0.24578139185905457,
      "learning_rate": 4.759950632520827e-05,
      "loss": 0.036,
      "step": 7780
    },
    {
      "epoch": 2.403579142240049,
      "grad_norm": 5.089114665985107,
      "learning_rate": 4.7596420857759954e-05,
      "loss": 0.0337,
      "step": 7790
    },
    {
      "epoch": 2.406664609688368,
      "grad_norm": 0.4012916386127472,
      "learning_rate": 4.759333539031163e-05,
      "loss": 0.0403,
      "step": 7800
    },
    {
      "epoch": 2.409750077136686,
      "grad_norm": 5.435967445373535,
      "learning_rate": 4.759024992286332e-05,
      "loss": 0.0361,
      "step": 7810
    },
    {
      "epoch": 2.4128355445850045,
      "grad_norm": 0.7472293376922607,
      "learning_rate": 4.7587164455414995e-05,
      "loss": 0.0257,
      "step": 7820
    },
    {
      "epoch": 2.415921012033323,
      "grad_norm": 4.789355754852295,
      "learning_rate": 4.758407898796668e-05,
      "loss": 0.0403,
      "step": 7830
    },
    {
      "epoch": 2.4190064794816415,
      "grad_norm": 0.24182680249214172,
      "learning_rate": 4.7580993520518366e-05,
      "loss": 0.0411,
      "step": 7840
    },
    {
      "epoch": 2.4220919469299598,
      "grad_norm": 1.2075566053390503,
      "learning_rate": 4.757790805307004e-05,
      "loss": 0.037,
      "step": 7850
    },
    {
      "epoch": 2.4251774143782785,
      "grad_norm": 2.285007953643799,
      "learning_rate": 4.7574822585621725e-05,
      "loss": 0.0292,
      "step": 7860
    },
    {
      "epoch": 2.4282628818265968,
      "grad_norm": 3.5051209926605225,
      "learning_rate": 4.757173711817341e-05,
      "loss": 0.043,
      "step": 7870
    },
    {
      "epoch": 2.431348349274915,
      "grad_norm": 0.6902135014533997,
      "learning_rate": 4.756865165072509e-05,
      "loss": 0.0226,
      "step": 7880
    },
    {
      "epoch": 2.4344338167232333,
      "grad_norm": 0.18582645058631897,
      "learning_rate": 4.7565566183276765e-05,
      "loss": 0.0225,
      "step": 7890
    },
    {
      "epoch": 2.437519284171552,
      "grad_norm": 2.358522653579712,
      "learning_rate": 4.756248071582845e-05,
      "loss": 0.0286,
      "step": 7900
    },
    {
      "epoch": 2.4406047516198703,
      "grad_norm": 3.0857934951782227,
      "learning_rate": 4.755939524838014e-05,
      "loss": 0.0376,
      "step": 7910
    },
    {
      "epoch": 2.4436902190681886,
      "grad_norm": 7.315994739532471,
      "learning_rate": 4.755630978093181e-05,
      "loss": 0.0433,
      "step": 7920
    },
    {
      "epoch": 2.4467756865165073,
      "grad_norm": 2.142849922180176,
      "learning_rate": 4.7553224313483495e-05,
      "loss": 0.0325,
      "step": 7930
    },
    {
      "epoch": 2.4498611539648256,
      "grad_norm": 0.14553463459014893,
      "learning_rate": 4.755013884603518e-05,
      "loss": 0.0224,
      "step": 7940
    },
    {
      "epoch": 2.452946621413144,
      "grad_norm": 1.9147154092788696,
      "learning_rate": 4.754705337858686e-05,
      "loss": 0.0239,
      "step": 7950
    },
    {
      "epoch": 2.4560320888614626,
      "grad_norm": 1.9099901914596558,
      "learning_rate": 4.7543967911138536e-05,
      "loss": 0.0286,
      "step": 7960
    },
    {
      "epoch": 2.459117556309781,
      "grad_norm": 0.8327261805534363,
      "learning_rate": 4.754088244369022e-05,
      "loss": 0.0425,
      "step": 7970
    },
    {
      "epoch": 2.462203023758099,
      "grad_norm": 2.2432000637054443,
      "learning_rate": 4.753779697624191e-05,
      "loss": 0.0221,
      "step": 7980
    },
    {
      "epoch": 2.465288491206418,
      "grad_norm": 2.7093658447265625,
      "learning_rate": 4.753471150879358e-05,
      "loss": 0.028,
      "step": 7990
    },
    {
      "epoch": 2.468373958654736,
      "grad_norm": 4.519611358642578,
      "learning_rate": 4.7531626041345266e-05,
      "loss": 0.0511,
      "step": 8000
    },
    {
      "epoch": 2.4714594261030545,
      "grad_norm": 2.505563259124756,
      "learning_rate": 4.752854057389695e-05,
      "loss": 0.0401,
      "step": 8010
    },
    {
      "epoch": 2.474544893551373,
      "grad_norm": 3.275968313217163,
      "learning_rate": 4.752545510644863e-05,
      "loss": 0.0225,
      "step": 8020
    },
    {
      "epoch": 2.4776303609996915,
      "grad_norm": 1.6241998672485352,
      "learning_rate": 4.7522369639000306e-05,
      "loss": 0.0424,
      "step": 8030
    },
    {
      "epoch": 2.4807158284480098,
      "grad_norm": 1.5639262199401855,
      "learning_rate": 4.751928417155199e-05,
      "loss": 0.0599,
      "step": 8040
    },
    {
      "epoch": 2.4838012958963285,
      "grad_norm": 1.2538328170776367,
      "learning_rate": 4.751619870410368e-05,
      "loss": 0.0313,
      "step": 8050
    },
    {
      "epoch": 2.4868867633446468,
      "grad_norm": 1.6765644550323486,
      "learning_rate": 4.7513113236655354e-05,
      "loss": 0.04,
      "step": 8060
    },
    {
      "epoch": 2.489972230792965,
      "grad_norm": 0.3934183120727539,
      "learning_rate": 4.7510027769207036e-05,
      "loss": 0.0255,
      "step": 8070
    },
    {
      "epoch": 2.4930576982412838,
      "grad_norm": 1.1766653060913086,
      "learning_rate": 4.750694230175872e-05,
      "loss": 0.0387,
      "step": 8080
    },
    {
      "epoch": 2.496143165689602,
      "grad_norm": 0.9793378710746765,
      "learning_rate": 4.75038568343104e-05,
      "loss": 0.0211,
      "step": 8090
    },
    {
      "epoch": 2.4992286331379203,
      "grad_norm": 2.9994139671325684,
      "learning_rate": 4.7500771366862084e-05,
      "loss": 0.04,
      "step": 8100
    },
    {
      "epoch": 2.502314100586239,
      "grad_norm": 1.8147684335708618,
      "learning_rate": 4.7497685899413766e-05,
      "loss": 0.0375,
      "step": 8110
    },
    {
      "epoch": 2.5053995680345573,
      "grad_norm": 1.5138483047485352,
      "learning_rate": 4.749460043196545e-05,
      "loss": 0.0223,
      "step": 8120
    },
    {
      "epoch": 2.5084850354828756,
      "grad_norm": 0.9631831645965576,
      "learning_rate": 4.7491514964517124e-05,
      "loss": 0.0367,
      "step": 8130
    },
    {
      "epoch": 2.5115705029311943,
      "grad_norm": 2.065601110458374,
      "learning_rate": 4.748842949706881e-05,
      "loss": 0.0572,
      "step": 8140
    },
    {
      "epoch": 2.5146559703795126,
      "grad_norm": 5.046134948730469,
      "learning_rate": 4.748534402962049e-05,
      "loss": 0.0374,
      "step": 8150
    },
    {
      "epoch": 2.517741437827831,
      "grad_norm": 0.655400812625885,
      "learning_rate": 4.748225856217217e-05,
      "loss": 0.0215,
      "step": 8160
    },
    {
      "epoch": 2.5208269052761496,
      "grad_norm": 0.968156635761261,
      "learning_rate": 4.7479173094723854e-05,
      "loss": 0.0336,
      "step": 8170
    },
    {
      "epoch": 2.523912372724468,
      "grad_norm": 0.4286148250102997,
      "learning_rate": 4.747608762727554e-05,
      "loss": 0.0271,
      "step": 8180
    },
    {
      "epoch": 2.526997840172786,
      "grad_norm": 0.16336043179035187,
      "learning_rate": 4.747300215982722e-05,
      "loss": 0.0234,
      "step": 8190
    },
    {
      "epoch": 2.5300833076211044,
      "grad_norm": 2.509721040725708,
      "learning_rate": 4.7469916692378895e-05,
      "loss": 0.0287,
      "step": 8200
    },
    {
      "epoch": 2.533168775069423,
      "grad_norm": 3.101008653640747,
      "learning_rate": 4.746683122493058e-05,
      "loss": 0.0336,
      "step": 8210
    },
    {
      "epoch": 2.5362542425177415,
      "grad_norm": 5.279877185821533,
      "learning_rate": 4.746374575748226e-05,
      "loss": 0.0437,
      "step": 8220
    },
    {
      "epoch": 2.5393397099660597,
      "grad_norm": 1.0913348197937012,
      "learning_rate": 4.746066029003394e-05,
      "loss": 0.0295,
      "step": 8230
    },
    {
      "epoch": 2.542425177414378,
      "grad_norm": 2.5596883296966553,
      "learning_rate": 4.7457574822585625e-05,
      "loss": 0.0422,
      "step": 8240
    },
    {
      "epoch": 2.5455106448626967,
      "grad_norm": 3.233140230178833,
      "learning_rate": 4.745448935513731e-05,
      "loss": 0.0245,
      "step": 8250
    },
    {
      "epoch": 2.548596112311015,
      "grad_norm": 3.7084951400756836,
      "learning_rate": 4.745140388768899e-05,
      "loss": 0.0326,
      "step": 8260
    },
    {
      "epoch": 2.5516815797593333,
      "grad_norm": 3.156935930252075,
      "learning_rate": 4.7448318420240665e-05,
      "loss": 0.0164,
      "step": 8270
    },
    {
      "epoch": 2.554767047207652,
      "grad_norm": 0.40711021423339844,
      "learning_rate": 4.744523295279235e-05,
      "loss": 0.0287,
      "step": 8280
    },
    {
      "epoch": 2.5578525146559703,
      "grad_norm": 1.900583267211914,
      "learning_rate": 4.744214748534403e-05,
      "loss": 0.025,
      "step": 8290
    },
    {
      "epoch": 2.5609379821042886,
      "grad_norm": 2.4816713333129883,
      "learning_rate": 4.743906201789571e-05,
      "loss": 0.0334,
      "step": 8300
    },
    {
      "epoch": 2.5640234495526073,
      "grad_norm": 4.630988597869873,
      "learning_rate": 4.7435976550447395e-05,
      "loss": 0.0224,
      "step": 8310
    },
    {
      "epoch": 2.5671089170009256,
      "grad_norm": 0.44224855303764343,
      "learning_rate": 4.743289108299908e-05,
      "loss": 0.0457,
      "step": 8320
    },
    {
      "epoch": 2.570194384449244,
      "grad_norm": 1.0000836849212646,
      "learning_rate": 4.742980561555076e-05,
      "loss": 0.0195,
      "step": 8330
    },
    {
      "epoch": 2.5732798518975626,
      "grad_norm": 4.285229682922363,
      "learning_rate": 4.7426720148102436e-05,
      "loss": 0.0417,
      "step": 8340
    },
    {
      "epoch": 2.576365319345881,
      "grad_norm": 0.6118230819702148,
      "learning_rate": 4.7423634680654125e-05,
      "loss": 0.0263,
      "step": 8350
    },
    {
      "epoch": 2.579450786794199,
      "grad_norm": 3.0709586143493652,
      "learning_rate": 4.74205492132058e-05,
      "loss": 0.04,
      "step": 8360
    },
    {
      "epoch": 2.582536254242518,
      "grad_norm": 0.7139210104942322,
      "learning_rate": 4.7417463745757483e-05,
      "loss": 0.0429,
      "step": 8370
    },
    {
      "epoch": 2.585621721690836,
      "grad_norm": 4.381478309631348,
      "learning_rate": 4.7414378278309166e-05,
      "loss": 0.031,
      "step": 8380
    },
    {
      "epoch": 2.5887071891391544,
      "grad_norm": 0.3275727927684784,
      "learning_rate": 4.741129281086085e-05,
      "loss": 0.0259,
      "step": 8390
    },
    {
      "epoch": 2.591792656587473,
      "grad_norm": 4.834922790527344,
      "learning_rate": 4.740820734341253e-05,
      "loss": 0.0363,
      "step": 8400
    },
    {
      "epoch": 2.5948781240357914,
      "grad_norm": 4.134532928466797,
      "learning_rate": 4.7405121875964207e-05,
      "loss": 0.0231,
      "step": 8410
    },
    {
      "epoch": 2.5979635914841097,
      "grad_norm": 3.245882034301758,
      "learning_rate": 4.7402036408515896e-05,
      "loss": 0.0347,
      "step": 8420
    },
    {
      "epoch": 2.6010490589324284,
      "grad_norm": 1.4151952266693115,
      "learning_rate": 4.739895094106757e-05,
      "loss": 0.0237,
      "step": 8430
    },
    {
      "epoch": 2.6041345263807467,
      "grad_norm": 0.6320883631706238,
      "learning_rate": 4.7395865473619254e-05,
      "loss": 0.0201,
      "step": 8440
    },
    {
      "epoch": 2.607219993829065,
      "grad_norm": 0.8814252614974976,
      "learning_rate": 4.7392780006170937e-05,
      "loss": 0.039,
      "step": 8450
    },
    {
      "epoch": 2.6103054612773837,
      "grad_norm": 1.2883470058441162,
      "learning_rate": 4.738969453872262e-05,
      "loss": 0.0432,
      "step": 8460
    },
    {
      "epoch": 2.613390928725702,
      "grad_norm": 1.7415090799331665,
      "learning_rate": 4.73866090712743e-05,
      "loss": 0.0348,
      "step": 8470
    },
    {
      "epoch": 2.6164763961740203,
      "grad_norm": 6.983344078063965,
      "learning_rate": 4.738352360382598e-05,
      "loss": 0.0288,
      "step": 8480
    },
    {
      "epoch": 2.619561863622339,
      "grad_norm": 1.6546447277069092,
      "learning_rate": 4.7380438136377666e-05,
      "loss": 0.0231,
      "step": 8490
    },
    {
      "epoch": 2.6226473310706573,
      "grad_norm": 2.031625270843506,
      "learning_rate": 4.737735266892934e-05,
      "loss": 0.0373,
      "step": 8500
    },
    {
      "epoch": 2.6257327985189756,
      "grad_norm": 2.6035525798797607,
      "learning_rate": 4.7374267201481025e-05,
      "loss": 0.0236,
      "step": 8510
    },
    {
      "epoch": 2.6288182659672943,
      "grad_norm": 6.402820587158203,
      "learning_rate": 4.737118173403271e-05,
      "loss": 0.0244,
      "step": 8520
    },
    {
      "epoch": 2.6319037334156126,
      "grad_norm": 5.439671039581299,
      "learning_rate": 4.736809626658439e-05,
      "loss": 0.0362,
      "step": 8530
    },
    {
      "epoch": 2.634989200863931,
      "grad_norm": 1.151525855064392,
      "learning_rate": 4.736501079913607e-05,
      "loss": 0.0214,
      "step": 8540
    },
    {
      "epoch": 2.6380746683122496,
      "grad_norm": 2.4681100845336914,
      "learning_rate": 4.736192533168775e-05,
      "loss": 0.0586,
      "step": 8550
    },
    {
      "epoch": 2.641160135760568,
      "grad_norm": 3.451354503631592,
      "learning_rate": 4.735883986423944e-05,
      "loss": 0.0313,
      "step": 8560
    },
    {
      "epoch": 2.644245603208886,
      "grad_norm": 2.459134340286255,
      "learning_rate": 4.735575439679112e-05,
      "loss": 0.0216,
      "step": 8570
    },
    {
      "epoch": 2.6473310706572044,
      "grad_norm": 6.96041202545166,
      "learning_rate": 4.7352668929342795e-05,
      "loss": 0.0363,
      "step": 8580
    },
    {
      "epoch": 2.650416538105523,
      "grad_norm": 0.38082388043403625,
      "learning_rate": 4.7349583461894484e-05,
      "loss": 0.0245,
      "step": 8590
    },
    {
      "epoch": 2.6535020055538414,
      "grad_norm": 0.3748543858528137,
      "learning_rate": 4.734649799444616e-05,
      "loss": 0.0219,
      "step": 8600
    },
    {
      "epoch": 2.6565874730021597,
      "grad_norm": 0.5012634992599487,
      "learning_rate": 4.734341252699784e-05,
      "loss": 0.0176,
      "step": 8610
    },
    {
      "epoch": 2.659672940450478,
      "grad_norm": 1.6676772832870483,
      "learning_rate": 4.7340327059549525e-05,
      "loss": 0.0443,
      "step": 8620
    },
    {
      "epoch": 2.6627584078987967,
      "grad_norm": 4.889507293701172,
      "learning_rate": 4.733724159210121e-05,
      "loss": 0.0427,
      "step": 8630
    },
    {
      "epoch": 2.665843875347115,
      "grad_norm": 0.02278469130396843,
      "learning_rate": 4.733415612465289e-05,
      "loss": 0.021,
      "step": 8640
    },
    {
      "epoch": 2.6689293427954333,
      "grad_norm": 3.021791696548462,
      "learning_rate": 4.7331070657204566e-05,
      "loss": 0.0374,
      "step": 8650
    },
    {
      "epoch": 2.672014810243752,
      "grad_norm": 0.4120505452156067,
      "learning_rate": 4.7327985189756255e-05,
      "loss": 0.0283,
      "step": 8660
    },
    {
      "epoch": 2.6751002776920703,
      "grad_norm": 0.15524400770664215,
      "learning_rate": 4.732489972230793e-05,
      "loss": 0.0295,
      "step": 8670
    },
    {
      "epoch": 2.6781857451403885,
      "grad_norm": 4.099704265594482,
      "learning_rate": 4.732181425485961e-05,
      "loss": 0.0206,
      "step": 8680
    },
    {
      "epoch": 2.6812712125887073,
      "grad_norm": 1.4594897031784058,
      "learning_rate": 4.7318728787411296e-05,
      "loss": 0.0239,
      "step": 8690
    },
    {
      "epoch": 2.6843566800370255,
      "grad_norm": 3.1012027263641357,
      "learning_rate": 4.731564331996298e-05,
      "loss": 0.0365,
      "step": 8700
    },
    {
      "epoch": 2.687442147485344,
      "grad_norm": 1.3832403421401978,
      "learning_rate": 4.731255785251466e-05,
      "loss": 0.0143,
      "step": 8710
    },
    {
      "epoch": 2.6905276149336625,
      "grad_norm": 1.9919263124465942,
      "learning_rate": 4.7309472385066336e-05,
      "loss": 0.0248,
      "step": 8720
    },
    {
      "epoch": 2.693613082381981,
      "grad_norm": 1.6637014150619507,
      "learning_rate": 4.7306386917618026e-05,
      "loss": 0.0261,
      "step": 8730
    },
    {
      "epoch": 2.696698549830299,
      "grad_norm": 2.123410701751709,
      "learning_rate": 4.73033014501697e-05,
      "loss": 0.0392,
      "step": 8740
    },
    {
      "epoch": 2.699784017278618,
      "grad_norm": 0.4770054221153259,
      "learning_rate": 4.7300215982721384e-05,
      "loss": 0.0245,
      "step": 8750
    },
    {
      "epoch": 2.702869484726936,
      "grad_norm": 5.261619567871094,
      "learning_rate": 4.7297130515273066e-05,
      "loss": 0.0301,
      "step": 8760
    },
    {
      "epoch": 2.7059549521752544,
      "grad_norm": 4.200944900512695,
      "learning_rate": 4.729404504782475e-05,
      "loss": 0.0161,
      "step": 8770
    },
    {
      "epoch": 2.709040419623573,
      "grad_norm": 1.0546218156814575,
      "learning_rate": 4.729095958037643e-05,
      "loss": 0.0463,
      "step": 8780
    },
    {
      "epoch": 2.7121258870718914,
      "grad_norm": 2.0206105709075928,
      "learning_rate": 4.728787411292811e-05,
      "loss": 0.0143,
      "step": 8790
    },
    {
      "epoch": 2.7152113545202097,
      "grad_norm": 0.160983607172966,
      "learning_rate": 4.7284788645479796e-05,
      "loss": 0.0191,
      "step": 8800
    },
    {
      "epoch": 2.7182968219685284,
      "grad_norm": 3.987510919570923,
      "learning_rate": 4.728170317803147e-05,
      "loss": 0.0421,
      "step": 8810
    },
    {
      "epoch": 2.7213822894168467,
      "grad_norm": 2.4654135704040527,
      "learning_rate": 4.7278617710583154e-05,
      "loss": 0.0397,
      "step": 8820
    },
    {
      "epoch": 2.724467756865165,
      "grad_norm": 0.21608775854110718,
      "learning_rate": 4.727553224313484e-05,
      "loss": 0.0579,
      "step": 8830
    },
    {
      "epoch": 2.7275532243134837,
      "grad_norm": 1.558688998222351,
      "learning_rate": 4.727244677568652e-05,
      "loss": 0.0209,
      "step": 8840
    },
    {
      "epoch": 2.730638691761802,
      "grad_norm": 3.14103102684021,
      "learning_rate": 4.72693613082382e-05,
      "loss": 0.0321,
      "step": 8850
    },
    {
      "epoch": 2.7337241592101202,
      "grad_norm": 1.208664059638977,
      "learning_rate": 4.7266275840789884e-05,
      "loss": 0.0148,
      "step": 8860
    },
    {
      "epoch": 2.736809626658439,
      "grad_norm": 3.320988416671753,
      "learning_rate": 4.726319037334157e-05,
      "loss": 0.0248,
      "step": 8870
    },
    {
      "epoch": 2.7398950941067572,
      "grad_norm": 3.825644016265869,
      "learning_rate": 4.726010490589324e-05,
      "loss": 0.0471,
      "step": 8880
    },
    {
      "epoch": 2.7429805615550755,
      "grad_norm": 2.0431253910064697,
      "learning_rate": 4.7257019438444925e-05,
      "loss": 0.018,
      "step": 8890
    },
    {
      "epoch": 2.7460660290033942,
      "grad_norm": 1.454513430595398,
      "learning_rate": 4.725393397099661e-05,
      "loss": 0.0421,
      "step": 8900
    },
    {
      "epoch": 2.7491514964517125,
      "grad_norm": 2.315002918243408,
      "learning_rate": 4.725084850354829e-05,
      "loss": 0.0265,
      "step": 8910
    },
    {
      "epoch": 2.752236963900031,
      "grad_norm": 5.138339042663574,
      "learning_rate": 4.724776303609997e-05,
      "loss": 0.0141,
      "step": 8920
    },
    {
      "epoch": 2.7553224313483495,
      "grad_norm": 2.456338882446289,
      "learning_rate": 4.7244677568651655e-05,
      "loss": 0.0198,
      "step": 8930
    },
    {
      "epoch": 2.758407898796668,
      "grad_norm": 1.9971728324890137,
      "learning_rate": 4.724159210120334e-05,
      "loss": 0.0163,
      "step": 8940
    },
    {
      "epoch": 2.761493366244986,
      "grad_norm": 0.4982670545578003,
      "learning_rate": 4.723850663375501e-05,
      "loss": 0.0386,
      "step": 8950
    },
    {
      "epoch": 2.7645788336933044,
      "grad_norm": 0.7244619131088257,
      "learning_rate": 4.7235421166306695e-05,
      "loss": 0.0121,
      "step": 8960
    },
    {
      "epoch": 2.767664301141623,
      "grad_norm": 4.095398426055908,
      "learning_rate": 4.7232335698858385e-05,
      "loss": 0.0392,
      "step": 8970
    },
    {
      "epoch": 2.7707497685899414,
      "grad_norm": 3.52532958984375,
      "learning_rate": 4.722925023141006e-05,
      "loss": 0.0281,
      "step": 8980
    },
    {
      "epoch": 2.7738352360382597,
      "grad_norm": 8.470723152160645,
      "learning_rate": 4.722616476396174e-05,
      "loss": 0.0319,
      "step": 8990
    },
    {
      "epoch": 2.7769207034865784,
      "grad_norm": 3.2482869625091553,
      "learning_rate": 4.7223079296513425e-05,
      "loss": 0.0267,
      "step": 9000
    },
    {
      "epoch": 2.7800061709348967,
      "grad_norm": 2.1473968029022217,
      "learning_rate": 4.721999382906511e-05,
      "loss": 0.0194,
      "step": 9010
    },
    {
      "epoch": 2.783091638383215,
      "grad_norm": 0.23866663873195648,
      "learning_rate": 4.7216908361616783e-05,
      "loss": 0.0286,
      "step": 9020
    },
    {
      "epoch": 2.786177105831533,
      "grad_norm": 1.2463945150375366,
      "learning_rate": 4.7213822894168466e-05,
      "loss": 0.0238,
      "step": 9030
    },
    {
      "epoch": 2.789262573279852,
      "grad_norm": 1.583561658859253,
      "learning_rate": 4.7210737426720155e-05,
      "loss": 0.012,
      "step": 9040
    },
    {
      "epoch": 2.79234804072817,
      "grad_norm": 0.3606446385383606,
      "learning_rate": 4.720765195927183e-05,
      "loss": 0.0283,
      "step": 9050
    },
    {
      "epoch": 2.7954335081764885,
      "grad_norm": 2.3037869930267334,
      "learning_rate": 4.7204566491823513e-05,
      "loss": 0.0265,
      "step": 9060
    },
    {
      "epoch": 2.7985189756248072,
      "grad_norm": 0.9638343453407288,
      "learning_rate": 4.7201481024375196e-05,
      "loss": 0.03,
      "step": 9070
    },
    {
      "epoch": 2.8016044430731255,
      "grad_norm": 1.3996540307998657,
      "learning_rate": 4.719839555692688e-05,
      "loss": 0.0325,
      "step": 9080
    },
    {
      "epoch": 2.804689910521444,
      "grad_norm": 0.6328832507133484,
      "learning_rate": 4.7195310089478554e-05,
      "loss": 0.0307,
      "step": 9090
    },
    {
      "epoch": 2.8077753779697625,
      "grad_norm": 5.22744607925415,
      "learning_rate": 4.719222462203024e-05,
      "loss": 0.0284,
      "step": 9100
    },
    {
      "epoch": 2.810860845418081,
      "grad_norm": 1.2030888795852661,
      "learning_rate": 4.7189139154581926e-05,
      "loss": 0.0233,
      "step": 9110
    },
    {
      "epoch": 2.813946312866399,
      "grad_norm": 3.539918899536133,
      "learning_rate": 4.71860536871336e-05,
      "loss": 0.0391,
      "step": 9120
    },
    {
      "epoch": 2.817031780314718,
      "grad_norm": 2.8826706409454346,
      "learning_rate": 4.7182968219685284e-05,
      "loss": 0.027,
      "step": 9130
    },
    {
      "epoch": 2.820117247763036,
      "grad_norm": 1.943490982055664,
      "learning_rate": 4.7179882752236966e-05,
      "loss": 0.0287,
      "step": 9140
    },
    {
      "epoch": 2.8232027152113544,
      "grad_norm": 0.7313085794448853,
      "learning_rate": 4.717679728478865e-05,
      "loss": 0.0136,
      "step": 9150
    },
    {
      "epoch": 2.826288182659673,
      "grad_norm": 2.7603540420532227,
      "learning_rate": 4.7173711817340325e-05,
      "loss": 0.0297,
      "step": 9160
    },
    {
      "epoch": 2.8293736501079914,
      "grad_norm": 0.78846275806427,
      "learning_rate": 4.7170626349892014e-05,
      "loss": 0.0306,
      "step": 9170
    },
    {
      "epoch": 2.8324591175563096,
      "grad_norm": 1.4620318412780762,
      "learning_rate": 4.7167540882443696e-05,
      "loss": 0.0357,
      "step": 9180
    },
    {
      "epoch": 2.8355445850046284,
      "grad_norm": 1.7554619312286377,
      "learning_rate": 4.716445541499537e-05,
      "loss": 0.0151,
      "step": 9190
    },
    {
      "epoch": 2.8386300524529466,
      "grad_norm": 2.342902183532715,
      "learning_rate": 4.7161369947547055e-05,
      "loss": 0.0214,
      "step": 9200
    },
    {
      "epoch": 2.841715519901265,
      "grad_norm": 4.701825141906738,
      "learning_rate": 4.715828448009874e-05,
      "loss": 0.0192,
      "step": 9210
    },
    {
      "epoch": 2.8448009873495836,
      "grad_norm": 2.2794268131256104,
      "learning_rate": 4.715519901265042e-05,
      "loss": 0.0362,
      "step": 9220
    },
    {
      "epoch": 2.847886454797902,
      "grad_norm": 1.2640140056610107,
      "learning_rate": 4.7152113545202095e-05,
      "loss": 0.0193,
      "step": 9230
    },
    {
      "epoch": 2.85097192224622,
      "grad_norm": 1.3004584312438965,
      "learning_rate": 4.7149028077753784e-05,
      "loss": 0.0344,
      "step": 9240
    },
    {
      "epoch": 2.854057389694539,
      "grad_norm": 1.1366807222366333,
      "learning_rate": 4.714594261030547e-05,
      "loss": 0.0358,
      "step": 9250
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 1.5495542287826538,
      "learning_rate": 4.714285714285714e-05,
      "loss": 0.0219,
      "step": 9260
    },
    {
      "epoch": 2.8602283245911755,
      "grad_norm": 1.99170982837677,
      "learning_rate": 4.7139771675408825e-05,
      "loss": 0.0381,
      "step": 9270
    },
    {
      "epoch": 2.863313792039494,
      "grad_norm": 2.8682374954223633,
      "learning_rate": 4.713668620796051e-05,
      "loss": 0.0253,
      "step": 9280
    },
    {
      "epoch": 2.8663992594878125,
      "grad_norm": 2.7489569187164307,
      "learning_rate": 4.713360074051219e-05,
      "loss": 0.0319,
      "step": 9290
    },
    {
      "epoch": 2.8694847269361308,
      "grad_norm": 0.5038652420043945,
      "learning_rate": 4.7130515273063866e-05,
      "loss": 0.0315,
      "step": 9300
    },
    {
      "epoch": 2.8725701943844495,
      "grad_norm": 2.8736326694488525,
      "learning_rate": 4.7127429805615555e-05,
      "loss": 0.0253,
      "step": 9310
    },
    {
      "epoch": 2.8756556618327678,
      "grad_norm": 1.5720841884613037,
      "learning_rate": 4.712434433816724e-05,
      "loss": 0.0336,
      "step": 9320
    },
    {
      "epoch": 2.878741129281086,
      "grad_norm": 4.417728900909424,
      "learning_rate": 4.712125887071891e-05,
      "loss": 0.0279,
      "step": 9330
    },
    {
      "epoch": 2.8818265967294048,
      "grad_norm": 4.402674674987793,
      "learning_rate": 4.71181734032706e-05,
      "loss": 0.0381,
      "step": 9340
    },
    {
      "epoch": 2.884912064177723,
      "grad_norm": 2.0362093448638916,
      "learning_rate": 4.711508793582228e-05,
      "loss": 0.0205,
      "step": 9350
    },
    {
      "epoch": 2.8879975316260413,
      "grad_norm": 1.6456263065338135,
      "learning_rate": 4.711200246837396e-05,
      "loss": 0.0127,
      "step": 9360
    },
    {
      "epoch": 2.8910829990743596,
      "grad_norm": 0.9643340110778809,
      "learning_rate": 4.710891700092564e-05,
      "loss": 0.0285,
      "step": 9370
    },
    {
      "epoch": 2.8941684665226783,
      "grad_norm": 0.8578532934188843,
      "learning_rate": 4.7105831533477326e-05,
      "loss": 0.0092,
      "step": 9380
    },
    {
      "epoch": 2.8972539339709966,
      "grad_norm": 2.896810531616211,
      "learning_rate": 4.710274606602901e-05,
      "loss": 0.0362,
      "step": 9390
    },
    {
      "epoch": 2.900339401419315,
      "grad_norm": 1.5208158493041992,
      "learning_rate": 4.7099660598580684e-05,
      "loss": 0.024,
      "step": 9400
    },
    {
      "epoch": 2.903424868867633,
      "grad_norm": 1.2738536596298218,
      "learning_rate": 4.709657513113237e-05,
      "loss": 0.0409,
      "step": 9410
    },
    {
      "epoch": 2.906510336315952,
      "grad_norm": 1.5429438352584839,
      "learning_rate": 4.709348966368405e-05,
      "loss": 0.0347,
      "step": 9420
    },
    {
      "epoch": 2.90959580376427,
      "grad_norm": 1.3235758543014526,
      "learning_rate": 4.709040419623573e-05,
      "loss": 0.0298,
      "step": 9430
    },
    {
      "epoch": 2.9126812712125885,
      "grad_norm": 0.7786209583282471,
      "learning_rate": 4.7087318728787414e-05,
      "loss": 0.0217,
      "step": 9440
    },
    {
      "epoch": 2.915766738660907,
      "grad_norm": 0.3827936053276062,
      "learning_rate": 4.7084233261339096e-05,
      "loss": 0.0205,
      "step": 9450
    },
    {
      "epoch": 2.9188522061092255,
      "grad_norm": 0.9913727045059204,
      "learning_rate": 4.708114779389078e-05,
      "loss": 0.0138,
      "step": 9460
    },
    {
      "epoch": 2.9219376735575437,
      "grad_norm": 2.174999237060547,
      "learning_rate": 4.7078062326442454e-05,
      "loss": 0.0374,
      "step": 9470
    },
    {
      "epoch": 2.9250231410058625,
      "grad_norm": 1.0660285949707031,
      "learning_rate": 4.7074976858994144e-05,
      "loss": 0.0201,
      "step": 9480
    },
    {
      "epoch": 2.9281086084541808,
      "grad_norm": 1.066846251487732,
      "learning_rate": 4.707189139154582e-05,
      "loss": 0.0286,
      "step": 9490
    },
    {
      "epoch": 2.931194075902499,
      "grad_norm": 3.511831521987915,
      "learning_rate": 4.70688059240975e-05,
      "loss": 0.0338,
      "step": 9500
    },
    {
      "epoch": 2.9342795433508178,
      "grad_norm": 2.5798537731170654,
      "learning_rate": 4.7065720456649184e-05,
      "loss": 0.0234,
      "step": 9510
    },
    {
      "epoch": 2.937365010799136,
      "grad_norm": 0.5576172471046448,
      "learning_rate": 4.706263498920087e-05,
      "loss": 0.0396,
      "step": 9520
    },
    {
      "epoch": 2.9404504782474543,
      "grad_norm": 0.15131814777851105,
      "learning_rate": 4.705954952175255e-05,
      "loss": 0.0354,
      "step": 9530
    },
    {
      "epoch": 2.943535945695773,
      "grad_norm": 0.19961540400981903,
      "learning_rate": 4.7056464054304225e-05,
      "loss": 0.0119,
      "step": 9540
    },
    {
      "epoch": 2.9466214131440913,
      "grad_norm": 2.1737215518951416,
      "learning_rate": 4.7053378586855914e-05,
      "loss": 0.0232,
      "step": 9550
    },
    {
      "epoch": 2.9497068805924096,
      "grad_norm": 1.3063338994979858,
      "learning_rate": 4.705029311940759e-05,
      "loss": 0.0167,
      "step": 9560
    },
    {
      "epoch": 2.9527923480407283,
      "grad_norm": 2.002000093460083,
      "learning_rate": 4.704720765195927e-05,
      "loss": 0.0239,
      "step": 9570
    },
    {
      "epoch": 2.9558778154890466,
      "grad_norm": 0.08274871110916138,
      "learning_rate": 4.7044122184510955e-05,
      "loss": 0.0238,
      "step": 9580
    },
    {
      "epoch": 2.958963282937365,
      "grad_norm": 3.924395799636841,
      "learning_rate": 4.704103671706264e-05,
      "loss": 0.0159,
      "step": 9590
    },
    {
      "epoch": 2.9620487503856836,
      "grad_norm": 3.0777463912963867,
      "learning_rate": 4.703795124961432e-05,
      "loss": 0.0276,
      "step": 9600
    },
    {
      "epoch": 2.965134217834002,
      "grad_norm": 2.623166084289551,
      "learning_rate": 4.7034865782166e-05,
      "loss": 0.0321,
      "step": 9610
    },
    {
      "epoch": 2.96821968528232,
      "grad_norm": 2.2027218341827393,
      "learning_rate": 4.7031780314717685e-05,
      "loss": 0.0195,
      "step": 9620
    },
    {
      "epoch": 2.971305152730639,
      "grad_norm": 4.6383957862854,
      "learning_rate": 4.702869484726936e-05,
      "loss": 0.0337,
      "step": 9630
    },
    {
      "epoch": 2.974390620178957,
      "grad_norm": 1.8391629457473755,
      "learning_rate": 4.702560937982104e-05,
      "loss": 0.0149,
      "step": 9640
    },
    {
      "epoch": 2.9774760876272754,
      "grad_norm": 1.5731112957000732,
      "learning_rate": 4.702252391237273e-05,
      "loss": 0.0132,
      "step": 9650
    },
    {
      "epoch": 2.980561555075594,
      "grad_norm": 1.642905592918396,
      "learning_rate": 4.701943844492441e-05,
      "loss": 0.0115,
      "step": 9660
    },
    {
      "epoch": 2.9836470225239125,
      "grad_norm": 1.2868491411209106,
      "learning_rate": 4.701635297747609e-05,
      "loss": 0.0217,
      "step": 9670
    },
    {
      "epoch": 2.9867324899722307,
      "grad_norm": 0.3508487343788147,
      "learning_rate": 4.701326751002777e-05,
      "loss": 0.0195,
      "step": 9680
    },
    {
      "epoch": 2.9898179574205495,
      "grad_norm": 0.9552680253982544,
      "learning_rate": 4.7010182042579455e-05,
      "loss": 0.0354,
      "step": 9690
    },
    {
      "epoch": 2.9929034248688677,
      "grad_norm": 2.873387098312378,
      "learning_rate": 4.700709657513113e-05,
      "loss": 0.0548,
      "step": 9700
    },
    {
      "epoch": 2.995988892317186,
      "grad_norm": 2.1607730388641357,
      "learning_rate": 4.7004011107682813e-05,
      "loss": 0.0209,
      "step": 9710
    },
    {
      "epoch": 2.9990743597655047,
      "grad_norm": 2.8067150115966797,
      "learning_rate": 4.70009256402345e-05,
      "loss": 0.0331,
      "step": 9720
    },
    {
      "epoch": 3.0,
      "eval_accuracy_branch1": 0.9873171108089079,
      "eval_accuracy_branch2": 0.44410366212397406,
      "eval_f1_branch1": 0.9862793245738469,
      "eval_f1_branch2": 0.4432012851513738,
      "eval_loss": 0.010182630270719528,
      "eval_precision_branch1": 0.9863109653827172,
      "eval_precision_branch2": 0.5157811683442078,
      "eval_recall_branch1": 0.9863109518574379,
      "eval_recall_branch2": 0.5147131159399323,
      "eval_runtime": 235.6732,
      "eval_samples_per_second": 439.944,
      "eval_steps_per_second": 54.996,
      "step": 9723
    },
    {
      "epoch": 3.002159827213823,
      "grad_norm": 0.2898816168308258,
      "learning_rate": 4.699784017278618e-05,
      "loss": 0.0219,
      "step": 9730
    },
    {
      "epoch": 3.0052452946621413,
      "grad_norm": 0.2240496277809143,
      "learning_rate": 4.699475470533786e-05,
      "loss": 0.0189,
      "step": 9740
    },
    {
      "epoch": 3.0083307621104596,
      "grad_norm": 4.4799418449401855,
      "learning_rate": 4.699166923788954e-05,
      "loss": 0.022,
      "step": 9750
    },
    {
      "epoch": 3.0114162295587783,
      "grad_norm": 0.16378365457057953,
      "learning_rate": 4.6988583770441226e-05,
      "loss": 0.0235,
      "step": 9760
    },
    {
      "epoch": 3.0145016970070966,
      "grad_norm": 0.05346018821001053,
      "learning_rate": 4.69854983029929e-05,
      "loss": 0.0248,
      "step": 9770
    },
    {
      "epoch": 3.017587164455415,
      "grad_norm": 0.019899247214198112,
      "learning_rate": 4.6982412835544584e-05,
      "loss": 0.013,
      "step": 9780
    },
    {
      "epoch": 3.0206726319037336,
      "grad_norm": 1.8597179651260376,
      "learning_rate": 4.697932736809627e-05,
      "loss": 0.0323,
      "step": 9790
    },
    {
      "epoch": 3.023758099352052,
      "grad_norm": 0.3673851191997528,
      "learning_rate": 4.697624190064795e-05,
      "loss": 0.0238,
      "step": 9800
    },
    {
      "epoch": 3.02684356680037,
      "grad_norm": 0.2811773419380188,
      "learning_rate": 4.697315643319963e-05,
      "loss": 0.0224,
      "step": 9810
    },
    {
      "epoch": 3.029929034248689,
      "grad_norm": 0.4453994333744049,
      "learning_rate": 4.6970070965751314e-05,
      "loss": 0.0117,
      "step": 9820
    },
    {
      "epoch": 3.033014501697007,
      "grad_norm": 3.356118679046631,
      "learning_rate": 4.6966985498302996e-05,
      "loss": 0.0178,
      "step": 9830
    },
    {
      "epoch": 3.0360999691453254,
      "grad_norm": 1.1083375215530396,
      "learning_rate": 4.696390003085468e-05,
      "loss": 0.0267,
      "step": 9840
    },
    {
      "epoch": 3.039185436593644,
      "grad_norm": 1.654136300086975,
      "learning_rate": 4.6960814563406355e-05,
      "loss": 0.0233,
      "step": 9850
    },
    {
      "epoch": 3.0422709040419624,
      "grad_norm": 0.5826218724250793,
      "learning_rate": 4.6957729095958044e-05,
      "loss": 0.0121,
      "step": 9860
    },
    {
      "epoch": 3.0453563714902807,
      "grad_norm": 1.2503294944763184,
      "learning_rate": 4.695464362850972e-05,
      "loss": 0.0163,
      "step": 9870
    },
    {
      "epoch": 3.048441838938599,
      "grad_norm": 5.3022613525390625,
      "learning_rate": 4.69515581610614e-05,
      "loss": 0.0313,
      "step": 9880
    },
    {
      "epoch": 3.0515273063869177,
      "grad_norm": 1.3785552978515625,
      "learning_rate": 4.6948472693613084e-05,
      "loss": 0.0191,
      "step": 9890
    },
    {
      "epoch": 3.054612773835236,
      "grad_norm": 1.4909160137176514,
      "learning_rate": 4.694538722616477e-05,
      "loss": 0.0304,
      "step": 9900
    },
    {
      "epoch": 3.0576982412835543,
      "grad_norm": 2.293591022491455,
      "learning_rate": 4.694230175871645e-05,
      "loss": 0.0213,
      "step": 9910
    },
    {
      "epoch": 3.060783708731873,
      "grad_norm": 2.6541340351104736,
      "learning_rate": 4.693921629126813e-05,
      "loss": 0.0239,
      "step": 9920
    },
    {
      "epoch": 3.0638691761801913,
      "grad_norm": 0.5691254138946533,
      "learning_rate": 4.6936130823819814e-05,
      "loss": 0.022,
      "step": 9930
    },
    {
      "epoch": 3.0669546436285096,
      "grad_norm": 0.6385452747344971,
      "learning_rate": 4.693304535637149e-05,
      "loss": 0.0192,
      "step": 9940
    },
    {
      "epoch": 3.0700401110768283,
      "grad_norm": 0.4266578257083893,
      "learning_rate": 4.692995988892317e-05,
      "loss": 0.0178,
      "step": 9950
    },
    {
      "epoch": 3.0731255785251466,
      "grad_norm": 1.5541101694107056,
      "learning_rate": 4.6926874421474855e-05,
      "loss": 0.0127,
      "step": 9960
    },
    {
      "epoch": 3.076211045973465,
      "grad_norm": 1.445854663848877,
      "learning_rate": 4.692378895402654e-05,
      "loss": 0.026,
      "step": 9970
    },
    {
      "epoch": 3.0792965134217836,
      "grad_norm": 4.749696254730225,
      "learning_rate": 4.692070348657822e-05,
      "loss": 0.0229,
      "step": 9980
    },
    {
      "epoch": 3.082381980870102,
      "grad_norm": 2.936647891998291,
      "learning_rate": 4.69176180191299e-05,
      "loss": 0.0147,
      "step": 9990
    },
    {
      "epoch": 3.08546744831842,
      "grad_norm": 0.2339506894350052,
      "learning_rate": 4.6914532551681585e-05,
      "loss": 0.0156,
      "step": 10000
    },
    {
      "epoch": 3.088552915766739,
      "grad_norm": 0.5497573614120483,
      "learning_rate": 4.691144708423326e-05,
      "loss": 0.0193,
      "step": 10010
    },
    {
      "epoch": 3.091638383215057,
      "grad_norm": 0.9833458065986633,
      "learning_rate": 4.690836161678494e-05,
      "loss": 0.0129,
      "step": 10020
    },
    {
      "epoch": 3.0947238506633754,
      "grad_norm": 0.7057141661643982,
      "learning_rate": 4.6905276149336626e-05,
      "loss": 0.0084,
      "step": 10030
    },
    {
      "epoch": 3.097809318111694,
      "grad_norm": 0.9797516465187073,
      "learning_rate": 4.690219068188831e-05,
      "loss": 0.0215,
      "step": 10040
    },
    {
      "epoch": 3.1008947855600124,
      "grad_norm": 0.09137165546417236,
      "learning_rate": 4.689910521443999e-05,
      "loss": 0.017,
      "step": 10050
    },
    {
      "epoch": 3.1039802530083307,
      "grad_norm": 2.729607582092285,
      "learning_rate": 4.689601974699167e-05,
      "loss": 0.0173,
      "step": 10060
    },
    {
      "epoch": 3.107065720456649,
      "grad_norm": 0.2831135094165802,
      "learning_rate": 4.6892934279543355e-05,
      "loss": 0.0126,
      "step": 10070
    },
    {
      "epoch": 3.1101511879049677,
      "grad_norm": 1.8033860921859741,
      "learning_rate": 4.688984881209503e-05,
      "loss": 0.0431,
      "step": 10080
    },
    {
      "epoch": 3.113236655353286,
      "grad_norm": 0.7115163207054138,
      "learning_rate": 4.6886763344646714e-05,
      "loss": 0.005,
      "step": 10090
    },
    {
      "epoch": 3.1163221228016043,
      "grad_norm": 1.0723150968551636,
      "learning_rate": 4.6883677877198396e-05,
      "loss": 0.0189,
      "step": 10100
    },
    {
      "epoch": 3.119407590249923,
      "grad_norm": 0.016719382256269455,
      "learning_rate": 4.688059240975008e-05,
      "loss": 0.0028,
      "step": 10110
    },
    {
      "epoch": 3.1224930576982413,
      "grad_norm": 0.4838813543319702,
      "learning_rate": 4.687750694230176e-05,
      "loss": 0.0177,
      "step": 10120
    },
    {
      "epoch": 3.1255785251465595,
      "grad_norm": 0.1343994289636612,
      "learning_rate": 4.6874421474853444e-05,
      "loss": 0.0182,
      "step": 10130
    },
    {
      "epoch": 3.1286639925948783,
      "grad_norm": 1.950774073600769,
      "learning_rate": 4.6871336007405126e-05,
      "loss": 0.0285,
      "step": 10140
    },
    {
      "epoch": 3.1317494600431965,
      "grad_norm": 0.1244848221540451,
      "learning_rate": 4.68682505399568e-05,
      "loss": 0.0203,
      "step": 10150
    },
    {
      "epoch": 3.134834927491515,
      "grad_norm": 0.35997140407562256,
      "learning_rate": 4.686516507250849e-05,
      "loss": 0.0131,
      "step": 10160
    },
    {
      "epoch": 3.1379203949398335,
      "grad_norm": 0.8233411908149719,
      "learning_rate": 4.686207960506017e-05,
      "loss": 0.0195,
      "step": 10170
    },
    {
      "epoch": 3.141005862388152,
      "grad_norm": 4.1209235191345215,
      "learning_rate": 4.685899413761185e-05,
      "loss": 0.0224,
      "step": 10180
    },
    {
      "epoch": 3.14409132983647,
      "grad_norm": 2.040964365005493,
      "learning_rate": 4.685590867016353e-05,
      "loss": 0.0197,
      "step": 10190
    },
    {
      "epoch": 3.147176797284789,
      "grad_norm": 2.2173945903778076,
      "learning_rate": 4.6852823202715214e-05,
      "loss": 0.0309,
      "step": 10200
    },
    {
      "epoch": 3.150262264733107,
      "grad_norm": 4.085736274719238,
      "learning_rate": 4.6849737735266897e-05,
      "loss": 0.0204,
      "step": 10210
    },
    {
      "epoch": 3.1533477321814254,
      "grad_norm": 0.03891703486442566,
      "learning_rate": 4.684665226781857e-05,
      "loss": 0.0265,
      "step": 10220
    },
    {
      "epoch": 3.156433199629744,
      "grad_norm": 0.10283015668392181,
      "learning_rate": 4.684356680037026e-05,
      "loss": 0.0168,
      "step": 10230
    },
    {
      "epoch": 3.1595186670780624,
      "grad_norm": 1.5002933740615845,
      "learning_rate": 4.684048133292194e-05,
      "loss": 0.0159,
      "step": 10240
    },
    {
      "epoch": 3.1626041345263807,
      "grad_norm": 0.13125692307949066,
      "learning_rate": 4.683739586547362e-05,
      "loss": 0.0132,
      "step": 10250
    },
    {
      "epoch": 3.165689601974699,
      "grad_norm": 1.2696573734283447,
      "learning_rate": 4.68343103980253e-05,
      "loss": 0.0228,
      "step": 10260
    },
    {
      "epoch": 3.1687750694230177,
      "grad_norm": 0.5620637536048889,
      "learning_rate": 4.6831224930576985e-05,
      "loss": 0.0161,
      "step": 10270
    },
    {
      "epoch": 3.171860536871336,
      "grad_norm": 0.23364759981632233,
      "learning_rate": 4.682813946312867e-05,
      "loss": 0.0116,
      "step": 10280
    },
    {
      "epoch": 3.1749460043196542,
      "grad_norm": 0.3905796706676483,
      "learning_rate": 4.682505399568034e-05,
      "loss": 0.0195,
      "step": 10290
    },
    {
      "epoch": 3.178031471767973,
      "grad_norm": 1.8813639879226685,
      "learning_rate": 4.682196852823203e-05,
      "loss": 0.0211,
      "step": 10300
    },
    {
      "epoch": 3.1811169392162912,
      "grad_norm": 0.09324078261852264,
      "learning_rate": 4.6818883060783715e-05,
      "loss": 0.0213,
      "step": 10310
    },
    {
      "epoch": 3.1842024066646095,
      "grad_norm": 5.128471374511719,
      "learning_rate": 4.681579759333539e-05,
      "loss": 0.0348,
      "step": 10320
    },
    {
      "epoch": 3.1872878741129282,
      "grad_norm": 1.3698090314865112,
      "learning_rate": 4.681271212588707e-05,
      "loss": 0.0128,
      "step": 10330
    },
    {
      "epoch": 3.1903733415612465,
      "grad_norm": 0.6492913365364075,
      "learning_rate": 4.6809626658438755e-05,
      "loss": 0.0298,
      "step": 10340
    },
    {
      "epoch": 3.193458809009565,
      "grad_norm": 1.8385807275772095,
      "learning_rate": 4.680654119099044e-05,
      "loss": 0.0277,
      "step": 10350
    },
    {
      "epoch": 3.1965442764578835,
      "grad_norm": 0.25267165899276733,
      "learning_rate": 4.6803455723542113e-05,
      "loss": 0.0212,
      "step": 10360
    },
    {
      "epoch": 3.199629743906202,
      "grad_norm": 0.2146638184785843,
      "learning_rate": 4.68003702560938e-05,
      "loss": 0.0195,
      "step": 10370
    },
    {
      "epoch": 3.20271521135452,
      "grad_norm": 0.2808595895767212,
      "learning_rate": 4.6797284788645485e-05,
      "loss": 0.0127,
      "step": 10380
    },
    {
      "epoch": 3.205800678802839,
      "grad_norm": 1.272281527519226,
      "learning_rate": 4.679419932119716e-05,
      "loss": 0.0181,
      "step": 10390
    },
    {
      "epoch": 3.208886146251157,
      "grad_norm": 0.6248729825019836,
      "learning_rate": 4.679111385374885e-05,
      "loss": 0.0297,
      "step": 10400
    },
    {
      "epoch": 3.2119716136994754,
      "grad_norm": 3.172381639480591,
      "learning_rate": 4.6788028386300526e-05,
      "loss": 0.0208,
      "step": 10410
    },
    {
      "epoch": 3.215057081147794,
      "grad_norm": 1.6445634365081787,
      "learning_rate": 4.678494291885221e-05,
      "loss": 0.0125,
      "step": 10420
    },
    {
      "epoch": 3.2181425485961124,
      "grad_norm": 0.3838621973991394,
      "learning_rate": 4.678185745140389e-05,
      "loss": 0.0206,
      "step": 10430
    },
    {
      "epoch": 3.2212280160444307,
      "grad_norm": 0.5130524039268494,
      "learning_rate": 4.677877198395557e-05,
      "loss": 0.0129,
      "step": 10440
    },
    {
      "epoch": 3.2243134834927494,
      "grad_norm": 2.957608699798584,
      "learning_rate": 4.6775686516507256e-05,
      "loss": 0.0342,
      "step": 10450
    },
    {
      "epoch": 3.2273989509410677,
      "grad_norm": 1.0879982709884644,
      "learning_rate": 4.677260104905893e-05,
      "loss": 0.0327,
      "step": 10460
    },
    {
      "epoch": 3.230484418389386,
      "grad_norm": 3.8048481941223145,
      "learning_rate": 4.676951558161062e-05,
      "loss": 0.018,
      "step": 10470
    },
    {
      "epoch": 3.233569885837704,
      "grad_norm": 0.3459453880786896,
      "learning_rate": 4.6766430114162296e-05,
      "loss": 0.0219,
      "step": 10480
    },
    {
      "epoch": 3.236655353286023,
      "grad_norm": 2.4569473266601562,
      "learning_rate": 4.676334464671398e-05,
      "loss": 0.0251,
      "step": 10490
    },
    {
      "epoch": 3.239740820734341,
      "grad_norm": 2.3559772968292236,
      "learning_rate": 4.676025917926566e-05,
      "loss": 0.0252,
      "step": 10500
    },
    {
      "epoch": 3.2428262881826595,
      "grad_norm": 4.031168460845947,
      "learning_rate": 4.6757173711817344e-05,
      "loss": 0.021,
      "step": 10510
    },
    {
      "epoch": 3.2459117556309782,
      "grad_norm": 1.1763273477554321,
      "learning_rate": 4.6754088244369026e-05,
      "loss": 0.0194,
      "step": 10520
    },
    {
      "epoch": 3.2489972230792965,
      "grad_norm": 1.1734604835510254,
      "learning_rate": 4.67510027769207e-05,
      "loss": 0.0218,
      "step": 10530
    },
    {
      "epoch": 3.252082690527615,
      "grad_norm": 0.42014771699905396,
      "learning_rate": 4.674791730947239e-05,
      "loss": 0.0223,
      "step": 10540
    },
    {
      "epoch": 3.2551681579759335,
      "grad_norm": 0.5342223644256592,
      "learning_rate": 4.674483184202407e-05,
      "loss": 0.0142,
      "step": 10550
    },
    {
      "epoch": 3.258253625424252,
      "grad_norm": 1.6747307777404785,
      "learning_rate": 4.674174637457575e-05,
      "loss": 0.0217,
      "step": 10560
    },
    {
      "epoch": 3.26133909287257,
      "grad_norm": 1.9654526710510254,
      "learning_rate": 4.673866090712743e-05,
      "loss": 0.0084,
      "step": 10570
    },
    {
      "epoch": 3.264424560320889,
      "grad_norm": 1.21476149559021,
      "learning_rate": 4.6735575439679114e-05,
      "loss": 0.0282,
      "step": 10580
    },
    {
      "epoch": 3.267510027769207,
      "grad_norm": 0.46690019965171814,
      "learning_rate": 4.67324899722308e-05,
      "loss": 0.0102,
      "step": 10590
    },
    {
      "epoch": 3.2705954952175254,
      "grad_norm": 0.6101491451263428,
      "learning_rate": 4.672940450478247e-05,
      "loss": 0.0315,
      "step": 10600
    },
    {
      "epoch": 3.2736809626658436,
      "grad_norm": 4.830318927764893,
      "learning_rate": 4.672631903733416e-05,
      "loss": 0.0239,
      "step": 10610
    },
    {
      "epoch": 3.2767664301141624,
      "grad_norm": 1.7697703838348389,
      "learning_rate": 4.672323356988584e-05,
      "loss": 0.0277,
      "step": 10620
    },
    {
      "epoch": 3.2798518975624806,
      "grad_norm": 3.699795961380005,
      "learning_rate": 4.672014810243752e-05,
      "loss": 0.024,
      "step": 10630
    },
    {
      "epoch": 3.282937365010799,
      "grad_norm": 0.30726099014282227,
      "learning_rate": 4.67170626349892e-05,
      "loss": 0.0089,
      "step": 10640
    },
    {
      "epoch": 3.2860228324591176,
      "grad_norm": 0.4645273983478546,
      "learning_rate": 4.6713977167540885e-05,
      "loss": 0.0508,
      "step": 10650
    },
    {
      "epoch": 3.289108299907436,
      "grad_norm": 1.4909498691558838,
      "learning_rate": 4.671089170009257e-05,
      "loss": 0.0263,
      "step": 10660
    },
    {
      "epoch": 3.292193767355754,
      "grad_norm": 2.1508495807647705,
      "learning_rate": 4.670780623264425e-05,
      "loss": 0.0226,
      "step": 10670
    },
    {
      "epoch": 3.295279234804073,
      "grad_norm": 0.10930383950471878,
      "learning_rate": 4.670472076519593e-05,
      "loss": 0.0101,
      "step": 10680
    },
    {
      "epoch": 3.298364702252391,
      "grad_norm": 0.29189056158065796,
      "learning_rate": 4.670163529774761e-05,
      "loss": 0.025,
      "step": 10690
    },
    {
      "epoch": 3.3014501697007095,
      "grad_norm": 2.6592049598693848,
      "learning_rate": 4.669854983029929e-05,
      "loss": 0.0287,
      "step": 10700
    },
    {
      "epoch": 3.304535637149028,
      "grad_norm": 0.05250220373272896,
      "learning_rate": 4.669546436285098e-05,
      "loss": 0.0177,
      "step": 10710
    },
    {
      "epoch": 3.3076211045973465,
      "grad_norm": 3.9899790287017822,
      "learning_rate": 4.6692378895402655e-05,
      "loss": 0.0286,
      "step": 10720
    },
    {
      "epoch": 3.3107065720456648,
      "grad_norm": 0.4995623826980591,
      "learning_rate": 4.668929342795434e-05,
      "loss": 0.0182,
      "step": 10730
    },
    {
      "epoch": 3.3137920394939835,
      "grad_norm": 0.5972905158996582,
      "learning_rate": 4.668620796050602e-05,
      "loss": 0.0332,
      "step": 10740
    },
    {
      "epoch": 3.3168775069423018,
      "grad_norm": 4.31416654586792,
      "learning_rate": 4.66831224930577e-05,
      "loss": 0.0123,
      "step": 10750
    },
    {
      "epoch": 3.31996297439062,
      "grad_norm": 1.3451787233352661,
      "learning_rate": 4.668003702560938e-05,
      "loss": 0.0105,
      "step": 10760
    },
    {
      "epoch": 3.3230484418389388,
      "grad_norm": 2.240250587463379,
      "learning_rate": 4.667695155816106e-05,
      "loss": 0.0091,
      "step": 10770
    },
    {
      "epoch": 3.326133909287257,
      "grad_norm": 0.018331458792090416,
      "learning_rate": 4.667386609071275e-05,
      "loss": 0.0206,
      "step": 10780
    },
    {
      "epoch": 3.3292193767355753,
      "grad_norm": 0.4547940790653229,
      "learning_rate": 4.6670780623264426e-05,
      "loss": 0.0181,
      "step": 10790
    },
    {
      "epoch": 3.332304844183894,
      "grad_norm": 1.2145633697509766,
      "learning_rate": 4.666769515581611e-05,
      "loss": 0.0098,
      "step": 10800
    },
    {
      "epoch": 3.3353903116322123,
      "grad_norm": 0.691753089427948,
      "learning_rate": 4.666460968836779e-05,
      "loss": 0.0144,
      "step": 10810
    },
    {
      "epoch": 3.3384757790805306,
      "grad_norm": 1.816736102104187,
      "learning_rate": 4.6661524220919473e-05,
      "loss": 0.0083,
      "step": 10820
    },
    {
      "epoch": 3.3415612465288493,
      "grad_norm": 5.127889633178711,
      "learning_rate": 4.665843875347115e-05,
      "loss": 0.0125,
      "step": 10830
    },
    {
      "epoch": 3.3446467139771676,
      "grad_norm": 1.5012696981430054,
      "learning_rate": 4.665535328602283e-05,
      "loss": 0.0107,
      "step": 10840
    },
    {
      "epoch": 3.347732181425486,
      "grad_norm": 0.04580581188201904,
      "learning_rate": 4.665226781857452e-05,
      "loss": 0.0266,
      "step": 10850
    },
    {
      "epoch": 3.3508176488738046,
      "grad_norm": 1.979263424873352,
      "learning_rate": 4.66491823511262e-05,
      "loss": 0.0227,
      "step": 10860
    },
    {
      "epoch": 3.353903116322123,
      "grad_norm": 0.15047049522399902,
      "learning_rate": 4.664609688367788e-05,
      "loss": 0.0132,
      "step": 10870
    },
    {
      "epoch": 3.356988583770441,
      "grad_norm": 2.1027581691741943,
      "learning_rate": 4.664301141622956e-05,
      "loss": 0.0273,
      "step": 10880
    },
    {
      "epoch": 3.3600740512187595,
      "grad_norm": 0.13188350200653076,
      "learning_rate": 4.6639925948781244e-05,
      "loss": 0.027,
      "step": 10890
    },
    {
      "epoch": 3.363159518667078,
      "grad_norm": 0.1622598022222519,
      "learning_rate": 4.663684048133292e-05,
      "loss": 0.0092,
      "step": 10900
    },
    {
      "epoch": 3.3662449861153965,
      "grad_norm": 2.7321925163269043,
      "learning_rate": 4.663375501388461e-05,
      "loss": 0.0175,
      "step": 10910
    },
    {
      "epoch": 3.3693304535637147,
      "grad_norm": 0.7893818616867065,
      "learning_rate": 4.663066954643629e-05,
      "loss": 0.0109,
      "step": 10920
    },
    {
      "epoch": 3.3724159210120335,
      "grad_norm": 0.9700832366943359,
      "learning_rate": 4.662758407898797e-05,
      "loss": 0.0183,
      "step": 10930
    },
    {
      "epoch": 3.3755013884603517,
      "grad_norm": 0.19870148599147797,
      "learning_rate": 4.662449861153965e-05,
      "loss": 0.0146,
      "step": 10940
    },
    {
      "epoch": 3.37858685590867,
      "grad_norm": 1.2416114807128906,
      "learning_rate": 4.662141314409133e-05,
      "loss": 0.0112,
      "step": 10950
    },
    {
      "epoch": 3.3816723233569888,
      "grad_norm": 1.7517279386520386,
      "learning_rate": 4.6618327676643015e-05,
      "loss": 0.0202,
      "step": 10960
    },
    {
      "epoch": 3.384757790805307,
      "grad_norm": 0.8048480153083801,
      "learning_rate": 4.661524220919469e-05,
      "loss": 0.0162,
      "step": 10970
    },
    {
      "epoch": 3.3878432582536253,
      "grad_norm": 0.5122244358062744,
      "learning_rate": 4.661215674174638e-05,
      "loss": 0.0296,
      "step": 10980
    },
    {
      "epoch": 3.390928725701944,
      "grad_norm": 0.23376062512397766,
      "learning_rate": 4.660907127429806e-05,
      "loss": 0.0272,
      "step": 10990
    },
    {
      "epoch": 3.3940141931502623,
      "grad_norm": 0.7962751388549805,
      "learning_rate": 4.660598580684974e-05,
      "loss": 0.0157,
      "step": 11000
    },
    {
      "epoch": 3.3970996605985806,
      "grad_norm": 1.9045196771621704,
      "learning_rate": 4.660290033940142e-05,
      "loss": 0.0188,
      "step": 11010
    },
    {
      "epoch": 3.400185128046899,
      "grad_norm": 0.5358371734619141,
      "learning_rate": 4.65998148719531e-05,
      "loss": 0.0261,
      "step": 11020
    },
    {
      "epoch": 3.4032705954952176,
      "grad_norm": 0.03245224803686142,
      "learning_rate": 4.6596729404504785e-05,
      "loss": 0.0185,
      "step": 11030
    },
    {
      "epoch": 3.406356062943536,
      "grad_norm": 0.5854340195655823,
      "learning_rate": 4.659364393705646e-05,
      "loss": 0.0325,
      "step": 11040
    },
    {
      "epoch": 3.409441530391854,
      "grad_norm": 6.382516860961914,
      "learning_rate": 4.659055846960815e-05,
      "loss": 0.0225,
      "step": 11050
    },
    {
      "epoch": 3.412526997840173,
      "grad_norm": 2.084156036376953,
      "learning_rate": 4.658747300215983e-05,
      "loss": 0.0065,
      "step": 11060
    },
    {
      "epoch": 3.415612465288491,
      "grad_norm": 5.274860382080078,
      "learning_rate": 4.658438753471151e-05,
      "loss": 0.0326,
      "step": 11070
    },
    {
      "epoch": 3.4186979327368094,
      "grad_norm": 0.05484525486826897,
      "learning_rate": 4.658130206726319e-05,
      "loss": 0.009,
      "step": 11080
    },
    {
      "epoch": 3.421783400185128,
      "grad_norm": 1.4137336015701294,
      "learning_rate": 4.657821659981487e-05,
      "loss": 0.0157,
      "step": 11090
    },
    {
      "epoch": 3.4248688676334464,
      "grad_norm": 0.3805008828639984,
      "learning_rate": 4.6575131132366556e-05,
      "loss": 0.0094,
      "step": 11100
    },
    {
      "epoch": 3.4279543350817647,
      "grad_norm": 0.3446905016899109,
      "learning_rate": 4.657204566491823e-05,
      "loss": 0.0037,
      "step": 11110
    },
    {
      "epoch": 3.4310398025300834,
      "grad_norm": 0.339074969291687,
      "learning_rate": 4.656896019746992e-05,
      "loss": 0.012,
      "step": 11120
    },
    {
      "epoch": 3.4341252699784017,
      "grad_norm": 0.08063941448926926,
      "learning_rate": 4.65658747300216e-05,
      "loss": 0.0133,
      "step": 11130
    },
    {
      "epoch": 3.43721073742672,
      "grad_norm": 1.4228986501693726,
      "learning_rate": 4.656278926257328e-05,
      "loss": 0.0388,
      "step": 11140
    },
    {
      "epoch": 3.4402962048750387,
      "grad_norm": 0.5753380656242371,
      "learning_rate": 4.655970379512497e-05,
      "loss": 0.0178,
      "step": 11150
    },
    {
      "epoch": 3.443381672323357,
      "grad_norm": 1.5967140197753906,
      "learning_rate": 4.6556618327676644e-05,
      "loss": 0.0276,
      "step": 11160
    },
    {
      "epoch": 3.4464671397716753,
      "grad_norm": 0.6523293852806091,
      "learning_rate": 4.6553532860228326e-05,
      "loss": 0.0228,
      "step": 11170
    },
    {
      "epoch": 3.449552607219994,
      "grad_norm": 3.1874256134033203,
      "learning_rate": 4.655044739278001e-05,
      "loss": 0.0266,
      "step": 11180
    },
    {
      "epoch": 3.4526380746683123,
      "grad_norm": 0.38897281885147095,
      "learning_rate": 4.654736192533169e-05,
      "loss": 0.0282,
      "step": 11190
    },
    {
      "epoch": 3.4557235421166306,
      "grad_norm": 6.615248680114746,
      "learning_rate": 4.6544276457883374e-05,
      "loss": 0.0447,
      "step": 11200
    },
    {
      "epoch": 3.4588090095649493,
      "grad_norm": 0.7523469924926758,
      "learning_rate": 4.654119099043505e-05,
      "loss": 0.0115,
      "step": 11210
    },
    {
      "epoch": 3.4618944770132676,
      "grad_norm": 0.7735840678215027,
      "learning_rate": 4.653810552298674e-05,
      "loss": 0.0147,
      "step": 11220
    },
    {
      "epoch": 3.464979944461586,
      "grad_norm": 0.45046043395996094,
      "learning_rate": 4.6535020055538414e-05,
      "loss": 0.019,
      "step": 11230
    },
    {
      "epoch": 3.4680654119099046,
      "grad_norm": 0.9314776659011841,
      "learning_rate": 4.65319345880901e-05,
      "loss": 0.0066,
      "step": 11240
    },
    {
      "epoch": 3.471150879358223,
      "grad_norm": 1.4552322626113892,
      "learning_rate": 4.652884912064178e-05,
      "loss": 0.0259,
      "step": 11250
    },
    {
      "epoch": 3.474236346806541,
      "grad_norm": 1.5908514261245728,
      "learning_rate": 4.652576365319346e-05,
      "loss": 0.0162,
      "step": 11260
    },
    {
      "epoch": 3.4773218142548594,
      "grad_norm": 3.3790855407714844,
      "learning_rate": 4.6522678185745144e-05,
      "loss": 0.033,
      "step": 11270
    },
    {
      "epoch": 3.480407281703178,
      "grad_norm": 1.5227514505386353,
      "learning_rate": 4.651959271829682e-05,
      "loss": 0.0332,
      "step": 11280
    },
    {
      "epoch": 3.4834927491514964,
      "grad_norm": 3.2074034214019775,
      "learning_rate": 4.651650725084851e-05,
      "loss": 0.0111,
      "step": 11290
    },
    {
      "epoch": 3.4865782165998147,
      "grad_norm": 2.432767868041992,
      "learning_rate": 4.6513421783400185e-05,
      "loss": 0.0142,
      "step": 11300
    },
    {
      "epoch": 3.4896636840481334,
      "grad_norm": 0.10137725621461868,
      "learning_rate": 4.651033631595187e-05,
      "loss": 0.0277,
      "step": 11310
    },
    {
      "epoch": 3.4927491514964517,
      "grad_norm": 0.23660023510456085,
      "learning_rate": 4.650725084850355e-05,
      "loss": 0.0135,
      "step": 11320
    },
    {
      "epoch": 3.49583461894477,
      "grad_norm": 0.15115788578987122,
      "learning_rate": 4.650416538105523e-05,
      "loss": 0.0169,
      "step": 11330
    },
    {
      "epoch": 3.4989200863930887,
      "grad_norm": 0.6961629390716553,
      "learning_rate": 4.6501079913606915e-05,
      "loss": 0.0112,
      "step": 11340
    },
    {
      "epoch": 3.502005553841407,
      "grad_norm": 0.2240394949913025,
      "learning_rate": 4.649799444615859e-05,
      "loss": 0.0033,
      "step": 11350
    },
    {
      "epoch": 3.5050910212897253,
      "grad_norm": 0.33803606033325195,
      "learning_rate": 4.649490897871028e-05,
      "loss": 0.0113,
      "step": 11360
    },
    {
      "epoch": 3.5081764887380436,
      "grad_norm": 2.3877670764923096,
      "learning_rate": 4.6491823511261956e-05,
      "loss": 0.0169,
      "step": 11370
    },
    {
      "epoch": 3.5112619561863623,
      "grad_norm": 3.3829052448272705,
      "learning_rate": 4.648873804381364e-05,
      "loss": 0.0371,
      "step": 11380
    },
    {
      "epoch": 3.5143474236346806,
      "grad_norm": 3.789524793624878,
      "learning_rate": 4.648565257636533e-05,
      "loss": 0.0336,
      "step": 11390
    },
    {
      "epoch": 3.517432891082999,
      "grad_norm": 0.07933788001537323,
      "learning_rate": 4.6482567108917e-05,
      "loss": 0.0245,
      "step": 11400
    },
    {
      "epoch": 3.5205183585313176,
      "grad_norm": 3.3062543869018555,
      "learning_rate": 4.6479481641468685e-05,
      "loss": 0.0348,
      "step": 11410
    },
    {
      "epoch": 3.523603825979636,
      "grad_norm": 6.086333274841309,
      "learning_rate": 4.647639617402037e-05,
      "loss": 0.0491,
      "step": 11420
    },
    {
      "epoch": 3.526689293427954,
      "grad_norm": 2.017409324645996,
      "learning_rate": 4.647331070657205e-05,
      "loss": 0.0296,
      "step": 11430
    },
    {
      "epoch": 3.529774760876273,
      "grad_norm": 0.9629236459732056,
      "learning_rate": 4.6470225239123726e-05,
      "loss": 0.0308,
      "step": 11440
    },
    {
      "epoch": 3.532860228324591,
      "grad_norm": 1.4346286058425903,
      "learning_rate": 4.646713977167541e-05,
      "loss": 0.0259,
      "step": 11450
    },
    {
      "epoch": 3.5359456957729094,
      "grad_norm": 0.09686722606420517,
      "learning_rate": 4.64640543042271e-05,
      "loss": 0.0111,
      "step": 11460
    },
    {
      "epoch": 3.539031163221228,
      "grad_norm": 3.0380027294158936,
      "learning_rate": 4.6460968836778774e-05,
      "loss": 0.0312,
      "step": 11470
    },
    {
      "epoch": 3.5421166306695464,
      "grad_norm": 2.204704523086548,
      "learning_rate": 4.6457883369330456e-05,
      "loss": 0.034,
      "step": 11480
    },
    {
      "epoch": 3.5452020981178647,
      "grad_norm": 1.9035242795944214,
      "learning_rate": 4.645479790188214e-05,
      "loss": 0.0246,
      "step": 11490
    },
    {
      "epoch": 3.5482875655661834,
      "grad_norm": 4.035039901733398,
      "learning_rate": 4.645171243443382e-05,
      "loss": 0.0261,
      "step": 11500
    },
    {
      "epoch": 3.5513730330145017,
      "grad_norm": 0.21553970873355865,
      "learning_rate": 4.64486269669855e-05,
      "loss": 0.032,
      "step": 11510
    },
    {
      "epoch": 3.55445850046282,
      "grad_norm": 0.055316001176834106,
      "learning_rate": 4.644554149953718e-05,
      "loss": 0.0246,
      "step": 11520
    },
    {
      "epoch": 3.5575439679111387,
      "grad_norm": 1.824745535850525,
      "learning_rate": 4.644245603208887e-05,
      "loss": 0.0212,
      "step": 11530
    },
    {
      "epoch": 3.560629435359457,
      "grad_norm": 2.3101320266723633,
      "learning_rate": 4.6439370564640544e-05,
      "loss": 0.0089,
      "step": 11540
    },
    {
      "epoch": 3.5637149028077753,
      "grad_norm": 0.2937747836112976,
      "learning_rate": 4.6436285097192227e-05,
      "loss": 0.0286,
      "step": 11550
    },
    {
      "epoch": 3.566800370256094,
      "grad_norm": 0.765609085559845,
      "learning_rate": 4.643319962974391e-05,
      "loss": 0.0177,
      "step": 11560
    },
    {
      "epoch": 3.5698858377044123,
      "grad_norm": 0.012176609598100185,
      "learning_rate": 4.643011416229559e-05,
      "loss": 0.0079,
      "step": 11570
    },
    {
      "epoch": 3.5729713051527305,
      "grad_norm": 0.025130802765488625,
      "learning_rate": 4.6427028694847274e-05,
      "loss": 0.0155,
      "step": 11580
    },
    {
      "epoch": 3.5760567726010493,
      "grad_norm": 0.2410212755203247,
      "learning_rate": 4.642394322739895e-05,
      "loss": 0.0194,
      "step": 11590
    },
    {
      "epoch": 3.5791422400493675,
      "grad_norm": 0.12658396363258362,
      "learning_rate": 4.642085775995064e-05,
      "loss": 0.01,
      "step": 11600
    },
    {
      "epoch": 3.582227707497686,
      "grad_norm": 1.4569634199142456,
      "learning_rate": 4.6417772292502315e-05,
      "loss": 0.0372,
      "step": 11610
    },
    {
      "epoch": 3.5853131749460045,
      "grad_norm": 1.3980519771575928,
      "learning_rate": 4.6414686825054e-05,
      "loss": 0.0197,
      "step": 11620
    },
    {
      "epoch": 3.588398642394323,
      "grad_norm": 1.6302673816680908,
      "learning_rate": 4.641160135760568e-05,
      "loss": 0.028,
      "step": 11630
    },
    {
      "epoch": 3.591484109842641,
      "grad_norm": 0.25449591875076294,
      "learning_rate": 4.640851589015736e-05,
      "loss": 0.0176,
      "step": 11640
    },
    {
      "epoch": 3.59456957729096,
      "grad_norm": 0.6458696126937866,
      "learning_rate": 4.6405430422709045e-05,
      "loss": 0.0323,
      "step": 11650
    },
    {
      "epoch": 3.597655044739278,
      "grad_norm": 0.016703767701983452,
      "learning_rate": 4.640234495526073e-05,
      "loss": 0.0145,
      "step": 11660
    },
    {
      "epoch": 3.6007405121875964,
      "grad_norm": 3.3753437995910645,
      "learning_rate": 4.639925948781241e-05,
      "loss": 0.0271,
      "step": 11670
    },
    {
      "epoch": 3.603825979635915,
      "grad_norm": 0.19581741094589233,
      "learning_rate": 4.6396174020364085e-05,
      "loss": 0.0121,
      "step": 11680
    },
    {
      "epoch": 3.6069114470842334,
      "grad_norm": 1.2840687036514282,
      "learning_rate": 4.639308855291577e-05,
      "loss": 0.0293,
      "step": 11690
    },
    {
      "epoch": 3.6099969145325517,
      "grad_norm": 0.9338639378547668,
      "learning_rate": 4.639000308546745e-05,
      "loss": 0.019,
      "step": 11700
    },
    {
      "epoch": 3.61308238198087,
      "grad_norm": 2.7763915061950684,
      "learning_rate": 4.638691761801913e-05,
      "loss": 0.0096,
      "step": 11710
    },
    {
      "epoch": 3.6161678494291887,
      "grad_norm": 2.0774166584014893,
      "learning_rate": 4.6383832150570815e-05,
      "loss": 0.0193,
      "step": 11720
    },
    {
      "epoch": 3.619253316877507,
      "grad_norm": 2.1844143867492676,
      "learning_rate": 4.63807466831225e-05,
      "loss": 0.0125,
      "step": 11730
    },
    {
      "epoch": 3.6223387843258252,
      "grad_norm": 1.2659555673599243,
      "learning_rate": 4.637766121567418e-05,
      "loss": 0.0136,
      "step": 11740
    },
    {
      "epoch": 3.6254242517741435,
      "grad_norm": 1.382305383682251,
      "learning_rate": 4.6374575748225856e-05,
      "loss": 0.0143,
      "step": 11750
    },
    {
      "epoch": 3.6285097192224622,
      "grad_norm": 0.2715927064418793,
      "learning_rate": 4.637149028077754e-05,
      "loss": 0.0134,
      "step": 11760
    },
    {
      "epoch": 3.6315951866707805,
      "grad_norm": 0.10642721503973007,
      "learning_rate": 4.636840481332922e-05,
      "loss": 0.0075,
      "step": 11770
    },
    {
      "epoch": 3.634680654119099,
      "grad_norm": 0.44626903533935547,
      "learning_rate": 4.63653193458809e-05,
      "loss": 0.01,
      "step": 11780
    },
    {
      "epoch": 3.6377661215674175,
      "grad_norm": 0.109685517847538,
      "learning_rate": 4.6362233878432586e-05,
      "loss": 0.0132,
      "step": 11790
    },
    {
      "epoch": 3.640851589015736,
      "grad_norm": 0.3576889634132385,
      "learning_rate": 4.635914841098427e-05,
      "loss": 0.0123,
      "step": 11800
    },
    {
      "epoch": 3.643937056464054,
      "grad_norm": 0.31301358342170715,
      "learning_rate": 4.635606294353595e-05,
      "loss": 0.0208,
      "step": 11810
    },
    {
      "epoch": 3.647022523912373,
      "grad_norm": 2.5274429321289062,
      "learning_rate": 4.6352977476087626e-05,
      "loss": 0.0191,
      "step": 11820
    },
    {
      "epoch": 3.650107991360691,
      "grad_norm": 1.784593105316162,
      "learning_rate": 4.634989200863931e-05,
      "loss": 0.0336,
      "step": 11830
    },
    {
      "epoch": 3.6531934588090094,
      "grad_norm": 7.074016094207764,
      "learning_rate": 4.634680654119099e-05,
      "loss": 0.0589,
      "step": 11840
    },
    {
      "epoch": 3.656278926257328,
      "grad_norm": 1.0218844413757324,
      "learning_rate": 4.6343721073742674e-05,
      "loss": 0.0226,
      "step": 11850
    },
    {
      "epoch": 3.6593643937056464,
      "grad_norm": 0.5601137280464172,
      "learning_rate": 4.6340635606294356e-05,
      "loss": 0.0268,
      "step": 11860
    },
    {
      "epoch": 3.6624498611539646,
      "grad_norm": 0.08156048506498337,
      "learning_rate": 4.633755013884604e-05,
      "loss": 0.0129,
      "step": 11870
    },
    {
      "epoch": 3.6655353286022834,
      "grad_norm": 3.7779836654663086,
      "learning_rate": 4.633446467139772e-05,
      "loss": 0.0193,
      "step": 11880
    },
    {
      "epoch": 3.6686207960506017,
      "grad_norm": 0.3215641379356384,
      "learning_rate": 4.63313792039494e-05,
      "loss": 0.0158,
      "step": 11890
    },
    {
      "epoch": 3.67170626349892,
      "grad_norm": 1.9160044193267822,
      "learning_rate": 4.632829373650108e-05,
      "loss": 0.0228,
      "step": 11900
    },
    {
      "epoch": 3.6747917309472387,
      "grad_norm": 0.7087558507919312,
      "learning_rate": 4.632520826905276e-05,
      "loss": 0.0067,
      "step": 11910
    },
    {
      "epoch": 3.677877198395557,
      "grad_norm": 0.779420018196106,
      "learning_rate": 4.6322122801604444e-05,
      "loss": 0.0079,
      "step": 11920
    },
    {
      "epoch": 3.680962665843875,
      "grad_norm": 0.7445876598358154,
      "learning_rate": 4.631903733415613e-05,
      "loss": 0.0173,
      "step": 11930
    },
    {
      "epoch": 3.684048133292194,
      "grad_norm": 2.2272884845733643,
      "learning_rate": 4.631595186670781e-05,
      "loss": 0.009,
      "step": 11940
    },
    {
      "epoch": 3.687133600740512,
      "grad_norm": 1.075089931488037,
      "learning_rate": 4.631286639925949e-05,
      "loss": 0.0395,
      "step": 11950
    },
    {
      "epoch": 3.6902190681888305,
      "grad_norm": 2.1850011348724365,
      "learning_rate": 4.630978093181117e-05,
      "loss": 0.0141,
      "step": 11960
    },
    {
      "epoch": 3.693304535637149,
      "grad_norm": 0.5379526615142822,
      "learning_rate": 4.630669546436286e-05,
      "loss": 0.0048,
      "step": 11970
    },
    {
      "epoch": 3.6963900030854675,
      "grad_norm": 0.23604358732700348,
      "learning_rate": 4.630360999691453e-05,
      "loss": 0.0186,
      "step": 11980
    },
    {
      "epoch": 3.699475470533786,
      "grad_norm": 1.0165958404541016,
      "learning_rate": 4.6300524529466215e-05,
      "loss": 0.0191,
      "step": 11990
    },
    {
      "epoch": 3.7025609379821045,
      "grad_norm": 0.17228049039840698,
      "learning_rate": 4.62974390620179e-05,
      "loss": 0.0192,
      "step": 12000
    },
    {
      "epoch": 3.705646405430423,
      "grad_norm": 0.03773445636034012,
      "learning_rate": 4.629435359456958e-05,
      "loss": 0.0044,
      "step": 12010
    },
    {
      "epoch": 3.708731872878741,
      "grad_norm": 0.18319319188594818,
      "learning_rate": 4.629126812712126e-05,
      "loss": 0.0078,
      "step": 12020
    },
    {
      "epoch": 3.71181734032706,
      "grad_norm": 0.634311854839325,
      "learning_rate": 4.628818265967294e-05,
      "loss": 0.0187,
      "step": 12030
    },
    {
      "epoch": 3.714902807775378,
      "grad_norm": 0.9422563910484314,
      "learning_rate": 4.628509719222463e-05,
      "loss": 0.013,
      "step": 12040
    },
    {
      "epoch": 3.7179882752236963,
      "grad_norm": 1.9578752517700195,
      "learning_rate": 4.628201172477631e-05,
      "loss": 0.0068,
      "step": 12050
    },
    {
      "epoch": 3.721073742672015,
      "grad_norm": 0.466521680355072,
      "learning_rate": 4.6278926257327985e-05,
      "loss": 0.0249,
      "step": 12060
    },
    {
      "epoch": 3.7241592101203334,
      "grad_norm": 2.0023231506347656,
      "learning_rate": 4.627584078987967e-05,
      "loss": 0.015,
      "step": 12070
    },
    {
      "epoch": 3.7272446775686516,
      "grad_norm": 0.2963044345378876,
      "learning_rate": 4.627275532243135e-05,
      "loss": 0.0155,
      "step": 12080
    },
    {
      "epoch": 3.73033014501697,
      "grad_norm": 1.0775257349014282,
      "learning_rate": 4.626966985498303e-05,
      "loss": 0.0114,
      "step": 12090
    },
    {
      "epoch": 3.7334156124652886,
      "grad_norm": 0.18015891313552856,
      "learning_rate": 4.626658438753471e-05,
      "loss": 0.0425,
      "step": 12100
    },
    {
      "epoch": 3.736501079913607,
      "grad_norm": 0.08664599061012268,
      "learning_rate": 4.62634989200864e-05,
      "loss": 0.0055,
      "step": 12110
    },
    {
      "epoch": 3.739586547361925,
      "grad_norm": 0.8813639283180237,
      "learning_rate": 4.626041345263808e-05,
      "loss": 0.0115,
      "step": 12120
    },
    {
      "epoch": 3.7426720148102435,
      "grad_norm": 2.3950002193450928,
      "learning_rate": 4.6257327985189756e-05,
      "loss": 0.0415,
      "step": 12130
    },
    {
      "epoch": 3.745757482258562,
      "grad_norm": 0.07780031859874725,
      "learning_rate": 4.625424251774144e-05,
      "loss": 0.0327,
      "step": 12140
    },
    {
      "epoch": 3.7488429497068805,
      "grad_norm": 0.08329632878303528,
      "learning_rate": 4.625115705029312e-05,
      "loss": 0.0118,
      "step": 12150
    },
    {
      "epoch": 3.7519284171551988,
      "grad_norm": 1.2227623462677002,
      "learning_rate": 4.6248071582844803e-05,
      "loss": 0.0071,
      "step": 12160
    },
    {
      "epoch": 3.7550138846035175,
      "grad_norm": 2.4399707317352295,
      "learning_rate": 4.624498611539648e-05,
      "loss": 0.014,
      "step": 12170
    },
    {
      "epoch": 3.7580993520518358,
      "grad_norm": 0.7081981897354126,
      "learning_rate": 4.624190064794817e-05,
      "loss": 0.0118,
      "step": 12180
    },
    {
      "epoch": 3.761184819500154,
      "grad_norm": 0.36927366256713867,
      "learning_rate": 4.623881518049985e-05,
      "loss": 0.0185,
      "step": 12190
    },
    {
      "epoch": 3.7642702869484728,
      "grad_norm": 2.0579161643981934,
      "learning_rate": 4.6235729713051527e-05,
      "loss": 0.0177,
      "step": 12200
    },
    {
      "epoch": 3.767355754396791,
      "grad_norm": 0.4115067422389984,
      "learning_rate": 4.6232644245603216e-05,
      "loss": 0.0105,
      "step": 12210
    },
    {
      "epoch": 3.7704412218451093,
      "grad_norm": 2.304595470428467,
      "learning_rate": 4.622955877815489e-05,
      "loss": 0.0185,
      "step": 12220
    },
    {
      "epoch": 3.773526689293428,
      "grad_norm": 0.2664611041545868,
      "learning_rate": 4.6226473310706574e-05,
      "loss": 0.0086,
      "step": 12230
    },
    {
      "epoch": 3.7766121567417463,
      "grad_norm": 0.4623121917247772,
      "learning_rate": 4.6223387843258256e-05,
      "loss": 0.0076,
      "step": 12240
    },
    {
      "epoch": 3.7796976241900646,
      "grad_norm": 0.020601261407136917,
      "learning_rate": 4.622030237580994e-05,
      "loss": 0.0086,
      "step": 12250
    },
    {
      "epoch": 3.7827830916383833,
      "grad_norm": 0.36631378531455994,
      "learning_rate": 4.621721690836162e-05,
      "loss": 0.0165,
      "step": 12260
    },
    {
      "epoch": 3.7858685590867016,
      "grad_norm": 1.5450230836868286,
      "learning_rate": 4.62141314409133e-05,
      "loss": 0.0138,
      "step": 12270
    },
    {
      "epoch": 3.78895402653502,
      "grad_norm": 0.42235127091407776,
      "learning_rate": 4.6211045973464986e-05,
      "loss": 0.0162,
      "step": 12280
    },
    {
      "epoch": 3.7920394939833386,
      "grad_norm": 0.6911444664001465,
      "learning_rate": 4.620796050601666e-05,
      "loss": 0.0108,
      "step": 12290
    },
    {
      "epoch": 3.795124961431657,
      "grad_norm": 0.3841926157474518,
      "learning_rate": 4.6204875038568345e-05,
      "loss": 0.0205,
      "step": 12300
    },
    {
      "epoch": 3.798210428879975,
      "grad_norm": 0.14078645408153534,
      "learning_rate": 4.620178957112003e-05,
      "loss": 0.0148,
      "step": 12310
    },
    {
      "epoch": 3.801295896328294,
      "grad_norm": 1.0514214038848877,
      "learning_rate": 4.619870410367171e-05,
      "loss": 0.0206,
      "step": 12320
    },
    {
      "epoch": 3.804381363776612,
      "grad_norm": 2.0895864963531494,
      "learning_rate": 4.619561863622339e-05,
      "loss": 0.0239,
      "step": 12330
    },
    {
      "epoch": 3.8074668312249305,
      "grad_norm": 1.2137041091918945,
      "learning_rate": 4.619253316877507e-05,
      "loss": 0.0068,
      "step": 12340
    },
    {
      "epoch": 3.810552298673249,
      "grad_norm": 0.8896976709365845,
      "learning_rate": 4.618944770132676e-05,
      "loss": 0.0141,
      "step": 12350
    },
    {
      "epoch": 3.8136377661215675,
      "grad_norm": 0.19534268975257874,
      "learning_rate": 4.618636223387843e-05,
      "loss": 0.0129,
      "step": 12360
    },
    {
      "epoch": 3.8167232335698857,
      "grad_norm": 0.13420352339744568,
      "learning_rate": 4.6183276766430115e-05,
      "loss": 0.0132,
      "step": 12370
    },
    {
      "epoch": 3.8198087010182045,
      "grad_norm": 1.2735114097595215,
      "learning_rate": 4.61801912989818e-05,
      "loss": 0.0274,
      "step": 12380
    },
    {
      "epoch": 3.8228941684665227,
      "grad_norm": 1.6534104347229004,
      "learning_rate": 4.617710583153348e-05,
      "loss": 0.0182,
      "step": 12390
    },
    {
      "epoch": 3.825979635914841,
      "grad_norm": 0.7502182722091675,
      "learning_rate": 4.617402036408516e-05,
      "loss": 0.0167,
      "step": 12400
    },
    {
      "epoch": 3.8290651033631597,
      "grad_norm": 1.1104768514633179,
      "learning_rate": 4.617093489663684e-05,
      "loss": 0.0421,
      "step": 12410
    },
    {
      "epoch": 3.832150570811478,
      "grad_norm": 0.1835946887731552,
      "learning_rate": 4.616784942918853e-05,
      "loss": 0.0091,
      "step": 12420
    },
    {
      "epoch": 3.8352360382597963,
      "grad_norm": 0.862921953201294,
      "learning_rate": 4.61647639617402e-05,
      "loss": 0.0255,
      "step": 12430
    },
    {
      "epoch": 3.838321505708115,
      "grad_norm": 0.7117749452590942,
      "learning_rate": 4.6161678494291886e-05,
      "loss": 0.0213,
      "step": 12440
    },
    {
      "epoch": 3.8414069731564333,
      "grad_norm": 0.5036042928695679,
      "learning_rate": 4.6158593026843575e-05,
      "loss": 0.0155,
      "step": 12450
    },
    {
      "epoch": 3.8444924406047516,
      "grad_norm": 1.7221165895462036,
      "learning_rate": 4.615550755939525e-05,
      "loss": 0.0183,
      "step": 12460
    },
    {
      "epoch": 3.8475779080530703,
      "grad_norm": 1.904334545135498,
      "learning_rate": 4.615242209194693e-05,
      "loss": 0.0172,
      "step": 12470
    },
    {
      "epoch": 3.8506633755013886,
      "grad_norm": 0.21770255267620087,
      "learning_rate": 4.6149336624498616e-05,
      "loss": 0.0133,
      "step": 12480
    },
    {
      "epoch": 3.853748842949707,
      "grad_norm": 2.0577292442321777,
      "learning_rate": 4.61462511570503e-05,
      "loss": 0.0104,
      "step": 12490
    },
    {
      "epoch": 3.856834310398025,
      "grad_norm": 2.501596212387085,
      "learning_rate": 4.6143165689601974e-05,
      "loss": 0.0099,
      "step": 12500
    },
    {
      "epoch": 3.859919777846344,
      "grad_norm": 2.1005308628082275,
      "learning_rate": 4.6140080222153656e-05,
      "loss": 0.0252,
      "step": 12510
    },
    {
      "epoch": 3.863005245294662,
      "grad_norm": 0.11084392666816711,
      "learning_rate": 4.6136994754705345e-05,
      "loss": 0.0248,
      "step": 12520
    },
    {
      "epoch": 3.8660907127429804,
      "grad_norm": 0.01803397387266159,
      "learning_rate": 4.613390928725702e-05,
      "loss": 0.0203,
      "step": 12530
    },
    {
      "epoch": 3.8691761801912987,
      "grad_norm": 1.0999237298965454,
      "learning_rate": 4.6130823819808704e-05,
      "loss": 0.0053,
      "step": 12540
    },
    {
      "epoch": 3.8722616476396174,
      "grad_norm": 0.8696185350418091,
      "learning_rate": 4.6127738352360386e-05,
      "loss": 0.0165,
      "step": 12550
    },
    {
      "epoch": 3.8753471150879357,
      "grad_norm": 3.746297836303711,
      "learning_rate": 4.612465288491207e-05,
      "loss": 0.0192,
      "step": 12560
    },
    {
      "epoch": 3.878432582536254,
      "grad_norm": 0.8469532132148743,
      "learning_rate": 4.6121567417463744e-05,
      "loss": 0.0225,
      "step": 12570
    },
    {
      "epoch": 3.8815180499845727,
      "grad_norm": 0.8919146656990051,
      "learning_rate": 4.611848195001543e-05,
      "loss": 0.0218,
      "step": 12580
    },
    {
      "epoch": 3.884603517432891,
      "grad_norm": 0.11069228500127792,
      "learning_rate": 4.6115396482567116e-05,
      "loss": 0.0208,
      "step": 12590
    },
    {
      "epoch": 3.8876889848812093,
      "grad_norm": 1.3865219354629517,
      "learning_rate": 4.611231101511879e-05,
      "loss": 0.0198,
      "step": 12600
    },
    {
      "epoch": 3.890774452329528,
      "grad_norm": 2.424099922180176,
      "learning_rate": 4.6109225547670474e-05,
      "loss": 0.033,
      "step": 12610
    },
    {
      "epoch": 3.8938599197778463,
      "grad_norm": 1.2454642057418823,
      "learning_rate": 4.610614008022216e-05,
      "loss": 0.0079,
      "step": 12620
    },
    {
      "epoch": 3.8969453872261646,
      "grad_norm": 0.38285917043685913,
      "learning_rate": 4.610305461277384e-05,
      "loss": 0.0163,
      "step": 12630
    },
    {
      "epoch": 3.9000308546744833,
      "grad_norm": 2.4219303131103516,
      "learning_rate": 4.6099969145325515e-05,
      "loss": 0.0195,
      "step": 12640
    },
    {
      "epoch": 3.9031163221228016,
      "grad_norm": 0.293514221906662,
      "learning_rate": 4.60968836778772e-05,
      "loss": 0.0077,
      "step": 12650
    },
    {
      "epoch": 3.90620178957112,
      "grad_norm": 0.011582501232624054,
      "learning_rate": 4.609379821042889e-05,
      "loss": 0.0189,
      "step": 12660
    },
    {
      "epoch": 3.9092872570194386,
      "grad_norm": 1.5626857280731201,
      "learning_rate": 4.609071274298056e-05,
      "loss": 0.0095,
      "step": 12670
    },
    {
      "epoch": 3.912372724467757,
      "grad_norm": 0.08512066304683685,
      "learning_rate": 4.6087627275532245e-05,
      "loss": 0.0053,
      "step": 12680
    },
    {
      "epoch": 3.915458191916075,
      "grad_norm": 0.14883282780647278,
      "learning_rate": 4.608454180808393e-05,
      "loss": 0.0248,
      "step": 12690
    },
    {
      "epoch": 3.918543659364394,
      "grad_norm": 0.7199479937553406,
      "learning_rate": 4.608145634063561e-05,
      "loss": 0.008,
      "step": 12700
    },
    {
      "epoch": 3.921629126812712,
      "grad_norm": 4.6113386154174805,
      "learning_rate": 4.6078370873187285e-05,
      "loss": 0.0128,
      "step": 12710
    },
    {
      "epoch": 3.9247145942610304,
      "grad_norm": 3.552649736404419,
      "learning_rate": 4.6075285405738975e-05,
      "loss": 0.022,
      "step": 12720
    },
    {
      "epoch": 3.927800061709349,
      "grad_norm": 0.5750815868377686,
      "learning_rate": 4.607219993829066e-05,
      "loss": 0.0066,
      "step": 12730
    },
    {
      "epoch": 3.9308855291576674,
      "grad_norm": 0.17586538195610046,
      "learning_rate": 4.606911447084233e-05,
      "loss": 0.0091,
      "step": 12740
    },
    {
      "epoch": 3.9339709966059857,
      "grad_norm": 1.3761242628097534,
      "learning_rate": 4.6066029003394015e-05,
      "loss": 0.0129,
      "step": 12750
    },
    {
      "epoch": 3.9370564640543044,
      "grad_norm": 2.39342999458313,
      "learning_rate": 4.60629435359457e-05,
      "loss": 0.0121,
      "step": 12760
    },
    {
      "epoch": 3.9401419315026227,
      "grad_norm": 1.492074728012085,
      "learning_rate": 4.605985806849738e-05,
      "loss": 0.0379,
      "step": 12770
    },
    {
      "epoch": 3.943227398950941,
      "grad_norm": 3.189126491546631,
      "learning_rate": 4.6056772601049056e-05,
      "loss": 0.0161,
      "step": 12780
    },
    {
      "epoch": 3.9463128663992597,
      "grad_norm": 0.0224959347397089,
      "learning_rate": 4.6053687133600745e-05,
      "loss": 0.0058,
      "step": 12790
    },
    {
      "epoch": 3.949398333847578,
      "grad_norm": 1.0417232513427734,
      "learning_rate": 4.605060166615243e-05,
      "loss": 0.0061,
      "step": 12800
    },
    {
      "epoch": 3.9524838012958963,
      "grad_norm": 0.2428256869316101,
      "learning_rate": 4.6047516198704103e-05,
      "loss": 0.0091,
      "step": 12810
    },
    {
      "epoch": 3.955569268744215,
      "grad_norm": 4.4434590339660645,
      "learning_rate": 4.6044430731255786e-05,
      "loss": 0.0237,
      "step": 12820
    },
    {
      "epoch": 3.9586547361925333,
      "grad_norm": 0.24915194511413574,
      "learning_rate": 4.604134526380747e-05,
      "loss": 0.0111,
      "step": 12830
    },
    {
      "epoch": 3.9617402036408516,
      "grad_norm": 0.3886648714542389,
      "learning_rate": 4.603825979635915e-05,
      "loss": 0.0153,
      "step": 12840
    },
    {
      "epoch": 3.9648256710891703,
      "grad_norm": 0.7096961140632629,
      "learning_rate": 4.6035174328910827e-05,
      "loss": 0.0261,
      "step": 12850
    },
    {
      "epoch": 3.9679111385374886,
      "grad_norm": 2.8508284091949463,
      "learning_rate": 4.6032088861462516e-05,
      "loss": 0.0139,
      "step": 12860
    },
    {
      "epoch": 3.970996605985807,
      "grad_norm": 0.9243795871734619,
      "learning_rate": 4.60290033940142e-05,
      "loss": 0.0298,
      "step": 12870
    },
    {
      "epoch": 3.974082073434125,
      "grad_norm": 0.189609557390213,
      "learning_rate": 4.6025917926565874e-05,
      "loss": 0.0149,
      "step": 12880
    },
    {
      "epoch": 3.977167540882444,
      "grad_norm": 0.06894528120756149,
      "learning_rate": 4.6022832459117556e-05,
      "loss": 0.022,
      "step": 12890
    },
    {
      "epoch": 3.980253008330762,
      "grad_norm": 0.3608192205429077,
      "learning_rate": 4.601974699166924e-05,
      "loss": 0.0257,
      "step": 12900
    },
    {
      "epoch": 3.9833384757790804,
      "grad_norm": 3.0065293312072754,
      "learning_rate": 4.601666152422092e-05,
      "loss": 0.016,
      "step": 12910
    },
    {
      "epoch": 3.9864239432273987,
      "grad_norm": 0.1038360744714737,
      "learning_rate": 4.6013576056772604e-05,
      "loss": 0.0043,
      "step": 12920
    },
    {
      "epoch": 3.9895094106757174,
      "grad_norm": 1.846316933631897,
      "learning_rate": 4.6010490589324286e-05,
      "loss": 0.0046,
      "step": 12930
    },
    {
      "epoch": 3.9925948781240357,
      "grad_norm": 0.012775108218193054,
      "learning_rate": 4.600740512187597e-05,
      "loss": 0.0228,
      "step": 12940
    },
    {
      "epoch": 3.995680345572354,
      "grad_norm": 0.7181783318519592,
      "learning_rate": 4.6004319654427645e-05,
      "loss": 0.0243,
      "step": 12950
    },
    {
      "epoch": 3.9987658130206727,
      "grad_norm": 3.5402326583862305,
      "learning_rate": 4.6001234186979334e-05,
      "loss": 0.0201,
      "step": 12960
    },
    {
      "epoch": 4.0,
      "eval_accuracy_branch1": 0.9931232699671113,
      "eval_accuracy_branch2": 0.4377766847024102,
      "eval_f1_branch1": 0.9922559792073887,
      "eval_f1_branch2": 0.43637964883231284,
      "eval_loss": 0.004839715547859669,
      "eval_precision_branch1": 0.9924994215699303,
      "eval_precision_branch2": 0.5122173146994807,
      "eval_recall_branch1": 0.992072004405733,
      "eval_recall_branch2": 0.5111686583142849,
      "eval_runtime": 239.7885,
      "eval_samples_per_second": 432.394,
      "eval_steps_per_second": 54.052,
      "step": 12964
    },
    {
      "epoch": 4.001851280468991,
      "grad_norm": 0.020862726494669914,
      "learning_rate": 4.599814871953101e-05,
      "loss": 0.0068,
      "step": 12970
    },
    {
      "epoch": 4.004936747917309,
      "grad_norm": 0.12922906875610352,
      "learning_rate": 4.599506325208269e-05,
      "loss": 0.022,
      "step": 12980
    },
    {
      "epoch": 4.008022215365628,
      "grad_norm": 0.013532161712646484,
      "learning_rate": 4.5991977784634374e-05,
      "loss": 0.0041,
      "step": 12990
    },
    {
      "epoch": 4.011107682813947,
      "grad_norm": 6.233229637145996,
      "learning_rate": 4.598889231718606e-05,
      "loss": 0.0147,
      "step": 13000
    },
    {
      "epoch": 4.0141931502622645,
      "grad_norm": 0.5681403279304504,
      "learning_rate": 4.598580684973774e-05,
      "loss": 0.0097,
      "step": 13010
    },
    {
      "epoch": 4.017278617710583,
      "grad_norm": 0.41264912486076355,
      "learning_rate": 4.5982721382289415e-05,
      "loss": 0.0215,
      "step": 13020
    },
    {
      "epoch": 4.020364085158902,
      "grad_norm": 2.795559883117676,
      "learning_rate": 4.5979635914841104e-05,
      "loss": 0.0081,
      "step": 13030
    },
    {
      "epoch": 4.02344955260722,
      "grad_norm": 0.5743004679679871,
      "learning_rate": 4.597655044739278e-05,
      "loss": 0.0121,
      "step": 13040
    },
    {
      "epoch": 4.0265350200555385,
      "grad_norm": 0.4892767071723938,
      "learning_rate": 4.597346497994446e-05,
      "loss": 0.0037,
      "step": 13050
    },
    {
      "epoch": 4.029620487503857,
      "grad_norm": 0.059938617050647736,
      "learning_rate": 4.5970379512496145e-05,
      "loss": 0.0145,
      "step": 13060
    },
    {
      "epoch": 4.032705954952175,
      "grad_norm": 0.05073240026831627,
      "learning_rate": 4.596729404504783e-05,
      "loss": 0.0098,
      "step": 13070
    },
    {
      "epoch": 4.035791422400494,
      "grad_norm": 1.5330836772918701,
      "learning_rate": 4.596420857759951e-05,
      "loss": 0.0102,
      "step": 13080
    },
    {
      "epoch": 4.038876889848812,
      "grad_norm": 0.5532904267311096,
      "learning_rate": 4.5961123110151186e-05,
      "loss": 0.0077,
      "step": 13090
    },
    {
      "epoch": 4.04196235729713,
      "grad_norm": 0.053473953157663345,
      "learning_rate": 4.5958037642702875e-05,
      "loss": 0.0209,
      "step": 13100
    },
    {
      "epoch": 4.045047824745449,
      "grad_norm": 1.0636930465698242,
      "learning_rate": 4.595495217525455e-05,
      "loss": 0.0035,
      "step": 13110
    },
    {
      "epoch": 4.048133292193767,
      "grad_norm": 0.10333981364965439,
      "learning_rate": 4.595186670780623e-05,
      "loss": 0.0116,
      "step": 13120
    },
    {
      "epoch": 4.051218759642086,
      "grad_norm": 0.017568863928318024,
      "learning_rate": 4.5948781240357916e-05,
      "loss": 0.0143,
      "step": 13130
    },
    {
      "epoch": 4.054304227090404,
      "grad_norm": 3.629704475402832,
      "learning_rate": 4.59456957729096e-05,
      "loss": 0.0208,
      "step": 13140
    },
    {
      "epoch": 4.057389694538722,
      "grad_norm": 0.2724808156490326,
      "learning_rate": 4.594261030546128e-05,
      "loss": 0.0085,
      "step": 13150
    },
    {
      "epoch": 4.060475161987041,
      "grad_norm": 1.551350474357605,
      "learning_rate": 4.5939524838012956e-05,
      "loss": 0.0128,
      "step": 13160
    },
    {
      "epoch": 4.06356062943536,
      "grad_norm": 0.08219466358423233,
      "learning_rate": 4.5936439370564646e-05,
      "loss": 0.0274,
      "step": 13170
    },
    {
      "epoch": 4.0666460968836775,
      "grad_norm": 1.7375900745391846,
      "learning_rate": 4.593335390311632e-05,
      "loss": 0.0194,
      "step": 13180
    },
    {
      "epoch": 4.069731564331996,
      "grad_norm": 1.030842900276184,
      "learning_rate": 4.5930268435668004e-05,
      "loss": 0.0205,
      "step": 13190
    },
    {
      "epoch": 4.072817031780315,
      "grad_norm": 0.28226178884506226,
      "learning_rate": 4.592718296821969e-05,
      "loss": 0.0067,
      "step": 13200
    },
    {
      "epoch": 4.075902499228633,
      "grad_norm": 0.4810529053211212,
      "learning_rate": 4.592409750077137e-05,
      "loss": 0.013,
      "step": 13210
    },
    {
      "epoch": 4.0789879666769515,
      "grad_norm": 4.430753707885742,
      "learning_rate": 4.592101203332305e-05,
      "loss": 0.0234,
      "step": 13220
    },
    {
      "epoch": 4.08207343412527,
      "grad_norm": 1.1373564004898071,
      "learning_rate": 4.5917926565874734e-05,
      "loss": 0.0108,
      "step": 13230
    },
    {
      "epoch": 4.085158901573588,
      "grad_norm": 4.508241176605225,
      "learning_rate": 4.5914841098426416e-05,
      "loss": 0.0167,
      "step": 13240
    },
    {
      "epoch": 4.088244369021907,
      "grad_norm": 2.6351332664489746,
      "learning_rate": 4.591175563097809e-05,
      "loss": 0.01,
      "step": 13250
    },
    {
      "epoch": 4.0913298364702255,
      "grad_norm": 3.262605905532837,
      "learning_rate": 4.5908670163529774e-05,
      "loss": 0.0058,
      "step": 13260
    },
    {
      "epoch": 4.094415303918543,
      "grad_norm": 0.44207891821861267,
      "learning_rate": 4.5905584696081464e-05,
      "loss": 0.0151,
      "step": 13270
    },
    {
      "epoch": 4.097500771366862,
      "grad_norm": 1.5706018209457397,
      "learning_rate": 4.590249922863314e-05,
      "loss": 0.0061,
      "step": 13280
    },
    {
      "epoch": 4.100586238815181,
      "grad_norm": 0.1748003512620926,
      "learning_rate": 4.589941376118482e-05,
      "loss": 0.0048,
      "step": 13290
    },
    {
      "epoch": 4.103671706263499,
      "grad_norm": 1.585105061531067,
      "learning_rate": 4.5896328293736504e-05,
      "loss": 0.0083,
      "step": 13300
    },
    {
      "epoch": 4.106757173711817,
      "grad_norm": 3.0885279178619385,
      "learning_rate": 4.589324282628819e-05,
      "loss": 0.0277,
      "step": 13310
    },
    {
      "epoch": 4.109842641160136,
      "grad_norm": 0.013407296501100063,
      "learning_rate": 4.589015735883986e-05,
      "loss": 0.0159,
      "step": 13320
    },
    {
      "epoch": 4.112928108608454,
      "grad_norm": 0.39172396063804626,
      "learning_rate": 4.5887071891391545e-05,
      "loss": 0.0056,
      "step": 13330
    },
    {
      "epoch": 4.116013576056773,
      "grad_norm": 0.04904058575630188,
      "learning_rate": 4.5883986423943234e-05,
      "loss": 0.0086,
      "step": 13340
    },
    {
      "epoch": 4.119099043505091,
      "grad_norm": 0.2769964933395386,
      "learning_rate": 4.588090095649491e-05,
      "loss": 0.0106,
      "step": 13350
    },
    {
      "epoch": 4.122184510953409,
      "grad_norm": 1.199144959449768,
      "learning_rate": 4.587781548904659e-05,
      "loss": 0.006,
      "step": 13360
    },
    {
      "epoch": 4.125269978401728,
      "grad_norm": 1.023507833480835,
      "learning_rate": 4.5874730021598275e-05,
      "loss": 0.0063,
      "step": 13370
    },
    {
      "epoch": 4.128355445850047,
      "grad_norm": 0.47486957907676697,
      "learning_rate": 4.587164455414996e-05,
      "loss": 0.0222,
      "step": 13380
    },
    {
      "epoch": 4.1314409132983645,
      "grad_norm": 1.8682959079742432,
      "learning_rate": 4.586855908670164e-05,
      "loss": 0.0113,
      "step": 13390
    },
    {
      "epoch": 4.134526380746683,
      "grad_norm": 0.1546202152967453,
      "learning_rate": 4.5865473619253315e-05,
      "loss": 0.0122,
      "step": 13400
    },
    {
      "epoch": 4.137611848195002,
      "grad_norm": 2.4129984378814697,
      "learning_rate": 4.5862388151805005e-05,
      "loss": 0.0117,
      "step": 13410
    },
    {
      "epoch": 4.14069731564332,
      "grad_norm": 0.12180816382169724,
      "learning_rate": 4.585930268435668e-05,
      "loss": 0.0047,
      "step": 13420
    },
    {
      "epoch": 4.1437827830916385,
      "grad_norm": 0.7669844031333923,
      "learning_rate": 4.585621721690836e-05,
      "loss": 0.0075,
      "step": 13430
    },
    {
      "epoch": 4.146868250539957,
      "grad_norm": 0.018743664026260376,
      "learning_rate": 4.5853131749460045e-05,
      "loss": 0.0043,
      "step": 13440
    },
    {
      "epoch": 4.149953717988275,
      "grad_norm": 0.12306870520114899,
      "learning_rate": 4.585004628201173e-05,
      "loss": 0.0257,
      "step": 13450
    },
    {
      "epoch": 4.153039185436594,
      "grad_norm": 5.527297019958496,
      "learning_rate": 4.584696081456341e-05,
      "loss": 0.0062,
      "step": 13460
    },
    {
      "epoch": 4.1561246528849125,
      "grad_norm": 3.3890278339385986,
      "learning_rate": 4.584387534711509e-05,
      "loss": 0.0181,
      "step": 13470
    },
    {
      "epoch": 4.15921012033323,
      "grad_norm": 1.1442313194274902,
      "learning_rate": 4.5840789879666775e-05,
      "loss": 0.0159,
      "step": 13480
    },
    {
      "epoch": 4.162295587781549,
      "grad_norm": 4.2102766036987305,
      "learning_rate": 4.583770441221845e-05,
      "loss": 0.0239,
      "step": 13490
    },
    {
      "epoch": 4.165381055229867,
      "grad_norm": 3.0906970500946045,
      "learning_rate": 4.583461894477013e-05,
      "loss": 0.0127,
      "step": 13500
    },
    {
      "epoch": 4.168466522678186,
      "grad_norm": 1.135364055633545,
      "learning_rate": 4.5831533477321816e-05,
      "loss": 0.0312,
      "step": 13510
    },
    {
      "epoch": 4.171551990126504,
      "grad_norm": 1.0371692180633545,
      "learning_rate": 4.58284480098735e-05,
      "loss": 0.022,
      "step": 13520
    },
    {
      "epoch": 4.174637457574822,
      "grad_norm": 1.096882939338684,
      "learning_rate": 4.582536254242518e-05,
      "loss": 0.0156,
      "step": 13530
    },
    {
      "epoch": 4.177722925023141,
      "grad_norm": 0.3145757019519806,
      "learning_rate": 4.582227707497686e-05,
      "loss": 0.0108,
      "step": 13540
    },
    {
      "epoch": 4.18080839247146,
      "grad_norm": 1.0658490657806396,
      "learning_rate": 4.5819191607528546e-05,
      "loss": 0.0082,
      "step": 13550
    },
    {
      "epoch": 4.1838938599197775,
      "grad_norm": 0.250936895608902,
      "learning_rate": 4.581610614008022e-05,
      "loss": 0.0215,
      "step": 13560
    },
    {
      "epoch": 4.186979327368096,
      "grad_norm": 0.3283131718635559,
      "learning_rate": 4.5813020672631904e-05,
      "loss": 0.0102,
      "step": 13570
    },
    {
      "epoch": 4.190064794816415,
      "grad_norm": 0.04848813638091087,
      "learning_rate": 4.5809935205183586e-05,
      "loss": 0.0227,
      "step": 13580
    },
    {
      "epoch": 4.193150262264733,
      "grad_norm": 1.9653723239898682,
      "learning_rate": 4.580684973773527e-05,
      "loss": 0.0154,
      "step": 13590
    },
    {
      "epoch": 4.1962357297130515,
      "grad_norm": 0.7404777407646179,
      "learning_rate": 4.580376427028695e-05,
      "loss": 0.0108,
      "step": 13600
    },
    {
      "epoch": 4.19932119716137,
      "grad_norm": 0.9836784601211548,
      "learning_rate": 4.5800678802838634e-05,
      "loss": 0.024,
      "step": 13610
    },
    {
      "epoch": 4.202406664609688,
      "grad_norm": 0.5829309225082397,
      "learning_rate": 4.5797593335390316e-05,
      "loss": 0.0074,
      "step": 13620
    },
    {
      "epoch": 4.205492132058007,
      "grad_norm": 0.09855067729949951,
      "learning_rate": 4.579450786794199e-05,
      "loss": 0.0035,
      "step": 13630
    },
    {
      "epoch": 4.2085775995063255,
      "grad_norm": 4.4046196937561035,
      "learning_rate": 4.5791422400493674e-05,
      "loss": 0.0172,
      "step": 13640
    },
    {
      "epoch": 4.211663066954643,
      "grad_norm": 0.6437279582023621,
      "learning_rate": 4.578833693304536e-05,
      "loss": 0.0216,
      "step": 13650
    },
    {
      "epoch": 4.214748534402962,
      "grad_norm": 0.013462581671774387,
      "learning_rate": 4.578525146559704e-05,
      "loss": 0.0183,
      "step": 13660
    },
    {
      "epoch": 4.217834001851281,
      "grad_norm": 0.36403703689575195,
      "learning_rate": 4.578216599814872e-05,
      "loss": 0.0216,
      "step": 13670
    },
    {
      "epoch": 4.220919469299599,
      "grad_norm": 0.09646281599998474,
      "learning_rate": 4.5779080530700404e-05,
      "loss": 0.0124,
      "step": 13680
    },
    {
      "epoch": 4.224004936747917,
      "grad_norm": 0.31032794713974,
      "learning_rate": 4.577599506325209e-05,
      "loss": 0.0102,
      "step": 13690
    },
    {
      "epoch": 4.227090404196236,
      "grad_norm": 0.8160489201545715,
      "learning_rate": 4.577290959580376e-05,
      "loss": 0.0079,
      "step": 13700
    },
    {
      "epoch": 4.230175871644554,
      "grad_norm": 0.3380565941333771,
      "learning_rate": 4.576982412835545e-05,
      "loss": 0.0094,
      "step": 13710
    },
    {
      "epoch": 4.233261339092873,
      "grad_norm": 0.3199678361415863,
      "learning_rate": 4.576673866090713e-05,
      "loss": 0.0103,
      "step": 13720
    },
    {
      "epoch": 4.236346806541191,
      "grad_norm": 2.7851662635803223,
      "learning_rate": 4.576365319345881e-05,
      "loss": 0.01,
      "step": 13730
    },
    {
      "epoch": 4.239432273989509,
      "grad_norm": 1.9149197340011597,
      "learning_rate": 4.576056772601049e-05,
      "loss": 0.0076,
      "step": 13740
    },
    {
      "epoch": 4.242517741437828,
      "grad_norm": 0.5327556133270264,
      "learning_rate": 4.5757482258562175e-05,
      "loss": 0.0083,
      "step": 13750
    },
    {
      "epoch": 4.245603208886147,
      "grad_norm": 1.961883544921875,
      "learning_rate": 4.575439679111386e-05,
      "loss": 0.0036,
      "step": 13760
    },
    {
      "epoch": 4.2486886763344645,
      "grad_norm": 0.10512840747833252,
      "learning_rate": 4.575131132366553e-05,
      "loss": 0.0018,
      "step": 13770
    },
    {
      "epoch": 4.251774143782783,
      "grad_norm": 1.6033722162246704,
      "learning_rate": 4.574822585621722e-05,
      "loss": 0.008,
      "step": 13780
    },
    {
      "epoch": 4.254859611231102,
      "grad_norm": 0.07711638510227203,
      "learning_rate": 4.5745140388768905e-05,
      "loss": 0.0106,
      "step": 13790
    },
    {
      "epoch": 4.25794507867942,
      "grad_norm": 0.29445144534111023,
      "learning_rate": 4.574205492132058e-05,
      "loss": 0.0144,
      "step": 13800
    },
    {
      "epoch": 4.2610305461277385,
      "grad_norm": 3.885657787322998,
      "learning_rate": 4.573896945387226e-05,
      "loss": 0.011,
      "step": 13810
    },
    {
      "epoch": 4.264116013576057,
      "grad_norm": 0.0613701269030571,
      "learning_rate": 4.5735883986423946e-05,
      "loss": 0.0129,
      "step": 13820
    },
    {
      "epoch": 4.267201481024375,
      "grad_norm": 2.8139100074768066,
      "learning_rate": 4.573279851897563e-05,
      "loss": 0.0121,
      "step": 13830
    },
    {
      "epoch": 4.270286948472694,
      "grad_norm": 0.6034573316574097,
      "learning_rate": 4.5729713051527304e-05,
      "loss": 0.0192,
      "step": 13840
    },
    {
      "epoch": 4.273372415921012,
      "grad_norm": 1.958395004272461,
      "learning_rate": 4.572662758407899e-05,
      "loss": 0.0178,
      "step": 13850
    },
    {
      "epoch": 4.27645788336933,
      "grad_norm": 2.2700040340423584,
      "learning_rate": 4.5723542116630675e-05,
      "loss": 0.031,
      "step": 13860
    },
    {
      "epoch": 4.279543350817649,
      "grad_norm": 1.7927166223526,
      "learning_rate": 4.572045664918235e-05,
      "loss": 0.014,
      "step": 13870
    },
    {
      "epoch": 4.282628818265968,
      "grad_norm": 3.4151549339294434,
      "learning_rate": 4.5717371181734034e-05,
      "loss": 0.0085,
      "step": 13880
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 2.1172163486480713,
      "learning_rate": 4.5714285714285716e-05,
      "loss": 0.0092,
      "step": 13890
    },
    {
      "epoch": 4.288799753162604,
      "grad_norm": 0.26591771841049194,
      "learning_rate": 4.57112002468374e-05,
      "loss": 0.0205,
      "step": 13900
    },
    {
      "epoch": 4.291885220610922,
      "grad_norm": 2.06186842918396,
      "learning_rate": 4.5708114779389074e-05,
      "loss": 0.0102,
      "step": 13910
    },
    {
      "epoch": 4.294970688059241,
      "grad_norm": 0.47544246912002563,
      "learning_rate": 4.5705029311940764e-05,
      "loss": 0.0147,
      "step": 13920
    },
    {
      "epoch": 4.29805615550756,
      "grad_norm": 0.15703646838665009,
      "learning_rate": 4.5701943844492446e-05,
      "loss": 0.0067,
      "step": 13930
    },
    {
      "epoch": 4.301141622955877,
      "grad_norm": 0.23665541410446167,
      "learning_rate": 4.569885837704412e-05,
      "loss": 0.019,
      "step": 13940
    },
    {
      "epoch": 4.304227090404196,
      "grad_norm": 0.91178959608078,
      "learning_rate": 4.569577290959581e-05,
      "loss": 0.0107,
      "step": 13950
    },
    {
      "epoch": 4.307312557852515,
      "grad_norm": 4.755242347717285,
      "learning_rate": 4.569268744214749e-05,
      "loss": 0.0254,
      "step": 13960
    },
    {
      "epoch": 4.310398025300833,
      "grad_norm": 1.0883511304855347,
      "learning_rate": 4.568960197469917e-05,
      "loss": 0.009,
      "step": 13970
    },
    {
      "epoch": 4.313483492749151,
      "grad_norm": 1.8696951866149902,
      "learning_rate": 4.568651650725085e-05,
      "loss": 0.018,
      "step": 13980
    },
    {
      "epoch": 4.31656896019747,
      "grad_norm": 0.7260957956314087,
      "learning_rate": 4.5683431039802534e-05,
      "loss": 0.018,
      "step": 13990
    },
    {
      "epoch": 4.319654427645788,
      "grad_norm": 1.224738597869873,
      "learning_rate": 4.5680345572354217e-05,
      "loss": 0.0161,
      "step": 14000
    },
    {
      "epoch": 4.322739895094107,
      "grad_norm": 0.07207956165075302,
      "learning_rate": 4.567726010490589e-05,
      "loss": 0.0262,
      "step": 14010
    },
    {
      "epoch": 4.3258253625424254,
      "grad_norm": 1.5871481895446777,
      "learning_rate": 4.567417463745758e-05,
      "loss": 0.018,
      "step": 14020
    },
    {
      "epoch": 4.328910829990743,
      "grad_norm": 0.6221901774406433,
      "learning_rate": 4.567108917000926e-05,
      "loss": 0.0051,
      "step": 14030
    },
    {
      "epoch": 4.331996297439062,
      "grad_norm": 13.01141357421875,
      "learning_rate": 4.566800370256094e-05,
      "loss": 0.0498,
      "step": 14040
    },
    {
      "epoch": 4.335081764887381,
      "grad_norm": 0.9344055652618408,
      "learning_rate": 4.566491823511262e-05,
      "loss": 0.0214,
      "step": 14050
    },
    {
      "epoch": 4.338167232335699,
      "grad_norm": 0.43968623876571655,
      "learning_rate": 4.5661832767664305e-05,
      "loss": 0.0129,
      "step": 14060
    },
    {
      "epoch": 4.341252699784017,
      "grad_norm": 0.26801443099975586,
      "learning_rate": 4.565874730021599e-05,
      "loss": 0.0128,
      "step": 14070
    },
    {
      "epoch": 4.344338167232336,
      "grad_norm": 0.07658467441797256,
      "learning_rate": 4.565566183276766e-05,
      "loss": 0.0208,
      "step": 14080
    },
    {
      "epoch": 4.347423634680654,
      "grad_norm": 0.23040789365768433,
      "learning_rate": 4.565257636531935e-05,
      "loss": 0.0126,
      "step": 14090
    },
    {
      "epoch": 4.350509102128973,
      "grad_norm": 0.8663433194160461,
      "learning_rate": 4.564949089787103e-05,
      "loss": 0.0072,
      "step": 14100
    },
    {
      "epoch": 4.353594569577291,
      "grad_norm": 4.302695274353027,
      "learning_rate": 4.564640543042271e-05,
      "loss": 0.0052,
      "step": 14110
    },
    {
      "epoch": 4.356680037025609,
      "grad_norm": 0.2834096848964691,
      "learning_rate": 4.564331996297439e-05,
      "loss": 0.0031,
      "step": 14120
    },
    {
      "epoch": 4.359765504473928,
      "grad_norm": 0.5169387459754944,
      "learning_rate": 4.5640234495526075e-05,
      "loss": 0.0092,
      "step": 14130
    },
    {
      "epoch": 4.362850971922247,
      "grad_norm": 3.247364044189453,
      "learning_rate": 4.563714902807776e-05,
      "loss": 0.0149,
      "step": 14140
    },
    {
      "epoch": 4.365936439370564,
      "grad_norm": 0.2811272144317627,
      "learning_rate": 4.563406356062943e-05,
      "loss": 0.0162,
      "step": 14150
    },
    {
      "epoch": 4.369021906818883,
      "grad_norm": 0.9403014779090881,
      "learning_rate": 4.563097809318112e-05,
      "loss": 0.0162,
      "step": 14160
    },
    {
      "epoch": 4.372107374267202,
      "grad_norm": 0.44694674015045166,
      "learning_rate": 4.56278926257328e-05,
      "loss": 0.0039,
      "step": 14170
    },
    {
      "epoch": 4.37519284171552,
      "grad_norm": 2.504917860031128,
      "learning_rate": 4.562480715828448e-05,
      "loss": 0.0085,
      "step": 14180
    },
    {
      "epoch": 4.378278309163838,
      "grad_norm": 0.010846833698451519,
      "learning_rate": 4.562172169083616e-05,
      "loss": 0.0057,
      "step": 14190
    },
    {
      "epoch": 4.381363776612157,
      "grad_norm": 1.7250114679336548,
      "learning_rate": 4.5618636223387846e-05,
      "loss": 0.0212,
      "step": 14200
    },
    {
      "epoch": 4.384449244060475,
      "grad_norm": 0.44790592789649963,
      "learning_rate": 4.561555075593953e-05,
      "loss": 0.0229,
      "step": 14210
    },
    {
      "epoch": 4.387534711508794,
      "grad_norm": 0.53673255443573,
      "learning_rate": 4.561246528849121e-05,
      "loss": 0.0132,
      "step": 14220
    },
    {
      "epoch": 4.390620178957112,
      "grad_norm": 0.3580801784992218,
      "learning_rate": 4.560937982104289e-05,
      "loss": 0.0218,
      "step": 14230
    },
    {
      "epoch": 4.39370564640543,
      "grad_norm": 0.4354979395866394,
      "learning_rate": 4.560629435359457e-05,
      "loss": 0.0095,
      "step": 14240
    },
    {
      "epoch": 4.396791113853749,
      "grad_norm": 2.2785542011260986,
      "learning_rate": 4.560320888614625e-05,
      "loss": 0.0107,
      "step": 14250
    },
    {
      "epoch": 4.399876581302067,
      "grad_norm": 0.8221689462661743,
      "learning_rate": 4.560012341869794e-05,
      "loss": 0.0049,
      "step": 14260
    },
    {
      "epoch": 4.4029620487503855,
      "grad_norm": 1.749332308769226,
      "learning_rate": 4.5597037951249616e-05,
      "loss": 0.0237,
      "step": 14270
    },
    {
      "epoch": 4.406047516198704,
      "grad_norm": 0.040585100650787354,
      "learning_rate": 4.55939524838013e-05,
      "loss": 0.0023,
      "step": 14280
    },
    {
      "epoch": 4.409132983647022,
      "grad_norm": 0.20001386106014252,
      "learning_rate": 4.559086701635298e-05,
      "loss": 0.0094,
      "step": 14290
    },
    {
      "epoch": 4.412218451095341,
      "grad_norm": 2.869729995727539,
      "learning_rate": 4.5587781548904664e-05,
      "loss": 0.0173,
      "step": 14300
    },
    {
      "epoch": 4.41530391854366,
      "grad_norm": 0.07557753473520279,
      "learning_rate": 4.558469608145634e-05,
      "loss": 0.0207,
      "step": 14310
    },
    {
      "epoch": 4.418389385991977,
      "grad_norm": 3.043370485305786,
      "learning_rate": 4.558161061400802e-05,
      "loss": 0.0082,
      "step": 14320
    },
    {
      "epoch": 4.421474853440296,
      "grad_norm": 0.11851117014884949,
      "learning_rate": 4.557852514655971e-05,
      "loss": 0.025,
      "step": 14330
    },
    {
      "epoch": 4.424560320888615,
      "grad_norm": 1.3674203157424927,
      "learning_rate": 4.557543967911139e-05,
      "loss": 0.0093,
      "step": 14340
    },
    {
      "epoch": 4.427645788336933,
      "grad_norm": 0.29205024242401123,
      "learning_rate": 4.557235421166307e-05,
      "loss": 0.0034,
      "step": 14350
    },
    {
      "epoch": 4.430731255785251,
      "grad_norm": 0.7462857961654663,
      "learning_rate": 4.556926874421475e-05,
      "loss": 0.0057,
      "step": 14360
    },
    {
      "epoch": 4.43381672323357,
      "grad_norm": 1.1991093158721924,
      "learning_rate": 4.5566183276766434e-05,
      "loss": 0.0044,
      "step": 14370
    },
    {
      "epoch": 4.436902190681888,
      "grad_norm": 0.0011663242476060987,
      "learning_rate": 4.556309780931811e-05,
      "loss": 0.0092,
      "step": 14380
    },
    {
      "epoch": 4.439987658130207,
      "grad_norm": 0.8712801337242126,
      "learning_rate": 4.556001234186979e-05,
      "loss": 0.0133,
      "step": 14390
    },
    {
      "epoch": 4.443073125578525,
      "grad_norm": 2.198113441467285,
      "learning_rate": 4.555692687442148e-05,
      "loss": 0.0143,
      "step": 14400
    },
    {
      "epoch": 4.446158593026843,
      "grad_norm": 2.6980178356170654,
      "learning_rate": 4.555384140697316e-05,
      "loss": 0.0167,
      "step": 14410
    },
    {
      "epoch": 4.449244060475162,
      "grad_norm": 3.5218539237976074,
      "learning_rate": 4.555075593952484e-05,
      "loss": 0.0109,
      "step": 14420
    },
    {
      "epoch": 4.452329527923481,
      "grad_norm": 0.0032464179676026106,
      "learning_rate": 4.554767047207652e-05,
      "loss": 0.0052,
      "step": 14430
    },
    {
      "epoch": 4.4554149953717985,
      "grad_norm": 0.00617801770567894,
      "learning_rate": 4.5544585004628205e-05,
      "loss": 0.017,
      "step": 14440
    },
    {
      "epoch": 4.458500462820117,
      "grad_norm": 0.5747128129005432,
      "learning_rate": 4.554149953717988e-05,
      "loss": 0.017,
      "step": 14450
    },
    {
      "epoch": 4.461585930268436,
      "grad_norm": 0.1251470297574997,
      "learning_rate": 4.553841406973156e-05,
      "loss": 0.0058,
      "step": 14460
    },
    {
      "epoch": 4.464671397716754,
      "grad_norm": 0.3894619643688202,
      "learning_rate": 4.553532860228325e-05,
      "loss": 0.0113,
      "step": 14470
    },
    {
      "epoch": 4.4677568651650725,
      "grad_norm": 0.01874040998518467,
      "learning_rate": 4.553224313483493e-05,
      "loss": 0.0178,
      "step": 14480
    },
    {
      "epoch": 4.470842332613391,
      "grad_norm": 0.24861863255500793,
      "learning_rate": 4.552915766738661e-05,
      "loss": 0.0094,
      "step": 14490
    },
    {
      "epoch": 4.473927800061709,
      "grad_norm": 0.12025664001703262,
      "learning_rate": 4.552607219993829e-05,
      "loss": 0.0074,
      "step": 14500
    },
    {
      "epoch": 4.477013267510028,
      "grad_norm": 0.8285485506057739,
      "learning_rate": 4.5522986732489975e-05,
      "loss": 0.0116,
      "step": 14510
    },
    {
      "epoch": 4.4800987349583465,
      "grad_norm": 0.0020530875772237778,
      "learning_rate": 4.551990126504165e-05,
      "loss": 0.008,
      "step": 14520
    },
    {
      "epoch": 4.483184202406664,
      "grad_norm": 1.8966541290283203,
      "learning_rate": 4.551681579759334e-05,
      "loss": 0.0135,
      "step": 14530
    },
    {
      "epoch": 4.486269669854983,
      "grad_norm": 0.02127174660563469,
      "learning_rate": 4.551373033014502e-05,
      "loss": 0.012,
      "step": 14540
    },
    {
      "epoch": 4.489355137303302,
      "grad_norm": 0.5363849997520447,
      "learning_rate": 4.55106448626967e-05,
      "loss": 0.0185,
      "step": 14550
    },
    {
      "epoch": 4.49244060475162,
      "grad_norm": 2.9798872470855713,
      "learning_rate": 4.550755939524838e-05,
      "loss": 0.0115,
      "step": 14560
    },
    {
      "epoch": 4.495526072199938,
      "grad_norm": 1.6666120290756226,
      "learning_rate": 4.5504473927800064e-05,
      "loss": 0.0099,
      "step": 14570
    },
    {
      "epoch": 4.498611539648257,
      "grad_norm": 1.072243332862854,
      "learning_rate": 4.5501388460351746e-05,
      "loss": 0.0133,
      "step": 14580
    },
    {
      "epoch": 4.501697007096575,
      "grad_norm": 0.024613499641418457,
      "learning_rate": 4.549830299290342e-05,
      "loss": 0.0156,
      "step": 14590
    },
    {
      "epoch": 4.504782474544894,
      "grad_norm": 0.1540810763835907,
      "learning_rate": 4.549521752545511e-05,
      "loss": 0.0141,
      "step": 14600
    },
    {
      "epoch": 4.5078679419932115,
      "grad_norm": 0.4239861071109772,
      "learning_rate": 4.5492132058006793e-05,
      "loss": 0.0072,
      "step": 14610
    },
    {
      "epoch": 4.51095340944153,
      "grad_norm": 2.066356658935547,
      "learning_rate": 4.548904659055847e-05,
      "loss": 0.0157,
      "step": 14620
    },
    {
      "epoch": 4.514038876889849,
      "grad_norm": 0.603240966796875,
      "learning_rate": 4.548596112311015e-05,
      "loss": 0.0107,
      "step": 14630
    },
    {
      "epoch": 4.517124344338168,
      "grad_norm": 1.2028872966766357,
      "learning_rate": 4.5482875655661834e-05,
      "loss": 0.0065,
      "step": 14640
    },
    {
      "epoch": 4.5202098117864855,
      "grad_norm": 4.490499973297119,
      "learning_rate": 4.5479790188213517e-05,
      "loss": 0.01,
      "step": 14650
    },
    {
      "epoch": 4.523295279234804,
      "grad_norm": 0.2658461332321167,
      "learning_rate": 4.54767047207652e-05,
      "loss": 0.0032,
      "step": 14660
    },
    {
      "epoch": 4.526380746683122,
      "grad_norm": 0.7931166291236877,
      "learning_rate": 4.547361925331688e-05,
      "loss": 0.0162,
      "step": 14670
    },
    {
      "epoch": 4.529466214131441,
      "grad_norm": 2.27396297454834,
      "learning_rate": 4.5470533785868564e-05,
      "loss": 0.0122,
      "step": 14680
    },
    {
      "epoch": 4.5325516815797595,
      "grad_norm": 2.813624858856201,
      "learning_rate": 4.546744831842024e-05,
      "loss": 0.0077,
      "step": 14690
    },
    {
      "epoch": 4.535637149028078,
      "grad_norm": 0.3096902668476105,
      "learning_rate": 4.546436285097192e-05,
      "loss": 0.0104,
      "step": 14700
    },
    {
      "epoch": 4.538722616476396,
      "grad_norm": 2.146209716796875,
      "learning_rate": 4.5461277383523605e-05,
      "loss": 0.0119,
      "step": 14710
    },
    {
      "epoch": 4.541808083924715,
      "grad_norm": 0.18571454286575317,
      "learning_rate": 4.545819191607529e-05,
      "loss": 0.0171,
      "step": 14720
    },
    {
      "epoch": 4.544893551373033,
      "grad_norm": 0.10957515984773636,
      "learning_rate": 4.545510644862697e-05,
      "loss": 0.0103,
      "step": 14730
    },
    {
      "epoch": 4.547979018821351,
      "grad_norm": 0.36719200015068054,
      "learning_rate": 4.545202098117865e-05,
      "loss": 0.0177,
      "step": 14740
    },
    {
      "epoch": 4.55106448626967,
      "grad_norm": 4.026346206665039,
      "learning_rate": 4.5448935513730335e-05,
      "loss": 0.0241,
      "step": 14750
    },
    {
      "epoch": 4.554149953717988,
      "grad_norm": 0.0029622740112245083,
      "learning_rate": 4.544585004628201e-05,
      "loss": 0.0079,
      "step": 14760
    },
    {
      "epoch": 4.557235421166307,
      "grad_norm": 0.01298590563237667,
      "learning_rate": 4.54427645788337e-05,
      "loss": 0.0092,
      "step": 14770
    },
    {
      "epoch": 4.560320888614625,
      "grad_norm": 0.02392345853149891,
      "learning_rate": 4.5439679111385375e-05,
      "loss": 0.004,
      "step": 14780
    },
    {
      "epoch": 4.563406356062943,
      "grad_norm": 2.900712013244629,
      "learning_rate": 4.543659364393706e-05,
      "loss": 0.0178,
      "step": 14790
    },
    {
      "epoch": 4.566491823511262,
      "grad_norm": 0.12233532965183258,
      "learning_rate": 4.543350817648874e-05,
      "loss": 0.0058,
      "step": 14800
    },
    {
      "epoch": 4.569577290959581,
      "grad_norm": 1.9089975357055664,
      "learning_rate": 4.543042270904042e-05,
      "loss": 0.0244,
      "step": 14810
    },
    {
      "epoch": 4.5726627584078985,
      "grad_norm": 1.4113032817840576,
      "learning_rate": 4.5427337241592105e-05,
      "loss": 0.0193,
      "step": 14820
    },
    {
      "epoch": 4.575748225856217,
      "grad_norm": 2.44612979888916,
      "learning_rate": 4.542425177414378e-05,
      "loss": 0.0182,
      "step": 14830
    },
    {
      "epoch": 4.578833693304536,
      "grad_norm": 0.19056662917137146,
      "learning_rate": 4.542116630669547e-05,
      "loss": 0.0161,
      "step": 14840
    },
    {
      "epoch": 4.581919160752854,
      "grad_norm": 1.3561592102050781,
      "learning_rate": 4.5418080839247146e-05,
      "loss": 0.022,
      "step": 14850
    },
    {
      "epoch": 4.5850046282011725,
      "grad_norm": 2.159345865249634,
      "learning_rate": 4.541499537179883e-05,
      "loss": 0.0096,
      "step": 14860
    },
    {
      "epoch": 4.588090095649491,
      "grad_norm": 1.0455044507980347,
      "learning_rate": 4.541190990435051e-05,
      "loss": 0.0197,
      "step": 14870
    },
    {
      "epoch": 4.591175563097809,
      "grad_norm": 1.8649572134017944,
      "learning_rate": 4.540882443690219e-05,
      "loss": 0.0225,
      "step": 14880
    },
    {
      "epoch": 4.594261030546128,
      "grad_norm": 3.3775200843811035,
      "learning_rate": 4.5405738969453876e-05,
      "loss": 0.0191,
      "step": 14890
    },
    {
      "epoch": 4.5973464979944465,
      "grad_norm": 0.03014122135937214,
      "learning_rate": 4.540265350200555e-05,
      "loss": 0.0114,
      "step": 14900
    },
    {
      "epoch": 4.600431965442764,
      "grad_norm": 4.047933101654053,
      "learning_rate": 4.539956803455724e-05,
      "loss": 0.017,
      "step": 14910
    },
    {
      "epoch": 4.603517432891083,
      "grad_norm": 0.9250238537788391,
      "learning_rate": 4.5396482567108916e-05,
      "loss": 0.0087,
      "step": 14920
    },
    {
      "epoch": 4.606602900339402,
      "grad_norm": 0.4847596287727356,
      "learning_rate": 4.53933970996606e-05,
      "loss": 0.0117,
      "step": 14930
    },
    {
      "epoch": 4.60968836778772,
      "grad_norm": 0.4488896429538727,
      "learning_rate": 4.539031163221228e-05,
      "loss": 0.0125,
      "step": 14940
    },
    {
      "epoch": 4.612773835236038,
      "grad_norm": 1.7297875881195068,
      "learning_rate": 4.5387226164763964e-05,
      "loss": 0.02,
      "step": 14950
    },
    {
      "epoch": 4.615859302684357,
      "grad_norm": 0.11698947101831436,
      "learning_rate": 4.5384140697315646e-05,
      "loss": 0.011,
      "step": 14960
    },
    {
      "epoch": 4.618944770132675,
      "grad_norm": 1.6379446983337402,
      "learning_rate": 4.538105522986732e-05,
      "loss": 0.0116,
      "step": 14970
    },
    {
      "epoch": 4.622030237580994,
      "grad_norm": 0.1875704973936081,
      "learning_rate": 4.537796976241901e-05,
      "loss": 0.0197,
      "step": 14980
    },
    {
      "epoch": 4.625115705029312,
      "grad_norm": 2.3097918033599854,
      "learning_rate": 4.537488429497069e-05,
      "loss": 0.012,
      "step": 14990
    },
    {
      "epoch": 4.62820117247763,
      "grad_norm": 0.021803369745612144,
      "learning_rate": 4.537179882752237e-05,
      "loss": 0.0115,
      "step": 15000
    },
    {
      "epoch": 4.631286639925949,
      "grad_norm": 0.11280474811792374,
      "learning_rate": 4.536871336007406e-05,
      "loss": 0.0275,
      "step": 15010
    },
    {
      "epoch": 4.634372107374267,
      "grad_norm": 1.8137598037719727,
      "learning_rate": 4.5365627892625734e-05,
      "loss": 0.0134,
      "step": 15020
    },
    {
      "epoch": 4.6374575748225855,
      "grad_norm": 0.03186147287487984,
      "learning_rate": 4.536254242517742e-05,
      "loss": 0.0031,
      "step": 15030
    },
    {
      "epoch": 4.640543042270904,
      "grad_norm": 0.021476028487086296,
      "learning_rate": 4.53594569577291e-05,
      "loss": 0.008,
      "step": 15040
    },
    {
      "epoch": 4.643628509719223,
      "grad_norm": 0.6715227365493774,
      "learning_rate": 4.535637149028078e-05,
      "loss": 0.0159,
      "step": 15050
    },
    {
      "epoch": 4.646713977167541,
      "grad_norm": 0.1452142894268036,
      "learning_rate": 4.535328602283246e-05,
      "loss": 0.0102,
      "step": 15060
    },
    {
      "epoch": 4.6497994446158595,
      "grad_norm": 0.9138184785842896,
      "learning_rate": 4.535020055538414e-05,
      "loss": 0.0075,
      "step": 15070
    },
    {
      "epoch": 4.652884912064177,
      "grad_norm": 0.05479595810174942,
      "learning_rate": 4.534711508793583e-05,
      "loss": 0.0099,
      "step": 15080
    },
    {
      "epoch": 4.655970379512496,
      "grad_norm": 0.6003912091255188,
      "learning_rate": 4.5344029620487505e-05,
      "loss": 0.015,
      "step": 15090
    },
    {
      "epoch": 4.659055846960815,
      "grad_norm": 0.05791381746530533,
      "learning_rate": 4.534094415303919e-05,
      "loss": 0.0054,
      "step": 15100
    },
    {
      "epoch": 4.662141314409133,
      "grad_norm": 0.007077537942677736,
      "learning_rate": 4.533785868559087e-05,
      "loss": 0.0022,
      "step": 15110
    },
    {
      "epoch": 4.665226781857451,
      "grad_norm": 0.13108870387077332,
      "learning_rate": 4.533477321814255e-05,
      "loss": 0.0137,
      "step": 15120
    },
    {
      "epoch": 4.66831224930577,
      "grad_norm": 0.01758045144379139,
      "learning_rate": 4.5331687750694235e-05,
      "loss": 0.021,
      "step": 15130
    },
    {
      "epoch": 4.671397716754088,
      "grad_norm": 0.05642889812588692,
      "learning_rate": 4.532860228324591e-05,
      "loss": 0.0033,
      "step": 15140
    },
    {
      "epoch": 4.674483184202407,
      "grad_norm": 1.4356375932693481,
      "learning_rate": 4.53255168157976e-05,
      "loss": 0.0137,
      "step": 15150
    },
    {
      "epoch": 4.677568651650725,
      "grad_norm": 0.5842714905738831,
      "learning_rate": 4.5322431348349275e-05,
      "loss": 0.0092,
      "step": 15160
    },
    {
      "epoch": 4.680654119099043,
      "grad_norm": 1.4300442934036255,
      "learning_rate": 4.531934588090096e-05,
      "loss": 0.0172,
      "step": 15170
    },
    {
      "epoch": 4.683739586547362,
      "grad_norm": 0.8497487306594849,
      "learning_rate": 4.531626041345264e-05,
      "loss": 0.0044,
      "step": 15180
    },
    {
      "epoch": 4.686825053995681,
      "grad_norm": 0.2850475311279297,
      "learning_rate": 4.531317494600432e-05,
      "loss": 0.0113,
      "step": 15190
    },
    {
      "epoch": 4.6899105214439984,
      "grad_norm": 1.4218772649765015,
      "learning_rate": 4.5310089478556005e-05,
      "loss": 0.0205,
      "step": 15200
    },
    {
      "epoch": 4.692995988892317,
      "grad_norm": 0.11017671972513199,
      "learning_rate": 4.530700401110768e-05,
      "loss": 0.0203,
      "step": 15210
    },
    {
      "epoch": 4.696081456340636,
      "grad_norm": 0.1781492680311203,
      "learning_rate": 4.530391854365937e-05,
      "loss": 0.0156,
      "step": 15220
    },
    {
      "epoch": 4.699166923788954,
      "grad_norm": 5.016216278076172,
      "learning_rate": 4.5300833076211046e-05,
      "loss": 0.0193,
      "step": 15230
    },
    {
      "epoch": 4.7022523912372725,
      "grad_norm": 0.0050734770484268665,
      "learning_rate": 4.529774760876273e-05,
      "loss": 0.0192,
      "step": 15240
    },
    {
      "epoch": 4.705337858685591,
      "grad_norm": 0.14617322385311127,
      "learning_rate": 4.529466214131441e-05,
      "loss": 0.0185,
      "step": 15250
    },
    {
      "epoch": 4.708423326133909,
      "grad_norm": 0.46342378854751587,
      "learning_rate": 4.5291576673866093e-05,
      "loss": 0.013,
      "step": 15260
    },
    {
      "epoch": 4.711508793582228,
      "grad_norm": 0.1632327139377594,
      "learning_rate": 4.5288491206417776e-05,
      "loss": 0.03,
      "step": 15270
    },
    {
      "epoch": 4.7145942610305465,
      "grad_norm": 0.48361825942993164,
      "learning_rate": 4.528540573896946e-05,
      "loss": 0.0118,
      "step": 15280
    },
    {
      "epoch": 4.717679728478864,
      "grad_norm": 1.8635928630828857,
      "learning_rate": 4.528232027152114e-05,
      "loss": 0.0124,
      "step": 15290
    },
    {
      "epoch": 4.720765195927183,
      "grad_norm": 4.408708095550537,
      "learning_rate": 4.5279234804072817e-05,
      "loss": 0.017,
      "step": 15300
    },
    {
      "epoch": 4.723850663375502,
      "grad_norm": 0.018028950318694115,
      "learning_rate": 4.52761493366245e-05,
      "loss": 0.0078,
      "step": 15310
    },
    {
      "epoch": 4.72693613082382,
      "grad_norm": 0.0017499891109764576,
      "learning_rate": 4.527306386917618e-05,
      "loss": 0.0144,
      "step": 15320
    },
    {
      "epoch": 4.730021598272138,
      "grad_norm": 4.613059043884277,
      "learning_rate": 4.5269978401727864e-05,
      "loss": 0.0204,
      "step": 15330
    },
    {
      "epoch": 4.733107065720457,
      "grad_norm": 1.4391006231307983,
      "learning_rate": 4.5266892934279547e-05,
      "loss": 0.0105,
      "step": 15340
    },
    {
      "epoch": 4.736192533168775,
      "grad_norm": 0.0025566613767296076,
      "learning_rate": 4.526380746683123e-05,
      "loss": 0.0083,
      "step": 15350
    },
    {
      "epoch": 4.739278000617094,
      "grad_norm": 1.6883257627487183,
      "learning_rate": 4.526072199938291e-05,
      "loss": 0.0161,
      "step": 15360
    },
    {
      "epoch": 4.742363468065411,
      "grad_norm": 0.29691606760025024,
      "learning_rate": 4.525763653193459e-05,
      "loss": 0.0084,
      "step": 15370
    },
    {
      "epoch": 4.74544893551373,
      "grad_norm": 2.2590911388397217,
      "learning_rate": 4.525455106448627e-05,
      "loss": 0.0183,
      "step": 15380
    },
    {
      "epoch": 4.748534402962049,
      "grad_norm": 0.09045302122831345,
      "learning_rate": 4.525146559703795e-05,
      "loss": 0.0052,
      "step": 15390
    },
    {
      "epoch": 4.751619870410368,
      "grad_norm": 3.7559170722961426,
      "learning_rate": 4.5248380129589635e-05,
      "loss": 0.014,
      "step": 15400
    },
    {
      "epoch": 4.754705337858685,
      "grad_norm": 0.1589173674583435,
      "learning_rate": 4.524529466214132e-05,
      "loss": 0.0278,
      "step": 15410
    },
    {
      "epoch": 4.757790805307004,
      "grad_norm": 0.1069880798459053,
      "learning_rate": 4.5242209194693e-05,
      "loss": 0.0077,
      "step": 15420
    },
    {
      "epoch": 4.760876272755322,
      "grad_norm": 0.233368381857872,
      "learning_rate": 4.523912372724468e-05,
      "loss": 0.0146,
      "step": 15430
    },
    {
      "epoch": 4.763961740203641,
      "grad_norm": 1.3953773975372314,
      "learning_rate": 4.523603825979636e-05,
      "loss": 0.0238,
      "step": 15440
    },
    {
      "epoch": 4.767047207651959,
      "grad_norm": 1.7734055519104004,
      "learning_rate": 4.523295279234804e-05,
      "loss": 0.0195,
      "step": 15450
    },
    {
      "epoch": 4.770132675100278,
      "grad_norm": 1.2589409351348877,
      "learning_rate": 4.522986732489972e-05,
      "loss": 0.023,
      "step": 15460
    },
    {
      "epoch": 4.773218142548596,
      "grad_norm": 0.721833348274231,
      "learning_rate": 4.5226781857451405e-05,
      "loss": 0.0249,
      "step": 15470
    },
    {
      "epoch": 4.776303609996915,
      "grad_norm": 1.9334228038787842,
      "learning_rate": 4.522369639000309e-05,
      "loss": 0.0132,
      "step": 15480
    },
    {
      "epoch": 4.779389077445233,
      "grad_norm": 0.5341910123825073,
      "learning_rate": 4.522061092255477e-05,
      "loss": 0.0059,
      "step": 15490
    },
    {
      "epoch": 4.782474544893551,
      "grad_norm": 0.3352513313293457,
      "learning_rate": 4.521752545510645e-05,
      "loss": 0.0196,
      "step": 15500
    },
    {
      "epoch": 4.78556001234187,
      "grad_norm": 1.7120964527130127,
      "learning_rate": 4.521443998765813e-05,
      "loss": 0.0146,
      "step": 15510
    },
    {
      "epoch": 4.788645479790188,
      "grad_norm": 1.2087656259536743,
      "learning_rate": 4.521135452020982e-05,
      "loss": 0.0112,
      "step": 15520
    },
    {
      "epoch": 4.791730947238507,
      "grad_norm": 1.5021517276763916,
      "learning_rate": 4.52082690527615e-05,
      "loss": 0.0091,
      "step": 15530
    },
    {
      "epoch": 4.794816414686825,
      "grad_norm": 0.6566817760467529,
      "learning_rate": 4.5205183585313176e-05,
      "loss": 0.0171,
      "step": 15540
    },
    {
      "epoch": 4.797901882135143,
      "grad_norm": 3.2936902046203613,
      "learning_rate": 4.520209811786486e-05,
      "loss": 0.0157,
      "step": 15550
    },
    {
      "epoch": 4.800987349583462,
      "grad_norm": 0.06864804029464722,
      "learning_rate": 4.519901265041654e-05,
      "loss": 0.0098,
      "step": 15560
    },
    {
      "epoch": 4.804072817031781,
      "grad_norm": 0.1787082701921463,
      "learning_rate": 4.519592718296822e-05,
      "loss": 0.014,
      "step": 15570
    },
    {
      "epoch": 4.807158284480098,
      "grad_norm": 0.17160986363887787,
      "learning_rate": 4.51928417155199e-05,
      "loss": 0.0076,
      "step": 15580
    },
    {
      "epoch": 4.810243751928417,
      "grad_norm": 3.4801340103149414,
      "learning_rate": 4.518975624807159e-05,
      "loss": 0.006,
      "step": 15590
    },
    {
      "epoch": 4.813329219376736,
      "grad_norm": 0.440928190946579,
      "learning_rate": 4.518667078062327e-05,
      "loss": 0.0042,
      "step": 15600
    },
    {
      "epoch": 4.816414686825054,
      "grad_norm": 1.1088789701461792,
      "learning_rate": 4.5183585313174946e-05,
      "loss": 0.0061,
      "step": 15610
    },
    {
      "epoch": 4.819500154273372,
      "grad_norm": 0.3096362054347992,
      "learning_rate": 4.518049984572663e-05,
      "loss": 0.0061,
      "step": 15620
    },
    {
      "epoch": 4.822585621721691,
      "grad_norm": 1.2268491983413696,
      "learning_rate": 4.517741437827831e-05,
      "loss": 0.019,
      "step": 15630
    },
    {
      "epoch": 4.825671089170009,
      "grad_norm": 0.46036723256111145,
      "learning_rate": 4.5174328910829994e-05,
      "loss": 0.005,
      "step": 15640
    },
    {
      "epoch": 4.828756556618328,
      "grad_norm": 1.0725542306900024,
      "learning_rate": 4.517124344338167e-05,
      "loss": 0.0084,
      "step": 15650
    },
    {
      "epoch": 4.831842024066646,
      "grad_norm": 0.15236519277095795,
      "learning_rate": 4.516815797593336e-05,
      "loss": 0.0135,
      "step": 15660
    },
    {
      "epoch": 4.834927491514964,
      "grad_norm": 0.03236336633563042,
      "learning_rate": 4.516507250848504e-05,
      "loss": 0.0067,
      "step": 15670
    },
    {
      "epoch": 4.838012958963283,
      "grad_norm": 0.3176511526107788,
      "learning_rate": 4.516198704103672e-05,
      "loss": 0.0058,
      "step": 15680
    },
    {
      "epoch": 4.841098426411602,
      "grad_norm": 2.466325283050537,
      "learning_rate": 4.51589015735884e-05,
      "loss": 0.0076,
      "step": 15690
    },
    {
      "epoch": 4.8441838938599195,
      "grad_norm": 2.683225154876709,
      "learning_rate": 4.515581610614008e-05,
      "loss": 0.0101,
      "step": 15700
    },
    {
      "epoch": 4.847269361308238,
      "grad_norm": 0.03660350665450096,
      "learning_rate": 4.5152730638691764e-05,
      "loss": 0.0119,
      "step": 15710
    },
    {
      "epoch": 4.850354828756557,
      "grad_norm": 0.03014606051146984,
      "learning_rate": 4.514964517124344e-05,
      "loss": 0.0076,
      "step": 15720
    },
    {
      "epoch": 4.853440296204875,
      "grad_norm": 0.007763666566461325,
      "learning_rate": 4.514655970379513e-05,
      "loss": 0.0102,
      "step": 15730
    },
    {
      "epoch": 4.8565257636531936,
      "grad_norm": 0.03538857400417328,
      "learning_rate": 4.514347423634681e-05,
      "loss": 0.0087,
      "step": 15740
    },
    {
      "epoch": 4.859611231101512,
      "grad_norm": 3.8982431888580322,
      "learning_rate": 4.514038876889849e-05,
      "loss": 0.0115,
      "step": 15750
    },
    {
      "epoch": 4.86269669854983,
      "grad_norm": 0.009681101888418198,
      "learning_rate": 4.513730330145018e-05,
      "loss": 0.0167,
      "step": 15760
    },
    {
      "epoch": 4.865782165998149,
      "grad_norm": 0.39880505204200745,
      "learning_rate": 4.513421783400185e-05,
      "loss": 0.0191,
      "step": 15770
    },
    {
      "epoch": 4.868867633446467,
      "grad_norm": 0.09847963601350784,
      "learning_rate": 4.5131132366553535e-05,
      "loss": 0.0123,
      "step": 15780
    },
    {
      "epoch": 4.871953100894785,
      "grad_norm": 0.687276303768158,
      "learning_rate": 4.512804689910522e-05,
      "loss": 0.0095,
      "step": 15790
    },
    {
      "epoch": 4.875038568343104,
      "grad_norm": 0.09401138126850128,
      "learning_rate": 4.51249614316569e-05,
      "loss": 0.009,
      "step": 15800
    },
    {
      "epoch": 4.878124035791423,
      "grad_norm": 4.111306667327881,
      "learning_rate": 4.512187596420858e-05,
      "loss": 0.0116,
      "step": 15810
    },
    {
      "epoch": 4.881209503239741,
      "grad_norm": 0.4289659559726715,
      "learning_rate": 4.511879049676026e-05,
      "loss": 0.003,
      "step": 15820
    },
    {
      "epoch": 4.884294970688059,
      "grad_norm": 0.0387490950524807,
      "learning_rate": 4.511570502931195e-05,
      "loss": 0.0209,
      "step": 15830
    },
    {
      "epoch": 4.887380438136377,
      "grad_norm": 0.21393372118473053,
      "learning_rate": 4.511261956186362e-05,
      "loss": 0.0026,
      "step": 15840
    },
    {
      "epoch": 4.890465905584696,
      "grad_norm": 0.1724623739719391,
      "learning_rate": 4.5109534094415305e-05,
      "loss": 0.0133,
      "step": 15850
    },
    {
      "epoch": 4.893551373033015,
      "grad_norm": 1.516015887260437,
      "learning_rate": 4.510644862696699e-05,
      "loss": 0.0096,
      "step": 15860
    },
    {
      "epoch": 4.896636840481333,
      "grad_norm": 0.011296011507511139,
      "learning_rate": 4.510336315951867e-05,
      "loss": 0.0216,
      "step": 15870
    },
    {
      "epoch": 4.899722307929651,
      "grad_norm": 0.27749499678611755,
      "learning_rate": 4.510027769207035e-05,
      "loss": 0.0138,
      "step": 15880
    },
    {
      "epoch": 4.90280777537797,
      "grad_norm": 0.35044997930526733,
      "learning_rate": 4.509719222462203e-05,
      "loss": 0.005,
      "step": 15890
    },
    {
      "epoch": 4.905893242826288,
      "grad_norm": 0.48865577578544617,
      "learning_rate": 4.509410675717372e-05,
      "loss": 0.0083,
      "step": 15900
    },
    {
      "epoch": 4.9089787102746065,
      "grad_norm": 2.703721046447754,
      "learning_rate": 4.5091021289725393e-05,
      "loss": 0.0059,
      "step": 15910
    },
    {
      "epoch": 4.912064177722925,
      "grad_norm": 0.12205740064382553,
      "learning_rate": 4.5087935822277076e-05,
      "loss": 0.0158,
      "step": 15920
    },
    {
      "epoch": 4.915149645171243,
      "grad_norm": 0.002559967339038849,
      "learning_rate": 4.508485035482876e-05,
      "loss": 0.0123,
      "step": 15930
    },
    {
      "epoch": 4.918235112619562,
      "grad_norm": 0.010146727785468102,
      "learning_rate": 4.508176488738044e-05,
      "loss": 0.0027,
      "step": 15940
    },
    {
      "epoch": 4.9213205800678805,
      "grad_norm": 0.07307925820350647,
      "learning_rate": 4.507867941993212e-05,
      "loss": 0.0179,
      "step": 15950
    },
    {
      "epoch": 4.924406047516198,
      "grad_norm": 0.2354421764612198,
      "learning_rate": 4.50755939524838e-05,
      "loss": 0.0209,
      "step": 15960
    },
    {
      "epoch": 4.927491514964517,
      "grad_norm": 0.06779259443283081,
      "learning_rate": 4.507250848503549e-05,
      "loss": 0.0126,
      "step": 15970
    },
    {
      "epoch": 4.930576982412836,
      "grad_norm": 1.0007117986679077,
      "learning_rate": 4.5069423017587164e-05,
      "loss": 0.0139,
      "step": 15980
    },
    {
      "epoch": 4.933662449861154,
      "grad_norm": 0.02600502409040928,
      "learning_rate": 4.5066337550138847e-05,
      "loss": 0.013,
      "step": 15990
    },
    {
      "epoch": 4.936747917309472,
      "grad_norm": 2.3622934818267822,
      "learning_rate": 4.5063252082690536e-05,
      "loss": 0.0149,
      "step": 16000
    },
    {
      "epoch": 4.939833384757791,
      "grad_norm": 2.78434157371521,
      "learning_rate": 4.506016661524221e-05,
      "loss": 0.0092,
      "step": 16010
    },
    {
      "epoch": 4.942918852206109,
      "grad_norm": 0.04727852717041969,
      "learning_rate": 4.5057081147793894e-05,
      "loss": 0.0155,
      "step": 16020
    },
    {
      "epoch": 4.946004319654428,
      "grad_norm": 1.7159130573272705,
      "learning_rate": 4.5053995680345576e-05,
      "loss": 0.0101,
      "step": 16030
    },
    {
      "epoch": 4.949089787102746,
      "grad_norm": 0.009631386026740074,
      "learning_rate": 4.505091021289726e-05,
      "loss": 0.0104,
      "step": 16040
    },
    {
      "epoch": 4.952175254551064,
      "grad_norm": 3.524862289428711,
      "learning_rate": 4.5047824745448935e-05,
      "loss": 0.0061,
      "step": 16050
    },
    {
      "epoch": 4.955260721999383,
      "grad_norm": 0.7282890677452087,
      "learning_rate": 4.504473927800062e-05,
      "loss": 0.0056,
      "step": 16060
    },
    {
      "epoch": 4.958346189447702,
      "grad_norm": 1.4171080589294434,
      "learning_rate": 4.5041653810552306e-05,
      "loss": 0.0101,
      "step": 16070
    },
    {
      "epoch": 4.9614316568960195,
      "grad_norm": 0.447787880897522,
      "learning_rate": 4.503856834310398e-05,
      "loss": 0.0058,
      "step": 16080
    },
    {
      "epoch": 4.964517124344338,
      "grad_norm": 2.8111722469329834,
      "learning_rate": 4.5035482875655665e-05,
      "loss": 0.0096,
      "step": 16090
    },
    {
      "epoch": 4.967602591792657,
      "grad_norm": 0.012382092885673046,
      "learning_rate": 4.503239740820735e-05,
      "loss": 0.0202,
      "step": 16100
    },
    {
      "epoch": 4.970688059240975,
      "grad_norm": 0.06503067910671234,
      "learning_rate": 4.502931194075903e-05,
      "loss": 0.0098,
      "step": 16110
    },
    {
      "epoch": 4.9737735266892935,
      "grad_norm": 0.3533759117126465,
      "learning_rate": 4.5026226473310705e-05,
      "loss": 0.0111,
      "step": 16120
    },
    {
      "epoch": 4.976858994137612,
      "grad_norm": 0.2634517550468445,
      "learning_rate": 4.502314100586239e-05,
      "loss": 0.0151,
      "step": 16130
    },
    {
      "epoch": 4.97994446158593,
      "grad_norm": 0.04736311733722687,
      "learning_rate": 4.502005553841408e-05,
      "loss": 0.0104,
      "step": 16140
    },
    {
      "epoch": 4.983029929034249,
      "grad_norm": 0.0992303341627121,
      "learning_rate": 4.501697007096575e-05,
      "loss": 0.0055,
      "step": 16150
    },
    {
      "epoch": 4.9861153964825675,
      "grad_norm": 0.037124741822481155,
      "learning_rate": 4.5013884603517435e-05,
      "loss": 0.0066,
      "step": 16160
    },
    {
      "epoch": 4.989200863930885,
      "grad_norm": 1.9338123798370361,
      "learning_rate": 4.501079913606912e-05,
      "loss": 0.0049,
      "step": 16170
    },
    {
      "epoch": 4.992286331379204,
      "grad_norm": 0.03143240511417389,
      "learning_rate": 4.50077136686208e-05,
      "loss": 0.0043,
      "step": 16180
    },
    {
      "epoch": 4.995371798827522,
      "grad_norm": 0.5906786918640137,
      "learning_rate": 4.5004628201172476e-05,
      "loss": 0.0067,
      "step": 16190
    },
    {
      "epoch": 4.998457266275841,
      "grad_norm": 0.5589767694473267,
      "learning_rate": 4.500154273372416e-05,
      "loss": 0.0077,
      "step": 16200
    },
    {
      "epoch": 5.0,
      "eval_accuracy_branch1": 0.9970969204208984,
      "eval_accuracy_branch2": 0.43656144208790254,
      "eval_f1_branch1": 0.9962232455030295,
      "eval_f1_branch2": 0.4337868524000886,
      "eval_loss": 0.0026330521795898676,
      "eval_precision_branch1": 0.9961974978937714,
      "eval_precision_branch2": 0.519912236969203,
      "eval_recall_branch1": 0.9962745053684743,
      "eval_recall_branch2": 0.5173823095396546,
      "eval_runtime": 237.6069,
      "eval_samples_per_second": 436.364,
      "eval_steps_per_second": 54.548,
      "step": 16205
    },
    {
      "epoch": 5.001542733724159,
      "grad_norm": 0.08906827121973038,
      "learning_rate": 4.499845726627585e-05,
      "loss": 0.0045,
      "step": 16210
    },
    {
      "epoch": 5.004628201172477,
      "grad_norm": 0.031131543219089508,
      "learning_rate": 4.499537179882752e-05,
      "loss": 0.0049,
      "step": 16220
    },
    {
      "epoch": 5.007713668620796,
      "grad_norm": 0.22039853036403656,
      "learning_rate": 4.4992286331379206e-05,
      "loss": 0.0014,
      "step": 16230
    },
    {
      "epoch": 5.010799136069115,
      "grad_norm": 0.43917563557624817,
      "learning_rate": 4.498920086393089e-05,
      "loss": 0.0036,
      "step": 16240
    },
    {
      "epoch": 5.0138846035174325,
      "grad_norm": 1.1026012897491455,
      "learning_rate": 4.498611539648257e-05,
      "loss": 0.006,
      "step": 16250
    },
    {
      "epoch": 5.016970070965751,
      "grad_norm": 0.09597975760698318,
      "learning_rate": 4.4983029929034246e-05,
      "loss": 0.0129,
      "step": 16260
    },
    {
      "epoch": 5.02005553841407,
      "grad_norm": 0.04113505408167839,
      "learning_rate": 4.4979944461585936e-05,
      "loss": 0.0107,
      "step": 16270
    },
    {
      "epoch": 5.023141005862388,
      "grad_norm": 0.01555646676570177,
      "learning_rate": 4.497685899413762e-05,
      "loss": 0.0264,
      "step": 16280
    },
    {
      "epoch": 5.0262264733107065,
      "grad_norm": 2.6540534496307373,
      "learning_rate": 4.4973773526689294e-05,
      "loss": 0.0234,
      "step": 16290
    },
    {
      "epoch": 5.029311940759025,
      "grad_norm": 0.6150976419448853,
      "learning_rate": 4.4970688059240976e-05,
      "loss": 0.0044,
      "step": 16300
    },
    {
      "epoch": 5.032397408207343,
      "grad_norm": 0.06151686608791351,
      "learning_rate": 4.496760259179266e-05,
      "loss": 0.0112,
      "step": 16310
    },
    {
      "epoch": 5.035482875655662,
      "grad_norm": 0.6536204218864441,
      "learning_rate": 4.496451712434434e-05,
      "loss": 0.0047,
      "step": 16320
    },
    {
      "epoch": 5.0385683431039805,
      "grad_norm": 0.035594187676906586,
      "learning_rate": 4.496143165689602e-05,
      "loss": 0.0065,
      "step": 16330
    },
    {
      "epoch": 5.041653810552298,
      "grad_norm": 0.37793639302253723,
      "learning_rate": 4.4958346189447706e-05,
      "loss": 0.0177,
      "step": 16340
    },
    {
      "epoch": 5.044739278000617,
      "grad_norm": 1.7443978786468506,
      "learning_rate": 4.495526072199939e-05,
      "loss": 0.009,
      "step": 16350
    },
    {
      "epoch": 5.047824745448936,
      "grad_norm": 0.04524870589375496,
      "learning_rate": 4.4952175254551064e-05,
      "loss": 0.0034,
      "step": 16360
    },
    {
      "epoch": 5.050910212897254,
      "grad_norm": 2.3249399662017822,
      "learning_rate": 4.494908978710275e-05,
      "loss": 0.007,
      "step": 16370
    },
    {
      "epoch": 5.053995680345572,
      "grad_norm": 0.26005101203918457,
      "learning_rate": 4.494600431965443e-05,
      "loss": 0.0101,
      "step": 16380
    },
    {
      "epoch": 5.057081147793891,
      "grad_norm": 0.054399989545345306,
      "learning_rate": 4.494291885220611e-05,
      "loss": 0.0101,
      "step": 16390
    },
    {
      "epoch": 5.060166615242209,
      "grad_norm": 0.19694094359874725,
      "learning_rate": 4.4939833384757794e-05,
      "loss": 0.0069,
      "step": 16400
    },
    {
      "epoch": 5.063252082690528,
      "grad_norm": 0.1944621056318283,
      "learning_rate": 4.493674791730948e-05,
      "loss": 0.0047,
      "step": 16410
    },
    {
      "epoch": 5.066337550138846,
      "grad_norm": 0.013091661036014557,
      "learning_rate": 4.493366244986116e-05,
      "loss": 0.0076,
      "step": 16420
    },
    {
      "epoch": 5.069423017587164,
      "grad_norm": 1.6027425527572632,
      "learning_rate": 4.4930576982412835e-05,
      "loss": 0.0048,
      "step": 16430
    },
    {
      "epoch": 5.072508485035483,
      "grad_norm": 1.2674317359924316,
      "learning_rate": 4.492749151496452e-05,
      "loss": 0.0161,
      "step": 16440
    },
    {
      "epoch": 5.075593952483802,
      "grad_norm": 2.230070114135742,
      "learning_rate": 4.49244060475162e-05,
      "loss": 0.0075,
      "step": 16450
    },
    {
      "epoch": 5.0786794199321195,
      "grad_norm": 0.006252087652683258,
      "learning_rate": 4.492132058006788e-05,
      "loss": 0.0069,
      "step": 16460
    },
    {
      "epoch": 5.081764887380438,
      "grad_norm": 0.005219650454819202,
      "learning_rate": 4.4918235112619565e-05,
      "loss": 0.0088,
      "step": 16470
    },
    {
      "epoch": 5.084850354828757,
      "grad_norm": 2.3965139389038086,
      "learning_rate": 4.491514964517125e-05,
      "loss": 0.0172,
      "step": 16480
    },
    {
      "epoch": 5.087935822277075,
      "grad_norm": 1.3625571727752686,
      "learning_rate": 4.491206417772293e-05,
      "loss": 0.0021,
      "step": 16490
    },
    {
      "epoch": 5.0910212897253935,
      "grad_norm": 0.3726576268672943,
      "learning_rate": 4.4908978710274605e-05,
      "loss": 0.0104,
      "step": 16500
    },
    {
      "epoch": 5.094106757173712,
      "grad_norm": 0.0007489178096875548,
      "learning_rate": 4.4905893242826295e-05,
      "loss": 0.0044,
      "step": 16510
    },
    {
      "epoch": 5.09719222462203,
      "grad_norm": 2.3139355182647705,
      "learning_rate": 4.490280777537797e-05,
      "loss": 0.0102,
      "step": 16520
    },
    {
      "epoch": 5.100277692070349,
      "grad_norm": 5.1383538246154785,
      "learning_rate": 4.489972230792965e-05,
      "loss": 0.0114,
      "step": 16530
    },
    {
      "epoch": 5.1033631595186675,
      "grad_norm": 3.76808500289917,
      "learning_rate": 4.4896636840481335e-05,
      "loss": 0.0153,
      "step": 16540
    },
    {
      "epoch": 5.106448626966985,
      "grad_norm": 1.697879672050476,
      "learning_rate": 4.489355137303302e-05,
      "loss": 0.0082,
      "step": 16550
    },
    {
      "epoch": 5.109534094415304,
      "grad_norm": 0.11885848641395569,
      "learning_rate": 4.48904659055847e-05,
      "loss": 0.0141,
      "step": 16560
    },
    {
      "epoch": 5.112619561863623,
      "grad_norm": 0.035928141325712204,
      "learning_rate": 4.4887380438136376e-05,
      "loss": 0.0172,
      "step": 16570
    },
    {
      "epoch": 5.115705029311941,
      "grad_norm": 0.6622852683067322,
      "learning_rate": 4.4884294970688065e-05,
      "loss": 0.0116,
      "step": 16580
    },
    {
      "epoch": 5.118790496760259,
      "grad_norm": 0.8231230974197388,
      "learning_rate": 4.488120950323974e-05,
      "loss": 0.0108,
      "step": 16590
    },
    {
      "epoch": 5.121875964208577,
      "grad_norm": 0.9517918229103088,
      "learning_rate": 4.4878124035791423e-05,
      "loss": 0.0103,
      "step": 16600
    },
    {
      "epoch": 5.124961431656896,
      "grad_norm": 4.40701961517334,
      "learning_rate": 4.4875038568343106e-05,
      "loss": 0.0156,
      "step": 16610
    },
    {
      "epoch": 5.128046899105215,
      "grad_norm": 0.295044869184494,
      "learning_rate": 4.487195310089479e-05,
      "loss": 0.0065,
      "step": 16620
    },
    {
      "epoch": 5.131132366553532,
      "grad_norm": 1.7426379919052124,
      "learning_rate": 4.486886763344647e-05,
      "loss": 0.0046,
      "step": 16630
    },
    {
      "epoch": 5.134217834001851,
      "grad_norm": 0.2684710621833801,
      "learning_rate": 4.4865782165998147e-05,
      "loss": 0.0053,
      "step": 16640
    },
    {
      "epoch": 5.13730330145017,
      "grad_norm": 4.197202205657959,
      "learning_rate": 4.4862696698549836e-05,
      "loss": 0.0092,
      "step": 16650
    },
    {
      "epoch": 5.140388768898488,
      "grad_norm": 0.012456836178898811,
      "learning_rate": 4.485961123110151e-05,
      "loss": 0.0028,
      "step": 16660
    },
    {
      "epoch": 5.1434742363468064,
      "grad_norm": 0.40103721618652344,
      "learning_rate": 4.4856525763653194e-05,
      "loss": 0.0146,
      "step": 16670
    },
    {
      "epoch": 5.146559703795125,
      "grad_norm": 0.01300046220421791,
      "learning_rate": 4.4853440296204876e-05,
      "loss": 0.0084,
      "step": 16680
    },
    {
      "epoch": 5.149645171243443,
      "grad_norm": 0.7218863368034363,
      "learning_rate": 4.485035482875656e-05,
      "loss": 0.0072,
      "step": 16690
    },
    {
      "epoch": 5.152730638691762,
      "grad_norm": 1.2746787071228027,
      "learning_rate": 4.484726936130824e-05,
      "loss": 0.0051,
      "step": 16700
    },
    {
      "epoch": 5.1558161061400805,
      "grad_norm": 0.43976902961730957,
      "learning_rate": 4.484418389385992e-05,
      "loss": 0.0129,
      "step": 16710
    },
    {
      "epoch": 5.158901573588398,
      "grad_norm": 0.04892577975988388,
      "learning_rate": 4.4841098426411606e-05,
      "loss": 0.014,
      "step": 16720
    },
    {
      "epoch": 5.161987041036717,
      "grad_norm": 0.09787904471158981,
      "learning_rate": 4.483801295896328e-05,
      "loss": 0.0008,
      "step": 16730
    },
    {
      "epoch": 5.165072508485036,
      "grad_norm": 1.0309349298477173,
      "learning_rate": 4.4834927491514965e-05,
      "loss": 0.0058,
      "step": 16740
    },
    {
      "epoch": 5.168157975933354,
      "grad_norm": 1.1224708557128906,
      "learning_rate": 4.483184202406665e-05,
      "loss": 0.0107,
      "step": 16750
    },
    {
      "epoch": 5.171243443381672,
      "grad_norm": 0.16266436874866486,
      "learning_rate": 4.482875655661833e-05,
      "loss": 0.0072,
      "step": 16760
    },
    {
      "epoch": 5.174328910829991,
      "grad_norm": 1.8227689266204834,
      "learning_rate": 4.482567108917001e-05,
      "loss": 0.0142,
      "step": 16770
    },
    {
      "epoch": 5.177414378278309,
      "grad_norm": 0.19781339168548584,
      "learning_rate": 4.4822585621721694e-05,
      "loss": 0.0078,
      "step": 16780
    },
    {
      "epoch": 5.180499845726628,
      "grad_norm": 0.007699923124164343,
      "learning_rate": 4.481950015427338e-05,
      "loss": 0.0042,
      "step": 16790
    },
    {
      "epoch": 5.183585313174946,
      "grad_norm": 0.2543927729129791,
      "learning_rate": 4.481641468682505e-05,
      "loss": 0.0053,
      "step": 16800
    },
    {
      "epoch": 5.186670780623264,
      "grad_norm": 1.61724054813385,
      "learning_rate": 4.4813329219376735e-05,
      "loss": 0.0038,
      "step": 16810
    },
    {
      "epoch": 5.189756248071583,
      "grad_norm": 0.5417696237564087,
      "learning_rate": 4.4810243751928424e-05,
      "loss": 0.0015,
      "step": 16820
    },
    {
      "epoch": 5.192841715519902,
      "grad_norm": 0.0022231426555663347,
      "learning_rate": 4.48071582844801e-05,
      "loss": 0.0017,
      "step": 16830
    },
    {
      "epoch": 5.195927182968219,
      "grad_norm": 0.02602052502334118,
      "learning_rate": 4.480407281703178e-05,
      "loss": 0.0168,
      "step": 16840
    },
    {
      "epoch": 5.199012650416538,
      "grad_norm": 0.014257978647947311,
      "learning_rate": 4.4800987349583465e-05,
      "loss": 0.0088,
      "step": 16850
    },
    {
      "epoch": 5.202098117864857,
      "grad_norm": 1.6783735752105713,
      "learning_rate": 4.479790188213515e-05,
      "loss": 0.0027,
      "step": 16860
    },
    {
      "epoch": 5.205183585313175,
      "grad_norm": 0.635762631893158,
      "learning_rate": 4.479481641468683e-05,
      "loss": 0.0064,
      "step": 16870
    },
    {
      "epoch": 5.208269052761493,
      "grad_norm": 0.35619229078292847,
      "learning_rate": 4.4791730947238506e-05,
      "loss": 0.0105,
      "step": 16880
    },
    {
      "epoch": 5.211354520209812,
      "grad_norm": 4.189825057983398,
      "learning_rate": 4.4788645479790195e-05,
      "loss": 0.0136,
      "step": 16890
    },
    {
      "epoch": 5.21443998765813,
      "grad_norm": 0.2878950238227844,
      "learning_rate": 4.478556001234187e-05,
      "loss": 0.0163,
      "step": 16900
    },
    {
      "epoch": 5.217525455106449,
      "grad_norm": 2.497314214706421,
      "learning_rate": 4.478247454489355e-05,
      "loss": 0.0144,
      "step": 16910
    },
    {
      "epoch": 5.220610922554767,
      "grad_norm": 0.07659117877483368,
      "learning_rate": 4.4779389077445236e-05,
      "loss": 0.0137,
      "step": 16920
    },
    {
      "epoch": 5.223696390003085,
      "grad_norm": 0.16827517747879028,
      "learning_rate": 4.477630360999692e-05,
      "loss": 0.009,
      "step": 16930
    },
    {
      "epoch": 5.226781857451404,
      "grad_norm": 0.4477158486843109,
      "learning_rate": 4.47732181425486e-05,
      "loss": 0.0056,
      "step": 16940
    },
    {
      "epoch": 5.229867324899723,
      "grad_norm": 0.0073484075255692005,
      "learning_rate": 4.4770132675100276e-05,
      "loss": 0.0062,
      "step": 16950
    },
    {
      "epoch": 5.232952792348041,
      "grad_norm": 0.09227962791919708,
      "learning_rate": 4.4767047207651965e-05,
      "loss": 0.0037,
      "step": 16960
    },
    {
      "epoch": 5.236038259796359,
      "grad_norm": 0.9161446690559387,
      "learning_rate": 4.476396174020364e-05,
      "loss": 0.0029,
      "step": 16970
    },
    {
      "epoch": 5.239123727244678,
      "grad_norm": 0.019726276397705078,
      "learning_rate": 4.4760876272755324e-05,
      "loss": 0.0279,
      "step": 16980
    },
    {
      "epoch": 5.242209194692996,
      "grad_norm": 0.4079534113407135,
      "learning_rate": 4.4757790805307006e-05,
      "loss": 0.0101,
      "step": 16990
    },
    {
      "epoch": 5.245294662141315,
      "grad_norm": 0.014985359273850918,
      "learning_rate": 4.475470533785869e-05,
      "loss": 0.009,
      "step": 17000
    },
    {
      "epoch": 5.248380129589632,
      "grad_norm": 0.011203927919268608,
      "learning_rate": 4.475161987041037e-05,
      "loss": 0.0066,
      "step": 17010
    },
    {
      "epoch": 5.251465597037951,
      "grad_norm": 0.06411868333816528,
      "learning_rate": 4.474853440296205e-05,
      "loss": 0.0063,
      "step": 17020
    },
    {
      "epoch": 5.25455106448627,
      "grad_norm": 2.0621495246887207,
      "learning_rate": 4.4745448935513736e-05,
      "loss": 0.0169,
      "step": 17030
    },
    {
      "epoch": 5.257636531934588,
      "grad_norm": 1.1934441328048706,
      "learning_rate": 4.474236346806541e-05,
      "loss": 0.0088,
      "step": 17040
    },
    {
      "epoch": 5.260721999382906,
      "grad_norm": 2.899477005004883,
      "learning_rate": 4.4739278000617094e-05,
      "loss": 0.007,
      "step": 17050
    },
    {
      "epoch": 5.263807466831225,
      "grad_norm": 0.18817995488643646,
      "learning_rate": 4.473619253316878e-05,
      "loss": 0.0014,
      "step": 17060
    },
    {
      "epoch": 5.266892934279543,
      "grad_norm": 2.539336681365967,
      "learning_rate": 4.473310706572046e-05,
      "loss": 0.0143,
      "step": 17070
    },
    {
      "epoch": 5.269978401727862,
      "grad_norm": 1.8867454528808594,
      "learning_rate": 4.473002159827214e-05,
      "loss": 0.009,
      "step": 17080
    },
    {
      "epoch": 5.27306386917618,
      "grad_norm": 0.05770157277584076,
      "learning_rate": 4.4726936130823824e-05,
      "loss": 0.0159,
      "step": 17090
    },
    {
      "epoch": 5.276149336624498,
      "grad_norm": 1.5232858657836914,
      "learning_rate": 4.4723850663375507e-05,
      "loss": 0.0159,
      "step": 17100
    },
    {
      "epoch": 5.279234804072817,
      "grad_norm": 0.23003093898296356,
      "learning_rate": 4.472076519592718e-05,
      "loss": 0.0193,
      "step": 17110
    },
    {
      "epoch": 5.282320271521136,
      "grad_norm": 0.07606781274080276,
      "learning_rate": 4.4717679728478865e-05,
      "loss": 0.028,
      "step": 17120
    },
    {
      "epoch": 5.2854057389694535,
      "grad_norm": 6.300752639770508,
      "learning_rate": 4.471459426103055e-05,
      "loss": 0.0105,
      "step": 17130
    },
    {
      "epoch": 5.288491206417772,
      "grad_norm": 0.2187931388616562,
      "learning_rate": 4.471150879358223e-05,
      "loss": 0.0163,
      "step": 17140
    },
    {
      "epoch": 5.291576673866091,
      "grad_norm": 2.6889517307281494,
      "learning_rate": 4.470842332613391e-05,
      "loss": 0.0119,
      "step": 17150
    },
    {
      "epoch": 5.294662141314409,
      "grad_norm": 1.4385076761245728,
      "learning_rate": 4.4705337858685595e-05,
      "loss": 0.0033,
      "step": 17160
    },
    {
      "epoch": 5.2977476087627275,
      "grad_norm": 1.0428153276443481,
      "learning_rate": 4.470225239123728e-05,
      "loss": 0.0036,
      "step": 17170
    },
    {
      "epoch": 5.300833076211046,
      "grad_norm": 3.1893320083618164,
      "learning_rate": 4.469916692378895e-05,
      "loss": 0.013,
      "step": 17180
    },
    {
      "epoch": 5.303918543659364,
      "grad_norm": 0.7735329866409302,
      "learning_rate": 4.4696081456340635e-05,
      "loss": 0.005,
      "step": 17190
    },
    {
      "epoch": 5.307004011107683,
      "grad_norm": 0.022046560421586037,
      "learning_rate": 4.469299598889232e-05,
      "loss": 0.0176,
      "step": 17200
    },
    {
      "epoch": 5.3100894785560016,
      "grad_norm": 1.5602236986160278,
      "learning_rate": 4.4689910521444e-05,
      "loss": 0.0144,
      "step": 17210
    },
    {
      "epoch": 5.313174946004319,
      "grad_norm": 0.916081428527832,
      "learning_rate": 4.468682505399568e-05,
      "loss": 0.0159,
      "step": 17220
    },
    {
      "epoch": 5.316260413452638,
      "grad_norm": 0.07786783576011658,
      "learning_rate": 4.4683739586547365e-05,
      "loss": 0.0132,
      "step": 17230
    },
    {
      "epoch": 5.319345880900957,
      "grad_norm": 0.03302059695124626,
      "learning_rate": 4.468065411909905e-05,
      "loss": 0.0013,
      "step": 17240
    },
    {
      "epoch": 5.322431348349275,
      "grad_norm": 2.311816692352295,
      "learning_rate": 4.4677568651650723e-05,
      "loss": 0.0096,
      "step": 17250
    },
    {
      "epoch": 5.325516815797593,
      "grad_norm": 0.750300407409668,
      "learning_rate": 4.4674483184202406e-05,
      "loss": 0.0077,
      "step": 17260
    },
    {
      "epoch": 5.328602283245912,
      "grad_norm": 0.0537218414247036,
      "learning_rate": 4.4671397716754095e-05,
      "loss": 0.0034,
      "step": 17270
    },
    {
      "epoch": 5.33168775069423,
      "grad_norm": 0.12953636050224304,
      "learning_rate": 4.466831224930577e-05,
      "loss": 0.0186,
      "step": 17280
    },
    {
      "epoch": 5.334773218142549,
      "grad_norm": 0.4975931942462921,
      "learning_rate": 4.466522678185745e-05,
      "loss": 0.0084,
      "step": 17290
    },
    {
      "epoch": 5.337858685590867,
      "grad_norm": 0.02584458515048027,
      "learning_rate": 4.4662141314409136e-05,
      "loss": 0.015,
      "step": 17300
    },
    {
      "epoch": 5.340944153039185,
      "grad_norm": 0.20544473826885223,
      "learning_rate": 4.465905584696082e-05,
      "loss": 0.0022,
      "step": 17310
    },
    {
      "epoch": 5.344029620487504,
      "grad_norm": 0.008351851254701614,
      "learning_rate": 4.4655970379512494e-05,
      "loss": 0.0116,
      "step": 17320
    },
    {
      "epoch": 5.347115087935823,
      "grad_norm": 0.030595438554883003,
      "learning_rate": 4.465288491206418e-05,
      "loss": 0.0108,
      "step": 17330
    },
    {
      "epoch": 5.3502005553841405,
      "grad_norm": 0.057021886110305786,
      "learning_rate": 4.4649799444615866e-05,
      "loss": 0.0102,
      "step": 17340
    },
    {
      "epoch": 5.353286022832459,
      "grad_norm": 0.07571674138307571,
      "learning_rate": 4.464671397716754e-05,
      "loss": 0.008,
      "step": 17350
    },
    {
      "epoch": 5.356371490280777,
      "grad_norm": 0.0681328997015953,
      "learning_rate": 4.4643628509719224e-05,
      "loss": 0.0042,
      "step": 17360
    },
    {
      "epoch": 5.359456957729096,
      "grad_norm": 0.261972576379776,
      "learning_rate": 4.4640543042270906e-05,
      "loss": 0.0102,
      "step": 17370
    },
    {
      "epoch": 5.3625424251774145,
      "grad_norm": 0.053237494081258774,
      "learning_rate": 4.463745757482259e-05,
      "loss": 0.007,
      "step": 17380
    },
    {
      "epoch": 5.365627892625733,
      "grad_norm": 0.08225703239440918,
      "learning_rate": 4.4634372107374265e-05,
      "loss": 0.0184,
      "step": 17390
    },
    {
      "epoch": 5.368713360074051,
      "grad_norm": 0.42155972123146057,
      "learning_rate": 4.4631286639925954e-05,
      "loss": 0.0164,
      "step": 17400
    },
    {
      "epoch": 5.37179882752237,
      "grad_norm": 0.7163597345352173,
      "learning_rate": 4.4628201172477636e-05,
      "loss": 0.0065,
      "step": 17410
    },
    {
      "epoch": 5.374884294970688,
      "grad_norm": 4.379214763641357,
      "learning_rate": 4.462511570502931e-05,
      "loss": 0.0176,
      "step": 17420
    },
    {
      "epoch": 5.377969762419006,
      "grad_norm": 0.1420108675956726,
      "learning_rate": 4.4622030237580994e-05,
      "loss": 0.02,
      "step": 17430
    },
    {
      "epoch": 5.381055229867325,
      "grad_norm": 0.23258577287197113,
      "learning_rate": 4.461894477013268e-05,
      "loss": 0.0094,
      "step": 17440
    },
    {
      "epoch": 5.384140697315643,
      "grad_norm": 0.11895822733640671,
      "learning_rate": 4.461585930268436e-05,
      "loss": 0.0173,
      "step": 17450
    },
    {
      "epoch": 5.387226164763962,
      "grad_norm": 3.340644359588623,
      "learning_rate": 4.4612773835236035e-05,
      "loss": 0.0117,
      "step": 17460
    },
    {
      "epoch": 5.39031163221228,
      "grad_norm": 0.27661991119384766,
      "learning_rate": 4.4609688367787724e-05,
      "loss": 0.0076,
      "step": 17470
    },
    {
      "epoch": 5.393397099660598,
      "grad_norm": 0.36701223254203796,
      "learning_rate": 4.460660290033941e-05,
      "loss": 0.011,
      "step": 17480
    },
    {
      "epoch": 5.396482567108917,
      "grad_norm": 2.9532577991485596,
      "learning_rate": 4.460351743289108e-05,
      "loss": 0.0078,
      "step": 17490
    },
    {
      "epoch": 5.399568034557236,
      "grad_norm": 2.73405385017395,
      "learning_rate": 4.4600431965442765e-05,
      "loss": 0.0093,
      "step": 17500
    },
    {
      "epoch": 5.4026535020055535,
      "grad_norm": 0.06655272841453552,
      "learning_rate": 4.459734649799445e-05,
      "loss": 0.0124,
      "step": 17510
    },
    {
      "epoch": 5.405738969453872,
      "grad_norm": 0.5442686080932617,
      "learning_rate": 4.459426103054613e-05,
      "loss": 0.0175,
      "step": 17520
    },
    {
      "epoch": 5.408824436902191,
      "grad_norm": 0.6374780535697937,
      "learning_rate": 4.4591175563097806e-05,
      "loss": 0.0118,
      "step": 17530
    },
    {
      "epoch": 5.411909904350509,
      "grad_norm": 0.3337579071521759,
      "learning_rate": 4.4588090095649495e-05,
      "loss": 0.0138,
      "step": 17540
    },
    {
      "epoch": 5.4149953717988275,
      "grad_norm": 0.16456089913845062,
      "learning_rate": 4.458500462820118e-05,
      "loss": 0.0241,
      "step": 17550
    },
    {
      "epoch": 5.418080839247146,
      "grad_norm": 1.9846522808074951,
      "learning_rate": 4.458191916075285e-05,
      "loss": 0.0101,
      "step": 17560
    },
    {
      "epoch": 5.421166306695464,
      "grad_norm": 0.624066948890686,
      "learning_rate": 4.457883369330454e-05,
      "loss": 0.0147,
      "step": 17570
    },
    {
      "epoch": 5.424251774143783,
      "grad_norm": 1.3668289184570312,
      "learning_rate": 4.457574822585622e-05,
      "loss": 0.0157,
      "step": 17580
    },
    {
      "epoch": 5.4273372415921015,
      "grad_norm": 0.46742987632751465,
      "learning_rate": 4.45726627584079e-05,
      "loss": 0.016,
      "step": 17590
    },
    {
      "epoch": 5.430422709040419,
      "grad_norm": 2.117438793182373,
      "learning_rate": 4.456957729095958e-05,
      "loss": 0.0077,
      "step": 17600
    },
    {
      "epoch": 5.433508176488738,
      "grad_norm": 4.107086658477783,
      "learning_rate": 4.4566491823511265e-05,
      "loss": 0.0146,
      "step": 17610
    },
    {
      "epoch": 5.436593643937057,
      "grad_norm": 1.5794579982757568,
      "learning_rate": 4.456340635606295e-05,
      "loss": 0.0079,
      "step": 17620
    },
    {
      "epoch": 5.439679111385375,
      "grad_norm": 0.6075090765953064,
      "learning_rate": 4.4560320888614624e-05,
      "loss": 0.0065,
      "step": 17630
    },
    {
      "epoch": 5.442764578833693,
      "grad_norm": 2.575334072113037,
      "learning_rate": 4.455723542116631e-05,
      "loss": 0.0085,
      "step": 17640
    },
    {
      "epoch": 5.445850046282012,
      "grad_norm": 0.02738145738840103,
      "learning_rate": 4.455414995371799e-05,
      "loss": 0.0103,
      "step": 17650
    },
    {
      "epoch": 5.44893551373033,
      "grad_norm": 3.2178866863250732,
      "learning_rate": 4.455106448626967e-05,
      "loss": 0.0117,
      "step": 17660
    },
    {
      "epoch": 5.452020981178649,
      "grad_norm": 0.05841059982776642,
      "learning_rate": 4.4547979018821354e-05,
      "loss": 0.0187,
      "step": 17670
    },
    {
      "epoch": 5.455106448626967,
      "grad_norm": 0.5398756265640259,
      "learning_rate": 4.4544893551373036e-05,
      "loss": 0.0052,
      "step": 17680
    },
    {
      "epoch": 5.458191916075285,
      "grad_norm": 0.06769251823425293,
      "learning_rate": 4.454180808392472e-05,
      "loss": 0.0049,
      "step": 17690
    },
    {
      "epoch": 5.461277383523604,
      "grad_norm": 0.692001223564148,
      "learning_rate": 4.4538722616476394e-05,
      "loss": 0.0035,
      "step": 17700
    },
    {
      "epoch": 5.464362850971923,
      "grad_norm": 0.6121616959571838,
      "learning_rate": 4.4535637149028083e-05,
      "loss": 0.0067,
      "step": 17710
    },
    {
      "epoch": 5.4674483184202405,
      "grad_norm": 1.7896791696548462,
      "learning_rate": 4.453255168157976e-05,
      "loss": 0.0061,
      "step": 17720
    },
    {
      "epoch": 5.470533785868559,
      "grad_norm": 0.6361498236656189,
      "learning_rate": 4.452946621413144e-05,
      "loss": 0.0123,
      "step": 17730
    },
    {
      "epoch": 5.473619253316878,
      "grad_norm": 0.1815928965806961,
      "learning_rate": 4.4526380746683124e-05,
      "loss": 0.0132,
      "step": 17740
    },
    {
      "epoch": 5.476704720765196,
      "grad_norm": 4.280343532562256,
      "learning_rate": 4.452329527923481e-05,
      "loss": 0.0093,
      "step": 17750
    },
    {
      "epoch": 5.4797901882135145,
      "grad_norm": 3.517359972000122,
      "learning_rate": 4.452020981178649e-05,
      "loss": 0.0171,
      "step": 17760
    },
    {
      "epoch": 5.482875655661832,
      "grad_norm": 1.3574109077453613,
      "learning_rate": 4.4517124344338165e-05,
      "loss": 0.0174,
      "step": 17770
    },
    {
      "epoch": 5.485961123110151,
      "grad_norm": 0.03175761178135872,
      "learning_rate": 4.4514038876889854e-05,
      "loss": 0.0128,
      "step": 17780
    },
    {
      "epoch": 5.48904659055847,
      "grad_norm": 0.12454444169998169,
      "learning_rate": 4.451095340944153e-05,
      "loss": 0.0072,
      "step": 17790
    },
    {
      "epoch": 5.4921320580067885,
      "grad_norm": 0.04876164719462395,
      "learning_rate": 4.450786794199321e-05,
      "loss": 0.0053,
      "step": 17800
    },
    {
      "epoch": 5.495217525455106,
      "grad_norm": 0.2263917773962021,
      "learning_rate": 4.45047824745449e-05,
      "loss": 0.0129,
      "step": 17810
    },
    {
      "epoch": 5.498302992903425,
      "grad_norm": 0.48222658038139343,
      "learning_rate": 4.450169700709658e-05,
      "loss": 0.0103,
      "step": 17820
    },
    {
      "epoch": 5.501388460351743,
      "grad_norm": 0.5595093369483948,
      "learning_rate": 4.449861153964826e-05,
      "loss": 0.0137,
      "step": 17830
    },
    {
      "epoch": 5.504473927800062,
      "grad_norm": 1.3191691637039185,
      "learning_rate": 4.449552607219994e-05,
      "loss": 0.0113,
      "step": 17840
    },
    {
      "epoch": 5.50755939524838,
      "grad_norm": 0.6930291652679443,
      "learning_rate": 4.4492440604751625e-05,
      "loss": 0.0095,
      "step": 17850
    },
    {
      "epoch": 5.510644862696698,
      "grad_norm": 3.0476810932159424,
      "learning_rate": 4.44893551373033e-05,
      "loss": 0.0125,
      "step": 17860
    },
    {
      "epoch": 5.513730330145017,
      "grad_norm": 0.0897885411977768,
      "learning_rate": 4.448626966985498e-05,
      "loss": 0.0074,
      "step": 17870
    },
    {
      "epoch": 5.516815797593336,
      "grad_norm": 2.5528225898742676,
      "learning_rate": 4.448318420240667e-05,
      "loss": 0.0134,
      "step": 17880
    },
    {
      "epoch": 5.5199012650416535,
      "grad_norm": 4.445013999938965,
      "learning_rate": 4.448009873495835e-05,
      "loss": 0.0137,
      "step": 17890
    },
    {
      "epoch": 5.522986732489972,
      "grad_norm": 0.3345179259777069,
      "learning_rate": 4.447701326751003e-05,
      "loss": 0.0114,
      "step": 17900
    },
    {
      "epoch": 5.526072199938291,
      "grad_norm": 0.5824679732322693,
      "learning_rate": 4.447392780006171e-05,
      "loss": 0.0176,
      "step": 17910
    },
    {
      "epoch": 5.529157667386609,
      "grad_norm": 4.82108211517334,
      "learning_rate": 4.4470842332613395e-05,
      "loss": 0.005,
      "step": 17920
    },
    {
      "epoch": 5.5322431348349275,
      "grad_norm": 0.8273614048957825,
      "learning_rate": 4.446775686516507e-05,
      "loss": 0.0073,
      "step": 17930
    },
    {
      "epoch": 5.535328602283246,
      "grad_norm": 0.11773596704006195,
      "learning_rate": 4.446467139771675e-05,
      "loss": 0.0043,
      "step": 17940
    },
    {
      "epoch": 5.538414069731564,
      "grad_norm": 0.05011209473013878,
      "learning_rate": 4.446158593026844e-05,
      "loss": 0.0026,
      "step": 17950
    },
    {
      "epoch": 5.541499537179883,
      "grad_norm": 0.08292318880558014,
      "learning_rate": 4.445850046282012e-05,
      "loss": 0.0046,
      "step": 17960
    },
    {
      "epoch": 5.5445850046282015,
      "grad_norm": 0.3476340174674988,
      "learning_rate": 4.44554149953718e-05,
      "loss": 0.0136,
      "step": 17970
    },
    {
      "epoch": 5.547670472076519,
      "grad_norm": 0.09198737144470215,
      "learning_rate": 4.445232952792348e-05,
      "loss": 0.0076,
      "step": 17980
    },
    {
      "epoch": 5.550755939524838,
      "grad_norm": 1.9164488315582275,
      "learning_rate": 4.4449244060475166e-05,
      "loss": 0.0043,
      "step": 17990
    },
    {
      "epoch": 5.553841406973157,
      "grad_norm": 2.1312367916107178,
      "learning_rate": 4.444615859302684e-05,
      "loss": 0.0268,
      "step": 18000
    },
    {
      "epoch": 5.556926874421475,
      "grad_norm": 0.21011686325073242,
      "learning_rate": 4.4443073125578524e-05,
      "loss": 0.0027,
      "step": 18010
    },
    {
      "epoch": 5.560012341869793,
      "grad_norm": 0.5172872543334961,
      "learning_rate": 4.443998765813021e-05,
      "loss": 0.0101,
      "step": 18020
    },
    {
      "epoch": 5.563097809318112,
      "grad_norm": 1.9712852239608765,
      "learning_rate": 4.443690219068189e-05,
      "loss": 0.0087,
      "step": 18030
    },
    {
      "epoch": 5.56618327676643,
      "grad_norm": 2.6245884895324707,
      "learning_rate": 4.443381672323357e-05,
      "loss": 0.0129,
      "step": 18040
    },
    {
      "epoch": 5.569268744214749,
      "grad_norm": 0.02405538596212864,
      "learning_rate": 4.4430731255785254e-05,
      "loss": 0.0101,
      "step": 18050
    },
    {
      "epoch": 5.572354211663067,
      "grad_norm": 4.8272385597229,
      "learning_rate": 4.4427645788336936e-05,
      "loss": 0.0095,
      "step": 18060
    },
    {
      "epoch": 5.575439679111385,
      "grad_norm": 0.8047119975090027,
      "learning_rate": 4.442456032088861e-05,
      "loss": 0.0096,
      "step": 18070
    },
    {
      "epoch": 5.578525146559704,
      "grad_norm": 0.45798081159591675,
      "learning_rate": 4.44214748534403e-05,
      "loss": 0.0015,
      "step": 18080
    },
    {
      "epoch": 5.581610614008023,
      "grad_norm": 0.10334502160549164,
      "learning_rate": 4.4418389385991984e-05,
      "loss": 0.0095,
      "step": 18090
    },
    {
      "epoch": 5.58469608145634,
      "grad_norm": 1.9973344802856445,
      "learning_rate": 4.441530391854366e-05,
      "loss": 0.0107,
      "step": 18100
    },
    {
      "epoch": 5.587781548904659,
      "grad_norm": 2.998969793319702,
      "learning_rate": 4.441221845109534e-05,
      "loss": 0.0114,
      "step": 18110
    },
    {
      "epoch": 5.590867016352977,
      "grad_norm": 0.20454661548137665,
      "learning_rate": 4.4409132983647024e-05,
      "loss": 0.0176,
      "step": 18120
    },
    {
      "epoch": 5.593952483801296,
      "grad_norm": 2.0774831771850586,
      "learning_rate": 4.440604751619871e-05,
      "loss": 0.0057,
      "step": 18130
    },
    {
      "epoch": 5.5970379512496145,
      "grad_norm": 0.48369356989860535,
      "learning_rate": 4.440296204875039e-05,
      "loss": 0.0064,
      "step": 18140
    },
    {
      "epoch": 5.600123418697933,
      "grad_norm": 0.13067206740379333,
      "learning_rate": 4.439987658130207e-05,
      "loss": 0.0139,
      "step": 18150
    },
    {
      "epoch": 5.603208886146251,
      "grad_norm": 0.05871925130486488,
      "learning_rate": 4.4396791113853754e-05,
      "loss": 0.0046,
      "step": 18160
    },
    {
      "epoch": 5.60629435359457,
      "grad_norm": 0.13323043286800385,
      "learning_rate": 4.439370564640543e-05,
      "loss": 0.002,
      "step": 18170
    },
    {
      "epoch": 5.609379821042888,
      "grad_norm": 0.4389779567718506,
      "learning_rate": 4.439062017895711e-05,
      "loss": 0.0034,
      "step": 18180
    },
    {
      "epoch": 5.612465288491206,
      "grad_norm": 1.1245163679122925,
      "learning_rate": 4.4387534711508795e-05,
      "loss": 0.0183,
      "step": 18190
    },
    {
      "epoch": 5.615550755939525,
      "grad_norm": 3.1136586666107178,
      "learning_rate": 4.438444924406048e-05,
      "loss": 0.0121,
      "step": 18200
    },
    {
      "epoch": 5.618636223387844,
      "grad_norm": 0.03847905620932579,
      "learning_rate": 4.438136377661216e-05,
      "loss": 0.0074,
      "step": 18210
    },
    {
      "epoch": 5.621721690836162,
      "grad_norm": 0.21705053746700287,
      "learning_rate": 4.437827830916384e-05,
      "loss": 0.0093,
      "step": 18220
    },
    {
      "epoch": 5.62480715828448,
      "grad_norm": 0.04533164203166962,
      "learning_rate": 4.4375192841715525e-05,
      "loss": 0.0114,
      "step": 18230
    },
    {
      "epoch": 5.627892625732798,
      "grad_norm": 0.8527051210403442,
      "learning_rate": 4.43721073742672e-05,
      "loss": 0.0428,
      "step": 18240
    },
    {
      "epoch": 5.630978093181117,
      "grad_norm": 0.24988669157028198,
      "learning_rate": 4.436902190681888e-05,
      "loss": 0.0075,
      "step": 18250
    },
    {
      "epoch": 5.634063560629436,
      "grad_norm": 5.5855712890625,
      "learning_rate": 4.4365936439370566e-05,
      "loss": 0.0106,
      "step": 18260
    },
    {
      "epoch": 5.637149028077753,
      "grad_norm": 1.1655234098434448,
      "learning_rate": 4.436285097192225e-05,
      "loss": 0.0188,
      "step": 18270
    },
    {
      "epoch": 5.640234495526072,
      "grad_norm": 0.5250959396362305,
      "learning_rate": 4.435976550447393e-05,
      "loss": 0.0093,
      "step": 18280
    },
    {
      "epoch": 5.643319962974391,
      "grad_norm": 0.6157266497612,
      "learning_rate": 4.435668003702561e-05,
      "loss": 0.0127,
      "step": 18290
    },
    {
      "epoch": 5.646405430422709,
      "grad_norm": 2.1538002490997314,
      "learning_rate": 4.4353594569577295e-05,
      "loss": 0.0103,
      "step": 18300
    },
    {
      "epoch": 5.649490897871027,
      "grad_norm": 0.13207949697971344,
      "learning_rate": 4.435050910212897e-05,
      "loss": 0.0091,
      "step": 18310
    },
    {
      "epoch": 5.652576365319346,
      "grad_norm": 0.04187026619911194,
      "learning_rate": 4.434742363468066e-05,
      "loss": 0.0023,
      "step": 18320
    },
    {
      "epoch": 5.655661832767664,
      "grad_norm": 0.8705079555511475,
      "learning_rate": 4.4344338167232336e-05,
      "loss": 0.0071,
      "step": 18330
    },
    {
      "epoch": 5.658747300215983,
      "grad_norm": 0.40618619322776794,
      "learning_rate": 4.434125269978402e-05,
      "loss": 0.0023,
      "step": 18340
    },
    {
      "epoch": 5.661832767664301,
      "grad_norm": 2.9576656818389893,
      "learning_rate": 4.43381672323357e-05,
      "loss": 0.0132,
      "step": 18350
    },
    {
      "epoch": 5.664918235112619,
      "grad_norm": 0.40792396664619446,
      "learning_rate": 4.4335081764887383e-05,
      "loss": 0.0134,
      "step": 18360
    },
    {
      "epoch": 5.668003702560938,
      "grad_norm": 1.6276475191116333,
      "learning_rate": 4.4331996297439066e-05,
      "loss": 0.0099,
      "step": 18370
    },
    {
      "epoch": 5.671089170009257,
      "grad_norm": 0.7065392732620239,
      "learning_rate": 4.432891082999074e-05,
      "loss": 0.0084,
      "step": 18380
    },
    {
      "epoch": 5.6741746374575746,
      "grad_norm": 0.06826864928007126,
      "learning_rate": 4.432582536254243e-05,
      "loss": 0.0046,
      "step": 18390
    },
    {
      "epoch": 5.677260104905893,
      "grad_norm": 0.08463264256715775,
      "learning_rate": 4.432273989509411e-05,
      "loss": 0.0076,
      "step": 18400
    },
    {
      "epoch": 5.680345572354212,
      "grad_norm": 0.02745198830962181,
      "learning_rate": 4.431965442764579e-05,
      "loss": 0.0014,
      "step": 18410
    },
    {
      "epoch": 5.68343103980253,
      "grad_norm": 0.5123368501663208,
      "learning_rate": 4.431656896019747e-05,
      "loss": 0.0151,
      "step": 18420
    },
    {
      "epoch": 5.686516507250849,
      "grad_norm": 1.8668932914733887,
      "learning_rate": 4.4313483492749154e-05,
      "loss": 0.0097,
      "step": 18430
    },
    {
      "epoch": 5.689601974699167,
      "grad_norm": 0.0003482255560811609,
      "learning_rate": 4.4310398025300837e-05,
      "loss": 0.0079,
      "step": 18440
    },
    {
      "epoch": 5.692687442147485,
      "grad_norm": 0.09559690952301025,
      "learning_rate": 4.430731255785251e-05,
      "loss": 0.0039,
      "step": 18450
    },
    {
      "epoch": 5.695772909595804,
      "grad_norm": 1.8843756914138794,
      "learning_rate": 4.43042270904042e-05,
      "loss": 0.0045,
      "step": 18460
    },
    {
      "epoch": 5.698858377044123,
      "grad_norm": 0.0365636982023716,
      "learning_rate": 4.430114162295588e-05,
      "loss": 0.0151,
      "step": 18470
    },
    {
      "epoch": 5.70194384449244,
      "grad_norm": 0.6227720975875854,
      "learning_rate": 4.429805615550756e-05,
      "loss": 0.0052,
      "step": 18480
    },
    {
      "epoch": 5.705029311940759,
      "grad_norm": 1.965100646018982,
      "learning_rate": 4.429497068805924e-05,
      "loss": 0.0057,
      "step": 18490
    },
    {
      "epoch": 5.708114779389078,
      "grad_norm": 2.0487818717956543,
      "learning_rate": 4.4291885220610925e-05,
      "loss": 0.0113,
      "step": 18500
    },
    {
      "epoch": 5.711200246837396,
      "grad_norm": 0.750812292098999,
      "learning_rate": 4.428879975316261e-05,
      "loss": 0.0135,
      "step": 18510
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.5048181414604187,
      "learning_rate": 4.428571428571428e-05,
      "loss": 0.0081,
      "step": 18520
    },
    {
      "epoch": 5.717371181734032,
      "grad_norm": 0.0033847333397716284,
      "learning_rate": 4.428262881826597e-05,
      "loss": 0.0024,
      "step": 18530
    },
    {
      "epoch": 5.720456649182351,
      "grad_norm": 4.879157066345215,
      "learning_rate": 4.427954335081765e-05,
      "loss": 0.0114,
      "step": 18540
    },
    {
      "epoch": 5.72354211663067,
      "grad_norm": 0.11513395607471466,
      "learning_rate": 4.427645788336933e-05,
      "loss": 0.0074,
      "step": 18550
    },
    {
      "epoch": 5.726627584078988,
      "grad_norm": 0.02505325898528099,
      "learning_rate": 4.427337241592102e-05,
      "loss": 0.0068,
      "step": 18560
    },
    {
      "epoch": 5.729713051527306,
      "grad_norm": 0.029096493497490883,
      "learning_rate": 4.4270286948472695e-05,
      "loss": 0.0101,
      "step": 18570
    },
    {
      "epoch": 5.732798518975625,
      "grad_norm": 0.12007232010364532,
      "learning_rate": 4.426720148102438e-05,
      "loss": 0.0052,
      "step": 18580
    },
    {
      "epoch": 5.735883986423943,
      "grad_norm": 0.013364923186600208,
      "learning_rate": 4.426411601357606e-05,
      "loss": 0.0087,
      "step": 18590
    },
    {
      "epoch": 5.7389694538722615,
      "grad_norm": 0.34676238894462585,
      "learning_rate": 4.426103054612774e-05,
      "loss": 0.013,
      "step": 18600
    },
    {
      "epoch": 5.74205492132058,
      "grad_norm": 0.16192950308322906,
      "learning_rate": 4.4257945078679425e-05,
      "loss": 0.0052,
      "step": 18610
    },
    {
      "epoch": 5.745140388768899,
      "grad_norm": 0.33365148305892944,
      "learning_rate": 4.42548596112311e-05,
      "loss": 0.0085,
      "step": 18620
    },
    {
      "epoch": 5.748225856217217,
      "grad_norm": 0.6305715441703796,
      "learning_rate": 4.425177414378279e-05,
      "loss": 0.0299,
      "step": 18630
    },
    {
      "epoch": 5.7513113236655355,
      "grad_norm": 0.17640747129917145,
      "learning_rate": 4.4248688676334466e-05,
      "loss": 0.0058,
      "step": 18640
    },
    {
      "epoch": 5.754396791113853,
      "grad_norm": 0.6121029853820801,
      "learning_rate": 4.424560320888615e-05,
      "loss": 0.006,
      "step": 18650
    },
    {
      "epoch": 5.757482258562172,
      "grad_norm": 0.1351809799671173,
      "learning_rate": 4.424251774143783e-05,
      "loss": 0.0043,
      "step": 18660
    },
    {
      "epoch": 5.760567726010491,
      "grad_norm": 0.22868874669075012,
      "learning_rate": 4.423943227398951e-05,
      "loss": 0.0064,
      "step": 18670
    },
    {
      "epoch": 5.763653193458809,
      "grad_norm": 1.663018822669983,
      "learning_rate": 4.4236346806541196e-05,
      "loss": 0.0108,
      "step": 18680
    },
    {
      "epoch": 5.766738660907127,
      "grad_norm": 0.003255305113270879,
      "learning_rate": 4.423326133909287e-05,
      "loss": 0.0028,
      "step": 18690
    },
    {
      "epoch": 5.769824128355446,
      "grad_norm": 0.48814061284065247,
      "learning_rate": 4.423017587164456e-05,
      "loss": 0.0192,
      "step": 18700
    },
    {
      "epoch": 5.772909595803764,
      "grad_norm": 5.779806613922119,
      "learning_rate": 4.4227090404196236e-05,
      "loss": 0.036,
      "step": 18710
    },
    {
      "epoch": 5.775995063252083,
      "grad_norm": 0.029782112687826157,
      "learning_rate": 4.422400493674792e-05,
      "loss": 0.0024,
      "step": 18720
    },
    {
      "epoch": 5.779080530700401,
      "grad_norm": 1.7693990468978882,
      "learning_rate": 4.42209194692996e-05,
      "loss": 0.013,
      "step": 18730
    },
    {
      "epoch": 5.782165998148719,
      "grad_norm": 2.4411253929138184,
      "learning_rate": 4.4217834001851284e-05,
      "loss": 0.0039,
      "step": 18740
    },
    {
      "epoch": 5.785251465597038,
      "grad_norm": 0.015624512918293476,
      "learning_rate": 4.4214748534402966e-05,
      "loss": 0.0049,
      "step": 18750
    },
    {
      "epoch": 5.788336933045357,
      "grad_norm": 0.04697446897625923,
      "learning_rate": 4.421166306695464e-05,
      "loss": 0.0226,
      "step": 18760
    },
    {
      "epoch": 5.7914224004936745,
      "grad_norm": 0.003044282319024205,
      "learning_rate": 4.420857759950633e-05,
      "loss": 0.0017,
      "step": 18770
    },
    {
      "epoch": 5.794507867941993,
      "grad_norm": 2.4570913314819336,
      "learning_rate": 4.420549213205801e-05,
      "loss": 0.0123,
      "step": 18780
    },
    {
      "epoch": 5.797593335390312,
      "grad_norm": 0.07708656787872314,
      "learning_rate": 4.420240666460969e-05,
      "loss": 0.0119,
      "step": 18790
    },
    {
      "epoch": 5.80067880283863,
      "grad_norm": 0.0509665422141552,
      "learning_rate": 4.419932119716137e-05,
      "loss": 0.0079,
      "step": 18800
    },
    {
      "epoch": 5.8037642702869485,
      "grad_norm": 1.1584795713424683,
      "learning_rate": 4.4196235729713054e-05,
      "loss": 0.0099,
      "step": 18810
    },
    {
      "epoch": 5.806849737735267,
      "grad_norm": 1.212546944618225,
      "learning_rate": 4.419315026226474e-05,
      "loss": 0.0066,
      "step": 18820
    },
    {
      "epoch": 5.809935205183585,
      "grad_norm": 0.6668530702590942,
      "learning_rate": 4.419006479481642e-05,
      "loss": 0.009,
      "step": 18830
    },
    {
      "epoch": 5.813020672631904,
      "grad_norm": 0.3794437050819397,
      "learning_rate": 4.41869793273681e-05,
      "loss": 0.0037,
      "step": 18840
    },
    {
      "epoch": 5.8161061400802225,
      "grad_norm": 1.3805351257324219,
      "learning_rate": 4.418389385991978e-05,
      "loss": 0.0071,
      "step": 18850
    },
    {
      "epoch": 5.81919160752854,
      "grad_norm": 0.0407901294529438,
      "learning_rate": 4.418080839247146e-05,
      "loss": 0.0217,
      "step": 18860
    },
    {
      "epoch": 5.822277074976859,
      "grad_norm": 0.24009408056735992,
      "learning_rate": 4.417772292502314e-05,
      "loss": 0.011,
      "step": 18870
    },
    {
      "epoch": 5.825362542425177,
      "grad_norm": 0.028244303539395332,
      "learning_rate": 4.4174637457574825e-05,
      "loss": 0.0112,
      "step": 18880
    },
    {
      "epoch": 5.828448009873496,
      "grad_norm": 1.870415210723877,
      "learning_rate": 4.417155199012651e-05,
      "loss": 0.0064,
      "step": 18890
    },
    {
      "epoch": 5.831533477321814,
      "grad_norm": 0.009761002846062183,
      "learning_rate": 4.416846652267819e-05,
      "loss": 0.0247,
      "step": 18900
    },
    {
      "epoch": 5.834618944770133,
      "grad_norm": 4.259448528289795,
      "learning_rate": 4.416538105522987e-05,
      "loss": 0.0238,
      "step": 18910
    },
    {
      "epoch": 5.837704412218451,
      "grad_norm": 0.46993303298950195,
      "learning_rate": 4.416229558778155e-05,
      "loss": 0.011,
      "step": 18920
    },
    {
      "epoch": 5.84078987966677,
      "grad_norm": 0.007472571916878223,
      "learning_rate": 4.415921012033323e-05,
      "loss": 0.0046,
      "step": 18930
    },
    {
      "epoch": 5.8438753471150875,
      "grad_norm": 0.24151484668254852,
      "learning_rate": 4.415612465288491e-05,
      "loss": 0.0094,
      "step": 18940
    },
    {
      "epoch": 5.846960814563406,
      "grad_norm": 1.5696053504943848,
      "learning_rate": 4.4153039185436595e-05,
      "loss": 0.0162,
      "step": 18950
    },
    {
      "epoch": 5.850046282011725,
      "grad_norm": 0.01653195358812809,
      "learning_rate": 4.414995371798828e-05,
      "loss": 0.0135,
      "step": 18960
    },
    {
      "epoch": 5.853131749460044,
      "grad_norm": 1.5392526388168335,
      "learning_rate": 4.414686825053996e-05,
      "loss": 0.0125,
      "step": 18970
    },
    {
      "epoch": 5.8562172169083615,
      "grad_norm": 0.016105124726891518,
      "learning_rate": 4.414378278309164e-05,
      "loss": 0.0093,
      "step": 18980
    },
    {
      "epoch": 5.85930268435668,
      "grad_norm": 4.027551174163818,
      "learning_rate": 4.414069731564332e-05,
      "loss": 0.0136,
      "step": 18990
    },
    {
      "epoch": 5.862388151804998,
      "grad_norm": 0.15022967755794525,
      "learning_rate": 4.4137611848195e-05,
      "loss": 0.0139,
      "step": 19000
    },
    {
      "epoch": 5.865473619253317,
      "grad_norm": 0.014775003306567669,
      "learning_rate": 4.413452638074669e-05,
      "loss": 0.008,
      "step": 19010
    },
    {
      "epoch": 5.8685590867016355,
      "grad_norm": 0.35634735226631165,
      "learning_rate": 4.4131440913298366e-05,
      "loss": 0.0143,
      "step": 19020
    },
    {
      "epoch": 5.871644554149953,
      "grad_norm": 1.4083579778671265,
      "learning_rate": 4.412835544585005e-05,
      "loss": 0.012,
      "step": 19030
    },
    {
      "epoch": 5.874730021598272,
      "grad_norm": 0.3960478603839874,
      "learning_rate": 4.412526997840173e-05,
      "loss": 0.005,
      "step": 19040
    },
    {
      "epoch": 5.877815489046591,
      "grad_norm": 0.3965110182762146,
      "learning_rate": 4.4122184510953413e-05,
      "loss": 0.014,
      "step": 19050
    },
    {
      "epoch": 5.880900956494909,
      "grad_norm": 1.4710581302642822,
      "learning_rate": 4.411909904350509e-05,
      "loss": 0.0253,
      "step": 19060
    },
    {
      "epoch": 5.883986423943227,
      "grad_norm": 0.2995789647102356,
      "learning_rate": 4.411601357605677e-05,
      "loss": 0.0152,
      "step": 19070
    },
    {
      "epoch": 5.887071891391546,
      "grad_norm": 0.09444966912269592,
      "learning_rate": 4.411292810860846e-05,
      "loss": 0.0075,
      "step": 19080
    },
    {
      "epoch": 5.890157358839864,
      "grad_norm": 2.564749240875244,
      "learning_rate": 4.4109842641160137e-05,
      "loss": 0.0042,
      "step": 19090
    },
    {
      "epoch": 5.893242826288183,
      "grad_norm": 0.04481871798634529,
      "learning_rate": 4.410675717371182e-05,
      "loss": 0.0127,
      "step": 19100
    },
    {
      "epoch": 5.896328293736501,
      "grad_norm": 0.2425900250673294,
      "learning_rate": 4.41036717062635e-05,
      "loss": 0.0039,
      "step": 19110
    },
    {
      "epoch": 5.899413761184819,
      "grad_norm": 0.2619381248950958,
      "learning_rate": 4.4100586238815184e-05,
      "loss": 0.0149,
      "step": 19120
    },
    {
      "epoch": 5.902499228633138,
      "grad_norm": 0.5863376259803772,
      "learning_rate": 4.409750077136686e-05,
      "loss": 0.0142,
      "step": 19130
    },
    {
      "epoch": 5.905584696081457,
      "grad_norm": 3.3745312690734863,
      "learning_rate": 4.409441530391855e-05,
      "loss": 0.0224,
      "step": 19140
    },
    {
      "epoch": 5.9086701635297745,
      "grad_norm": 2.5332157611846924,
      "learning_rate": 4.409132983647023e-05,
      "loss": 0.0094,
      "step": 19150
    },
    {
      "epoch": 5.911755630978093,
      "grad_norm": 0.16484665870666504,
      "learning_rate": 4.408824436902191e-05,
      "loss": 0.0053,
      "step": 19160
    },
    {
      "epoch": 5.914841098426412,
      "grad_norm": 0.028722237795591354,
      "learning_rate": 4.408515890157359e-05,
      "loss": 0.0093,
      "step": 19170
    },
    {
      "epoch": 5.91792656587473,
      "grad_norm": 0.6548365354537964,
      "learning_rate": 4.408207343412527e-05,
      "loss": 0.002,
      "step": 19180
    },
    {
      "epoch": 5.9210120333230485,
      "grad_norm": 0.024523979052901268,
      "learning_rate": 4.4078987966676955e-05,
      "loss": 0.0085,
      "step": 19190
    },
    {
      "epoch": 5.924097500771367,
      "grad_norm": 0.16211280226707458,
      "learning_rate": 4.407590249922863e-05,
      "loss": 0.0028,
      "step": 19200
    },
    {
      "epoch": 5.927182968219685,
      "grad_norm": 0.05933351814746857,
      "learning_rate": 4.407281703178032e-05,
      "loss": 0.0055,
      "step": 19210
    },
    {
      "epoch": 5.930268435668004,
      "grad_norm": 0.12599867582321167,
      "learning_rate": 4.4069731564332e-05,
      "loss": 0.0086,
      "step": 19220
    },
    {
      "epoch": 5.9333539031163225,
      "grad_norm": 0.0458189994096756,
      "learning_rate": 4.406664609688368e-05,
      "loss": 0.0034,
      "step": 19230
    },
    {
      "epoch": 5.93643937056464,
      "grad_norm": 0.0015579642495140433,
      "learning_rate": 4.406356062943536e-05,
      "loss": 0.001,
      "step": 19240
    },
    {
      "epoch": 5.939524838012959,
      "grad_norm": 0.10557051002979279,
      "learning_rate": 4.406047516198704e-05,
      "loss": 0.0053,
      "step": 19250
    },
    {
      "epoch": 5.942610305461278,
      "grad_norm": 0.13958576321601868,
      "learning_rate": 4.4057389694538725e-05,
      "loss": 0.0056,
      "step": 19260
    },
    {
      "epoch": 5.945695772909596,
      "grad_norm": 1.597181797027588,
      "learning_rate": 4.40543042270904e-05,
      "loss": 0.0051,
      "step": 19270
    },
    {
      "epoch": 5.948781240357914,
      "grad_norm": 2.087390184402466,
      "learning_rate": 4.405121875964209e-05,
      "loss": 0.0076,
      "step": 19280
    },
    {
      "epoch": 5.951866707806232,
      "grad_norm": 3.345353126525879,
      "learning_rate": 4.404813329219377e-05,
      "loss": 0.0057,
      "step": 19290
    },
    {
      "epoch": 5.954952175254551,
      "grad_norm": 0.06508473306894302,
      "learning_rate": 4.404504782474545e-05,
      "loss": 0.0044,
      "step": 19300
    },
    {
      "epoch": 5.95803764270287,
      "grad_norm": 1.2630428075790405,
      "learning_rate": 4.404196235729713e-05,
      "loss": 0.0109,
      "step": 19310
    },
    {
      "epoch": 5.961123110151188,
      "grad_norm": 2.1375925540924072,
      "learning_rate": 4.403887688984881e-05,
      "loss": 0.0103,
      "step": 19320
    },
    {
      "epoch": 5.964208577599506,
      "grad_norm": 0.10718148946762085,
      "learning_rate": 4.4035791422400496e-05,
      "loss": 0.0026,
      "step": 19330
    },
    {
      "epoch": 5.967294045047825,
      "grad_norm": 0.6790165305137634,
      "learning_rate": 4.403270595495218e-05,
      "loss": 0.0098,
      "step": 19340
    },
    {
      "epoch": 5.970379512496143,
      "grad_norm": 0.009069354273378849,
      "learning_rate": 4.402962048750386e-05,
      "loss": 0.0008,
      "step": 19350
    },
    {
      "epoch": 5.9734649799444615,
      "grad_norm": 0.03953220322728157,
      "learning_rate": 4.402653502005554e-05,
      "loss": 0.0031,
      "step": 19360
    },
    {
      "epoch": 5.97655044739278,
      "grad_norm": 0.47074463963508606,
      "learning_rate": 4.402344955260722e-05,
      "loss": 0.0056,
      "step": 19370
    },
    {
      "epoch": 5.979635914841099,
      "grad_norm": 0.18896567821502686,
      "learning_rate": 4.402036408515891e-05,
      "loss": 0.005,
      "step": 19380
    },
    {
      "epoch": 5.982721382289417,
      "grad_norm": 0.11518445611000061,
      "learning_rate": 4.4017278617710584e-05,
      "loss": 0.0178,
      "step": 19390
    },
    {
      "epoch": 5.9858068497377355,
      "grad_norm": 0.984285295009613,
      "learning_rate": 4.4014193150262266e-05,
      "loss": 0.005,
      "step": 19400
    },
    {
      "epoch": 5.988892317186053,
      "grad_norm": 0.0767383798956871,
      "learning_rate": 4.401110768281395e-05,
      "loss": 0.0037,
      "step": 19410
    },
    {
      "epoch": 5.991977784634372,
      "grad_norm": 0.008228694088757038,
      "learning_rate": 4.400802221536563e-05,
      "loss": 0.0123,
      "step": 19420
    },
    {
      "epoch": 5.995063252082691,
      "grad_norm": 0.7952910661697388,
      "learning_rate": 4.4004936747917314e-05,
      "loss": 0.0072,
      "step": 19430
    },
    {
      "epoch": 5.998148719531009,
      "grad_norm": 0.17508640885353088,
      "learning_rate": 4.400185128046899e-05,
      "loss": 0.0088,
      "step": 19440
    },
    {
      "epoch": 6.0,
      "eval_accuracy_branch1": 0.9971837234647917,
      "eval_accuracy_branch2": 0.4938900301881697,
      "eval_f1_branch1": 0.9965964314402669,
      "eval_f1_branch2": 0.49039540993216624,
      "eval_loss": 0.001813238370232284,
      "eval_precision_branch1": 0.9965403422890531,
      "eval_precision_branch2": 0.5224743699526326,
      "eval_recall_branch1": 0.9966806557168092,
      "eval_recall_branch2": 0.524572495008825,
      "eval_runtime": 238.4803,
      "eval_samples_per_second": 434.765,
      "eval_steps_per_second": 54.348,
      "step": 19446
    },
    {
      "epoch": 6.001234186979327,
      "grad_norm": 0.025031188502907753,
      "learning_rate": 4.399876581302068e-05,
      "loss": 0.0108,
      "step": 19450
    },
    {
      "epoch": 6.004319654427646,
      "grad_norm": 0.4155508279800415,
      "learning_rate": 4.3995680345572354e-05,
      "loss": 0.0034,
      "step": 19460
    },
    {
      "epoch": 6.007405121875964,
      "grad_norm": 0.4839437007904053,
      "learning_rate": 4.399259487812404e-05,
      "loss": 0.0125,
      "step": 19470
    },
    {
      "epoch": 6.010490589324283,
      "grad_norm": 0.01944444328546524,
      "learning_rate": 4.398950941067572e-05,
      "loss": 0.0126,
      "step": 19480
    },
    {
      "epoch": 6.013576056772601,
      "grad_norm": 0.43683022260665894,
      "learning_rate": 4.39864239432274e-05,
      "loss": 0.0146,
      "step": 19490
    },
    {
      "epoch": 6.016661524220919,
      "grad_norm": 1.6960413455963135,
      "learning_rate": 4.3983338475779084e-05,
      "loss": 0.0097,
      "step": 19500
    },
    {
      "epoch": 6.019746991669238,
      "grad_norm": 0.31773486733436584,
      "learning_rate": 4.398025300833076e-05,
      "loss": 0.008,
      "step": 19510
    },
    {
      "epoch": 6.022832459117557,
      "grad_norm": 0.038457490503787994,
      "learning_rate": 4.397716754088245e-05,
      "loss": 0.004,
      "step": 19520
    },
    {
      "epoch": 6.025917926565874,
      "grad_norm": 0.15828388929367065,
      "learning_rate": 4.3974082073434125e-05,
      "loss": 0.0039,
      "step": 19530
    },
    {
      "epoch": 6.029003394014193,
      "grad_norm": 2.114483118057251,
      "learning_rate": 4.397099660598581e-05,
      "loss": 0.0037,
      "step": 19540
    },
    {
      "epoch": 6.032088861462512,
      "grad_norm": 0.030370794236660004,
      "learning_rate": 4.396791113853749e-05,
      "loss": 0.009,
      "step": 19550
    },
    {
      "epoch": 6.03517432891083,
      "grad_norm": 0.0008142617298290133,
      "learning_rate": 4.396482567108917e-05,
      "loss": 0.0027,
      "step": 19560
    },
    {
      "epoch": 6.0382597963591484,
      "grad_norm": 0.771618664264679,
      "learning_rate": 4.3961740203640855e-05,
      "loss": 0.0071,
      "step": 19570
    },
    {
      "epoch": 6.041345263807467,
      "grad_norm": 0.11601614207029343,
      "learning_rate": 4.395865473619253e-05,
      "loss": 0.0014,
      "step": 19580
    },
    {
      "epoch": 6.044430731255785,
      "grad_norm": 0.002359396778047085,
      "learning_rate": 4.395556926874422e-05,
      "loss": 0.0127,
      "step": 19590
    },
    {
      "epoch": 6.047516198704104,
      "grad_norm": 0.01377680990844965,
      "learning_rate": 4.3952483801295895e-05,
      "loss": 0.003,
      "step": 19600
    },
    {
      "epoch": 6.0506016661524225,
      "grad_norm": 0.031205184757709503,
      "learning_rate": 4.394939833384758e-05,
      "loss": 0.0037,
      "step": 19610
    },
    {
      "epoch": 6.05368713360074,
      "grad_norm": 0.0719299465417862,
      "learning_rate": 4.394631286639927e-05,
      "loss": 0.0034,
      "step": 19620
    },
    {
      "epoch": 6.056772601049059,
      "grad_norm": 0.006747508887201548,
      "learning_rate": 4.394322739895094e-05,
      "loss": 0.0121,
      "step": 19630
    },
    {
      "epoch": 6.059858068497378,
      "grad_norm": 0.011635773815214634,
      "learning_rate": 4.3940141931502625e-05,
      "loss": 0.011,
      "step": 19640
    },
    {
      "epoch": 6.062943535945696,
      "grad_norm": 1.338059425354004,
      "learning_rate": 4.393705646405431e-05,
      "loss": 0.0043,
      "step": 19650
    },
    {
      "epoch": 6.066029003394014,
      "grad_norm": 0.3447963297367096,
      "learning_rate": 4.393397099660599e-05,
      "loss": 0.0038,
      "step": 19660
    },
    {
      "epoch": 6.069114470842333,
      "grad_norm": 1.579786777496338,
      "learning_rate": 4.3930885529157666e-05,
      "loss": 0.0043,
      "step": 19670
    },
    {
      "epoch": 6.072199938290651,
      "grad_norm": 1.5588370561599731,
      "learning_rate": 4.392780006170935e-05,
      "loss": 0.0017,
      "step": 19680
    },
    {
      "epoch": 6.07528540573897,
      "grad_norm": 0.591575026512146,
      "learning_rate": 4.392471459426104e-05,
      "loss": 0.0149,
      "step": 19690
    },
    {
      "epoch": 6.078370873187288,
      "grad_norm": 0.2605186402797699,
      "learning_rate": 4.3921629126812713e-05,
      "loss": 0.0243,
      "step": 19700
    },
    {
      "epoch": 6.081456340635606,
      "grad_norm": 0.029566839337348938,
      "learning_rate": 4.3918543659364396e-05,
      "loss": 0.0187,
      "step": 19710
    },
    {
      "epoch": 6.084541808083925,
      "grad_norm": 2.066962718963623,
      "learning_rate": 4.391545819191608e-05,
      "loss": 0.0123,
      "step": 19720
    },
    {
      "epoch": 6.087627275532243,
      "grad_norm": 0.29763150215148926,
      "learning_rate": 4.391237272446776e-05,
      "loss": 0.0053,
      "step": 19730
    },
    {
      "epoch": 6.090712742980561,
      "grad_norm": 0.7163619995117188,
      "learning_rate": 4.3909287257019437e-05,
      "loss": 0.0046,
      "step": 19740
    },
    {
      "epoch": 6.09379821042888,
      "grad_norm": 0.03128092363476753,
      "learning_rate": 4.390620178957112e-05,
      "loss": 0.0013,
      "step": 19750
    },
    {
      "epoch": 6.096883677877198,
      "grad_norm": 0.31774061918258667,
      "learning_rate": 4.390311632212281e-05,
      "loss": 0.0093,
      "step": 19760
    },
    {
      "epoch": 6.099969145325517,
      "grad_norm": 0.0036462859716266394,
      "learning_rate": 4.3900030854674484e-05,
      "loss": 0.0011,
      "step": 19770
    },
    {
      "epoch": 6.103054612773835,
      "grad_norm": 0.011096274480223656,
      "learning_rate": 4.3896945387226166e-05,
      "loss": 0.007,
      "step": 19780
    },
    {
      "epoch": 6.106140080222153,
      "grad_norm": 4.299456596374512,
      "learning_rate": 4.389385991977785e-05,
      "loss": 0.0058,
      "step": 19790
    },
    {
      "epoch": 6.109225547670472,
      "grad_norm": 1.051062822341919,
      "learning_rate": 4.389077445232953e-05,
      "loss": 0.0085,
      "step": 19800
    },
    {
      "epoch": 6.112311015118791,
      "grad_norm": 0.0006275329506024718,
      "learning_rate": 4.388768898488121e-05,
      "loss": 0.0015,
      "step": 19810
    },
    {
      "epoch": 6.1153964825671085,
      "grad_norm": 0.004876970313489437,
      "learning_rate": 4.388460351743289e-05,
      "loss": 0.001,
      "step": 19820
    },
    {
      "epoch": 6.118481950015427,
      "grad_norm": 0.04866981506347656,
      "learning_rate": 4.388151804998458e-05,
      "loss": 0.0016,
      "step": 19830
    },
    {
      "epoch": 6.121567417463746,
      "grad_norm": 1.2586538791656494,
      "learning_rate": 4.3878432582536255e-05,
      "loss": 0.006,
      "step": 19840
    },
    {
      "epoch": 6.124652884912064,
      "grad_norm": 0.007722432259470224,
      "learning_rate": 4.387534711508794e-05,
      "loss": 0.0015,
      "step": 19850
    },
    {
      "epoch": 6.127738352360383,
      "grad_norm": 0.9713599681854248,
      "learning_rate": 4.387226164763962e-05,
      "loss": 0.0014,
      "step": 19860
    },
    {
      "epoch": 6.130823819808701,
      "grad_norm": 1.5190393924713135,
      "learning_rate": 4.38691761801913e-05,
      "loss": 0.0075,
      "step": 19870
    },
    {
      "epoch": 6.133909287257019,
      "grad_norm": 2.13279128074646,
      "learning_rate": 4.3866090712742984e-05,
      "loss": 0.0116,
      "step": 19880
    },
    {
      "epoch": 6.136994754705338,
      "grad_norm": 0.09045141935348511,
      "learning_rate": 4.386300524529467e-05,
      "loss": 0.005,
      "step": 19890
    },
    {
      "epoch": 6.140080222153657,
      "grad_norm": 1.6062108278274536,
      "learning_rate": 4.385991977784635e-05,
      "loss": 0.0121,
      "step": 19900
    },
    {
      "epoch": 6.143165689601974,
      "grad_norm": 2.3171732425689697,
      "learning_rate": 4.3856834310398025e-05,
      "loss": 0.0219,
      "step": 19910
    },
    {
      "epoch": 6.146251157050293,
      "grad_norm": 0.003073149360716343,
      "learning_rate": 4.385374884294971e-05,
      "loss": 0.0013,
      "step": 19920
    },
    {
      "epoch": 6.149336624498612,
      "grad_norm": 0.008792058564722538,
      "learning_rate": 4.385066337550139e-05,
      "loss": 0.0086,
      "step": 19930
    },
    {
      "epoch": 6.15242209194693,
      "grad_norm": 0.06959453970193863,
      "learning_rate": 4.384757790805307e-05,
      "loss": 0.0091,
      "step": 19940
    },
    {
      "epoch": 6.155507559395248,
      "grad_norm": 5.511371612548828,
      "learning_rate": 4.3844492440604755e-05,
      "loss": 0.0153,
      "step": 19950
    },
    {
      "epoch": 6.158593026843567,
      "grad_norm": 0.049966029822826385,
      "learning_rate": 4.384140697315644e-05,
      "loss": 0.0041,
      "step": 19960
    },
    {
      "epoch": 6.161678494291885,
      "grad_norm": 0.09815894812345505,
      "learning_rate": 4.383832150570812e-05,
      "loss": 0.0029,
      "step": 19970
    },
    {
      "epoch": 6.164763961740204,
      "grad_norm": 0.006661337334662676,
      "learning_rate": 4.3835236038259796e-05,
      "loss": 0.0133,
      "step": 19980
    },
    {
      "epoch": 6.167849429188522,
      "grad_norm": 0.7567116022109985,
      "learning_rate": 4.383215057081148e-05,
      "loss": 0.0025,
      "step": 19990
    },
    {
      "epoch": 6.17093489663684,
      "grad_norm": 0.023551924154162407,
      "learning_rate": 4.382906510336316e-05,
      "loss": 0.0045,
      "step": 20000
    },
    {
      "epoch": 6.174020364085159,
      "grad_norm": 1.3671659231185913,
      "learning_rate": 4.382597963591484e-05,
      "loss": 0.0103,
      "step": 20010
    },
    {
      "epoch": 6.177105831533478,
      "grad_norm": 0.021214161068201065,
      "learning_rate": 4.3822894168466526e-05,
      "loss": 0.0012,
      "step": 20020
    },
    {
      "epoch": 6.1801912989817955,
      "grad_norm": 0.10823294520378113,
      "learning_rate": 4.381980870101821e-05,
      "loss": 0.0037,
      "step": 20030
    },
    {
      "epoch": 6.183276766430114,
      "grad_norm": 0.36305972933769226,
      "learning_rate": 4.381672323356989e-05,
      "loss": 0.0062,
      "step": 20040
    },
    {
      "epoch": 6.186362233878433,
      "grad_norm": 4.414568901062012,
      "learning_rate": 4.3813637766121566e-05,
      "loss": 0.0164,
      "step": 20050
    },
    {
      "epoch": 6.189447701326751,
      "grad_norm": 1.8320083618164062,
      "learning_rate": 4.381055229867325e-05,
      "loss": 0.0024,
      "step": 20060
    },
    {
      "epoch": 6.1925331687750695,
      "grad_norm": 2.8624417781829834,
      "learning_rate": 4.380746683122493e-05,
      "loss": 0.0216,
      "step": 20070
    },
    {
      "epoch": 6.195618636223388,
      "grad_norm": 0.039145033806562424,
      "learning_rate": 4.3804381363776614e-05,
      "loss": 0.0037,
      "step": 20080
    },
    {
      "epoch": 6.198704103671706,
      "grad_norm": 3.0688650608062744,
      "learning_rate": 4.3801295896328296e-05,
      "loss": 0.0129,
      "step": 20090
    },
    {
      "epoch": 6.201789571120025,
      "grad_norm": 0.1665601134300232,
      "learning_rate": 4.379821042887998e-05,
      "loss": 0.0092,
      "step": 20100
    },
    {
      "epoch": 6.204875038568343,
      "grad_norm": 0.7377421259880066,
      "learning_rate": 4.379512496143166e-05,
      "loss": 0.0079,
      "step": 20110
    },
    {
      "epoch": 6.207960506016661,
      "grad_norm": 1.2776981592178345,
      "learning_rate": 4.379203949398334e-05,
      "loss": 0.0038,
      "step": 20120
    },
    {
      "epoch": 6.21104597346498,
      "grad_norm": 0.7342957854270935,
      "learning_rate": 4.3788954026535026e-05,
      "loss": 0.0056,
      "step": 20130
    },
    {
      "epoch": 6.214131440913298,
      "grad_norm": 0.00037684227572754025,
      "learning_rate": 4.37858685590867e-05,
      "loss": 0.0069,
      "step": 20140
    },
    {
      "epoch": 6.217216908361617,
      "grad_norm": 0.577774167060852,
      "learning_rate": 4.3782783091638384e-05,
      "loss": 0.0044,
      "step": 20150
    },
    {
      "epoch": 6.220302375809935,
      "grad_norm": 0.13624976575374603,
      "learning_rate": 4.377969762419007e-05,
      "loss": 0.0007,
      "step": 20160
    },
    {
      "epoch": 6.223387843258253,
      "grad_norm": 1.9047996997833252,
      "learning_rate": 4.377661215674175e-05,
      "loss": 0.0039,
      "step": 20170
    },
    {
      "epoch": 6.226473310706572,
      "grad_norm": 0.029078546911478043,
      "learning_rate": 4.377352668929343e-05,
      "loss": 0.0165,
      "step": 20180
    },
    {
      "epoch": 6.229558778154891,
      "grad_norm": 0.011036568321287632,
      "learning_rate": 4.377044122184511e-05,
      "loss": 0.0027,
      "step": 20190
    },
    {
      "epoch": 6.2326442456032085,
      "grad_norm": 0.5926899313926697,
      "learning_rate": 4.37673557543968e-05,
      "loss": 0.0199,
      "step": 20200
    },
    {
      "epoch": 6.235729713051527,
      "grad_norm": 1.4956951141357422,
      "learning_rate": 4.376427028694847e-05,
      "loss": 0.0014,
      "step": 20210
    },
    {
      "epoch": 6.238815180499846,
      "grad_norm": 3.314101457595825,
      "learning_rate": 4.3761184819500155e-05,
      "loss": 0.0102,
      "step": 20220
    },
    {
      "epoch": 6.241900647948164,
      "grad_norm": 0.053903985768556595,
      "learning_rate": 4.375809935205184e-05,
      "loss": 0.007,
      "step": 20230
    },
    {
      "epoch": 6.2449861153964825,
      "grad_norm": 0.009256857447326183,
      "learning_rate": 4.375501388460352e-05,
      "loss": 0.0086,
      "step": 20240
    },
    {
      "epoch": 6.248071582844801,
      "grad_norm": 0.11655201762914658,
      "learning_rate": 4.37519284171552e-05,
      "loss": 0.0149,
      "step": 20250
    },
    {
      "epoch": 6.251157050293119,
      "grad_norm": 1.9162002801895142,
      "learning_rate": 4.374884294970688e-05,
      "loss": 0.0077,
      "step": 20260
    },
    {
      "epoch": 6.254242517741438,
      "grad_norm": 0.08433527499437332,
      "learning_rate": 4.374575748225857e-05,
      "loss": 0.0037,
      "step": 20270
    },
    {
      "epoch": 6.2573279851897565,
      "grad_norm": 0.4047539532184601,
      "learning_rate": 4.374267201481024e-05,
      "loss": 0.0061,
      "step": 20280
    },
    {
      "epoch": 6.260413452638074,
      "grad_norm": 0.03531233221292496,
      "learning_rate": 4.3739586547361925e-05,
      "loss": 0.0113,
      "step": 20290
    },
    {
      "epoch": 6.263498920086393,
      "grad_norm": 2.980351209640503,
      "learning_rate": 4.373650107991361e-05,
      "loss": 0.0023,
      "step": 20300
    },
    {
      "epoch": 6.266584387534712,
      "grad_norm": 2.7205491065979004,
      "learning_rate": 4.373341561246529e-05,
      "loss": 0.0031,
      "step": 20310
    },
    {
      "epoch": 6.26966985498303,
      "grad_norm": 0.06559325009584427,
      "learning_rate": 4.373033014501697e-05,
      "loss": 0.006,
      "step": 20320
    },
    {
      "epoch": 6.272755322431348,
      "grad_norm": 3.013029098510742,
      "learning_rate": 4.372724467756865e-05,
      "loss": 0.0224,
      "step": 20330
    },
    {
      "epoch": 6.275840789879667,
      "grad_norm": 0.004595499020069838,
      "learning_rate": 4.372415921012034e-05,
      "loss": 0.0064,
      "step": 20340
    },
    {
      "epoch": 6.278926257327985,
      "grad_norm": 0.3163924515247345,
      "learning_rate": 4.372107374267202e-05,
      "loss": 0.0037,
      "step": 20350
    },
    {
      "epoch": 6.282011724776304,
      "grad_norm": 1.3729181289672852,
      "learning_rate": 4.3717988275223696e-05,
      "loss": 0.0039,
      "step": 20360
    },
    {
      "epoch": 6.285097192224622,
      "grad_norm": 0.337251752614975,
      "learning_rate": 4.3714902807775385e-05,
      "loss": 0.0045,
      "step": 20370
    },
    {
      "epoch": 6.28818265967294,
      "grad_norm": 1.8841172456741333,
      "learning_rate": 4.371181734032706e-05,
      "loss": 0.0191,
      "step": 20380
    },
    {
      "epoch": 6.291268127121259,
      "grad_norm": 0.12795664370059967,
      "learning_rate": 4.370873187287874e-05,
      "loss": 0.0029,
      "step": 20390
    },
    {
      "epoch": 6.294353594569578,
      "grad_norm": 0.0038797655142843723,
      "learning_rate": 4.3705646405430426e-05,
      "loss": 0.0027,
      "step": 20400
    },
    {
      "epoch": 6.2974390620178955,
      "grad_norm": 2.8170318603515625,
      "learning_rate": 4.370256093798211e-05,
      "loss": 0.0041,
      "step": 20410
    },
    {
      "epoch": 6.300524529466214,
      "grad_norm": 0.022790517657995224,
      "learning_rate": 4.369947547053379e-05,
      "loss": 0.0055,
      "step": 20420
    },
    {
      "epoch": 6.303609996914533,
      "grad_norm": 0.014921688474714756,
      "learning_rate": 4.3696390003085466e-05,
      "loss": 0.0134,
      "step": 20430
    },
    {
      "epoch": 6.306695464362851,
      "grad_norm": 0.0016494382871314883,
      "learning_rate": 4.3693304535637156e-05,
      "loss": 0.0261,
      "step": 20440
    },
    {
      "epoch": 6.3097809318111695,
      "grad_norm": 0.0008995062671601772,
      "learning_rate": 4.369021906818883e-05,
      "loss": 0.0097,
      "step": 20450
    },
    {
      "epoch": 6.312866399259488,
      "grad_norm": 0.5651404857635498,
      "learning_rate": 4.3687133600740514e-05,
      "loss": 0.007,
      "step": 20460
    },
    {
      "epoch": 6.315951866707806,
      "grad_norm": 0.07203906029462814,
      "learning_rate": 4.3684048133292196e-05,
      "loss": 0.0134,
      "step": 20470
    },
    {
      "epoch": 6.319037334156125,
      "grad_norm": 0.2601079046726227,
      "learning_rate": 4.368096266584388e-05,
      "loss": 0.002,
      "step": 20480
    },
    {
      "epoch": 6.3221228016044435,
      "grad_norm": 0.0441519170999527,
      "learning_rate": 4.367787719839556e-05,
      "loss": 0.0045,
      "step": 20490
    },
    {
      "epoch": 6.325208269052761,
      "grad_norm": 0.20930850505828857,
      "learning_rate": 4.367479173094724e-05,
      "loss": 0.0125,
      "step": 20500
    },
    {
      "epoch": 6.32829373650108,
      "grad_norm": 0.10744304209947586,
      "learning_rate": 4.3671706263498926e-05,
      "loss": 0.0019,
      "step": 20510
    },
    {
      "epoch": 6.331379203949398,
      "grad_norm": 0.006621269509196281,
      "learning_rate": 4.36686207960506e-05,
      "loss": 0.0025,
      "step": 20520
    },
    {
      "epoch": 6.334464671397717,
      "grad_norm": 0.008771580643951893,
      "learning_rate": 4.3665535328602284e-05,
      "loss": 0.0081,
      "step": 20530
    },
    {
      "epoch": 6.337550138846035,
      "grad_norm": 0.005061639007180929,
      "learning_rate": 4.366244986115397e-05,
      "loss": 0.0021,
      "step": 20540
    },
    {
      "epoch": 6.340635606294353,
      "grad_norm": 0.028912167996168137,
      "learning_rate": 4.365936439370565e-05,
      "loss": 0.0056,
      "step": 20550
    },
    {
      "epoch": 6.343721073742672,
      "grad_norm": 0.05212315544486046,
      "learning_rate": 4.365627892625733e-05,
      "loss": 0.0113,
      "step": 20560
    },
    {
      "epoch": 6.346806541190991,
      "grad_norm": 3.261838436126709,
      "learning_rate": 4.365319345880901e-05,
      "loss": 0.0046,
      "step": 20570
    },
    {
      "epoch": 6.3498920086393085,
      "grad_norm": 3.014859199523926,
      "learning_rate": 4.36501079913607e-05,
      "loss": 0.009,
      "step": 20580
    },
    {
      "epoch": 6.352977476087627,
      "grad_norm": 0.003957700915634632,
      "learning_rate": 4.364702252391237e-05,
      "loss": 0.0058,
      "step": 20590
    },
    {
      "epoch": 6.356062943535946,
      "grad_norm": 0.003190044080838561,
      "learning_rate": 4.3643937056464055e-05,
      "loss": 0.0206,
      "step": 20600
    },
    {
      "epoch": 6.359148410984264,
      "grad_norm": 0.014715070836246014,
      "learning_rate": 4.364085158901574e-05,
      "loss": 0.0105,
      "step": 20610
    },
    {
      "epoch": 6.3622338784325825,
      "grad_norm": 0.562056303024292,
      "learning_rate": 4.363776612156742e-05,
      "loss": 0.0076,
      "step": 20620
    },
    {
      "epoch": 6.365319345880901,
      "grad_norm": 0.07819163054227829,
      "learning_rate": 4.36346806541191e-05,
      "loss": 0.0048,
      "step": 20630
    },
    {
      "epoch": 6.368404813329219,
      "grad_norm": 0.0011127808829769492,
      "learning_rate": 4.3631595186670785e-05,
      "loss": 0.0059,
      "step": 20640
    },
    {
      "epoch": 6.371490280777538,
      "grad_norm": 0.32144808769226074,
      "learning_rate": 4.362850971922247e-05,
      "loss": 0.023,
      "step": 20650
    },
    {
      "epoch": 6.3745757482258565,
      "grad_norm": 1.231318473815918,
      "learning_rate": 4.362542425177414e-05,
      "loss": 0.0193,
      "step": 20660
    },
    {
      "epoch": 6.377661215674174,
      "grad_norm": 0.04806244373321533,
      "learning_rate": 4.3622338784325826e-05,
      "loss": 0.0103,
      "step": 20670
    },
    {
      "epoch": 6.380746683122493,
      "grad_norm": 0.0004529393627308309,
      "learning_rate": 4.361925331687751e-05,
      "loss": 0.0026,
      "step": 20680
    },
    {
      "epoch": 6.383832150570812,
      "grad_norm": 0.050820719450712204,
      "learning_rate": 4.361616784942919e-05,
      "loss": 0.0038,
      "step": 20690
    },
    {
      "epoch": 6.38691761801913,
      "grad_norm": 3.553575038909912,
      "learning_rate": 4.361308238198087e-05,
      "loss": 0.0209,
      "step": 20700
    },
    {
      "epoch": 6.390003085467448,
      "grad_norm": 0.002464711433276534,
      "learning_rate": 4.3609996914532556e-05,
      "loss": 0.0163,
      "step": 20710
    },
    {
      "epoch": 6.393088552915767,
      "grad_norm": 0.0963410809636116,
      "learning_rate": 4.360691144708424e-05,
      "loss": 0.0097,
      "step": 20720
    },
    {
      "epoch": 6.396174020364085,
      "grad_norm": 1.5125808715820312,
      "learning_rate": 4.3603825979635914e-05,
      "loss": 0.0035,
      "step": 20730
    },
    {
      "epoch": 6.399259487812404,
      "grad_norm": 0.14225707948207855,
      "learning_rate": 4.3600740512187596e-05,
      "loss": 0.0051,
      "step": 20740
    },
    {
      "epoch": 6.402344955260722,
      "grad_norm": 1.6935944557189941,
      "learning_rate": 4.3597655044739285e-05,
      "loss": 0.0084,
      "step": 20750
    },
    {
      "epoch": 6.40543042270904,
      "grad_norm": 0.013054480776190758,
      "learning_rate": 4.359456957729096e-05,
      "loss": 0.0052,
      "step": 20760
    },
    {
      "epoch": 6.408515890157359,
      "grad_norm": 0.31036579608917236,
      "learning_rate": 4.3591484109842644e-05,
      "loss": 0.0005,
      "step": 20770
    },
    {
      "epoch": 6.411601357605678,
      "grad_norm": 0.3046468198299408,
      "learning_rate": 4.3588398642394326e-05,
      "loss": 0.0058,
      "step": 20780
    },
    {
      "epoch": 6.4146868250539955,
      "grad_norm": 0.02159672975540161,
      "learning_rate": 4.358531317494601e-05,
      "loss": 0.0029,
      "step": 20790
    },
    {
      "epoch": 6.417772292502314,
      "grad_norm": 0.04802187159657478,
      "learning_rate": 4.3582227707497684e-05,
      "loss": 0.009,
      "step": 20800
    },
    {
      "epoch": 6.420857759950633,
      "grad_norm": 1.6582955121994019,
      "learning_rate": 4.357914224004937e-05,
      "loss": 0.0033,
      "step": 20810
    },
    {
      "epoch": 6.423943227398951,
      "grad_norm": 0.12645050883293152,
      "learning_rate": 4.3576056772601056e-05,
      "loss": 0.0263,
      "step": 20820
    },
    {
      "epoch": 6.4270286948472695,
      "grad_norm": 0.010596192441880703,
      "learning_rate": 4.357297130515273e-05,
      "loss": 0.0044,
      "step": 20830
    },
    {
      "epoch": 6.430114162295588,
      "grad_norm": 3.334868907928467,
      "learning_rate": 4.3569885837704414e-05,
      "loss": 0.0125,
      "step": 20840
    },
    {
      "epoch": 6.433199629743906,
      "grad_norm": 0.14738069474697113,
      "learning_rate": 4.35668003702561e-05,
      "loss": 0.0085,
      "step": 20850
    },
    {
      "epoch": 6.436285097192225,
      "grad_norm": 0.010663899593055248,
      "learning_rate": 4.356371490280778e-05,
      "loss": 0.008,
      "step": 20860
    },
    {
      "epoch": 6.439370564640543,
      "grad_norm": 0.19266578555107117,
      "learning_rate": 4.3560629435359455e-05,
      "loss": 0.0031,
      "step": 20870
    },
    {
      "epoch": 6.442456032088861,
      "grad_norm": 0.8931399583816528,
      "learning_rate": 4.3557543967911144e-05,
      "loss": 0.0025,
      "step": 20880
    },
    {
      "epoch": 6.44554149953718,
      "grad_norm": 0.0022820846643298864,
      "learning_rate": 4.3554458500462827e-05,
      "loss": 0.0112,
      "step": 20890
    },
    {
      "epoch": 6.448626966985499,
      "grad_norm": 0.019349265843629837,
      "learning_rate": 4.35513730330145e-05,
      "loss": 0.0039,
      "step": 20900
    },
    {
      "epoch": 6.451712434433817,
      "grad_norm": 0.018481960520148277,
      "learning_rate": 4.3548287565566185e-05,
      "loss": 0.0014,
      "step": 20910
    },
    {
      "epoch": 6.454797901882135,
      "grad_norm": 0.004926789086312056,
      "learning_rate": 4.354520209811787e-05,
      "loss": 0.003,
      "step": 20920
    },
    {
      "epoch": 6.457883369330453,
      "grad_norm": 0.002968425629660487,
      "learning_rate": 4.354211663066955e-05,
      "loss": 0.0049,
      "step": 20930
    },
    {
      "epoch": 6.460968836778772,
      "grad_norm": 5.064061641693115,
      "learning_rate": 4.3539031163221225e-05,
      "loss": 0.0054,
      "step": 20940
    },
    {
      "epoch": 6.464054304227091,
      "grad_norm": 0.8685519695281982,
      "learning_rate": 4.3535945695772915e-05,
      "loss": 0.0017,
      "step": 20950
    },
    {
      "epoch": 6.467139771675408,
      "grad_norm": 0.04249992221593857,
      "learning_rate": 4.35328602283246e-05,
      "loss": 0.0255,
      "step": 20960
    },
    {
      "epoch": 6.470225239123727,
      "grad_norm": 0.10273344814777374,
      "learning_rate": 4.352977476087627e-05,
      "loss": 0.0051,
      "step": 20970
    },
    {
      "epoch": 6.473310706572046,
      "grad_norm": 0.6940929293632507,
      "learning_rate": 4.3526689293427955e-05,
      "loss": 0.0128,
      "step": 20980
    },
    {
      "epoch": 6.476396174020364,
      "grad_norm": 3.314476251602173,
      "learning_rate": 4.352360382597964e-05,
      "loss": 0.0062,
      "step": 20990
    },
    {
      "epoch": 6.479481641468682,
      "grad_norm": 0.8113518953323364,
      "learning_rate": 4.352051835853132e-05,
      "loss": 0.0124,
      "step": 21000
    },
    {
      "epoch": 6.482567108917001,
      "grad_norm": 0.16427157819271088,
      "learning_rate": 4.3517432891082996e-05,
      "loss": 0.0055,
      "step": 21010
    },
    {
      "epoch": 6.485652576365319,
      "grad_norm": 0.49828898906707764,
      "learning_rate": 4.3514347423634685e-05,
      "loss": 0.0038,
      "step": 21020
    },
    {
      "epoch": 6.488738043813638,
      "grad_norm": 0.10462439060211182,
      "learning_rate": 4.351126195618637e-05,
      "loss": 0.0094,
      "step": 21030
    },
    {
      "epoch": 6.4918235112619564,
      "grad_norm": 0.05407291650772095,
      "learning_rate": 4.350817648873804e-05,
      "loss": 0.0116,
      "step": 21040
    },
    {
      "epoch": 6.494908978710274,
      "grad_norm": 0.2764866352081299,
      "learning_rate": 4.3505091021289726e-05,
      "loss": 0.0131,
      "step": 21050
    },
    {
      "epoch": 6.497994446158593,
      "grad_norm": 1.4808766841888428,
      "learning_rate": 4.350200555384141e-05,
      "loss": 0.0154,
      "step": 21060
    },
    {
      "epoch": 6.501079913606912,
      "grad_norm": 0.08473675698041916,
      "learning_rate": 4.349892008639309e-05,
      "loss": 0.0078,
      "step": 21070
    },
    {
      "epoch": 6.50416538105523,
      "grad_norm": 2.1274099349975586,
      "learning_rate": 4.3495834618944767e-05,
      "loss": 0.007,
      "step": 21080
    },
    {
      "epoch": 6.507250848503548,
      "grad_norm": 1.219818353652954,
      "learning_rate": 4.3492749151496456e-05,
      "loss": 0.0059,
      "step": 21090
    },
    {
      "epoch": 6.510336315951867,
      "grad_norm": 1.3143372535705566,
      "learning_rate": 4.348966368404814e-05,
      "loss": 0.0125,
      "step": 21100
    },
    {
      "epoch": 6.513421783400185,
      "grad_norm": 0.3260611593723297,
      "learning_rate": 4.3486578216599814e-05,
      "loss": 0.0032,
      "step": 21110
    },
    {
      "epoch": 6.516507250848504,
      "grad_norm": 0.056691598147153854,
      "learning_rate": 4.34834927491515e-05,
      "loss": 0.0082,
      "step": 21120
    },
    {
      "epoch": 6.519592718296822,
      "grad_norm": 0.04055064544081688,
      "learning_rate": 4.348040728170318e-05,
      "loss": 0.0029,
      "step": 21130
    },
    {
      "epoch": 6.52267818574514,
      "grad_norm": 0.2948054373264313,
      "learning_rate": 4.347732181425486e-05,
      "loss": 0.013,
      "step": 21140
    },
    {
      "epoch": 6.525763653193459,
      "grad_norm": 0.31431156396865845,
      "learning_rate": 4.3474236346806544e-05,
      "loss": 0.0082,
      "step": 21150
    },
    {
      "epoch": 6.528849120641778,
      "grad_norm": 0.024619005620479584,
      "learning_rate": 4.3471150879358226e-05,
      "loss": 0.0117,
      "step": 21160
    },
    {
      "epoch": 6.531934588090095,
      "grad_norm": 0.25848424434661865,
      "learning_rate": 4.346806541190991e-05,
      "loss": 0.0025,
      "step": 21170
    },
    {
      "epoch": 6.535020055538414,
      "grad_norm": 0.010152383707463741,
      "learning_rate": 4.3464979944461585e-05,
      "loss": 0.0302,
      "step": 21180
    },
    {
      "epoch": 6.538105522986733,
      "grad_norm": 0.016424935311079025,
      "learning_rate": 4.3461894477013274e-05,
      "loss": 0.0022,
      "step": 21190
    },
    {
      "epoch": 6.541190990435051,
      "grad_norm": 2.369464874267578,
      "learning_rate": 4.345880900956495e-05,
      "loss": 0.0101,
      "step": 21200
    },
    {
      "epoch": 6.544276457883369,
      "grad_norm": 0.25409436225891113,
      "learning_rate": 4.345572354211663e-05,
      "loss": 0.0093,
      "step": 21210
    },
    {
      "epoch": 6.547361925331687,
      "grad_norm": 0.1293962001800537,
      "learning_rate": 4.3452638074668314e-05,
      "loss": 0.0145,
      "step": 21220
    },
    {
      "epoch": 6.550447392780006,
      "grad_norm": 3.1764307022094727,
      "learning_rate": 4.344955260722e-05,
      "loss": 0.0059,
      "step": 21230
    },
    {
      "epoch": 6.553532860228325,
      "grad_norm": 0.05636971816420555,
      "learning_rate": 4.344646713977168e-05,
      "loss": 0.0041,
      "step": 21240
    },
    {
      "epoch": 6.556618327676643,
      "grad_norm": 0.20124147832393646,
      "learning_rate": 4.3443381672323355e-05,
      "loss": 0.0008,
      "step": 21250
    },
    {
      "epoch": 6.559703795124961,
      "grad_norm": 0.3487820327281952,
      "learning_rate": 4.3440296204875044e-05,
      "loss": 0.0094,
      "step": 21260
    },
    {
      "epoch": 6.56278926257328,
      "grad_norm": 0.010135778225958347,
      "learning_rate": 4.343721073742672e-05,
      "loss": 0.0069,
      "step": 21270
    },
    {
      "epoch": 6.565874730021598,
      "grad_norm": 0.13534989953041077,
      "learning_rate": 4.34341252699784e-05,
      "loss": 0.0036,
      "step": 21280
    },
    {
      "epoch": 6.5689601974699166,
      "grad_norm": 1.4448150396347046,
      "learning_rate": 4.3431039802530085e-05,
      "loss": 0.0108,
      "step": 21290
    },
    {
      "epoch": 6.572045664918235,
      "grad_norm": 0.2954677939414978,
      "learning_rate": 4.342795433508177e-05,
      "loss": 0.001,
      "step": 21300
    },
    {
      "epoch": 6.575131132366554,
      "grad_norm": 0.08455072343349457,
      "learning_rate": 4.342486886763345e-05,
      "loss": 0.0019,
      "step": 21310
    },
    {
      "epoch": 6.578216599814872,
      "grad_norm": 0.42725899815559387,
      "learning_rate": 4.3421783400185126e-05,
      "loss": 0.0007,
      "step": 21320
    },
    {
      "epoch": 6.581302067263191,
      "grad_norm": 3.02091383934021,
      "learning_rate": 4.3418697932736815e-05,
      "loss": 0.0093,
      "step": 21330
    },
    {
      "epoch": 6.584387534711508,
      "grad_norm": 0.44968661665916443,
      "learning_rate": 4.341561246528849e-05,
      "loss": 0.0026,
      "step": 21340
    },
    {
      "epoch": 6.587473002159827,
      "grad_norm": 0.8151145577430725,
      "learning_rate": 4.341252699784017e-05,
      "loss": 0.0092,
      "step": 21350
    },
    {
      "epoch": 6.590558469608146,
      "grad_norm": 0.032821789383888245,
      "learning_rate": 4.3409441530391856e-05,
      "loss": 0.0087,
      "step": 21360
    },
    {
      "epoch": 6.593643937056464,
      "grad_norm": 1.3342994451522827,
      "learning_rate": 4.340635606294354e-05,
      "loss": 0.0053,
      "step": 21370
    },
    {
      "epoch": 6.596729404504782,
      "grad_norm": 0.11135336756706238,
      "learning_rate": 4.340327059549522e-05,
      "loss": 0.0184,
      "step": 21380
    },
    {
      "epoch": 6.599814871953101,
      "grad_norm": 0.0415649488568306,
      "learning_rate": 4.34001851280469e-05,
      "loss": 0.0076,
      "step": 21390
    },
    {
      "epoch": 6.602900339401419,
      "grad_norm": 0.5098322629928589,
      "learning_rate": 4.3397099660598585e-05,
      "loss": 0.006,
      "step": 21400
    },
    {
      "epoch": 6.605985806849738,
      "grad_norm": 0.0032164237927645445,
      "learning_rate": 4.339401419315026e-05,
      "loss": 0.0158,
      "step": 21410
    },
    {
      "epoch": 6.609071274298056,
      "grad_norm": 0.4074234068393707,
      "learning_rate": 4.3390928725701944e-05,
      "loss": 0.002,
      "step": 21420
    },
    {
      "epoch": 6.612156741746374,
      "grad_norm": 1.3531941175460815,
      "learning_rate": 4.338784325825363e-05,
      "loss": 0.0081,
      "step": 21430
    },
    {
      "epoch": 6.615242209194693,
      "grad_norm": 0.32988184690475464,
      "learning_rate": 4.338475779080531e-05,
      "loss": 0.0057,
      "step": 21440
    },
    {
      "epoch": 6.618327676643012,
      "grad_norm": 0.3440116345882416,
      "learning_rate": 4.338167232335699e-05,
      "loss": 0.01,
      "step": 21450
    },
    {
      "epoch": 6.6214131440913295,
      "grad_norm": 1.2671535015106201,
      "learning_rate": 4.3378586855908674e-05,
      "loss": 0.0119,
      "step": 21460
    },
    {
      "epoch": 6.624498611539648,
      "grad_norm": 0.0018246646504849195,
      "learning_rate": 4.3375501388460356e-05,
      "loss": 0.0067,
      "step": 21470
    },
    {
      "epoch": 6.627584078987967,
      "grad_norm": 0.3317773640155792,
      "learning_rate": 4.337241592101203e-05,
      "loss": 0.0163,
      "step": 21480
    },
    {
      "epoch": 6.630669546436285,
      "grad_norm": 0.6486328840255737,
      "learning_rate": 4.3369330453563714e-05,
      "loss": 0.0077,
      "step": 21490
    },
    {
      "epoch": 6.6337550138846035,
      "grad_norm": 0.038724612444639206,
      "learning_rate": 4.3366244986115403e-05,
      "loss": 0.0016,
      "step": 21500
    },
    {
      "epoch": 6.636840481332922,
      "grad_norm": 1.8842662572860718,
      "learning_rate": 4.336315951866708e-05,
      "loss": 0.0058,
      "step": 21510
    },
    {
      "epoch": 6.63992594878124,
      "grad_norm": 2.4802637100219727,
      "learning_rate": 4.336007405121876e-05,
      "loss": 0.0056,
      "step": 21520
    },
    {
      "epoch": 6.643011416229559,
      "grad_norm": 0.7315614223480225,
      "learning_rate": 4.3356988583770444e-05,
      "loss": 0.0118,
      "step": 21530
    },
    {
      "epoch": 6.6460968836778775,
      "grad_norm": 0.27848947048187256,
      "learning_rate": 4.3353903116322127e-05,
      "loss": 0.0091,
      "step": 21540
    },
    {
      "epoch": 6.649182351126195,
      "grad_norm": 0.2189452052116394,
      "learning_rate": 4.33508176488738e-05,
      "loss": 0.0037,
      "step": 21550
    },
    {
      "epoch": 6.652267818574514,
      "grad_norm": 0.0711720734834671,
      "learning_rate": 4.3347732181425485e-05,
      "loss": 0.0086,
      "step": 21560
    },
    {
      "epoch": 6.655353286022833,
      "grad_norm": 0.4837411344051361,
      "learning_rate": 4.3344646713977174e-05,
      "loss": 0.0034,
      "step": 21570
    },
    {
      "epoch": 6.658438753471151,
      "grad_norm": 1.17671799659729,
      "learning_rate": 4.334156124652885e-05,
      "loss": 0.0048,
      "step": 21580
    },
    {
      "epoch": 6.661524220919469,
      "grad_norm": 0.8920096158981323,
      "learning_rate": 4.333847577908053e-05,
      "loss": 0.0026,
      "step": 21590
    },
    {
      "epoch": 6.664609688367788,
      "grad_norm": 0.058884404599666595,
      "learning_rate": 4.3335390311632215e-05,
      "loss": 0.0063,
      "step": 21600
    },
    {
      "epoch": 6.667695155816106,
      "grad_norm": 3.0285286903381348,
      "learning_rate": 4.33323048441839e-05,
      "loss": 0.0042,
      "step": 21610
    },
    {
      "epoch": 6.670780623264425,
      "grad_norm": 2.538449764251709,
      "learning_rate": 4.332921937673557e-05,
      "loss": 0.0152,
      "step": 21620
    },
    {
      "epoch": 6.6738660907127425,
      "grad_norm": 0.8418416380882263,
      "learning_rate": 4.3326133909287255e-05,
      "loss": 0.0216,
      "step": 21630
    },
    {
      "epoch": 6.676951558161061,
      "grad_norm": 0.0015470186481252313,
      "learning_rate": 4.3323048441838945e-05,
      "loss": 0.0033,
      "step": 21640
    },
    {
      "epoch": 6.68003702560938,
      "grad_norm": 1.024425745010376,
      "learning_rate": 4.331996297439062e-05,
      "loss": 0.0064,
      "step": 21650
    },
    {
      "epoch": 6.683122493057699,
      "grad_norm": 0.3845343589782715,
      "learning_rate": 4.33168775069423e-05,
      "loss": 0.0051,
      "step": 21660
    },
    {
      "epoch": 6.6862079605060165,
      "grad_norm": 0.5288268327713013,
      "learning_rate": 4.3313792039493985e-05,
      "loss": 0.006,
      "step": 21670
    },
    {
      "epoch": 6.689293427954335,
      "grad_norm": 3.744143009185791,
      "learning_rate": 4.331070657204567e-05,
      "loss": 0.019,
      "step": 21680
    },
    {
      "epoch": 6.692378895402653,
      "grad_norm": 0.18564626574516296,
      "learning_rate": 4.330762110459735e-05,
      "loss": 0.0078,
      "step": 21690
    },
    {
      "epoch": 6.695464362850972,
      "grad_norm": 0.019132204353809357,
      "learning_rate": 4.330453563714903e-05,
      "loss": 0.0024,
      "step": 21700
    },
    {
      "epoch": 6.6985498302992905,
      "grad_norm": 3.145286798477173,
      "learning_rate": 4.3301450169700715e-05,
      "loss": 0.0082,
      "step": 21710
    },
    {
      "epoch": 6.701635297747609,
      "grad_norm": 2.3208205699920654,
      "learning_rate": 4.329836470225239e-05,
      "loss": 0.0206,
      "step": 21720
    },
    {
      "epoch": 6.704720765195927,
      "grad_norm": 0.05310928076505661,
      "learning_rate": 4.329527923480407e-05,
      "loss": 0.0113,
      "step": 21730
    },
    {
      "epoch": 6.707806232644246,
      "grad_norm": 1.886673092842102,
      "learning_rate": 4.3292193767355756e-05,
      "loss": 0.0126,
      "step": 21740
    },
    {
      "epoch": 6.710891700092564,
      "grad_norm": 1.198637843132019,
      "learning_rate": 4.328910829990744e-05,
      "loss": 0.0146,
      "step": 21750
    },
    {
      "epoch": 6.713977167540882,
      "grad_norm": 0.001887522405013442,
      "learning_rate": 4.328602283245912e-05,
      "loss": 0.0204,
      "step": 21760
    },
    {
      "epoch": 6.717062634989201,
      "grad_norm": 0.0021252483129501343,
      "learning_rate": 4.32829373650108e-05,
      "loss": 0.0053,
      "step": 21770
    },
    {
      "epoch": 6.720148102437519,
      "grad_norm": 0.031013725325465202,
      "learning_rate": 4.3279851897562486e-05,
      "loss": 0.0017,
      "step": 21780
    },
    {
      "epoch": 6.723233569885838,
      "grad_norm": 2.0144224166870117,
      "learning_rate": 4.327676643011416e-05,
      "loss": 0.0186,
      "step": 21790
    },
    {
      "epoch": 6.726319037334156,
      "grad_norm": 0.008560172282159328,
      "learning_rate": 4.3273680962665844e-05,
      "loss": 0.0064,
      "step": 21800
    },
    {
      "epoch": 6.729404504782474,
      "grad_norm": 0.5782594680786133,
      "learning_rate": 4.3270595495217526e-05,
      "loss": 0.0206,
      "step": 21810
    },
    {
      "epoch": 6.732489972230793,
      "grad_norm": 0.003092263825237751,
      "learning_rate": 4.326751002776921e-05,
      "loss": 0.0062,
      "step": 21820
    },
    {
      "epoch": 6.735575439679112,
      "grad_norm": 0.26973238587379456,
      "learning_rate": 4.326442456032089e-05,
      "loss": 0.0024,
      "step": 21830
    },
    {
      "epoch": 6.7386609071274295,
      "grad_norm": 0.2504541277885437,
      "learning_rate": 4.3261339092872574e-05,
      "loss": 0.006,
      "step": 21840
    },
    {
      "epoch": 6.741746374575748,
      "grad_norm": 2.1409013271331787,
      "learning_rate": 4.3258253625424256e-05,
      "loss": 0.0074,
      "step": 21850
    },
    {
      "epoch": 6.744831842024067,
      "grad_norm": 0.7430024147033691,
      "learning_rate": 4.325516815797593e-05,
      "loss": 0.0039,
      "step": 21860
    },
    {
      "epoch": 6.747917309472385,
      "grad_norm": 2.952281951904297,
      "learning_rate": 4.3252082690527614e-05,
      "loss": 0.0082,
      "step": 21870
    },
    {
      "epoch": 6.7510027769207035,
      "grad_norm": 0.3860059380531311,
      "learning_rate": 4.32489972230793e-05,
      "loss": 0.0078,
      "step": 21880
    },
    {
      "epoch": 6.754088244369022,
      "grad_norm": 0.002793436637148261,
      "learning_rate": 4.324591175563098e-05,
      "loss": 0.003,
      "step": 21890
    },
    {
      "epoch": 6.75717371181734,
      "grad_norm": 0.02194209024310112,
      "learning_rate": 4.324282628818266e-05,
      "loss": 0.0037,
      "step": 21900
    },
    {
      "epoch": 6.760259179265659,
      "grad_norm": 0.04283851012587547,
      "learning_rate": 4.3239740820734344e-05,
      "loss": 0.0175,
      "step": 21910
    },
    {
      "epoch": 6.7633446467139775,
      "grad_norm": 0.012774137780070305,
      "learning_rate": 4.323665535328603e-05,
      "loss": 0.0024,
      "step": 21920
    },
    {
      "epoch": 6.766430114162295,
      "grad_norm": 0.30683958530426025,
      "learning_rate": 4.32335698858377e-05,
      "loss": 0.0014,
      "step": 21930
    },
    {
      "epoch": 6.769515581610614,
      "grad_norm": 1.7462575435638428,
      "learning_rate": 4.323048441838939e-05,
      "loss": 0.0101,
      "step": 21940
    },
    {
      "epoch": 6.772601049058933,
      "grad_norm": 0.0056639802642166615,
      "learning_rate": 4.322739895094107e-05,
      "loss": 0.002,
      "step": 21950
    },
    {
      "epoch": 6.775686516507251,
      "grad_norm": 0.14095048606395721,
      "learning_rate": 4.322431348349275e-05,
      "loss": 0.0055,
      "step": 21960
    },
    {
      "epoch": 6.778771983955569,
      "grad_norm": 0.024264400824904442,
      "learning_rate": 4.322122801604443e-05,
      "loss": 0.0044,
      "step": 21970
    },
    {
      "epoch": 6.781857451403888,
      "grad_norm": 0.4217868149280548,
      "learning_rate": 4.3218142548596115e-05,
      "loss": 0.0083,
      "step": 21980
    },
    {
      "epoch": 6.784942918852206,
      "grad_norm": 0.39847496151924133,
      "learning_rate": 4.32150570811478e-05,
      "loss": 0.0185,
      "step": 21990
    },
    {
      "epoch": 6.788028386300525,
      "grad_norm": 0.02248314581811428,
      "learning_rate": 4.321197161369947e-05,
      "loss": 0.0097,
      "step": 22000
    },
    {
      "epoch": 6.791113853748843,
      "grad_norm": 0.02162463590502739,
      "learning_rate": 4.320888614625116e-05,
      "loss": 0.004,
      "step": 22010
    },
    {
      "epoch": 6.794199321197161,
      "grad_norm": 0.01796913333237171,
      "learning_rate": 4.320580067880284e-05,
      "loss": 0.0044,
      "step": 22020
    },
    {
      "epoch": 6.79728478864548,
      "grad_norm": 0.8014398217201233,
      "learning_rate": 4.320271521135452e-05,
      "loss": 0.003,
      "step": 22030
    },
    {
      "epoch": 6.800370256093798,
      "grad_norm": 0.0017365736421197653,
      "learning_rate": 4.31996297439062e-05,
      "loss": 0.0018,
      "step": 22040
    },
    {
      "epoch": 6.8034557235421165,
      "grad_norm": 0.14015407860279083,
      "learning_rate": 4.3196544276457885e-05,
      "loss": 0.0041,
      "step": 22050
    },
    {
      "epoch": 6.806541190990435,
      "grad_norm": 0.08205201476812363,
      "learning_rate": 4.319345880900957e-05,
      "loss": 0.0027,
      "step": 22060
    },
    {
      "epoch": 6.809626658438754,
      "grad_norm": 2.2406349182128906,
      "learning_rate": 4.3190373341561244e-05,
      "loss": 0.0033,
      "step": 22070
    },
    {
      "epoch": 6.812712125887072,
      "grad_norm": 0.4360966086387634,
      "learning_rate": 4.318728787411293e-05,
      "loss": 0.0009,
      "step": 22080
    },
    {
      "epoch": 6.8157975933353905,
      "grad_norm": 0.2833743691444397,
      "learning_rate": 4.3184202406664615e-05,
      "loss": 0.0073,
      "step": 22090
    },
    {
      "epoch": 6.818883060783708,
      "grad_norm": 0.03436047583818436,
      "learning_rate": 4.318111693921629e-05,
      "loss": 0.0052,
      "step": 22100
    },
    {
      "epoch": 6.821968528232027,
      "grad_norm": 2.8618791103363037,
      "learning_rate": 4.3178031471767974e-05,
      "loss": 0.0059,
      "step": 22110
    },
    {
      "epoch": 6.825053995680346,
      "grad_norm": 0.03365994244813919,
      "learning_rate": 4.3174946004319656e-05,
      "loss": 0.014,
      "step": 22120
    },
    {
      "epoch": 6.8281394631286645,
      "grad_norm": 0.12191835045814514,
      "learning_rate": 4.317186053687134e-05,
      "loss": 0.0019,
      "step": 22130
    },
    {
      "epoch": 6.831224930576982,
      "grad_norm": 2.586974620819092,
      "learning_rate": 4.3168775069423014e-05,
      "loss": 0.0082,
      "step": 22140
    },
    {
      "epoch": 6.834310398025301,
      "grad_norm": 0.31075620651245117,
      "learning_rate": 4.3165689601974703e-05,
      "loss": 0.0077,
      "step": 22150
    },
    {
      "epoch": 6.837395865473619,
      "grad_norm": 1.1125984191894531,
      "learning_rate": 4.3162604134526386e-05,
      "loss": 0.0045,
      "step": 22160
    },
    {
      "epoch": 6.840481332921938,
      "grad_norm": 0.04568903148174286,
      "learning_rate": 4.315951866707806e-05,
      "loss": 0.0069,
      "step": 22170
    },
    {
      "epoch": 6.843566800370256,
      "grad_norm": 0.47923436760902405,
      "learning_rate": 4.315643319962975e-05,
      "loss": 0.0011,
      "step": 22180
    },
    {
      "epoch": 6.846652267818574,
      "grad_norm": 0.28392139077186584,
      "learning_rate": 4.3153347732181427e-05,
      "loss": 0.0024,
      "step": 22190
    },
    {
      "epoch": 6.849737735266893,
      "grad_norm": 0.3475344777107239,
      "learning_rate": 4.315026226473311e-05,
      "loss": 0.0104,
      "step": 22200
    },
    {
      "epoch": 6.852823202715212,
      "grad_norm": 0.3583335876464844,
      "learning_rate": 4.314717679728479e-05,
      "loss": 0.0024,
      "step": 22210
    },
    {
      "epoch": 6.8559086701635295,
      "grad_norm": 1.9446536302566528,
      "learning_rate": 4.3144091329836474e-05,
      "loss": 0.003,
      "step": 22220
    },
    {
      "epoch": 6.858994137611848,
      "grad_norm": 0.3217964768409729,
      "learning_rate": 4.3141005862388157e-05,
      "loss": 0.0117,
      "step": 22230
    },
    {
      "epoch": 6.862079605060167,
      "grad_norm": 2.855585813522339,
      "learning_rate": 4.313792039493983e-05,
      "loss": 0.0213,
      "step": 22240
    },
    {
      "epoch": 6.865165072508485,
      "grad_norm": 0.7999009490013123,
      "learning_rate": 4.313483492749152e-05,
      "loss": 0.009,
      "step": 22250
    },
    {
      "epoch": 6.8682505399568035,
      "grad_norm": 0.007510893978178501,
      "learning_rate": 4.31317494600432e-05,
      "loss": 0.002,
      "step": 22260
    },
    {
      "epoch": 6.871336007405122,
      "grad_norm": 0.00030152086401358247,
      "learning_rate": 4.312866399259488e-05,
      "loss": 0.0109,
      "step": 22270
    },
    {
      "epoch": 6.87442147485344,
      "grad_norm": 0.011317595839500427,
      "learning_rate": 4.312557852514656e-05,
      "loss": 0.0135,
      "step": 22280
    },
    {
      "epoch": 6.877506942301759,
      "grad_norm": 0.005925054661929607,
      "learning_rate": 4.3122493057698245e-05,
      "loss": 0.0063,
      "step": 22290
    },
    {
      "epoch": 6.8805924097500775,
      "grad_norm": 0.8269861340522766,
      "learning_rate": 4.311940759024993e-05,
      "loss": 0.0295,
      "step": 22300
    },
    {
      "epoch": 6.883677877198395,
      "grad_norm": 0.1812710016965866,
      "learning_rate": 4.31163221228016e-05,
      "loss": 0.0069,
      "step": 22310
    },
    {
      "epoch": 6.886763344646714,
      "grad_norm": 1.0336540937423706,
      "learning_rate": 4.311323665535329e-05,
      "loss": 0.0179,
      "step": 22320
    },
    {
      "epoch": 6.889848812095033,
      "grad_norm": 0.6006250977516174,
      "learning_rate": 4.311015118790497e-05,
      "loss": 0.0063,
      "step": 22330
    },
    {
      "epoch": 6.892934279543351,
      "grad_norm": 0.1008240357041359,
      "learning_rate": 4.310706572045665e-05,
      "loss": 0.0019,
      "step": 22340
    },
    {
      "epoch": 6.896019746991669,
      "grad_norm": 0.005306389648467302,
      "learning_rate": 4.310398025300833e-05,
      "loss": 0.0095,
      "step": 22350
    },
    {
      "epoch": 6.899105214439988,
      "grad_norm": 4.671462535858154,
      "learning_rate": 4.3100894785560015e-05,
      "loss": 0.0203,
      "step": 22360
    },
    {
      "epoch": 6.902190681888306,
      "grad_norm": 1.4469150304794312,
      "learning_rate": 4.30978093181117e-05,
      "loss": 0.004,
      "step": 22370
    },
    {
      "epoch": 6.905276149336625,
      "grad_norm": 1.433998703956604,
      "learning_rate": 4.309472385066337e-05,
      "loss": 0.0144,
      "step": 22380
    },
    {
      "epoch": 6.908361616784942,
      "grad_norm": 0.1346260905265808,
      "learning_rate": 4.309163838321506e-05,
      "loss": 0.0038,
      "step": 22390
    },
    {
      "epoch": 6.911447084233261,
      "grad_norm": 0.7664596438407898,
      "learning_rate": 4.308855291576674e-05,
      "loss": 0.0256,
      "step": 22400
    },
    {
      "epoch": 6.91453255168158,
      "grad_norm": 1.756716251373291,
      "learning_rate": 4.308546744831842e-05,
      "loss": 0.0056,
      "step": 22410
    },
    {
      "epoch": 6.917618019129899,
      "grad_norm": 0.06780683249235153,
      "learning_rate": 4.30823819808701e-05,
      "loss": 0.0056,
      "step": 22420
    },
    {
      "epoch": 6.920703486578216,
      "grad_norm": 2.255587577819824,
      "learning_rate": 4.3079296513421786e-05,
      "loss": 0.0123,
      "step": 22430
    },
    {
      "epoch": 6.923788954026535,
      "grad_norm": 0.5549487471580505,
      "learning_rate": 4.307621104597347e-05,
      "loss": 0.0038,
      "step": 22440
    },
    {
      "epoch": 6.926874421474853,
      "grad_norm": 0.6130908727645874,
      "learning_rate": 4.307312557852515e-05,
      "loss": 0.007,
      "step": 22450
    },
    {
      "epoch": 6.929959888923172,
      "grad_norm": 2.352276086807251,
      "learning_rate": 4.307004011107683e-05,
      "loss": 0.0026,
      "step": 22460
    },
    {
      "epoch": 6.93304535637149,
      "grad_norm": 0.20427727699279785,
      "learning_rate": 4.306695464362851e-05,
      "loss": 0.0017,
      "step": 22470
    },
    {
      "epoch": 6.936130823819809,
      "grad_norm": 0.21840961277484894,
      "learning_rate": 4.306386917618019e-05,
      "loss": 0.011,
      "step": 22480
    },
    {
      "epoch": 6.939216291268127,
      "grad_norm": 0.44998490810394287,
      "learning_rate": 4.3060783708731874e-05,
      "loss": 0.0037,
      "step": 22490
    },
    {
      "epoch": 6.942301758716446,
      "grad_norm": 0.17266273498535156,
      "learning_rate": 4.3057698241283556e-05,
      "loss": 0.0145,
      "step": 22500
    },
    {
      "epoch": 6.945387226164764,
      "grad_norm": 3.2577128410339355,
      "learning_rate": 4.305461277383524e-05,
      "loss": 0.0124,
      "step": 22510
    },
    {
      "epoch": 6.948472693613082,
      "grad_norm": 1.554063320159912,
      "learning_rate": 4.305152730638692e-05,
      "loss": 0.0079,
      "step": 22520
    },
    {
      "epoch": 6.951558161061401,
      "grad_norm": 0.13622018694877625,
      "learning_rate": 4.3048441838938604e-05,
      "loss": 0.0046,
      "step": 22530
    },
    {
      "epoch": 6.954643628509719,
      "grad_norm": 0.28430619835853577,
      "learning_rate": 4.304535637149028e-05,
      "loss": 0.0053,
      "step": 22540
    },
    {
      "epoch": 6.957729095958038,
      "grad_norm": 0.1478748619556427,
      "learning_rate": 4.304227090404196e-05,
      "loss": 0.0013,
      "step": 22550
    },
    {
      "epoch": 6.960814563406356,
      "grad_norm": 0.09981455653905869,
      "learning_rate": 4.303918543659365e-05,
      "loss": 0.0087,
      "step": 22560
    },
    {
      "epoch": 6.963900030854674,
      "grad_norm": 0.4439893364906311,
      "learning_rate": 4.303609996914533e-05,
      "loss": 0.007,
      "step": 22570
    },
    {
      "epoch": 6.966985498302993,
      "grad_norm": 0.36194711923599243,
      "learning_rate": 4.303301450169701e-05,
      "loss": 0.0104,
      "step": 22580
    },
    {
      "epoch": 6.970070965751312,
      "grad_norm": 0.060601912438869476,
      "learning_rate": 4.302992903424869e-05,
      "loss": 0.0168,
      "step": 22590
    },
    {
      "epoch": 6.973156433199629,
      "grad_norm": 1.4447565078735352,
      "learning_rate": 4.3026843566800374e-05,
      "loss": 0.0079,
      "step": 22600
    },
    {
      "epoch": 6.976241900647948,
      "grad_norm": 0.9026398658752441,
      "learning_rate": 4.302375809935205e-05,
      "loss": 0.0063,
      "step": 22610
    },
    {
      "epoch": 6.979327368096267,
      "grad_norm": 0.06786155700683594,
      "learning_rate": 4.302067263190373e-05,
      "loss": 0.0027,
      "step": 22620
    },
    {
      "epoch": 6.982412835544585,
      "grad_norm": 0.1314178854227066,
      "learning_rate": 4.301758716445542e-05,
      "loss": 0.0019,
      "step": 22630
    },
    {
      "epoch": 6.985498302992903,
      "grad_norm": 0.018755163997411728,
      "learning_rate": 4.30145016970071e-05,
      "loss": 0.0056,
      "step": 22640
    },
    {
      "epoch": 6.988583770441222,
      "grad_norm": 0.016754088923335075,
      "learning_rate": 4.301141622955878e-05,
      "loss": 0.0026,
      "step": 22650
    },
    {
      "epoch": 6.99166923788954,
      "grad_norm": 0.33811160922050476,
      "learning_rate": 4.300833076211046e-05,
      "loss": 0.0027,
      "step": 22660
    },
    {
      "epoch": 6.994754705337859,
      "grad_norm": 0.003794141113758087,
      "learning_rate": 4.3005245294662145e-05,
      "loss": 0.0042,
      "step": 22670
    },
    {
      "epoch": 6.997840172786177,
      "grad_norm": 0.00022509835253003985,
      "learning_rate": 4.300215982721382e-05,
      "loss": 0.0027,
      "step": 22680
    },
    {
      "epoch": 7.0,
      "eval_accuracy_branch1": 0.9977624104240811,
      "eval_accuracy_branch2": 0.4615896530771679,
      "eval_f1_branch1": 0.9974493033235727,
      "eval_f1_branch2": 0.4615246703177047,
      "eval_loss": 0.001180819352157414,
      "eval_precision_branch1": 0.997413748512148,
      "eval_precision_branch2": 0.5238132162447406,
      "eval_recall_branch1": 0.9974925280993954,
      "eval_recall_branch2": 0.5234078875032551,
      "eval_runtime": 246.5009,
      "eval_samples_per_second": 420.619,
      "eval_steps_per_second": 52.58,
      "step": 22687
    },
    {
      "epoch": 7.000925640234495,
      "grad_norm": 0.02261575497686863,
      "learning_rate": 4.299907435976551e-05,
      "loss": 0.0034,
      "step": 22690
    },
    {
      "epoch": 7.004011107682814,
      "grad_norm": 0.0044927094131708145,
      "learning_rate": 4.299598889231719e-05,
      "loss": 0.0054,
      "step": 22700
    },
    {
      "epoch": 7.007096575131133,
      "grad_norm": 1.0855381488800049,
      "learning_rate": 4.299290342486887e-05,
      "loss": 0.0131,
      "step": 22710
    },
    {
      "epoch": 7.0101820425794505,
      "grad_norm": 0.4775581955909729,
      "learning_rate": 4.298981795742055e-05,
      "loss": 0.0011,
      "step": 22720
    },
    {
      "epoch": 7.013267510027769,
      "grad_norm": 0.8744452595710754,
      "learning_rate": 4.298673248997223e-05,
      "loss": 0.0048,
      "step": 22730
    },
    {
      "epoch": 7.016352977476088,
      "grad_norm": 3.261953830718994,
      "learning_rate": 4.2983647022523915e-05,
      "loss": 0.0214,
      "step": 22740
    },
    {
      "epoch": 7.019438444924406,
      "grad_norm": 1.5763369798660278,
      "learning_rate": 4.298056155507559e-05,
      "loss": 0.0058,
      "step": 22750
    },
    {
      "epoch": 7.0225239123727246,
      "grad_norm": 1.1638710498809814,
      "learning_rate": 4.297747608762728e-05,
      "loss": 0.0019,
      "step": 22760
    },
    {
      "epoch": 7.025609379821043,
      "grad_norm": 0.3274098038673401,
      "learning_rate": 4.297439062017896e-05,
      "loss": 0.0075,
      "step": 22770
    },
    {
      "epoch": 7.028694847269361,
      "grad_norm": 0.3100173771381378,
      "learning_rate": 4.297130515273064e-05,
      "loss": 0.0027,
      "step": 22780
    },
    {
      "epoch": 7.03178031471768,
      "grad_norm": 0.16815818846225739,
      "learning_rate": 4.296821968528232e-05,
      "loss": 0.0011,
      "step": 22790
    },
    {
      "epoch": 7.034865782165999,
      "grad_norm": 0.16417603194713593,
      "learning_rate": 4.2965134217834003e-05,
      "loss": 0.0036,
      "step": 22800
    },
    {
      "epoch": 7.037951249614316,
      "grad_norm": 0.018923528492450714,
      "learning_rate": 4.2962048750385686e-05,
      "loss": 0.0043,
      "step": 22810
    },
    {
      "epoch": 7.041036717062635,
      "grad_norm": 0.17803749442100525,
      "learning_rate": 4.295896328293736e-05,
      "loss": 0.0033,
      "step": 22820
    },
    {
      "epoch": 7.044122184510954,
      "grad_norm": 0.23046688735485077,
      "learning_rate": 4.295587781548905e-05,
      "loss": 0.0023,
      "step": 22830
    },
    {
      "epoch": 7.047207651959272,
      "grad_norm": 0.23759382963180542,
      "learning_rate": 4.295279234804073e-05,
      "loss": 0.0101,
      "step": 22840
    },
    {
      "epoch": 7.05029311940759,
      "grad_norm": 0.21196724474430084,
      "learning_rate": 4.294970688059241e-05,
      "loss": 0.0025,
      "step": 22850
    },
    {
      "epoch": 7.053378586855908,
      "grad_norm": 1.2909218072891235,
      "learning_rate": 4.294662141314409e-05,
      "loss": 0.0057,
      "step": 22860
    },
    {
      "epoch": 7.056464054304227,
      "grad_norm": 0.49006932973861694,
      "learning_rate": 4.2943535945695774e-05,
      "loss": 0.0044,
      "step": 22870
    },
    {
      "epoch": 7.059549521752546,
      "grad_norm": 0.005673319101333618,
      "learning_rate": 4.2940450478247457e-05,
      "loss": 0.005,
      "step": 22880
    },
    {
      "epoch": 7.0626349892008635,
      "grad_norm": 1.4144665002822876,
      "learning_rate": 4.293736501079913e-05,
      "loss": 0.0023,
      "step": 22890
    },
    {
      "epoch": 7.065720456649182,
      "grad_norm": 1.6276241540908813,
      "learning_rate": 4.293427954335082e-05,
      "loss": 0.0067,
      "step": 22900
    },
    {
      "epoch": 7.068805924097501,
      "grad_norm": 0.1431364119052887,
      "learning_rate": 4.2931194075902504e-05,
      "loss": 0.0095,
      "step": 22910
    },
    {
      "epoch": 7.071891391545819,
      "grad_norm": 1.44584059715271,
      "learning_rate": 4.292810860845418e-05,
      "loss": 0.0107,
      "step": 22920
    },
    {
      "epoch": 7.0749768589941375,
      "grad_norm": 0.01008495595306158,
      "learning_rate": 4.292502314100587e-05,
      "loss": 0.0118,
      "step": 22930
    },
    {
      "epoch": 7.078062326442456,
      "grad_norm": 0.012559042312204838,
      "learning_rate": 4.2921937673557545e-05,
      "loss": 0.0029,
      "step": 22940
    },
    {
      "epoch": 7.081147793890774,
      "grad_norm": 2.3180196285247803,
      "learning_rate": 4.291885220610923e-05,
      "loss": 0.0089,
      "step": 22950
    },
    {
      "epoch": 7.084233261339093,
      "grad_norm": 0.010983437299728394,
      "learning_rate": 4.291576673866091e-05,
      "loss": 0.0033,
      "step": 22960
    },
    {
      "epoch": 7.0873187287874115,
      "grad_norm": 2.1933963298797607,
      "learning_rate": 4.291268127121259e-05,
      "loss": 0.0119,
      "step": 22970
    },
    {
      "epoch": 7.090404196235729,
      "grad_norm": 4.45725154876709,
      "learning_rate": 4.2909595803764275e-05,
      "loss": 0.0072,
      "step": 22980
    },
    {
      "epoch": 7.093489663684048,
      "grad_norm": 0.011224879883229733,
      "learning_rate": 4.290651033631595e-05,
      "loss": 0.0072,
      "step": 22990
    },
    {
      "epoch": 7.096575131132367,
      "grad_norm": 0.001754558878019452,
      "learning_rate": 4.290342486886764e-05,
      "loss": 0.0092,
      "step": 23000
    },
    {
      "epoch": 7.099660598580685,
      "grad_norm": 1.1306297779083252,
      "learning_rate": 4.2900339401419315e-05,
      "loss": 0.0065,
      "step": 23010
    },
    {
      "epoch": 7.102746066029003,
      "grad_norm": 0.1479618400335312,
      "learning_rate": 4.2897253933971e-05,
      "loss": 0.0056,
      "step": 23020
    },
    {
      "epoch": 7.105831533477322,
      "grad_norm": 0.07469052076339722,
      "learning_rate": 4.289416846652268e-05,
      "loss": 0.0044,
      "step": 23030
    },
    {
      "epoch": 7.10891700092564,
      "grad_norm": 0.003435614053159952,
      "learning_rate": 4.289108299907436e-05,
      "loss": 0.0035,
      "step": 23040
    },
    {
      "epoch": 7.112002468373959,
      "grad_norm": 2.0215084552764893,
      "learning_rate": 4.2887997531626045e-05,
      "loss": 0.0017,
      "step": 23050
    },
    {
      "epoch": 7.115087935822277,
      "grad_norm": 0.006982976570725441,
      "learning_rate": 4.288491206417772e-05,
      "loss": 0.0018,
      "step": 23060
    },
    {
      "epoch": 7.118173403270595,
      "grad_norm": 1.4940061569213867,
      "learning_rate": 4.288182659672941e-05,
      "loss": 0.0057,
      "step": 23070
    },
    {
      "epoch": 7.121258870718914,
      "grad_norm": 0.2180338054895401,
      "learning_rate": 4.2878741129281086e-05,
      "loss": 0.0057,
      "step": 23080
    },
    {
      "epoch": 7.124344338167233,
      "grad_norm": 0.00995788723230362,
      "learning_rate": 4.287565566183277e-05,
      "loss": 0.0012,
      "step": 23090
    },
    {
      "epoch": 7.1274298056155505,
      "grad_norm": 0.03224674612283707,
      "learning_rate": 4.287257019438445e-05,
      "loss": 0.0076,
      "step": 23100
    },
    {
      "epoch": 7.130515273063869,
      "grad_norm": 0.0011076285736635327,
      "learning_rate": 4.286948472693613e-05,
      "loss": 0.0045,
      "step": 23110
    },
    {
      "epoch": 7.133600740512188,
      "grad_norm": 0.5333171486854553,
      "learning_rate": 4.2866399259487816e-05,
      "loss": 0.005,
      "step": 23120
    },
    {
      "epoch": 7.136686207960506,
      "grad_norm": 0.011551260948181152,
      "learning_rate": 4.286331379203949e-05,
      "loss": 0.0085,
      "step": 23130
    },
    {
      "epoch": 7.1397716754088245,
      "grad_norm": 0.3814822733402252,
      "learning_rate": 4.286022832459118e-05,
      "loss": 0.0087,
      "step": 23140
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.008769779466092587,
      "learning_rate": 4.2857142857142856e-05,
      "loss": 0.0011,
      "step": 23150
    },
    {
      "epoch": 7.145942610305461,
      "grad_norm": 0.9746726155281067,
      "learning_rate": 4.285405738969454e-05,
      "loss": 0.0079,
      "step": 23160
    },
    {
      "epoch": 7.14902807775378,
      "grad_norm": 0.04147631675004959,
      "learning_rate": 4.285097192224623e-05,
      "loss": 0.0035,
      "step": 23170
    },
    {
      "epoch": 7.1521135452020985,
      "grad_norm": 0.009954588487744331,
      "learning_rate": 4.2847886454797904e-05,
      "loss": 0.001,
      "step": 23180
    },
    {
      "epoch": 7.155199012650416,
      "grad_norm": 0.0017117190873250365,
      "learning_rate": 4.2844800987349586e-05,
      "loss": 0.0062,
      "step": 23190
    },
    {
      "epoch": 7.158284480098735,
      "grad_norm": 0.004838341381400824,
      "learning_rate": 4.284171551990127e-05,
      "loss": 0.0041,
      "step": 23200
    },
    {
      "epoch": 7.161369947547054,
      "grad_norm": 0.6278029680252075,
      "learning_rate": 4.283863005245295e-05,
      "loss": 0.0011,
      "step": 23210
    },
    {
      "epoch": 7.164455414995372,
      "grad_norm": 0.005373620893806219,
      "learning_rate": 4.283554458500463e-05,
      "loss": 0.0035,
      "step": 23220
    },
    {
      "epoch": 7.16754088244369,
      "grad_norm": 0.0026882996316999197,
      "learning_rate": 4.283245911755631e-05,
      "loss": 0.0077,
      "step": 23230
    },
    {
      "epoch": 7.170626349892009,
      "grad_norm": 0.008932800032198429,
      "learning_rate": 4.2829373650108e-05,
      "loss": 0.008,
      "step": 23240
    },
    {
      "epoch": 7.173711817340327,
      "grad_norm": 0.01070481538772583,
      "learning_rate": 4.2826288182659674e-05,
      "loss": 0.008,
      "step": 23250
    },
    {
      "epoch": 7.176797284788646,
      "grad_norm": 0.017910102382302284,
      "learning_rate": 4.282320271521136e-05,
      "loss": 0.0065,
      "step": 23260
    },
    {
      "epoch": 7.1798827522369635,
      "grad_norm": 0.012762167491018772,
      "learning_rate": 4.282011724776304e-05,
      "loss": 0.0008,
      "step": 23270
    },
    {
      "epoch": 7.182968219685282,
      "grad_norm": 0.043747514486312866,
      "learning_rate": 4.281703178031472e-05,
      "loss": 0.0062,
      "step": 23280
    },
    {
      "epoch": 7.186053687133601,
      "grad_norm": 0.26884523034095764,
      "learning_rate": 4.28139463128664e-05,
      "loss": 0.0014,
      "step": 23290
    },
    {
      "epoch": 7.189139154581919,
      "grad_norm": 0.3021408021450043,
      "learning_rate": 4.281086084541808e-05,
      "loss": 0.0021,
      "step": 23300
    },
    {
      "epoch": 7.1922246220302375,
      "grad_norm": 0.050028711557388306,
      "learning_rate": 4.280777537796977e-05,
      "loss": 0.0022,
      "step": 23310
    },
    {
      "epoch": 7.195310089478556,
      "grad_norm": 0.13685977458953857,
      "learning_rate": 4.2804689910521445e-05,
      "loss": 0.001,
      "step": 23320
    },
    {
      "epoch": 7.198395556926874,
      "grad_norm": 0.0002537369728088379,
      "learning_rate": 4.280160444307313e-05,
      "loss": 0.0039,
      "step": 23330
    },
    {
      "epoch": 7.201481024375193,
      "grad_norm": 0.87338787317276,
      "learning_rate": 4.279851897562481e-05,
      "loss": 0.0012,
      "step": 23340
    },
    {
      "epoch": 7.2045664918235115,
      "grad_norm": 0.01925557106733322,
      "learning_rate": 4.279543350817649e-05,
      "loss": 0.0017,
      "step": 23350
    },
    {
      "epoch": 7.207651959271829,
      "grad_norm": 0.0019747563637793064,
      "learning_rate": 4.279234804072817e-05,
      "loss": 0.0018,
      "step": 23360
    },
    {
      "epoch": 7.210737426720148,
      "grad_norm": 0.009018673561513424,
      "learning_rate": 4.278926257327985e-05,
      "loss": 0.0046,
      "step": 23370
    },
    {
      "epoch": 7.213822894168467,
      "grad_norm": 0.001155838486738503,
      "learning_rate": 4.278617710583154e-05,
      "loss": 0.001,
      "step": 23380
    },
    {
      "epoch": 7.216908361616785,
      "grad_norm": 0.0065594022162258625,
      "learning_rate": 4.2783091638383215e-05,
      "loss": 0.0021,
      "step": 23390
    },
    {
      "epoch": 7.219993829065103,
      "grad_norm": 0.013419806025922298,
      "learning_rate": 4.27800061709349e-05,
      "loss": 0.0048,
      "step": 23400
    },
    {
      "epoch": 7.223079296513422,
      "grad_norm": 0.695453405380249,
      "learning_rate": 4.277692070348658e-05,
      "loss": 0.0054,
      "step": 23410
    },
    {
      "epoch": 7.22616476396174,
      "grad_norm": 0.27815887331962585,
      "learning_rate": 4.277383523603826e-05,
      "loss": 0.001,
      "step": 23420
    },
    {
      "epoch": 7.229250231410059,
      "grad_norm": 2.017153263092041,
      "learning_rate": 4.2770749768589945e-05,
      "loss": 0.0029,
      "step": 23430
    },
    {
      "epoch": 7.232335698858377,
      "grad_norm": 0.047139838337898254,
      "learning_rate": 4.276766430114163e-05,
      "loss": 0.0045,
      "step": 23440
    },
    {
      "epoch": 7.235421166306695,
      "grad_norm": 0.5447395443916321,
      "learning_rate": 4.276457883369331e-05,
      "loss": 0.0008,
      "step": 23450
    },
    {
      "epoch": 7.238506633755014,
      "grad_norm": 0.1294693946838379,
      "learning_rate": 4.2761493366244986e-05,
      "loss": 0.0038,
      "step": 23460
    },
    {
      "epoch": 7.241592101203333,
      "grad_norm": 0.017978103831410408,
      "learning_rate": 4.275840789879667e-05,
      "loss": 0.0024,
      "step": 23470
    },
    {
      "epoch": 7.2446775686516505,
      "grad_norm": 1.6870293617248535,
      "learning_rate": 4.275532243134835e-05,
      "loss": 0.0039,
      "step": 23480
    },
    {
      "epoch": 7.247763036099969,
      "grad_norm": 0.056001827120780945,
      "learning_rate": 4.2752236963900033e-05,
      "loss": 0.0037,
      "step": 23490
    },
    {
      "epoch": 7.250848503548288,
      "grad_norm": 0.013211230747401714,
      "learning_rate": 4.2749151496451716e-05,
      "loss": 0.0046,
      "step": 23500
    },
    {
      "epoch": 7.253933970996606,
      "grad_norm": 0.06517099589109421,
      "learning_rate": 4.27460660290034e-05,
      "loss": 0.007,
      "step": 23510
    },
    {
      "epoch": 7.2570194384449245,
      "grad_norm": 0.001103164628148079,
      "learning_rate": 4.274298056155508e-05,
      "loss": 0.0076,
      "step": 23520
    },
    {
      "epoch": 7.260104905893243,
      "grad_norm": 1.6004496812820435,
      "learning_rate": 4.2739895094106757e-05,
      "loss": 0.0033,
      "step": 23530
    },
    {
      "epoch": 7.263190373341561,
      "grad_norm": 0.3952571451663971,
      "learning_rate": 4.273680962665844e-05,
      "loss": 0.0012,
      "step": 23540
    },
    {
      "epoch": 7.26627584078988,
      "grad_norm": 0.012068078853189945,
      "learning_rate": 4.273372415921012e-05,
      "loss": 0.0014,
      "step": 23550
    },
    {
      "epoch": 7.2693613082381985,
      "grad_norm": 0.02327847108244896,
      "learning_rate": 4.2730638691761804e-05,
      "loss": 0.0083,
      "step": 23560
    },
    {
      "epoch": 7.272446775686516,
      "grad_norm": 0.00614510802552104,
      "learning_rate": 4.2727553224313486e-05,
      "loss": 0.0018,
      "step": 23570
    },
    {
      "epoch": 7.275532243134835,
      "grad_norm": 0.6506460309028625,
      "learning_rate": 4.272446775686517e-05,
      "loss": 0.002,
      "step": 23580
    },
    {
      "epoch": 7.278617710583154,
      "grad_norm": 1.5937232971191406,
      "learning_rate": 4.272138228941685e-05,
      "loss": 0.0187,
      "step": 23590
    },
    {
      "epoch": 7.281703178031472,
      "grad_norm": 0.002404051134362817,
      "learning_rate": 4.271829682196853e-05,
      "loss": 0.0083,
      "step": 23600
    },
    {
      "epoch": 7.28478864547979,
      "grad_norm": 0.012165349908173084,
      "learning_rate": 4.271521135452021e-05,
      "loss": 0.0194,
      "step": 23610
    },
    {
      "epoch": 7.287874112928108,
      "grad_norm": 0.32097944617271423,
      "learning_rate": 4.271212588707189e-05,
      "loss": 0.0088,
      "step": 23620
    },
    {
      "epoch": 7.290959580376427,
      "grad_norm": 0.047785814851522446,
      "learning_rate": 4.2709040419623575e-05,
      "loss": 0.0029,
      "step": 23630
    },
    {
      "epoch": 7.294045047824746,
      "grad_norm": 0.08555996417999268,
      "learning_rate": 4.270595495217526e-05,
      "loss": 0.0061,
      "step": 23640
    },
    {
      "epoch": 7.297130515273064,
      "grad_norm": 0.11790511012077332,
      "learning_rate": 4.270286948472694e-05,
      "loss": 0.0025,
      "step": 23650
    },
    {
      "epoch": 7.300215982721382,
      "grad_norm": 0.05395748093724251,
      "learning_rate": 4.269978401727862e-05,
      "loss": 0.0036,
      "step": 23660
    },
    {
      "epoch": 7.303301450169701,
      "grad_norm": 0.8531647324562073,
      "learning_rate": 4.26966985498303e-05,
      "loss": 0.0128,
      "step": 23670
    },
    {
      "epoch": 7.306386917618019,
      "grad_norm": 3.2781941890716553,
      "learning_rate": 4.269361308238199e-05,
      "loss": 0.0054,
      "step": 23680
    },
    {
      "epoch": 7.3094723850663375,
      "grad_norm": 1.1502573490142822,
      "learning_rate": 4.269052761493366e-05,
      "loss": 0.0058,
      "step": 23690
    },
    {
      "epoch": 7.312557852514656,
      "grad_norm": 0.0036897542886435986,
      "learning_rate": 4.2687442147485345e-05,
      "loss": 0.0079,
      "step": 23700
    },
    {
      "epoch": 7.315643319962974,
      "grad_norm": 0.38288572430610657,
      "learning_rate": 4.268435668003703e-05,
      "loss": 0.0025,
      "step": 23710
    },
    {
      "epoch": 7.318728787411293,
      "grad_norm": 0.04786911979317665,
      "learning_rate": 4.268127121258871e-05,
      "loss": 0.0122,
      "step": 23720
    },
    {
      "epoch": 7.3218142548596115,
      "grad_norm": 0.10529384762048721,
      "learning_rate": 4.267818574514039e-05,
      "loss": 0.0018,
      "step": 23730
    },
    {
      "epoch": 7.324899722307929,
      "grad_norm": 0.0023822246585041285,
      "learning_rate": 4.267510027769207e-05,
      "loss": 0.0045,
      "step": 23740
    },
    {
      "epoch": 7.327985189756248,
      "grad_norm": 0.0019577965140342712,
      "learning_rate": 4.267201481024376e-05,
      "loss": 0.0004,
      "step": 23750
    },
    {
      "epoch": 7.331070657204567,
      "grad_norm": 0.017872048541903496,
      "learning_rate": 4.266892934279543e-05,
      "loss": 0.0119,
      "step": 23760
    },
    {
      "epoch": 7.334156124652885,
      "grad_norm": 0.9689710736274719,
      "learning_rate": 4.2665843875347116e-05,
      "loss": 0.0126,
      "step": 23770
    },
    {
      "epoch": 7.337241592101203,
      "grad_norm": 0.007684700656682253,
      "learning_rate": 4.26627584078988e-05,
      "loss": 0.0119,
      "step": 23780
    },
    {
      "epoch": 7.340327059549522,
      "grad_norm": 0.23145945370197296,
      "learning_rate": 4.265967294045048e-05,
      "loss": 0.0043,
      "step": 23790
    },
    {
      "epoch": 7.34341252699784,
      "grad_norm": 0.006907193455845118,
      "learning_rate": 4.265658747300216e-05,
      "loss": 0.012,
      "step": 23800
    },
    {
      "epoch": 7.346497994446159,
      "grad_norm": 0.0030508164782077074,
      "learning_rate": 4.265350200555384e-05,
      "loss": 0.003,
      "step": 23810
    },
    {
      "epoch": 7.349583461894477,
      "grad_norm": 0.10014372318983078,
      "learning_rate": 4.265041653810553e-05,
      "loss": 0.0018,
      "step": 23820
    },
    {
      "epoch": 7.352668929342795,
      "grad_norm": 0.06952764093875885,
      "learning_rate": 4.264733107065721e-05,
      "loss": 0.0025,
      "step": 23830
    },
    {
      "epoch": 7.355754396791114,
      "grad_norm": 0.0026845468673855066,
      "learning_rate": 4.2644245603208886e-05,
      "loss": 0.0025,
      "step": 23840
    },
    {
      "epoch": 7.358839864239433,
      "grad_norm": 0.00229666824452579,
      "learning_rate": 4.264116013576057e-05,
      "loss": 0.0006,
      "step": 23850
    },
    {
      "epoch": 7.36192533168775,
      "grad_norm": 0.030310900881886482,
      "learning_rate": 4.263807466831225e-05,
      "loss": 0.0027,
      "step": 23860
    },
    {
      "epoch": 7.365010799136069,
      "grad_norm": 0.7379245758056641,
      "learning_rate": 4.2634989200863934e-05,
      "loss": 0.0241,
      "step": 23870
    },
    {
      "epoch": 7.368096266584388,
      "grad_norm": 0.2923294007778168,
      "learning_rate": 4.263190373341561e-05,
      "loss": 0.0042,
      "step": 23880
    },
    {
      "epoch": 7.371181734032706,
      "grad_norm": 3.984891891479492,
      "learning_rate": 4.26288182659673e-05,
      "loss": 0.0079,
      "step": 23890
    },
    {
      "epoch": 7.374267201481024,
      "grad_norm": 0.22642117738723755,
      "learning_rate": 4.262573279851898e-05,
      "loss": 0.0012,
      "step": 23900
    },
    {
      "epoch": 7.377352668929343,
      "grad_norm": 4.009177207946777,
      "learning_rate": 4.262264733107066e-05,
      "loss": 0.0064,
      "step": 23910
    },
    {
      "epoch": 7.380438136377661,
      "grad_norm": 0.00726610142737627,
      "learning_rate": 4.261956186362234e-05,
      "loss": 0.0032,
      "step": 23920
    },
    {
      "epoch": 7.38352360382598,
      "grad_norm": 1.7878432273864746,
      "learning_rate": 4.261647639617402e-05,
      "loss": 0.0116,
      "step": 23930
    },
    {
      "epoch": 7.386609071274298,
      "grad_norm": 0.02135022170841694,
      "learning_rate": 4.2613390928725704e-05,
      "loss": 0.0034,
      "step": 23940
    },
    {
      "epoch": 7.389694538722616,
      "grad_norm": 0.04655680060386658,
      "learning_rate": 4.261030546127739e-05,
      "loss": 0.0125,
      "step": 23950
    },
    {
      "epoch": 7.392780006170935,
      "grad_norm": 0.0239779781550169,
      "learning_rate": 4.260721999382907e-05,
      "loss": 0.004,
      "step": 23960
    },
    {
      "epoch": 7.395865473619254,
      "grad_norm": 0.002916898112744093,
      "learning_rate": 4.260413452638075e-05,
      "loss": 0.001,
      "step": 23970
    },
    {
      "epoch": 7.398950941067572,
      "grad_norm": 4.203744411468506,
      "learning_rate": 4.260104905893243e-05,
      "loss": 0.0079,
      "step": 23980
    },
    {
      "epoch": 7.40203640851589,
      "grad_norm": 0.20760752260684967,
      "learning_rate": 4.2597963591484117e-05,
      "loss": 0.0035,
      "step": 23990
    },
    {
      "epoch": 7.405121875964209,
      "grad_norm": 0.11778547614812851,
      "learning_rate": 4.259487812403579e-05,
      "loss": 0.0155,
      "step": 24000
    },
    {
      "epoch": 7.408207343412527,
      "grad_norm": 1.4071571826934814,
      "learning_rate": 4.2591792656587475e-05,
      "loss": 0.0125,
      "step": 24010
    },
    {
      "epoch": 7.411292810860846,
      "grad_norm": 0.9657593965530396,
      "learning_rate": 4.258870718913916e-05,
      "loss": 0.0076,
      "step": 24020
    },
    {
      "epoch": 7.414378278309163,
      "grad_norm": 0.208819180727005,
      "learning_rate": 4.258562172169084e-05,
      "loss": 0.006,
      "step": 24030
    },
    {
      "epoch": 7.417463745757482,
      "grad_norm": 0.06330293416976929,
      "learning_rate": 4.258253625424252e-05,
      "loss": 0.0083,
      "step": 24040
    },
    {
      "epoch": 7.420549213205801,
      "grad_norm": 0.28125184774398804,
      "learning_rate": 4.25794507867942e-05,
      "loss": 0.003,
      "step": 24050
    },
    {
      "epoch": 7.423634680654119,
      "grad_norm": 0.04251018539071083,
      "learning_rate": 4.257636531934589e-05,
      "loss": 0.0014,
      "step": 24060
    },
    {
      "epoch": 7.426720148102437,
      "grad_norm": 4.085343837738037,
      "learning_rate": 4.257327985189756e-05,
      "loss": 0.0145,
      "step": 24070
    },
    {
      "epoch": 7.429805615550756,
      "grad_norm": 0.09445808827877045,
      "learning_rate": 4.2570194384449245e-05,
      "loss": 0.0008,
      "step": 24080
    },
    {
      "epoch": 7.432891082999074,
      "grad_norm": 0.01695120893418789,
      "learning_rate": 4.256710891700093e-05,
      "loss": 0.0093,
      "step": 24090
    },
    {
      "epoch": 7.435976550447393,
      "grad_norm": 1.5475969314575195,
      "learning_rate": 4.256402344955261e-05,
      "loss": 0.0086,
      "step": 24100
    },
    {
      "epoch": 7.439062017895711,
      "grad_norm": 0.015573649667203426,
      "learning_rate": 4.256093798210429e-05,
      "loss": 0.0006,
      "step": 24110
    },
    {
      "epoch": 7.442147485344029,
      "grad_norm": 0.07506528496742249,
      "learning_rate": 4.255785251465597e-05,
      "loss": 0.0077,
      "step": 24120
    },
    {
      "epoch": 7.445232952792348,
      "grad_norm": 0.037741489708423615,
      "learning_rate": 4.255476704720766e-05,
      "loss": 0.0026,
      "step": 24130
    },
    {
      "epoch": 7.448318420240667,
      "grad_norm": 2.901823043823242,
      "learning_rate": 4.2551681579759333e-05,
      "loss": 0.017,
      "step": 24140
    },
    {
      "epoch": 7.4514038876889845,
      "grad_norm": 0.6615912318229675,
      "learning_rate": 4.2548596112311016e-05,
      "loss": 0.0036,
      "step": 24150
    },
    {
      "epoch": 7.454489355137303,
      "grad_norm": 0.08977364748716354,
      "learning_rate": 4.25455106448627e-05,
      "loss": 0.0055,
      "step": 24160
    },
    {
      "epoch": 7.457574822585622,
      "grad_norm": 0.5957583785057068,
      "learning_rate": 4.254242517741438e-05,
      "loss": 0.0033,
      "step": 24170
    },
    {
      "epoch": 7.46066029003394,
      "grad_norm": 0.03509316220879555,
      "learning_rate": 4.253933970996606e-05,
      "loss": 0.0066,
      "step": 24180
    },
    {
      "epoch": 7.4637457574822585,
      "grad_norm": 1.3150137662887573,
      "learning_rate": 4.253625424251774e-05,
      "loss": 0.0096,
      "step": 24190
    },
    {
      "epoch": 7.466831224930577,
      "grad_norm": 2.0300018787384033,
      "learning_rate": 4.253316877506943e-05,
      "loss": 0.0087,
      "step": 24200
    },
    {
      "epoch": 7.469916692378895,
      "grad_norm": 0.019522380083799362,
      "learning_rate": 4.2530083307621104e-05,
      "loss": 0.0028,
      "step": 24210
    },
    {
      "epoch": 7.473002159827214,
      "grad_norm": 0.0539359413087368,
      "learning_rate": 4.2526997840172786e-05,
      "loss": 0.0093,
      "step": 24220
    },
    {
      "epoch": 7.4760876272755326,
      "grad_norm": 0.2157851606607437,
      "learning_rate": 4.252391237272447e-05,
      "loss": 0.0061,
      "step": 24230
    },
    {
      "epoch": 7.47917309472385,
      "grad_norm": 0.15111230313777924,
      "learning_rate": 4.252082690527615e-05,
      "loss": 0.0019,
      "step": 24240
    },
    {
      "epoch": 7.482258562172169,
      "grad_norm": 0.042912986129522324,
      "learning_rate": 4.2517741437827834e-05,
      "loss": 0.0089,
      "step": 24250
    },
    {
      "epoch": 7.485344029620488,
      "grad_norm": 3.1808815002441406,
      "learning_rate": 4.2514655970379516e-05,
      "loss": 0.0073,
      "step": 24260
    },
    {
      "epoch": 7.488429497068806,
      "grad_norm": 0.0021602394990622997,
      "learning_rate": 4.25115705029312e-05,
      "loss": 0.0022,
      "step": 24270
    },
    {
      "epoch": 7.491514964517124,
      "grad_norm": 0.36037859320640564,
      "learning_rate": 4.2508485035482875e-05,
      "loss": 0.0029,
      "step": 24280
    },
    {
      "epoch": 7.494600431965443,
      "grad_norm": 0.00036156957503408194,
      "learning_rate": 4.250539956803456e-05,
      "loss": 0.0018,
      "step": 24290
    },
    {
      "epoch": 7.497685899413761,
      "grad_norm": 0.02472919225692749,
      "learning_rate": 4.2502314100586246e-05,
      "loss": 0.0019,
      "step": 24300
    },
    {
      "epoch": 7.50077136686208,
      "grad_norm": 0.015814464539289474,
      "learning_rate": 4.249922863313792e-05,
      "loss": 0.0081,
      "step": 24310
    },
    {
      "epoch": 7.503856834310398,
      "grad_norm": 0.027265174314379692,
      "learning_rate": 4.2496143165689604e-05,
      "loss": 0.0003,
      "step": 24320
    },
    {
      "epoch": 7.506942301758716,
      "grad_norm": 0.004020641557872295,
      "learning_rate": 4.249305769824129e-05,
      "loss": 0.0072,
      "step": 24330
    },
    {
      "epoch": 7.510027769207035,
      "grad_norm": 0.0021160603500902653,
      "learning_rate": 4.248997223079297e-05,
      "loss": 0.0023,
      "step": 24340
    },
    {
      "epoch": 7.513113236655354,
      "grad_norm": 0.0007417011656798422,
      "learning_rate": 4.2486886763344645e-05,
      "loss": 0.0047,
      "step": 24350
    },
    {
      "epoch": 7.5161987041036715,
      "grad_norm": 0.2194252461194992,
      "learning_rate": 4.248380129589633e-05,
      "loss": 0.0009,
      "step": 24360
    },
    {
      "epoch": 7.51928417155199,
      "grad_norm": 0.4312242567539215,
      "learning_rate": 4.248071582844802e-05,
      "loss": 0.0087,
      "step": 24370
    },
    {
      "epoch": 7.522369639000308,
      "grad_norm": 0.038069356232881546,
      "learning_rate": 4.247763036099969e-05,
      "loss": 0.0074,
      "step": 24380
    },
    {
      "epoch": 7.525455106448627,
      "grad_norm": 0.07632414996623993,
      "learning_rate": 4.2474544893551375e-05,
      "loss": 0.0036,
      "step": 24390
    },
    {
      "epoch": 7.5285405738969455,
      "grad_norm": 0.011481903493404388,
      "learning_rate": 4.247145942610306e-05,
      "loss": 0.007,
      "step": 24400
    },
    {
      "epoch": 7.531626041345264,
      "grad_norm": 0.8923015594482422,
      "learning_rate": 4.246837395865474e-05,
      "loss": 0.0026,
      "step": 24410
    },
    {
      "epoch": 7.534711508793582,
      "grad_norm": 3.7888448238372803,
      "learning_rate": 4.2465288491206416e-05,
      "loss": 0.0134,
      "step": 24420
    },
    {
      "epoch": 7.537796976241901,
      "grad_norm": 0.001763608306646347,
      "learning_rate": 4.24622030237581e-05,
      "loss": 0.0039,
      "step": 24430
    },
    {
      "epoch": 7.540882443690219,
      "grad_norm": 0.11690115928649902,
      "learning_rate": 4.245911755630979e-05,
      "loss": 0.0068,
      "step": 24440
    },
    {
      "epoch": 7.543967911138537,
      "grad_norm": 0.015339725650846958,
      "learning_rate": 4.245603208886146e-05,
      "loss": 0.0036,
      "step": 24450
    },
    {
      "epoch": 7.547053378586856,
      "grad_norm": 0.008737465366721153,
      "learning_rate": 4.2452946621413146e-05,
      "loss": 0.0065,
      "step": 24460
    },
    {
      "epoch": 7.550138846035175,
      "grad_norm": 0.0625302717089653,
      "learning_rate": 4.244986115396483e-05,
      "loss": 0.005,
      "step": 24470
    },
    {
      "epoch": 7.553224313483493,
      "grad_norm": 0.024160124361515045,
      "learning_rate": 4.244677568651651e-05,
      "loss": 0.0019,
      "step": 24480
    },
    {
      "epoch": 7.556309780931811,
      "grad_norm": 0.010103568434715271,
      "learning_rate": 4.2443690219068186e-05,
      "loss": 0.0101,
      "step": 24490
    },
    {
      "epoch": 7.559395248380129,
      "grad_norm": 0.18230214715003967,
      "learning_rate": 4.2440604751619875e-05,
      "loss": 0.0133,
      "step": 24500
    },
    {
      "epoch": 7.562480715828448,
      "grad_norm": 0.14178498089313507,
      "learning_rate": 4.243751928417156e-05,
      "loss": 0.0085,
      "step": 24510
    },
    {
      "epoch": 7.565566183276767,
      "grad_norm": 0.19640326499938965,
      "learning_rate": 4.2434433816723234e-05,
      "loss": 0.0148,
      "step": 24520
    },
    {
      "epoch": 7.5686516507250845,
      "grad_norm": 1.3018933534622192,
      "learning_rate": 4.2431348349274916e-05,
      "loss": 0.0057,
      "step": 24530
    },
    {
      "epoch": 7.571737118173403,
      "grad_norm": 0.033121902495622635,
      "learning_rate": 4.24282628818266e-05,
      "loss": 0.018,
      "step": 24540
    },
    {
      "epoch": 7.574822585621722,
      "grad_norm": 0.0902794674038887,
      "learning_rate": 4.242517741437828e-05,
      "loss": 0.0037,
      "step": 24550
    },
    {
      "epoch": 7.57790805307004,
      "grad_norm": 0.36872991919517517,
      "learning_rate": 4.242209194692996e-05,
      "loss": 0.0073,
      "step": 24560
    },
    {
      "epoch": 7.5809935205183585,
      "grad_norm": 0.0037711842451244593,
      "learning_rate": 4.2419006479481646e-05,
      "loss": 0.0088,
      "step": 24570
    },
    {
      "epoch": 7.584078987966677,
      "grad_norm": 2.2299890518188477,
      "learning_rate": 4.241592101203333e-05,
      "loss": 0.0127,
      "step": 24580
    },
    {
      "epoch": 7.587164455414995,
      "grad_norm": 0.004171059932559729,
      "learning_rate": 4.2412835544585004e-05,
      "loss": 0.0017,
      "step": 24590
    },
    {
      "epoch": 7.590249922863314,
      "grad_norm": 0.004724330268800259,
      "learning_rate": 4.240975007713669e-05,
      "loss": 0.0024,
      "step": 24600
    },
    {
      "epoch": 7.5933353903116325,
      "grad_norm": 0.0013065154198557138,
      "learning_rate": 4.240666460968837e-05,
      "loss": 0.0057,
      "step": 24610
    },
    {
      "epoch": 7.59642085775995,
      "grad_norm": 1.0496711730957031,
      "learning_rate": 4.240357914224005e-05,
      "loss": 0.0115,
      "step": 24620
    },
    {
      "epoch": 7.599506325208269,
      "grad_norm": 0.33001381158828735,
      "learning_rate": 4.240049367479173e-05,
      "loss": 0.0135,
      "step": 24630
    },
    {
      "epoch": 7.602591792656588,
      "grad_norm": 0.05240894854068756,
      "learning_rate": 4.239740820734342e-05,
      "loss": 0.0043,
      "step": 24640
    },
    {
      "epoch": 7.605677260104906,
      "grad_norm": 0.08829823136329651,
      "learning_rate": 4.23943227398951e-05,
      "loss": 0.0079,
      "step": 24650
    },
    {
      "epoch": 7.608762727553224,
      "grad_norm": 1.8618377447128296,
      "learning_rate": 4.2391237272446775e-05,
      "loss": 0.0071,
      "step": 24660
    },
    {
      "epoch": 7.611848195001543,
      "grad_norm": 0.013656742870807648,
      "learning_rate": 4.238815180499846e-05,
      "loss": 0.006,
      "step": 24670
    },
    {
      "epoch": 7.614933662449861,
      "grad_norm": 0.006142497528344393,
      "learning_rate": 4.238506633755014e-05,
      "loss": 0.0058,
      "step": 24680
    },
    {
      "epoch": 7.61801912989818,
      "grad_norm": 0.11471589654684067,
      "learning_rate": 4.238198087010182e-05,
      "loss": 0.0097,
      "step": 24690
    },
    {
      "epoch": 7.621104597346498,
      "grad_norm": 0.036403462290763855,
      "learning_rate": 4.2378895402653505e-05,
      "loss": 0.0092,
      "step": 24700
    },
    {
      "epoch": 7.624190064794816,
      "grad_norm": 2.174715518951416,
      "learning_rate": 4.237580993520519e-05,
      "loss": 0.0035,
      "step": 24710
    },
    {
      "epoch": 7.627275532243135,
      "grad_norm": 0.15229879319667816,
      "learning_rate": 4.237272446775687e-05,
      "loss": 0.0234,
      "step": 24720
    },
    {
      "epoch": 7.630360999691453,
      "grad_norm": 0.10386646538972855,
      "learning_rate": 4.2369639000308545e-05,
      "loss": 0.01,
      "step": 24730
    },
    {
      "epoch": 7.6334464671397715,
      "grad_norm": 0.006510745268315077,
      "learning_rate": 4.2366553532860235e-05,
      "loss": 0.0072,
      "step": 24740
    },
    {
      "epoch": 7.63653193458809,
      "grad_norm": 0.006765380036085844,
      "learning_rate": 4.236346806541191e-05,
      "loss": 0.0052,
      "step": 24750
    },
    {
      "epoch": 7.639617402036409,
      "grad_norm": 0.030426498502492905,
      "learning_rate": 4.236038259796359e-05,
      "loss": 0.0064,
      "step": 24760
    },
    {
      "epoch": 7.642702869484727,
      "grad_norm": 1.7601449489593506,
      "learning_rate": 4.2357297130515275e-05,
      "loss": 0.0078,
      "step": 24770
    },
    {
      "epoch": 7.6457883369330455,
      "grad_norm": 0.007554355077445507,
      "learning_rate": 4.235421166306696e-05,
      "loss": 0.006,
      "step": 24780
    },
    {
      "epoch": 7.648873804381363,
      "grad_norm": 0.008866448886692524,
      "learning_rate": 4.235112619561864e-05,
      "loss": 0.0045,
      "step": 24790
    },
    {
      "epoch": 7.651959271829682,
      "grad_norm": 0.027655446901917458,
      "learning_rate": 4.2348040728170316e-05,
      "loss": 0.0012,
      "step": 24800
    },
    {
      "epoch": 7.655044739278001,
      "grad_norm": 0.12978728115558624,
      "learning_rate": 4.2344955260722005e-05,
      "loss": 0.0058,
      "step": 24810
    },
    {
      "epoch": 7.6581302067263195,
      "grad_norm": 2.454198122024536,
      "learning_rate": 4.234186979327368e-05,
      "loss": 0.0026,
      "step": 24820
    },
    {
      "epoch": 7.661215674174637,
      "grad_norm": 0.19143150746822357,
      "learning_rate": 4.233878432582536e-05,
      "loss": 0.011,
      "step": 24830
    },
    {
      "epoch": 7.664301141622956,
      "grad_norm": 0.2919619679450989,
      "learning_rate": 4.2335698858377046e-05,
      "loss": 0.0054,
      "step": 24840
    },
    {
      "epoch": 7.667386609071274,
      "grad_norm": 0.013647164218127728,
      "learning_rate": 4.233261339092873e-05,
      "loss": 0.0025,
      "step": 24850
    },
    {
      "epoch": 7.670472076519593,
      "grad_norm": 0.00010803241457324475,
      "learning_rate": 4.232952792348041e-05,
      "loss": 0.0027,
      "step": 24860
    },
    {
      "epoch": 7.673557543967911,
      "grad_norm": 0.5089616179466248,
      "learning_rate": 4.2326442456032086e-05,
      "loss": 0.0092,
      "step": 24870
    },
    {
      "epoch": 7.676643011416229,
      "grad_norm": 0.013549107126891613,
      "learning_rate": 4.2323356988583776e-05,
      "loss": 0.0037,
      "step": 24880
    },
    {
      "epoch": 7.679728478864548,
      "grad_norm": 0.15268084406852722,
      "learning_rate": 4.232027152113545e-05,
      "loss": 0.0025,
      "step": 24890
    },
    {
      "epoch": 7.682813946312867,
      "grad_norm": 0.035086024552583694,
      "learning_rate": 4.2317186053687134e-05,
      "loss": 0.0091,
      "step": 24900
    },
    {
      "epoch": 7.6858994137611845,
      "grad_norm": 0.07308340072631836,
      "learning_rate": 4.2314100586238816e-05,
      "loss": 0.0104,
      "step": 24910
    },
    {
      "epoch": 7.688984881209503,
      "grad_norm": 0.41297516226768494,
      "learning_rate": 4.23110151187905e-05,
      "loss": 0.0029,
      "step": 24920
    },
    {
      "epoch": 7.692070348657822,
      "grad_norm": 0.004587574861943722,
      "learning_rate": 4.230792965134218e-05,
      "loss": 0.0023,
      "step": 24930
    },
    {
      "epoch": 7.69515581610614,
      "grad_norm": 0.0774269849061966,
      "learning_rate": 4.230484418389386e-05,
      "loss": 0.0051,
      "step": 24940
    },
    {
      "epoch": 7.6982412835544585,
      "grad_norm": 0.014737647026777267,
      "learning_rate": 4.2301758716445546e-05,
      "loss": 0.0046,
      "step": 24950
    },
    {
      "epoch": 7.701326751002777,
      "grad_norm": 0.33688899874687195,
      "learning_rate": 4.229867324899722e-05,
      "loss": 0.0026,
      "step": 24960
    },
    {
      "epoch": 7.704412218451095,
      "grad_norm": 0.004658919293433428,
      "learning_rate": 4.2295587781548904e-05,
      "loss": 0.0009,
      "step": 24970
    },
    {
      "epoch": 7.707497685899414,
      "grad_norm": 0.00808791909366846,
      "learning_rate": 4.2292502314100594e-05,
      "loss": 0.0084,
      "step": 24980
    },
    {
      "epoch": 7.7105831533477325,
      "grad_norm": 0.02243555709719658,
      "learning_rate": 4.228941684665227e-05,
      "loss": 0.0102,
      "step": 24990
    },
    {
      "epoch": 7.71366862079605,
      "grad_norm": 1.5964090824127197,
      "learning_rate": 4.228633137920395e-05,
      "loss": 0.0044,
      "step": 25000
    },
    {
      "epoch": 7.716754088244369,
      "grad_norm": 0.01711598038673401,
      "learning_rate": 4.2283245911755634e-05,
      "loss": 0.0058,
      "step": 25010
    },
    {
      "epoch": 7.719839555692688,
      "grad_norm": 0.24694566428661346,
      "learning_rate": 4.228016044430732e-05,
      "loss": 0.0051,
      "step": 25020
    },
    {
      "epoch": 7.722925023141006,
      "grad_norm": 0.006081940606236458,
      "learning_rate": 4.227707497685899e-05,
      "loss": 0.005,
      "step": 25030
    },
    {
      "epoch": 7.726010490589324,
      "grad_norm": 0.07470081746578217,
      "learning_rate": 4.2273989509410675e-05,
      "loss": 0.0026,
      "step": 25040
    },
    {
      "epoch": 7.729095958037643,
      "grad_norm": 2.8270115852355957,
      "learning_rate": 4.2270904041962364e-05,
      "loss": 0.0051,
      "step": 25050
    },
    {
      "epoch": 7.732181425485961,
      "grad_norm": 0.33026421070098877,
      "learning_rate": 4.226781857451404e-05,
      "loss": 0.0045,
      "step": 25060
    },
    {
      "epoch": 7.73526689293428,
      "grad_norm": 0.01139112375676632,
      "learning_rate": 4.226473310706572e-05,
      "loss": 0.0012,
      "step": 25070
    },
    {
      "epoch": 7.738352360382598,
      "grad_norm": 0.29615139961242676,
      "learning_rate": 4.2261647639617405e-05,
      "loss": 0.0134,
      "step": 25080
    },
    {
      "epoch": 7.741437827830916,
      "grad_norm": 3.054314136505127,
      "learning_rate": 4.225856217216909e-05,
      "loss": 0.0079,
      "step": 25090
    },
    {
      "epoch": 7.744523295279235,
      "grad_norm": 0.032442037016153336,
      "learning_rate": 4.225547670472076e-05,
      "loss": 0.0087,
      "step": 25100
    },
    {
      "epoch": 7.747608762727554,
      "grad_norm": 0.009971031919121742,
      "learning_rate": 4.2252391237272446e-05,
      "loss": 0.0049,
      "step": 25110
    },
    {
      "epoch": 7.7506942301758714,
      "grad_norm": 1.1012042760849,
      "learning_rate": 4.2249305769824135e-05,
      "loss": 0.0121,
      "step": 25120
    },
    {
      "epoch": 7.75377969762419,
      "grad_norm": 0.06798744201660156,
      "learning_rate": 4.224622030237581e-05,
      "loss": 0.0055,
      "step": 25130
    },
    {
      "epoch": 7.756865165072508,
      "grad_norm": 0.08445285260677338,
      "learning_rate": 4.224313483492749e-05,
      "loss": 0.0151,
      "step": 25140
    },
    {
      "epoch": 7.759950632520827,
      "grad_norm": 2.8394527435302734,
      "learning_rate": 4.2240049367479176e-05,
      "loss": 0.0099,
      "step": 25150
    },
    {
      "epoch": 7.7630360999691455,
      "grad_norm": 0.007318607997149229,
      "learning_rate": 4.223696390003086e-05,
      "loss": 0.0072,
      "step": 25160
    },
    {
      "epoch": 7.766121567417464,
      "grad_norm": 0.0021800356917083263,
      "learning_rate": 4.223387843258254e-05,
      "loss": 0.0008,
      "step": 25170
    },
    {
      "epoch": 7.769207034865782,
      "grad_norm": 0.12485531717538834,
      "learning_rate": 4.2230792965134216e-05,
      "loss": 0.0103,
      "step": 25180
    },
    {
      "epoch": 7.772292502314101,
      "grad_norm": 0.05087607353925705,
      "learning_rate": 4.2227707497685905e-05,
      "loss": 0.0026,
      "step": 25190
    },
    {
      "epoch": 7.775377969762419,
      "grad_norm": 0.008331974036991596,
      "learning_rate": 4.222462203023758e-05,
      "loss": 0.0031,
      "step": 25200
    },
    {
      "epoch": 7.778463437210737,
      "grad_norm": 0.06708809733390808,
      "learning_rate": 4.2221536562789264e-05,
      "loss": 0.004,
      "step": 25210
    },
    {
      "epoch": 7.781548904659056,
      "grad_norm": 0.03319811820983887,
      "learning_rate": 4.2218451095340946e-05,
      "loss": 0.0093,
      "step": 25220
    },
    {
      "epoch": 7.784634372107375,
      "grad_norm": 0.11209731549024582,
      "learning_rate": 4.221536562789263e-05,
      "loss": 0.0045,
      "step": 25230
    },
    {
      "epoch": 7.787719839555693,
      "grad_norm": 0.02930593676865101,
      "learning_rate": 4.221228016044431e-05,
      "loss": 0.0054,
      "step": 25240
    },
    {
      "epoch": 7.790805307004011,
      "grad_norm": 0.01277779322117567,
      "learning_rate": 4.2209194692995993e-05,
      "loss": 0.0178,
      "step": 25250
    },
    {
      "epoch": 7.793890774452329,
      "grad_norm": 0.049962546676397324,
      "learning_rate": 4.2206109225547676e-05,
      "loss": 0.0035,
      "step": 25260
    },
    {
      "epoch": 7.796976241900648,
      "grad_norm": 1.2339476346969604,
      "learning_rate": 4.220302375809935e-05,
      "loss": 0.007,
      "step": 25270
    },
    {
      "epoch": 7.800061709348967,
      "grad_norm": 0.004001028835773468,
      "learning_rate": 4.2199938290651034e-05,
      "loss": 0.0028,
      "step": 25280
    },
    {
      "epoch": 7.803147176797284,
      "grad_norm": 0.09420772641897202,
      "learning_rate": 4.219685282320272e-05,
      "loss": 0.0028,
      "step": 25290
    },
    {
      "epoch": 7.806232644245603,
      "grad_norm": 3.8448214530944824,
      "learning_rate": 4.21937673557544e-05,
      "loss": 0.011,
      "step": 25300
    },
    {
      "epoch": 7.809318111693922,
      "grad_norm": 0.11390509456396103,
      "learning_rate": 4.219068188830608e-05,
      "loss": 0.0098,
      "step": 25310
    },
    {
      "epoch": 7.81240357914224,
      "grad_norm": 0.3138035237789154,
      "learning_rate": 4.2187596420857764e-05,
      "loss": 0.007,
      "step": 25320
    },
    {
      "epoch": 7.815489046590558,
      "grad_norm": 0.11202544718980789,
      "learning_rate": 4.2184510953409447e-05,
      "loss": 0.0021,
      "step": 25330
    },
    {
      "epoch": 7.818574514038877,
      "grad_norm": 0.005266071297228336,
      "learning_rate": 4.218142548596112e-05,
      "loss": 0.0012,
      "step": 25340
    },
    {
      "epoch": 7.821659981487195,
      "grad_norm": 0.005343226715922356,
      "learning_rate": 4.2178340018512805e-05,
      "loss": 0.0011,
      "step": 25350
    },
    {
      "epoch": 7.824745448935514,
      "grad_norm": 0.11510287970304489,
      "learning_rate": 4.217525455106449e-05,
      "loss": 0.0073,
      "step": 25360
    },
    {
      "epoch": 7.827830916383832,
      "grad_norm": 1.566282868385315,
      "learning_rate": 4.217216908361617e-05,
      "loss": 0.0054,
      "step": 25370
    },
    {
      "epoch": 7.83091638383215,
      "grad_norm": 0.011758992448449135,
      "learning_rate": 4.216908361616785e-05,
      "loss": 0.0013,
      "step": 25380
    },
    {
      "epoch": 7.834001851280469,
      "grad_norm": 2.348290205001831,
      "learning_rate": 4.2165998148719535e-05,
      "loss": 0.0054,
      "step": 25390
    },
    {
      "epoch": 7.837087318728788,
      "grad_norm": 3.126796007156372,
      "learning_rate": 4.216291268127122e-05,
      "loss": 0.0338,
      "step": 25400
    },
    {
      "epoch": 7.840172786177106,
      "grad_norm": 0.8975479602813721,
      "learning_rate": 4.215982721382289e-05,
      "loss": 0.0122,
      "step": 25410
    },
    {
      "epoch": 7.843258253625424,
      "grad_norm": 0.004045062232762575,
      "learning_rate": 4.2156741746374575e-05,
      "loss": 0.0019,
      "step": 25420
    },
    {
      "epoch": 7.846343721073743,
      "grad_norm": 0.004589171148836613,
      "learning_rate": 4.215365627892626e-05,
      "loss": 0.0023,
      "step": 25430
    },
    {
      "epoch": 7.849429188522061,
      "grad_norm": 0.0061465366743505,
      "learning_rate": 4.215057081147794e-05,
      "loss": 0.0032,
      "step": 25440
    },
    {
      "epoch": 7.85251465597038,
      "grad_norm": 0.00015214364975690842,
      "learning_rate": 4.214748534402962e-05,
      "loss": 0.0042,
      "step": 25450
    },
    {
      "epoch": 7.855600123418698,
      "grad_norm": 0.19469301402568817,
      "learning_rate": 4.2144399876581305e-05,
      "loss": 0.0063,
      "step": 25460
    },
    {
      "epoch": 7.858685590867016,
      "grad_norm": 0.02143036015331745,
      "learning_rate": 4.214131440913299e-05,
      "loss": 0.0317,
      "step": 25470
    },
    {
      "epoch": 7.861771058315335,
      "grad_norm": 0.007555003743618727,
      "learning_rate": 4.213822894168466e-05,
      "loss": 0.0033,
      "step": 25480
    },
    {
      "epoch": 7.864856525763654,
      "grad_norm": 0.3232518136501312,
      "learning_rate": 4.213514347423635e-05,
      "loss": 0.0066,
      "step": 25490
    },
    {
      "epoch": 7.867941993211971,
      "grad_norm": 0.09497595578432083,
      "learning_rate": 4.213205800678803e-05,
      "loss": 0.0082,
      "step": 25500
    },
    {
      "epoch": 7.87102746066029,
      "grad_norm": 0.0013887069653719664,
      "learning_rate": 4.212897253933971e-05,
      "loss": 0.0005,
      "step": 25510
    },
    {
      "epoch": 7.874112928108609,
      "grad_norm": 0.00847981870174408,
      "learning_rate": 4.212588707189139e-05,
      "loss": 0.0045,
      "step": 25520
    },
    {
      "epoch": 7.877198395556927,
      "grad_norm": 0.0144161656498909,
      "learning_rate": 4.2122801604443076e-05,
      "loss": 0.0074,
      "step": 25530
    },
    {
      "epoch": 7.880283863005245,
      "grad_norm": 0.004772082902491093,
      "learning_rate": 4.211971613699476e-05,
      "loss": 0.0018,
      "step": 25540
    },
    {
      "epoch": 7.883369330453563,
      "grad_norm": 0.011330028995871544,
      "learning_rate": 4.2116630669546434e-05,
      "loss": 0.0012,
      "step": 25550
    },
    {
      "epoch": 7.886454797901882,
      "grad_norm": 0.01682623103260994,
      "learning_rate": 4.211354520209812e-05,
      "loss": 0.004,
      "step": 25560
    },
    {
      "epoch": 7.889540265350201,
      "grad_norm": 0.017985986545681953,
      "learning_rate": 4.2110459734649806e-05,
      "loss": 0.0046,
      "step": 25570
    },
    {
      "epoch": 7.892625732798519,
      "grad_norm": 3.1992480754852295,
      "learning_rate": 4.210737426720148e-05,
      "loss": 0.0041,
      "step": 25580
    },
    {
      "epoch": 7.895711200246837,
      "grad_norm": 0.00232532131485641,
      "learning_rate": 4.2104288799753164e-05,
      "loss": 0.0053,
      "step": 25590
    },
    {
      "epoch": 7.898796667695156,
      "grad_norm": 0.3250751793384552,
      "learning_rate": 4.2101203332304846e-05,
      "loss": 0.0016,
      "step": 25600
    },
    {
      "epoch": 7.901882135143474,
      "grad_norm": 0.017353003844618797,
      "learning_rate": 4.209811786485653e-05,
      "loss": 0.0006,
      "step": 25610
    },
    {
      "epoch": 7.9049676025917925,
      "grad_norm": 0.004155430942773819,
      "learning_rate": 4.2095032397408204e-05,
      "loss": 0.0163,
      "step": 25620
    },
    {
      "epoch": 7.908053070040111,
      "grad_norm": 0.0005336955655366182,
      "learning_rate": 4.2091946929959894e-05,
      "loss": 0.006,
      "step": 25630
    },
    {
      "epoch": 7.91113853748843,
      "grad_norm": 0.4284829795360565,
      "learning_rate": 4.2088861462511576e-05,
      "loss": 0.0095,
      "step": 25640
    },
    {
      "epoch": 7.914224004936748,
      "grad_norm": 0.002894296543672681,
      "learning_rate": 4.208577599506325e-05,
      "loss": 0.001,
      "step": 25650
    },
    {
      "epoch": 7.9173094723850665,
      "grad_norm": 0.9453171491622925,
      "learning_rate": 4.2082690527614934e-05,
      "loss": 0.0055,
      "step": 25660
    },
    {
      "epoch": 7.920394939833384,
      "grad_norm": 0.04810437560081482,
      "learning_rate": 4.207960506016662e-05,
      "loss": 0.0097,
      "step": 25670
    },
    {
      "epoch": 7.923480407281703,
      "grad_norm": 0.06792407482862473,
      "learning_rate": 4.20765195927183e-05,
      "loss": 0.0023,
      "step": 25680
    },
    {
      "epoch": 7.926565874730022,
      "grad_norm": 0.2207825481891632,
      "learning_rate": 4.2073434125269975e-05,
      "loss": 0.001,
      "step": 25690
    },
    {
      "epoch": 7.92965134217834,
      "grad_norm": 0.0757126659154892,
      "learning_rate": 4.2070348657821664e-05,
      "loss": 0.0131,
      "step": 25700
    },
    {
      "epoch": 7.932736809626658,
      "grad_norm": 0.030067265033721924,
      "learning_rate": 4.206726319037335e-05,
      "loss": 0.0012,
      "step": 25710
    },
    {
      "epoch": 7.935822277074977,
      "grad_norm": 0.002155841328203678,
      "learning_rate": 4.206417772292502e-05,
      "loss": 0.0028,
      "step": 25720
    },
    {
      "epoch": 7.938907744523295,
      "grad_norm": 0.0761822834610939,
      "learning_rate": 4.206109225547671e-05,
      "loss": 0.0083,
      "step": 25730
    },
    {
      "epoch": 7.941993211971614,
      "grad_norm": 4.897467613220215,
      "learning_rate": 4.205800678802839e-05,
      "loss": 0.0182,
      "step": 25740
    },
    {
      "epoch": 7.945078679419932,
      "grad_norm": 0.3455621302127838,
      "learning_rate": 4.205492132058007e-05,
      "loss": 0.0011,
      "step": 25750
    },
    {
      "epoch": 7.94816414686825,
      "grad_norm": 0.0009108436061069369,
      "learning_rate": 4.205183585313175e-05,
      "loss": 0.0016,
      "step": 25760
    },
    {
      "epoch": 7.951249614316569,
      "grad_norm": 0.18896521627902985,
      "learning_rate": 4.2048750385683435e-05,
      "loss": 0.0195,
      "step": 25770
    },
    {
      "epoch": 7.954335081764888,
      "grad_norm": 0.023532964289188385,
      "learning_rate": 4.204566491823512e-05,
      "loss": 0.0087,
      "step": 25780
    },
    {
      "epoch": 7.9574205492132055,
      "grad_norm": 0.11118821799755096,
      "learning_rate": 4.204257945078679e-05,
      "loss": 0.0066,
      "step": 25790
    },
    {
      "epoch": 7.960506016661524,
      "grad_norm": 0.005851816385984421,
      "learning_rate": 4.203949398333848e-05,
      "loss": 0.0032,
      "step": 25800
    },
    {
      "epoch": 7.963591484109843,
      "grad_norm": 0.07088300585746765,
      "learning_rate": 4.203640851589016e-05,
      "loss": 0.0038,
      "step": 25810
    },
    {
      "epoch": 7.966676951558161,
      "grad_norm": 0.005296970717608929,
      "learning_rate": 4.203332304844184e-05,
      "loss": 0.0058,
      "step": 25820
    },
    {
      "epoch": 7.9697624190064795,
      "grad_norm": 0.07144959270954132,
      "learning_rate": 4.203023758099352e-05,
      "loss": 0.0125,
      "step": 25830
    },
    {
      "epoch": 7.972847886454798,
      "grad_norm": 0.010210157372057438,
      "learning_rate": 4.2027152113545205e-05,
      "loss": 0.0025,
      "step": 25840
    },
    {
      "epoch": 7.975933353903116,
      "grad_norm": 0.10123604536056519,
      "learning_rate": 4.202406664609689e-05,
      "loss": 0.003,
      "step": 25850
    },
    {
      "epoch": 7.979018821351435,
      "grad_norm": 0.005071051884442568,
      "learning_rate": 4.2020981178648564e-05,
      "loss": 0.0057,
      "step": 25860
    },
    {
      "epoch": 7.9821042887997535,
      "grad_norm": 0.004123716615140438,
      "learning_rate": 4.201789571120025e-05,
      "loss": 0.0009,
      "step": 25870
    },
    {
      "epoch": 7.985189756248071,
      "grad_norm": 0.1643553525209427,
      "learning_rate": 4.201481024375193e-05,
      "loss": 0.0035,
      "step": 25880
    },
    {
      "epoch": 7.98827522369639,
      "grad_norm": 3.19315505027771,
      "learning_rate": 4.201172477630361e-05,
      "loss": 0.0074,
      "step": 25890
    },
    {
      "epoch": 7.991360691144708,
      "grad_norm": 0.4377363622188568,
      "learning_rate": 4.2008639308855294e-05,
      "loss": 0.0017,
      "step": 25900
    },
    {
      "epoch": 7.994446158593027,
      "grad_norm": 0.03693186864256859,
      "learning_rate": 4.2005553841406976e-05,
      "loss": 0.002,
      "step": 25910
    },
    {
      "epoch": 7.997531626041345,
      "grad_norm": 2.286600351333618,
      "learning_rate": 4.200246837395866e-05,
      "loss": 0.008,
      "step": 25920
    },
    {
      "epoch": 8.0,
      "eval_accuracy_branch1": 0.9973380399872689,
      "eval_accuracy_branch2": 0.4108966754434189,
      "eval_f1_branch1": 0.9955062854455455,
      "eval_f1_branch2": 0.4053462741666665,
      "eval_loss": 0.002130812732502818,
      "eval_precision_branch1": 0.9954322244775795,
      "eval_precision_branch2": 0.49814062627343275,
      "eval_recall_branch1": 0.9956673308366022,
      "eval_recall_branch2": 0.4984881803188565,
      "eval_runtime": 238.9048,
      "eval_samples_per_second": 433.993,
      "eval_steps_per_second": 54.252,
      "step": 25928
    },
    {
      "epoch": 8.000617093489664,
      "grad_norm": 0.02180344983935356,
      "learning_rate": 4.1999382906510334e-05,
      "loss": 0.2264,
      "step": 25930
    },
    {
      "epoch": 8.003702560937983,
      "grad_norm": 1.1831581592559814,
      "learning_rate": 4.1996297439062023e-05,
      "loss": 0.0063,
      "step": 25940
    },
    {
      "epoch": 8.0067880283863,
      "grad_norm": 0.008477011695504189,
      "learning_rate": 4.19932119716137e-05,
      "loss": 0.0041,
      "step": 25950
    },
    {
      "epoch": 8.009873495834618,
      "grad_norm": 1.4459573030471802,
      "learning_rate": 4.199012650416538e-05,
      "loss": 0.0047,
      "step": 25960
    },
    {
      "epoch": 8.012958963282937,
      "grad_norm": 1.6269532442092896,
      "learning_rate": 4.1987041036717064e-05,
      "loss": 0.0024,
      "step": 25970
    },
    {
      "epoch": 8.016044430731256,
      "grad_norm": 1.4376780986785889,
      "learning_rate": 4.1983955569268747e-05,
      "loss": 0.0119,
      "step": 25980
    },
    {
      "epoch": 8.019129898179575,
      "grad_norm": 1.531531810760498,
      "learning_rate": 4.198087010182043e-05,
      "loss": 0.0022,
      "step": 25990
    },
    {
      "epoch": 8.022215365627893,
      "grad_norm": 0.918778657913208,
      "learning_rate": 4.197778463437211e-05,
      "loss": 0.0178,
      "step": 26000
    },
    {
      "epoch": 8.02530083307621,
      "grad_norm": 0.6839869022369385,
      "learning_rate": 4.1974699166923794e-05,
      "loss": 0.0165,
      "step": 26010
    },
    {
      "epoch": 8.028386300524529,
      "grad_norm": 0.18756212294101715,
      "learning_rate": 4.197161369947547e-05,
      "loss": 0.003,
      "step": 26020
    },
    {
      "epoch": 8.031471767972848,
      "grad_norm": 0.01894235424697399,
      "learning_rate": 4.196852823202715e-05,
      "loss": 0.0005,
      "step": 26030
    },
    {
      "epoch": 8.034557235421167,
      "grad_norm": 1.643917202949524,
      "learning_rate": 4.196544276457884e-05,
      "loss": 0.0023,
      "step": 26040
    },
    {
      "epoch": 8.037642702869485,
      "grad_norm": 0.10805849730968475,
      "learning_rate": 4.196235729713052e-05,
      "loss": 0.009,
      "step": 26050
    },
    {
      "epoch": 8.040728170317804,
      "grad_norm": 0.5084934234619141,
      "learning_rate": 4.19592718296822e-05,
      "loss": 0.0064,
      "step": 26060
    },
    {
      "epoch": 8.043813637766121,
      "grad_norm": 0.04829726740717888,
      "learning_rate": 4.195618636223388e-05,
      "loss": 0.0061,
      "step": 26070
    },
    {
      "epoch": 8.04689910521444,
      "grad_norm": 0.009003547951579094,
      "learning_rate": 4.1953100894785565e-05,
      "loss": 0.0072,
      "step": 26080
    },
    {
      "epoch": 8.049984572662758,
      "grad_norm": 0.05204566568136215,
      "learning_rate": 4.195001542733724e-05,
      "loss": 0.0018,
      "step": 26090
    },
    {
      "epoch": 8.053070040111077,
      "grad_norm": 0.5964857339859009,
      "learning_rate": 4.194692995988892e-05,
      "loss": 0.0007,
      "step": 26100
    },
    {
      "epoch": 8.056155507559396,
      "grad_norm": 0.0001324666664004326,
      "learning_rate": 4.194384449244061e-05,
      "loss": 0.0064,
      "step": 26110
    },
    {
      "epoch": 8.059240975007715,
      "grad_norm": 0.13772748410701752,
      "learning_rate": 4.194075902499229e-05,
      "loss": 0.0007,
      "step": 26120
    },
    {
      "epoch": 8.062326442456031,
      "grad_norm": 0.051504477858543396,
      "learning_rate": 4.193767355754397e-05,
      "loss": 0.0045,
      "step": 26130
    },
    {
      "epoch": 8.06541190990435,
      "grad_norm": 0.01462466735392809,
      "learning_rate": 4.193458809009565e-05,
      "loss": 0.01,
      "step": 26140
    },
    {
      "epoch": 8.068497377352669,
      "grad_norm": 0.02589196152985096,
      "learning_rate": 4.1931502622647335e-05,
      "loss": 0.0011,
      "step": 26150
    },
    {
      "epoch": 8.071582844800988,
      "grad_norm": 0.011471354402601719,
      "learning_rate": 4.192841715519901e-05,
      "loss": 0.0114,
      "step": 26160
    },
    {
      "epoch": 8.074668312249306,
      "grad_norm": 3.1457602977752686,
      "learning_rate": 4.192533168775069e-05,
      "loss": 0.007,
      "step": 26170
    },
    {
      "epoch": 8.077753779697623,
      "grad_norm": 0.046428002417087555,
      "learning_rate": 4.192224622030238e-05,
      "loss": 0.0019,
      "step": 26180
    },
    {
      "epoch": 8.080839247145942,
      "grad_norm": 0.0004824385978281498,
      "learning_rate": 4.191916075285406e-05,
      "loss": 0.0047,
      "step": 26190
    },
    {
      "epoch": 8.08392471459426,
      "grad_norm": 0.0012716524070128798,
      "learning_rate": 4.191607528540574e-05,
      "loss": 0.0074,
      "step": 26200
    },
    {
      "epoch": 8.08701018204258,
      "grad_norm": 0.0056677041575312614,
      "learning_rate": 4.191298981795742e-05,
      "loss": 0.0009,
      "step": 26210
    },
    {
      "epoch": 8.090095649490898,
      "grad_norm": 2.123782157897949,
      "learning_rate": 4.1909904350509106e-05,
      "loss": 0.0035,
      "step": 26220
    },
    {
      "epoch": 8.093181116939217,
      "grad_norm": 0.06587952375411987,
      "learning_rate": 4.190681888306078e-05,
      "loss": 0.0024,
      "step": 26230
    },
    {
      "epoch": 8.096266584387534,
      "grad_norm": 1.1977802515029907,
      "learning_rate": 4.1903733415612464e-05,
      "loss": 0.0056,
      "step": 26240
    },
    {
      "epoch": 8.099352051835853,
      "grad_norm": 1.5331416130065918,
      "learning_rate": 4.190064794816415e-05,
      "loss": 0.0038,
      "step": 26250
    },
    {
      "epoch": 8.102437519284171,
      "grad_norm": 0.009174259379506111,
      "learning_rate": 4.189756248071583e-05,
      "loss": 0.0011,
      "step": 26260
    },
    {
      "epoch": 8.10552298673249,
      "grad_norm": 0.6597232818603516,
      "learning_rate": 4.189447701326751e-05,
      "loss": 0.0025,
      "step": 26270
    },
    {
      "epoch": 8.108608454180809,
      "grad_norm": 0.3847323954105377,
      "learning_rate": 4.1891391545819194e-05,
      "loss": 0.0024,
      "step": 26280
    },
    {
      "epoch": 8.111693921629128,
      "grad_norm": 0.09133254736661911,
      "learning_rate": 4.1888306078370876e-05,
      "loss": 0.0048,
      "step": 26290
    },
    {
      "epoch": 8.114779389077444,
      "grad_norm": 3.2849857807159424,
      "learning_rate": 4.188522061092255e-05,
      "loss": 0.0048,
      "step": 26300
    },
    {
      "epoch": 8.117864856525763,
      "grad_norm": 0.013791377656161785,
      "learning_rate": 4.188213514347424e-05,
      "loss": 0.0004,
      "step": 26310
    },
    {
      "epoch": 8.120950323974082,
      "grad_norm": 0.016935568302869797,
      "learning_rate": 4.1879049676025924e-05,
      "loss": 0.0027,
      "step": 26320
    },
    {
      "epoch": 8.1240357914224,
      "grad_norm": 0.5658202767372131,
      "learning_rate": 4.18759642085776e-05,
      "loss": 0.0011,
      "step": 26330
    },
    {
      "epoch": 8.12712125887072,
      "grad_norm": 1.8978145122528076,
      "learning_rate": 4.187287874112928e-05,
      "loss": 0.0036,
      "step": 26340
    },
    {
      "epoch": 8.130206726319038,
      "grad_norm": 0.8068263530731201,
      "learning_rate": 4.1869793273680964e-05,
      "loss": 0.0014,
      "step": 26350
    },
    {
      "epoch": 8.133292193767355,
      "grad_norm": 0.010261302813887596,
      "learning_rate": 4.186670780623265e-05,
      "loss": 0.0009,
      "step": 26360
    },
    {
      "epoch": 8.136377661215674,
      "grad_norm": 0.7986578345298767,
      "learning_rate": 4.186362233878432e-05,
      "loss": 0.0048,
      "step": 26370
    },
    {
      "epoch": 8.139463128663992,
      "grad_norm": 0.0021584772039204836,
      "learning_rate": 4.186053687133601e-05,
      "loss": 0.0029,
      "step": 26380
    },
    {
      "epoch": 8.142548596112311,
      "grad_norm": 0.002669141162186861,
      "learning_rate": 4.1857451403887694e-05,
      "loss": 0.0041,
      "step": 26390
    },
    {
      "epoch": 8.14563406356063,
      "grad_norm": 0.0270845890045166,
      "learning_rate": 4.185436593643937e-05,
      "loss": 0.0009,
      "step": 26400
    },
    {
      "epoch": 8.148719531008949,
      "grad_norm": 0.08667232096195221,
      "learning_rate": 4.185128046899105e-05,
      "loss": 0.0007,
      "step": 26410
    },
    {
      "epoch": 8.151804998457266,
      "grad_norm": 0.13604775071144104,
      "learning_rate": 4.1848195001542735e-05,
      "loss": 0.0033,
      "step": 26420
    },
    {
      "epoch": 8.154890465905584,
      "grad_norm": 4.431789398193359,
      "learning_rate": 4.184510953409442e-05,
      "loss": 0.008,
      "step": 26430
    },
    {
      "epoch": 8.157975933353903,
      "grad_norm": 3.1696314811706543,
      "learning_rate": 4.18420240666461e-05,
      "loss": 0.0063,
      "step": 26440
    },
    {
      "epoch": 8.161061400802222,
      "grad_norm": 0.04431000351905823,
      "learning_rate": 4.183893859919778e-05,
      "loss": 0.0056,
      "step": 26450
    },
    {
      "epoch": 8.16414686825054,
      "grad_norm": 0.14774541556835175,
      "learning_rate": 4.1835853131749465e-05,
      "loss": 0.0139,
      "step": 26460
    },
    {
      "epoch": 8.16723233569886,
      "grad_norm": 2.516000509262085,
      "learning_rate": 4.183276766430114e-05,
      "loss": 0.0128,
      "step": 26470
    },
    {
      "epoch": 8.170317803147176,
      "grad_norm": 0.0008547017350792885,
      "learning_rate": 4.182968219685282e-05,
      "loss": 0.0081,
      "step": 26480
    },
    {
      "epoch": 8.173403270595495,
      "grad_norm": 2.5999927520751953,
      "learning_rate": 4.1826596729404505e-05,
      "loss": 0.0038,
      "step": 26490
    },
    {
      "epoch": 8.176488738043814,
      "grad_norm": 0.0006947940564714372,
      "learning_rate": 4.182351126195619e-05,
      "loss": 0.0005,
      "step": 26500
    },
    {
      "epoch": 8.179574205492132,
      "grad_norm": 0.009043160825967789,
      "learning_rate": 4.182042579450787e-05,
      "loss": 0.005,
      "step": 26510
    },
    {
      "epoch": 8.182659672940451,
      "grad_norm": 0.16046704351902008,
      "learning_rate": 4.181734032705955e-05,
      "loss": 0.0048,
      "step": 26520
    },
    {
      "epoch": 8.18574514038877,
      "grad_norm": 0.027553346008062363,
      "learning_rate": 4.1814254859611235e-05,
      "loss": 0.0001,
      "step": 26530
    },
    {
      "epoch": 8.188830607837087,
      "grad_norm": 0.005779489874839783,
      "learning_rate": 4.181116939216291e-05,
      "loss": 0.0003,
      "step": 26540
    },
    {
      "epoch": 8.191916075285405,
      "grad_norm": 0.018414707854390144,
      "learning_rate": 4.18080839247146e-05,
      "loss": 0.0034,
      "step": 26550
    },
    {
      "epoch": 8.195001542733724,
      "grad_norm": 0.023422930389642715,
      "learning_rate": 4.1804998457266276e-05,
      "loss": 0.0013,
      "step": 26560
    },
    {
      "epoch": 8.198087010182043,
      "grad_norm": 1.1964664459228516,
      "learning_rate": 4.180191298981796e-05,
      "loss": 0.0172,
      "step": 26570
    },
    {
      "epoch": 8.201172477630362,
      "grad_norm": 0.007060597185045481,
      "learning_rate": 4.179882752236964e-05,
      "loss": 0.012,
      "step": 26580
    },
    {
      "epoch": 8.204257945078679,
      "grad_norm": 0.8763294816017151,
      "learning_rate": 4.1795742054921323e-05,
      "loss": 0.0024,
      "step": 26590
    },
    {
      "epoch": 8.207343412526997,
      "grad_norm": 0.37704232335090637,
      "learning_rate": 4.1792656587473006e-05,
      "loss": 0.0053,
      "step": 26600
    },
    {
      "epoch": 8.210428879975316,
      "grad_norm": 0.0027181298937648535,
      "learning_rate": 4.178957112002468e-05,
      "loss": 0.005,
      "step": 26610
    },
    {
      "epoch": 8.213514347423635,
      "grad_norm": 0.03247104212641716,
      "learning_rate": 4.178648565257637e-05,
      "loss": 0.0022,
      "step": 26620
    },
    {
      "epoch": 8.216599814871953,
      "grad_norm": 2.7786202430725098,
      "learning_rate": 4.1783400185128047e-05,
      "loss": 0.0105,
      "step": 26630
    },
    {
      "epoch": 8.219685282320272,
      "grad_norm": 1.0787359476089478,
      "learning_rate": 4.178031471767973e-05,
      "loss": 0.0026,
      "step": 26640
    },
    {
      "epoch": 8.22277074976859,
      "grad_norm": 0.01823379658162594,
      "learning_rate": 4.177722925023141e-05,
      "loss": 0.0073,
      "step": 26650
    },
    {
      "epoch": 8.225856217216908,
      "grad_norm": 3.854459285736084,
      "learning_rate": 4.1774143782783094e-05,
      "loss": 0.004,
      "step": 26660
    },
    {
      "epoch": 8.228941684665227,
      "grad_norm": 0.015459815971553326,
      "learning_rate": 4.1771058315334776e-05,
      "loss": 0.0037,
      "step": 26670
    },
    {
      "epoch": 8.232027152113545,
      "grad_norm": 0.009034634567797184,
      "learning_rate": 4.176797284788645e-05,
      "loss": 0.0058,
      "step": 26680
    },
    {
      "epoch": 8.235112619561864,
      "grad_norm": 0.002651055110618472,
      "learning_rate": 4.176488738043814e-05,
      "loss": 0.0029,
      "step": 26690
    },
    {
      "epoch": 8.238198087010183,
      "grad_norm": 0.08193285763263702,
      "learning_rate": 4.176180191298982e-05,
      "loss": 0.0012,
      "step": 26700
    },
    {
      "epoch": 8.2412835544585,
      "grad_norm": 0.010431535542011261,
      "learning_rate": 4.17587164455415e-05,
      "loss": 0.0096,
      "step": 26710
    },
    {
      "epoch": 8.244369021906818,
      "grad_norm": 0.5949903130531311,
      "learning_rate": 4.175563097809318e-05,
      "loss": 0.0028,
      "step": 26720
    },
    {
      "epoch": 8.247454489355137,
      "grad_norm": 0.0030137738212943077,
      "learning_rate": 4.1752545510644865e-05,
      "loss": 0.0079,
      "step": 26730
    },
    {
      "epoch": 8.250539956803456,
      "grad_norm": 1.7183253765106201,
      "learning_rate": 4.174946004319655e-05,
      "loss": 0.0029,
      "step": 26740
    },
    {
      "epoch": 8.253625424251775,
      "grad_norm": 0.45539072155952454,
      "learning_rate": 4.174637457574822e-05,
      "loss": 0.0049,
      "step": 26750
    },
    {
      "epoch": 8.256710891700093,
      "grad_norm": 0.011535351164638996,
      "learning_rate": 4.174328910829991e-05,
      "loss": 0.002,
      "step": 26760
    },
    {
      "epoch": 8.25979635914841,
      "grad_norm": 0.03804268687963486,
      "learning_rate": 4.174020364085159e-05,
      "loss": 0.0101,
      "step": 26770
    },
    {
      "epoch": 8.262881826596729,
      "grad_norm": 0.08396714925765991,
      "learning_rate": 4.173711817340327e-05,
      "loss": 0.0056,
      "step": 26780
    },
    {
      "epoch": 8.265967294045048,
      "grad_norm": 0.5628363490104675,
      "learning_rate": 4.173403270595496e-05,
      "loss": 0.0026,
      "step": 26790
    },
    {
      "epoch": 8.269052761493366,
      "grad_norm": 0.2332162857055664,
      "learning_rate": 4.1730947238506635e-05,
      "loss": 0.0031,
      "step": 26800
    },
    {
      "epoch": 8.272138228941685,
      "grad_norm": 0.035536862909793854,
      "learning_rate": 4.172786177105832e-05,
      "loss": 0.0007,
      "step": 26810
    },
    {
      "epoch": 8.275223696390004,
      "grad_norm": 0.2879379689693451,
      "learning_rate": 4.172477630361e-05,
      "loss": 0.0006,
      "step": 26820
    },
    {
      "epoch": 8.27830916383832,
      "grad_norm": 0.03700688108801842,
      "learning_rate": 4.172169083616168e-05,
      "loss": 0.0026,
      "step": 26830
    },
    {
      "epoch": 8.28139463128664,
      "grad_norm": 2.2615153789520264,
      "learning_rate": 4.171860536871336e-05,
      "loss": 0.0032,
      "step": 26840
    },
    {
      "epoch": 8.284480098734958,
      "grad_norm": 0.0038525916170328856,
      "learning_rate": 4.171551990126504e-05,
      "loss": 0.0015,
      "step": 26850
    },
    {
      "epoch": 8.287565566183277,
      "grad_norm": 0.10929784178733826,
      "learning_rate": 4.171243443381673e-05,
      "loss": 0.0039,
      "step": 26860
    },
    {
      "epoch": 8.290651033631596,
      "grad_norm": 0.008066573180258274,
      "learning_rate": 4.1709348966368406e-05,
      "loss": 0.0006,
      "step": 26870
    },
    {
      "epoch": 8.293736501079914,
      "grad_norm": 0.45254752039909363,
      "learning_rate": 4.170626349892009e-05,
      "loss": 0.0021,
      "step": 26880
    },
    {
      "epoch": 8.296821968528231,
      "grad_norm": 0.003938497044146061,
      "learning_rate": 4.170317803147177e-05,
      "loss": 0.0054,
      "step": 26890
    },
    {
      "epoch": 8.29990743597655,
      "grad_norm": 0.10096599161624908,
      "learning_rate": 4.170009256402345e-05,
      "loss": 0.0005,
      "step": 26900
    },
    {
      "epoch": 8.302992903424869,
      "grad_norm": 0.5468363165855408,
      "learning_rate": 4.1697007096575136e-05,
      "loss": 0.0015,
      "step": 26910
    },
    {
      "epoch": 8.306078370873188,
      "grad_norm": 0.0007622112752869725,
      "learning_rate": 4.169392162912681e-05,
      "loss": 0.0025,
      "step": 26920
    },
    {
      "epoch": 8.309163838321506,
      "grad_norm": 0.028414037078619003,
      "learning_rate": 4.16908361616785e-05,
      "loss": 0.004,
      "step": 26930
    },
    {
      "epoch": 8.312249305769825,
      "grad_norm": 0.19896666705608368,
      "learning_rate": 4.1687750694230176e-05,
      "loss": 0.0032,
      "step": 26940
    },
    {
      "epoch": 8.315334773218142,
      "grad_norm": 0.20604056119918823,
      "learning_rate": 4.168466522678186e-05,
      "loss": 0.0004,
      "step": 26950
    },
    {
      "epoch": 8.31842024066646,
      "grad_norm": 0.000939049874432385,
      "learning_rate": 4.168157975933354e-05,
      "loss": 0.0114,
      "step": 26960
    },
    {
      "epoch": 8.32150570811478,
      "grad_norm": 0.009797546081244946,
      "learning_rate": 4.1678494291885224e-05,
      "loss": 0.0095,
      "step": 26970
    },
    {
      "epoch": 8.324591175563098,
      "grad_norm": 0.0018504185136407614,
      "learning_rate": 4.1675408824436906e-05,
      "loss": 0.0057,
      "step": 26980
    },
    {
      "epoch": 8.327676643011417,
      "grad_norm": 0.029806911945343018,
      "learning_rate": 4.167232335698858e-05,
      "loss": 0.0005,
      "step": 26990
    },
    {
      "epoch": 8.330762110459734,
      "grad_norm": 0.03909338265657425,
      "learning_rate": 4.166923788954027e-05,
      "loss": 0.0003,
      "step": 27000
    },
    {
      "epoch": 8.333847577908053,
      "grad_norm": 0.19415117800235748,
      "learning_rate": 4.166615242209195e-05,
      "loss": 0.0124,
      "step": 27010
    },
    {
      "epoch": 8.336933045356371,
      "grad_norm": 0.0009185970993712544,
      "learning_rate": 4.166306695464363e-05,
      "loss": 0.0012,
      "step": 27020
    },
    {
      "epoch": 8.34001851280469,
      "grad_norm": 0.0065058935433626175,
      "learning_rate": 4.165998148719531e-05,
      "loss": 0.0007,
      "step": 27030
    },
    {
      "epoch": 8.343103980253009,
      "grad_norm": 0.028578869998455048,
      "learning_rate": 4.1656896019746994e-05,
      "loss": 0.0011,
      "step": 27040
    },
    {
      "epoch": 8.346189447701327,
      "grad_norm": 0.021333977580070496,
      "learning_rate": 4.165381055229868e-05,
      "loss": 0.0025,
      "step": 27050
    },
    {
      "epoch": 8.349274915149644,
      "grad_norm": 0.015370028093457222,
      "learning_rate": 4.165072508485036e-05,
      "loss": 0.0041,
      "step": 27060
    },
    {
      "epoch": 8.352360382597963,
      "grad_norm": 0.19993029534816742,
      "learning_rate": 4.164763961740204e-05,
      "loss": 0.0024,
      "step": 27070
    },
    {
      "epoch": 8.355445850046282,
      "grad_norm": 0.05409973859786987,
      "learning_rate": 4.164455414995372e-05,
      "loss": 0.0002,
      "step": 27080
    },
    {
      "epoch": 8.3585313174946,
      "grad_norm": 0.019849486649036407,
      "learning_rate": 4.16414686825054e-05,
      "loss": 0.0081,
      "step": 27090
    },
    {
      "epoch": 8.36161678494292,
      "grad_norm": 4.481069564819336,
      "learning_rate": 4.163838321505708e-05,
      "loss": 0.0107,
      "step": 27100
    },
    {
      "epoch": 8.364702252391238,
      "grad_norm": 0.02471465989947319,
      "learning_rate": 4.1635297747608765e-05,
      "loss": 0.0018,
      "step": 27110
    },
    {
      "epoch": 8.367787719839555,
      "grad_norm": 2.768372058868408,
      "learning_rate": 4.163221228016045e-05,
      "loss": 0.0086,
      "step": 27120
    },
    {
      "epoch": 8.370873187287874,
      "grad_norm": 0.009055954404175282,
      "learning_rate": 4.162912681271213e-05,
      "loss": 0.0007,
      "step": 27130
    },
    {
      "epoch": 8.373958654736192,
      "grad_norm": 0.006888775620609522,
      "learning_rate": 4.162604134526381e-05,
      "loss": 0.0058,
      "step": 27140
    },
    {
      "epoch": 8.377044122184511,
      "grad_norm": 1.003568410873413,
      "learning_rate": 4.162295587781549e-05,
      "loss": 0.0172,
      "step": 27150
    },
    {
      "epoch": 8.38012958963283,
      "grad_norm": 0.0017460526432842016,
      "learning_rate": 4.161987041036717e-05,
      "loss": 0.0032,
      "step": 27160
    },
    {
      "epoch": 8.383215057081149,
      "grad_norm": 0.08034998178482056,
      "learning_rate": 4.161678494291885e-05,
      "loss": 0.0009,
      "step": 27170
    },
    {
      "epoch": 8.386300524529466,
      "grad_norm": 0.04564040154218674,
      "learning_rate": 4.1613699475470535e-05,
      "loss": 0.0055,
      "step": 27180
    },
    {
      "epoch": 8.389385991977784,
      "grad_norm": 0.5540038347244263,
      "learning_rate": 4.161061400802222e-05,
      "loss": 0.0018,
      "step": 27190
    },
    {
      "epoch": 8.392471459426103,
      "grad_norm": 1.8819854259490967,
      "learning_rate": 4.16075285405739e-05,
      "loss": 0.0046,
      "step": 27200
    },
    {
      "epoch": 8.395556926874422,
      "grad_norm": 0.0045220754109323025,
      "learning_rate": 4.160444307312558e-05,
      "loss": 0.0047,
      "step": 27210
    },
    {
      "epoch": 8.39864239432274,
      "grad_norm": 0.228713259100914,
      "learning_rate": 4.160135760567726e-05,
      "loss": 0.0009,
      "step": 27220
    },
    {
      "epoch": 8.40172786177106,
      "grad_norm": 0.2322496771812439,
      "learning_rate": 4.159827213822894e-05,
      "loss": 0.0019,
      "step": 27230
    },
    {
      "epoch": 8.404813329219376,
      "grad_norm": 1.6484237909317017,
      "learning_rate": 4.1595186670780623e-05,
      "loss": 0.0031,
      "step": 27240
    },
    {
      "epoch": 8.407898796667695,
      "grad_norm": 0.1191449984908104,
      "learning_rate": 4.1592101203332306e-05,
      "loss": 0.0135,
      "step": 27250
    },
    {
      "epoch": 8.410984264116014,
      "grad_norm": 0.00416996143758297,
      "learning_rate": 4.158901573588399e-05,
      "loss": 0.0084,
      "step": 27260
    },
    {
      "epoch": 8.414069731564332,
      "grad_norm": 0.05298130586743355,
      "learning_rate": 4.158593026843567e-05,
      "loss": 0.0171,
      "step": 27270
    },
    {
      "epoch": 8.417155199012651,
      "grad_norm": 0.01174961868673563,
      "learning_rate": 4.158284480098735e-05,
      "loss": 0.002,
      "step": 27280
    },
    {
      "epoch": 8.42024066646097,
      "grad_norm": 3.1354129314422607,
      "learning_rate": 4.157975933353903e-05,
      "loss": 0.0125,
      "step": 27290
    },
    {
      "epoch": 8.423326133909287,
      "grad_norm": 0.04483984038233757,
      "learning_rate": 4.157667386609072e-05,
      "loss": 0.0042,
      "step": 27300
    },
    {
      "epoch": 8.426411601357605,
      "grad_norm": 0.36843064427375793,
      "learning_rate": 4.15735883986424e-05,
      "loss": 0.0008,
      "step": 27310
    },
    {
      "epoch": 8.429497068805924,
      "grad_norm": 0.005442007910460234,
      "learning_rate": 4.1570502931194076e-05,
      "loss": 0.0078,
      "step": 27320
    },
    {
      "epoch": 8.432582536254243,
      "grad_norm": 0.43795114755630493,
      "learning_rate": 4.156741746374576e-05,
      "loss": 0.0025,
      "step": 27330
    },
    {
      "epoch": 8.435668003702562,
      "grad_norm": 0.8521794676780701,
      "learning_rate": 4.156433199629744e-05,
      "loss": 0.0063,
      "step": 27340
    },
    {
      "epoch": 8.438753471150878,
      "grad_norm": 0.005429700016975403,
      "learning_rate": 4.1561246528849124e-05,
      "loss": 0.008,
      "step": 27350
    },
    {
      "epoch": 8.441838938599197,
      "grad_norm": 0.1591930091381073,
      "learning_rate": 4.15581610614008e-05,
      "loss": 0.0079,
      "step": 27360
    },
    {
      "epoch": 8.444924406047516,
      "grad_norm": 0.004956705030053854,
      "learning_rate": 4.155507559395249e-05,
      "loss": 0.0084,
      "step": 27370
    },
    {
      "epoch": 8.448009873495835,
      "grad_norm": 0.20256105065345764,
      "learning_rate": 4.155199012650417e-05,
      "loss": 0.0034,
      "step": 27380
    },
    {
      "epoch": 8.451095340944153,
      "grad_norm": 0.06517618149518967,
      "learning_rate": 4.154890465905585e-05,
      "loss": 0.0021,
      "step": 27390
    },
    {
      "epoch": 8.454180808392472,
      "grad_norm": 0.036658238619565964,
      "learning_rate": 4.154581919160753e-05,
      "loss": 0.0021,
      "step": 27400
    },
    {
      "epoch": 8.457266275840789,
      "grad_norm": 0.6590988636016846,
      "learning_rate": 4.154273372415921e-05,
      "loss": 0.0095,
      "step": 27410
    },
    {
      "epoch": 8.460351743289108,
      "grad_norm": 1.4657678604125977,
      "learning_rate": 4.1539648256710894e-05,
      "loss": 0.0073,
      "step": 27420
    },
    {
      "epoch": 8.463437210737426,
      "grad_norm": 2.6423606872558594,
      "learning_rate": 4.153656278926257e-05,
      "loss": 0.0078,
      "step": 27430
    },
    {
      "epoch": 8.466522678185745,
      "grad_norm": 0.0022484902292490005,
      "learning_rate": 4.153347732181426e-05,
      "loss": 0.0076,
      "step": 27440
    },
    {
      "epoch": 8.469608145634064,
      "grad_norm": 5.751829624176025,
      "learning_rate": 4.153039185436594e-05,
      "loss": 0.0159,
      "step": 27450
    },
    {
      "epoch": 8.472693613082383,
      "grad_norm": 0.21739673614501953,
      "learning_rate": 4.152730638691762e-05,
      "loss": 0.0053,
      "step": 27460
    },
    {
      "epoch": 8.4757790805307,
      "grad_norm": 0.0009097068686969578,
      "learning_rate": 4.15242209194693e-05,
      "loss": 0.0055,
      "step": 27470
    },
    {
      "epoch": 8.478864547979018,
      "grad_norm": 0.4873068034648895,
      "learning_rate": 4.152113545202098e-05,
      "loss": 0.0044,
      "step": 27480
    },
    {
      "epoch": 8.481950015427337,
      "grad_norm": 0.3798848092556,
      "learning_rate": 4.1518049984572665e-05,
      "loss": 0.0025,
      "step": 27490
    },
    {
      "epoch": 8.485035482875656,
      "grad_norm": 0.4163951277732849,
      "learning_rate": 4.151496451712434e-05,
      "loss": 0.0035,
      "step": 27500
    },
    {
      "epoch": 8.488120950323975,
      "grad_norm": 0.005329848267138004,
      "learning_rate": 4.151187904967603e-05,
      "loss": 0.0006,
      "step": 27510
    },
    {
      "epoch": 8.491206417772293,
      "grad_norm": 0.7297326922416687,
      "learning_rate": 4.150879358222771e-05,
      "loss": 0.0059,
      "step": 27520
    },
    {
      "epoch": 8.49429188522061,
      "grad_norm": 0.009951174259185791,
      "learning_rate": 4.150570811477939e-05,
      "loss": 0.0089,
      "step": 27530
    },
    {
      "epoch": 8.497377352668929,
      "grad_norm": 0.011551626026630402,
      "learning_rate": 4.150262264733108e-05,
      "loss": 0.0017,
      "step": 27540
    },
    {
      "epoch": 8.500462820117248,
      "grad_norm": 0.08732021600008011,
      "learning_rate": 4.149953717988275e-05,
      "loss": 0.0074,
      "step": 27550
    },
    {
      "epoch": 8.503548287565566,
      "grad_norm": 0.011051314882934093,
      "learning_rate": 4.1496451712434436e-05,
      "loss": 0.0044,
      "step": 27560
    },
    {
      "epoch": 8.506633755013885,
      "grad_norm": 0.07224658131599426,
      "learning_rate": 4.149336624498612e-05,
      "loss": 0.0004,
      "step": 27570
    },
    {
      "epoch": 8.509719222462204,
      "grad_norm": 0.02371015027165413,
      "learning_rate": 4.14902807775378e-05,
      "loss": 0.0017,
      "step": 27580
    },
    {
      "epoch": 8.51280468991052,
      "grad_norm": 0.0003063926415052265,
      "learning_rate": 4.148719531008948e-05,
      "loss": 0.0012,
      "step": 27590
    },
    {
      "epoch": 8.51589015735884,
      "grad_norm": 0.1375861018896103,
      "learning_rate": 4.148410984264116e-05,
      "loss": 0.0046,
      "step": 27600
    },
    {
      "epoch": 8.518975624807158,
      "grad_norm": 2.078216791152954,
      "learning_rate": 4.148102437519285e-05,
      "loss": 0.0097,
      "step": 27610
    },
    {
      "epoch": 8.522061092255477,
      "grad_norm": 0.023096159100532532,
      "learning_rate": 4.1477938907744524e-05,
      "loss": 0.0031,
      "step": 27620
    },
    {
      "epoch": 8.525146559703796,
      "grad_norm": 0.0010790262604132295,
      "learning_rate": 4.1474853440296206e-05,
      "loss": 0.0011,
      "step": 27630
    },
    {
      "epoch": 8.528232027152114,
      "grad_norm": 0.031645048409700394,
      "learning_rate": 4.147176797284789e-05,
      "loss": 0.0027,
      "step": 27640
    },
    {
      "epoch": 8.531317494600431,
      "grad_norm": 0.1544341742992401,
      "learning_rate": 4.146868250539957e-05,
      "loss": 0.0014,
      "step": 27650
    },
    {
      "epoch": 8.53440296204875,
      "grad_norm": 0.00035377583117224276,
      "learning_rate": 4.1465597037951254e-05,
      "loss": 0.0015,
      "step": 27660
    },
    {
      "epoch": 8.537488429497069,
      "grad_norm": 0.0077221691608428955,
      "learning_rate": 4.146251157050293e-05,
      "loss": 0.0044,
      "step": 27670
    },
    {
      "epoch": 8.540573896945387,
      "grad_norm": 0.0157205481082201,
      "learning_rate": 4.145942610305462e-05,
      "loss": 0.0004,
      "step": 27680
    },
    {
      "epoch": 8.543659364393706,
      "grad_norm": 0.003456225385889411,
      "learning_rate": 4.1456340635606294e-05,
      "loss": 0.0036,
      "step": 27690
    },
    {
      "epoch": 8.546744831842023,
      "grad_norm": 0.026520835235714912,
      "learning_rate": 4.145325516815798e-05,
      "loss": 0.0028,
      "step": 27700
    },
    {
      "epoch": 8.549830299290342,
      "grad_norm": 0.022594142705202103,
      "learning_rate": 4.145016970070966e-05,
      "loss": 0.0013,
      "step": 27710
    },
    {
      "epoch": 8.55291576673866,
      "grad_norm": 0.006071443669497967,
      "learning_rate": 4.144708423326134e-05,
      "loss": 0.015,
      "step": 27720
    },
    {
      "epoch": 8.55600123418698,
      "grad_norm": 0.008476716466248035,
      "learning_rate": 4.1443998765813024e-05,
      "loss": 0.001,
      "step": 27730
    },
    {
      "epoch": 8.559086701635298,
      "grad_norm": 0.06083545461297035,
      "learning_rate": 4.14409132983647e-05,
      "loss": 0.0011,
      "step": 27740
    },
    {
      "epoch": 8.562172169083617,
      "grad_norm": 1.813132405281067,
      "learning_rate": 4.143782783091639e-05,
      "loss": 0.0065,
      "step": 27750
    },
    {
      "epoch": 8.565257636531936,
      "grad_norm": 1.2650902271270752,
      "learning_rate": 4.1434742363468065e-05,
      "loss": 0.0026,
      "step": 27760
    },
    {
      "epoch": 8.568343103980252,
      "grad_norm": 3.35882830619812,
      "learning_rate": 4.143165689601975e-05,
      "loss": 0.0069,
      "step": 27770
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 0.0030064312741160393,
      "learning_rate": 4.1428571428571437e-05,
      "loss": 0.001,
      "step": 27780
    },
    {
      "epoch": 8.57451403887689,
      "grad_norm": 0.0015922945458441973,
      "learning_rate": 4.142548596112311e-05,
      "loss": 0.0016,
      "step": 27790
    },
    {
      "epoch": 8.577599506325209,
      "grad_norm": 0.011738203465938568,
      "learning_rate": 4.1422400493674795e-05,
      "loss": 0.0148,
      "step": 27800
    },
    {
      "epoch": 8.580684973773527,
      "grad_norm": 0.024559378623962402,
      "learning_rate": 4.141931502622648e-05,
      "loss": 0.0034,
      "step": 27810
    },
    {
      "epoch": 8.583770441221844,
      "grad_norm": 0.43109315633773804,
      "learning_rate": 4.141622955877816e-05,
      "loss": 0.0065,
      "step": 27820
    },
    {
      "epoch": 8.586855908670163,
      "grad_norm": 0.2906211316585541,
      "learning_rate": 4.1413144091329835e-05,
      "loss": 0.0078,
      "step": 27830
    },
    {
      "epoch": 8.589941376118482,
      "grad_norm": 1.5136613845825195,
      "learning_rate": 4.141005862388152e-05,
      "loss": 0.0061,
      "step": 27840
    },
    {
      "epoch": 8.5930268435668,
      "grad_norm": 1.5795055627822876,
      "learning_rate": 4.140697315643321e-05,
      "loss": 0.0091,
      "step": 27850
    },
    {
      "epoch": 8.59611231101512,
      "grad_norm": 0.7727453112602234,
      "learning_rate": 4.140388768898488e-05,
      "loss": 0.0107,
      "step": 27860
    },
    {
      "epoch": 8.599197778463438,
      "grad_norm": 1.7851126194000244,
      "learning_rate": 4.1400802221536565e-05,
      "loss": 0.0106,
      "step": 27870
    },
    {
      "epoch": 8.602283245911755,
      "grad_norm": 0.4689392149448395,
      "learning_rate": 4.139771675408825e-05,
      "loss": 0.0131,
      "step": 27880
    },
    {
      "epoch": 8.605368713360074,
      "grad_norm": 2.6330862045288086,
      "learning_rate": 4.139463128663993e-05,
      "loss": 0.0146,
      "step": 27890
    },
    {
      "epoch": 8.608454180808392,
      "grad_norm": 0.5789006352424622,
      "learning_rate": 4.1391545819191606e-05,
      "loss": 0.0159,
      "step": 27900
    },
    {
      "epoch": 8.611539648256711,
      "grad_norm": 0.7847501039505005,
      "learning_rate": 4.138846035174329e-05,
      "loss": 0.0044,
      "step": 27910
    },
    {
      "epoch": 8.61462511570503,
      "grad_norm": 0.9635860919952393,
      "learning_rate": 4.138537488429498e-05,
      "loss": 0.0112,
      "step": 27920
    },
    {
      "epoch": 8.617710583153348,
      "grad_norm": 0.3367955684661865,
      "learning_rate": 4.138228941684665e-05,
      "loss": 0.0089,
      "step": 27930
    },
    {
      "epoch": 8.620796050601665,
      "grad_norm": 0.4775908291339874,
      "learning_rate": 4.1379203949398336e-05,
      "loss": 0.0051,
      "step": 27940
    },
    {
      "epoch": 8.623881518049984,
      "grad_norm": 0.48216187953948975,
      "learning_rate": 4.137611848195002e-05,
      "loss": 0.0041,
      "step": 27950
    },
    {
      "epoch": 8.626966985498303,
      "grad_norm": 1.1385987997055054,
      "learning_rate": 4.13730330145017e-05,
      "loss": 0.0067,
      "step": 27960
    },
    {
      "epoch": 8.630052452946622,
      "grad_norm": 0.0022650861646980047,
      "learning_rate": 4.1369947547053377e-05,
      "loss": 0.0027,
      "step": 27970
    },
    {
      "epoch": 8.63313792039494,
      "grad_norm": 1.9188531637191772,
      "learning_rate": 4.136686207960506e-05,
      "loss": 0.0032,
      "step": 27980
    },
    {
      "epoch": 8.636223387843259,
      "grad_norm": 0.09244095534086227,
      "learning_rate": 4.136377661215675e-05,
      "loss": 0.0008,
      "step": 27990
    },
    {
      "epoch": 8.639308855291576,
      "grad_norm": 1.0929709672927856,
      "learning_rate": 4.1360691144708424e-05,
      "loss": 0.0053,
      "step": 28000
    },
    {
      "epoch": 8.642394322739895,
      "grad_norm": 0.01922772265970707,
      "learning_rate": 4.1357605677260106e-05,
      "loss": 0.0018,
      "step": 28010
    },
    {
      "epoch": 8.645479790188213,
      "grad_norm": 0.10635723918676376,
      "learning_rate": 4.135452020981179e-05,
      "loss": 0.0028,
      "step": 28020
    },
    {
      "epoch": 8.648565257636532,
      "grad_norm": 2.003657341003418,
      "learning_rate": 4.135143474236347e-05,
      "loss": 0.005,
      "step": 28030
    },
    {
      "epoch": 8.651650725084851,
      "grad_norm": 2.8568668365478516,
      "learning_rate": 4.134834927491515e-05,
      "loss": 0.0049,
      "step": 28040
    },
    {
      "epoch": 8.654736192533168,
      "grad_norm": 0.00276233465410769,
      "learning_rate": 4.1345263807466836e-05,
      "loss": 0.0058,
      "step": 28050
    },
    {
      "epoch": 8.657821659981487,
      "grad_norm": 0.06204794719815254,
      "learning_rate": 4.134217834001852e-05,
      "loss": 0.0057,
      "step": 28060
    },
    {
      "epoch": 8.660907127429805,
      "grad_norm": 0.09325850009918213,
      "learning_rate": 4.1339092872570195e-05,
      "loss": 0.0048,
      "step": 28070
    },
    {
      "epoch": 8.663992594878124,
      "grad_norm": 2.8400583267211914,
      "learning_rate": 4.133600740512188e-05,
      "loss": 0.0082,
      "step": 28080
    },
    {
      "epoch": 8.667078062326443,
      "grad_norm": 0.05504489690065384,
      "learning_rate": 4.133292193767356e-05,
      "loss": 0.0174,
      "step": 28090
    },
    {
      "epoch": 8.670163529774761,
      "grad_norm": 7.706209659576416,
      "learning_rate": 4.132983647022524e-05,
      "loss": 0.0167,
      "step": 28100
    },
    {
      "epoch": 8.67324899722308,
      "grad_norm": 0.9647124409675598,
      "learning_rate": 4.132675100277692e-05,
      "loss": 0.0097,
      "step": 28110
    },
    {
      "epoch": 8.676334464671397,
      "grad_norm": 0.7231084108352661,
      "learning_rate": 4.132366553532861e-05,
      "loss": 0.0024,
      "step": 28120
    },
    {
      "epoch": 8.679419932119716,
      "grad_norm": 1.221007227897644,
      "learning_rate": 4.132058006788029e-05,
      "loss": 0.0055,
      "step": 28130
    },
    {
      "epoch": 8.682505399568035,
      "grad_norm": 0.016465840861201286,
      "learning_rate": 4.1317494600431965e-05,
      "loss": 0.0005,
      "step": 28140
    },
    {
      "epoch": 8.685590867016353,
      "grad_norm": 1.6651782989501953,
      "learning_rate": 4.131440913298365e-05,
      "loss": 0.0087,
      "step": 28150
    },
    {
      "epoch": 8.688676334464672,
      "grad_norm": 0.028999699279665947,
      "learning_rate": 4.131132366553533e-05,
      "loss": 0.0036,
      "step": 28160
    },
    {
      "epoch": 8.691761801912989,
      "grad_norm": 0.034716080874204636,
      "learning_rate": 4.130823819808701e-05,
      "loss": 0.0038,
      "step": 28170
    },
    {
      "epoch": 8.694847269361308,
      "grad_norm": 2.111924409866333,
      "learning_rate": 4.1305152730638695e-05,
      "loss": 0.0058,
      "step": 28180
    },
    {
      "epoch": 8.697932736809626,
      "grad_norm": 0.008414174430072308,
      "learning_rate": 4.130206726319038e-05,
      "loss": 0.0045,
      "step": 28190
    },
    {
      "epoch": 8.701018204257945,
      "grad_norm": 0.001673271763138473,
      "learning_rate": 4.129898179574206e-05,
      "loss": 0.0012,
      "step": 28200
    },
    {
      "epoch": 8.704103671706264,
      "grad_norm": 0.0035739229060709476,
      "learning_rate": 4.1295896328293736e-05,
      "loss": 0.0055,
      "step": 28210
    },
    {
      "epoch": 8.707189139154583,
      "grad_norm": 0.04153711348772049,
      "learning_rate": 4.129281086084542e-05,
      "loss": 0.0029,
      "step": 28220
    },
    {
      "epoch": 8.7102746066029,
      "grad_norm": 0.42298394441604614,
      "learning_rate": 4.12897253933971e-05,
      "loss": 0.0037,
      "step": 28230
    },
    {
      "epoch": 8.713360074051218,
      "grad_norm": 0.32159319519996643,
      "learning_rate": 4.128663992594878e-05,
      "loss": 0.0022,
      "step": 28240
    },
    {
      "epoch": 8.716445541499537,
      "grad_norm": 0.07885456830263138,
      "learning_rate": 4.1283554458500466e-05,
      "loss": 0.0003,
      "step": 28250
    },
    {
      "epoch": 8.719531008947856,
      "grad_norm": 2.3632972240448,
      "learning_rate": 4.128046899105215e-05,
      "loss": 0.0128,
      "step": 28260
    },
    {
      "epoch": 8.722616476396174,
      "grad_norm": 0.00513603538274765,
      "learning_rate": 4.127738352360383e-05,
      "loss": 0.0044,
      "step": 28270
    },
    {
      "epoch": 8.725701943844493,
      "grad_norm": 0.048902418464422226,
      "learning_rate": 4.1274298056155506e-05,
      "loss": 0.0019,
      "step": 28280
    },
    {
      "epoch": 8.72878741129281,
      "grad_norm": 0.002371154259890318,
      "learning_rate": 4.1271212588707195e-05,
      "loss": 0.0116,
      "step": 28290
    },
    {
      "epoch": 8.731872878741129,
      "grad_norm": 0.01960594393312931,
      "learning_rate": 4.126812712125887e-05,
      "loss": 0.001,
      "step": 28300
    },
    {
      "epoch": 8.734958346189448,
      "grad_norm": 0.039058391004800797,
      "learning_rate": 4.1265041653810554e-05,
      "loss": 0.0086,
      "step": 28310
    },
    {
      "epoch": 8.738043813637766,
      "grad_norm": 0.16399575769901276,
      "learning_rate": 4.1261956186362236e-05,
      "loss": 0.008,
      "step": 28320
    },
    {
      "epoch": 8.741129281086085,
      "grad_norm": 0.0003174705780111253,
      "learning_rate": 4.125887071891392e-05,
      "loss": 0.0121,
      "step": 28330
    },
    {
      "epoch": 8.744214748534404,
      "grad_norm": 0.15502820909023285,
      "learning_rate": 4.12557852514656e-05,
      "loss": 0.0111,
      "step": 28340
    },
    {
      "epoch": 8.74730021598272,
      "grad_norm": 0.1541312336921692,
      "learning_rate": 4.125269978401728e-05,
      "loss": 0.0053,
      "step": 28350
    },
    {
      "epoch": 8.75038568343104,
      "grad_norm": 0.1182524561882019,
      "learning_rate": 4.1249614316568966e-05,
      "loss": 0.0022,
      "step": 28360
    },
    {
      "epoch": 8.753471150879358,
      "grad_norm": 0.02180044911801815,
      "learning_rate": 4.124652884912064e-05,
      "loss": 0.0009,
      "step": 28370
    },
    {
      "epoch": 8.756556618327677,
      "grad_norm": 0.000721339019946754,
      "learning_rate": 4.1243443381672324e-05,
      "loss": 0.0097,
      "step": 28380
    },
    {
      "epoch": 8.759642085775996,
      "grad_norm": 0.015477468259632587,
      "learning_rate": 4.124035791422401e-05,
      "loss": 0.0026,
      "step": 28390
    },
    {
      "epoch": 8.762727553224314,
      "grad_norm": 0.002118121599778533,
      "learning_rate": 4.123727244677569e-05,
      "loss": 0.0022,
      "step": 28400
    },
    {
      "epoch": 8.765813020672631,
      "grad_norm": 0.0746070072054863,
      "learning_rate": 4.123418697932737e-05,
      "loss": 0.0023,
      "step": 28410
    },
    {
      "epoch": 8.76889848812095,
      "grad_norm": 0.06565312296152115,
      "learning_rate": 4.123110151187905e-05,
      "loss": 0.0085,
      "step": 28420
    },
    {
      "epoch": 8.771983955569269,
      "grad_norm": 0.03901289775967598,
      "learning_rate": 4.1228016044430737e-05,
      "loss": 0.0017,
      "step": 28430
    },
    {
      "epoch": 8.775069423017587,
      "grad_norm": 0.052349288016557693,
      "learning_rate": 4.122493057698241e-05,
      "loss": 0.0006,
      "step": 28440
    },
    {
      "epoch": 8.778154890465906,
      "grad_norm": 0.013352125883102417,
      "learning_rate": 4.1221845109534095e-05,
      "loss": 0.0011,
      "step": 28450
    },
    {
      "epoch": 8.781240357914225,
      "grad_norm": 0.008696941658854485,
      "learning_rate": 4.121875964208578e-05,
      "loss": 0.001,
      "step": 28460
    },
    {
      "epoch": 8.784325825362542,
      "grad_norm": 0.017182495445013046,
      "learning_rate": 4.121567417463746e-05,
      "loss": 0.004,
      "step": 28470
    },
    {
      "epoch": 8.78741129281086,
      "grad_norm": 0.07323940843343735,
      "learning_rate": 4.121258870718914e-05,
      "loss": 0.0022,
      "step": 28480
    },
    {
      "epoch": 8.79049676025918,
      "grad_norm": 0.015022830106317997,
      "learning_rate": 4.120950323974082e-05,
      "loss": 0.0059,
      "step": 28490
    },
    {
      "epoch": 8.793582227707498,
      "grad_norm": 1.8531711101531982,
      "learning_rate": 4.120641777229251e-05,
      "loss": 0.0104,
      "step": 28500
    },
    {
      "epoch": 8.796667695155817,
      "grad_norm": 0.0014215597184374928,
      "learning_rate": 4.120333230484418e-05,
      "loss": 0.002,
      "step": 28510
    },
    {
      "epoch": 8.799753162604134,
      "grad_norm": 0.7805995345115662,
      "learning_rate": 4.1200246837395865e-05,
      "loss": 0.0042,
      "step": 28520
    },
    {
      "epoch": 8.802838630052452,
      "grad_norm": 0.03733139485120773,
      "learning_rate": 4.119716136994755e-05,
      "loss": 0.0017,
      "step": 28530
    },
    {
      "epoch": 8.805924097500771,
      "grad_norm": 0.00032437380286864936,
      "learning_rate": 4.119407590249923e-05,
      "loss": 0.0005,
      "step": 28540
    },
    {
      "epoch": 8.80900956494909,
      "grad_norm": 0.2396409660577774,
      "learning_rate": 4.119099043505091e-05,
      "loss": 0.004,
      "step": 28550
    },
    {
      "epoch": 8.812095032397409,
      "grad_norm": 0.7887933254241943,
      "learning_rate": 4.1187904967602595e-05,
      "loss": 0.0103,
      "step": 28560
    },
    {
      "epoch": 8.815180499845727,
      "grad_norm": 0.01599065400660038,
      "learning_rate": 4.118481950015428e-05,
      "loss": 0.0093,
      "step": 28570
    },
    {
      "epoch": 8.818265967294044,
      "grad_norm": 0.16922779381275177,
      "learning_rate": 4.1181734032705953e-05,
      "loss": 0.0088,
      "step": 28580
    },
    {
      "epoch": 8.821351434742363,
      "grad_norm": 0.00094664964126423,
      "learning_rate": 4.1178648565257636e-05,
      "loss": 0.0043,
      "step": 28590
    },
    {
      "epoch": 8.824436902190682,
      "grad_norm": 0.06882929056882858,
      "learning_rate": 4.1175563097809325e-05,
      "loss": 0.0024,
      "step": 28600
    },
    {
      "epoch": 8.827522369639,
      "grad_norm": 0.36322852969169617,
      "learning_rate": 4.1172477630361e-05,
      "loss": 0.0092,
      "step": 28610
    },
    {
      "epoch": 8.83060783708732,
      "grad_norm": 0.027702419087290764,
      "learning_rate": 4.116939216291268e-05,
      "loss": 0.0029,
      "step": 28620
    },
    {
      "epoch": 8.833693304535638,
      "grad_norm": 0.5602742433547974,
      "learning_rate": 4.1166306695464366e-05,
      "loss": 0.0022,
      "step": 28630
    },
    {
      "epoch": 8.836778771983955,
      "grad_norm": 0.017974853515625,
      "learning_rate": 4.116322122801605e-05,
      "loss": 0.016,
      "step": 28640
    },
    {
      "epoch": 8.839864239432274,
      "grad_norm": 0.001092218211852014,
      "learning_rate": 4.116013576056773e-05,
      "loss": 0.0114,
      "step": 28650
    },
    {
      "epoch": 8.842949706880592,
      "grad_norm": 0.0015492591774091125,
      "learning_rate": 4.1157050293119406e-05,
      "loss": 0.0103,
      "step": 28660
    },
    {
      "epoch": 8.846035174328911,
      "grad_norm": 0.07595244795084,
      "learning_rate": 4.1153964825671096e-05,
      "loss": 0.0034,
      "step": 28670
    },
    {
      "epoch": 8.84912064177723,
      "grad_norm": 1.7699881792068481,
      "learning_rate": 4.115087935822277e-05,
      "loss": 0.005,
      "step": 28680
    },
    {
      "epoch": 8.852206109225548,
      "grad_norm": 0.019612805917859077,
      "learning_rate": 4.1147793890774454e-05,
      "loss": 0.0046,
      "step": 28690
    },
    {
      "epoch": 8.855291576673865,
      "grad_norm": 0.010105228051543236,
      "learning_rate": 4.1144708423326136e-05,
      "loss": 0.0046,
      "step": 28700
    },
    {
      "epoch": 8.858377044122184,
      "grad_norm": 0.0008435305790044367,
      "learning_rate": 4.114162295587782e-05,
      "loss": 0.0027,
      "step": 28710
    },
    {
      "epoch": 8.861462511570503,
      "grad_norm": 0.21699807047843933,
      "learning_rate": 4.11385374884295e-05,
      "loss": 0.002,
      "step": 28720
    },
    {
      "epoch": 8.864547979018822,
      "grad_norm": 0.006931050214916468,
      "learning_rate": 4.113545202098118e-05,
      "loss": 0.0011,
      "step": 28730
    },
    {
      "epoch": 8.86763344646714,
      "grad_norm": 0.002289432566612959,
      "learning_rate": 4.1132366553532866e-05,
      "loss": 0.006,
      "step": 28740
    },
    {
      "epoch": 8.870718913915459,
      "grad_norm": 0.016808848828077316,
      "learning_rate": 4.112928108608454e-05,
      "loss": 0.0043,
      "step": 28750
    },
    {
      "epoch": 8.873804381363776,
      "grad_norm": 0.020415879786014557,
      "learning_rate": 4.1126195618636224e-05,
      "loss": 0.0007,
      "step": 28760
    },
    {
      "epoch": 8.876889848812095,
      "grad_norm": 0.003265843726694584,
      "learning_rate": 4.112311015118791e-05,
      "loss": 0.0014,
      "step": 28770
    },
    {
      "epoch": 8.879975316260413,
      "grad_norm": 0.07298583537340164,
      "learning_rate": 4.112002468373959e-05,
      "loss": 0.001,
      "step": 28780
    },
    {
      "epoch": 8.883060783708732,
      "grad_norm": 0.04747029021382332,
      "learning_rate": 4.111693921629127e-05,
      "loss": 0.0006,
      "step": 28790
    },
    {
      "epoch": 8.88614625115705,
      "grad_norm": 0.7700725793838501,
      "learning_rate": 4.111385374884295e-05,
      "loss": 0.0051,
      "step": 28800
    },
    {
      "epoch": 8.88923171860537,
      "grad_norm": 0.008944356814026833,
      "learning_rate": 4.111076828139464e-05,
      "loss": 0.0027,
      "step": 28810
    },
    {
      "epoch": 8.892317186053686,
      "grad_norm": 0.07387015223503113,
      "learning_rate": 4.110768281394631e-05,
      "loss": 0.0009,
      "step": 28820
    },
    {
      "epoch": 8.895402653502005,
      "grad_norm": 0.0020473019685596228,
      "learning_rate": 4.1104597346497995e-05,
      "loss": 0.0009,
      "step": 28830
    },
    {
      "epoch": 8.898488120950324,
      "grad_norm": 0.0808442011475563,
      "learning_rate": 4.110151187904968e-05,
      "loss": 0.0021,
      "step": 28840
    },
    {
      "epoch": 8.901573588398643,
      "grad_norm": 0.002238644752651453,
      "learning_rate": 4.109842641160136e-05,
      "loss": 0.0032,
      "step": 28850
    },
    {
      "epoch": 8.904659055846961,
      "grad_norm": 0.14005859196186066,
      "learning_rate": 4.109534094415304e-05,
      "loss": 0.0005,
      "step": 28860
    },
    {
      "epoch": 8.907744523295278,
      "grad_norm": 0.02104148268699646,
      "learning_rate": 4.1092255476704725e-05,
      "loss": 0.0096,
      "step": 28870
    },
    {
      "epoch": 8.910829990743597,
      "grad_norm": 0.0034909253008663654,
      "learning_rate": 4.108917000925641e-05,
      "loss": 0.0018,
      "step": 28880
    },
    {
      "epoch": 8.913915458191916,
      "grad_norm": 1.188217282295227,
      "learning_rate": 4.108608454180808e-05,
      "loss": 0.0033,
      "step": 28890
    },
    {
      "epoch": 8.917000925640234,
      "grad_norm": 0.0268813818693161,
      "learning_rate": 4.1082999074359766e-05,
      "loss": 0.0006,
      "step": 28900
    },
    {
      "epoch": 8.920086393088553,
      "grad_norm": 0.005238908343017101,
      "learning_rate": 4.107991360691145e-05,
      "loss": 0.0021,
      "step": 28910
    },
    {
      "epoch": 8.923171860536872,
      "grad_norm": 0.02766483463346958,
      "learning_rate": 4.107682813946313e-05,
      "loss": 0.0008,
      "step": 28920
    },
    {
      "epoch": 8.92625732798519,
      "grad_norm": 0.024788953363895416,
      "learning_rate": 4.107374267201481e-05,
      "loss": 0.0034,
      "step": 28930
    },
    {
      "epoch": 8.929342795433508,
      "grad_norm": 0.013044492341578007,
      "learning_rate": 4.1070657204566495e-05,
      "loss": 0.0059,
      "step": 28940
    },
    {
      "epoch": 8.932428262881826,
      "grad_norm": 0.0011745949741452932,
      "learning_rate": 4.106757173711818e-05,
      "loss": 0.0101,
      "step": 28950
    },
    {
      "epoch": 8.935513730330145,
      "grad_norm": 0.2506055235862732,
      "learning_rate": 4.1064486269669854e-05,
      "loss": 0.0018,
      "step": 28960
    },
    {
      "epoch": 8.938599197778464,
      "grad_norm": 0.0017826539697125554,
      "learning_rate": 4.1061400802221536e-05,
      "loss": 0.0009,
      "step": 28970
    },
    {
      "epoch": 8.941684665226783,
      "grad_norm": 0.0016700195847079158,
      "learning_rate": 4.105831533477322e-05,
      "loss": 0.0067,
      "step": 28980
    },
    {
      "epoch": 8.9447701326751,
      "grad_norm": 0.0003045175108127296,
      "learning_rate": 4.10552298673249e-05,
      "loss": 0.007,
      "step": 28990
    },
    {
      "epoch": 8.947855600123418,
      "grad_norm": 4.233180046081543,
      "learning_rate": 4.1052144399876584e-05,
      "loss": 0.006,
      "step": 29000
    },
    {
      "epoch": 8.950941067571737,
      "grad_norm": 4.416897773742676,
      "learning_rate": 4.1049058932428266e-05,
      "loss": 0.0047,
      "step": 29010
    },
    {
      "epoch": 8.954026535020056,
      "grad_norm": 0.132942333817482,
      "learning_rate": 4.104597346497995e-05,
      "loss": 0.004,
      "step": 29020
    },
    {
      "epoch": 8.957112002468374,
      "grad_norm": 0.10131264477968216,
      "learning_rate": 4.1042887997531624e-05,
      "loss": 0.0122,
      "step": 29030
    },
    {
      "epoch": 8.960197469916693,
      "grad_norm": 1.6119630336761475,
      "learning_rate": 4.103980253008331e-05,
      "loss": 0.009,
      "step": 29040
    },
    {
      "epoch": 8.96328293736501,
      "grad_norm": 0.1274966448545456,
      "learning_rate": 4.1036717062634996e-05,
      "loss": 0.0184,
      "step": 29050
    },
    {
      "epoch": 8.966368404813329,
      "grad_norm": 0.1421467512845993,
      "learning_rate": 4.103363159518667e-05,
      "loss": 0.0115,
      "step": 29060
    },
    {
      "epoch": 8.969453872261647,
      "grad_norm": 0.12170898169279099,
      "learning_rate": 4.1030546127738354e-05,
      "loss": 0.0023,
      "step": 29070
    },
    {
      "epoch": 8.972539339709966,
      "grad_norm": 0.1741667240858078,
      "learning_rate": 4.1027460660290037e-05,
      "loss": 0.0013,
      "step": 29080
    },
    {
      "epoch": 8.975624807158285,
      "grad_norm": 0.009244355373084545,
      "learning_rate": 4.102437519284172e-05,
      "loss": 0.0096,
      "step": 29090
    },
    {
      "epoch": 8.978710274606604,
      "grad_norm": 0.02832074463367462,
      "learning_rate": 4.1021289725393395e-05,
      "loss": 0.0102,
      "step": 29100
    },
    {
      "epoch": 8.98179574205492,
      "grad_norm": 0.10980795323848724,
      "learning_rate": 4.1018204257945084e-05,
      "loss": 0.0078,
      "step": 29110
    },
    {
      "epoch": 8.98488120950324,
      "grad_norm": 0.06435967981815338,
      "learning_rate": 4.1015118790496767e-05,
      "loss": 0.0091,
      "step": 29120
    },
    {
      "epoch": 8.987966676951558,
      "grad_norm": 0.01380506157875061,
      "learning_rate": 4.101203332304844e-05,
      "loss": 0.0087,
      "step": 29130
    },
    {
      "epoch": 8.991052144399877,
      "grad_norm": 0.09717957675457001,
      "learning_rate": 4.1008947855600125e-05,
      "loss": 0.0038,
      "step": 29140
    },
    {
      "epoch": 8.994137611848195,
      "grad_norm": 0.9523482918739319,
      "learning_rate": 4.100586238815181e-05,
      "loss": 0.0065,
      "step": 29150
    },
    {
      "epoch": 8.997223079296514,
      "grad_norm": 2.206308126449585,
      "learning_rate": 4.100277692070349e-05,
      "loss": 0.0042,
      "step": 29160
    },
    {
      "epoch": 9.0,
      "eval_accuracy_branch1": 0.9978492134679745,
      "eval_accuracy_branch2": 0.4032194284501799,
      "eval_f1_branch1": 0.9974521667441452,
      "eval_f1_branch2": 0.3922476733521617,
      "eval_loss": 0.0013154560001567006,
      "eval_precision_branch1": 0.9975583426880479,
      "eval_precision_branch2": 0.5055874225557889,
      "eval_recall_branch1": 0.9973690345875731,
      "eval_recall_branch2": 0.5040074071930789,
      "eval_runtime": 239.5278,
      "eval_samples_per_second": 432.864,
      "eval_steps_per_second": 54.111,
      "step": 29169
    },
    {
      "epoch": 9.000308546744831,
      "grad_norm": 0.09063535928726196,
      "learning_rate": 4.0999691453255165e-05,
      "loss": 0.0075,
      "step": 29170
    },
    {
      "epoch": 9.00339401419315,
      "grad_norm": 1.597892165184021,
      "learning_rate": 4.0996605985806855e-05,
      "loss": 0.0032,
      "step": 29180
    },
    {
      "epoch": 9.006479481641469,
      "grad_norm": 0.20917673408985138,
      "learning_rate": 4.099352051835854e-05,
      "loss": 0.0065,
      "step": 29190
    },
    {
      "epoch": 9.009564949089787,
      "grad_norm": 0.008354553952813148,
      "learning_rate": 4.099043505091021e-05,
      "loss": 0.003,
      "step": 29200
    },
    {
      "epoch": 9.012650416538106,
      "grad_norm": 1.7667856216430664,
      "learning_rate": 4.0987349583461895e-05,
      "loss": 0.0043,
      "step": 29210
    },
    {
      "epoch": 9.015735883986425,
      "grad_norm": 0.0002671091351658106,
      "learning_rate": 4.098426411601358e-05,
      "loss": 0.0017,
      "step": 29220
    },
    {
      "epoch": 9.018821351434742,
      "grad_norm": 0.9689339399337769,
      "learning_rate": 4.098117864856526e-05,
      "loss": 0.0072,
      "step": 29230
    },
    {
      "epoch": 9.02190681888306,
      "grad_norm": 0.15899556875228882,
      "learning_rate": 4.0978093181116936e-05,
      "loss": 0.0128,
      "step": 29240
    },
    {
      "epoch": 9.02499228633138,
      "grad_norm": 0.08592674881219864,
      "learning_rate": 4.0975007713668625e-05,
      "loss": 0.0027,
      "step": 29250
    },
    {
      "epoch": 9.028077753779698,
      "grad_norm": 0.003804352367296815,
      "learning_rate": 4.097192224622031e-05,
      "loss": 0.0054,
      "step": 29260
    },
    {
      "epoch": 9.031163221228017,
      "grad_norm": 0.6148256063461304,
      "learning_rate": 4.096883677877198e-05,
      "loss": 0.0008,
      "step": 29270
    },
    {
      "epoch": 9.034248688676335,
      "grad_norm": 0.005289863795042038,
      "learning_rate": 4.0965751311323666e-05,
      "loss": 0.006,
      "step": 29280
    },
    {
      "epoch": 9.037334156124652,
      "grad_norm": 2.7923097610473633,
      "learning_rate": 4.096266584387535e-05,
      "loss": 0.0085,
      "step": 29290
    },
    {
      "epoch": 9.040419623572971,
      "grad_norm": 0.018725639209151268,
      "learning_rate": 4.095958037642703e-05,
      "loss": 0.0003,
      "step": 29300
    },
    {
      "epoch": 9.04350509102129,
      "grad_norm": 0.0315677784383297,
      "learning_rate": 4.0956494908978706e-05,
      "loss": 0.0048,
      "step": 29310
    },
    {
      "epoch": 9.046590558469608,
      "grad_norm": 0.04529169574379921,
      "learning_rate": 4.0953409441530396e-05,
      "loss": 0.012,
      "step": 29320
    },
    {
      "epoch": 9.049676025917927,
      "grad_norm": 0.12845201790332794,
      "learning_rate": 4.095032397408208e-05,
      "loss": 0.0042,
      "step": 29330
    },
    {
      "epoch": 9.052761493366244,
      "grad_norm": 0.04317506402730942,
      "learning_rate": 4.0947238506633754e-05,
      "loss": 0.0085,
      "step": 29340
    },
    {
      "epoch": 9.055846960814563,
      "grad_norm": 0.011584791354835033,
      "learning_rate": 4.094415303918544e-05,
      "loss": 0.006,
      "step": 29350
    },
    {
      "epoch": 9.058932428262882,
      "grad_norm": 0.00012358615640550852,
      "learning_rate": 4.094106757173712e-05,
      "loss": 0.0056,
      "step": 29360
    },
    {
      "epoch": 9.0620178957112,
      "grad_norm": 0.0003116264706477523,
      "learning_rate": 4.09379821042888e-05,
      "loss": 0.0018,
      "step": 29370
    },
    {
      "epoch": 9.065103363159519,
      "grad_norm": 0.005755819380283356,
      "learning_rate": 4.0934896636840484e-05,
      "loss": 0.0125,
      "step": 29380
    },
    {
      "epoch": 9.068188830607838,
      "grad_norm": 0.01988093927502632,
      "learning_rate": 4.0931811169392166e-05,
      "loss": 0.0011,
      "step": 29390
    },
    {
      "epoch": 9.071274298056155,
      "grad_norm": 0.0008599346620030701,
      "learning_rate": 4.092872570194385e-05,
      "loss": 0.0077,
      "step": 29400
    },
    {
      "epoch": 9.074359765504473,
      "grad_norm": 0.01373511366546154,
      "learning_rate": 4.0925640234495524e-05,
      "loss": 0.0007,
      "step": 29410
    },
    {
      "epoch": 9.077445232952792,
      "grad_norm": 1.0306905508041382,
      "learning_rate": 4.0922554767047214e-05,
      "loss": 0.0035,
      "step": 29420
    },
    {
      "epoch": 9.08053070040111,
      "grad_norm": 0.0011430969461798668,
      "learning_rate": 4.091946929959889e-05,
      "loss": 0.0003,
      "step": 29430
    },
    {
      "epoch": 9.08361616784943,
      "grad_norm": 0.0008316628518514335,
      "learning_rate": 4.091638383215057e-05,
      "loss": 0.0006,
      "step": 29440
    },
    {
      "epoch": 9.086701635297748,
      "grad_norm": 0.1230795681476593,
      "learning_rate": 4.0913298364702254e-05,
      "loss": 0.0014,
      "step": 29450
    },
    {
      "epoch": 9.089787102746065,
      "grad_norm": 0.03308340534567833,
      "learning_rate": 4.091021289725394e-05,
      "loss": 0.001,
      "step": 29460
    },
    {
      "epoch": 9.092872570194384,
      "grad_norm": 0.0016963914968073368,
      "learning_rate": 4.090712742980562e-05,
      "loss": 0.0009,
      "step": 29470
    },
    {
      "epoch": 9.095958037642703,
      "grad_norm": 0.013828685507178307,
      "learning_rate": 4.0904041962357295e-05,
      "loss": 0.0023,
      "step": 29480
    },
    {
      "epoch": 9.099043505091021,
      "grad_norm": 0.0011441693641245365,
      "learning_rate": 4.0900956494908984e-05,
      "loss": 0.002,
      "step": 29490
    },
    {
      "epoch": 9.10212897253934,
      "grad_norm": 0.025268953293561935,
      "learning_rate": 4.089787102746066e-05,
      "loss": 0.0042,
      "step": 29500
    },
    {
      "epoch": 9.105214439987659,
      "grad_norm": 0.0048450869508087635,
      "learning_rate": 4.089478556001234e-05,
      "loss": 0.0004,
      "step": 29510
    },
    {
      "epoch": 9.108299907435976,
      "grad_norm": 0.014028925448656082,
      "learning_rate": 4.0891700092564025e-05,
      "loss": 0.0034,
      "step": 29520
    },
    {
      "epoch": 9.111385374884295,
      "grad_norm": 0.014408325776457787,
      "learning_rate": 4.088861462511571e-05,
      "loss": 0.0004,
      "step": 29530
    },
    {
      "epoch": 9.114470842332613,
      "grad_norm": 0.09618554264307022,
      "learning_rate": 4.088552915766739e-05,
      "loss": 0.0011,
      "step": 29540
    },
    {
      "epoch": 9.117556309780932,
      "grad_norm": 0.10701128840446472,
      "learning_rate": 4.0882443690219066e-05,
      "loss": 0.0054,
      "step": 29550
    },
    {
      "epoch": 9.12064177722925,
      "grad_norm": 0.021611418575048447,
      "learning_rate": 4.0879358222770755e-05,
      "loss": 0.0015,
      "step": 29560
    },
    {
      "epoch": 9.12372724467757,
      "grad_norm": 3.3607699871063232,
      "learning_rate": 4.087627275532243e-05,
      "loss": 0.0056,
      "step": 29570
    },
    {
      "epoch": 9.126812712125886,
      "grad_norm": 0.03135346993803978,
      "learning_rate": 4.087318728787411e-05,
      "loss": 0.0039,
      "step": 29580
    },
    {
      "epoch": 9.129898179574205,
      "grad_norm": 1.1440885066986084,
      "learning_rate": 4.08701018204258e-05,
      "loss": 0.0019,
      "step": 29590
    },
    {
      "epoch": 9.132983647022524,
      "grad_norm": 0.0872112587094307,
      "learning_rate": 4.086701635297748e-05,
      "loss": 0.0023,
      "step": 29600
    },
    {
      "epoch": 9.136069114470843,
      "grad_norm": 0.21008062362670898,
      "learning_rate": 4.086393088552916e-05,
      "loss": 0.0076,
      "step": 29610
    },
    {
      "epoch": 9.139154581919161,
      "grad_norm": 0.014794827438890934,
      "learning_rate": 4.086084541808084e-05,
      "loss": 0.001,
      "step": 29620
    },
    {
      "epoch": 9.14224004936748,
      "grad_norm": 0.00019930962298531085,
      "learning_rate": 4.0857759950632525e-05,
      "loss": 0.0047,
      "step": 29630
    },
    {
      "epoch": 9.145325516815797,
      "grad_norm": 6.057629070710391e-05,
      "learning_rate": 4.08546744831842e-05,
      "loss": 0.0075,
      "step": 29640
    },
    {
      "epoch": 9.148410984264116,
      "grad_norm": 0.026296470314264297,
      "learning_rate": 4.0851589015735884e-05,
      "loss": 0.0108,
      "step": 29650
    },
    {
      "epoch": 9.151496451712434,
      "grad_norm": 0.008188735693693161,
      "learning_rate": 4.084850354828757e-05,
      "loss": 0.0011,
      "step": 29660
    },
    {
      "epoch": 9.154581919160753,
      "grad_norm": 0.07709226757287979,
      "learning_rate": 4.084541808083925e-05,
      "loss": 0.0012,
      "step": 29670
    },
    {
      "epoch": 9.157667386609072,
      "grad_norm": 0.1518368422985077,
      "learning_rate": 4.084233261339093e-05,
      "loss": 0.004,
      "step": 29680
    },
    {
      "epoch": 9.160752854057389,
      "grad_norm": 0.03396311402320862,
      "learning_rate": 4.0839247145942613e-05,
      "loss": 0.0022,
      "step": 29690
    },
    {
      "epoch": 9.163838321505708,
      "grad_norm": 0.49283233284950256,
      "learning_rate": 4.0836161678494296e-05,
      "loss": 0.0057,
      "step": 29700
    },
    {
      "epoch": 9.166923788954026,
      "grad_norm": 1.4062029123306274,
      "learning_rate": 4.083307621104597e-05,
      "loss": 0.0146,
      "step": 29710
    },
    {
      "epoch": 9.170009256402345,
      "grad_norm": 0.03995032608509064,
      "learning_rate": 4.0829990743597654e-05,
      "loss": 0.0044,
      "step": 29720
    },
    {
      "epoch": 9.173094723850664,
      "grad_norm": 0.04832123965024948,
      "learning_rate": 4.082690527614934e-05,
      "loss": 0.0025,
      "step": 29730
    },
    {
      "epoch": 9.176180191298982,
      "grad_norm": 0.3939226567745209,
      "learning_rate": 4.082381980870102e-05,
      "loss": 0.0032,
      "step": 29740
    },
    {
      "epoch": 9.1792656587473,
      "grad_norm": 0.9230534434318542,
      "learning_rate": 4.08207343412527e-05,
      "loss": 0.012,
      "step": 29750
    },
    {
      "epoch": 9.182351126195618,
      "grad_norm": 0.07499200850725174,
      "learning_rate": 4.0817648873804384e-05,
      "loss": 0.0013,
      "step": 29760
    },
    {
      "epoch": 9.185436593643937,
      "grad_norm": 0.002896118676289916,
      "learning_rate": 4.0814563406356067e-05,
      "loss": 0.0043,
      "step": 29770
    },
    {
      "epoch": 9.188522061092256,
      "grad_norm": 0.06225213035941124,
      "learning_rate": 4.081147793890774e-05,
      "loss": 0.0002,
      "step": 29780
    },
    {
      "epoch": 9.191607528540574,
      "grad_norm": 3.0243523120880127,
      "learning_rate": 4.0808392471459425e-05,
      "loss": 0.0094,
      "step": 29790
    },
    {
      "epoch": 9.194692995988893,
      "grad_norm": 0.012602229602634907,
      "learning_rate": 4.0805307004011114e-05,
      "loss": 0.0021,
      "step": 29800
    },
    {
      "epoch": 9.19777846343721,
      "grad_norm": 1.6818876266479492,
      "learning_rate": 4.080222153656279e-05,
      "loss": 0.0015,
      "step": 29810
    },
    {
      "epoch": 9.200863930885529,
      "grad_norm": 0.001849080086685717,
      "learning_rate": 4.079913606911447e-05,
      "loss": 0.0075,
      "step": 29820
    },
    {
      "epoch": 9.203949398333847,
      "grad_norm": 2.0174975395202637,
      "learning_rate": 4.0796050601666155e-05,
      "loss": 0.0016,
      "step": 29830
    },
    {
      "epoch": 9.207034865782166,
      "grad_norm": 1.4561290740966797,
      "learning_rate": 4.079296513421784e-05,
      "loss": 0.0081,
      "step": 29840
    },
    {
      "epoch": 9.210120333230485,
      "grad_norm": 0.022636806592345238,
      "learning_rate": 4.078987966676951e-05,
      "loss": 0.0004,
      "step": 29850
    },
    {
      "epoch": 9.213205800678804,
      "grad_norm": 2.68513560295105,
      "learning_rate": 4.07867941993212e-05,
      "loss": 0.0096,
      "step": 29860
    },
    {
      "epoch": 9.21629126812712,
      "grad_norm": 0.0011316054733470082,
      "learning_rate": 4.0783708731872885e-05,
      "loss": 0.0026,
      "step": 29870
    },
    {
      "epoch": 9.21937673557544,
      "grad_norm": 0.47125858068466187,
      "learning_rate": 4.078062326442456e-05,
      "loss": 0.0015,
      "step": 29880
    },
    {
      "epoch": 9.222462203023758,
      "grad_norm": 0.05915435031056404,
      "learning_rate": 4.077753779697624e-05,
      "loss": 0.0031,
      "step": 29890
    },
    {
      "epoch": 9.225547670472077,
      "grad_norm": 0.3504895567893982,
      "learning_rate": 4.0774452329527925e-05,
      "loss": 0.0006,
      "step": 29900
    },
    {
      "epoch": 9.228633137920395,
      "grad_norm": 0.0738857090473175,
      "learning_rate": 4.077136686207961e-05,
      "loss": 0.0026,
      "step": 29910
    },
    {
      "epoch": 9.231718605368714,
      "grad_norm": 0.15109123289585114,
      "learning_rate": 4.076828139463128e-05,
      "loss": 0.0016,
      "step": 29920
    },
    {
      "epoch": 9.234804072817031,
      "grad_norm": 0.14086849987506866,
      "learning_rate": 4.076519592718297e-05,
      "loss": 0.0028,
      "step": 29930
    },
    {
      "epoch": 9.23788954026535,
      "grad_norm": 0.00010871196718653664,
      "learning_rate": 4.0762110459734655e-05,
      "loss": 0.0016,
      "step": 29940
    },
    {
      "epoch": 9.240975007713669,
      "grad_norm": 0.2971441447734833,
      "learning_rate": 4.075902499228633e-05,
      "loss": 0.0003,
      "step": 29950
    },
    {
      "epoch": 9.244060475161987,
      "grad_norm": 0.07504136860370636,
      "learning_rate": 4.075593952483801e-05,
      "loss": 0.0021,
      "step": 29960
    },
    {
      "epoch": 9.247145942610306,
      "grad_norm": 0.0006452423986047506,
      "learning_rate": 4.0752854057389696e-05,
      "loss": 0.0004,
      "step": 29970
    },
    {
      "epoch": 9.250231410058625,
      "grad_norm": 0.03099299781024456,
      "learning_rate": 4.074976858994138e-05,
      "loss": 0.0008,
      "step": 29980
    },
    {
      "epoch": 9.253316877506942,
      "grad_norm": 0.002484541153535247,
      "learning_rate": 4.074668312249306e-05,
      "loss": 0.0003,
      "step": 29990
    },
    {
      "epoch": 9.25640234495526,
      "grad_norm": 0.0013980533694848418,
      "learning_rate": 4.074359765504474e-05,
      "loss": 0.0007,
      "step": 30000
    },
    {
      "epoch": 9.259487812403579,
      "grad_norm": 0.3818858563899994,
      "learning_rate": 4.0740512187596426e-05,
      "loss": 0.0043,
      "step": 30010
    },
    {
      "epoch": 9.262573279851898,
      "grad_norm": 0.005106846336275339,
      "learning_rate": 4.07374267201481e-05,
      "loss": 0.0053,
      "step": 30020
    },
    {
      "epoch": 9.265658747300217,
      "grad_norm": 0.0023746422957628965,
      "learning_rate": 4.0734341252699784e-05,
      "loss": 0.0038,
      "step": 30030
    },
    {
      "epoch": 9.268744214748533,
      "grad_norm": 2.1007490158081055,
      "learning_rate": 4.0731255785251466e-05,
      "loss": 0.0058,
      "step": 30040
    },
    {
      "epoch": 9.271829682196852,
      "grad_norm": 3.930586099624634,
      "learning_rate": 4.072817031780315e-05,
      "loss": 0.0122,
      "step": 30050
    },
    {
      "epoch": 9.274915149645171,
      "grad_norm": 0.3510209023952484,
      "learning_rate": 4.072508485035483e-05,
      "loss": 0.0073,
      "step": 30060
    },
    {
      "epoch": 9.27800061709349,
      "grad_norm": 0.5151615738868713,
      "learning_rate": 4.0721999382906514e-05,
      "loss": 0.0104,
      "step": 30070
    },
    {
      "epoch": 9.281086084541808,
      "grad_norm": 0.6562323570251465,
      "learning_rate": 4.0718913915458196e-05,
      "loss": 0.004,
      "step": 30080
    },
    {
      "epoch": 9.284171551990127,
      "grad_norm": 0.29261043667793274,
      "learning_rate": 4.071582844800987e-05,
      "loss": 0.0004,
      "step": 30090
    },
    {
      "epoch": 9.287257019438446,
      "grad_norm": 5.180535316467285,
      "learning_rate": 4.071274298056156e-05,
      "loss": 0.0038,
      "step": 30100
    },
    {
      "epoch": 9.290342486886763,
      "grad_norm": 0.20745514333248138,
      "learning_rate": 4.070965751311324e-05,
      "loss": 0.0045,
      "step": 30110
    },
    {
      "epoch": 9.293427954335082,
      "grad_norm": 0.0006754375644959509,
      "learning_rate": 4.070657204566492e-05,
      "loss": 0.0063,
      "step": 30120
    },
    {
      "epoch": 9.2965134217834,
      "grad_norm": 0.020910218358039856,
      "learning_rate": 4.07034865782166e-05,
      "loss": 0.0059,
      "step": 30130
    },
    {
      "epoch": 9.299598889231719,
      "grad_norm": 0.025993626564741135,
      "learning_rate": 4.0700401110768284e-05,
      "loss": 0.001,
      "step": 30140
    },
    {
      "epoch": 9.302684356680038,
      "grad_norm": 0.002055087359622121,
      "learning_rate": 4.069731564331997e-05,
      "loss": 0.0068,
      "step": 30150
    },
    {
      "epoch": 9.305769824128355,
      "grad_norm": 0.5302808284759521,
      "learning_rate": 4.069423017587164e-05,
      "loss": 0.0098,
      "step": 30160
    },
    {
      "epoch": 9.308855291576673,
      "grad_norm": 0.0070792874321341515,
      "learning_rate": 4.069114470842333e-05,
      "loss": 0.0019,
      "step": 30170
    },
    {
      "epoch": 9.311940759024992,
      "grad_norm": 0.00020572023640852422,
      "learning_rate": 4.068805924097501e-05,
      "loss": 0.005,
      "step": 30180
    },
    {
      "epoch": 9.31502622647331,
      "grad_norm": 0.8402931094169617,
      "learning_rate": 4.068497377352669e-05,
      "loss": 0.0008,
      "step": 30190
    },
    {
      "epoch": 9.31811169392163,
      "grad_norm": 0.006653483957052231,
      "learning_rate": 4.068188830607837e-05,
      "loss": 0.0074,
      "step": 30200
    },
    {
      "epoch": 9.321197161369948,
      "grad_norm": 0.16385118663311005,
      "learning_rate": 4.0678802838630055e-05,
      "loss": 0.0057,
      "step": 30210
    },
    {
      "epoch": 9.324282628818265,
      "grad_norm": 0.002759641967713833,
      "learning_rate": 4.067571737118174e-05,
      "loss": 0.0006,
      "step": 30220
    },
    {
      "epoch": 9.327368096266584,
      "grad_norm": 4.223837375640869,
      "learning_rate": 4.067263190373341e-05,
      "loss": 0.0095,
      "step": 30230
    },
    {
      "epoch": 9.330453563714903,
      "grad_norm": 2.086350202560425,
      "learning_rate": 4.06695464362851e-05,
      "loss": 0.0081,
      "step": 30240
    },
    {
      "epoch": 9.333539031163221,
      "grad_norm": 0.0019385552732273936,
      "learning_rate": 4.066646096883678e-05,
      "loss": 0.0037,
      "step": 30250
    },
    {
      "epoch": 9.33662449861154,
      "grad_norm": 0.794830858707428,
      "learning_rate": 4.066337550138846e-05,
      "loss": 0.0016,
      "step": 30260
    },
    {
      "epoch": 9.339709966059859,
      "grad_norm": 0.0024187290109694004,
      "learning_rate": 4.066029003394014e-05,
      "loss": 0.0104,
      "step": 30270
    },
    {
      "epoch": 9.342795433508176,
      "grad_norm": 1.1544007062911987,
      "learning_rate": 4.0657204566491825e-05,
      "loss": 0.0096,
      "step": 30280
    },
    {
      "epoch": 9.345880900956494,
      "grad_norm": 0.2023923248052597,
      "learning_rate": 4.065411909904351e-05,
      "loss": 0.0029,
      "step": 30290
    },
    {
      "epoch": 9.348966368404813,
      "grad_norm": 0.48745450377464294,
      "learning_rate": 4.0651033631595184e-05,
      "loss": 0.0073,
      "step": 30300
    },
    {
      "epoch": 9.352051835853132,
      "grad_norm": 0.04189126566052437,
      "learning_rate": 4.064794816414687e-05,
      "loss": 0.0023,
      "step": 30310
    },
    {
      "epoch": 9.35513730330145,
      "grad_norm": 0.4768182635307312,
      "learning_rate": 4.064486269669855e-05,
      "loss": 0.0009,
      "step": 30320
    },
    {
      "epoch": 9.35822277074977,
      "grad_norm": 1.4610486030578613,
      "learning_rate": 4.064177722925023e-05,
      "loss": 0.0055,
      "step": 30330
    },
    {
      "epoch": 9.361308238198086,
      "grad_norm": 0.011175640858709812,
      "learning_rate": 4.063869176180192e-05,
      "loss": 0.0007,
      "step": 30340
    },
    {
      "epoch": 9.364393705646405,
      "grad_norm": 0.006048725452274084,
      "learning_rate": 4.0635606294353596e-05,
      "loss": 0.0036,
      "step": 30350
    },
    {
      "epoch": 9.367479173094724,
      "grad_norm": 3.494849681854248,
      "learning_rate": 4.063252082690528e-05,
      "loss": 0.0103,
      "step": 30360
    },
    {
      "epoch": 9.370564640543043,
      "grad_norm": 0.002845283132046461,
      "learning_rate": 4.062943535945696e-05,
      "loss": 0.0058,
      "step": 30370
    },
    {
      "epoch": 9.373650107991361,
      "grad_norm": 0.0023395398166030645,
      "learning_rate": 4.0626349892008643e-05,
      "loss": 0.0159,
      "step": 30380
    },
    {
      "epoch": 9.37673557543968,
      "grad_norm": 0.005780430976301432,
      "learning_rate": 4.0623264424560326e-05,
      "loss": 0.0048,
      "step": 30390
    },
    {
      "epoch": 9.379821042887997,
      "grad_norm": 0.28165048360824585,
      "learning_rate": 4.0620178957112e-05,
      "loss": 0.008,
      "step": 30400
    },
    {
      "epoch": 9.382906510336316,
      "grad_norm": 0.030515970662236214,
      "learning_rate": 4.061709348966369e-05,
      "loss": 0.0124,
      "step": 30410
    },
    {
      "epoch": 9.385991977784634,
      "grad_norm": 0.00012395133671816438,
      "learning_rate": 4.0614008022215367e-05,
      "loss": 0.005,
      "step": 30420
    },
    {
      "epoch": 9.389077445232953,
      "grad_norm": 0.11005411297082901,
      "learning_rate": 4.061092255476705e-05,
      "loss": 0.0063,
      "step": 30430
    },
    {
      "epoch": 9.392162912681272,
      "grad_norm": 0.4651777744293213,
      "learning_rate": 4.060783708731873e-05,
      "loss": 0.0018,
      "step": 30440
    },
    {
      "epoch": 9.39524838012959,
      "grad_norm": 0.005046895705163479,
      "learning_rate": 4.0604751619870414e-05,
      "loss": 0.001,
      "step": 30450
    },
    {
      "epoch": 9.398333847577907,
      "grad_norm": 0.015279769897460938,
      "learning_rate": 4.0601666152422096e-05,
      "loss": 0.0007,
      "step": 30460
    },
    {
      "epoch": 9.401419315026226,
      "grad_norm": 0.0021751795429736376,
      "learning_rate": 4.059858068497377e-05,
      "loss": 0.0038,
      "step": 30470
    },
    {
      "epoch": 9.404504782474545,
      "grad_norm": 0.29956480860710144,
      "learning_rate": 4.059549521752546e-05,
      "loss": 0.0041,
      "step": 30480
    },
    {
      "epoch": 9.407590249922864,
      "grad_norm": 0.19813254475593567,
      "learning_rate": 4.059240975007714e-05,
      "loss": 0.0005,
      "step": 30490
    },
    {
      "epoch": 9.410675717371182,
      "grad_norm": 4.598155498504639,
      "learning_rate": 4.058932428262882e-05,
      "loss": 0.0054,
      "step": 30500
    },
    {
      "epoch": 9.4137611848195,
      "grad_norm": 3.328108549118042,
      "learning_rate": 4.05862388151805e-05,
      "loss": 0.0052,
      "step": 30510
    },
    {
      "epoch": 9.416846652267818,
      "grad_norm": 0.010722997598350048,
      "learning_rate": 4.0583153347732185e-05,
      "loss": 0.002,
      "step": 30520
    },
    {
      "epoch": 9.419932119716137,
      "grad_norm": 0.00028037710580974817,
      "learning_rate": 4.058006788028387e-05,
      "loss": 0.0106,
      "step": 30530
    },
    {
      "epoch": 9.423017587164455,
      "grad_norm": 0.00476813642308116,
      "learning_rate": 4.057698241283554e-05,
      "loss": 0.0105,
      "step": 30540
    },
    {
      "epoch": 9.426103054612774,
      "grad_norm": 1.1916170120239258,
      "learning_rate": 4.057389694538723e-05,
      "loss": 0.0068,
      "step": 30550
    },
    {
      "epoch": 9.429188522061093,
      "grad_norm": 0.08655881881713867,
      "learning_rate": 4.057081147793891e-05,
      "loss": 0.0092,
      "step": 30560
    },
    {
      "epoch": 9.43227398950941,
      "grad_norm": 0.0064820218831300735,
      "learning_rate": 4.056772601049059e-05,
      "loss": 0.0022,
      "step": 30570
    },
    {
      "epoch": 9.435359456957729,
      "grad_norm": 0.011187600903213024,
      "learning_rate": 4.056464054304227e-05,
      "loss": 0.0007,
      "step": 30580
    },
    {
      "epoch": 9.438444924406047,
      "grad_norm": 0.039239946752786636,
      "learning_rate": 4.0561555075593955e-05,
      "loss": 0.0004,
      "step": 30590
    },
    {
      "epoch": 9.441530391854366,
      "grad_norm": 1.3158771991729736,
      "learning_rate": 4.055846960814564e-05,
      "loss": 0.0024,
      "step": 30600
    },
    {
      "epoch": 9.444615859302685,
      "grad_norm": 0.05540168285369873,
      "learning_rate": 4.055538414069732e-05,
      "loss": 0.0076,
      "step": 30610
    },
    {
      "epoch": 9.447701326751003,
      "grad_norm": 0.2174377292394638,
      "learning_rate": 4.0552298673249e-05,
      "loss": 0.0041,
      "step": 30620
    },
    {
      "epoch": 9.45078679419932,
      "grad_norm": 0.023387430235743523,
      "learning_rate": 4.054921320580068e-05,
      "loss": 0.0054,
      "step": 30630
    },
    {
      "epoch": 9.45387226164764,
      "grad_norm": 0.6167578101158142,
      "learning_rate": 4.054612773835236e-05,
      "loss": 0.0015,
      "step": 30640
    },
    {
      "epoch": 9.456957729095958,
      "grad_norm": 0.04199099540710449,
      "learning_rate": 4.054304227090404e-05,
      "loss": 0.0047,
      "step": 30650
    },
    {
      "epoch": 9.460043196544277,
      "grad_norm": 0.8862906694412231,
      "learning_rate": 4.0539956803455726e-05,
      "loss": 0.003,
      "step": 30660
    },
    {
      "epoch": 9.463128663992595,
      "grad_norm": 0.054299794137477875,
      "learning_rate": 4.053687133600741e-05,
      "loss": 0.0005,
      "step": 30670
    },
    {
      "epoch": 9.466214131440914,
      "grad_norm": 0.3006037175655365,
      "learning_rate": 4.053378586855909e-05,
      "loss": 0.009,
      "step": 30680
    },
    {
      "epoch": 9.469299598889231,
      "grad_norm": 0.006248150020837784,
      "learning_rate": 4.053070040111077e-05,
      "loss": 0.002,
      "step": 30690
    },
    {
      "epoch": 9.47238506633755,
      "grad_norm": 0.4270210862159729,
      "learning_rate": 4.052761493366245e-05,
      "loss": 0.0026,
      "step": 30700
    },
    {
      "epoch": 9.475470533785868,
      "grad_norm": 2.948245048522949,
      "learning_rate": 4.052452946621413e-05,
      "loss": 0.0083,
      "step": 30710
    },
    {
      "epoch": 9.478556001234187,
      "grad_norm": 1.8150591850280762,
      "learning_rate": 4.0521443998765814e-05,
      "loss": 0.0028,
      "step": 30720
    },
    {
      "epoch": 9.481641468682506,
      "grad_norm": 0.0009440039866603911,
      "learning_rate": 4.0518358531317496e-05,
      "loss": 0.0004,
      "step": 30730
    },
    {
      "epoch": 9.484726936130825,
      "grad_norm": 0.06285995990037918,
      "learning_rate": 4.051527306386918e-05,
      "loss": 0.0068,
      "step": 30740
    },
    {
      "epoch": 9.487812403579142,
      "grad_norm": 0.6095467805862427,
      "learning_rate": 4.051218759642086e-05,
      "loss": 0.0015,
      "step": 30750
    },
    {
      "epoch": 9.49089787102746,
      "grad_norm": 0.03483651205897331,
      "learning_rate": 4.0509102128972544e-05,
      "loss": 0.0009,
      "step": 30760
    },
    {
      "epoch": 9.493983338475779,
      "grad_norm": 0.031478941440582275,
      "learning_rate": 4.050601666152422e-05,
      "loss": 0.0036,
      "step": 30770
    },
    {
      "epoch": 9.497068805924098,
      "grad_norm": 2.6190879344940186,
      "learning_rate": 4.05029311940759e-05,
      "loss": 0.0045,
      "step": 30780
    },
    {
      "epoch": 9.500154273372416,
      "grad_norm": 0.0164034441113472,
      "learning_rate": 4.0499845726627584e-05,
      "loss": 0.004,
      "step": 30790
    },
    {
      "epoch": 9.503239740820735,
      "grad_norm": 0.17552605271339417,
      "learning_rate": 4.049676025917927e-05,
      "loss": 0.0026,
      "step": 30800
    },
    {
      "epoch": 9.506325208269052,
      "grad_norm": 0.027469076216220856,
      "learning_rate": 4.049367479173095e-05,
      "loss": 0.0017,
      "step": 30810
    },
    {
      "epoch": 9.50941067571737,
      "grad_norm": 0.00558804627507925,
      "learning_rate": 4.049058932428263e-05,
      "loss": 0.0125,
      "step": 30820
    },
    {
      "epoch": 9.51249614316569,
      "grad_norm": 1.357664942741394,
      "learning_rate": 4.0487503856834314e-05,
      "loss": 0.0045,
      "step": 30830
    },
    {
      "epoch": 9.515581610614008,
      "grad_norm": 0.0004772772663272917,
      "learning_rate": 4.048441838938599e-05,
      "loss": 0.004,
      "step": 30840
    },
    {
      "epoch": 9.518667078062327,
      "grad_norm": 0.14785942435264587,
      "learning_rate": 4.048133292193768e-05,
      "loss": 0.0061,
      "step": 30850
    },
    {
      "epoch": 9.521752545510644,
      "grad_norm": 0.018753627315163612,
      "learning_rate": 4.047824745448936e-05,
      "loss": 0.0017,
      "step": 30860
    },
    {
      "epoch": 9.524838012958963,
      "grad_norm": 0.02373928390443325,
      "learning_rate": 4.047516198704104e-05,
      "loss": 0.001,
      "step": 30870
    },
    {
      "epoch": 9.527923480407281,
      "grad_norm": 0.05370977148413658,
      "learning_rate": 4.047207651959272e-05,
      "loss": 0.0023,
      "step": 30880
    },
    {
      "epoch": 9.5310089478556,
      "grad_norm": 0.4055424630641937,
      "learning_rate": 4.04689910521444e-05,
      "loss": 0.0027,
      "step": 30890
    },
    {
      "epoch": 9.534094415303919,
      "grad_norm": 0.0014303139178082347,
      "learning_rate": 4.0465905584696085e-05,
      "loss": 0.0035,
      "step": 30900
    },
    {
      "epoch": 9.537179882752238,
      "grad_norm": 1.297621250152588,
      "learning_rate": 4.046282011724776e-05,
      "loss": 0.0014,
      "step": 30910
    },
    {
      "epoch": 9.540265350200556,
      "grad_norm": 0.14419250190258026,
      "learning_rate": 4.045973464979945e-05,
      "loss": 0.0012,
      "step": 30920
    },
    {
      "epoch": 9.543350817648873,
      "grad_norm": 0.13156405091285706,
      "learning_rate": 4.045664918235113e-05,
      "loss": 0.0012,
      "step": 30930
    },
    {
      "epoch": 9.546436285097192,
      "grad_norm": 0.004923058673739433,
      "learning_rate": 4.045356371490281e-05,
      "loss": 0.0056,
      "step": 30940
    },
    {
      "epoch": 9.54952175254551,
      "grad_norm": 0.10334400832653046,
      "learning_rate": 4.045047824745449e-05,
      "loss": 0.0026,
      "step": 30950
    },
    {
      "epoch": 9.55260721999383,
      "grad_norm": 0.0034049563109874725,
      "learning_rate": 4.044739278000617e-05,
      "loss": 0.0015,
      "step": 30960
    },
    {
      "epoch": 9.555692687442148,
      "grad_norm": 0.00010805382044054568,
      "learning_rate": 4.0444307312557855e-05,
      "loss": 0.0011,
      "step": 30970
    },
    {
      "epoch": 9.558778154890465,
      "grad_norm": 0.0024653335567563772,
      "learning_rate": 4.044122184510953e-05,
      "loss": 0.0048,
      "step": 30980
    },
    {
      "epoch": 9.561863622338784,
      "grad_norm": 0.0015972275286912918,
      "learning_rate": 4.043813637766122e-05,
      "loss": 0.0031,
      "step": 30990
    },
    {
      "epoch": 9.564949089787103,
      "grad_norm": 0.0002582120359875262,
      "learning_rate": 4.04350509102129e-05,
      "loss": 0.0004,
      "step": 31000
    },
    {
      "epoch": 9.568034557235421,
      "grad_norm": 0.45712316036224365,
      "learning_rate": 4.043196544276458e-05,
      "loss": 0.0057,
      "step": 31010
    },
    {
      "epoch": 9.57112002468374,
      "grad_norm": 0.009270540438592434,
      "learning_rate": 4.042887997531626e-05,
      "loss": 0.0013,
      "step": 31020
    },
    {
      "epoch": 9.574205492132059,
      "grad_norm": 0.7664071917533875,
      "learning_rate": 4.0425794507867943e-05,
      "loss": 0.0026,
      "step": 31030
    },
    {
      "epoch": 9.577290959580376,
      "grad_norm": 0.003332579741254449,
      "learning_rate": 4.0422709040419626e-05,
      "loss": 0.0015,
      "step": 31040
    },
    {
      "epoch": 9.580376427028694,
      "grad_norm": 0.012141263112425804,
      "learning_rate": 4.04196235729713e-05,
      "loss": 0.0094,
      "step": 31050
    },
    {
      "epoch": 9.583461894477013,
      "grad_norm": 0.004905844572931528,
      "learning_rate": 4.041653810552299e-05,
      "loss": 0.001,
      "step": 31060
    },
    {
      "epoch": 9.586547361925332,
      "grad_norm": 1.5783003568649292,
      "learning_rate": 4.041345263807467e-05,
      "loss": 0.0033,
      "step": 31070
    },
    {
      "epoch": 9.58963282937365,
      "grad_norm": 0.06754862517118454,
      "learning_rate": 4.041036717062635e-05,
      "loss": 0.009,
      "step": 31080
    },
    {
      "epoch": 9.59271829682197,
      "grad_norm": 0.0573686882853508,
      "learning_rate": 4.040728170317803e-05,
      "loss": 0.0006,
      "step": 31090
    },
    {
      "epoch": 9.595803764270286,
      "grad_norm": 0.07580987364053726,
      "learning_rate": 4.0404196235729714e-05,
      "loss": 0.0045,
      "step": 31100
    },
    {
      "epoch": 9.598889231718605,
      "grad_norm": 0.029845774173736572,
      "learning_rate": 4.0401110768281396e-05,
      "loss": 0.0117,
      "step": 31110
    },
    {
      "epoch": 9.601974699166924,
      "grad_norm": 1.4274265766143799,
      "learning_rate": 4.039802530083308e-05,
      "loss": 0.0046,
      "step": 31120
    },
    {
      "epoch": 9.605060166615242,
      "grad_norm": 0.02048717811703682,
      "learning_rate": 4.039493983338476e-05,
      "loss": 0.0008,
      "step": 31130
    },
    {
      "epoch": 9.608145634063561,
      "grad_norm": 0.06420284509658813,
      "learning_rate": 4.0391854365936444e-05,
      "loss": 0.004,
      "step": 31140
    },
    {
      "epoch": 9.61123110151188,
      "grad_norm": 0.0215203408151865,
      "learning_rate": 4.038876889848812e-05,
      "loss": 0.0001,
      "step": 31150
    },
    {
      "epoch": 9.614316568960197,
      "grad_norm": 0.014486992731690407,
      "learning_rate": 4.038568343103981e-05,
      "loss": 0.0014,
      "step": 31160
    },
    {
      "epoch": 9.617402036408516,
      "grad_norm": 0.01991293393075466,
      "learning_rate": 4.0382597963591485e-05,
      "loss": 0.0081,
      "step": 31170
    },
    {
      "epoch": 9.620487503856834,
      "grad_norm": 0.0007156329229474068,
      "learning_rate": 4.037951249614317e-05,
      "loss": 0.0032,
      "step": 31180
    },
    {
      "epoch": 9.623572971305153,
      "grad_norm": 0.09715861827135086,
      "learning_rate": 4.037642702869485e-05,
      "loss": 0.0041,
      "step": 31190
    },
    {
      "epoch": 9.626658438753472,
      "grad_norm": 0.025675298646092415,
      "learning_rate": 4.037334156124653e-05,
      "loss": 0.0025,
      "step": 31200
    },
    {
      "epoch": 9.629743906201789,
      "grad_norm": 0.4179958403110504,
      "learning_rate": 4.0370256093798214e-05,
      "loss": 0.0025,
      "step": 31210
    },
    {
      "epoch": 9.632829373650107,
      "grad_norm": 0.10934187471866608,
      "learning_rate": 4.036717062634989e-05,
      "loss": 0.0072,
      "step": 31220
    },
    {
      "epoch": 9.635914841098426,
      "grad_norm": 0.046116527169942856,
      "learning_rate": 4.036408515890158e-05,
      "loss": 0.0103,
      "step": 31230
    },
    {
      "epoch": 9.639000308546745,
      "grad_norm": 0.05309554189443588,
      "learning_rate": 4.0360999691453255e-05,
      "loss": 0.0035,
      "step": 31240
    },
    {
      "epoch": 9.642085775995064,
      "grad_norm": 0.0007745930925011635,
      "learning_rate": 4.035791422400494e-05,
      "loss": 0.0022,
      "step": 31250
    },
    {
      "epoch": 9.645171243443382,
      "grad_norm": 0.6369435787200928,
      "learning_rate": 4.035482875655662e-05,
      "loss": 0.002,
      "step": 31260
    },
    {
      "epoch": 9.648256710891701,
      "grad_norm": 0.13834123313426971,
      "learning_rate": 4.03517432891083e-05,
      "loss": 0.0021,
      "step": 31270
    },
    {
      "epoch": 9.651342178340018,
      "grad_norm": 0.021690454334020615,
      "learning_rate": 4.0348657821659985e-05,
      "loss": 0.0021,
      "step": 31280
    },
    {
      "epoch": 9.654427645788337,
      "grad_norm": 0.13539795577526093,
      "learning_rate": 4.034557235421166e-05,
      "loss": 0.0052,
      "step": 31290
    },
    {
      "epoch": 9.657513113236655,
      "grad_norm": 0.19161207973957062,
      "learning_rate": 4.034248688676335e-05,
      "loss": 0.0052,
      "step": 31300
    },
    {
      "epoch": 9.660598580684974,
      "grad_norm": 0.265139639377594,
      "learning_rate": 4.0339401419315026e-05,
      "loss": 0.0003,
      "step": 31310
    },
    {
      "epoch": 9.663684048133293,
      "grad_norm": 0.0022795316763222218,
      "learning_rate": 4.033631595186671e-05,
      "loss": 0.0032,
      "step": 31320
    },
    {
      "epoch": 9.66676951558161,
      "grad_norm": 0.008958744816482067,
      "learning_rate": 4.033323048441839e-05,
      "loss": 0.0028,
      "step": 31330
    },
    {
      "epoch": 9.669854983029929,
      "grad_norm": 0.05699307098984718,
      "learning_rate": 4.033014501697007e-05,
      "loss": 0.0028,
      "step": 31340
    },
    {
      "epoch": 9.672940450478247,
      "grad_norm": 0.0013154060579836369,
      "learning_rate": 4.0327059549521756e-05,
      "loss": 0.0002,
      "step": 31350
    },
    {
      "epoch": 9.676025917926566,
      "grad_norm": 0.00040150026325136423,
      "learning_rate": 4.032397408207343e-05,
      "loss": 0.0027,
      "step": 31360
    },
    {
      "epoch": 9.679111385374885,
      "grad_norm": 0.00021960504818707705,
      "learning_rate": 4.032088861462512e-05,
      "loss": 0.0026,
      "step": 31370
    },
    {
      "epoch": 9.682196852823203,
      "grad_norm": 0.04257070645689964,
      "learning_rate": 4.0317803147176796e-05,
      "loss": 0.0122,
      "step": 31380
    },
    {
      "epoch": 9.68528232027152,
      "grad_norm": 0.03717825189232826,
      "learning_rate": 4.031471767972848e-05,
      "loss": 0.0057,
      "step": 31390
    },
    {
      "epoch": 9.688367787719839,
      "grad_norm": 0.2825215458869934,
      "learning_rate": 4.031163221228017e-05,
      "loss": 0.0036,
      "step": 31400
    },
    {
      "epoch": 9.691453255168158,
      "grad_norm": 0.0257040336728096,
      "learning_rate": 4.0308546744831844e-05,
      "loss": 0.0008,
      "step": 31410
    },
    {
      "epoch": 9.694538722616477,
      "grad_norm": 0.03339603170752525,
      "learning_rate": 4.0305461277383526e-05,
      "loss": 0.0025,
      "step": 31420
    },
    {
      "epoch": 9.697624190064795,
      "grad_norm": 0.5557712912559509,
      "learning_rate": 4.030237580993521e-05,
      "loss": 0.0081,
      "step": 31430
    },
    {
      "epoch": 9.700709657513114,
      "grad_norm": 0.2788199782371521,
      "learning_rate": 4.029929034248689e-05,
      "loss": 0.0018,
      "step": 31440
    },
    {
      "epoch": 9.703795124961431,
      "grad_norm": 0.057657063007354736,
      "learning_rate": 4.029620487503857e-05,
      "loss": 0.0055,
      "step": 31450
    },
    {
      "epoch": 9.70688059240975,
      "grad_norm": 0.2835497558116913,
      "learning_rate": 4.029311940759025e-05,
      "loss": 0.0038,
      "step": 31460
    },
    {
      "epoch": 9.709966059858068,
      "grad_norm": 0.029662828892469406,
      "learning_rate": 4.029003394014194e-05,
      "loss": 0.0007,
      "step": 31470
    },
    {
      "epoch": 9.713051527306387,
      "grad_norm": 0.004317356273531914,
      "learning_rate": 4.0286948472693614e-05,
      "loss": 0.0011,
      "step": 31480
    },
    {
      "epoch": 9.716136994754706,
      "grad_norm": 0.5566151142120361,
      "learning_rate": 4.02838630052453e-05,
      "loss": 0.0054,
      "step": 31490
    },
    {
      "epoch": 9.719222462203025,
      "grad_norm": 0.11947421729564667,
      "learning_rate": 4.028077753779698e-05,
      "loss": 0.0027,
      "step": 31500
    },
    {
      "epoch": 9.722307929651341,
      "grad_norm": 0.04669437184929848,
      "learning_rate": 4.027769207034866e-05,
      "loss": 0.0063,
      "step": 31510
    },
    {
      "epoch": 9.72539339709966,
      "grad_norm": 2.0616037845611572,
      "learning_rate": 4.027460660290034e-05,
      "loss": 0.0087,
      "step": 31520
    },
    {
      "epoch": 9.728478864547979,
      "grad_norm": 1.4243417978286743,
      "learning_rate": 4.027152113545202e-05,
      "loss": 0.0085,
      "step": 31530
    },
    {
      "epoch": 9.731564331996298,
      "grad_norm": 1.4032537937164307,
      "learning_rate": 4.026843566800371e-05,
      "loss": 0.0012,
      "step": 31540
    },
    {
      "epoch": 9.734649799444616,
      "grad_norm": 0.28695908188819885,
      "learning_rate": 4.0265350200555385e-05,
      "loss": 0.0017,
      "step": 31550
    },
    {
      "epoch": 9.737735266892933,
      "grad_norm": 0.0037125281523913145,
      "learning_rate": 4.026226473310707e-05,
      "loss": 0.0009,
      "step": 31560
    },
    {
      "epoch": 9.740820734341252,
      "grad_norm": 0.14204959571361542,
      "learning_rate": 4.025917926565875e-05,
      "loss": 0.0097,
      "step": 31570
    },
    {
      "epoch": 9.74390620178957,
      "grad_norm": 0.003703838447108865,
      "learning_rate": 4.025609379821043e-05,
      "loss": 0.0039,
      "step": 31580
    },
    {
      "epoch": 9.74699166923789,
      "grad_norm": 0.0036860182881355286,
      "learning_rate": 4.025300833076211e-05,
      "loss": 0.0018,
      "step": 31590
    },
    {
      "epoch": 9.750077136686208,
      "grad_norm": 0.4922601580619812,
      "learning_rate": 4.024992286331379e-05,
      "loss": 0.0026,
      "step": 31600
    },
    {
      "epoch": 9.753162604134527,
      "grad_norm": 0.5490732789039612,
      "learning_rate": 4.024683739586548e-05,
      "loss": 0.0027,
      "step": 31610
    },
    {
      "epoch": 9.756248071582846,
      "grad_norm": 0.0034758655820041895,
      "learning_rate": 4.0243751928417155e-05,
      "loss": 0.0004,
      "step": 31620
    },
    {
      "epoch": 9.759333539031163,
      "grad_norm": 0.34940534830093384,
      "learning_rate": 4.024066646096884e-05,
      "loss": 0.0174,
      "step": 31630
    },
    {
      "epoch": 9.762419006479481,
      "grad_norm": 0.0002375729673076421,
      "learning_rate": 4.023758099352052e-05,
      "loss": 0.0161,
      "step": 31640
    },
    {
      "epoch": 9.7655044739278,
      "grad_norm": 1.825535535812378,
      "learning_rate": 4.02344955260722e-05,
      "loss": 0.0047,
      "step": 31650
    },
    {
      "epoch": 9.768589941376119,
      "grad_norm": 0.055754125118255615,
      "learning_rate": 4.023141005862388e-05,
      "loss": 0.005,
      "step": 31660
    },
    {
      "epoch": 9.771675408824438,
      "grad_norm": 0.04598615691065788,
      "learning_rate": 4.022832459117557e-05,
      "loss": 0.0043,
      "step": 31670
    },
    {
      "epoch": 9.774760876272754,
      "grad_norm": 0.013800631277263165,
      "learning_rate": 4.022523912372725e-05,
      "loss": 0.0037,
      "step": 31680
    },
    {
      "epoch": 9.777846343721073,
      "grad_norm": 0.033039260655641556,
      "learning_rate": 4.0222153656278926e-05,
      "loss": 0.005,
      "step": 31690
    },
    {
      "epoch": 9.780931811169392,
      "grad_norm": 0.0014615289401262999,
      "learning_rate": 4.021906818883061e-05,
      "loss": 0.0078,
      "step": 31700
    },
    {
      "epoch": 9.78401727861771,
      "grad_norm": 0.010109666734933853,
      "learning_rate": 4.021598272138229e-05,
      "loss": 0.0011,
      "step": 31710
    },
    {
      "epoch": 9.78710274606603,
      "grad_norm": 0.0037181891966611147,
      "learning_rate": 4.021289725393397e-05,
      "loss": 0.0007,
      "step": 31720
    },
    {
      "epoch": 9.790188213514348,
      "grad_norm": 0.037559498101472855,
      "learning_rate": 4.0209811786485656e-05,
      "loss": 0.0093,
      "step": 31730
    },
    {
      "epoch": 9.793273680962665,
      "grad_norm": 0.008079846389591694,
      "learning_rate": 4.020672631903734e-05,
      "loss": 0.0055,
      "step": 31740
    },
    {
      "epoch": 9.796359148410984,
      "grad_norm": 0.437854140996933,
      "learning_rate": 4.020364085158902e-05,
      "loss": 0.0038,
      "step": 31750
    },
    {
      "epoch": 9.799444615859302,
      "grad_norm": 0.005206595174968243,
      "learning_rate": 4.0200555384140696e-05,
      "loss": 0.0205,
      "step": 31760
    },
    {
      "epoch": 9.802530083307621,
      "grad_norm": 0.001159650506451726,
      "learning_rate": 4.019746991669238e-05,
      "loss": 0.0033,
      "step": 31770
    },
    {
      "epoch": 9.80561555075594,
      "grad_norm": 0.8028435707092285,
      "learning_rate": 4.019438444924406e-05,
      "loss": 0.0014,
      "step": 31780
    },
    {
      "epoch": 9.808701018204259,
      "grad_norm": 0.07841403037309647,
      "learning_rate": 4.0191298981795744e-05,
      "loss": 0.0024,
      "step": 31790
    },
    {
      "epoch": 9.811786485652576,
      "grad_norm": 0.002007167087867856,
      "learning_rate": 4.0188213514347426e-05,
      "loss": 0.0003,
      "step": 31800
    },
    {
      "epoch": 9.814871953100894,
      "grad_norm": 0.14452578127384186,
      "learning_rate": 4.018512804689911e-05,
      "loss": 0.0016,
      "step": 31810
    },
    {
      "epoch": 9.817957420549213,
      "grad_norm": 0.0053763799369335175,
      "learning_rate": 4.018204257945079e-05,
      "loss": 0.0133,
      "step": 31820
    },
    {
      "epoch": 9.821042887997532,
      "grad_norm": 0.027957983314990997,
      "learning_rate": 4.017895711200247e-05,
      "loss": 0.0019,
      "step": 31830
    },
    {
      "epoch": 9.82412835544585,
      "grad_norm": 0.05100417509675026,
      "learning_rate": 4.017587164455415e-05,
      "loss": 0.0004,
      "step": 31840
    },
    {
      "epoch": 9.82721382289417,
      "grad_norm": 0.0005868126172572374,
      "learning_rate": 4.017278617710583e-05,
      "loss": 0.0039,
      "step": 31850
    },
    {
      "epoch": 9.830299290342486,
      "grad_norm": 0.00010615413339110091,
      "learning_rate": 4.0169700709657514e-05,
      "loss": 0.0014,
      "step": 31860
    },
    {
      "epoch": 9.833384757790805,
      "grad_norm": 0.005448599811643362,
      "learning_rate": 4.01666152422092e-05,
      "loss": 0.0024,
      "step": 31870
    },
    {
      "epoch": 9.836470225239124,
      "grad_norm": 0.17020432651042938,
      "learning_rate": 4.016352977476088e-05,
      "loss": 0.0035,
      "step": 31880
    },
    {
      "epoch": 9.839555692687442,
      "grad_norm": 1.838921070098877,
      "learning_rate": 4.016044430731256e-05,
      "loss": 0.0057,
      "step": 31890
    },
    {
      "epoch": 9.842641160135761,
      "grad_norm": 0.19034089148044586,
      "learning_rate": 4.015735883986424e-05,
      "loss": 0.0028,
      "step": 31900
    },
    {
      "epoch": 9.84572662758408,
      "grad_norm": 0.04707818850874901,
      "learning_rate": 4.015427337241593e-05,
      "loss": 0.0054,
      "step": 31910
    },
    {
      "epoch": 9.848812095032397,
      "grad_norm": 0.0007232259958982468,
      "learning_rate": 4.01511879049676e-05,
      "loss": 0.0013,
      "step": 31920
    },
    {
      "epoch": 9.851897562480715,
      "grad_norm": 0.0038987917359918356,
      "learning_rate": 4.0148102437519285e-05,
      "loss": 0.0026,
      "step": 31930
    },
    {
      "epoch": 9.854983029929034,
      "grad_norm": 0.5309978127479553,
      "learning_rate": 4.014501697007097e-05,
      "loss": 0.0111,
      "step": 31940
    },
    {
      "epoch": 9.858068497377353,
      "grad_norm": 2.9486100673675537,
      "learning_rate": 4.014193150262265e-05,
      "loss": 0.0065,
      "step": 31950
    },
    {
      "epoch": 9.861153964825672,
      "grad_norm": 0.2617625594139099,
      "learning_rate": 4.013884603517433e-05,
      "loss": 0.0007,
      "step": 31960
    },
    {
      "epoch": 9.86423943227399,
      "grad_norm": 0.006894243881106377,
      "learning_rate": 4.013576056772601e-05,
      "loss": 0.0002,
      "step": 31970
    },
    {
      "epoch": 9.867324899722307,
      "grad_norm": 0.054229993373155594,
      "learning_rate": 4.01326751002777e-05,
      "loss": 0.0004,
      "step": 31980
    },
    {
      "epoch": 9.870410367170626,
      "grad_norm": 0.06337416172027588,
      "learning_rate": 4.012958963282937e-05,
      "loss": 0.0053,
      "step": 31990
    },
    {
      "epoch": 9.873495834618945,
      "grad_norm": 0.0655173808336258,
      "learning_rate": 4.0126504165381056e-05,
      "loss": 0.0008,
      "step": 32000
    },
    {
      "epoch": 9.876581302067263,
      "grad_norm": 0.577869713306427,
      "learning_rate": 4.012341869793274e-05,
      "loss": 0.0032,
      "step": 32010
    },
    {
      "epoch": 9.879666769515582,
      "grad_norm": 0.010925094597041607,
      "learning_rate": 4.012033323048442e-05,
      "loss": 0.0008,
      "step": 32020
    },
    {
      "epoch": 9.8827522369639,
      "grad_norm": 0.07049204409122467,
      "learning_rate": 4.01172477630361e-05,
      "loss": 0.0066,
      "step": 32030
    },
    {
      "epoch": 9.885837704412218,
      "grad_norm": 0.06194482371211052,
      "learning_rate": 4.011416229558778e-05,
      "loss": 0.0007,
      "step": 32040
    },
    {
      "epoch": 9.888923171860537,
      "grad_norm": 0.0007038222393020988,
      "learning_rate": 4.011107682813947e-05,
      "loss": 0.0072,
      "step": 32050
    },
    {
      "epoch": 9.892008639308855,
      "grad_norm": 0.0008252880652435124,
      "learning_rate": 4.0107991360691144e-05,
      "loss": 0.0044,
      "step": 32060
    },
    {
      "epoch": 9.895094106757174,
      "grad_norm": 0.10919519513845444,
      "learning_rate": 4.0104905893242826e-05,
      "loss": 0.004,
      "step": 32070
    },
    {
      "epoch": 9.898179574205493,
      "grad_norm": 0.0006739696837030351,
      "learning_rate": 4.010182042579451e-05,
      "loss": 0.0051,
      "step": 32080
    },
    {
      "epoch": 9.901265041653811,
      "grad_norm": 0.7449561953544617,
      "learning_rate": 4.009873495834619e-05,
      "loss": 0.0108,
      "step": 32090
    },
    {
      "epoch": 9.904350509102128,
      "grad_norm": 0.051532354205846786,
      "learning_rate": 4.0095649490897874e-05,
      "loss": 0.0006,
      "step": 32100
    },
    {
      "epoch": 9.907435976550447,
      "grad_norm": 0.00044558136141858995,
      "learning_rate": 4.009256402344955e-05,
      "loss": 0.0045,
      "step": 32110
    },
    {
      "epoch": 9.910521443998766,
      "grad_norm": 0.1966913491487503,
      "learning_rate": 4.008947855600124e-05,
      "loss": 0.0017,
      "step": 32120
    },
    {
      "epoch": 9.913606911447085,
      "grad_norm": 0.05308058112859726,
      "learning_rate": 4.008639308855292e-05,
      "loss": 0.0008,
      "step": 32130
    },
    {
      "epoch": 9.916692378895403,
      "grad_norm": 0.03386892005801201,
      "learning_rate": 4.00833076211046e-05,
      "loss": 0.0051,
      "step": 32140
    },
    {
      "epoch": 9.91977784634372,
      "grad_norm": 0.10699732601642609,
      "learning_rate": 4.0080222153656286e-05,
      "loss": 0.0073,
      "step": 32150
    },
    {
      "epoch": 9.922863313792039,
      "grad_norm": 0.5085179209709167,
      "learning_rate": 4.007713668620796e-05,
      "loss": 0.0041,
      "step": 32160
    },
    {
      "epoch": 9.925948781240358,
      "grad_norm": 0.0019481461495161057,
      "learning_rate": 4.0074051218759644e-05,
      "loss": 0.0001,
      "step": 32170
    },
    {
      "epoch": 9.929034248688676,
      "grad_norm": 0.09402826428413391,
      "learning_rate": 4.007096575131133e-05,
      "loss": 0.0126,
      "step": 32180
    },
    {
      "epoch": 9.932119716136995,
      "grad_norm": 0.40332314372062683,
      "learning_rate": 4.006788028386301e-05,
      "loss": 0.0019,
      "step": 32190
    },
    {
      "epoch": 9.935205183585314,
      "grad_norm": 0.0027233860455453396,
      "learning_rate": 4.006479481641469e-05,
      "loss": 0.0004,
      "step": 32200
    },
    {
      "epoch": 9.93829065103363,
      "grad_norm": 0.2910800874233246,
      "learning_rate": 4.006170934896637e-05,
      "loss": 0.0016,
      "step": 32210
    },
    {
      "epoch": 9.94137611848195,
      "grad_norm": 0.00017182451847475022,
      "learning_rate": 4.0058623881518057e-05,
      "loss": 0.0004,
      "step": 32220
    },
    {
      "epoch": 9.944461585930268,
      "grad_norm": 0.5330315828323364,
      "learning_rate": 4.005553841406973e-05,
      "loss": 0.001,
      "step": 32230
    },
    {
      "epoch": 9.947547053378587,
      "grad_norm": 0.04005039483308792,
      "learning_rate": 4.0052452946621415e-05,
      "loss": 0.0004,
      "step": 32240
    },
    {
      "epoch": 9.950632520826906,
      "grad_norm": 5.836814671056345e-05,
      "learning_rate": 4.00493674791731e-05,
      "loss": 0.0008,
      "step": 32250
    },
    {
      "epoch": 9.953717988275224,
      "grad_norm": 0.019750315696001053,
      "learning_rate": 4.004628201172478e-05,
      "loss": 0.003,
      "step": 32260
    },
    {
      "epoch": 9.956803455723541,
      "grad_norm": 0.002652800874784589,
      "learning_rate": 4.004319654427646e-05,
      "loss": 0.0021,
      "step": 32270
    },
    {
      "epoch": 9.95988892317186,
      "grad_norm": 0.0004143126425333321,
      "learning_rate": 4.004011107682814e-05,
      "loss": 0.0036,
      "step": 32280
    },
    {
      "epoch": 9.962974390620179,
      "grad_norm": 0.505345344543457,
      "learning_rate": 4.003702560937983e-05,
      "loss": 0.0008,
      "step": 32290
    },
    {
      "epoch": 9.966059858068498,
      "grad_norm": 0.006278201937675476,
      "learning_rate": 4.00339401419315e-05,
      "loss": 0.0061,
      "step": 32300
    },
    {
      "epoch": 9.969145325516816,
      "grad_norm": 0.7838610410690308,
      "learning_rate": 4.0030854674483185e-05,
      "loss": 0.0045,
      "step": 32310
    },
    {
      "epoch": 9.972230792965135,
      "grad_norm": 0.0049432432278990746,
      "learning_rate": 4.002776920703487e-05,
      "loss": 0.0064,
      "step": 32320
    },
    {
      "epoch": 9.975316260413452,
      "grad_norm": 0.0048776064068078995,
      "learning_rate": 4.002468373958655e-05,
      "loss": 0.0002,
      "step": 32330
    },
    {
      "epoch": 9.97840172786177,
      "grad_norm": 0.0002891968179028481,
      "learning_rate": 4.002159827213823e-05,
      "loss": 0.0087,
      "step": 32340
    },
    {
      "epoch": 9.98148719531009,
      "grad_norm": 1.9766308069229126,
      "learning_rate": 4.001851280468991e-05,
      "loss": 0.0041,
      "step": 32350
    },
    {
      "epoch": 9.984572662758408,
      "grad_norm": 1.8358047008514404,
      "learning_rate": 4.00154273372416e-05,
      "loss": 0.0054,
      "step": 32360
    },
    {
      "epoch": 9.987658130206727,
      "grad_norm": 2.638094902038574,
      "learning_rate": 4.001234186979327e-05,
      "loss": 0.0032,
      "step": 32370
    },
    {
      "epoch": 9.990743597655044,
      "grad_norm": 0.0056136129423975945,
      "learning_rate": 4.0009256402344956e-05,
      "loss": 0.0086,
      "step": 32380
    },
    {
      "epoch": 9.993829065103363,
      "grad_norm": 0.01366901770234108,
      "learning_rate": 4.000617093489664e-05,
      "loss": 0.0102,
      "step": 32390
    },
    {
      "epoch": 9.996914532551681,
      "grad_norm": 0.31375303864479065,
      "learning_rate": 4.000308546744832e-05,
      "loss": 0.0018,
      "step": 32400
    },
    {
      "epoch": 10.0,
      "grad_norm": 28.370628356933594,
      "learning_rate": 4e-05,
      "loss": 0.1029,
      "step": 32410
    },
    {
      "epoch": 10.0,
      "eval_accuracy_branch1": 0.9988908499946954,
      "eval_accuracy_branch2": 0.4535169699950812,
      "eval_f1_branch1": 0.9981687280172337,
      "eval_f1_branch2": 0.4534347076353837,
      "eval_loss": 0.0011113460641354322,
      "eval_precision_branch1": 0.9982307791353907,
      "eval_precision_branch2": 0.5055083938571093,
      "eval_recall_branch1": 0.9981102558658066,
      "eval_recall_branch2": 0.5056060299181158,
      "eval_runtime": 241.0035,
      "eval_samples_per_second": 430.214,
      "eval_steps_per_second": 53.779,
      "step": 32410
    },
    {
      "epoch": 10.003085467448319,
      "grad_norm": 0.0004629589384421706,
      "learning_rate": 3.9996914532551686e-05,
      "loss": 0.002,
      "step": 32420
    },
    {
      "epoch": 10.006170934896637,
      "grad_norm": 0.07980287075042725,
      "learning_rate": 3.999382906510337e-05,
      "loss": 0.0055,
      "step": 32430
    },
    {
      "epoch": 10.009256402344954,
      "grad_norm": 0.00655120937153697,
      "learning_rate": 3.9990743597655044e-05,
      "loss": 0.0047,
      "step": 32440
    },
    {
      "epoch": 10.012341869793273,
      "grad_norm": 0.0008789945859462023,
      "learning_rate": 3.9987658130206726e-05,
      "loss": 0.0003,
      "step": 32450
    },
    {
      "epoch": 10.015427337241592,
      "grad_norm": 2.2998595237731934,
      "learning_rate": 3.998457266275841e-05,
      "loss": 0.0126,
      "step": 32460
    },
    {
      "epoch": 10.01851280468991,
      "grad_norm": 0.0014202928869053721,
      "learning_rate": 3.998148719531009e-05,
      "loss": 0.0105,
      "step": 32470
    },
    {
      "epoch": 10.02159827213823,
      "grad_norm": 0.08608603477478027,
      "learning_rate": 3.9978401727861774e-05,
      "loss": 0.0033,
      "step": 32480
    },
    {
      "epoch": 10.024683739586548,
      "grad_norm": 0.004210033919662237,
      "learning_rate": 3.9975316260413456e-05,
      "loss": 0.0043,
      "step": 32490
    },
    {
      "epoch": 10.027769207034865,
      "grad_norm": 0.0014591848012059927,
      "learning_rate": 3.997223079296514e-05,
      "loss": 0.0007,
      "step": 32500
    },
    {
      "epoch": 10.030854674483184,
      "grad_norm": 0.0014118872350081801,
      "learning_rate": 3.9969145325516814e-05,
      "loss": 0.0011,
      "step": 32510
    },
    {
      "epoch": 10.033940141931502,
      "grad_norm": 0.9859828948974609,
      "learning_rate": 3.99660598580685e-05,
      "loss": 0.0019,
      "step": 32520
    },
    {
      "epoch": 10.037025609379821,
      "grad_norm": 0.0038511173333972692,
      "learning_rate": 3.996297439062018e-05,
      "loss": 0.0109,
      "step": 32530
    },
    {
      "epoch": 10.04011107682814,
      "grad_norm": 0.02050735056400299,
      "learning_rate": 3.995988892317186e-05,
      "loss": 0.0017,
      "step": 32540
    },
    {
      "epoch": 10.043196544276459,
      "grad_norm": 0.40937313437461853,
      "learning_rate": 3.9956803455723544e-05,
      "loss": 0.0022,
      "step": 32550
    },
    {
      "epoch": 10.046282011724776,
      "grad_norm": 0.30815231800079346,
      "learning_rate": 3.995371798827523e-05,
      "loss": 0.0048,
      "step": 32560
    },
    {
      "epoch": 10.049367479173094,
      "grad_norm": 1.8148233890533447,
      "learning_rate": 3.995063252082691e-05,
      "loss": 0.002,
      "step": 32570
    },
    {
      "epoch": 10.052452946621413,
      "grad_norm": 0.1755816787481308,
      "learning_rate": 3.9947547053378585e-05,
      "loss": 0.0049,
      "step": 32580
    },
    {
      "epoch": 10.055538414069732,
      "grad_norm": 0.2034730464220047,
      "learning_rate": 3.994446158593027e-05,
      "loss": 0.0033,
      "step": 32590
    },
    {
      "epoch": 10.05862388151805,
      "grad_norm": 0.01171695627272129,
      "learning_rate": 3.994137611848196e-05,
      "loss": 0.0069,
      "step": 32600
    },
    {
      "epoch": 10.06170934896637,
      "grad_norm": 0.38927513360977173,
      "learning_rate": 3.993829065103363e-05,
      "loss": 0.0017,
      "step": 32610
    },
    {
      "epoch": 10.064794816414686,
      "grad_norm": 0.029830217361450195,
      "learning_rate": 3.9935205183585315e-05,
      "loss": 0.002,
      "step": 32620
    },
    {
      "epoch": 10.067880283863005,
      "grad_norm": 0.017414113506674767,
      "learning_rate": 3.9932119716137e-05,
      "loss": 0.0025,
      "step": 32630
    },
    {
      "epoch": 10.070965751311324,
      "grad_norm": 0.04670994356274605,
      "learning_rate": 3.992903424868868e-05,
      "loss": 0.0006,
      "step": 32640
    },
    {
      "epoch": 10.074051218759642,
      "grad_norm": 0.0072623807936906815,
      "learning_rate": 3.9925948781240356e-05,
      "loss": 0.0099,
      "step": 32650
    },
    {
      "epoch": 10.077136686207961,
      "grad_norm": 0.042197708040475845,
      "learning_rate": 3.9922863313792045e-05,
      "loss": 0.0041,
      "step": 32660
    },
    {
      "epoch": 10.08022215365628,
      "grad_norm": 0.018198400735855103,
      "learning_rate": 3.991977784634373e-05,
      "loss": 0.0015,
      "step": 32670
    },
    {
      "epoch": 10.083307621104597,
      "grad_norm": 0.0029305650386959314,
      "learning_rate": 3.99166923788954e-05,
      "loss": 0.0045,
      "step": 32680
    },
    {
      "epoch": 10.086393088552915,
      "grad_norm": 0.0029698708094656467,
      "learning_rate": 3.9913606911447086e-05,
      "loss": 0.0052,
      "step": 32690
    },
    {
      "epoch": 10.089478556001234,
      "grad_norm": 2.169323205947876,
      "learning_rate": 3.991052144399877e-05,
      "loss": 0.0055,
      "step": 32700
    },
    {
      "epoch": 10.092564023449553,
      "grad_norm": 0.02348228171467781,
      "learning_rate": 3.990743597655045e-05,
      "loss": 0.0003,
      "step": 32710
    },
    {
      "epoch": 10.095649490897872,
      "grad_norm": 4.0496134757995605,
      "learning_rate": 3.9904350509102126e-05,
      "loss": 0.0189,
      "step": 32720
    },
    {
      "epoch": 10.09873495834619,
      "grad_norm": 1.0634753704071045,
      "learning_rate": 3.9901265041653815e-05,
      "loss": 0.0089,
      "step": 32730
    },
    {
      "epoch": 10.101820425794507,
      "grad_norm": 0.0011164415627717972,
      "learning_rate": 3.98981795742055e-05,
      "loss": 0.0004,
      "step": 32740
    },
    {
      "epoch": 10.104905893242826,
      "grad_norm": 0.15320095419883728,
      "learning_rate": 3.9895094106757174e-05,
      "loss": 0.0011,
      "step": 32750
    },
    {
      "epoch": 10.107991360691145,
      "grad_norm": 0.04271591827273369,
      "learning_rate": 3.9892008639308856e-05,
      "loss": 0.0023,
      "step": 32760
    },
    {
      "epoch": 10.111076828139463,
      "grad_norm": 0.17093642055988312,
      "learning_rate": 3.988892317186054e-05,
      "loss": 0.004,
      "step": 32770
    },
    {
      "epoch": 10.114162295587782,
      "grad_norm": 0.011510837823152542,
      "learning_rate": 3.988583770441222e-05,
      "loss": 0.0028,
      "step": 32780
    },
    {
      "epoch": 10.1172477630361,
      "grad_norm": 0.014946687035262585,
      "learning_rate": 3.98827522369639e-05,
      "loss": 0.007,
      "step": 32790
    },
    {
      "epoch": 10.120333230484418,
      "grad_norm": 0.005473980214446783,
      "learning_rate": 3.9879666769515586e-05,
      "loss": 0.0016,
      "step": 32800
    },
    {
      "epoch": 10.123418697932737,
      "grad_norm": 0.0948541909456253,
      "learning_rate": 3.987658130206727e-05,
      "loss": 0.0086,
      "step": 32810
    },
    {
      "epoch": 10.126504165381055,
      "grad_norm": 0.06497377902269363,
      "learning_rate": 3.9873495834618944e-05,
      "loss": 0.012,
      "step": 32820
    },
    {
      "epoch": 10.129589632829374,
      "grad_norm": 0.0008039093227125704,
      "learning_rate": 3.987041036717063e-05,
      "loss": 0.0042,
      "step": 32830
    },
    {
      "epoch": 10.132675100277693,
      "grad_norm": 0.3196943402290344,
      "learning_rate": 3.986732489972231e-05,
      "loss": 0.0006,
      "step": 32840
    },
    {
      "epoch": 10.13576056772601,
      "grad_norm": 1.7275772094726562,
      "learning_rate": 3.986423943227399e-05,
      "loss": 0.0042,
      "step": 32850
    },
    {
      "epoch": 10.138846035174328,
      "grad_norm": 0.0018113568658009171,
      "learning_rate": 3.986115396482567e-05,
      "loss": 0.0013,
      "step": 32860
    },
    {
      "epoch": 10.141931502622647,
      "grad_norm": 6.0517952078953385e-05,
      "learning_rate": 3.9858068497377357e-05,
      "loss": 0.0005,
      "step": 32870
    },
    {
      "epoch": 10.145016970070966,
      "grad_norm": 0.018208572641015053,
      "learning_rate": 3.985498302992904e-05,
      "loss": 0.0019,
      "step": 32880
    },
    {
      "epoch": 10.148102437519285,
      "grad_norm": 0.01964903064072132,
      "learning_rate": 3.9851897562480715e-05,
      "loss": 0.004,
      "step": 32890
    },
    {
      "epoch": 10.151187904967603,
      "grad_norm": 1.1570273637771606,
      "learning_rate": 3.9848812095032404e-05,
      "loss": 0.0004,
      "step": 32900
    },
    {
      "epoch": 10.15427337241592,
      "grad_norm": 0.00017772270075511187,
      "learning_rate": 3.984572662758408e-05,
      "loss": 0.0005,
      "step": 32910
    },
    {
      "epoch": 10.157358839864239,
      "grad_norm": 0.8058361411094666,
      "learning_rate": 3.984264116013576e-05,
      "loss": 0.0057,
      "step": 32920
    },
    {
      "epoch": 10.160444307312558,
      "grad_norm": 0.0009217143524438143,
      "learning_rate": 3.9839555692687445e-05,
      "loss": 0.0047,
      "step": 32930
    },
    {
      "epoch": 10.163529774760876,
      "grad_norm": 0.07359013706445694,
      "learning_rate": 3.983647022523913e-05,
      "loss": 0.0019,
      "step": 32940
    },
    {
      "epoch": 10.166615242209195,
      "grad_norm": 0.06714247167110443,
      "learning_rate": 3.983338475779081e-05,
      "loss": 0.0052,
      "step": 32950
    },
    {
      "epoch": 10.169700709657514,
      "grad_norm": 0.0019514387240633368,
      "learning_rate": 3.9830299290342485e-05,
      "loss": 0.0026,
      "step": 32960
    },
    {
      "epoch": 10.17278617710583,
      "grad_norm": 0.00016562957898713648,
      "learning_rate": 3.9827213822894175e-05,
      "loss": 0.0001,
      "step": 32970
    },
    {
      "epoch": 10.17587164455415,
      "grad_norm": 0.006884633097797632,
      "learning_rate": 3.982412835544585e-05,
      "loss": 0.0008,
      "step": 32980
    },
    {
      "epoch": 10.178957112002468,
      "grad_norm": 0.05637058615684509,
      "learning_rate": 3.982104288799753e-05,
      "loss": 0.0044,
      "step": 32990
    },
    {
      "epoch": 10.182042579450787,
      "grad_norm": 0.3231120705604553,
      "learning_rate": 3.9817957420549215e-05,
      "loss": 0.0019,
      "step": 33000
    },
    {
      "epoch": 10.185128046899106,
      "grad_norm": 0.23787690699100494,
      "learning_rate": 3.98148719531009e-05,
      "loss": 0.0005,
      "step": 33010
    },
    {
      "epoch": 10.188213514347424,
      "grad_norm": 0.22472494840621948,
      "learning_rate": 3.981178648565258e-05,
      "loss": 0.0081,
      "step": 33020
    },
    {
      "epoch": 10.191298981795741,
      "grad_norm": 0.004564148373901844,
      "learning_rate": 3.9808701018204256e-05,
      "loss": 0.0117,
      "step": 33030
    },
    {
      "epoch": 10.19438444924406,
      "grad_norm": 0.2805332541465759,
      "learning_rate": 3.9805615550755945e-05,
      "loss": 0.0037,
      "step": 33040
    },
    {
      "epoch": 10.197469916692379,
      "grad_norm": 0.733593225479126,
      "learning_rate": 3.980253008330762e-05,
      "loss": 0.0152,
      "step": 33050
    },
    {
      "epoch": 10.200555384140698,
      "grad_norm": 0.13135837018489838,
      "learning_rate": 3.97994446158593e-05,
      "loss": 0.0058,
      "step": 33060
    },
    {
      "epoch": 10.203640851589016,
      "grad_norm": 0.014668659307062626,
      "learning_rate": 3.9796359148410986e-05,
      "loss": 0.0037,
      "step": 33070
    },
    {
      "epoch": 10.206726319037335,
      "grad_norm": 0.1894129514694214,
      "learning_rate": 3.979327368096267e-05,
      "loss": 0.0058,
      "step": 33080
    },
    {
      "epoch": 10.209811786485652,
      "grad_norm": 0.0019186324207112193,
      "learning_rate": 3.979018821351435e-05,
      "loss": 0.0005,
      "step": 33090
    },
    {
      "epoch": 10.21289725393397,
      "grad_norm": 0.08429177105426788,
      "learning_rate": 3.9787102746066026e-05,
      "loss": 0.0102,
      "step": 33100
    },
    {
      "epoch": 10.21598272138229,
      "grad_norm": 0.9099704027175903,
      "learning_rate": 3.9784017278617716e-05,
      "loss": 0.0032,
      "step": 33110
    },
    {
      "epoch": 10.219068188830608,
      "grad_norm": 0.06603016704320908,
      "learning_rate": 3.978093181116939e-05,
      "loss": 0.0069,
      "step": 33120
    },
    {
      "epoch": 10.222153656278927,
      "grad_norm": 0.03620179370045662,
      "learning_rate": 3.9777846343721074e-05,
      "loss": 0.0016,
      "step": 33130
    },
    {
      "epoch": 10.225239123727246,
      "grad_norm": 0.4101373255252838,
      "learning_rate": 3.9774760876272756e-05,
      "loss": 0.0035,
      "step": 33140
    },
    {
      "epoch": 10.228324591175562,
      "grad_norm": 0.004752712324261665,
      "learning_rate": 3.977167540882444e-05,
      "loss": 0.0004,
      "step": 33150
    },
    {
      "epoch": 10.231410058623881,
      "grad_norm": 0.0002380549267400056,
      "learning_rate": 3.976858994137612e-05,
      "loss": 0.0022,
      "step": 33160
    },
    {
      "epoch": 10.2344955260722,
      "grad_norm": 0.010430536232888699,
      "learning_rate": 3.9765504473927804e-05,
      "loss": 0.0098,
      "step": 33170
    },
    {
      "epoch": 10.237580993520519,
      "grad_norm": 0.0867234617471695,
      "learning_rate": 3.9762419006479486e-05,
      "loss": 0.0039,
      "step": 33180
    },
    {
      "epoch": 10.240666460968837,
      "grad_norm": 0.0012995193246752024,
      "learning_rate": 3.975933353903116e-05,
      "loss": 0.0005,
      "step": 33190
    },
    {
      "epoch": 10.243751928417154,
      "grad_norm": 0.03529081493616104,
      "learning_rate": 3.9756248071582844e-05,
      "loss": 0.0041,
      "step": 33200
    },
    {
      "epoch": 10.246837395865473,
      "grad_norm": 0.03645957633852959,
      "learning_rate": 3.9753162604134534e-05,
      "loss": 0.002,
      "step": 33210
    },
    {
      "epoch": 10.249922863313792,
      "grad_norm": 0.0007883260259404778,
      "learning_rate": 3.975007713668621e-05,
      "loss": 0.0009,
      "step": 33220
    },
    {
      "epoch": 10.25300833076211,
      "grad_norm": 0.3817119896411896,
      "learning_rate": 3.974699166923789e-05,
      "loss": 0.0006,
      "step": 33230
    },
    {
      "epoch": 10.25609379821043,
      "grad_norm": 0.24998222291469574,
      "learning_rate": 3.9743906201789574e-05,
      "loss": 0.0007,
      "step": 33240
    },
    {
      "epoch": 10.259179265658748,
      "grad_norm": 0.0720919594168663,
      "learning_rate": 3.974082073434126e-05,
      "loss": 0.003,
      "step": 33250
    },
    {
      "epoch": 10.262264733107065,
      "grad_norm": 0.41857674717903137,
      "learning_rate": 3.973773526689293e-05,
      "loss": 0.0021,
      "step": 33260
    },
    {
      "epoch": 10.265350200555384,
      "grad_norm": 0.06744483858346939,
      "learning_rate": 3.9734649799444615e-05,
      "loss": 0.0002,
      "step": 33270
    },
    {
      "epoch": 10.268435668003702,
      "grad_norm": 0.012809708714485168,
      "learning_rate": 3.9731564331996304e-05,
      "loss": 0.003,
      "step": 33280
    },
    {
      "epoch": 10.271521135452021,
      "grad_norm": 0.26402127742767334,
      "learning_rate": 3.972847886454798e-05,
      "loss": 0.0001,
      "step": 33290
    },
    {
      "epoch": 10.27460660290034,
      "grad_norm": 0.20257103443145752,
      "learning_rate": 3.972539339709966e-05,
      "loss": 0.0028,
      "step": 33300
    },
    {
      "epoch": 10.277692070348659,
      "grad_norm": 0.37239953875541687,
      "learning_rate": 3.9722307929651345e-05,
      "loss": 0.003,
      "step": 33310
    },
    {
      "epoch": 10.280777537796975,
      "grad_norm": 0.2188407927751541,
      "learning_rate": 3.971922246220303e-05,
      "loss": 0.0017,
      "step": 33320
    },
    {
      "epoch": 10.283863005245294,
      "grad_norm": 0.04642253369092941,
      "learning_rate": 3.97161369947547e-05,
      "loss": 0.0047,
      "step": 33330
    },
    {
      "epoch": 10.286948472693613,
      "grad_norm": 0.0015436091925948858,
      "learning_rate": 3.9713051527306386e-05,
      "loss": 0.0081,
      "step": 33340
    },
    {
      "epoch": 10.290033940141932,
      "grad_norm": 0.002458106493577361,
      "learning_rate": 3.9709966059858075e-05,
      "loss": 0.0015,
      "step": 33350
    },
    {
      "epoch": 10.29311940759025,
      "grad_norm": 0.14123639464378357,
      "learning_rate": 3.970688059240975e-05,
      "loss": 0.0075,
      "step": 33360
    },
    {
      "epoch": 10.296204875038569,
      "grad_norm": 3.09855580329895,
      "learning_rate": 3.970379512496143e-05,
      "loss": 0.0086,
      "step": 33370
    },
    {
      "epoch": 10.299290342486886,
      "grad_norm": 0.22346355020999908,
      "learning_rate": 3.9700709657513115e-05,
      "loss": 0.0014,
      "step": 33380
    },
    {
      "epoch": 10.302375809935205,
      "grad_norm": 1.7321966886520386,
      "learning_rate": 3.96976241900648e-05,
      "loss": 0.0062,
      "step": 33390
    },
    {
      "epoch": 10.305461277383523,
      "grad_norm": 0.022233393043279648,
      "learning_rate": 3.9694538722616474e-05,
      "loss": 0.0007,
      "step": 33400
    },
    {
      "epoch": 10.308546744831842,
      "grad_norm": 0.01012019906193018,
      "learning_rate": 3.9691453255168156e-05,
      "loss": 0.003,
      "step": 33410
    },
    {
      "epoch": 10.311632212280161,
      "grad_norm": 0.00044467690167948604,
      "learning_rate": 3.9688367787719845e-05,
      "loss": 0.0035,
      "step": 33420
    },
    {
      "epoch": 10.31471767972848,
      "grad_norm": 0.003993980586528778,
      "learning_rate": 3.968528232027152e-05,
      "loss": 0.0006,
      "step": 33430
    },
    {
      "epoch": 10.317803147176797,
      "grad_norm": 0.0004936364712193608,
      "learning_rate": 3.9682196852823204e-05,
      "loss": 0.006,
      "step": 33440
    },
    {
      "epoch": 10.320888614625115,
      "grad_norm": 0.004378237295895815,
      "learning_rate": 3.9679111385374886e-05,
      "loss": 0.0047,
      "step": 33450
    },
    {
      "epoch": 10.323974082073434,
      "grad_norm": 0.18092763423919678,
      "learning_rate": 3.967602591792657e-05,
      "loss": 0.0001,
      "step": 33460
    },
    {
      "epoch": 10.327059549521753,
      "grad_norm": 0.1839766800403595,
      "learning_rate": 3.967294045047825e-05,
      "loss": 0.0036,
      "step": 33470
    },
    {
      "epoch": 10.330145016970071,
      "grad_norm": 0.018557321280241013,
      "learning_rate": 3.9669854983029933e-05,
      "loss": 0.0003,
      "step": 33480
    },
    {
      "epoch": 10.33323048441839,
      "grad_norm": 0.004129377193748951,
      "learning_rate": 3.9666769515581616e-05,
      "loss": 0.0008,
      "step": 33490
    },
    {
      "epoch": 10.336315951866707,
      "grad_norm": 0.009173057973384857,
      "learning_rate": 3.966368404813329e-05,
      "loss": 0.0037,
      "step": 33500
    },
    {
      "epoch": 10.339401419315026,
      "grad_norm": 0.02312491275370121,
      "learning_rate": 3.9660598580684974e-05,
      "loss": 0.0011,
      "step": 33510
    },
    {
      "epoch": 10.342486886763345,
      "grad_norm": 0.005260996054857969,
      "learning_rate": 3.9657513113236657e-05,
      "loss": 0.0002,
      "step": 33520
    },
    {
      "epoch": 10.345572354211663,
      "grad_norm": 0.026206882670521736,
      "learning_rate": 3.965442764578834e-05,
      "loss": 0.0031,
      "step": 33530
    },
    {
      "epoch": 10.348657821659982,
      "grad_norm": 0.04283157363533974,
      "learning_rate": 3.965134217834002e-05,
      "loss": 0.0015,
      "step": 33540
    },
    {
      "epoch": 10.351743289108299,
      "grad_norm": 0.4251753091812134,
      "learning_rate": 3.9648256710891704e-05,
      "loss": 0.001,
      "step": 33550
    },
    {
      "epoch": 10.354828756556618,
      "grad_norm": 0.5853288173675537,
      "learning_rate": 3.9645171243443386e-05,
      "loss": 0.0016,
      "step": 33560
    },
    {
      "epoch": 10.357914224004936,
      "grad_norm": 0.001527438755147159,
      "learning_rate": 3.964208577599506e-05,
      "loss": 0.0043,
      "step": 33570
    },
    {
      "epoch": 10.360999691453255,
      "grad_norm": 0.008625660091638565,
      "learning_rate": 3.9639000308546745e-05,
      "loss": 0.0014,
      "step": 33580
    },
    {
      "epoch": 10.364085158901574,
      "grad_norm": 0.008784335106611252,
      "learning_rate": 3.963591484109843e-05,
      "loss": 0.0004,
      "step": 33590
    },
    {
      "epoch": 10.367170626349893,
      "grad_norm": 8.14115337561816e-05,
      "learning_rate": 3.963282937365011e-05,
      "loss": 0.0025,
      "step": 33600
    },
    {
      "epoch": 10.370256093798211,
      "grad_norm": 0.005392750259488821,
      "learning_rate": 3.962974390620179e-05,
      "loss": 0.0003,
      "step": 33610
    },
    {
      "epoch": 10.373341561246528,
      "grad_norm": 0.006709625944495201,
      "learning_rate": 3.9626658438753475e-05,
      "loss": 0.0001,
      "step": 33620
    },
    {
      "epoch": 10.376427028694847,
      "grad_norm": 0.024173451587557793,
      "learning_rate": 3.962357297130516e-05,
      "loss": 0.0004,
      "step": 33630
    },
    {
      "epoch": 10.379512496143166,
      "grad_norm": 0.006939368788152933,
      "learning_rate": 3.962048750385683e-05,
      "loss": 0.0008,
      "step": 33640
    },
    {
      "epoch": 10.382597963591484,
      "grad_norm": 0.07292503118515015,
      "learning_rate": 3.9617402036408515e-05,
      "loss": 0.0031,
      "step": 33650
    },
    {
      "epoch": 10.385683431039803,
      "grad_norm": 0.0002786427503451705,
      "learning_rate": 3.96143165689602e-05,
      "loss": 0.005,
      "step": 33660
    },
    {
      "epoch": 10.38876889848812,
      "grad_norm": 0.011887523345649242,
      "learning_rate": 3.961123110151188e-05,
      "loss": 0.0016,
      "step": 33670
    },
    {
      "epoch": 10.391854365936439,
      "grad_norm": 0.4285352826118469,
      "learning_rate": 3.960814563406356e-05,
      "loss": 0.001,
      "step": 33680
    },
    {
      "epoch": 10.394939833384758,
      "grad_norm": 0.136636421084404,
      "learning_rate": 3.9605060166615245e-05,
      "loss": 0.0016,
      "step": 33690
    },
    {
      "epoch": 10.398025300833076,
      "grad_norm": 0.0037532257847487926,
      "learning_rate": 3.960197469916693e-05,
      "loss": 0.0037,
      "step": 33700
    },
    {
      "epoch": 10.401110768281395,
      "grad_norm": 0.13699018955230713,
      "learning_rate": 3.95988892317186e-05,
      "loss": 0.004,
      "step": 33710
    },
    {
      "epoch": 10.404196235729714,
      "grad_norm": 0.004845634568482637,
      "learning_rate": 3.959580376427029e-05,
      "loss": 0.013,
      "step": 33720
    },
    {
      "epoch": 10.40728170317803,
      "grad_norm": 1.1350594758987427,
      "learning_rate": 3.959271829682197e-05,
      "loss": 0.0029,
      "step": 33730
    },
    {
      "epoch": 10.41036717062635,
      "grad_norm": 0.2364838868379593,
      "learning_rate": 3.958963282937365e-05,
      "loss": 0.0017,
      "step": 33740
    },
    {
      "epoch": 10.413452638074668,
      "grad_norm": 0.35868141055107117,
      "learning_rate": 3.958654736192533e-05,
      "loss": 0.0033,
      "step": 33750
    },
    {
      "epoch": 10.416538105522987,
      "grad_norm": 2.4513869285583496,
      "learning_rate": 3.9583461894477016e-05,
      "loss": 0.0054,
      "step": 33760
    },
    {
      "epoch": 10.419623572971306,
      "grad_norm": 0.003515594406053424,
      "learning_rate": 3.95803764270287e-05,
      "loss": 0.0042,
      "step": 33770
    },
    {
      "epoch": 10.422709040419624,
      "grad_norm": 0.02941160835325718,
      "learning_rate": 3.9577290959580374e-05,
      "loss": 0.006,
      "step": 33780
    },
    {
      "epoch": 10.425794507867941,
      "grad_norm": 0.0006270503508858383,
      "learning_rate": 3.957420549213206e-05,
      "loss": 0.0049,
      "step": 33790
    },
    {
      "epoch": 10.42887997531626,
      "grad_norm": 0.0018190264236181974,
      "learning_rate": 3.957112002468374e-05,
      "loss": 0.0008,
      "step": 33800
    },
    {
      "epoch": 10.431965442764579,
      "grad_norm": 0.041452351957559586,
      "learning_rate": 3.956803455723542e-05,
      "loss": 0.0007,
      "step": 33810
    },
    {
      "epoch": 10.435050910212897,
      "grad_norm": 0.000550119555555284,
      "learning_rate": 3.9564949089787104e-05,
      "loss": 0.0022,
      "step": 33820
    },
    {
      "epoch": 10.438136377661216,
      "grad_norm": 0.051784854382276535,
      "learning_rate": 3.9561863622338786e-05,
      "loss": 0.0011,
      "step": 33830
    },
    {
      "epoch": 10.441221845109535,
      "grad_norm": 0.06539912521839142,
      "learning_rate": 3.955877815489047e-05,
      "loss": 0.0013,
      "step": 33840
    },
    {
      "epoch": 10.444307312557852,
      "grad_norm": 0.010296818800270557,
      "learning_rate": 3.9555692687442144e-05,
      "loss": 0.0157,
      "step": 33850
    },
    {
      "epoch": 10.44739278000617,
      "grad_norm": 0.000301226886222139,
      "learning_rate": 3.9552607219993834e-05,
      "loss": 0.0008,
      "step": 33860
    },
    {
      "epoch": 10.45047824745449,
      "grad_norm": 0.3038802444934845,
      "learning_rate": 3.9549521752545516e-05,
      "loss": 0.0066,
      "step": 33870
    },
    {
      "epoch": 10.453563714902808,
      "grad_norm": 0.0008785249083302915,
      "learning_rate": 3.954643628509719e-05,
      "loss": 0.0044,
      "step": 33880
    },
    {
      "epoch": 10.456649182351127,
      "grad_norm": 0.0016197143122553825,
      "learning_rate": 3.9543350817648874e-05,
      "loss": 0.0028,
      "step": 33890
    },
    {
      "epoch": 10.459734649799445,
      "grad_norm": 0.003103740280494094,
      "learning_rate": 3.954026535020056e-05,
      "loss": 0.0012,
      "step": 33900
    },
    {
      "epoch": 10.462820117247762,
      "grad_norm": 0.003170829266309738,
      "learning_rate": 3.953717988275224e-05,
      "loss": 0.0038,
      "step": 33910
    },
    {
      "epoch": 10.465905584696081,
      "grad_norm": 0.0014867429854348302,
      "learning_rate": 3.9534094415303915e-05,
      "loss": 0.0031,
      "step": 33920
    },
    {
      "epoch": 10.4689910521444,
      "grad_norm": 0.0003287121653556824,
      "learning_rate": 3.9531008947855604e-05,
      "loss": 0.0027,
      "step": 33930
    },
    {
      "epoch": 10.472076519592719,
      "grad_norm": 0.001663775066845119,
      "learning_rate": 3.952792348040729e-05,
      "loss": 0.0007,
      "step": 33940
    },
    {
      "epoch": 10.475161987041037,
      "grad_norm": 0.2541004419326782,
      "learning_rate": 3.952483801295896e-05,
      "loss": 0.0129,
      "step": 33950
    },
    {
      "epoch": 10.478247454489356,
      "grad_norm": 0.00045976447290740907,
      "learning_rate": 3.952175254551065e-05,
      "loss": 0.001,
      "step": 33960
    },
    {
      "epoch": 10.481332921937673,
      "grad_norm": 0.10931973904371262,
      "learning_rate": 3.951866707806233e-05,
      "loss": 0.0006,
      "step": 33970
    },
    {
      "epoch": 10.484418389385992,
      "grad_norm": 0.0001441061613149941,
      "learning_rate": 3.951558161061401e-05,
      "loss": 0.008,
      "step": 33980
    },
    {
      "epoch": 10.48750385683431,
      "grad_norm": 3.6704862117767334,
      "learning_rate": 3.951249614316569e-05,
      "loss": 0.0179,
      "step": 33990
    },
    {
      "epoch": 10.49058932428263,
      "grad_norm": 0.01719023287296295,
      "learning_rate": 3.9509410675717375e-05,
      "loss": 0.0002,
      "step": 34000
    },
    {
      "epoch": 10.493674791730948,
      "grad_norm": 0.04528692737221718,
      "learning_rate": 3.950632520826906e-05,
      "loss": 0.0023,
      "step": 34010
    },
    {
      "epoch": 10.496760259179265,
      "grad_norm": 0.00047960923984646797,
      "learning_rate": 3.950323974082073e-05,
      "loss": 0.0038,
      "step": 34020
    },
    {
      "epoch": 10.499845726627584,
      "grad_norm": 0.01780821569263935,
      "learning_rate": 3.950015427337242e-05,
      "loss": 0.0015,
      "step": 34030
    },
    {
      "epoch": 10.502931194075902,
      "grad_norm": 0.015691716223955154,
      "learning_rate": 3.94970688059241e-05,
      "loss": 0.002,
      "step": 34040
    },
    {
      "epoch": 10.506016661524221,
      "grad_norm": 1.788898229598999,
      "learning_rate": 3.949398333847578e-05,
      "loss": 0.0039,
      "step": 34050
    },
    {
      "epoch": 10.50910212897254,
      "grad_norm": 0.054392918944358826,
      "learning_rate": 3.949089787102746e-05,
      "loss": 0.0054,
      "step": 34060
    },
    {
      "epoch": 10.512187596420858,
      "grad_norm": 0.021648898720741272,
      "learning_rate": 3.9487812403579145e-05,
      "loss": 0.0023,
      "step": 34070
    },
    {
      "epoch": 10.515273063869175,
      "grad_norm": 0.00906901154667139,
      "learning_rate": 3.948472693613083e-05,
      "loss": 0.0003,
      "step": 34080
    },
    {
      "epoch": 10.518358531317494,
      "grad_norm": 0.0013077445328235626,
      "learning_rate": 3.9481641468682504e-05,
      "loss": 0.0024,
      "step": 34090
    },
    {
      "epoch": 10.521443998765813,
      "grad_norm": 0.3637451231479645,
      "learning_rate": 3.947855600123419e-05,
      "loss": 0.0014,
      "step": 34100
    },
    {
      "epoch": 10.524529466214132,
      "grad_norm": 0.02052711509168148,
      "learning_rate": 3.947547053378587e-05,
      "loss": 0.0195,
      "step": 34110
    },
    {
      "epoch": 10.52761493366245,
      "grad_norm": 0.1481267660856247,
      "learning_rate": 3.947238506633755e-05,
      "loss": 0.0107,
      "step": 34120
    },
    {
      "epoch": 10.530700401110769,
      "grad_norm": 0.31106871366500854,
      "learning_rate": 3.9469299598889233e-05,
      "loss": 0.0019,
      "step": 34130
    },
    {
      "epoch": 10.533785868559086,
      "grad_norm": 1.3563858270645142,
      "learning_rate": 3.9466214131440916e-05,
      "loss": 0.0028,
      "step": 34140
    },
    {
      "epoch": 10.536871336007405,
      "grad_norm": 0.008068830706179142,
      "learning_rate": 3.94631286639926e-05,
      "loss": 0.0101,
      "step": 34150
    },
    {
      "epoch": 10.539956803455723,
      "grad_norm": 0.009887957945466042,
      "learning_rate": 3.9460043196544274e-05,
      "loss": 0.0047,
      "step": 34160
    },
    {
      "epoch": 10.543042270904042,
      "grad_norm": 0.009927559643983841,
      "learning_rate": 3.945695772909596e-05,
      "loss": 0.0028,
      "step": 34170
    },
    {
      "epoch": 10.54612773835236,
      "grad_norm": 0.0017468312289565802,
      "learning_rate": 3.945387226164764e-05,
      "loss": 0.0082,
      "step": 34180
    },
    {
      "epoch": 10.54921320580068,
      "grad_norm": 6.932514952495694e-05,
      "learning_rate": 3.945078679419932e-05,
      "loss": 0.0023,
      "step": 34190
    },
    {
      "epoch": 10.552298673248997,
      "grad_norm": 0.4986386299133301,
      "learning_rate": 3.9447701326751004e-05,
      "loss": 0.0004,
      "step": 34200
    },
    {
      "epoch": 10.555384140697315,
      "grad_norm": 9.706901619210839e-05,
      "learning_rate": 3.9444615859302686e-05,
      "loss": 0.0019,
      "step": 34210
    },
    {
      "epoch": 10.558469608145634,
      "grad_norm": 0.01420646533370018,
      "learning_rate": 3.944153039185437e-05,
      "loss": 0.0002,
      "step": 34220
    },
    {
      "epoch": 10.561555075593953,
      "grad_norm": 0.031191011890769005,
      "learning_rate": 3.943844492440605e-05,
      "loss": 0.0022,
      "step": 34230
    },
    {
      "epoch": 10.564640543042271,
      "grad_norm": 0.0022023352794349194,
      "learning_rate": 3.9435359456957734e-05,
      "loss": 0.0064,
      "step": 34240
    },
    {
      "epoch": 10.56772601049059,
      "grad_norm": 2.4522008895874023,
      "learning_rate": 3.943227398950941e-05,
      "loss": 0.004,
      "step": 34250
    },
    {
      "epoch": 10.570811477938907,
      "grad_norm": 0.002161570591852069,
      "learning_rate": 3.942918852206109e-05,
      "loss": 0.0063,
      "step": 34260
    },
    {
      "epoch": 10.573896945387226,
      "grad_norm": 0.08317291736602783,
      "learning_rate": 3.9426103054612775e-05,
      "loss": 0.0015,
      "step": 34270
    },
    {
      "epoch": 10.576982412835545,
      "grad_norm": 0.03614930808544159,
      "learning_rate": 3.942301758716446e-05,
      "loss": 0.0042,
      "step": 34280
    },
    {
      "epoch": 10.580067880283863,
      "grad_norm": 0.017494458705186844,
      "learning_rate": 3.941993211971614e-05,
      "loss": 0.0025,
      "step": 34290
    },
    {
      "epoch": 10.583153347732182,
      "grad_norm": 0.41447821259498596,
      "learning_rate": 3.941684665226782e-05,
      "loss": 0.002,
      "step": 34300
    },
    {
      "epoch": 10.5862388151805,
      "grad_norm": 0.005584793630987406,
      "learning_rate": 3.9413761184819504e-05,
      "loss": 0.0096,
      "step": 34310
    },
    {
      "epoch": 10.589324282628818,
      "grad_norm": 6.234283924102783,
      "learning_rate": 3.941067571737118e-05,
      "loss": 0.0058,
      "step": 34320
    },
    {
      "epoch": 10.592409750077136,
      "grad_norm": 0.3656103312969208,
      "learning_rate": 3.940759024992286e-05,
      "loss": 0.0014,
      "step": 34330
    },
    {
      "epoch": 10.595495217525455,
      "grad_norm": 0.0034592491574585438,
      "learning_rate": 3.940450478247455e-05,
      "loss": 0.0021,
      "step": 34340
    },
    {
      "epoch": 10.598580684973774,
      "grad_norm": 1.028738021850586,
      "learning_rate": 3.940141931502623e-05,
      "loss": 0.0008,
      "step": 34350
    },
    {
      "epoch": 10.601666152422093,
      "grad_norm": 0.022272244095802307,
      "learning_rate": 3.939833384757791e-05,
      "loss": 0.0071,
      "step": 34360
    },
    {
      "epoch": 10.60475161987041,
      "grad_norm": 0.032454799860715866,
      "learning_rate": 3.939524838012959e-05,
      "loss": 0.0034,
      "step": 34370
    },
    {
      "epoch": 10.607837087318728,
      "grad_norm": 0.014746519736945629,
      "learning_rate": 3.9392162912681275e-05,
      "loss": 0.0097,
      "step": 34380
    },
    {
      "epoch": 10.610922554767047,
      "grad_norm": 0.00030164310010150075,
      "learning_rate": 3.938907744523295e-05,
      "loss": 0.0036,
      "step": 34390
    },
    {
      "epoch": 10.614008022215366,
      "grad_norm": 0.026592830196022987,
      "learning_rate": 3.938599197778463e-05,
      "loss": 0.0003,
      "step": 34400
    },
    {
      "epoch": 10.617093489663684,
      "grad_norm": 0.0018136956496164203,
      "learning_rate": 3.938290651033632e-05,
      "loss": 0.0007,
      "step": 34410
    },
    {
      "epoch": 10.620178957112003,
      "grad_norm": 0.3066673278808594,
      "learning_rate": 3.9379821042888e-05,
      "loss": 0.005,
      "step": 34420
    },
    {
      "epoch": 10.623264424560322,
      "grad_norm": 1.283119797706604,
      "learning_rate": 3.937673557543968e-05,
      "loss": 0.0054,
      "step": 34430
    },
    {
      "epoch": 10.626349892008639,
      "grad_norm": 0.049154721200466156,
      "learning_rate": 3.937365010799136e-05,
      "loss": 0.0014,
      "step": 34440
    },
    {
      "epoch": 10.629435359456957,
      "grad_norm": 0.34580183029174805,
      "learning_rate": 3.9370564640543046e-05,
      "loss": 0.0086,
      "step": 34450
    },
    {
      "epoch": 10.632520826905276,
      "grad_norm": 0.8704226016998291,
      "learning_rate": 3.936747917309472e-05,
      "loss": 0.0033,
      "step": 34460
    },
    {
      "epoch": 10.635606294353595,
      "grad_norm": 0.38309192657470703,
      "learning_rate": 3.936439370564641e-05,
      "loss": 0.0016,
      "step": 34470
    },
    {
      "epoch": 10.638691761801914,
      "grad_norm": 0.03716570883989334,
      "learning_rate": 3.936130823819809e-05,
      "loss": 0.0112,
      "step": 34480
    },
    {
      "epoch": 10.64177722925023,
      "grad_norm": 0.014634901657700539,
      "learning_rate": 3.935822277074977e-05,
      "loss": 0.0029,
      "step": 34490
    },
    {
      "epoch": 10.64486269669855,
      "grad_norm": 0.0017405501566827297,
      "learning_rate": 3.935513730330145e-05,
      "loss": 0.0027,
      "step": 34500
    },
    {
      "epoch": 10.647948164146868,
      "grad_norm": 0.42457717657089233,
      "learning_rate": 3.9352051835853134e-05,
      "loss": 0.0011,
      "step": 34510
    },
    {
      "epoch": 10.651033631595187,
      "grad_norm": 0.4243801236152649,
      "learning_rate": 3.9348966368404816e-05,
      "loss": 0.0009,
      "step": 34520
    },
    {
      "epoch": 10.654119099043506,
      "grad_norm": 0.00830069836229086,
      "learning_rate": 3.934588090095649e-05,
      "loss": 0.0003,
      "step": 34530
    },
    {
      "epoch": 10.657204566491824,
      "grad_norm": 1.240784764289856,
      "learning_rate": 3.934279543350818e-05,
      "loss": 0.0039,
      "step": 34540
    },
    {
      "epoch": 10.660290033940141,
      "grad_norm": 0.03760237619280815,
      "learning_rate": 3.9339709966059864e-05,
      "loss": 0.0012,
      "step": 34550
    },
    {
      "epoch": 10.66337550138846,
      "grad_norm": 0.045115694403648376,
      "learning_rate": 3.933662449861154e-05,
      "loss": 0.002,
      "step": 34560
    },
    {
      "epoch": 10.666460968836779,
      "grad_norm": 0.0004666320455726236,
      "learning_rate": 3.933353903116322e-05,
      "loss": 0.0004,
      "step": 34570
    },
    {
      "epoch": 10.669546436285097,
      "grad_norm": 0.0005160461878404021,
      "learning_rate": 3.9330453563714904e-05,
      "loss": 0.0004,
      "step": 34580
    },
    {
      "epoch": 10.672631903733416,
      "grad_norm": 0.003980397246778011,
      "learning_rate": 3.932736809626659e-05,
      "loss": 0.0051,
      "step": 34590
    },
    {
      "epoch": 10.675717371181735,
      "grad_norm": 0.002168122446164489,
      "learning_rate": 3.932428262881826e-05,
      "loss": 0.0045,
      "step": 34600
    },
    {
      "epoch": 10.678802838630052,
      "grad_norm": 0.32599982619285583,
      "learning_rate": 3.932119716136995e-05,
      "loss": 0.0015,
      "step": 34610
    },
    {
      "epoch": 10.68188830607837,
      "grad_norm": 0.0017375238239765167,
      "learning_rate": 3.9318111693921634e-05,
      "loss": 0.0013,
      "step": 34620
    },
    {
      "epoch": 10.68497377352669,
      "grad_norm": 1.8664886951446533,
      "learning_rate": 3.931502622647331e-05,
      "loss": 0.0056,
      "step": 34630
    },
    {
      "epoch": 10.688059240975008,
      "grad_norm": 0.07975314557552338,
      "learning_rate": 3.931194075902499e-05,
      "loss": 0.0027,
      "step": 34640
    },
    {
      "epoch": 10.691144708423327,
      "grad_norm": 0.002674610586836934,
      "learning_rate": 3.9308855291576675e-05,
      "loss": 0.0056,
      "step": 34650
    },
    {
      "epoch": 10.694230175871645,
      "grad_norm": 0.01482411753386259,
      "learning_rate": 3.930576982412836e-05,
      "loss": 0.0106,
      "step": 34660
    },
    {
      "epoch": 10.697315643319962,
      "grad_norm": 0.011704785749316216,
      "learning_rate": 3.930268435668003e-05,
      "loss": 0.0021,
      "step": 34670
    },
    {
      "epoch": 10.700401110768281,
      "grad_norm": 0.00014309676771517843,
      "learning_rate": 3.929959888923172e-05,
      "loss": 0.0004,
      "step": 34680
    },
    {
      "epoch": 10.7034865782166,
      "grad_norm": 0.02768450416624546,
      "learning_rate": 3.9296513421783405e-05,
      "loss": 0.007,
      "step": 34690
    },
    {
      "epoch": 10.706572045664918,
      "grad_norm": 0.07928555458784103,
      "learning_rate": 3.929342795433508e-05,
      "loss": 0.0015,
      "step": 34700
    },
    {
      "epoch": 10.709657513113237,
      "grad_norm": 0.08286885172128677,
      "learning_rate": 3.929034248688677e-05,
      "loss": 0.0048,
      "step": 34710
    },
    {
      "epoch": 10.712742980561554,
      "grad_norm": 0.0031410842202603817,
      "learning_rate": 3.9287257019438445e-05,
      "loss": 0.0029,
      "step": 34720
    },
    {
      "epoch": 10.715828448009873,
      "grad_norm": 3.3573310375213623,
      "learning_rate": 3.928417155199013e-05,
      "loss": 0.0021,
      "step": 34730
    },
    {
      "epoch": 10.718913915458192,
      "grad_norm": 0.00011619555880315602,
      "learning_rate": 3.928108608454181e-05,
      "loss": 0.0002,
      "step": 34740
    },
    {
      "epoch": 10.72199938290651,
      "grad_norm": 1.858292579650879,
      "learning_rate": 3.927800061709349e-05,
      "loss": 0.0039,
      "step": 34750
    },
    {
      "epoch": 10.725084850354829,
      "grad_norm": 0.013611029833555222,
      "learning_rate": 3.9274915149645175e-05,
      "loss": 0.0028,
      "step": 34760
    },
    {
      "epoch": 10.728170317803148,
      "grad_norm": 2.804820724122692e-05,
      "learning_rate": 3.927182968219685e-05,
      "loss": 0.0017,
      "step": 34770
    },
    {
      "epoch": 10.731255785251467,
      "grad_norm": 0.0010867469245567918,
      "learning_rate": 3.926874421474854e-05,
      "loss": 0.0004,
      "step": 34780
    },
    {
      "epoch": 10.734341252699783,
      "grad_norm": 0.010950044728815556,
      "learning_rate": 3.9265658747300216e-05,
      "loss": 0.0162,
      "step": 34790
    },
    {
      "epoch": 10.737426720148102,
      "grad_norm": 0.00038815781590528786,
      "learning_rate": 3.92625732798519e-05,
      "loss": 0.0001,
      "step": 34800
    },
    {
      "epoch": 10.740512187596421,
      "grad_norm": 0.001000614371150732,
      "learning_rate": 3.925948781240358e-05,
      "loss": 0.0055,
      "step": 34810
    },
    {
      "epoch": 10.74359765504474,
      "grad_norm": 1.9482600688934326,
      "learning_rate": 3.925640234495526e-05,
      "loss": 0.0081,
      "step": 34820
    },
    {
      "epoch": 10.746683122493058,
      "grad_norm": 0.019078616052865982,
      "learning_rate": 3.9253316877506946e-05,
      "loss": 0.0001,
      "step": 34830
    },
    {
      "epoch": 10.749768589941375,
      "grad_norm": 0.004782683216035366,
      "learning_rate": 3.925023141005862e-05,
      "loss": 0.0006,
      "step": 34840
    },
    {
      "epoch": 10.752854057389694,
      "grad_norm": 0.06930018216371536,
      "learning_rate": 3.924714594261031e-05,
      "loss": 0.0003,
      "step": 34850
    },
    {
      "epoch": 10.755939524838013,
      "grad_norm": 0.06822560727596283,
      "learning_rate": 3.9244060475161987e-05,
      "loss": 0.001,
      "step": 34860
    },
    {
      "epoch": 10.759024992286331,
      "grad_norm": 0.014408683404326439,
      "learning_rate": 3.924097500771367e-05,
      "loss": 0.0013,
      "step": 34870
    },
    {
      "epoch": 10.76211045973465,
      "grad_norm": 0.02565457858145237,
      "learning_rate": 3.923788954026535e-05,
      "loss": 0.0001,
      "step": 34880
    },
    {
      "epoch": 10.765195927182969,
      "grad_norm": 0.004946182947605848,
      "learning_rate": 3.9234804072817034e-05,
      "loss": 0.0003,
      "step": 34890
    },
    {
      "epoch": 10.768281394631286,
      "grad_norm": 3.0415210723876953,
      "learning_rate": 3.9231718605368716e-05,
      "loss": 0.0019,
      "step": 34900
    },
    {
      "epoch": 10.771366862079605,
      "grad_norm": 0.000675646704621613,
      "learning_rate": 3.922863313792039e-05,
      "loss": 0.0054,
      "step": 34910
    },
    {
      "epoch": 10.774452329527923,
      "grad_norm": 0.04421915486454964,
      "learning_rate": 3.922554767047208e-05,
      "loss": 0.001,
      "step": 34920
    },
    {
      "epoch": 10.777537796976242,
      "grad_norm": 1.9939221143722534,
      "learning_rate": 3.922246220302376e-05,
      "loss": 0.0046,
      "step": 34930
    },
    {
      "epoch": 10.78062326442456,
      "grad_norm": 0.0035986069124192,
      "learning_rate": 3.921937673557544e-05,
      "loss": 0.0008,
      "step": 34940
    },
    {
      "epoch": 10.78370873187288,
      "grad_norm": 0.0007026430102996528,
      "learning_rate": 3.921629126812713e-05,
      "loss": 0.001,
      "step": 34950
    },
    {
      "epoch": 10.786794199321196,
      "grad_norm": 0.08506177365779877,
      "learning_rate": 3.9213205800678805e-05,
      "loss": 0.0038,
      "step": 34960
    },
    {
      "epoch": 10.789879666769515,
      "grad_norm": 0.14623551070690155,
      "learning_rate": 3.921012033323049e-05,
      "loss": 0.0091,
      "step": 34970
    },
    {
      "epoch": 10.792965134217834,
      "grad_norm": 0.1864195466041565,
      "learning_rate": 3.920703486578217e-05,
      "loss": 0.0006,
      "step": 34980
    },
    {
      "epoch": 10.796050601666153,
      "grad_norm": 0.24490635097026825,
      "learning_rate": 3.920394939833385e-05,
      "loss": 0.0023,
      "step": 34990
    },
    {
      "epoch": 10.799136069114471,
      "grad_norm": 1.1152245998382568,
      "learning_rate": 3.920086393088553e-05,
      "loss": 0.004,
      "step": 35000
    },
    {
      "epoch": 10.80222153656279,
      "grad_norm": 0.049139272421598434,
      "learning_rate": 3.919777846343721e-05,
      "loss": 0.0113,
      "step": 35010
    },
    {
      "epoch": 10.805307004011107,
      "grad_norm": 0.03459218144416809,
      "learning_rate": 3.91946929959889e-05,
      "loss": 0.0034,
      "step": 35020
    },
    {
      "epoch": 10.808392471459426,
      "grad_norm": 0.1373266875743866,
      "learning_rate": 3.9191607528540575e-05,
      "loss": 0.002,
      "step": 35030
    },
    {
      "epoch": 10.811477938907744,
      "grad_norm": 0.021961385384202003,
      "learning_rate": 3.918852206109226e-05,
      "loss": 0.0087,
      "step": 35040
    },
    {
      "epoch": 10.814563406356063,
      "grad_norm": 0.000719027069862932,
      "learning_rate": 3.918543659364394e-05,
      "loss": 0.0011,
      "step": 35050
    },
    {
      "epoch": 10.817648873804382,
      "grad_norm": 0.003857620758935809,
      "learning_rate": 3.918235112619562e-05,
      "loss": 0.0005,
      "step": 35060
    },
    {
      "epoch": 10.8207343412527,
      "grad_norm": 0.0032685252372175455,
      "learning_rate": 3.91792656587473e-05,
      "loss": 0.0016,
      "step": 35070
    },
    {
      "epoch": 10.823819808701018,
      "grad_norm": 0.001828534179367125,
      "learning_rate": 3.917618019129898e-05,
      "loss": 0.0018,
      "step": 35080
    },
    {
      "epoch": 10.826905276149336,
      "grad_norm": 0.018479159101843834,
      "learning_rate": 3.917309472385067e-05,
      "loss": 0.0036,
      "step": 35090
    },
    {
      "epoch": 10.829990743597655,
      "grad_norm": 2.3816418647766113,
      "learning_rate": 3.9170009256402346e-05,
      "loss": 0.0062,
      "step": 35100
    },
    {
      "epoch": 10.833076211045974,
      "grad_norm": 0.012961059808731079,
      "learning_rate": 3.916692378895403e-05,
      "loss": 0.0126,
      "step": 35110
    },
    {
      "epoch": 10.836161678494292,
      "grad_norm": 0.010597904212772846,
      "learning_rate": 3.916383832150571e-05,
      "loss": 0.0087,
      "step": 35120
    },
    {
      "epoch": 10.839247145942611,
      "grad_norm": 0.07395894080400467,
      "learning_rate": 3.916075285405739e-05,
      "loss": 0.0112,
      "step": 35130
    },
    {
      "epoch": 10.842332613390928,
      "grad_norm": 0.0412837378680706,
      "learning_rate": 3.915766738660907e-05,
      "loss": 0.005,
      "step": 35140
    },
    {
      "epoch": 10.845418080839247,
      "grad_norm": 0.315346360206604,
      "learning_rate": 3.915458191916075e-05,
      "loss": 0.0014,
      "step": 35150
    },
    {
      "epoch": 10.848503548287566,
      "grad_norm": 1.3356126546859741,
      "learning_rate": 3.915149645171244e-05,
      "loss": 0.0024,
      "step": 35160
    },
    {
      "epoch": 10.851589015735884,
      "grad_norm": 0.12116994708776474,
      "learning_rate": 3.9148410984264116e-05,
      "loss": 0.0031,
      "step": 35170
    },
    {
      "epoch": 10.854674483184203,
      "grad_norm": 0.8882165551185608,
      "learning_rate": 3.91453255168158e-05,
      "loss": 0.0039,
      "step": 35180
    },
    {
      "epoch": 10.85775995063252,
      "grad_norm": 0.011826058849692345,
      "learning_rate": 3.914224004936748e-05,
      "loss": 0.0009,
      "step": 35190
    },
    {
      "epoch": 10.860845418080839,
      "grad_norm": 0.22478041052818298,
      "learning_rate": 3.9139154581919164e-05,
      "loss": 0.0011,
      "step": 35200
    },
    {
      "epoch": 10.863930885529157,
      "grad_norm": 0.5949952602386475,
      "learning_rate": 3.9136069114470846e-05,
      "loss": 0.001,
      "step": 35210
    },
    {
      "epoch": 10.867016352977476,
      "grad_norm": 0.20468084514141083,
      "learning_rate": 3.913298364702253e-05,
      "loss": 0.0021,
      "step": 35220
    },
    {
      "epoch": 10.870101820425795,
      "grad_norm": 0.03608004376292229,
      "learning_rate": 3.912989817957421e-05,
      "loss": 0.0052,
      "step": 35230
    },
    {
      "epoch": 10.873187287874114,
      "grad_norm": 0.021642034873366356,
      "learning_rate": 3.912681271212589e-05,
      "loss": 0.0008,
      "step": 35240
    },
    {
      "epoch": 10.87627275532243,
      "grad_norm": 0.00742677366361022,
      "learning_rate": 3.912372724467757e-05,
      "loss": 0.0025,
      "step": 35250
    },
    {
      "epoch": 10.87935822277075,
      "grad_norm": 0.0017328127287328243,
      "learning_rate": 3.912064177722925e-05,
      "loss": 0.0034,
      "step": 35260
    },
    {
      "epoch": 10.882443690219068,
      "grad_norm": 0.10779552161693573,
      "learning_rate": 3.9117556309780934e-05,
      "loss": 0.0012,
      "step": 35270
    },
    {
      "epoch": 10.885529157667387,
      "grad_norm": 0.023599084466695786,
      "learning_rate": 3.911447084233262e-05,
      "loss": 0.0011,
      "step": 35280
    },
    {
      "epoch": 10.888614625115705,
      "grad_norm": 0.0029308574739843607,
      "learning_rate": 3.91113853748843e-05,
      "loss": 0.006,
      "step": 35290
    },
    {
      "epoch": 10.891700092564024,
      "grad_norm": 0.1400717943906784,
      "learning_rate": 3.910829990743598e-05,
      "loss": 0.0018,
      "step": 35300
    },
    {
      "epoch": 10.894785560012341,
      "grad_norm": 0.10653652995824814,
      "learning_rate": 3.910521443998766e-05,
      "loss": 0.0095,
      "step": 35310
    },
    {
      "epoch": 10.89787102746066,
      "grad_norm": 1.6293262888211757e-05,
      "learning_rate": 3.910212897253934e-05,
      "loss": 0.0182,
      "step": 35320
    },
    {
      "epoch": 10.900956494908979,
      "grad_norm": 0.0075275227427482605,
      "learning_rate": 3.909904350509102e-05,
      "loss": 0.0002,
      "step": 35330
    },
    {
      "epoch": 10.904041962357297,
      "grad_norm": 0.0009651387226767838,
      "learning_rate": 3.9095958037642705e-05,
      "loss": 0.0006,
      "step": 35340
    },
    {
      "epoch": 10.907127429805616,
      "grad_norm": 0.14062662422657013,
      "learning_rate": 3.909287257019439e-05,
      "loss": 0.0009,
      "step": 35350
    },
    {
      "epoch": 10.910212897253935,
      "grad_norm": 0.0001000498523353599,
      "learning_rate": 3.908978710274607e-05,
      "loss": 0.0035,
      "step": 35360
    },
    {
      "epoch": 10.913298364702252,
      "grad_norm": 0.052343059331178665,
      "learning_rate": 3.908670163529775e-05,
      "loss": 0.0016,
      "step": 35370
    },
    {
      "epoch": 10.91638383215057,
      "grad_norm": 0.00032067150459624827,
      "learning_rate": 3.908361616784943e-05,
      "loss": 0.0017,
      "step": 35380
    },
    {
      "epoch": 10.91946929959889,
      "grad_norm": 0.022724714130163193,
      "learning_rate": 3.908053070040111e-05,
      "loss": 0.0008,
      "step": 35390
    },
    {
      "epoch": 10.922554767047208,
      "grad_norm": 0.00012394193618092686,
      "learning_rate": 3.907744523295279e-05,
      "loss": 0.0031,
      "step": 35400
    },
    {
      "epoch": 10.925640234495527,
      "grad_norm": 0.006059959530830383,
      "learning_rate": 3.9074359765504475e-05,
      "loss": 0.0005,
      "step": 35410
    },
    {
      "epoch": 10.928725701943845,
      "grad_norm": 0.02388017438352108,
      "learning_rate": 3.907127429805616e-05,
      "loss": 0.0075,
      "step": 35420
    },
    {
      "epoch": 10.931811169392162,
      "grad_norm": 0.48471930623054504,
      "learning_rate": 3.906818883060784e-05,
      "loss": 0.0024,
      "step": 35430
    },
    {
      "epoch": 10.934896636840481,
      "grad_norm": 0.005669230595231056,
      "learning_rate": 3.906510336315952e-05,
      "loss": 0.0013,
      "step": 35440
    },
    {
      "epoch": 10.9379821042888,
      "grad_norm": 9.006149291992188,
      "learning_rate": 3.90620178957112e-05,
      "loss": 0.014,
      "step": 35450
    },
    {
      "epoch": 10.941067571737118,
      "grad_norm": 0.015810659155249596,
      "learning_rate": 3.905893242826289e-05,
      "loss": 0.0001,
      "step": 35460
    },
    {
      "epoch": 10.944153039185437,
      "grad_norm": 0.0026671343948692083,
      "learning_rate": 3.9055846960814563e-05,
      "loss": 0.0017,
      "step": 35470
    },
    {
      "epoch": 10.947238506633756,
      "grad_norm": 0.072724349796772,
      "learning_rate": 3.9052761493366246e-05,
      "loss": 0.005,
      "step": 35480
    },
    {
      "epoch": 10.950323974082073,
      "grad_norm": 2.087139129638672,
      "learning_rate": 3.904967602591793e-05,
      "loss": 0.0052,
      "step": 35490
    },
    {
      "epoch": 10.953409441530392,
      "grad_norm": 0.04638795182108879,
      "learning_rate": 3.904659055846961e-05,
      "loss": 0.0009,
      "step": 35500
    },
    {
      "epoch": 10.95649490897871,
      "grad_norm": 1.6517846584320068,
      "learning_rate": 3.904350509102129e-05,
      "loss": 0.0088,
      "step": 35510
    },
    {
      "epoch": 10.959580376427029,
      "grad_norm": 0.014295791275799274,
      "learning_rate": 3.904041962357297e-05,
      "loss": 0.0006,
      "step": 35520
    },
    {
      "epoch": 10.962665843875348,
      "grad_norm": 0.0012233343441039324,
      "learning_rate": 3.903733415612466e-05,
      "loss": 0.0007,
      "step": 35530
    },
    {
      "epoch": 10.965751311323665,
      "grad_norm": 1.758986234664917,
      "learning_rate": 3.9034248688676334e-05,
      "loss": 0.0054,
      "step": 35540
    },
    {
      "epoch": 10.968836778771983,
      "grad_norm": 0.000946488871704787,
      "learning_rate": 3.9031163221228016e-05,
      "loss": 0.0008,
      "step": 35550
    },
    {
      "epoch": 10.971922246220302,
      "grad_norm": 0.04462571069598198,
      "learning_rate": 3.90280777537797e-05,
      "loss": 0.0005,
      "step": 35560
    },
    {
      "epoch": 10.97500771366862,
      "grad_norm": 0.0017630783841013908,
      "learning_rate": 3.902499228633138e-05,
      "loss": 0.0004,
      "step": 35570
    },
    {
      "epoch": 10.97809318111694,
      "grad_norm": 0.024075984954833984,
      "learning_rate": 3.9021906818883064e-05,
      "loss": 0.0033,
      "step": 35580
    },
    {
      "epoch": 10.981178648565258,
      "grad_norm": 0.012795744463801384,
      "learning_rate": 3.901882135143474e-05,
      "loss": 0.0002,
      "step": 35590
    },
    {
      "epoch": 10.984264116013577,
      "grad_norm": 0.03780914470553398,
      "learning_rate": 3.901573588398643e-05,
      "loss": 0.0021,
      "step": 35600
    },
    {
      "epoch": 10.987349583461894,
      "grad_norm": 0.0030598246958106756,
      "learning_rate": 3.901265041653811e-05,
      "loss": 0.0027,
      "step": 35610
    },
    {
      "epoch": 10.990435050910213,
      "grad_norm": 0.003046542638912797,
      "learning_rate": 3.900956494908979e-05,
      "loss": 0.0045,
      "step": 35620
    },
    {
      "epoch": 10.993520518358531,
      "grad_norm": 0.0035419354680925608,
      "learning_rate": 3.900647948164147e-05,
      "loss": 0.0033,
      "step": 35630
    },
    {
      "epoch": 10.99660598580685,
      "grad_norm": 0.0032991052139550447,
      "learning_rate": 3.900339401419315e-05,
      "loss": 0.0012,
      "step": 35640
    },
    {
      "epoch": 10.999691453255169,
      "grad_norm": 4.5614968257723376e-05,
      "learning_rate": 3.9000308546744834e-05,
      "loss": 0.0044,
      "step": 35650
    },
    {
      "epoch": 11.0,
      "eval_accuracy_branch1": 0.9992284173876141,
      "eval_accuracy_branch2": 0.48898083581686486,
      "eval_f1_branch1": 0.9990538673928498,
      "eval_f1_branch2": 0.48448837462847333,
      "eval_loss": 0.00042501738062128425,
      "eval_precision_branch1": 0.9991108246375966,
      "eval_precision_branch2": 0.5137139611749569,
      "eval_recall_branch1": 0.9989987376856688,
      "eval_recall_branch2": 0.5150964960504615,
      "eval_runtime": 238.1164,
      "eval_samples_per_second": 435.43,
      "eval_steps_per_second": 54.431,
      "step": 35651
    },
    {
      "epoch": 11.002776920703486,
      "grad_norm": 0.0009773384081199765,
      "learning_rate": 3.899722307929651e-05,
      "loss": 0.0218,
      "step": 35660
    },
    {
      "epoch": 11.005862388151805,
      "grad_norm": 0.01848594658076763,
      "learning_rate": 3.89941376118482e-05,
      "loss": 0.0115,
      "step": 35670
    },
    {
      "epoch": 11.008947855600123,
      "grad_norm": 0.002736567985266447,
      "learning_rate": 3.899105214439988e-05,
      "loss": 0.001,
      "step": 35680
    },
    {
      "epoch": 11.012033323048442,
      "grad_norm": 0.002488924888893962,
      "learning_rate": 3.898796667695156e-05,
      "loss": 0.0038,
      "step": 35690
    },
    {
      "epoch": 11.01511879049676,
      "grad_norm": 1.1230734586715698,
      "learning_rate": 3.898488120950324e-05,
      "loss": 0.0013,
      "step": 35700
    },
    {
      "epoch": 11.01820425794508,
      "grad_norm": 0.05164794251322746,
      "learning_rate": 3.898179574205492e-05,
      "loss": 0.0002,
      "step": 35710
    },
    {
      "epoch": 11.021289725393396,
      "grad_norm": 0.00020832711015827954,
      "learning_rate": 3.8978710274606605e-05,
      "loss": 0.0057,
      "step": 35720
    },
    {
      "epoch": 11.024375192841715,
      "grad_norm": 0.09642981737852097,
      "learning_rate": 3.897562480715829e-05,
      "loss": 0.0038,
      "step": 35730
    },
    {
      "epoch": 11.027460660290034,
      "grad_norm": 0.0011170754441991448,
      "learning_rate": 3.897253933970997e-05,
      "loss": 0.0009,
      "step": 35740
    },
    {
      "epoch": 11.030546127738353,
      "grad_norm": 1.4365525245666504,
      "learning_rate": 3.896945387226165e-05,
      "loss": 0.0082,
      "step": 35750
    },
    {
      "epoch": 11.033631595186671,
      "grad_norm": 0.01604532077908516,
      "learning_rate": 3.896636840481333e-05,
      "loss": 0.0003,
      "step": 35760
    },
    {
      "epoch": 11.03671706263499,
      "grad_norm": 0.002035923069342971,
      "learning_rate": 3.896328293736502e-05,
      "loss": 0.0002,
      "step": 35770
    },
    {
      "epoch": 11.039802530083307,
      "grad_norm": 0.05570626258850098,
      "learning_rate": 3.896019746991669e-05,
      "loss": 0.0022,
      "step": 35780
    },
    {
      "epoch": 11.042887997531626,
      "grad_norm": 0.04582815244793892,
      "learning_rate": 3.8957112002468376e-05,
      "loss": 0.0013,
      "step": 35790
    },
    {
      "epoch": 11.045973464979944,
      "grad_norm": 0.016080766916275024,
      "learning_rate": 3.895402653502006e-05,
      "loss": 0.0015,
      "step": 35800
    },
    {
      "epoch": 11.049058932428263,
      "grad_norm": 0.011953994631767273,
      "learning_rate": 3.895094106757174e-05,
      "loss": 0.007,
      "step": 35810
    },
    {
      "epoch": 11.052144399876582,
      "grad_norm": 0.029571566730737686,
      "learning_rate": 3.894785560012342e-05,
      "loss": 0.0122,
      "step": 35820
    },
    {
      "epoch": 11.0552298673249,
      "grad_norm": 0.00567777780815959,
      "learning_rate": 3.89447701326751e-05,
      "loss": 0.0003,
      "step": 35830
    },
    {
      "epoch": 11.058315334773217,
      "grad_norm": 0.003326914506033063,
      "learning_rate": 3.894168466522679e-05,
      "loss": 0.0105,
      "step": 35840
    },
    {
      "epoch": 11.061400802221536,
      "grad_norm": 0.03663905709981918,
      "learning_rate": 3.8938599197778464e-05,
      "loss": 0.009,
      "step": 35850
    },
    {
      "epoch": 11.064486269669855,
      "grad_norm": 0.00012188508117105812,
      "learning_rate": 3.8935513730330146e-05,
      "loss": 0.0014,
      "step": 35860
    },
    {
      "epoch": 11.067571737118174,
      "grad_norm": 0.4823857545852661,
      "learning_rate": 3.893242826288183e-05,
      "loss": 0.0028,
      "step": 35870
    },
    {
      "epoch": 11.070657204566492,
      "grad_norm": 0.0476086288690567,
      "learning_rate": 3.892934279543351e-05,
      "loss": 0.0044,
      "step": 35880
    },
    {
      "epoch": 11.073742672014811,
      "grad_norm": 1.0572420358657837,
      "learning_rate": 3.8926257327985194e-05,
      "loss": 0.0031,
      "step": 35890
    },
    {
      "epoch": 11.076828139463128,
      "grad_norm": 0.008998429402709007,
      "learning_rate": 3.892317186053687e-05,
      "loss": 0.0004,
      "step": 35900
    },
    {
      "epoch": 11.079913606911447,
      "grad_norm": 1.0383538007736206,
      "learning_rate": 3.892008639308856e-05,
      "loss": 0.0087,
      "step": 35910
    },
    {
      "epoch": 11.082999074359766,
      "grad_norm": 0.000880497507750988,
      "learning_rate": 3.8917000925640234e-05,
      "loss": 0.0005,
      "step": 35920
    },
    {
      "epoch": 11.086084541808084,
      "grad_norm": 0.0009228985873050988,
      "learning_rate": 3.891391545819192e-05,
      "loss": 0.0012,
      "step": 35930
    },
    {
      "epoch": 11.089170009256403,
      "grad_norm": 0.003304372075945139,
      "learning_rate": 3.89108299907436e-05,
      "loss": 0.0017,
      "step": 35940
    },
    {
      "epoch": 11.09225547670472,
      "grad_norm": 0.8712889552116394,
      "learning_rate": 3.890774452329528e-05,
      "loss": 0.0007,
      "step": 35950
    },
    {
      "epoch": 11.095340944153039,
      "grad_norm": 0.02573350816965103,
      "learning_rate": 3.8904659055846964e-05,
      "loss": 0.0003,
      "step": 35960
    },
    {
      "epoch": 11.098426411601357,
      "grad_norm": 0.009806307032704353,
      "learning_rate": 3.890157358839864e-05,
      "loss": 0.0004,
      "step": 35970
    },
    {
      "epoch": 11.101511879049676,
      "grad_norm": 0.2586680054664612,
      "learning_rate": 3.889848812095033e-05,
      "loss": 0.0006,
      "step": 35980
    },
    {
      "epoch": 11.104597346497995,
      "grad_norm": 2.6592013835906982,
      "learning_rate": 3.8895402653502005e-05,
      "loss": 0.0031,
      "step": 35990
    },
    {
      "epoch": 11.107682813946314,
      "grad_norm": 0.0021617908496409655,
      "learning_rate": 3.889231718605369e-05,
      "loss": 0.0088,
      "step": 36000
    },
    {
      "epoch": 11.11076828139463,
      "grad_norm": 0.009930802509188652,
      "learning_rate": 3.888923171860537e-05,
      "loss": 0.0025,
      "step": 36010
    },
    {
      "epoch": 11.11385374884295,
      "grad_norm": 0.7165409922599792,
      "learning_rate": 3.888614625115705e-05,
      "loss": 0.0011,
      "step": 36020
    },
    {
      "epoch": 11.116939216291268,
      "grad_norm": 0.0003544192877598107,
      "learning_rate": 3.8883060783708735e-05,
      "loss": 0.022,
      "step": 36030
    },
    {
      "epoch": 11.120024683739587,
      "grad_norm": 0.4113890826702118,
      "learning_rate": 3.887997531626042e-05,
      "loss": 0.001,
      "step": 36040
    },
    {
      "epoch": 11.123110151187905,
      "grad_norm": 0.032319214195013046,
      "learning_rate": 3.88768898488121e-05,
      "loss": 0.0011,
      "step": 36050
    },
    {
      "epoch": 11.126195618636224,
      "grad_norm": 0.005675386171787977,
      "learning_rate": 3.8873804381363775e-05,
      "loss": 0.0004,
      "step": 36060
    },
    {
      "epoch": 11.129281086084541,
      "grad_norm": 0.045024324208498,
      "learning_rate": 3.887071891391546e-05,
      "loss": 0.001,
      "step": 36070
    },
    {
      "epoch": 11.13236655353286,
      "grad_norm": 1.024048924446106,
      "learning_rate": 3.886763344646715e-05,
      "loss": 0.0014,
      "step": 36080
    },
    {
      "epoch": 11.135452020981178,
      "grad_norm": 0.00013180295354686677,
      "learning_rate": 3.886454797901882e-05,
      "loss": 0.0044,
      "step": 36090
    },
    {
      "epoch": 11.138537488429497,
      "grad_norm": 3.036836862564087,
      "learning_rate": 3.8861462511570505e-05,
      "loss": 0.0049,
      "step": 36100
    },
    {
      "epoch": 11.141622955877816,
      "grad_norm": 1.7609632015228271,
      "learning_rate": 3.885837704412219e-05,
      "loss": 0.0027,
      "step": 36110
    },
    {
      "epoch": 11.144708423326135,
      "grad_norm": 0.007116079796105623,
      "learning_rate": 3.885529157667387e-05,
      "loss": 0.0016,
      "step": 36120
    },
    {
      "epoch": 11.147793890774452,
      "grad_norm": 2.4414546489715576,
      "learning_rate": 3.8852206109225546e-05,
      "loss": 0.0123,
      "step": 36130
    },
    {
      "epoch": 11.15087935822277,
      "grad_norm": 0.0002722865028772503,
      "learning_rate": 3.884912064177723e-05,
      "loss": 0.0006,
      "step": 36140
    },
    {
      "epoch": 11.153964825671089,
      "grad_norm": 0.21172749996185303,
      "learning_rate": 3.884603517432892e-05,
      "loss": 0.0002,
      "step": 36150
    },
    {
      "epoch": 11.157050293119408,
      "grad_norm": 0.3566407263278961,
      "learning_rate": 3.884294970688059e-05,
      "loss": 0.0085,
      "step": 36160
    },
    {
      "epoch": 11.160135760567726,
      "grad_norm": 0.03913828358054161,
      "learning_rate": 3.8839864239432276e-05,
      "loss": 0.0025,
      "step": 36170
    },
    {
      "epoch": 11.163221228016045,
      "grad_norm": 0.09034688770771027,
      "learning_rate": 3.883677877198396e-05,
      "loss": 0.0104,
      "step": 36180
    },
    {
      "epoch": 11.166306695464362,
      "grad_norm": 1.7075893878936768,
      "learning_rate": 3.883369330453564e-05,
      "loss": 0.0092,
      "step": 36190
    },
    {
      "epoch": 11.16939216291268,
      "grad_norm": 0.01610580086708069,
      "learning_rate": 3.8830607837087316e-05,
      "loss": 0.0025,
      "step": 36200
    },
    {
      "epoch": 11.172477630361,
      "grad_norm": 0.4706505537033081,
      "learning_rate": 3.8827522369639e-05,
      "loss": 0.0022,
      "step": 36210
    },
    {
      "epoch": 11.175563097809318,
      "grad_norm": 1.3728506565093994,
      "learning_rate": 3.882443690219069e-05,
      "loss": 0.0134,
      "step": 36220
    },
    {
      "epoch": 11.178648565257637,
      "grad_norm": 0.14204202592372894,
      "learning_rate": 3.8821351434742364e-05,
      "loss": 0.0016,
      "step": 36230
    },
    {
      "epoch": 11.181734032705956,
      "grad_norm": 0.7566902041435242,
      "learning_rate": 3.8818265967294046e-05,
      "loss": 0.0046,
      "step": 36240
    },
    {
      "epoch": 11.184819500154273,
      "grad_norm": 0.03972967714071274,
      "learning_rate": 3.881518049984573e-05,
      "loss": 0.004,
      "step": 36250
    },
    {
      "epoch": 11.187904967602591,
      "grad_norm": 0.021931063383817673,
      "learning_rate": 3.881209503239741e-05,
      "loss": 0.0003,
      "step": 36260
    },
    {
      "epoch": 11.19099043505091,
      "grad_norm": 0.03642972931265831,
      "learning_rate": 3.880900956494909e-05,
      "loss": 0.0131,
      "step": 36270
    },
    {
      "epoch": 11.194075902499229,
      "grad_norm": 0.010176503099501133,
      "learning_rate": 3.8805924097500776e-05,
      "loss": 0.0054,
      "step": 36280
    },
    {
      "epoch": 11.197161369947548,
      "grad_norm": 0.00010153294715564698,
      "learning_rate": 3.880283863005246e-05,
      "loss": 0.0025,
      "step": 36290
    },
    {
      "epoch": 11.200246837395866,
      "grad_norm": 0.14879056811332703,
      "learning_rate": 3.8799753162604134e-05,
      "loss": 0.0062,
      "step": 36300
    },
    {
      "epoch": 11.203332304844183,
      "grad_norm": 0.005598232615739107,
      "learning_rate": 3.879666769515582e-05,
      "loss": 0.0005,
      "step": 36310
    },
    {
      "epoch": 11.206417772292502,
      "grad_norm": 0.0039747064001858234,
      "learning_rate": 3.87935822277075e-05,
      "loss": 0.0041,
      "step": 36320
    },
    {
      "epoch": 11.20950323974082,
      "grad_norm": 0.006434321869164705,
      "learning_rate": 3.879049676025918e-05,
      "loss": 0.002,
      "step": 36330
    },
    {
      "epoch": 11.21258870718914,
      "grad_norm": 0.11194419860839844,
      "learning_rate": 3.878741129281086e-05,
      "loss": 0.0012,
      "step": 36340
    },
    {
      "epoch": 11.215674174637458,
      "grad_norm": 0.0006065862253308296,
      "learning_rate": 3.878432582536255e-05,
      "loss": 0.0035,
      "step": 36350
    },
    {
      "epoch": 11.218759642085775,
      "grad_norm": 6.139431934570894e-05,
      "learning_rate": 3.878124035791423e-05,
      "loss": 0.0015,
      "step": 36360
    },
    {
      "epoch": 11.221845109534094,
      "grad_norm": 0.00040476996218785644,
      "learning_rate": 3.8778154890465905e-05,
      "loss": 0.0055,
      "step": 36370
    },
    {
      "epoch": 11.224930576982413,
      "grad_norm": 0.013731139712035656,
      "learning_rate": 3.877506942301759e-05,
      "loss": 0.0026,
      "step": 36380
    },
    {
      "epoch": 11.228016044430731,
      "grad_norm": 0.011845706030726433,
      "learning_rate": 3.877198395556927e-05,
      "loss": 0.0052,
      "step": 36390
    },
    {
      "epoch": 11.23110151187905,
      "grad_norm": 0.6406970620155334,
      "learning_rate": 3.876889848812095e-05,
      "loss": 0.0038,
      "step": 36400
    },
    {
      "epoch": 11.234186979327369,
      "grad_norm": 0.15186481177806854,
      "learning_rate": 3.876581302067263e-05,
      "loss": 0.0028,
      "step": 36410
    },
    {
      "epoch": 11.237272446775686,
      "grad_norm": 0.036507297307252884,
      "learning_rate": 3.876272755322432e-05,
      "loss": 0.0004,
      "step": 36420
    },
    {
      "epoch": 11.240357914224004,
      "grad_norm": 0.5384003520011902,
      "learning_rate": 3.8759642085776e-05,
      "loss": 0.0004,
      "step": 36430
    },
    {
      "epoch": 11.243443381672323,
      "grad_norm": 0.0013621324906125665,
      "learning_rate": 3.8756556618327676e-05,
      "loss": 0.0024,
      "step": 36440
    },
    {
      "epoch": 11.246528849120642,
      "grad_norm": 0.022738462314009666,
      "learning_rate": 3.875347115087936e-05,
      "loss": 0.0001,
      "step": 36450
    },
    {
      "epoch": 11.24961431656896,
      "grad_norm": 0.0008837112691253424,
      "learning_rate": 3.875038568343104e-05,
      "loss": 0.0002,
      "step": 36460
    },
    {
      "epoch": 11.25269978401728,
      "grad_norm": 0.4122001528739929,
      "learning_rate": 3.874730021598272e-05,
      "loss": 0.0021,
      "step": 36470
    },
    {
      "epoch": 11.255785251465596,
      "grad_norm": 0.0007749678334221244,
      "learning_rate": 3.8744214748534405e-05,
      "loss": 0.002,
      "step": 36480
    },
    {
      "epoch": 11.258870718913915,
      "grad_norm": 0.0012729904847219586,
      "learning_rate": 3.874112928108609e-05,
      "loss": 0.0025,
      "step": 36490
    },
    {
      "epoch": 11.261956186362234,
      "grad_norm": 0.0005457836668938398,
      "learning_rate": 3.873804381363777e-05,
      "loss": 0.0026,
      "step": 36500
    },
    {
      "epoch": 11.265041653810552,
      "grad_norm": 0.34083083271980286,
      "learning_rate": 3.8734958346189446e-05,
      "loss": 0.0142,
      "step": 36510
    },
    {
      "epoch": 11.268127121258871,
      "grad_norm": 0.00923923309892416,
      "learning_rate": 3.8731872878741135e-05,
      "loss": 0.0008,
      "step": 36520
    },
    {
      "epoch": 11.27121258870719,
      "grad_norm": 0.04310529679059982,
      "learning_rate": 3.872878741129281e-05,
      "loss": 0.0008,
      "step": 36530
    },
    {
      "epoch": 11.274298056155507,
      "grad_norm": 0.6354261040687561,
      "learning_rate": 3.8725701943844494e-05,
      "loss": 0.001,
      "step": 36540
    },
    {
      "epoch": 11.277383523603826,
      "grad_norm": 0.007150697056204081,
      "learning_rate": 3.8722616476396176e-05,
      "loss": 0.0033,
      "step": 36550
    },
    {
      "epoch": 11.280468991052144,
      "grad_norm": 0.0023814814630895853,
      "learning_rate": 3.871953100894786e-05,
      "loss": 0.0014,
      "step": 36560
    },
    {
      "epoch": 11.283554458500463,
      "grad_norm": 0.0013113862369209528,
      "learning_rate": 3.871644554149954e-05,
      "loss": 0.0015,
      "step": 36570
    },
    {
      "epoch": 11.286639925948782,
      "grad_norm": 0.10184890776872635,
      "learning_rate": 3.871336007405122e-05,
      "loss": 0.0117,
      "step": 36580
    },
    {
      "epoch": 11.2897253933971,
      "grad_norm": 0.06078362464904785,
      "learning_rate": 3.8710274606602906e-05,
      "loss": 0.0069,
      "step": 36590
    },
    {
      "epoch": 11.292810860845417,
      "grad_norm": 0.0003155488520860672,
      "learning_rate": 3.870718913915458e-05,
      "loss": 0.0016,
      "step": 36600
    },
    {
      "epoch": 11.295896328293736,
      "grad_norm": 0.007830597460269928,
      "learning_rate": 3.8704103671706264e-05,
      "loss": 0.0029,
      "step": 36610
    },
    {
      "epoch": 11.298981795742055,
      "grad_norm": 0.006313696037977934,
      "learning_rate": 3.8701018204257947e-05,
      "loss": 0.0086,
      "step": 36620
    },
    {
      "epoch": 11.302067263190374,
      "grad_norm": 0.0005724413204006851,
      "learning_rate": 3.869793273680963e-05,
      "loss": 0.0007,
      "step": 36630
    },
    {
      "epoch": 11.305152730638692,
      "grad_norm": 0.018869265913963318,
      "learning_rate": 3.869484726936131e-05,
      "loss": 0.0092,
      "step": 36640
    },
    {
      "epoch": 11.308238198087011,
      "grad_norm": 0.005739923566579819,
      "learning_rate": 3.869176180191299e-05,
      "loss": 0.0019,
      "step": 36650
    },
    {
      "epoch": 11.311323665535328,
      "grad_norm": 0.025632891803979874,
      "learning_rate": 3.8688676334464677e-05,
      "loss": 0.0132,
      "step": 36660
    },
    {
      "epoch": 11.314409132983647,
      "grad_norm": 0.002420262200757861,
      "learning_rate": 3.868559086701635e-05,
      "loss": 0.0088,
      "step": 36670
    },
    {
      "epoch": 11.317494600431965,
      "grad_norm": 0.12379073351621628,
      "learning_rate": 3.8682505399568035e-05,
      "loss": 0.0035,
      "step": 36680
    },
    {
      "epoch": 11.320580067880284,
      "grad_norm": 0.05875082314014435,
      "learning_rate": 3.867941993211972e-05,
      "loss": 0.0017,
      "step": 36690
    },
    {
      "epoch": 11.323665535328603,
      "grad_norm": 0.022980429232120514,
      "learning_rate": 3.86763344646714e-05,
      "loss": 0.0016,
      "step": 36700
    },
    {
      "epoch": 11.32675100277692,
      "grad_norm": 0.07313750684261322,
      "learning_rate": 3.867324899722308e-05,
      "loss": 0.0022,
      "step": 36710
    },
    {
      "epoch": 11.329836470225239,
      "grad_norm": 0.04781118780374527,
      "learning_rate": 3.867016352977476e-05,
      "loss": 0.0078,
      "step": 36720
    },
    {
      "epoch": 11.332921937673557,
      "grad_norm": 0.07671865075826645,
      "learning_rate": 3.866707806232645e-05,
      "loss": 0.0047,
      "step": 36730
    },
    {
      "epoch": 11.336007405121876,
      "grad_norm": 3.7018353939056396,
      "learning_rate": 3.866399259487812e-05,
      "loss": 0.0136,
      "step": 36740
    },
    {
      "epoch": 11.339092872570195,
      "grad_norm": 0.0020287157967686653,
      "learning_rate": 3.8660907127429805e-05,
      "loss": 0.0055,
      "step": 36750
    },
    {
      "epoch": 11.342178340018513,
      "grad_norm": 0.24987363815307617,
      "learning_rate": 3.8657821659981495e-05,
      "loss": 0.0055,
      "step": 36760
    },
    {
      "epoch": 11.34526380746683,
      "grad_norm": 0.008519995026290417,
      "learning_rate": 3.865473619253317e-05,
      "loss": 0.0115,
      "step": 36770
    },
    {
      "epoch": 11.348349274915149,
      "grad_norm": 3.1179182529449463,
      "learning_rate": 3.865165072508485e-05,
      "loss": 0.0332,
      "step": 36780
    },
    {
      "epoch": 11.351434742363468,
      "grad_norm": 0.0020844335667788982,
      "learning_rate": 3.8648565257636535e-05,
      "loss": 0.0165,
      "step": 36790
    },
    {
      "epoch": 11.354520209811787,
      "grad_norm": 0.0420621782541275,
      "learning_rate": 3.864547979018822e-05,
      "loss": 0.0029,
      "step": 36800
    },
    {
      "epoch": 11.357605677260105,
      "grad_norm": 3.9139652252197266,
      "learning_rate": 3.864239432273989e-05,
      "loss": 0.0078,
      "step": 36810
    },
    {
      "epoch": 11.360691144708424,
      "grad_norm": 0.02069559507071972,
      "learning_rate": 3.8639308855291576e-05,
      "loss": 0.0026,
      "step": 36820
    },
    {
      "epoch": 11.363776612156741,
      "grad_norm": 0.10159418731927872,
      "learning_rate": 3.8636223387843265e-05,
      "loss": 0.0047,
      "step": 36830
    },
    {
      "epoch": 11.36686207960506,
      "grad_norm": 0.01934734359383583,
      "learning_rate": 3.863313792039494e-05,
      "loss": 0.001,
      "step": 36840
    },
    {
      "epoch": 11.369947547053378,
      "grad_norm": 0.006059990730136633,
      "learning_rate": 3.863005245294662e-05,
      "loss": 0.0037,
      "step": 36850
    },
    {
      "epoch": 11.373033014501697,
      "grad_norm": 0.004198515322059393,
      "learning_rate": 3.8626966985498306e-05,
      "loss": 0.0027,
      "step": 36860
    },
    {
      "epoch": 11.376118481950016,
      "grad_norm": 0.007546917535364628,
      "learning_rate": 3.862388151804999e-05,
      "loss": 0.0016,
      "step": 36870
    },
    {
      "epoch": 11.379203949398335,
      "grad_norm": 0.051879022270441055,
      "learning_rate": 3.8620796050601664e-05,
      "loss": 0.0015,
      "step": 36880
    },
    {
      "epoch": 11.382289416846652,
      "grad_norm": 3.641653060913086,
      "learning_rate": 3.8617710583153346e-05,
      "loss": 0.0035,
      "step": 36890
    },
    {
      "epoch": 11.38537488429497,
      "grad_norm": 0.02353573404252529,
      "learning_rate": 3.8614625115705036e-05,
      "loss": 0.0005,
      "step": 36900
    },
    {
      "epoch": 11.388460351743289,
      "grad_norm": 0.008630952797830105,
      "learning_rate": 3.861153964825671e-05,
      "loss": 0.0038,
      "step": 36910
    },
    {
      "epoch": 11.391545819191608,
      "grad_norm": 0.02416572906076908,
      "learning_rate": 3.8608454180808394e-05,
      "loss": 0.0039,
      "step": 36920
    },
    {
      "epoch": 11.394631286639926,
      "grad_norm": 0.006639049854129553,
      "learning_rate": 3.8605368713360076e-05,
      "loss": 0.0019,
      "step": 36930
    },
    {
      "epoch": 11.397716754088245,
      "grad_norm": 0.0012677666964009404,
      "learning_rate": 3.860228324591176e-05,
      "loss": 0.0029,
      "step": 36940
    },
    {
      "epoch": 11.400802221536562,
      "grad_norm": 0.7806257009506226,
      "learning_rate": 3.859919777846344e-05,
      "loss": 0.0011,
      "step": 36950
    },
    {
      "epoch": 11.40388768898488,
      "grad_norm": 0.002626015106216073,
      "learning_rate": 3.859611231101512e-05,
      "loss": 0.0012,
      "step": 36960
    },
    {
      "epoch": 11.4069731564332,
      "grad_norm": 0.003649982390925288,
      "learning_rate": 3.8593026843566806e-05,
      "loss": 0.004,
      "step": 36970
    },
    {
      "epoch": 11.410058623881518,
      "grad_norm": 0.025640955194830894,
      "learning_rate": 3.858994137611848e-05,
      "loss": 0.0062,
      "step": 36980
    },
    {
      "epoch": 11.413144091329837,
      "grad_norm": 0.06726795434951782,
      "learning_rate": 3.8586855908670164e-05,
      "loss": 0.0005,
      "step": 36990
    },
    {
      "epoch": 11.416229558778156,
      "grad_norm": 0.6810079216957092,
      "learning_rate": 3.858377044122185e-05,
      "loss": 0.004,
      "step": 37000
    },
    {
      "epoch": 11.419315026226473,
      "grad_norm": 0.019035838544368744,
      "learning_rate": 3.858068497377353e-05,
      "loss": 0.0007,
      "step": 37010
    },
    {
      "epoch": 11.422400493674791,
      "grad_norm": 0.0007598111405968666,
      "learning_rate": 3.857759950632521e-05,
      "loss": 0.0003,
      "step": 37020
    },
    {
      "epoch": 11.42548596112311,
      "grad_norm": 9.567708184476942e-05,
      "learning_rate": 3.8574514038876894e-05,
      "loss": 0.0011,
      "step": 37030
    },
    {
      "epoch": 11.428571428571429,
      "grad_norm": 0.00046269907034002244,
      "learning_rate": 3.857142857142858e-05,
      "loss": 0.0077,
      "step": 37040
    },
    {
      "epoch": 11.431656896019748,
      "grad_norm": 0.03732079640030861,
      "learning_rate": 3.856834310398025e-05,
      "loss": 0.0015,
      "step": 37050
    },
    {
      "epoch": 11.434742363468064,
      "grad_norm": 0.0014368444681167603,
      "learning_rate": 3.8565257636531935e-05,
      "loss": 0.0015,
      "step": 37060
    },
    {
      "epoch": 11.437827830916383,
      "grad_norm": 0.211099311709404,
      "learning_rate": 3.856217216908362e-05,
      "loss": 0.0024,
      "step": 37070
    },
    {
      "epoch": 11.440913298364702,
      "grad_norm": 0.00473887100815773,
      "learning_rate": 3.85590867016353e-05,
      "loss": 0.0084,
      "step": 37080
    },
    {
      "epoch": 11.44399876581302,
      "grad_norm": 0.0009361315169371665,
      "learning_rate": 3.855600123418698e-05,
      "loss": 0.0005,
      "step": 37090
    },
    {
      "epoch": 11.44708423326134,
      "grad_norm": 0.0008955649682320654,
      "learning_rate": 3.8552915766738665e-05,
      "loss": 0.0064,
      "step": 37100
    },
    {
      "epoch": 11.450169700709658,
      "grad_norm": 0.0008532541105523705,
      "learning_rate": 3.854983029929035e-05,
      "loss": 0.0002,
      "step": 37110
    },
    {
      "epoch": 11.453255168157977,
      "grad_norm": 0.055138614028692245,
      "learning_rate": 3.854674483184202e-05,
      "loss": 0.0035,
      "step": 37120
    },
    {
      "epoch": 11.456340635606294,
      "grad_norm": 0.005348464474081993,
      "learning_rate": 3.8543659364393706e-05,
      "loss": 0.004,
      "step": 37130
    },
    {
      "epoch": 11.459426103054613,
      "grad_norm": 0.0032580127008259296,
      "learning_rate": 3.854057389694539e-05,
      "loss": 0.0048,
      "step": 37140
    },
    {
      "epoch": 11.462511570502931,
      "grad_norm": 0.04256478324532509,
      "learning_rate": 3.853748842949707e-05,
      "loss": 0.0018,
      "step": 37150
    },
    {
      "epoch": 11.46559703795125,
      "grad_norm": 0.012801958248019218,
      "learning_rate": 3.853440296204875e-05,
      "loss": 0.0004,
      "step": 37160
    },
    {
      "epoch": 11.468682505399569,
      "grad_norm": 0.20326390862464905,
      "learning_rate": 3.8531317494600435e-05,
      "loss": 0.0042,
      "step": 37170
    },
    {
      "epoch": 11.471767972847886,
      "grad_norm": 0.5742046236991882,
      "learning_rate": 3.852823202715212e-05,
      "loss": 0.013,
      "step": 37180
    },
    {
      "epoch": 11.474853440296204,
      "grad_norm": 0.03198946639895439,
      "learning_rate": 3.8525146559703794e-05,
      "loss": 0.0005,
      "step": 37190
    },
    {
      "epoch": 11.477938907744523,
      "grad_norm": 0.3167783319950104,
      "learning_rate": 3.8522061092255476e-05,
      "loss": 0.0033,
      "step": 37200
    },
    {
      "epoch": 11.481024375192842,
      "grad_norm": 1.0697782039642334,
      "learning_rate": 3.851897562480716e-05,
      "loss": 0.0077,
      "step": 37210
    },
    {
      "epoch": 11.48410984264116,
      "grad_norm": 0.05226273089647293,
      "learning_rate": 3.851589015735884e-05,
      "loss": 0.0283,
      "step": 37220
    },
    {
      "epoch": 11.48719531008948,
      "grad_norm": 0.0023841948714107275,
      "learning_rate": 3.8512804689910523e-05,
      "loss": 0.0006,
      "step": 37230
    },
    {
      "epoch": 11.490280777537796,
      "grad_norm": 0.05142299830913544,
      "learning_rate": 3.8509719222462206e-05,
      "loss": 0.0005,
      "step": 37240
    },
    {
      "epoch": 11.493366244986115,
      "grad_norm": 0.25462400913238525,
      "learning_rate": 3.850663375501389e-05,
      "loss": 0.0006,
      "step": 37250
    },
    {
      "epoch": 11.496451712434434,
      "grad_norm": 2.340405225753784,
      "learning_rate": 3.8503548287565564e-05,
      "loss": 0.0041,
      "step": 37260
    },
    {
      "epoch": 11.499537179882752,
      "grad_norm": 0.2275221049785614,
      "learning_rate": 3.8500462820117253e-05,
      "loss": 0.0004,
      "step": 37270
    },
    {
      "epoch": 11.502622647331071,
      "grad_norm": 0.18990080058574677,
      "learning_rate": 3.849737735266893e-05,
      "loss": 0.0044,
      "step": 37280
    },
    {
      "epoch": 11.50570811477939,
      "grad_norm": 0.0007718426641076803,
      "learning_rate": 3.849429188522061e-05,
      "loss": 0.0045,
      "step": 37290
    },
    {
      "epoch": 11.508793582227707,
      "grad_norm": 0.00031677965307608247,
      "learning_rate": 3.8491206417772294e-05,
      "loss": 0.0009,
      "step": 37300
    },
    {
      "epoch": 11.511879049676025,
      "grad_norm": 0.0124496566131711,
      "learning_rate": 3.8488120950323977e-05,
      "loss": 0.0001,
      "step": 37310
    },
    {
      "epoch": 11.514964517124344,
      "grad_norm": 0.0003348685859236866,
      "learning_rate": 3.848503548287566e-05,
      "loss": 0.0011,
      "step": 37320
    },
    {
      "epoch": 11.518049984572663,
      "grad_norm": 0.004729607608169317,
      "learning_rate": 3.8481950015427335e-05,
      "loss": 0.0,
      "step": 37330
    },
    {
      "epoch": 11.521135452020982,
      "grad_norm": 0.00025303431903012097,
      "learning_rate": 3.8478864547979024e-05,
      "loss": 0.0037,
      "step": 37340
    },
    {
      "epoch": 11.5242209194693,
      "grad_norm": 1.996591567993164,
      "learning_rate": 3.8475779080530706e-05,
      "loss": 0.004,
      "step": 37350
    },
    {
      "epoch": 11.527306386917617,
      "grad_norm": 0.7512962222099304,
      "learning_rate": 3.847269361308238e-05,
      "loss": 0.0081,
      "step": 37360
    },
    {
      "epoch": 11.530391854365936,
      "grad_norm": 0.0014055265346542,
      "learning_rate": 3.8469608145634065e-05,
      "loss": 0.0006,
      "step": 37370
    },
    {
      "epoch": 11.533477321814255,
      "grad_norm": 0.05252972990274429,
      "learning_rate": 3.846652267818575e-05,
      "loss": 0.0037,
      "step": 37380
    },
    {
      "epoch": 11.536562789262574,
      "grad_norm": 0.18769203126430511,
      "learning_rate": 3.846343721073743e-05,
      "loss": 0.0005,
      "step": 37390
    },
    {
      "epoch": 11.539648256710892,
      "grad_norm": 0.02889464795589447,
      "learning_rate": 3.8460351743289105e-05,
      "loss": 0.0004,
      "step": 37400
    },
    {
      "epoch": 11.542733724159211,
      "grad_norm": 0.012275530025362968,
      "learning_rate": 3.8457266275840795e-05,
      "loss": 0.0004,
      "step": 37410
    },
    {
      "epoch": 11.545819191607528,
      "grad_norm": 0.06874403357505798,
      "learning_rate": 3.845418080839248e-05,
      "loss": 0.0006,
      "step": 37420
    },
    {
      "epoch": 11.548904659055847,
      "grad_norm": 0.01213742420077324,
      "learning_rate": 3.845109534094415e-05,
      "loss": 0.0083,
      "step": 37430
    },
    {
      "epoch": 11.551990126504165,
      "grad_norm": 0.005373839754611254,
      "learning_rate": 3.8448009873495835e-05,
      "loss": 0.0002,
      "step": 37440
    },
    {
      "epoch": 11.555075593952484,
      "grad_norm": 2.9028866265434772e-05,
      "learning_rate": 3.844492440604752e-05,
      "loss": 0.0006,
      "step": 37450
    },
    {
      "epoch": 11.558161061400803,
      "grad_norm": 0.2747635245323181,
      "learning_rate": 3.84418389385992e-05,
      "loss": 0.0003,
      "step": 37460
    },
    {
      "epoch": 11.561246528849122,
      "grad_norm": 0.7387315034866333,
      "learning_rate": 3.8438753471150876e-05,
      "loss": 0.0016,
      "step": 37470
    },
    {
      "epoch": 11.564331996297438,
      "grad_norm": 3.2129874229431152,
      "learning_rate": 3.8435668003702565e-05,
      "loss": 0.0155,
      "step": 37480
    },
    {
      "epoch": 11.567417463745757,
      "grad_norm": 0.013064427301287651,
      "learning_rate": 3.843258253625425e-05,
      "loss": 0.0001,
      "step": 37490
    },
    {
      "epoch": 11.570502931194076,
      "grad_norm": 0.021980371326208115,
      "learning_rate": 3.842949706880592e-05,
      "loss": 0.0006,
      "step": 37500
    },
    {
      "epoch": 11.573588398642395,
      "grad_norm": 0.001990001183003187,
      "learning_rate": 3.842641160135761e-05,
      "loss": 0.0005,
      "step": 37510
    },
    {
      "epoch": 11.576673866090713,
      "grad_norm": 0.0003120136971119791,
      "learning_rate": 3.842332613390929e-05,
      "loss": 0.0022,
      "step": 37520
    },
    {
      "epoch": 11.57975933353903,
      "grad_norm": 0.00024291084264405072,
      "learning_rate": 3.842024066646097e-05,
      "loss": 0.0014,
      "step": 37530
    },
    {
      "epoch": 11.582844800987349,
      "grad_norm": 0.00347428978420794,
      "learning_rate": 3.841715519901265e-05,
      "loss": 0.0057,
      "step": 37540
    },
    {
      "epoch": 11.585930268435668,
      "grad_norm": 0.003361340845003724,
      "learning_rate": 3.8414069731564336e-05,
      "loss": 0.0008,
      "step": 37550
    },
    {
      "epoch": 11.589015735883986,
      "grad_norm": 0.16119101643562317,
      "learning_rate": 3.841098426411602e-05,
      "loss": 0.0013,
      "step": 37560
    },
    {
      "epoch": 11.592101203332305,
      "grad_norm": 0.035214222967624664,
      "learning_rate": 3.8407898796667694e-05,
      "loss": 0.0022,
      "step": 37570
    },
    {
      "epoch": 11.595186670780624,
      "grad_norm": 0.007904384285211563,
      "learning_rate": 3.840481332921938e-05,
      "loss": 0.0003,
      "step": 37580
    },
    {
      "epoch": 11.59827213822894,
      "grad_norm": 0.00021631893469020724,
      "learning_rate": 3.840172786177106e-05,
      "loss": 0.0005,
      "step": 37590
    },
    {
      "epoch": 11.60135760567726,
      "grad_norm": 0.0007116206106729805,
      "learning_rate": 3.839864239432274e-05,
      "loss": 0.0015,
      "step": 37600
    },
    {
      "epoch": 11.604443073125578,
      "grad_norm": 0.0018737694481387734,
      "learning_rate": 3.8395556926874424e-05,
      "loss": 0.0005,
      "step": 37610
    },
    {
      "epoch": 11.607528540573897,
      "grad_norm": 0.023239541798830032,
      "learning_rate": 3.8392471459426106e-05,
      "loss": 0.0007,
      "step": 37620
    },
    {
      "epoch": 11.610614008022216,
      "grad_norm": 0.0996704176068306,
      "learning_rate": 3.838938599197779e-05,
      "loss": 0.002,
      "step": 37630
    },
    {
      "epoch": 11.613699475470534,
      "grad_norm": 0.16096705198287964,
      "learning_rate": 3.8386300524529464e-05,
      "loss": 0.0013,
      "step": 37640
    },
    {
      "epoch": 11.616784942918851,
      "grad_norm": 0.0004712707013823092,
      "learning_rate": 3.8383215057081154e-05,
      "loss": 0.0019,
      "step": 37650
    },
    {
      "epoch": 11.61987041036717,
      "grad_norm": 0.0033362999092787504,
      "learning_rate": 3.838012958963283e-05,
      "loss": 0.0001,
      "step": 37660
    },
    {
      "epoch": 11.622955877815489,
      "grad_norm": 0.0030060471035540104,
      "learning_rate": 3.837704412218451e-05,
      "loss": 0.0077,
      "step": 37670
    },
    {
      "epoch": 11.626041345263808,
      "grad_norm": 0.02752748318016529,
      "learning_rate": 3.8373958654736194e-05,
      "loss": 0.0003,
      "step": 37680
    },
    {
      "epoch": 11.629126812712126,
      "grad_norm": 0.05473480746150017,
      "learning_rate": 3.837087318728788e-05,
      "loss": 0.0019,
      "step": 37690
    },
    {
      "epoch": 11.632212280160445,
      "grad_norm": 0.28059446811676025,
      "learning_rate": 3.836778771983956e-05,
      "loss": 0.0005,
      "step": 37700
    },
    {
      "epoch": 11.635297747608762,
      "grad_norm": 0.030675392597913742,
      "learning_rate": 3.8364702252391235e-05,
      "loss": 0.0018,
      "step": 37710
    },
    {
      "epoch": 11.63838321505708,
      "grad_norm": 0.0013228278839960694,
      "learning_rate": 3.8361616784942924e-05,
      "loss": 0.0008,
      "step": 37720
    },
    {
      "epoch": 11.6414686825054,
      "grad_norm": 0.003181051230058074,
      "learning_rate": 3.83585313174946e-05,
      "loss": 0.001,
      "step": 37730
    },
    {
      "epoch": 11.644554149953718,
      "grad_norm": 0.16622468829154968,
      "learning_rate": 3.835544585004628e-05,
      "loss": 0.0043,
      "step": 37740
    },
    {
      "epoch": 11.647639617402037,
      "grad_norm": 1.5284472703933716,
      "learning_rate": 3.8352360382597965e-05,
      "loss": 0.0022,
      "step": 37750
    },
    {
      "epoch": 11.650725084850356,
      "grad_norm": 0.14227494597434998,
      "learning_rate": 3.834927491514965e-05,
      "loss": 0.0016,
      "step": 37760
    },
    {
      "epoch": 11.653810552298673,
      "grad_norm": 0.03210453316569328,
      "learning_rate": 3.834618944770133e-05,
      "loss": 0.0001,
      "step": 37770
    },
    {
      "epoch": 11.656896019746991,
      "grad_norm": 0.007982172071933746,
      "learning_rate": 3.834310398025301e-05,
      "loss": 0.0033,
      "step": 37780
    },
    {
      "epoch": 11.65998148719531,
      "grad_norm": 4.212376097711967e-06,
      "learning_rate": 3.8340018512804695e-05,
      "loss": 0.0018,
      "step": 37790
    },
    {
      "epoch": 11.663066954643629,
      "grad_norm": 0.13187745213508606,
      "learning_rate": 3.833693304535637e-05,
      "loss": 0.0053,
      "step": 37800
    },
    {
      "epoch": 11.666152422091947,
      "grad_norm": 0.0005649867234751582,
      "learning_rate": 3.833384757790805e-05,
      "loss": 0.0033,
      "step": 37810
    },
    {
      "epoch": 11.669237889540266,
      "grad_norm": 0.2237497866153717,
      "learning_rate": 3.833076211045974e-05,
      "loss": 0.0004,
      "step": 37820
    },
    {
      "epoch": 11.672323356988583,
      "grad_norm": 0.001130210468545556,
      "learning_rate": 3.832767664301142e-05,
      "loss": 0.0008,
      "step": 37830
    },
    {
      "epoch": 11.675408824436902,
      "grad_norm": 0.00116794987116009,
      "learning_rate": 3.83245911755631e-05,
      "loss": 0.0043,
      "step": 37840
    },
    {
      "epoch": 11.67849429188522,
      "grad_norm": 0.16312149167060852,
      "learning_rate": 3.832150570811478e-05,
      "loss": 0.003,
      "step": 37850
    },
    {
      "epoch": 11.68157975933354,
      "grad_norm": 0.031951528042554855,
      "learning_rate": 3.8318420240666465e-05,
      "loss": 0.0025,
      "step": 37860
    },
    {
      "epoch": 11.684665226781858,
      "grad_norm": 0.008491408079862595,
      "learning_rate": 3.831533477321814e-05,
      "loss": 0.0082,
      "step": 37870
    },
    {
      "epoch": 11.687750694230175,
      "grad_norm": 0.4052967429161072,
      "learning_rate": 3.8312249305769824e-05,
      "loss": 0.0008,
      "step": 37880
    },
    {
      "epoch": 11.690836161678494,
      "grad_norm": 0.0015719556249678135,
      "learning_rate": 3.830916383832151e-05,
      "loss": 0.0022,
      "step": 37890
    },
    {
      "epoch": 11.693921629126812,
      "grad_norm": 0.012417254038155079,
      "learning_rate": 3.830607837087319e-05,
      "loss": 0.0026,
      "step": 37900
    },
    {
      "epoch": 11.697007096575131,
      "grad_norm": 0.023486604914069176,
      "learning_rate": 3.830299290342487e-05,
      "loss": 0.0003,
      "step": 37910
    },
    {
      "epoch": 11.70009256402345,
      "grad_norm": 0.029305102303624153,
      "learning_rate": 3.8299907435976553e-05,
      "loss": 0.0011,
      "step": 37920
    },
    {
      "epoch": 11.703178031471769,
      "grad_norm": 0.4683012068271637,
      "learning_rate": 3.8296821968528236e-05,
      "loss": 0.002,
      "step": 37930
    },
    {
      "epoch": 11.706263498920087,
      "grad_norm": 0.0015193207655102015,
      "learning_rate": 3.829373650107991e-05,
      "loss": 0.001,
      "step": 37940
    },
    {
      "epoch": 11.709348966368404,
      "grad_norm": 1.7371786832809448,
      "learning_rate": 3.8290651033631594e-05,
      "loss": 0.0116,
      "step": 37950
    },
    {
      "epoch": 11.712434433816723,
      "grad_norm": 3.209176540374756,
      "learning_rate": 3.828756556618328e-05,
      "loss": 0.0122,
      "step": 37960
    },
    {
      "epoch": 11.715519901265042,
      "grad_norm": 0.026516694575548172,
      "learning_rate": 3.828448009873496e-05,
      "loss": 0.0087,
      "step": 37970
    },
    {
      "epoch": 11.71860536871336,
      "grad_norm": 0.03971988707780838,
      "learning_rate": 3.828139463128664e-05,
      "loss": 0.0004,
      "step": 37980
    },
    {
      "epoch": 11.72169083616168,
      "grad_norm": 0.5950803160667419,
      "learning_rate": 3.8278309163838324e-05,
      "loss": 0.0011,
      "step": 37990
    },
    {
      "epoch": 11.724776303609996,
      "grad_norm": 4.4771888497052714e-05,
      "learning_rate": 3.8275223696390006e-05,
      "loss": 0.0004,
      "step": 38000
    },
    {
      "epoch": 11.727861771058315,
      "grad_norm": 0.28506165742874146,
      "learning_rate": 3.827213822894168e-05,
      "loss": 0.0028,
      "step": 38010
    },
    {
      "epoch": 11.730947238506634,
      "grad_norm": 0.028347928076982498,
      "learning_rate": 3.826905276149337e-05,
      "loss": 0.003,
      "step": 38020
    },
    {
      "epoch": 11.734032705954952,
      "grad_norm": 0.024326922371983528,
      "learning_rate": 3.8265967294045054e-05,
      "loss": 0.002,
      "step": 38030
    },
    {
      "epoch": 11.737118173403271,
      "grad_norm": 0.8992205262184143,
      "learning_rate": 3.826288182659673e-05,
      "loss": 0.0072,
      "step": 38040
    },
    {
      "epoch": 11.74020364085159,
      "grad_norm": 3.44094181060791,
      "learning_rate": 3.825979635914841e-05,
      "loss": 0.0123,
      "step": 38050
    },
    {
      "epoch": 11.743289108299907,
      "grad_norm": 0.011084198951721191,
      "learning_rate": 3.8256710891700095e-05,
      "loss": 0.001,
      "step": 38060
    },
    {
      "epoch": 11.746374575748225,
      "grad_norm": 0.5101707577705383,
      "learning_rate": 3.825362542425178e-05,
      "loss": 0.0034,
      "step": 38070
    },
    {
      "epoch": 11.749460043196544,
      "grad_norm": 0.0033214809373021126,
      "learning_rate": 3.825053995680345e-05,
      "loss": 0.0068,
      "step": 38080
    },
    {
      "epoch": 11.752545510644863,
      "grad_norm": 0.024620920419692993,
      "learning_rate": 3.824745448935514e-05,
      "loss": 0.0004,
      "step": 38090
    },
    {
      "epoch": 11.755630978093182,
      "grad_norm": 0.00048786387196742,
      "learning_rate": 3.8244369021906824e-05,
      "loss": 0.0049,
      "step": 38100
    },
    {
      "epoch": 11.7587164455415,
      "grad_norm": 0.00039515196112915874,
      "learning_rate": 3.82412835544585e-05,
      "loss": 0.007,
      "step": 38110
    },
    {
      "epoch": 11.761801912989817,
      "grad_norm": 3.199913263320923,
      "learning_rate": 3.823819808701018e-05,
      "loss": 0.0114,
      "step": 38120
    },
    {
      "epoch": 11.764887380438136,
      "grad_norm": 1.874049425125122,
      "learning_rate": 3.8235112619561865e-05,
      "loss": 0.0077,
      "step": 38130
    },
    {
      "epoch": 11.767972847886455,
      "grad_norm": 0.7969886660575867,
      "learning_rate": 3.823202715211355e-05,
      "loss": 0.0008,
      "step": 38140
    },
    {
      "epoch": 11.771058315334773,
      "grad_norm": 0.03601038455963135,
      "learning_rate": 3.822894168466522e-05,
      "loss": 0.0056,
      "step": 38150
    },
    {
      "epoch": 11.774143782783092,
      "grad_norm": 0.04678600654006004,
      "learning_rate": 3.822585621721691e-05,
      "loss": 0.001,
      "step": 38160
    },
    {
      "epoch": 11.77722925023141,
      "grad_norm": 3.0490243434906006,
      "learning_rate": 3.8222770749768595e-05,
      "loss": 0.0075,
      "step": 38170
    },
    {
      "epoch": 11.780314717679728,
      "grad_norm": 0.9606390595436096,
      "learning_rate": 3.821968528232027e-05,
      "loss": 0.0038,
      "step": 38180
    },
    {
      "epoch": 11.783400185128047,
      "grad_norm": 0.034214917570352554,
      "learning_rate": 3.821659981487195e-05,
      "loss": 0.0024,
      "step": 38190
    },
    {
      "epoch": 11.786485652576365,
      "grad_norm": 0.4369783103466034,
      "learning_rate": 3.8213514347423636e-05,
      "loss": 0.0086,
      "step": 38200
    },
    {
      "epoch": 11.789571120024684,
      "grad_norm": 1.5427730083465576,
      "learning_rate": 3.821042887997532e-05,
      "loss": 0.0077,
      "step": 38210
    },
    {
      "epoch": 11.792656587473003,
      "grad_norm": 0.03389522433280945,
      "learning_rate": 3.8207343412527e-05,
      "loss": 0.0008,
      "step": 38220
    },
    {
      "epoch": 11.79574205492132,
      "grad_norm": 0.254978209733963,
      "learning_rate": 3.820425794507868e-05,
      "loss": 0.0073,
      "step": 38230
    },
    {
      "epoch": 11.798827522369638,
      "grad_norm": 0.0023681221064180136,
      "learning_rate": 3.8201172477630366e-05,
      "loss": 0.0012,
      "step": 38240
    },
    {
      "epoch": 11.801912989817957,
      "grad_norm": 2.1468708515167236,
      "learning_rate": 3.819808701018204e-05,
      "loss": 0.0204,
      "step": 38250
    },
    {
      "epoch": 11.804998457266276,
      "grad_norm": 0.014889434911310673,
      "learning_rate": 3.8195001542733724e-05,
      "loss": 0.0006,
      "step": 38260
    },
    {
      "epoch": 11.808083924714595,
      "grad_norm": 0.003823154838755727,
      "learning_rate": 3.8191916075285406e-05,
      "loss": 0.0039,
      "step": 38270
    },
    {
      "epoch": 11.811169392162913,
      "grad_norm": 0.1947403997182846,
      "learning_rate": 3.818883060783709e-05,
      "loss": 0.0032,
      "step": 38280
    },
    {
      "epoch": 11.814254859611232,
      "grad_norm": 0.0006362147978506982,
      "learning_rate": 3.818574514038877e-05,
      "loss": 0.0022,
      "step": 38290
    },
    {
      "epoch": 11.817340327059549,
      "grad_norm": 0.13161902129650116,
      "learning_rate": 3.8182659672940454e-05,
      "loss": 0.0002,
      "step": 38300
    },
    {
      "epoch": 11.820425794507868,
      "grad_norm": 2.3023548126220703,
      "learning_rate": 3.8179574205492136e-05,
      "loss": 0.0035,
      "step": 38310
    },
    {
      "epoch": 11.823511261956186,
      "grad_norm": 0.002753586508333683,
      "learning_rate": 3.817648873804381e-05,
      "loss": 0.0008,
      "step": 38320
    },
    {
      "epoch": 11.826596729404505,
      "grad_norm": 0.001400277018547058,
      "learning_rate": 3.81734032705955e-05,
      "loss": 0.0026,
      "step": 38330
    },
    {
      "epoch": 11.829682196852824,
      "grad_norm": 0.08267012983560562,
      "learning_rate": 3.817031780314718e-05,
      "loss": 0.0026,
      "step": 38340
    },
    {
      "epoch": 11.83276766430114,
      "grad_norm": 0.9086331725120544,
      "learning_rate": 3.816723233569886e-05,
      "loss": 0.0005,
      "step": 38350
    },
    {
      "epoch": 11.83585313174946,
      "grad_norm": 0.0001567275176057592,
      "learning_rate": 3.816414686825054e-05,
      "loss": 0.0002,
      "step": 38360
    },
    {
      "epoch": 11.838938599197778,
      "grad_norm": 0.0009157476597465575,
      "learning_rate": 3.8161061400802224e-05,
      "loss": 0.0004,
      "step": 38370
    },
    {
      "epoch": 11.842024066646097,
      "grad_norm": 0.057117220014333725,
      "learning_rate": 3.815797593335391e-05,
      "loss": 0.0008,
      "step": 38380
    },
    {
      "epoch": 11.845109534094416,
      "grad_norm": 0.0006383113213814795,
      "learning_rate": 3.815489046590558e-05,
      "loss": 0.0002,
      "step": 38390
    },
    {
      "epoch": 11.848195001542734,
      "grad_norm": 0.00022478061146102846,
      "learning_rate": 3.815180499845727e-05,
      "loss": 0.0008,
      "step": 38400
    },
    {
      "epoch": 11.851280468991051,
      "grad_norm": 0.024547291919589043,
      "learning_rate": 3.814871953100895e-05,
      "loss": 0.0002,
      "step": 38410
    },
    {
      "epoch": 11.85436593643937,
      "grad_norm": 0.020308710634708405,
      "learning_rate": 3.814563406356063e-05,
      "loss": 0.0035,
      "step": 38420
    },
    {
      "epoch": 11.857451403887689,
      "grad_norm": 0.028126608580350876,
      "learning_rate": 3.814254859611231e-05,
      "loss": 0.0001,
      "step": 38430
    },
    {
      "epoch": 11.860536871336008,
      "grad_norm": 0.09607752412557602,
      "learning_rate": 3.8139463128663995e-05,
      "loss": 0.0006,
      "step": 38440
    },
    {
      "epoch": 11.863622338784326,
      "grad_norm": 0.44604402780532837,
      "learning_rate": 3.813637766121568e-05,
      "loss": 0.004,
      "step": 38450
    },
    {
      "epoch": 11.866707806232645,
      "grad_norm": 0.06407486647367477,
      "learning_rate": 3.813329219376735e-05,
      "loss": 0.0024,
      "step": 38460
    },
    {
      "epoch": 11.869793273680962,
      "grad_norm": 0.37262704968452454,
      "learning_rate": 3.813020672631904e-05,
      "loss": 0.0108,
      "step": 38470
    },
    {
      "epoch": 11.87287874112928,
      "grad_norm": 0.06735770404338837,
      "learning_rate": 3.812712125887072e-05,
      "loss": 0.0073,
      "step": 38480
    },
    {
      "epoch": 11.8759642085776,
      "grad_norm": 5.574460010393523e-05,
      "learning_rate": 3.81240357914224e-05,
      "loss": 0.0004,
      "step": 38490
    },
    {
      "epoch": 11.879049676025918,
      "grad_norm": 0.005520087666809559,
      "learning_rate": 3.812095032397408e-05,
      "loss": 0.002,
      "step": 38500
    },
    {
      "epoch": 11.882135143474237,
      "grad_norm": 1.2711900472640991,
      "learning_rate": 3.8117864856525765e-05,
      "loss": 0.0067,
      "step": 38510
    },
    {
      "epoch": 11.885220610922556,
      "grad_norm": 0.0007177408551797271,
      "learning_rate": 3.811477938907745e-05,
      "loss": 0.0049,
      "step": 38520
    },
    {
      "epoch": 11.888306078370872,
      "grad_norm": 0.4963429868221283,
      "learning_rate": 3.8111693921629124e-05,
      "loss": 0.0013,
      "step": 38530
    },
    {
      "epoch": 11.891391545819191,
      "grad_norm": 0.00020233985560480505,
      "learning_rate": 3.810860845418081e-05,
      "loss": 0.0013,
      "step": 38540
    },
    {
      "epoch": 11.89447701326751,
      "grad_norm": 0.0018142061308026314,
      "learning_rate": 3.810552298673249e-05,
      "loss": 0.0056,
      "step": 38550
    },
    {
      "epoch": 11.897562480715829,
      "grad_norm": 0.007014257833361626,
      "learning_rate": 3.810243751928417e-05,
      "loss": 0.0017,
      "step": 38560
    },
    {
      "epoch": 11.900647948164147,
      "grad_norm": 1.5738712549209595,
      "learning_rate": 3.809935205183586e-05,
      "loss": 0.0152,
      "step": 38570
    },
    {
      "epoch": 11.903733415612466,
      "grad_norm": 0.3109496533870697,
      "learning_rate": 3.8096266584387536e-05,
      "loss": 0.0008,
      "step": 38580
    },
    {
      "epoch": 11.906818883060783,
      "grad_norm": 0.011167366057634354,
      "learning_rate": 3.809318111693922e-05,
      "loss": 0.0033,
      "step": 38590
    },
    {
      "epoch": 11.909904350509102,
      "grad_norm": 0.14900906383991241,
      "learning_rate": 3.80900956494909e-05,
      "loss": 0.001,
      "step": 38600
    },
    {
      "epoch": 11.91298981795742,
      "grad_norm": 1.8002464771270752,
      "learning_rate": 3.808701018204258e-05,
      "loss": 0.0018,
      "step": 38610
    },
    {
      "epoch": 11.91607528540574,
      "grad_norm": 0.10058264434337616,
      "learning_rate": 3.808392471459426e-05,
      "loss": 0.0019,
      "step": 38620
    },
    {
      "epoch": 11.919160752854058,
      "grad_norm": 0.00024110478989314288,
      "learning_rate": 3.808083924714594e-05,
      "loss": 0.0006,
      "step": 38630
    },
    {
      "epoch": 11.922246220302377,
      "grad_norm": 0.11273381859064102,
      "learning_rate": 3.807775377969763e-05,
      "loss": 0.0004,
      "step": 38640
    },
    {
      "epoch": 11.925331687750694,
      "grad_norm": 0.007769113406538963,
      "learning_rate": 3.8074668312249306e-05,
      "loss": 0.0018,
      "step": 38650
    },
    {
      "epoch": 11.928417155199012,
      "grad_norm": 0.0031803594902157784,
      "learning_rate": 3.807158284480099e-05,
      "loss": 0.0001,
      "step": 38660
    },
    {
      "epoch": 11.931502622647331,
      "grad_norm": 0.5975186824798584,
      "learning_rate": 3.806849737735267e-05,
      "loss": 0.0003,
      "step": 38670
    },
    {
      "epoch": 11.93458809009565,
      "grad_norm": 0.002234912011772394,
      "learning_rate": 3.8065411909904354e-05,
      "loss": 0.0004,
      "step": 38680
    },
    {
      "epoch": 11.937673557543969,
      "grad_norm": 0.0018837304087355733,
      "learning_rate": 3.8062326442456036e-05,
      "loss": 0.0002,
      "step": 38690
    },
    {
      "epoch": 11.940759024992285,
      "grad_norm": 0.0013823921326547861,
      "learning_rate": 3.805924097500771e-05,
      "loss": 0.0003,
      "step": 38700
    },
    {
      "epoch": 11.943844492440604,
      "grad_norm": 0.0017235910054296255,
      "learning_rate": 3.80561555075594e-05,
      "loss": 0.002,
      "step": 38710
    },
    {
      "epoch": 11.946929959888923,
      "grad_norm": 0.002649808069691062,
      "learning_rate": 3.805307004011108e-05,
      "loss": 0.0006,
      "step": 38720
    },
    {
      "epoch": 11.950015427337242,
      "grad_norm": 0.08147456496953964,
      "learning_rate": 3.804998457266276e-05,
      "loss": 0.0006,
      "step": 38730
    },
    {
      "epoch": 11.95310089478556,
      "grad_norm": 0.01303205918520689,
      "learning_rate": 3.804689910521444e-05,
      "loss": 0.0135,
      "step": 38740
    },
    {
      "epoch": 11.956186362233879,
      "grad_norm": 0.0032811881974339485,
      "learning_rate": 3.8043813637766124e-05,
      "loss": 0.0002,
      "step": 38750
    },
    {
      "epoch": 11.959271829682196,
      "grad_norm": 0.06600355356931686,
      "learning_rate": 3.804072817031781e-05,
      "loss": 0.0001,
      "step": 38760
    },
    {
      "epoch": 11.962357297130515,
      "grad_norm": 0.0011624932521954179,
      "learning_rate": 3.803764270286948e-05,
      "loss": 0.011,
      "step": 38770
    },
    {
      "epoch": 11.965442764578833,
      "grad_norm": 0.23958995938301086,
      "learning_rate": 3.803455723542117e-05,
      "loss": 0.0013,
      "step": 38780
    },
    {
      "epoch": 11.968528232027152,
      "grad_norm": 0.0017433742759749293,
      "learning_rate": 3.803147176797285e-05,
      "loss": 0.0033,
      "step": 38790
    },
    {
      "epoch": 11.971613699475471,
      "grad_norm": 0.029991058632731438,
      "learning_rate": 3.802838630052453e-05,
      "loss": 0.001,
      "step": 38800
    },
    {
      "epoch": 11.97469916692379,
      "grad_norm": 5.947629451751709,
      "learning_rate": 3.802530083307621e-05,
      "loss": 0.0088,
      "step": 38810
    },
    {
      "epoch": 11.977784634372107,
      "grad_norm": 0.002895154757425189,
      "learning_rate": 3.8022215365627895e-05,
      "loss": 0.0001,
      "step": 38820
    },
    {
      "epoch": 11.980870101820425,
      "grad_norm": 0.5243672728538513,
      "learning_rate": 3.801912989817958e-05,
      "loss": 0.001,
      "step": 38830
    },
    {
      "epoch": 11.983955569268744,
      "grad_norm": 9.845955355558544e-05,
      "learning_rate": 3.801604443073126e-05,
      "loss": 0.0003,
      "step": 38840
    },
    {
      "epoch": 11.987041036717063,
      "grad_norm": 0.28902560472488403,
      "learning_rate": 3.801295896328294e-05,
      "loss": 0.0009,
      "step": 38850
    },
    {
      "epoch": 11.990126504165382,
      "grad_norm": 0.07247330248355865,
      "learning_rate": 3.800987349583462e-05,
      "loss": 0.0019,
      "step": 38860
    },
    {
      "epoch": 11.9932119716137,
      "grad_norm": 2.7177319526672363,
      "learning_rate": 3.80067880283863e-05,
      "loss": 0.0071,
      "step": 38870
    },
    {
      "epoch": 11.996297439062017,
      "grad_norm": 0.0026353218127042055,
      "learning_rate": 3.800370256093798e-05,
      "loss": 0.0016,
      "step": 38880
    },
    {
      "epoch": 11.999382906510336,
      "grad_norm": 0.0005715155857615173,
      "learning_rate": 3.8000617093489666e-05,
      "loss": 0.0083,
      "step": 38890
    },
    {
      "epoch": 12.0,
      "eval_accuracy_branch1": 0.9994116682580558,
      "eval_accuracy_branch2": 0.3988117627769258,
      "eval_f1_branch1": 0.9989080820902978,
      "eval_f1_branch2": 0.3852064597452836,
      "eval_loss": 0.00027343747206032276,
      "eval_precision_branch1": 0.9989037888260314,
      "eval_precision_branch2": 0.5065684741934167,
      "eval_recall_branch1": 0.9989158786024425,
      "eval_recall_branch2": 0.504448655999537,
      "eval_runtime": 238.7923,
      "eval_samples_per_second": 434.197,
      "eval_steps_per_second": 54.277,
      "step": 38892
    },
    {
      "epoch": 12.002468373958655,
      "grad_norm": 3.8006083965301514,
      "learning_rate": 3.799753162604135e-05,
      "loss": 0.0066,
      "step": 38900
    },
    {
      "epoch": 12.005553841406973,
      "grad_norm": 0.28955569863319397,
      "learning_rate": 3.799444615859303e-05,
      "loss": 0.0009,
      "step": 38910
    },
    {
      "epoch": 12.008639308855292,
      "grad_norm": 0.07936321943998337,
      "learning_rate": 3.799136069114471e-05,
      "loss": 0.0001,
      "step": 38920
    },
    {
      "epoch": 12.01172477630361,
      "grad_norm": 0.002856598235666752,
      "learning_rate": 3.798827522369639e-05,
      "loss": 0.0006,
      "step": 38930
    },
    {
      "epoch": 12.014810243751928,
      "grad_norm": 0.010874135419726372,
      "learning_rate": 3.798518975624807e-05,
      "loss": 0.0074,
      "step": 38940
    },
    {
      "epoch": 12.017895711200246,
      "grad_norm": 0.00042360543739050627,
      "learning_rate": 3.7982104288799754e-05,
      "loss": 0.0071,
      "step": 38950
    },
    {
      "epoch": 12.020981178648565,
      "grad_norm": 0.1401461958885193,
      "learning_rate": 3.7979018821351436e-05,
      "loss": 0.0055,
      "step": 38960
    },
    {
      "epoch": 12.024066646096884,
      "grad_norm": 0.004325466696172953,
      "learning_rate": 3.797593335390312e-05,
      "loss": 0.0024,
      "step": 38970
    },
    {
      "epoch": 12.027152113545203,
      "grad_norm": 0.01610752008855343,
      "learning_rate": 3.79728478864548e-05,
      "loss": 0.0041,
      "step": 38980
    },
    {
      "epoch": 12.030237580993521,
      "grad_norm": 0.012650945223867893,
      "learning_rate": 3.7969762419006484e-05,
      "loss": 0.0151,
      "step": 38990
    },
    {
      "epoch": 12.033323048441838,
      "grad_norm": 0.02493502013385296,
      "learning_rate": 3.796667695155816e-05,
      "loss": 0.0009,
      "step": 39000
    },
    {
      "epoch": 12.036408515890157,
      "grad_norm": 0.012755973264575005,
      "learning_rate": 3.796359148410984e-05,
      "loss": 0.001,
      "step": 39010
    },
    {
      "epoch": 12.039493983338476,
      "grad_norm": 0.33327925205230713,
      "learning_rate": 3.7960506016661524e-05,
      "loss": 0.005,
      "step": 39020
    },
    {
      "epoch": 12.042579450786794,
      "grad_norm": 0.0029422373045235872,
      "learning_rate": 3.795742054921321e-05,
      "loss": 0.0,
      "step": 39030
    },
    {
      "epoch": 12.045664918235113,
      "grad_norm": 1.0121489763259888,
      "learning_rate": 3.795433508176489e-05,
      "loss": 0.0013,
      "step": 39040
    },
    {
      "epoch": 12.04875038568343,
      "grad_norm": 0.03523433953523636,
      "learning_rate": 3.795124961431657e-05,
      "loss": 0.0004,
      "step": 39050
    },
    {
      "epoch": 12.051835853131749,
      "grad_norm": 1.9368259906768799,
      "learning_rate": 3.7948164146868254e-05,
      "loss": 0.0035,
      "step": 39060
    },
    {
      "epoch": 12.054921320580068,
      "grad_norm": 0.11229011416435242,
      "learning_rate": 3.794507867941993e-05,
      "loss": 0.0029,
      "step": 39070
    },
    {
      "epoch": 12.058006788028386,
      "grad_norm": 0.010900652036070824,
      "learning_rate": 3.794199321197162e-05,
      "loss": 0.005,
      "step": 39080
    },
    {
      "epoch": 12.061092255476705,
      "grad_norm": 1.923933506011963,
      "learning_rate": 3.7938907744523295e-05,
      "loss": 0.0035,
      "step": 39090
    },
    {
      "epoch": 12.064177722925024,
      "grad_norm": 2.672910451889038,
      "learning_rate": 3.793582227707498e-05,
      "loss": 0.0073,
      "step": 39100
    },
    {
      "epoch": 12.06726319037334,
      "grad_norm": 0.6935922503471375,
      "learning_rate": 3.793273680962666e-05,
      "loss": 0.0011,
      "step": 39110
    },
    {
      "epoch": 12.07034865782166,
      "grad_norm": 0.0012957449071109295,
      "learning_rate": 3.792965134217834e-05,
      "loss": 0.0048,
      "step": 39120
    },
    {
      "epoch": 12.073434125269978,
      "grad_norm": 0.04246896505355835,
      "learning_rate": 3.7926565874730025e-05,
      "loss": 0.0053,
      "step": 39130
    },
    {
      "epoch": 12.076519592718297,
      "grad_norm": 0.2630413770675659,
      "learning_rate": 3.79234804072817e-05,
      "loss": 0.0113,
      "step": 39140
    },
    {
      "epoch": 12.079605060166616,
      "grad_norm": 0.01405038870871067,
      "learning_rate": 3.792039493983339e-05,
      "loss": 0.0,
      "step": 39150
    },
    {
      "epoch": 12.082690527614934,
      "grad_norm": 0.044856514781713486,
      "learning_rate": 3.791730947238507e-05,
      "loss": 0.0015,
      "step": 39160
    },
    {
      "epoch": 12.085775995063251,
      "grad_norm": 0.00020506748114712536,
      "learning_rate": 3.791422400493675e-05,
      "loss": 0.0044,
      "step": 39170
    },
    {
      "epoch": 12.08886146251157,
      "grad_norm": 0.6855499744415283,
      "learning_rate": 3.791113853748843e-05,
      "loss": 0.0015,
      "step": 39180
    },
    {
      "epoch": 12.091946929959889,
      "grad_norm": 0.02042061649262905,
      "learning_rate": 3.790805307004011e-05,
      "loss": 0.0002,
      "step": 39190
    },
    {
      "epoch": 12.095032397408207,
      "grad_norm": 0.049393486231565475,
      "learning_rate": 3.7904967602591795e-05,
      "loss": 0.0044,
      "step": 39200
    },
    {
      "epoch": 12.098117864856526,
      "grad_norm": 0.007525201421231031,
      "learning_rate": 3.790188213514347e-05,
      "loss": 0.0078,
      "step": 39210
    },
    {
      "epoch": 12.101203332304845,
      "grad_norm": 0.0027113575488328934,
      "learning_rate": 3.789879666769516e-05,
      "loss": 0.0049,
      "step": 39220
    },
    {
      "epoch": 12.104288799753162,
      "grad_norm": 0.0004914114251732826,
      "learning_rate": 3.789571120024684e-05,
      "loss": 0.0181,
      "step": 39230
    },
    {
      "epoch": 12.10737426720148,
      "grad_norm": 0.0001916228502523154,
      "learning_rate": 3.789262573279852e-05,
      "loss": 0.0025,
      "step": 39240
    },
    {
      "epoch": 12.1104597346498,
      "grad_norm": 0.03298318758606911,
      "learning_rate": 3.78895402653502e-05,
      "loss": 0.0027,
      "step": 39250
    },
    {
      "epoch": 12.113545202098118,
      "grad_norm": 0.014554494991898537,
      "learning_rate": 3.788645479790188e-05,
      "loss": 0.003,
      "step": 39260
    },
    {
      "epoch": 12.116630669546437,
      "grad_norm": 0.0001692869991529733,
      "learning_rate": 3.7883369330453566e-05,
      "loss": 0.0021,
      "step": 39270
    },
    {
      "epoch": 12.119716136994755,
      "grad_norm": 0.009807676076889038,
      "learning_rate": 3.788028386300524e-05,
      "loss": 0.001,
      "step": 39280
    },
    {
      "epoch": 12.122801604443072,
      "grad_norm": 2.093928813934326,
      "learning_rate": 3.787719839555693e-05,
      "loss": 0.0011,
      "step": 39290
    },
    {
      "epoch": 12.125887071891391,
      "grad_norm": 0.04119142144918442,
      "learning_rate": 3.787411292810861e-05,
      "loss": 0.0001,
      "step": 39300
    },
    {
      "epoch": 12.12897253933971,
      "grad_norm": 1.4853384494781494,
      "learning_rate": 3.787102746066029e-05,
      "loss": 0.0011,
      "step": 39310
    },
    {
      "epoch": 12.132058006788029,
      "grad_norm": 0.021716132760047913,
      "learning_rate": 3.786794199321198e-05,
      "loss": 0.0046,
      "step": 39320
    },
    {
      "epoch": 12.135143474236347,
      "grad_norm": 0.0047731297090649605,
      "learning_rate": 3.7864856525763654e-05,
      "loss": 0.0005,
      "step": 39330
    },
    {
      "epoch": 12.138228941684666,
      "grad_norm": 2.2665231227874756,
      "learning_rate": 3.7861771058315336e-05,
      "loss": 0.0049,
      "step": 39340
    },
    {
      "epoch": 12.141314409132983,
      "grad_norm": 0.0011572693474590778,
      "learning_rate": 3.785868559086702e-05,
      "loss": 0.0104,
      "step": 39350
    },
    {
      "epoch": 12.144399876581302,
      "grad_norm": 0.3377368450164795,
      "learning_rate": 3.78556001234187e-05,
      "loss": 0.0028,
      "step": 39360
    },
    {
      "epoch": 12.14748534402962,
      "grad_norm": 4.534604072570801,
      "learning_rate": 3.7852514655970384e-05,
      "loss": 0.0105,
      "step": 39370
    },
    {
      "epoch": 12.15057081147794,
      "grad_norm": 0.31776636838912964,
      "learning_rate": 3.784942918852206e-05,
      "loss": 0.0018,
      "step": 39380
    },
    {
      "epoch": 12.153656278926258,
      "grad_norm": 0.10893577337265015,
      "learning_rate": 3.784634372107375e-05,
      "loss": 0.0074,
      "step": 39390
    },
    {
      "epoch": 12.156741746374577,
      "grad_norm": 0.0011653653346002102,
      "learning_rate": 3.7843258253625424e-05,
      "loss": 0.0093,
      "step": 39400
    },
    {
      "epoch": 12.159827213822894,
      "grad_norm": 0.003457118757069111,
      "learning_rate": 3.784017278617711e-05,
      "loss": 0.002,
      "step": 39410
    },
    {
      "epoch": 12.162912681271212,
      "grad_norm": 0.0001434920122846961,
      "learning_rate": 3.783708731872879e-05,
      "loss": 0.0017,
      "step": 39420
    },
    {
      "epoch": 12.165998148719531,
      "grad_norm": 0.0003623805823735893,
      "learning_rate": 3.783400185128047e-05,
      "loss": 0.0011,
      "step": 39430
    },
    {
      "epoch": 12.16908361616785,
      "grad_norm": 0.0036490734200924635,
      "learning_rate": 3.7830916383832154e-05,
      "loss": 0.0002,
      "step": 39440
    },
    {
      "epoch": 12.172169083616168,
      "grad_norm": 0.09931200742721558,
      "learning_rate": 3.782783091638383e-05,
      "loss": 0.0033,
      "step": 39450
    },
    {
      "epoch": 12.175254551064485,
      "grad_norm": 0.5239060521125793,
      "learning_rate": 3.782474544893552e-05,
      "loss": 0.001,
      "step": 39460
    },
    {
      "epoch": 12.178340018512804,
      "grad_norm": 0.01607098989188671,
      "learning_rate": 3.7821659981487195e-05,
      "loss": 0.0008,
      "step": 39470
    },
    {
      "epoch": 12.181425485961123,
      "grad_norm": 1.987500548362732,
      "learning_rate": 3.781857451403888e-05,
      "loss": 0.0031,
      "step": 39480
    },
    {
      "epoch": 12.184510953409442,
      "grad_norm": 0.002201267285272479,
      "learning_rate": 3.781548904659056e-05,
      "loss": 0.0002,
      "step": 39490
    },
    {
      "epoch": 12.18759642085776,
      "grad_norm": 0.01994481310248375,
      "learning_rate": 3.781240357914224e-05,
      "loss": 0.0013,
      "step": 39500
    },
    {
      "epoch": 12.190681888306079,
      "grad_norm": 0.007741901557892561,
      "learning_rate": 3.7809318111693925e-05,
      "loss": 0.0011,
      "step": 39510
    },
    {
      "epoch": 12.193767355754396,
      "grad_norm": 0.0006471966626122594,
      "learning_rate": 3.78062326442456e-05,
      "loss": 0.006,
      "step": 39520
    },
    {
      "epoch": 12.196852823202715,
      "grad_norm": 0.06904717534780502,
      "learning_rate": 3.780314717679729e-05,
      "loss": 0.0007,
      "step": 39530
    },
    {
      "epoch": 12.199938290651033,
      "grad_norm": 8.253482519648969e-05,
      "learning_rate": 3.7800061709348966e-05,
      "loss": 0.0,
      "step": 39540
    },
    {
      "epoch": 12.203023758099352,
      "grad_norm": 0.04530531167984009,
      "learning_rate": 3.779697624190065e-05,
      "loss": 0.0006,
      "step": 39550
    },
    {
      "epoch": 12.20610922554767,
      "grad_norm": 0.000900974206160754,
      "learning_rate": 3.779389077445234e-05,
      "loss": 0.0002,
      "step": 39560
    },
    {
      "epoch": 12.20919469299599,
      "grad_norm": 0.0015455821994692087,
      "learning_rate": 3.779080530700401e-05,
      "loss": 0.0132,
      "step": 39570
    },
    {
      "epoch": 12.212280160444307,
      "grad_norm": 0.05128619819879532,
      "learning_rate": 3.7787719839555696e-05,
      "loss": 0.0024,
      "step": 39580
    },
    {
      "epoch": 12.215365627892625,
      "grad_norm": 0.01065754983574152,
      "learning_rate": 3.778463437210738e-05,
      "loss": 0.0,
      "step": 39590
    },
    {
      "epoch": 12.218451095340944,
      "grad_norm": 0.2359771430492401,
      "learning_rate": 3.778154890465906e-05,
      "loss": 0.0056,
      "step": 39600
    },
    {
      "epoch": 12.221536562789263,
      "grad_norm": 0.007195870857685804,
      "learning_rate": 3.7778463437210736e-05,
      "loss": 0.0046,
      "step": 39610
    },
    {
      "epoch": 12.224622030237581,
      "grad_norm": 1.9262293790234253e-05,
      "learning_rate": 3.777537796976242e-05,
      "loss": 0.0153,
      "step": 39620
    },
    {
      "epoch": 12.2277074976859,
      "grad_norm": 0.06842826306819916,
      "learning_rate": 3.777229250231411e-05,
      "loss": 0.001,
      "step": 39630
    },
    {
      "epoch": 12.230792965134217,
      "grad_norm": 0.2454451322555542,
      "learning_rate": 3.7769207034865784e-05,
      "loss": 0.0017,
      "step": 39640
    },
    {
      "epoch": 12.233878432582536,
      "grad_norm": 0.09144823998212814,
      "learning_rate": 3.7766121567417466e-05,
      "loss": 0.0005,
      "step": 39650
    },
    {
      "epoch": 12.236963900030855,
      "grad_norm": 0.0012211535358801484,
      "learning_rate": 3.776303609996915e-05,
      "loss": 0.0001,
      "step": 39660
    },
    {
      "epoch": 12.240049367479173,
      "grad_norm": 0.254738986492157,
      "learning_rate": 3.775995063252083e-05,
      "loss": 0.0002,
      "step": 39670
    },
    {
      "epoch": 12.243134834927492,
      "grad_norm": 0.0032883461099117994,
      "learning_rate": 3.775686516507251e-05,
      "loss": 0.0033,
      "step": 39680
    },
    {
      "epoch": 12.24622030237581,
      "grad_norm": 0.00036585924681276083,
      "learning_rate": 3.775377969762419e-05,
      "loss": 0.0024,
      "step": 39690
    },
    {
      "epoch": 12.249305769824128,
      "grad_norm": 0.001082583679817617,
      "learning_rate": 3.775069423017588e-05,
      "loss": 0.0001,
      "step": 39700
    },
    {
      "epoch": 12.252391237272446,
      "grad_norm": 0.00037963438080623746,
      "learning_rate": 3.7747608762727554e-05,
      "loss": 0.0001,
      "step": 39710
    },
    {
      "epoch": 12.255476704720765,
      "grad_norm": 0.18497614562511444,
      "learning_rate": 3.774452329527924e-05,
      "loss": 0.0096,
      "step": 39720
    },
    {
      "epoch": 12.258562172169084,
      "grad_norm": 0.008815057575702667,
      "learning_rate": 3.774143782783092e-05,
      "loss": 0.0075,
      "step": 39730
    },
    {
      "epoch": 12.261647639617403,
      "grad_norm": 0.03208508342504501,
      "learning_rate": 3.77383523603826e-05,
      "loss": 0.0006,
      "step": 39740
    },
    {
      "epoch": 12.264733107065721,
      "grad_norm": 0.0010853377170860767,
      "learning_rate": 3.773526689293428e-05,
      "loss": 0.0022,
      "step": 39750
    },
    {
      "epoch": 12.267818574514038,
      "grad_norm": 0.06930218636989594,
      "learning_rate": 3.773218142548596e-05,
      "loss": 0.0001,
      "step": 39760
    },
    {
      "epoch": 12.270904041962357,
      "grad_norm": 0.0033796599600464106,
      "learning_rate": 3.772909595803765e-05,
      "loss": 0.0037,
      "step": 39770
    },
    {
      "epoch": 12.273989509410676,
      "grad_norm": 0.0003284397243987769,
      "learning_rate": 3.7726010490589325e-05,
      "loss": 0.0006,
      "step": 39780
    },
    {
      "epoch": 12.277074976858994,
      "grad_norm": 0.0007700386340729892,
      "learning_rate": 3.772292502314101e-05,
      "loss": 0.0024,
      "step": 39790
    },
    {
      "epoch": 12.280160444307313,
      "grad_norm": 2.060791015625,
      "learning_rate": 3.771983955569269e-05,
      "loss": 0.0043,
      "step": 39800
    },
    {
      "epoch": 12.283245911755632,
      "grad_norm": 8.465893915854394e-05,
      "learning_rate": 3.771675408824437e-05,
      "loss": 0.0003,
      "step": 39810
    },
    {
      "epoch": 12.286331379203949,
      "grad_norm": 2.971670627593994,
      "learning_rate": 3.771366862079605e-05,
      "loss": 0.0225,
      "step": 39820
    },
    {
      "epoch": 12.289416846652268,
      "grad_norm": 0.026921436190605164,
      "learning_rate": 3.771058315334774e-05,
      "loss": 0.0004,
      "step": 39830
    },
    {
      "epoch": 12.292502314100586,
      "grad_norm": 0.3433944582939148,
      "learning_rate": 3.770749768589942e-05,
      "loss": 0.0087,
      "step": 39840
    },
    {
      "epoch": 12.295587781548905,
      "grad_norm": 0.15966172516345978,
      "learning_rate": 3.7704412218451095e-05,
      "loss": 0.0057,
      "step": 39850
    },
    {
      "epoch": 12.298673248997224,
      "grad_norm": 0.0652330294251442,
      "learning_rate": 3.770132675100278e-05,
      "loss": 0.0012,
      "step": 39860
    },
    {
      "epoch": 12.30175871644554,
      "grad_norm": 0.00018673817976377904,
      "learning_rate": 3.769824128355446e-05,
      "loss": 0.0036,
      "step": 39870
    },
    {
      "epoch": 12.30484418389386,
      "grad_norm": 0.00041155031067319214,
      "learning_rate": 3.769515581610614e-05,
      "loss": 0.0105,
      "step": 39880
    },
    {
      "epoch": 12.307929651342178,
      "grad_norm": 0.8978034257888794,
      "learning_rate": 3.769207034865782e-05,
      "loss": 0.0012,
      "step": 39890
    },
    {
      "epoch": 12.311015118790497,
      "grad_norm": 0.04260583966970444,
      "learning_rate": 3.768898488120951e-05,
      "loss": 0.0008,
      "step": 39900
    },
    {
      "epoch": 12.314100586238816,
      "grad_norm": 9.495465928921476e-05,
      "learning_rate": 3.768589941376119e-05,
      "loss": 0.0005,
      "step": 39910
    },
    {
      "epoch": 12.317186053687134,
      "grad_norm": 3.6064538955688477,
      "learning_rate": 3.7682813946312866e-05,
      "loss": 0.0084,
      "step": 39920
    },
    {
      "epoch": 12.320271521135451,
      "grad_norm": 3.9329352378845215,
      "learning_rate": 3.767972847886455e-05,
      "loss": 0.0093,
      "step": 39930
    },
    {
      "epoch": 12.32335698858377,
      "grad_norm": 1.2386517524719238,
      "learning_rate": 3.767664301141623e-05,
      "loss": 0.0052,
      "step": 39940
    },
    {
      "epoch": 12.326442456032089,
      "grad_norm": 3.525818347930908,
      "learning_rate": 3.767355754396791e-05,
      "loss": 0.0056,
      "step": 39950
    },
    {
      "epoch": 12.329527923480407,
      "grad_norm": 0.004764051176607609,
      "learning_rate": 3.767047207651959e-05,
      "loss": 0.0117,
      "step": 39960
    },
    {
      "epoch": 12.332613390928726,
      "grad_norm": 0.25081172585487366,
      "learning_rate": 3.766738660907128e-05,
      "loss": 0.0023,
      "step": 39970
    },
    {
      "epoch": 12.335698858377045,
      "grad_norm": 0.033446162939071655,
      "learning_rate": 3.766430114162296e-05,
      "loss": 0.0041,
      "step": 39980
    },
    {
      "epoch": 12.338784325825362,
      "grad_norm": 0.0057653700932860374,
      "learning_rate": 3.7661215674174636e-05,
      "loss": 0.0037,
      "step": 39990
    },
    {
      "epoch": 12.34186979327368,
      "grad_norm": 0.001693781465291977,
      "learning_rate": 3.765813020672632e-05,
      "loss": 0.0036,
      "step": 40000
    },
    {
      "epoch": 12.344955260722,
      "grad_norm": 0.010497597977519035,
      "learning_rate": 3.7655044739278e-05,
      "loss": 0.002,
      "step": 40010
    },
    {
      "epoch": 12.348040728170318,
      "grad_norm": 0.002244774252176285,
      "learning_rate": 3.7651959271829684e-05,
      "loss": 0.0024,
      "step": 40020
    },
    {
      "epoch": 12.351126195618637,
      "grad_norm": 0.0003337359521538019,
      "learning_rate": 3.7648873804381366e-05,
      "loss": 0.0007,
      "step": 40030
    },
    {
      "epoch": 12.354211663066955,
      "grad_norm": 0.0034556377213448286,
      "learning_rate": 3.764578833693305e-05,
      "loss": 0.0061,
      "step": 40040
    },
    {
      "epoch": 12.357297130515272,
      "grad_norm": 0.0216357484459877,
      "learning_rate": 3.764270286948473e-05,
      "loss": 0.0023,
      "step": 40050
    },
    {
      "epoch": 12.360382597963591,
      "grad_norm": 0.0001154887504526414,
      "learning_rate": 3.763961740203641e-05,
      "loss": 0.0032,
      "step": 40060
    },
    {
      "epoch": 12.36346806541191,
      "grad_norm": 0.01750318892300129,
      "learning_rate": 3.7636531934588096e-05,
      "loss": 0.0022,
      "step": 40070
    },
    {
      "epoch": 12.366553532860229,
      "grad_norm": 0.00020149101328570396,
      "learning_rate": 3.763344646713977e-05,
      "loss": 0.0002,
      "step": 40080
    },
    {
      "epoch": 12.369639000308547,
      "grad_norm": 0.0009778804378584027,
      "learning_rate": 3.7630360999691454e-05,
      "loss": 0.0049,
      "step": 40090
    },
    {
      "epoch": 12.372724467756866,
      "grad_norm": 4.650721530197188e-05,
      "learning_rate": 3.762727553224314e-05,
      "loss": 0.0058,
      "step": 40100
    },
    {
      "epoch": 12.375809935205183,
      "grad_norm": 0.0026807128451764584,
      "learning_rate": 3.762419006479482e-05,
      "loss": 0.0006,
      "step": 40110
    },
    {
      "epoch": 12.378895402653502,
      "grad_norm": 0.008659007027745247,
      "learning_rate": 3.76211045973465e-05,
      "loss": 0.0007,
      "step": 40120
    },
    {
      "epoch": 12.38198087010182,
      "grad_norm": 0.03665934130549431,
      "learning_rate": 3.761801912989818e-05,
      "loss": 0.0053,
      "step": 40130
    },
    {
      "epoch": 12.385066337550139,
      "grad_norm": 0.001677776570431888,
      "learning_rate": 3.761493366244987e-05,
      "loss": 0.0051,
      "step": 40140
    },
    {
      "epoch": 12.388151804998458,
      "grad_norm": 0.0001339938899036497,
      "learning_rate": 3.761184819500154e-05,
      "loss": 0.0006,
      "step": 40150
    },
    {
      "epoch": 12.391237272446777,
      "grad_norm": 2.4839184284210205,
      "learning_rate": 3.7608762727553225e-05,
      "loss": 0.0024,
      "step": 40160
    },
    {
      "epoch": 12.394322739895093,
      "grad_norm": 0.8977553248405457,
      "learning_rate": 3.760567726010491e-05,
      "loss": 0.0195,
      "step": 40170
    },
    {
      "epoch": 12.397408207343412,
      "grad_norm": 0.002865841845050454,
      "learning_rate": 3.760259179265659e-05,
      "loss": 0.0042,
      "step": 40180
    },
    {
      "epoch": 12.400493674791731,
      "grad_norm": 0.011831305921077728,
      "learning_rate": 3.759950632520827e-05,
      "loss": 0.0014,
      "step": 40190
    },
    {
      "epoch": 12.40357914224005,
      "grad_norm": 2.37910795211792,
      "learning_rate": 3.759642085775995e-05,
      "loss": 0.0032,
      "step": 40200
    },
    {
      "epoch": 12.406664609688368,
      "grad_norm": 0.02467481791973114,
      "learning_rate": 3.759333539031164e-05,
      "loss": 0.0066,
      "step": 40210
    },
    {
      "epoch": 12.409750077136685,
      "grad_norm": 9.606174717191607e-05,
      "learning_rate": 3.759024992286331e-05,
      "loss": 0.0026,
      "step": 40220
    },
    {
      "epoch": 12.412835544585004,
      "grad_norm": 0.05141426622867584,
      "learning_rate": 3.7587164455414996e-05,
      "loss": 0.0016,
      "step": 40230
    },
    {
      "epoch": 12.415921012033323,
      "grad_norm": 0.17663025856018066,
      "learning_rate": 3.758407898796668e-05,
      "loss": 0.0015,
      "step": 40240
    },
    {
      "epoch": 12.419006479481641,
      "grad_norm": 0.0006100141326896846,
      "learning_rate": 3.758099352051836e-05,
      "loss": 0.0019,
      "step": 40250
    },
    {
      "epoch": 12.42209194692996,
      "grad_norm": 0.0015357547672465444,
      "learning_rate": 3.757790805307004e-05,
      "loss": 0.0044,
      "step": 40260
    },
    {
      "epoch": 12.425177414378279,
      "grad_norm": 0.0040818448178470135,
      "learning_rate": 3.757482258562172e-05,
      "loss": 0.0039,
      "step": 40270
    },
    {
      "epoch": 12.428262881826596,
      "grad_norm": 0.0613652840256691,
      "learning_rate": 3.757173711817341e-05,
      "loss": 0.0002,
      "step": 40280
    },
    {
      "epoch": 12.431348349274915,
      "grad_norm": 0.5888261795043945,
      "learning_rate": 3.7568651650725084e-05,
      "loss": 0.0084,
      "step": 40290
    },
    {
      "epoch": 12.434433816723233,
      "grad_norm": 0.30571669340133667,
      "learning_rate": 3.7565566183276766e-05,
      "loss": 0.0055,
      "step": 40300
    },
    {
      "epoch": 12.437519284171552,
      "grad_norm": 0.4577854871749878,
      "learning_rate": 3.756248071582845e-05,
      "loss": 0.0025,
      "step": 40310
    },
    {
      "epoch": 12.44060475161987,
      "grad_norm": 0.01835252158343792,
      "learning_rate": 3.755939524838013e-05,
      "loss": 0.0027,
      "step": 40320
    },
    {
      "epoch": 12.44369021906819,
      "grad_norm": 0.7746424078941345,
      "learning_rate": 3.7556309780931814e-05,
      "loss": 0.0122,
      "step": 40330
    },
    {
      "epoch": 12.446775686516506,
      "grad_norm": 0.021534355357289314,
      "learning_rate": 3.7553224313483496e-05,
      "loss": 0.0001,
      "step": 40340
    },
    {
      "epoch": 12.449861153964825,
      "grad_norm": 0.36701616644859314,
      "learning_rate": 3.755013884603518e-05,
      "loss": 0.0027,
      "step": 40350
    },
    {
      "epoch": 12.452946621413144,
      "grad_norm": 0.0032329182140529156,
      "learning_rate": 3.7547053378586854e-05,
      "loss": 0.0062,
      "step": 40360
    },
    {
      "epoch": 12.456032088861463,
      "grad_norm": 1.229053258895874,
      "learning_rate": 3.754396791113854e-05,
      "loss": 0.0016,
      "step": 40370
    },
    {
      "epoch": 12.459117556309781,
      "grad_norm": 0.0047246916219592094,
      "learning_rate": 3.7540882443690226e-05,
      "loss": 0.0029,
      "step": 40380
    },
    {
      "epoch": 12.4622030237581,
      "grad_norm": 0.028482681140303612,
      "learning_rate": 3.75377969762419e-05,
      "loss": 0.0009,
      "step": 40390
    },
    {
      "epoch": 12.465288491206417,
      "grad_norm": 0.009325262159109116,
      "learning_rate": 3.7534711508793584e-05,
      "loss": 0.0026,
      "step": 40400
    },
    {
      "epoch": 12.468373958654736,
      "grad_norm": 0.07613463699817657,
      "learning_rate": 3.7531626041345267e-05,
      "loss": 0.0025,
      "step": 40410
    },
    {
      "epoch": 12.471459426103054,
      "grad_norm": 0.0022647941950708628,
      "learning_rate": 3.752854057389695e-05,
      "loss": 0.0016,
      "step": 40420
    },
    {
      "epoch": 12.474544893551373,
      "grad_norm": 0.0007215112564153969,
      "learning_rate": 3.752545510644863e-05,
      "loss": 0.0032,
      "step": 40430
    },
    {
      "epoch": 12.477630360999692,
      "grad_norm": 0.1161298006772995,
      "learning_rate": 3.752236963900031e-05,
      "loss": 0.0005,
      "step": 40440
    },
    {
      "epoch": 12.48071582844801,
      "grad_norm": 0.18244247138500214,
      "learning_rate": 3.7519284171551996e-05,
      "loss": 0.0031,
      "step": 40450
    },
    {
      "epoch": 12.483801295896328,
      "grad_norm": 0.014671598561108112,
      "learning_rate": 3.751619870410367e-05,
      "loss": 0.0012,
      "step": 40460
    },
    {
      "epoch": 12.486886763344646,
      "grad_norm": 0.29007503390312195,
      "learning_rate": 3.7513113236655355e-05,
      "loss": 0.0017,
      "step": 40470
    },
    {
      "epoch": 12.489972230792965,
      "grad_norm": 0.4950392246246338,
      "learning_rate": 3.751002776920704e-05,
      "loss": 0.0034,
      "step": 40480
    },
    {
      "epoch": 12.493057698241284,
      "grad_norm": 0.013357706367969513,
      "learning_rate": 3.750694230175872e-05,
      "loss": 0.0033,
      "step": 40490
    },
    {
      "epoch": 12.496143165689602,
      "grad_norm": 0.07055165618658066,
      "learning_rate": 3.75038568343104e-05,
      "loss": 0.0192,
      "step": 40500
    },
    {
      "epoch": 12.499228633137921,
      "grad_norm": 0.028282102197408676,
      "learning_rate": 3.750077136686208e-05,
      "loss": 0.0001,
      "step": 40510
    },
    {
      "epoch": 12.502314100586238,
      "grad_norm": 0.0011717304587364197,
      "learning_rate": 3.749768589941377e-05,
      "loss": 0.0001,
      "step": 40520
    },
    {
      "epoch": 12.505399568034557,
      "grad_norm": 0.11455231159925461,
      "learning_rate": 3.749460043196544e-05,
      "loss": 0.0013,
      "step": 40530
    },
    {
      "epoch": 12.508485035482876,
      "grad_norm": 0.06310323625802994,
      "learning_rate": 3.7491514964517125e-05,
      "loss": 0.0001,
      "step": 40540
    },
    {
      "epoch": 12.511570502931194,
      "grad_norm": 0.00021887091861572117,
      "learning_rate": 3.748842949706881e-05,
      "loss": 0.0004,
      "step": 40550
    },
    {
      "epoch": 12.514655970379513,
      "grad_norm": 2.481642723083496,
      "learning_rate": 3.748534402962049e-05,
      "loss": 0.0036,
      "step": 40560
    },
    {
      "epoch": 12.51774143782783,
      "grad_norm": 0.13862349092960358,
      "learning_rate": 3.748225856217217e-05,
      "loss": 0.0005,
      "step": 40570
    },
    {
      "epoch": 12.520826905276149,
      "grad_norm": 0.02920796163380146,
      "learning_rate": 3.7479173094723855e-05,
      "loss": 0.0001,
      "step": 40580
    },
    {
      "epoch": 12.523912372724467,
      "grad_norm": 0.005434083752334118,
      "learning_rate": 3.747608762727554e-05,
      "loss": 0.0016,
      "step": 40590
    },
    {
      "epoch": 12.526997840172786,
      "grad_norm": 0.0009242428932338953,
      "learning_rate": 3.747300215982721e-05,
      "loss": 0.0094,
      "step": 40600
    },
    {
      "epoch": 12.530083307621105,
      "grad_norm": 0.004303697496652603,
      "learning_rate": 3.7469916692378896e-05,
      "loss": 0.0009,
      "step": 40610
    },
    {
      "epoch": 12.533168775069424,
      "grad_norm": 0.5062374472618103,
      "learning_rate": 3.746683122493058e-05,
      "loss": 0.0027,
      "step": 40620
    },
    {
      "epoch": 12.536254242517742,
      "grad_norm": 0.0016067922115325928,
      "learning_rate": 3.746374575748226e-05,
      "loss": 0.0008,
      "step": 40630
    },
    {
      "epoch": 12.53933970996606,
      "grad_norm": 0.0008970755734480917,
      "learning_rate": 3.746066029003394e-05,
      "loss": 0.0078,
      "step": 40640
    },
    {
      "epoch": 12.542425177414378,
      "grad_norm": 0.1300109475851059,
      "learning_rate": 3.7457574822585626e-05,
      "loss": 0.0021,
      "step": 40650
    },
    {
      "epoch": 12.545510644862697,
      "grad_norm": 0.004915725439786911,
      "learning_rate": 3.745448935513731e-05,
      "loss": 0.003,
      "step": 40660
    },
    {
      "epoch": 12.548596112311015,
      "grad_norm": 0.0005591257940977812,
      "learning_rate": 3.7451403887688984e-05,
      "loss": 0.001,
      "step": 40670
    },
    {
      "epoch": 12.551681579759334,
      "grad_norm": 1.7078882455825806,
      "learning_rate": 3.7448318420240666e-05,
      "loss": 0.0027,
      "step": 40680
    },
    {
      "epoch": 12.554767047207651,
      "grad_norm": 1.8952645063400269,
      "learning_rate": 3.744523295279235e-05,
      "loss": 0.0015,
      "step": 40690
    },
    {
      "epoch": 12.55785251465597,
      "grad_norm": 0.003035173751413822,
      "learning_rate": 3.744214748534403e-05,
      "loss": 0.0002,
      "step": 40700
    },
    {
      "epoch": 12.560937982104289,
      "grad_norm": 0.009274824522435665,
      "learning_rate": 3.7439062017895714e-05,
      "loss": 0.0051,
      "step": 40710
    },
    {
      "epoch": 12.564023449552607,
      "grad_norm": 0.0005036731599830091,
      "learning_rate": 3.7435976550447396e-05,
      "loss": 0.0003,
      "step": 40720
    },
    {
      "epoch": 12.567108917000926,
      "grad_norm": 0.5893164277076721,
      "learning_rate": 3.743289108299908e-05,
      "loss": 0.0027,
      "step": 40730
    },
    {
      "epoch": 12.570194384449245,
      "grad_norm": 7.362276664935052e-05,
      "learning_rate": 3.7429805615550754e-05,
      "loss": 0.0008,
      "step": 40740
    },
    {
      "epoch": 12.573279851897562,
      "grad_norm": 0.0009867697954177856,
      "learning_rate": 3.742672014810244e-05,
      "loss": 0.0058,
      "step": 40750
    },
    {
      "epoch": 12.57636531934588,
      "grad_norm": 0.004718557931482792,
      "learning_rate": 3.742363468065412e-05,
      "loss": 0.0081,
      "step": 40760
    },
    {
      "epoch": 12.5794507867942,
      "grad_norm": 0.23805488646030426,
      "learning_rate": 3.74205492132058e-05,
      "loss": 0.0022,
      "step": 40770
    },
    {
      "epoch": 12.582536254242518,
      "grad_norm": 0.013920441269874573,
      "learning_rate": 3.7417463745757484e-05,
      "loss": 0.0009,
      "step": 40780
    },
    {
      "epoch": 12.585621721690837,
      "grad_norm": 0.003394290804862976,
      "learning_rate": 3.741437827830917e-05,
      "loss": 0.0118,
      "step": 40790
    },
    {
      "epoch": 12.588707189139155,
      "grad_norm": 0.9177032113075256,
      "learning_rate": 3.741129281086085e-05,
      "loss": 0.0037,
      "step": 40800
    },
    {
      "epoch": 12.591792656587472,
      "grad_norm": 0.0684531107544899,
      "learning_rate": 3.7408207343412525e-05,
      "loss": 0.009,
      "step": 40810
    },
    {
      "epoch": 12.594878124035791,
      "grad_norm": 0.00016128986317198724,
      "learning_rate": 3.740512187596421e-05,
      "loss": 0.0026,
      "step": 40820
    },
    {
      "epoch": 12.59796359148411,
      "grad_norm": 0.01814916357398033,
      "learning_rate": 3.740203640851589e-05,
      "loss": 0.0006,
      "step": 40830
    },
    {
      "epoch": 12.601049058932428,
      "grad_norm": 0.015294386073946953,
      "learning_rate": 3.739895094106757e-05,
      "loss": 0.0015,
      "step": 40840
    },
    {
      "epoch": 12.604134526380747,
      "grad_norm": 0.06303075700998306,
      "learning_rate": 3.7395865473619255e-05,
      "loss": 0.0101,
      "step": 40850
    },
    {
      "epoch": 12.607219993829066,
      "grad_norm": 0.007289350964128971,
      "learning_rate": 3.739278000617094e-05,
      "loss": 0.0008,
      "step": 40860
    },
    {
      "epoch": 12.610305461277383,
      "grad_norm": 0.012272360734641552,
      "learning_rate": 3.738969453872262e-05,
      "loss": 0.004,
      "step": 40870
    },
    {
      "epoch": 12.613390928725702,
      "grad_norm": 0.002220693975687027,
      "learning_rate": 3.7386609071274296e-05,
      "loss": 0.0023,
      "step": 40880
    },
    {
      "epoch": 12.61647639617402,
      "grad_norm": 0.0011562923900783062,
      "learning_rate": 3.7383523603825985e-05,
      "loss": 0.0027,
      "step": 40890
    },
    {
      "epoch": 12.619561863622339,
      "grad_norm": 0.03185718134045601,
      "learning_rate": 3.738043813637767e-05,
      "loss": 0.0015,
      "step": 40900
    },
    {
      "epoch": 12.622647331070658,
      "grad_norm": 0.016810273751616478,
      "learning_rate": 3.737735266892934e-05,
      "loss": 0.003,
      "step": 40910
    },
    {
      "epoch": 12.625732798518976,
      "grad_norm": 1.6544350385665894,
      "learning_rate": 3.7374267201481025e-05,
      "loss": 0.0077,
      "step": 40920
    },
    {
      "epoch": 12.628818265967293,
      "grad_norm": 2.0149054527282715,
      "learning_rate": 3.737118173403271e-05,
      "loss": 0.0116,
      "step": 40930
    },
    {
      "epoch": 12.631903733415612,
      "grad_norm": 0.04601345211267471,
      "learning_rate": 3.736809626658439e-05,
      "loss": 0.0012,
      "step": 40940
    },
    {
      "epoch": 12.63498920086393,
      "grad_norm": 0.015891242772340775,
      "learning_rate": 3.7365010799136066e-05,
      "loss": 0.0007,
      "step": 40950
    },
    {
      "epoch": 12.63807466831225,
      "grad_norm": 1.7267719507217407,
      "learning_rate": 3.7361925331687755e-05,
      "loss": 0.006,
      "step": 40960
    },
    {
      "epoch": 12.641160135760568,
      "grad_norm": 0.0001780534366844222,
      "learning_rate": 3.735883986423944e-05,
      "loss": 0.0068,
      "step": 40970
    },
    {
      "epoch": 12.644245603208887,
      "grad_norm": 0.0020114430226385593,
      "learning_rate": 3.7355754396791114e-05,
      "loss": 0.0013,
      "step": 40980
    },
    {
      "epoch": 12.647331070657204,
      "grad_norm": 0.0022314037196338177,
      "learning_rate": 3.7352668929342796e-05,
      "loss": 0.0015,
      "step": 40990
    },
    {
      "epoch": 12.650416538105523,
      "grad_norm": 0.06802988052368164,
      "learning_rate": 3.734958346189448e-05,
      "loss": 0.0003,
      "step": 41000
    },
    {
      "epoch": 12.653502005553841,
      "grad_norm": 0.047741323709487915,
      "learning_rate": 3.734649799444616e-05,
      "loss": 0.0071,
      "step": 41010
    },
    {
      "epoch": 12.65658747300216,
      "grad_norm": 0.005442093126475811,
      "learning_rate": 3.734341252699784e-05,
      "loss": 0.0047,
      "step": 41020
    },
    {
      "epoch": 12.659672940450479,
      "grad_norm": 0.002975477371364832,
      "learning_rate": 3.7340327059549526e-05,
      "loss": 0.0003,
      "step": 41030
    },
    {
      "epoch": 12.662758407898796,
      "grad_norm": 0.5538316369056702,
      "learning_rate": 3.733724159210121e-05,
      "loss": 0.0008,
      "step": 41040
    },
    {
      "epoch": 12.665843875347115,
      "grad_norm": 1.3414616584777832,
      "learning_rate": 3.7334156124652884e-05,
      "loss": 0.003,
      "step": 41050
    },
    {
      "epoch": 12.668929342795433,
      "grad_norm": 0.0393390879034996,
      "learning_rate": 3.7331070657204567e-05,
      "loss": 0.0028,
      "step": 41060
    },
    {
      "epoch": 12.672014810243752,
      "grad_norm": 0.002952065784484148,
      "learning_rate": 3.732798518975625e-05,
      "loss": 0.0047,
      "step": 41070
    },
    {
      "epoch": 12.67510027769207,
      "grad_norm": 0.00324165727943182,
      "learning_rate": 3.732489972230793e-05,
      "loss": 0.0007,
      "step": 41080
    },
    {
      "epoch": 12.67818574514039,
      "grad_norm": 0.0006316578947007656,
      "learning_rate": 3.732181425485961e-05,
      "loss": 0.0043,
      "step": 41090
    },
    {
      "epoch": 12.681271212588706,
      "grad_norm": 0.44697341322898865,
      "learning_rate": 3.7318728787411296e-05,
      "loss": 0.0119,
      "step": 41100
    },
    {
      "epoch": 12.684356680037025,
      "grad_norm": 0.04599299654364586,
      "learning_rate": 3.731564331996298e-05,
      "loss": 0.0009,
      "step": 41110
    },
    {
      "epoch": 12.687442147485344,
      "grad_norm": 0.001822284422814846,
      "learning_rate": 3.7312557852514655e-05,
      "loss": 0.0086,
      "step": 41120
    },
    {
      "epoch": 12.690527614933663,
      "grad_norm": 0.00040194785105995834,
      "learning_rate": 3.7309472385066344e-05,
      "loss": 0.0007,
      "step": 41130
    },
    {
      "epoch": 12.693613082381981,
      "grad_norm": 0.0007814174168743193,
      "learning_rate": 3.730638691761802e-05,
      "loss": 0.0002,
      "step": 41140
    },
    {
      "epoch": 12.6966985498303,
      "grad_norm": 0.0002148863859474659,
      "learning_rate": 3.73033014501697e-05,
      "loss": 0.0016,
      "step": 41150
    },
    {
      "epoch": 12.699784017278617,
      "grad_norm": 0.011875050142407417,
      "learning_rate": 3.7300215982721385e-05,
      "loss": 0.0003,
      "step": 41160
    },
    {
      "epoch": 12.702869484726936,
      "grad_norm": 0.20860017836093903,
      "learning_rate": 3.729713051527307e-05,
      "loss": 0.0024,
      "step": 41170
    },
    {
      "epoch": 12.705954952175254,
      "grad_norm": 0.00034745666198432446,
      "learning_rate": 3.729404504782475e-05,
      "loss": 0.0019,
      "step": 41180
    },
    {
      "epoch": 12.709040419623573,
      "grad_norm": 0.04849106818437576,
      "learning_rate": 3.7290959580376425e-05,
      "loss": 0.0001,
      "step": 41190
    },
    {
      "epoch": 12.712125887071892,
      "grad_norm": 0.0054045310243964195,
      "learning_rate": 3.7287874112928114e-05,
      "loss": 0.0104,
      "step": 41200
    },
    {
      "epoch": 12.71521135452021,
      "grad_norm": 0.0017999381525442004,
      "learning_rate": 3.728478864547979e-05,
      "loss": 0.0003,
      "step": 41210
    },
    {
      "epoch": 12.718296821968528,
      "grad_norm": 0.15986822545528412,
      "learning_rate": 3.728170317803147e-05,
      "loss": 0.0014,
      "step": 41220
    },
    {
      "epoch": 12.721382289416846,
      "grad_norm": 0.0121420593932271,
      "learning_rate": 3.7278617710583155e-05,
      "loss": 0.0046,
      "step": 41230
    },
    {
      "epoch": 12.724467756865165,
      "grad_norm": 0.003655605483800173,
      "learning_rate": 3.727553224313484e-05,
      "loss": 0.0006,
      "step": 41240
    },
    {
      "epoch": 12.727553224313484,
      "grad_norm": 0.01723954640328884,
      "learning_rate": 3.727244677568652e-05,
      "loss": 0.0017,
      "step": 41250
    },
    {
      "epoch": 12.730638691761802,
      "grad_norm": 1.213949203491211,
      "learning_rate": 3.7269361308238196e-05,
      "loss": 0.0021,
      "step": 41260
    },
    {
      "epoch": 12.733724159210121,
      "grad_norm": 0.005634264089167118,
      "learning_rate": 3.7266275840789885e-05,
      "loss": 0.0048,
      "step": 41270
    },
    {
      "epoch": 12.736809626658438,
      "grad_norm": 0.0005821830709464848,
      "learning_rate": 3.726319037334156e-05,
      "loss": 0.0002,
      "step": 41280
    },
    {
      "epoch": 12.739895094106757,
      "grad_norm": 0.16299250721931458,
      "learning_rate": 3.726010490589324e-05,
      "loss": 0.0093,
      "step": 41290
    },
    {
      "epoch": 12.742980561555076,
      "grad_norm": 0.0015234039165079594,
      "learning_rate": 3.7257019438444926e-05,
      "loss": 0.004,
      "step": 41300
    },
    {
      "epoch": 12.746066029003394,
      "grad_norm": 0.018925100564956665,
      "learning_rate": 3.725393397099661e-05,
      "loss": 0.0064,
      "step": 41310
    },
    {
      "epoch": 12.749151496451713,
      "grad_norm": 0.00783884059637785,
      "learning_rate": 3.725084850354829e-05,
      "loss": 0.0011,
      "step": 41320
    },
    {
      "epoch": 12.752236963900032,
      "grad_norm": 0.014825655147433281,
      "learning_rate": 3.7247763036099966e-05,
      "loss": 0.0016,
      "step": 41330
    },
    {
      "epoch": 12.755322431348349,
      "grad_norm": 0.01704998128116131,
      "learning_rate": 3.7244677568651656e-05,
      "loss": 0.0031,
      "step": 41340
    },
    {
      "epoch": 12.758407898796667,
      "grad_norm": 0.7301537990570068,
      "learning_rate": 3.724159210120333e-05,
      "loss": 0.0018,
      "step": 41350
    },
    {
      "epoch": 12.761493366244986,
      "grad_norm": 0.027326922863721848,
      "learning_rate": 3.7238506633755014e-05,
      "loss": 0.0001,
      "step": 41360
    },
    {
      "epoch": 12.764578833693305,
      "grad_norm": 0.002378528704866767,
      "learning_rate": 3.72354211663067e-05,
      "loss": 0.0002,
      "step": 41370
    },
    {
      "epoch": 12.767664301141624,
      "grad_norm": 0.09541846066713333,
      "learning_rate": 3.723233569885838e-05,
      "loss": 0.0025,
      "step": 41380
    },
    {
      "epoch": 12.77074976858994,
      "grad_norm": 0.005616127047687769,
      "learning_rate": 3.722925023141006e-05,
      "loss": 0.001,
      "step": 41390
    },
    {
      "epoch": 12.77383523603826,
      "grad_norm": 0.027258429676294327,
      "learning_rate": 3.7226164763961744e-05,
      "loss": 0.0019,
      "step": 41400
    },
    {
      "epoch": 12.776920703486578,
      "grad_norm": 7.565209865570068,
      "learning_rate": 3.7223079296513426e-05,
      "loss": 0.0136,
      "step": 41410
    },
    {
      "epoch": 12.780006170934897,
      "grad_norm": 8.669218368595466e-05,
      "learning_rate": 3.72199938290651e-05,
      "loss": 0.0008,
      "step": 41420
    },
    {
      "epoch": 12.783091638383215,
      "grad_norm": 0.0010070310672745109,
      "learning_rate": 3.7216908361616784e-05,
      "loss": 0.0071,
      "step": 41430
    },
    {
      "epoch": 12.786177105831534,
      "grad_norm": 0.002964332001283765,
      "learning_rate": 3.7213822894168474e-05,
      "loss": 0.0006,
      "step": 41440
    },
    {
      "epoch": 12.789262573279853,
      "grad_norm": 0.07355144619941711,
      "learning_rate": 3.721073742672015e-05,
      "loss": 0.0066,
      "step": 41450
    },
    {
      "epoch": 12.79234804072817,
      "grad_norm": 0.0146507378667593,
      "learning_rate": 3.720765195927183e-05,
      "loss": 0.0013,
      "step": 41460
    },
    {
      "epoch": 12.795433508176489,
      "grad_norm": 0.3802548348903656,
      "learning_rate": 3.7204566491823514e-05,
      "loss": 0.0015,
      "step": 41470
    },
    {
      "epoch": 12.798518975624807,
      "grad_norm": 0.8166021108627319,
      "learning_rate": 3.72014810243752e-05,
      "loss": 0.0028,
      "step": 41480
    },
    {
      "epoch": 12.801604443073126,
      "grad_norm": 0.02877267450094223,
      "learning_rate": 3.719839555692687e-05,
      "loss": 0.0021,
      "step": 41490
    },
    {
      "epoch": 12.804689910521445,
      "grad_norm": 0.0004200704279355705,
      "learning_rate": 3.7195310089478555e-05,
      "loss": 0.0012,
      "step": 41500
    },
    {
      "epoch": 12.807775377969762,
      "grad_norm": 0.006750214844942093,
      "learning_rate": 3.7192224622030244e-05,
      "loss": 0.0007,
      "step": 41510
    },
    {
      "epoch": 12.81086084541808,
      "grad_norm": 0.5991680026054382,
      "learning_rate": 3.718913915458192e-05,
      "loss": 0.0032,
      "step": 41520
    },
    {
      "epoch": 12.813946312866399,
      "grad_norm": 0.024883707985281944,
      "learning_rate": 3.71860536871336e-05,
      "loss": 0.003,
      "step": 41530
    },
    {
      "epoch": 12.817031780314718,
      "grad_norm": 0.003989658318459988,
      "learning_rate": 3.7182968219685285e-05,
      "loss": 0.0006,
      "step": 41540
    },
    {
      "epoch": 12.820117247763037,
      "grad_norm": 0.0007753297686576843,
      "learning_rate": 3.717988275223697e-05,
      "loss": 0.0015,
      "step": 41550
    },
    {
      "epoch": 12.823202715211355,
      "grad_norm": 0.5236560702323914,
      "learning_rate": 3.717679728478864e-05,
      "loss": 0.006,
      "step": 41560
    },
    {
      "epoch": 12.826288182659672,
      "grad_norm": 0.05913488194346428,
      "learning_rate": 3.7173711817340325e-05,
      "loss": 0.0012,
      "step": 41570
    },
    {
      "epoch": 12.829373650107991,
      "grad_norm": 1.988168478012085,
      "learning_rate": 3.7170626349892015e-05,
      "loss": 0.0089,
      "step": 41580
    },
    {
      "epoch": 12.83245911755631,
      "grad_norm": 0.0012319136876612902,
      "learning_rate": 3.716754088244369e-05,
      "loss": 0.0105,
      "step": 41590
    },
    {
      "epoch": 12.835544585004628,
      "grad_norm": 1.4920969009399414,
      "learning_rate": 3.716445541499537e-05,
      "loss": 0.0029,
      "step": 41600
    },
    {
      "epoch": 12.838630052452947,
      "grad_norm": 1.33357834815979,
      "learning_rate": 3.7161369947547055e-05,
      "loss": 0.0015,
      "step": 41610
    },
    {
      "epoch": 12.841715519901266,
      "grad_norm": 2.0369250774383545,
      "learning_rate": 3.715828448009874e-05,
      "loss": 0.0026,
      "step": 41620
    },
    {
      "epoch": 12.844800987349583,
      "grad_norm": 0.0004891909193247557,
      "learning_rate": 3.7155199012650414e-05,
      "loss": 0.0006,
      "step": 41630
    },
    {
      "epoch": 12.847886454797901,
      "grad_norm": 0.003503514686599374,
      "learning_rate": 3.71521135452021e-05,
      "loss": 0.002,
      "step": 41640
    },
    {
      "epoch": 12.85097192224622,
      "grad_norm": 0.001376922009512782,
      "learning_rate": 3.7149028077753785e-05,
      "loss": 0.0011,
      "step": 41650
    },
    {
      "epoch": 12.854057389694539,
      "grad_norm": 0.16026197373867035,
      "learning_rate": 3.714594261030546e-05,
      "loss": 0.0002,
      "step": 41660
    },
    {
      "epoch": 12.857142857142858,
      "grad_norm": 0.001912442035973072,
      "learning_rate": 3.7142857142857143e-05,
      "loss": 0.0003,
      "step": 41670
    },
    {
      "epoch": 12.860228324591176,
      "grad_norm": 0.005545193795114756,
      "learning_rate": 3.7139771675408826e-05,
      "loss": 0.006,
      "step": 41680
    },
    {
      "epoch": 12.863313792039493,
      "grad_norm": 0.023490065708756447,
      "learning_rate": 3.713668620796051e-05,
      "loss": 0.0026,
      "step": 41690
    },
    {
      "epoch": 12.866399259487812,
      "grad_norm": 0.0014697303995490074,
      "learning_rate": 3.7133600740512184e-05,
      "loss": 0.0011,
      "step": 41700
    },
    {
      "epoch": 12.86948472693613,
      "grad_norm": 0.0007805732311680913,
      "learning_rate": 3.713051527306387e-05,
      "loss": 0.0007,
      "step": 41710
    },
    {
      "epoch": 12.87257019438445,
      "grad_norm": 0.0038530847523361444,
      "learning_rate": 3.7127429805615556e-05,
      "loss": 0.0022,
      "step": 41720
    },
    {
      "epoch": 12.875655661832768,
      "grad_norm": 0.003356264904141426,
      "learning_rate": 3.712434433816723e-05,
      "loss": 0.0003,
      "step": 41730
    },
    {
      "epoch": 12.878741129281085,
      "grad_norm": 0.3058244585990906,
      "learning_rate": 3.7121258870718914e-05,
      "loss": 0.0009,
      "step": 41740
    },
    {
      "epoch": 12.881826596729404,
      "grad_norm": 0.009562610648572445,
      "learning_rate": 3.7118173403270597e-05,
      "loss": 0.0002,
      "step": 41750
    },
    {
      "epoch": 12.884912064177723,
      "grad_norm": 0.00048685495858080685,
      "learning_rate": 3.711508793582228e-05,
      "loss": 0.0001,
      "step": 41760
    },
    {
      "epoch": 12.887997531626041,
      "grad_norm": 0.0003407350741326809,
      "learning_rate": 3.711200246837396e-05,
      "loss": 0.0033,
      "step": 41770
    },
    {
      "epoch": 12.89108299907436,
      "grad_norm": 1.6997679471969604,
      "learning_rate": 3.7108917000925644e-05,
      "loss": 0.0022,
      "step": 41780
    },
    {
      "epoch": 12.894168466522679,
      "grad_norm": 0.0009124575881287456,
      "learning_rate": 3.7105831533477326e-05,
      "loss": 0.0069,
      "step": 41790
    },
    {
      "epoch": 12.897253933970998,
      "grad_norm": 0.001647004741244018,
      "learning_rate": 3.7102746066029e-05,
      "loss": 0.0088,
      "step": 41800
    },
    {
      "epoch": 12.900339401419314,
      "grad_norm": 0.0022494662553071976,
      "learning_rate": 3.7099660598580685e-05,
      "loss": 0.0033,
      "step": 41810
    },
    {
      "epoch": 12.903424868867633,
      "grad_norm": 0.3837117552757263,
      "learning_rate": 3.709657513113237e-05,
      "loss": 0.0007,
      "step": 41820
    },
    {
      "epoch": 12.906510336315952,
      "grad_norm": 0.007616149261593819,
      "learning_rate": 3.709348966368405e-05,
      "loss": 0.0007,
      "step": 41830
    },
    {
      "epoch": 12.90959580376427,
      "grad_norm": 0.1482764184474945,
      "learning_rate": 3.709040419623573e-05,
      "loss": 0.0002,
      "step": 41840
    },
    {
      "epoch": 12.91268127121259,
      "grad_norm": 0.04701925814151764,
      "learning_rate": 3.7087318728787415e-05,
      "loss": 0.0004,
      "step": 41850
    },
    {
      "epoch": 12.915766738660906,
      "grad_norm": 0.004938502795994282,
      "learning_rate": 3.70842332613391e-05,
      "loss": 0.0006,
      "step": 41860
    },
    {
      "epoch": 12.918852206109225,
      "grad_norm": 3.223007661290467e-05,
      "learning_rate": 3.708114779389077e-05,
      "loss": 0.0025,
      "step": 41870
    },
    {
      "epoch": 12.921937673557544,
      "grad_norm": 1.7803925275802612,
      "learning_rate": 3.707806232644246e-05,
      "loss": 0.0023,
      "step": 41880
    },
    {
      "epoch": 12.925023141005862,
      "grad_norm": 0.0015309631126001477,
      "learning_rate": 3.707497685899414e-05,
      "loss": 0.0,
      "step": 41890
    },
    {
      "epoch": 12.928108608454181,
      "grad_norm": 0.00637843506410718,
      "learning_rate": 3.707189139154582e-05,
      "loss": 0.0001,
      "step": 41900
    },
    {
      "epoch": 12.9311940759025,
      "grad_norm": 0.21221952140331268,
      "learning_rate": 3.70688059240975e-05,
      "loss": 0.0011,
      "step": 41910
    },
    {
      "epoch": 12.934279543350817,
      "grad_norm": 0.00861812848597765,
      "learning_rate": 3.7065720456649185e-05,
      "loss": 0.0009,
      "step": 41920
    },
    {
      "epoch": 12.937365010799136,
      "grad_norm": 0.06602583825588226,
      "learning_rate": 3.706263498920087e-05,
      "loss": 0.0008,
      "step": 41930
    },
    {
      "epoch": 12.940450478247454,
      "grad_norm": 0.013160341419279575,
      "learning_rate": 3.705954952175254e-05,
      "loss": 0.0035,
      "step": 41940
    },
    {
      "epoch": 12.943535945695773,
      "grad_norm": 0.11925280839204788,
      "learning_rate": 3.705646405430423e-05,
      "loss": 0.0002,
      "step": 41950
    },
    {
      "epoch": 12.946621413144092,
      "grad_norm": 1.052024483680725,
      "learning_rate": 3.705337858685591e-05,
      "loss": 0.0012,
      "step": 41960
    },
    {
      "epoch": 12.94970688059241,
      "grad_norm": 0.008013324812054634,
      "learning_rate": 3.705029311940759e-05,
      "loss": 0.0008,
      "step": 41970
    },
    {
      "epoch": 12.952792348040727,
      "grad_norm": 0.0010158889926970005,
      "learning_rate": 3.704720765195927e-05,
      "loss": 0.0022,
      "step": 41980
    },
    {
      "epoch": 12.955877815489046,
      "grad_norm": 0.4754120111465454,
      "learning_rate": 3.7044122184510956e-05,
      "loss": 0.0012,
      "step": 41990
    },
    {
      "epoch": 12.958963282937365,
      "grad_norm": 0.0018025832250714302,
      "learning_rate": 3.704103671706264e-05,
      "loss": 0.0069,
      "step": 42000
    },
    {
      "epoch": 12.962048750385684,
      "grad_norm": 0.00909697450697422,
      "learning_rate": 3.7037951249614314e-05,
      "loss": 0.0006,
      "step": 42010
    },
    {
      "epoch": 12.965134217834002,
      "grad_norm": 0.041399162262678146,
      "learning_rate": 3.7034865782166e-05,
      "loss": 0.0003,
      "step": 42020
    },
    {
      "epoch": 12.968219685282321,
      "grad_norm": 0.27968472242355347,
      "learning_rate": 3.703178031471768e-05,
      "loss": 0.0005,
      "step": 42030
    },
    {
      "epoch": 12.971305152730638,
      "grad_norm": 0.0010144251864403486,
      "learning_rate": 3.702869484726936e-05,
      "loss": 0.0,
      "step": 42040
    },
    {
      "epoch": 12.974390620178957,
      "grad_norm": 3.067835569381714,
      "learning_rate": 3.7025609379821044e-05,
      "loss": 0.0035,
      "step": 42050
    },
    {
      "epoch": 12.977476087627275,
      "grad_norm": 0.0338832288980484,
      "learning_rate": 3.7022523912372726e-05,
      "loss": 0.0006,
      "step": 42060
    },
    {
      "epoch": 12.980561555075594,
      "grad_norm": 0.09265121817588806,
      "learning_rate": 3.701943844492441e-05,
      "loss": 0.0001,
      "step": 42070
    },
    {
      "epoch": 12.983647022523913,
      "grad_norm": 0.012034480459988117,
      "learning_rate": 3.7016352977476084e-05,
      "loss": 0.001,
      "step": 42080
    },
    {
      "epoch": 12.986732489972232,
      "grad_norm": 0.008479956537485123,
      "learning_rate": 3.7013267510027774e-05,
      "loss": 0.0005,
      "step": 42090
    },
    {
      "epoch": 12.989817957420549,
      "grad_norm": 0.00024220104387495667,
      "learning_rate": 3.701018204257945e-05,
      "loss": 0.0016,
      "step": 42100
    },
    {
      "epoch": 12.992903424868867,
      "grad_norm": 0.09487780928611755,
      "learning_rate": 3.700709657513113e-05,
      "loss": 0.0013,
      "step": 42110
    },
    {
      "epoch": 12.995988892317186,
      "grad_norm": 0.00847742147743702,
      "learning_rate": 3.700401110768282e-05,
      "loss": 0.0018,
      "step": 42120
    },
    {
      "epoch": 12.999074359765505,
      "grad_norm": 0.3331124484539032,
      "learning_rate": 3.70009256402345e-05,
      "loss": 0.0002,
      "step": 42130
    },
    {
      "epoch": 13.0,
      "eval_accuracy_branch1": 0.9988136917334568,
      "eval_accuracy_branch2": 0.4052062536770734,
      "eval_f1_branch1": 0.9986804715312952,
      "eval_f1_branch2": 0.39152516334446447,
      "eval_loss": 0.0009045266779139638,
      "eval_precision_branch1": 0.9986788499129511,
      "eval_precision_branch2": 0.5179363815645758,
      "eval_recall_branch1": 0.9986886531932323,
      "eval_recall_branch2": 0.5120873238621567,
      "eval_runtime": 239.7826,
      "eval_samples_per_second": 432.404,
      "eval_steps_per_second": 54.053,
      "step": 42133
    },
    {
      "epoch": 13.002159827213823,
      "grad_norm": 0.0012702976819127798,
      "learning_rate": 3.699784017278618e-05,
      "loss": 0.0082,
      "step": 42140
    },
    {
      "epoch": 13.005245294662142,
      "grad_norm": 0.06144598871469498,
      "learning_rate": 3.699475470533786e-05,
      "loss": 0.0041,
      "step": 42150
    },
    {
      "epoch": 13.00833076211046,
      "grad_norm": 4.606373310089111,
      "learning_rate": 3.6991669237889544e-05,
      "loss": 0.0038,
      "step": 42160
    },
    {
      "epoch": 13.011416229558778,
      "grad_norm": 0.017013367265462875,
      "learning_rate": 3.698858377044123e-05,
      "loss": 0.0017,
      "step": 42170
    },
    {
      "epoch": 13.014501697007097,
      "grad_norm": 0.007903866469860077,
      "learning_rate": 3.69854983029929e-05,
      "loss": 0.0089,
      "step": 42180
    },
    {
      "epoch": 13.017587164455415,
      "grad_norm": 0.011680200695991516,
      "learning_rate": 3.698241283554459e-05,
      "loss": 0.0004,
      "step": 42190
    },
    {
      "epoch": 13.020672631903734,
      "grad_norm": 0.0006614621379412711,
      "learning_rate": 3.697932736809627e-05,
      "loss": 0.0063,
      "step": 42200
    },
    {
      "epoch": 13.023758099352051,
      "grad_norm": 0.03340817987918854,
      "learning_rate": 3.697624190064795e-05,
      "loss": 0.0002,
      "step": 42210
    },
    {
      "epoch": 13.02684356680037,
      "grad_norm": 1.8992823362350464,
      "learning_rate": 3.697315643319963e-05,
      "loss": 0.0019,
      "step": 42220
    },
    {
      "epoch": 13.029929034248688,
      "grad_norm": 0.1763841062784195,
      "learning_rate": 3.6970070965751315e-05,
      "loss": 0.0019,
      "step": 42230
    },
    {
      "epoch": 13.033014501697007,
      "grad_norm": 0.0004509620775934309,
      "learning_rate": 3.6966985498303e-05,
      "loss": 0.0014,
      "step": 42240
    },
    {
      "epoch": 13.036099969145326,
      "grad_norm": 0.07958964258432388,
      "learning_rate": 3.696390003085467e-05,
      "loss": 0.0048,
      "step": 42250
    },
    {
      "epoch": 13.039185436593645,
      "grad_norm": 0.011609803885221481,
      "learning_rate": 3.696081456340636e-05,
      "loss": 0.005,
      "step": 42260
    },
    {
      "epoch": 13.042270904041962,
      "grad_norm": 0.15329860150814056,
      "learning_rate": 3.695772909595804e-05,
      "loss": 0.0014,
      "step": 42270
    },
    {
      "epoch": 13.04535637149028,
      "grad_norm": 0.06390591710805893,
      "learning_rate": 3.695464362850972e-05,
      "loss": 0.0016,
      "step": 42280
    },
    {
      "epoch": 13.048441838938599,
      "grad_norm": 0.0002260109322378412,
      "learning_rate": 3.69515581610614e-05,
      "loss": 0.0019,
      "step": 42290
    },
    {
      "epoch": 13.051527306386918,
      "grad_norm": 0.0011073948116973042,
      "learning_rate": 3.6948472693613085e-05,
      "loss": 0.0098,
      "step": 42300
    },
    {
      "epoch": 13.054612773835236,
      "grad_norm": 0.0012336198706179857,
      "learning_rate": 3.694538722616477e-05,
      "loss": 0.0016,
      "step": 42310
    },
    {
      "epoch": 13.057698241283555,
      "grad_norm": 0.03013441525399685,
      "learning_rate": 3.6942301758716443e-05,
      "loss": 0.0002,
      "step": 42320
    },
    {
      "epoch": 13.060783708731872,
      "grad_norm": 0.00039103871677070856,
      "learning_rate": 3.693921629126813e-05,
      "loss": 0.0004,
      "step": 42330
    },
    {
      "epoch": 13.06386917618019,
      "grad_norm": 0.004225368145853281,
      "learning_rate": 3.693613082381981e-05,
      "loss": 0.0011,
      "step": 42340
    },
    {
      "epoch": 13.06695464362851,
      "grad_norm": 5.9907565628236625e-06,
      "learning_rate": 3.693304535637149e-05,
      "loss": 0.0066,
      "step": 42350
    },
    {
      "epoch": 13.070040111076828,
      "grad_norm": 0.004421623423695564,
      "learning_rate": 3.6929959888923173e-05,
      "loss": 0.0004,
      "step": 42360
    },
    {
      "epoch": 13.073125578525147,
      "grad_norm": 0.00015654864546377212,
      "learning_rate": 3.6926874421474856e-05,
      "loss": 0.0012,
      "step": 42370
    },
    {
      "epoch": 13.076211045973466,
      "grad_norm": 0.002403650898486376,
      "learning_rate": 3.692378895402654e-05,
      "loss": 0.0006,
      "step": 42380
    },
    {
      "epoch": 13.079296513421783,
      "grad_norm": 0.08874285221099854,
      "learning_rate": 3.692070348657822e-05,
      "loss": 0.0017,
      "step": 42390
    },
    {
      "epoch": 13.082381980870101,
      "grad_norm": 0.7770639061927795,
      "learning_rate": 3.69176180191299e-05,
      "loss": 0.0039,
      "step": 42400
    },
    {
      "epoch": 13.08546744831842,
      "grad_norm": 2.4331233501434326,
      "learning_rate": 3.691453255168158e-05,
      "loss": 0.0018,
      "step": 42410
    },
    {
      "epoch": 13.088552915766739,
      "grad_norm": 8.676003456115723,
      "learning_rate": 3.691144708423326e-05,
      "loss": 0.0129,
      "step": 42420
    },
    {
      "epoch": 13.091638383215058,
      "grad_norm": 0.0020345142111182213,
      "learning_rate": 3.6908361616784944e-05,
      "loss": 0.0,
      "step": 42430
    },
    {
      "epoch": 13.094723850663376,
      "grad_norm": 0.015202848240733147,
      "learning_rate": 3.6905276149336626e-05,
      "loss": 0.0002,
      "step": 42440
    },
    {
      "epoch": 13.097809318111693,
      "grad_norm": 0.09142016619443893,
      "learning_rate": 3.690219068188831e-05,
      "loss": 0.0018,
      "step": 42450
    },
    {
      "epoch": 13.100894785560012,
      "grad_norm": 0.008256260305643082,
      "learning_rate": 3.689910521443999e-05,
      "loss": 0.0024,
      "step": 42460
    },
    {
      "epoch": 13.10398025300833,
      "grad_norm": 0.007509835064411163,
      "learning_rate": 3.6896019746991674e-05,
      "loss": 0.0001,
      "step": 42470
    },
    {
      "epoch": 13.10706572045665,
      "grad_norm": 0.0003351520572323352,
      "learning_rate": 3.689293427954335e-05,
      "loss": 0.0004,
      "step": 42480
    },
    {
      "epoch": 13.110151187904968,
      "grad_norm": 0.00047685601748526096,
      "learning_rate": 3.688984881209503e-05,
      "loss": 0.0043,
      "step": 42490
    },
    {
      "epoch": 13.113236655353287,
      "grad_norm": 0.06153932586312294,
      "learning_rate": 3.6886763344646715e-05,
      "loss": 0.0016,
      "step": 42500
    },
    {
      "epoch": 13.116322122801604,
      "grad_norm": 0.00033308620913885534,
      "learning_rate": 3.68836778771984e-05,
      "loss": 0.0002,
      "step": 42510
    },
    {
      "epoch": 13.119407590249923,
      "grad_norm": 0.04169800877571106,
      "learning_rate": 3.688059240975008e-05,
      "loss": 0.0006,
      "step": 42520
    },
    {
      "epoch": 13.122493057698241,
      "grad_norm": 0.21811653673648834,
      "learning_rate": 3.687750694230176e-05,
      "loss": 0.0003,
      "step": 42530
    },
    {
      "epoch": 13.12557852514656,
      "grad_norm": 0.00015395350055769086,
      "learning_rate": 3.6874421474853444e-05,
      "loss": 0.0023,
      "step": 42540
    },
    {
      "epoch": 13.128663992594879,
      "grad_norm": 0.21215857565402985,
      "learning_rate": 3.687133600740512e-05,
      "loss": 0.0006,
      "step": 42550
    },
    {
      "epoch": 13.131749460043196,
      "grad_norm": 0.0002850077871698886,
      "learning_rate": 3.68682505399568e-05,
      "loss": 0.0021,
      "step": 42560
    },
    {
      "epoch": 13.134834927491514,
      "grad_norm": 0.0007656469824723899,
      "learning_rate": 3.6865165072508485e-05,
      "loss": 0.0001,
      "step": 42570
    },
    {
      "epoch": 13.137920394939833,
      "grad_norm": 0.0010359125444665551,
      "learning_rate": 3.686207960506017e-05,
      "loss": 0.0001,
      "step": 42580
    },
    {
      "epoch": 13.141005862388152,
      "grad_norm": 0.0005743890069425106,
      "learning_rate": 3.685899413761185e-05,
      "loss": 0.0004,
      "step": 42590
    },
    {
      "epoch": 13.14409132983647,
      "grad_norm": 0.012609611265361309,
      "learning_rate": 3.685590867016353e-05,
      "loss": 0.0012,
      "step": 42600
    },
    {
      "epoch": 13.14717679728479,
      "grad_norm": 0.0002968529879581183,
      "learning_rate": 3.6852823202715215e-05,
      "loss": 0.0003,
      "step": 42610
    },
    {
      "epoch": 13.150262264733106,
      "grad_norm": 0.03875858709216118,
      "learning_rate": 3.684973773526689e-05,
      "loss": 0.0013,
      "step": 42620
    },
    {
      "epoch": 13.153347732181425,
      "grad_norm": 0.002095842035487294,
      "learning_rate": 3.684665226781858e-05,
      "loss": 0.0034,
      "step": 42630
    },
    {
      "epoch": 13.156433199629744,
      "grad_norm": 0.02231028489768505,
      "learning_rate": 3.684356680037026e-05,
      "loss": 0.0001,
      "step": 42640
    },
    {
      "epoch": 13.159518667078062,
      "grad_norm": 0.03823978826403618,
      "learning_rate": 3.684048133292194e-05,
      "loss": 0.0014,
      "step": 42650
    },
    {
      "epoch": 13.162604134526381,
      "grad_norm": 0.003623990109190345,
      "learning_rate": 3.683739586547362e-05,
      "loss": 0.0001,
      "step": 42660
    },
    {
      "epoch": 13.1656896019747,
      "grad_norm": 0.09226857125759125,
      "learning_rate": 3.68343103980253e-05,
      "loss": 0.0008,
      "step": 42670
    },
    {
      "epoch": 13.168775069423017,
      "grad_norm": 0.0008987245382741094,
      "learning_rate": 3.6831224930576986e-05,
      "loss": 0.0042,
      "step": 42680
    },
    {
      "epoch": 13.171860536871336,
      "grad_norm": 0.017238039523363113,
      "learning_rate": 3.682813946312866e-05,
      "loss": 0.0038,
      "step": 42690
    },
    {
      "epoch": 13.174946004319654,
      "grad_norm": 8.949077891884372e-05,
      "learning_rate": 3.682505399568035e-05,
      "loss": 0.0022,
      "step": 42700
    },
    {
      "epoch": 13.178031471767973,
      "grad_norm": 0.5866769552230835,
      "learning_rate": 3.682196852823203e-05,
      "loss": 0.0028,
      "step": 42710
    },
    {
      "epoch": 13.181116939216292,
      "grad_norm": 0.04112345352768898,
      "learning_rate": 3.681888306078371e-05,
      "loss": 0.0014,
      "step": 42720
    },
    {
      "epoch": 13.18420240666461,
      "grad_norm": 0.052730195224285126,
      "learning_rate": 3.681579759333539e-05,
      "loss": 0.006,
      "step": 42730
    },
    {
      "epoch": 13.187287874112927,
      "grad_norm": 0.004769509192556143,
      "learning_rate": 3.6812712125887074e-05,
      "loss": 0.008,
      "step": 42740
    },
    {
      "epoch": 13.190373341561246,
      "grad_norm": 5.450041498988867e-05,
      "learning_rate": 3.6809626658438756e-05,
      "loss": 0.003,
      "step": 42750
    },
    {
      "epoch": 13.193458809009565,
      "grad_norm": 0.048159074038267136,
      "learning_rate": 3.680654119099043e-05,
      "loss": 0.0021,
      "step": 42760
    },
    {
      "epoch": 13.196544276457884,
      "grad_norm": 0.007741244975477457,
      "learning_rate": 3.680345572354212e-05,
      "loss": 0.0003,
      "step": 42770
    },
    {
      "epoch": 13.199629743906202,
      "grad_norm": 0.048964425921440125,
      "learning_rate": 3.6800370256093804e-05,
      "loss": 0.0005,
      "step": 42780
    },
    {
      "epoch": 13.202715211354521,
      "grad_norm": 0.21689139306545258,
      "learning_rate": 3.679728478864548e-05,
      "loss": 0.0007,
      "step": 42790
    },
    {
      "epoch": 13.205800678802838,
      "grad_norm": 0.03331056237220764,
      "learning_rate": 3.679419932119716e-05,
      "loss": 0.0018,
      "step": 42800
    },
    {
      "epoch": 13.208886146251157,
      "grad_norm": 0.042300380766391754,
      "learning_rate": 3.6791113853748844e-05,
      "loss": 0.001,
      "step": 42810
    },
    {
      "epoch": 13.211971613699475,
      "grad_norm": 0.0004793608095496893,
      "learning_rate": 3.678802838630053e-05,
      "loss": 0.001,
      "step": 42820
    },
    {
      "epoch": 13.215057081147794,
      "grad_norm": 0.03260251134634018,
      "learning_rate": 3.67849429188522e-05,
      "loss": 0.0005,
      "step": 42830
    },
    {
      "epoch": 13.218142548596113,
      "grad_norm": 0.006658979691565037,
      "learning_rate": 3.678185745140389e-05,
      "loss": 0.0001,
      "step": 42840
    },
    {
      "epoch": 13.221228016044432,
      "grad_norm": 0.07940705865621567,
      "learning_rate": 3.6778771983955574e-05,
      "loss": 0.0015,
      "step": 42850
    },
    {
      "epoch": 13.224313483492748,
      "grad_norm": 0.04944022744894028,
      "learning_rate": 3.677568651650725e-05,
      "loss": 0.0014,
      "step": 42860
    },
    {
      "epoch": 13.227398950941067,
      "grad_norm": 0.0006787988822907209,
      "learning_rate": 3.677260104905893e-05,
      "loss": 0.0049,
      "step": 42870
    },
    {
      "epoch": 13.230484418389386,
      "grad_norm": 0.0011971587082371116,
      "learning_rate": 3.6769515581610615e-05,
      "loss": 0.0078,
      "step": 42880
    },
    {
      "epoch": 13.233569885837705,
      "grad_norm": 0.003506510751321912,
      "learning_rate": 3.67664301141623e-05,
      "loss": 0.0009,
      "step": 42890
    },
    {
      "epoch": 13.236655353286023,
      "grad_norm": 0.008953897282481194,
      "learning_rate": 3.676334464671398e-05,
      "loss": 0.0033,
      "step": 42900
    },
    {
      "epoch": 13.239740820734342,
      "grad_norm": 0.0010209906613454223,
      "learning_rate": 3.676025917926566e-05,
      "loss": 0.0141,
      "step": 42910
    },
    {
      "epoch": 13.242826288182659,
      "grad_norm": 0.5909542441368103,
      "learning_rate": 3.6757173711817345e-05,
      "loss": 0.0014,
      "step": 42920
    },
    {
      "epoch": 13.245911755630978,
      "grad_norm": 0.06432618200778961,
      "learning_rate": 3.675408824436902e-05,
      "loss": 0.0002,
      "step": 42930
    },
    {
      "epoch": 13.248997223079297,
      "grad_norm": 0.000985587714239955,
      "learning_rate": 3.675100277692071e-05,
      "loss": 0.0047,
      "step": 42940
    },
    {
      "epoch": 13.252082690527615,
      "grad_norm": 0.3103255331516266,
      "learning_rate": 3.6747917309472385e-05,
      "loss": 0.0069,
      "step": 42950
    },
    {
      "epoch": 13.255168157975934,
      "grad_norm": 2.6778907340485603e-05,
      "learning_rate": 3.674483184202407e-05,
      "loss": 0.0009,
      "step": 42960
    },
    {
      "epoch": 13.258253625424253,
      "grad_norm": 0.0020123689901083708,
      "learning_rate": 3.674174637457575e-05,
      "loss": 0.0196,
      "step": 42970
    },
    {
      "epoch": 13.26133909287257,
      "grad_norm": 0.4319625198841095,
      "learning_rate": 3.673866090712743e-05,
      "loss": 0.0021,
      "step": 42980
    },
    {
      "epoch": 13.264424560320888,
      "grad_norm": 0.001365563366562128,
      "learning_rate": 3.6735575439679115e-05,
      "loss": 0.0167,
      "step": 42990
    },
    {
      "epoch": 13.267510027769207,
      "grad_norm": 0.04380388557910919,
      "learning_rate": 3.673248997223079e-05,
      "loss": 0.0002,
      "step": 43000
    },
    {
      "epoch": 13.270595495217526,
      "grad_norm": 0.1953413337469101,
      "learning_rate": 3.672940450478248e-05,
      "loss": 0.0034,
      "step": 43010
    },
    {
      "epoch": 13.273680962665845,
      "grad_norm": 0.0007204880239441991,
      "learning_rate": 3.6726319037334156e-05,
      "loss": 0.0041,
      "step": 43020
    },
    {
      "epoch": 13.276766430114161,
      "grad_norm": 0.009796024300158024,
      "learning_rate": 3.672323356988584e-05,
      "loss": 0.0006,
      "step": 43030
    },
    {
      "epoch": 13.27985189756248,
      "grad_norm": 0.04147312417626381,
      "learning_rate": 3.672014810243752e-05,
      "loss": 0.0103,
      "step": 43040
    },
    {
      "epoch": 13.282937365010799,
      "grad_norm": 1.7014163732528687,
      "learning_rate": 3.67170626349892e-05,
      "loss": 0.0096,
      "step": 43050
    },
    {
      "epoch": 13.286022832459118,
      "grad_norm": 0.0006539691239595413,
      "learning_rate": 3.6713977167540886e-05,
      "loss": 0.0106,
      "step": 43060
    },
    {
      "epoch": 13.289108299907436,
      "grad_norm": 0.5708170533180237,
      "learning_rate": 3.671089170009256e-05,
      "loss": 0.0016,
      "step": 43070
    },
    {
      "epoch": 13.292193767355755,
      "grad_norm": 0.0006642377120442688,
      "learning_rate": 3.670780623264425e-05,
      "loss": 0.0018,
      "step": 43080
    },
    {
      "epoch": 13.295279234804072,
      "grad_norm": 0.0014390430878847837,
      "learning_rate": 3.6704720765195926e-05,
      "loss": 0.0015,
      "step": 43090
    },
    {
      "epoch": 13.29836470225239,
      "grad_norm": 0.5611559748649597,
      "learning_rate": 3.670163529774761e-05,
      "loss": 0.0051,
      "step": 43100
    },
    {
      "epoch": 13.30145016970071,
      "grad_norm": 0.00014764767547603697,
      "learning_rate": 3.669854983029929e-05,
      "loss": 0.0028,
      "step": 43110
    },
    {
      "epoch": 13.304535637149028,
      "grad_norm": 0.01071374025195837,
      "learning_rate": 3.6695464362850974e-05,
      "loss": 0.0007,
      "step": 43120
    },
    {
      "epoch": 13.307621104597347,
      "grad_norm": 0.008477766998112202,
      "learning_rate": 3.6692378895402656e-05,
      "loss": 0.0009,
      "step": 43130
    },
    {
      "epoch": 13.310706572045666,
      "grad_norm": 0.00021964302868582308,
      "learning_rate": 3.668929342795433e-05,
      "loss": 0.0042,
      "step": 43140
    },
    {
      "epoch": 13.313792039493983,
      "grad_norm": 0.0012844220036640763,
      "learning_rate": 3.668620796050602e-05,
      "loss": 0.0066,
      "step": 43150
    },
    {
      "epoch": 13.316877506942301,
      "grad_norm": 0.010697316378355026,
      "learning_rate": 3.66831224930577e-05,
      "loss": 0.0001,
      "step": 43160
    },
    {
      "epoch": 13.31996297439062,
      "grad_norm": 0.0019444777863100171,
      "learning_rate": 3.668003702560938e-05,
      "loss": 0.0079,
      "step": 43170
    },
    {
      "epoch": 13.323048441838939,
      "grad_norm": 5.489415707415901e-05,
      "learning_rate": 3.667695155816107e-05,
      "loss": 0.0092,
      "step": 43180
    },
    {
      "epoch": 13.326133909287257,
      "grad_norm": 0.00039421708788722754,
      "learning_rate": 3.6673866090712744e-05,
      "loss": 0.0022,
      "step": 43190
    },
    {
      "epoch": 13.329219376735576,
      "grad_norm": 0.07236553728580475,
      "learning_rate": 3.667078062326443e-05,
      "loss": 0.0031,
      "step": 43200
    },
    {
      "epoch": 13.332304844183893,
      "grad_norm": 0.0017776383319869637,
      "learning_rate": 3.666769515581611e-05,
      "loss": 0.0052,
      "step": 43210
    },
    {
      "epoch": 13.335390311632212,
      "grad_norm": 0.021417833864688873,
      "learning_rate": 3.666460968836779e-05,
      "loss": 0.001,
      "step": 43220
    },
    {
      "epoch": 13.33847577908053,
      "grad_norm": 0.13648846745491028,
      "learning_rate": 3.666152422091947e-05,
      "loss": 0.001,
      "step": 43230
    },
    {
      "epoch": 13.34156124652885,
      "grad_norm": 0.015829354524612427,
      "learning_rate": 3.665843875347115e-05,
      "loss": 0.0012,
      "step": 43240
    },
    {
      "epoch": 13.344646713977168,
      "grad_norm": 0.00026282749604433775,
      "learning_rate": 3.665535328602284e-05,
      "loss": 0.0002,
      "step": 43250
    },
    {
      "epoch": 13.347732181425487,
      "grad_norm": 0.15455155074596405,
      "learning_rate": 3.6652267818574515e-05,
      "loss": 0.0021,
      "step": 43260
    },
    {
      "epoch": 13.350817648873804,
      "grad_norm": 0.006898225750774145,
      "learning_rate": 3.66491823511262e-05,
      "loss": 0.004,
      "step": 43270
    },
    {
      "epoch": 13.353903116322122,
      "grad_norm": 0.005765392445027828,
      "learning_rate": 3.664609688367788e-05,
      "loss": 0.0029,
      "step": 43280
    },
    {
      "epoch": 13.356988583770441,
      "grad_norm": 4.950007132720202e-05,
      "learning_rate": 3.664301141622956e-05,
      "loss": 0.003,
      "step": 43290
    },
    {
      "epoch": 13.36007405121876,
      "grad_norm": 0.0005343429511412978,
      "learning_rate": 3.663992594878124e-05,
      "loss": 0.0013,
      "step": 43300
    },
    {
      "epoch": 13.363159518667079,
      "grad_norm": 0.0007707591284997761,
      "learning_rate": 3.663684048133292e-05,
      "loss": 0.0001,
      "step": 43310
    },
    {
      "epoch": 13.366244986115397,
      "grad_norm": 0.12282215058803558,
      "learning_rate": 3.663375501388461e-05,
      "loss": 0.0022,
      "step": 43320
    },
    {
      "epoch": 13.369330453563714,
      "grad_norm": 0.00023711159883532673,
      "learning_rate": 3.6630669546436286e-05,
      "loss": 0.0109,
      "step": 43330
    },
    {
      "epoch": 13.372415921012033,
      "grad_norm": 0.03897104412317276,
      "learning_rate": 3.662758407898797e-05,
      "loss": 0.0036,
      "step": 43340
    },
    {
      "epoch": 13.375501388460352,
      "grad_norm": 0.007967640645802021,
      "learning_rate": 3.662449861153965e-05,
      "loss": 0.0003,
      "step": 43350
    },
    {
      "epoch": 13.37858685590867,
      "grad_norm": 0.059073641896247864,
      "learning_rate": 3.662141314409133e-05,
      "loss": 0.0067,
      "step": 43360
    },
    {
      "epoch": 13.38167232335699,
      "grad_norm": 1.7797023057937622,
      "learning_rate": 3.661832767664301e-05,
      "loss": 0.0039,
      "step": 43370
    },
    {
      "epoch": 13.384757790805306,
      "grad_norm": 0.1878139078617096,
      "learning_rate": 3.661524220919469e-05,
      "loss": 0.0018,
      "step": 43380
    },
    {
      "epoch": 13.387843258253625,
      "grad_norm": 1.267822790396167e-05,
      "learning_rate": 3.661215674174638e-05,
      "loss": 0.0017,
      "step": 43390
    },
    {
      "epoch": 13.390928725701944,
      "grad_norm": 0.025673318654298782,
      "learning_rate": 3.6609071274298056e-05,
      "loss": 0.0079,
      "step": 43400
    },
    {
      "epoch": 13.394014193150262,
      "grad_norm": 0.010403920896351337,
      "learning_rate": 3.660598580684974e-05,
      "loss": 0.0003,
      "step": 43410
    },
    {
      "epoch": 13.397099660598581,
      "grad_norm": 1.7982592582702637,
      "learning_rate": 3.660290033940142e-05,
      "loss": 0.0079,
      "step": 43420
    },
    {
      "epoch": 13.4001851280469,
      "grad_norm": 0.018763061612844467,
      "learning_rate": 3.6599814871953104e-05,
      "loss": 0.0014,
      "step": 43430
    },
    {
      "epoch": 13.403270595495217,
      "grad_norm": 0.8064419627189636,
      "learning_rate": 3.659672940450478e-05,
      "loss": 0.0047,
      "step": 43440
    },
    {
      "epoch": 13.406356062943535,
      "grad_norm": 0.11019834131002426,
      "learning_rate": 3.659364393705647e-05,
      "loss": 0.0012,
      "step": 43450
    },
    {
      "epoch": 13.409441530391854,
      "grad_norm": 0.011254662647843361,
      "learning_rate": 3.659055846960815e-05,
      "loss": 0.0033,
      "step": 43460
    },
    {
      "epoch": 13.412526997840173,
      "grad_norm": 0.008431421592831612,
      "learning_rate": 3.658747300215983e-05,
      "loss": 0.0064,
      "step": 43470
    },
    {
      "epoch": 13.415612465288492,
      "grad_norm": 0.010205664671957493,
      "learning_rate": 3.658438753471151e-05,
      "loss": 0.0041,
      "step": 43480
    },
    {
      "epoch": 13.41869793273681,
      "grad_norm": 0.22116822004318237,
      "learning_rate": 3.658130206726319e-05,
      "loss": 0.0038,
      "step": 43490
    },
    {
      "epoch": 13.421783400185127,
      "grad_norm": 0.0002786718832794577,
      "learning_rate": 3.6578216599814874e-05,
      "loss": 0.0003,
      "step": 43500
    },
    {
      "epoch": 13.424868867633446,
      "grad_norm": 0.02485593967139721,
      "learning_rate": 3.6575131132366557e-05,
      "loss": 0.0014,
      "step": 43510
    },
    {
      "epoch": 13.427954335081765,
      "grad_norm": 0.47260305285453796,
      "learning_rate": 3.657204566491824e-05,
      "loss": 0.0006,
      "step": 43520
    },
    {
      "epoch": 13.431039802530083,
      "grad_norm": 0.0025896274019032717,
      "learning_rate": 3.656896019746992e-05,
      "loss": 0.0044,
      "step": 43530
    },
    {
      "epoch": 13.434125269978402,
      "grad_norm": 0.2813495397567749,
      "learning_rate": 3.65658747300216e-05,
      "loss": 0.0003,
      "step": 43540
    },
    {
      "epoch": 13.437210737426721,
      "grad_norm": 0.006097707897424698,
      "learning_rate": 3.656278926257328e-05,
      "loss": 0.0006,
      "step": 43550
    },
    {
      "epoch": 13.440296204875038,
      "grad_norm": 0.000744229240808636,
      "learning_rate": 3.655970379512496e-05,
      "loss": 0.0,
      "step": 43560
    },
    {
      "epoch": 13.443381672323357,
      "grad_norm": 0.0003475257253739983,
      "learning_rate": 3.6556618327676645e-05,
      "loss": 0.007,
      "step": 43570
    },
    {
      "epoch": 13.446467139771675,
      "grad_norm": 0.004624322988092899,
      "learning_rate": 3.655353286022833e-05,
      "loss": 0.0057,
      "step": 43580
    },
    {
      "epoch": 13.449552607219994,
      "grad_norm": 0.00012241072545293719,
      "learning_rate": 3.655044739278001e-05,
      "loss": 0.0001,
      "step": 43590
    },
    {
      "epoch": 13.452638074668313,
      "grad_norm": 0.013845580630004406,
      "learning_rate": 3.654736192533169e-05,
      "loss": 0.0034,
      "step": 43600
    },
    {
      "epoch": 13.455723542116631,
      "grad_norm": 0.24427734315395355,
      "learning_rate": 3.654427645788337e-05,
      "loss": 0.0025,
      "step": 43610
    },
    {
      "epoch": 13.458809009564948,
      "grad_norm": 0.00015994947170838714,
      "learning_rate": 3.654119099043505e-05,
      "loss": 0.0006,
      "step": 43620
    },
    {
      "epoch": 13.461894477013267,
      "grad_norm": 0.015411320142447948,
      "learning_rate": 3.653810552298673e-05,
      "loss": 0.0004,
      "step": 43630
    },
    {
      "epoch": 13.464979944461586,
      "grad_norm": 0.11023404449224472,
      "learning_rate": 3.6535020055538415e-05,
      "loss": 0.0129,
      "step": 43640
    },
    {
      "epoch": 13.468065411909905,
      "grad_norm": 0.004438002128154039,
      "learning_rate": 3.65319345880901e-05,
      "loss": 0.0002,
      "step": 43650
    },
    {
      "epoch": 13.471150879358223,
      "grad_norm": 0.0019925679080188274,
      "learning_rate": 3.652884912064178e-05,
      "loss": 0.0004,
      "step": 43660
    },
    {
      "epoch": 13.474236346806542,
      "grad_norm": 0.0019572987221181393,
      "learning_rate": 3.652576365319346e-05,
      "loss": 0.0017,
      "step": 43670
    },
    {
      "epoch": 13.477321814254859,
      "grad_norm": 0.08221663534641266,
      "learning_rate": 3.652267818574514e-05,
      "loss": 0.0046,
      "step": 43680
    },
    {
      "epoch": 13.480407281703178,
      "grad_norm": 0.08527089655399323,
      "learning_rate": 3.651959271829683e-05,
      "loss": 0.0006,
      "step": 43690
    },
    {
      "epoch": 13.483492749151496,
      "grad_norm": 1.6933783292770386,
      "learning_rate": 3.65165072508485e-05,
      "loss": 0.004,
      "step": 43700
    },
    {
      "epoch": 13.486578216599815,
      "grad_norm": 0.04866625368595123,
      "learning_rate": 3.6513421783400186e-05,
      "loss": 0.0005,
      "step": 43710
    },
    {
      "epoch": 13.489663684048134,
      "grad_norm": 0.0036365261767059565,
      "learning_rate": 3.651033631595187e-05,
      "loss": 0.0036,
      "step": 43720
    },
    {
      "epoch": 13.49274915149645,
      "grad_norm": 0.1253485381603241,
      "learning_rate": 3.650725084850355e-05,
      "loss": 0.0004,
      "step": 43730
    },
    {
      "epoch": 13.49583461894477,
      "grad_norm": 0.0008553584339097142,
      "learning_rate": 3.650416538105523e-05,
      "loss": 0.0093,
      "step": 43740
    },
    {
      "epoch": 13.498920086393088,
      "grad_norm": 0.026092413812875748,
      "learning_rate": 3.650107991360691e-05,
      "loss": 0.0028,
      "step": 43750
    },
    {
      "epoch": 13.502005553841407,
      "grad_norm": 0.007857066579163074,
      "learning_rate": 3.64979944461586e-05,
      "loss": 0.0003,
      "step": 43760
    },
    {
      "epoch": 13.505091021289726,
      "grad_norm": 0.004049235954880714,
      "learning_rate": 3.6494908978710274e-05,
      "loss": 0.0029,
      "step": 43770
    },
    {
      "epoch": 13.508176488738044,
      "grad_norm": 0.0005265530198812485,
      "learning_rate": 3.6491823511261956e-05,
      "loss": 0.0113,
      "step": 43780
    },
    {
      "epoch": 13.511261956186363,
      "grad_norm": 0.00341865886002779,
      "learning_rate": 3.648873804381364e-05,
      "loss": 0.0022,
      "step": 43790
    },
    {
      "epoch": 13.51434742363468,
      "grad_norm": 0.01913527399301529,
      "learning_rate": 3.648565257636532e-05,
      "loss": 0.0017,
      "step": 43800
    },
    {
      "epoch": 13.517432891082999,
      "grad_norm": 0.0023869129363447428,
      "learning_rate": 3.6482567108917004e-05,
      "loss": 0.0069,
      "step": 43810
    },
    {
      "epoch": 13.520518358531318,
      "grad_norm": 0.3271489441394806,
      "learning_rate": 3.647948164146868e-05,
      "loss": 0.0004,
      "step": 43820
    },
    {
      "epoch": 13.523603825979636,
      "grad_norm": 0.12428653985261917,
      "learning_rate": 3.647639617402037e-05,
      "loss": 0.0066,
      "step": 43830
    },
    {
      "epoch": 13.526689293427955,
      "grad_norm": 0.00010059453779831529,
      "learning_rate": 3.6473310706572044e-05,
      "loss": 0.0052,
      "step": 43840
    },
    {
      "epoch": 13.529774760876272,
      "grad_norm": 0.00020251108799129725,
      "learning_rate": 3.647022523912373e-05,
      "loss": 0.0011,
      "step": 43850
    },
    {
      "epoch": 13.53286022832459,
      "grad_norm": 0.0015458038542419672,
      "learning_rate": 3.646713977167541e-05,
      "loss": 0.0005,
      "step": 43860
    },
    {
      "epoch": 13.53594569577291,
      "grad_norm": 0.006260573863983154,
      "learning_rate": 3.646405430422709e-05,
      "loss": 0.0044,
      "step": 43870
    },
    {
      "epoch": 13.539031163221228,
      "grad_norm": 0.0026603795122355223,
      "learning_rate": 3.6460968836778774e-05,
      "loss": 0.0024,
      "step": 43880
    },
    {
      "epoch": 13.542116630669547,
      "grad_norm": 0.13934189081192017,
      "learning_rate": 3.645788336933045e-05,
      "loss": 0.0074,
      "step": 43890
    },
    {
      "epoch": 13.545202098117866,
      "grad_norm": 0.0010836162837222219,
      "learning_rate": 3.645479790188214e-05,
      "loss": 0.0008,
      "step": 43900
    },
    {
      "epoch": 13.548287565566183,
      "grad_norm": 0.0053338524885475636,
      "learning_rate": 3.645171243443382e-05,
      "loss": 0.0067,
      "step": 43910
    },
    {
      "epoch": 13.551373033014501,
      "grad_norm": 0.03580582141876221,
      "learning_rate": 3.64486269669855e-05,
      "loss": 0.0001,
      "step": 43920
    },
    {
      "epoch": 13.55445850046282,
      "grad_norm": 0.10865853726863861,
      "learning_rate": 3.644554149953719e-05,
      "loss": 0.0014,
      "step": 43930
    },
    {
      "epoch": 13.557543967911139,
      "grad_norm": 1.823054552078247,
      "learning_rate": 3.644245603208886e-05,
      "loss": 0.0007,
      "step": 43940
    },
    {
      "epoch": 13.560629435359457,
      "grad_norm": 0.6288109421730042,
      "learning_rate": 3.6439370564640545e-05,
      "loss": 0.001,
      "step": 43950
    },
    {
      "epoch": 13.563714902807776,
      "grad_norm": 0.08433198183774948,
      "learning_rate": 3.643628509719223e-05,
      "loss": 0.0013,
      "step": 43960
    },
    {
      "epoch": 13.566800370256093,
      "grad_norm": 0.00010685637244023383,
      "learning_rate": 3.643319962974391e-05,
      "loss": 0.0015,
      "step": 43970
    },
    {
      "epoch": 13.569885837704412,
      "grad_norm": 7.956344052217901e-05,
      "learning_rate": 3.643011416229559e-05,
      "loss": 0.0015,
      "step": 43980
    },
    {
      "epoch": 13.57297130515273,
      "grad_norm": 0.4800197184085846,
      "learning_rate": 3.642702869484727e-05,
      "loss": 0.0032,
      "step": 43990
    },
    {
      "epoch": 13.57605677260105,
      "grad_norm": 0.03829348459839821,
      "learning_rate": 3.642394322739896e-05,
      "loss": 0.0005,
      "step": 44000
    },
    {
      "epoch": 13.579142240049368,
      "grad_norm": 0.5324382781982422,
      "learning_rate": 3.642085775995063e-05,
      "loss": 0.0034,
      "step": 44010
    },
    {
      "epoch": 13.582227707497687,
      "grad_norm": 0.05619664490222931,
      "learning_rate": 3.6417772292502316e-05,
      "loss": 0.0009,
      "step": 44020
    },
    {
      "epoch": 13.585313174946004,
      "grad_norm": 0.0005912717897444963,
      "learning_rate": 3.6414686825054e-05,
      "loss": 0.0008,
      "step": 44030
    },
    {
      "epoch": 13.588398642394322,
      "grad_norm": 0.0013966037658974528,
      "learning_rate": 3.641160135760568e-05,
      "loss": 0.0007,
      "step": 44040
    },
    {
      "epoch": 13.591484109842641,
      "grad_norm": 1.4916890859603882,
      "learning_rate": 3.640851589015736e-05,
      "loss": 0.0037,
      "step": 44050
    },
    {
      "epoch": 13.59456957729096,
      "grad_norm": 0.00022406814969144762,
      "learning_rate": 3.640543042270904e-05,
      "loss": 0.0474,
      "step": 44060
    },
    {
      "epoch": 13.597655044739279,
      "grad_norm": 0.01567302830517292,
      "learning_rate": 3.640234495526073e-05,
      "loss": 0.0008,
      "step": 44070
    },
    {
      "epoch": 13.600740512187595,
      "grad_norm": 0.011088017374277115,
      "learning_rate": 3.6399259487812404e-05,
      "loss": 0.0017,
      "step": 44080
    },
    {
      "epoch": 13.603825979635914,
      "grad_norm": 0.002508825622498989,
      "learning_rate": 3.6396174020364086e-05,
      "loss": 0.0,
      "step": 44090
    },
    {
      "epoch": 13.606911447084233,
      "grad_norm": 1.1916263103485107,
      "learning_rate": 3.639308855291577e-05,
      "loss": 0.0008,
      "step": 44100
    },
    {
      "epoch": 13.609996914532552,
      "grad_norm": 0.3358103632926941,
      "learning_rate": 3.639000308546745e-05,
      "loss": 0.0007,
      "step": 44110
    },
    {
      "epoch": 13.61308238198087,
      "grad_norm": 0.00013454114377964288,
      "learning_rate": 3.6386917618019133e-05,
      "loss": 0.0,
      "step": 44120
    },
    {
      "epoch": 13.61616784942919,
      "grad_norm": 0.5902164578437805,
      "learning_rate": 3.638383215057081e-05,
      "loss": 0.0003,
      "step": 44130
    },
    {
      "epoch": 13.619253316877508,
      "grad_norm": 0.001194676966406405,
      "learning_rate": 3.63807466831225e-05,
      "loss": 0.0001,
      "step": 44140
    },
    {
      "epoch": 13.622338784325825,
      "grad_norm": 0.0005273640854284167,
      "learning_rate": 3.6377661215674174e-05,
      "loss": 0.0039,
      "step": 44150
    },
    {
      "epoch": 13.625424251774144,
      "grad_norm": 0.24987070262432098,
      "learning_rate": 3.637457574822586e-05,
      "loss": 0.0067,
      "step": 44160
    },
    {
      "epoch": 13.628509719222462,
      "grad_norm": 0.1819913238286972,
      "learning_rate": 3.637149028077754e-05,
      "loss": 0.0049,
      "step": 44170
    },
    {
      "epoch": 13.631595186670781,
      "grad_norm": 0.0013186431024223566,
      "learning_rate": 3.636840481332922e-05,
      "loss": 0.0016,
      "step": 44180
    },
    {
      "epoch": 13.6346806541191,
      "grad_norm": 0.0028677666559815407,
      "learning_rate": 3.6365319345880904e-05,
      "loss": 0.0151,
      "step": 44190
    },
    {
      "epoch": 13.637766121567417,
      "grad_norm": 0.0018821238772943616,
      "learning_rate": 3.6362233878432587e-05,
      "loss": 0.0067,
      "step": 44200
    },
    {
      "epoch": 13.640851589015735,
      "grad_norm": 0.0012510427040979266,
      "learning_rate": 3.635914841098427e-05,
      "loss": 0.0002,
      "step": 44210
    },
    {
      "epoch": 13.643937056464054,
      "grad_norm": 0.0009812809294089675,
      "learning_rate": 3.6356062943535945e-05,
      "loss": 0.0039,
      "step": 44220
    },
    {
      "epoch": 13.647022523912373,
      "grad_norm": 1.0810693502426147,
      "learning_rate": 3.635297747608763e-05,
      "loss": 0.0033,
      "step": 44230
    },
    {
      "epoch": 13.650107991360692,
      "grad_norm": 0.048764538019895554,
      "learning_rate": 3.634989200863931e-05,
      "loss": 0.0011,
      "step": 44240
    },
    {
      "epoch": 13.65319345880901,
      "grad_norm": 0.16865502297878265,
      "learning_rate": 3.634680654119099e-05,
      "loss": 0.0034,
      "step": 44250
    },
    {
      "epoch": 13.656278926257327,
      "grad_norm": 0.0016476295422762632,
      "learning_rate": 3.6343721073742675e-05,
      "loss": 0.0066,
      "step": 44260
    },
    {
      "epoch": 13.659364393705646,
      "grad_norm": 0.012345203198492527,
      "learning_rate": 3.634063560629436e-05,
      "loss": 0.0012,
      "step": 44270
    },
    {
      "epoch": 13.662449861153965,
      "grad_norm": 1.5639203786849976,
      "learning_rate": 3.633755013884604e-05,
      "loss": 0.0039,
      "step": 44280
    },
    {
      "epoch": 13.665535328602283,
      "grad_norm": 0.0004708649648819119,
      "learning_rate": 3.6334464671397715e-05,
      "loss": 0.0064,
      "step": 44290
    },
    {
      "epoch": 13.668620796050602,
      "grad_norm": 0.0033062512520700693,
      "learning_rate": 3.63313792039494e-05,
      "loss": 0.0003,
      "step": 44300
    },
    {
      "epoch": 13.67170626349892,
      "grad_norm": 2.067173719406128,
      "learning_rate": 3.632829373650108e-05,
      "loss": 0.0067,
      "step": 44310
    },
    {
      "epoch": 13.674791730947238,
      "grad_norm": 0.0005197430728003383,
      "learning_rate": 3.632520826905276e-05,
      "loss": 0.0049,
      "step": 44320
    },
    {
      "epoch": 13.677877198395556,
      "grad_norm": 0.029769018292427063,
      "learning_rate": 3.6322122801604445e-05,
      "loss": 0.0022,
      "step": 44330
    },
    {
      "epoch": 13.680962665843875,
      "grad_norm": 0.28751587867736816,
      "learning_rate": 3.631903733415613e-05,
      "loss": 0.0029,
      "step": 44340
    },
    {
      "epoch": 13.684048133292194,
      "grad_norm": 0.2138676941394806,
      "learning_rate": 3.631595186670781e-05,
      "loss": 0.0013,
      "step": 44350
    },
    {
      "epoch": 13.687133600740513,
      "grad_norm": 0.06818078458309174,
      "learning_rate": 3.6312866399259486e-05,
      "loss": 0.0008,
      "step": 44360
    },
    {
      "epoch": 13.690219068188831,
      "grad_norm": 0.10683242976665497,
      "learning_rate": 3.630978093181117e-05,
      "loss": 0.0003,
      "step": 44370
    },
    {
      "epoch": 13.693304535637148,
      "grad_norm": 0.000329185975715518,
      "learning_rate": 3.630669546436286e-05,
      "loss": 0.0056,
      "step": 44380
    },
    {
      "epoch": 13.696390003085467,
      "grad_norm": 0.01841253973543644,
      "learning_rate": 3.630360999691453e-05,
      "loss": 0.0012,
      "step": 44390
    },
    {
      "epoch": 13.699475470533786,
      "grad_norm": 0.07638151198625565,
      "learning_rate": 3.6300524529466216e-05,
      "loss": 0.0005,
      "step": 44400
    },
    {
      "epoch": 13.702560937982105,
      "grad_norm": 0.005703992210328579,
      "learning_rate": 3.62974390620179e-05,
      "loss": 0.0043,
      "step": 44410
    },
    {
      "epoch": 13.705646405430423,
      "grad_norm": 0.005477020982652903,
      "learning_rate": 3.629435359456958e-05,
      "loss": 0.0002,
      "step": 44420
    },
    {
      "epoch": 13.708731872878742,
      "grad_norm": 0.016118520870804787,
      "learning_rate": 3.6291268127121256e-05,
      "loss": 0.002,
      "step": 44430
    },
    {
      "epoch": 13.711817340327059,
      "grad_norm": 1.19863760471344,
      "learning_rate": 3.6288182659672946e-05,
      "loss": 0.0053,
      "step": 44440
    },
    {
      "epoch": 13.714902807775378,
      "grad_norm": 0.003042121883481741,
      "learning_rate": 3.628509719222463e-05,
      "loss": 0.0003,
      "step": 44450
    },
    {
      "epoch": 13.717988275223696,
      "grad_norm": 0.008914309553802013,
      "learning_rate": 3.6282011724776304e-05,
      "loss": 0.0007,
      "step": 44460
    },
    {
      "epoch": 13.721073742672015,
      "grad_norm": 0.004192827269434929,
      "learning_rate": 3.6278926257327986e-05,
      "loss": 0.0004,
      "step": 44470
    },
    {
      "epoch": 13.724159210120334,
      "grad_norm": 0.00020580606360454112,
      "learning_rate": 3.627584078987967e-05,
      "loss": 0.0002,
      "step": 44480
    },
    {
      "epoch": 13.727244677568653,
      "grad_norm": 0.05456415191292763,
      "learning_rate": 3.627275532243135e-05,
      "loss": 0.0042,
      "step": 44490
    },
    {
      "epoch": 13.73033014501697,
      "grad_norm": 0.0021307000424712896,
      "learning_rate": 3.626966985498303e-05,
      "loss": 0.0013,
      "step": 44500
    },
    {
      "epoch": 13.733415612465288,
      "grad_norm": 0.027399122714996338,
      "learning_rate": 3.6266584387534716e-05,
      "loss": 0.0036,
      "step": 44510
    },
    {
      "epoch": 13.736501079913607,
      "grad_norm": 0.004430185072124004,
      "learning_rate": 3.62634989200864e-05,
      "loss": 0.0037,
      "step": 44520
    },
    {
      "epoch": 13.739586547361926,
      "grad_norm": 0.06880788505077362,
      "learning_rate": 3.6260413452638074e-05,
      "loss": 0.001,
      "step": 44530
    },
    {
      "epoch": 13.742672014810244,
      "grad_norm": 0.0031323812436312437,
      "learning_rate": 3.625732798518976e-05,
      "loss": 0.0002,
      "step": 44540
    },
    {
      "epoch": 13.745757482258561,
      "grad_norm": 8.09251723694615e-05,
      "learning_rate": 3.625424251774144e-05,
      "loss": 0.0005,
      "step": 44550
    },
    {
      "epoch": 13.74884294970688,
      "grad_norm": 0.01317966915667057,
      "learning_rate": 3.625115705029312e-05,
      "loss": 0.0007,
      "step": 44560
    },
    {
      "epoch": 13.751928417155199,
      "grad_norm": 4.162553787231445,
      "learning_rate": 3.62480715828448e-05,
      "loss": 0.0099,
      "step": 44570
    },
    {
      "epoch": 13.755013884603517,
      "grad_norm": 0.003079910296946764,
      "learning_rate": 3.624498611539649e-05,
      "loss": 0.0003,
      "step": 44580
    },
    {
      "epoch": 13.758099352051836,
      "grad_norm": 0.0005051469197496772,
      "learning_rate": 3.624190064794817e-05,
      "loss": 0.0009,
      "step": 44590
    },
    {
      "epoch": 13.761184819500155,
      "grad_norm": 0.0027119487058371305,
      "learning_rate": 3.6238815180499845e-05,
      "loss": 0.0004,
      "step": 44600
    },
    {
      "epoch": 13.764270286948472,
      "grad_norm": 1.5537667274475098,
      "learning_rate": 3.623572971305153e-05,
      "loss": 0.0042,
      "step": 44610
    },
    {
      "epoch": 13.76735575439679,
      "grad_norm": 0.00011756517778849229,
      "learning_rate": 3.623264424560321e-05,
      "loss": 0.0029,
      "step": 44620
    },
    {
      "epoch": 13.77044122184511,
      "grad_norm": 0.005660328082740307,
      "learning_rate": 3.622955877815489e-05,
      "loss": 0.0052,
      "step": 44630
    },
    {
      "epoch": 13.773526689293428,
      "grad_norm": 7.744665344944224e-05,
      "learning_rate": 3.622647331070657e-05,
      "loss": 0.0093,
      "step": 44640
    },
    {
      "epoch": 13.776612156741747,
      "grad_norm": 0.010112307034432888,
      "learning_rate": 3.622338784325826e-05,
      "loss": 0.0001,
      "step": 44650
    },
    {
      "epoch": 13.779697624190065,
      "grad_norm": 0.02519366517663002,
      "learning_rate": 3.622030237580994e-05,
      "loss": 0.0002,
      "step": 44660
    },
    {
      "epoch": 13.782783091638382,
      "grad_norm": 0.5025289058685303,
      "learning_rate": 3.6217216908361616e-05,
      "loss": 0.0095,
      "step": 44670
    },
    {
      "epoch": 13.785868559086701,
      "grad_norm": 0.005751431453973055,
      "learning_rate": 3.6214131440913305e-05,
      "loss": 0.005,
      "step": 44680
    },
    {
      "epoch": 13.78895402653502,
      "grad_norm": 0.0015964292688295245,
      "learning_rate": 3.621104597346498e-05,
      "loss": 0.0011,
      "step": 44690
    },
    {
      "epoch": 13.792039493983339,
      "grad_norm": 0.00022301841818261892,
      "learning_rate": 3.620796050601666e-05,
      "loss": 0.0007,
      "step": 44700
    },
    {
      "epoch": 13.795124961431657,
      "grad_norm": 1.1096420288085938,
      "learning_rate": 3.6204875038568345e-05,
      "loss": 0.0019,
      "step": 44710
    },
    {
      "epoch": 13.798210428879976,
      "grad_norm": 0.06202588602900505,
      "learning_rate": 3.620178957112003e-05,
      "loss": 0.0003,
      "step": 44720
    },
    {
      "epoch": 13.801295896328293,
      "grad_norm": 2.418025493621826,
      "learning_rate": 3.619870410367171e-05,
      "loss": 0.0045,
      "step": 44730
    },
    {
      "epoch": 13.804381363776612,
      "grad_norm": 0.0006619120249524713,
      "learning_rate": 3.6195618636223386e-05,
      "loss": 0.0001,
      "step": 44740
    },
    {
      "epoch": 13.80746683122493,
      "grad_norm": 0.014578086324036121,
      "learning_rate": 3.6192533168775075e-05,
      "loss": 0.0002,
      "step": 44750
    },
    {
      "epoch": 13.81055229867325,
      "grad_norm": 0.03476068377494812,
      "learning_rate": 3.618944770132675e-05,
      "loss": 0.0125,
      "step": 44760
    },
    {
      "epoch": 13.813637766121568,
      "grad_norm": 2.0586183071136475,
      "learning_rate": 3.6186362233878434e-05,
      "loss": 0.0018,
      "step": 44770
    },
    {
      "epoch": 13.816723233569887,
      "grad_norm": 0.0001311352534685284,
      "learning_rate": 3.6183276766430116e-05,
      "loss": 0.0007,
      "step": 44780
    },
    {
      "epoch": 13.819808701018204,
      "grad_norm": 0.21234819293022156,
      "learning_rate": 3.61801912989818e-05,
      "loss": 0.0078,
      "step": 44790
    },
    {
      "epoch": 13.822894168466522,
      "grad_norm": 0.8354076147079468,
      "learning_rate": 3.617710583153348e-05,
      "loss": 0.001,
      "step": 44800
    },
    {
      "epoch": 13.825979635914841,
      "grad_norm": 0.033774036914110184,
      "learning_rate": 3.617402036408516e-05,
      "loss": 0.0007,
      "step": 44810
    },
    {
      "epoch": 13.82906510336316,
      "grad_norm": 0.14870691299438477,
      "learning_rate": 3.6170934896636846e-05,
      "loss": 0.0008,
      "step": 44820
    },
    {
      "epoch": 13.832150570811478,
      "grad_norm": 0.00023745572252664715,
      "learning_rate": 3.616784942918852e-05,
      "loss": 0.0002,
      "step": 44830
    },
    {
      "epoch": 13.835236038259797,
      "grad_norm": 0.0005645285127684474,
      "learning_rate": 3.6164763961740204e-05,
      "loss": 0.0027,
      "step": 44840
    },
    {
      "epoch": 13.838321505708114,
      "grad_norm": 0.0009465764160268009,
      "learning_rate": 3.6161678494291887e-05,
      "loss": 0.0002,
      "step": 44850
    },
    {
      "epoch": 13.841406973156433,
      "grad_norm": 0.0024187234230339527,
      "learning_rate": 3.615859302684357e-05,
      "loss": 0.0014,
      "step": 44860
    },
    {
      "epoch": 13.844492440604752,
      "grad_norm": 0.0025450384709984064,
      "learning_rate": 3.615550755939525e-05,
      "loss": 0.0005,
      "step": 44870
    },
    {
      "epoch": 13.84757790805307,
      "grad_norm": 1.2253718376159668,
      "learning_rate": 3.615242209194693e-05,
      "loss": 0.0009,
      "step": 44880
    },
    {
      "epoch": 13.850663375501389,
      "grad_norm": 0.06993863731622696,
      "learning_rate": 3.6149336624498616e-05,
      "loss": 0.0001,
      "step": 44890
    },
    {
      "epoch": 13.853748842949706,
      "grad_norm": 0.01835593394935131,
      "learning_rate": 3.614625115705029e-05,
      "loss": 0.0008,
      "step": 44900
    },
    {
      "epoch": 13.856834310398025,
      "grad_norm": 2.1196960005909204e-05,
      "learning_rate": 3.6143165689601975e-05,
      "loss": 0.0002,
      "step": 44910
    },
    {
      "epoch": 13.859919777846343,
      "grad_norm": 0.00012001689174212515,
      "learning_rate": 3.6140080222153664e-05,
      "loss": 0.0023,
      "step": 44920
    },
    {
      "epoch": 13.863005245294662,
      "grad_norm": 0.0011465371353551745,
      "learning_rate": 3.613699475470534e-05,
      "loss": 0.0043,
      "step": 44930
    },
    {
      "epoch": 13.86609071274298,
      "grad_norm": 0.0857272744178772,
      "learning_rate": 3.613390928725702e-05,
      "loss": 0.0072,
      "step": 44940
    },
    {
      "epoch": 13.8691761801913,
      "grad_norm": 0.0009956170106306672,
      "learning_rate": 3.6130823819808705e-05,
      "loss": 0.0103,
      "step": 44950
    },
    {
      "epoch": 13.872261647639618,
      "grad_norm": 2.1803243160247803,
      "learning_rate": 3.612773835236039e-05,
      "loss": 0.0014,
      "step": 44960
    },
    {
      "epoch": 13.875347115087935,
      "grad_norm": 0.03477289900183678,
      "learning_rate": 3.612465288491206e-05,
      "loss": 0.0002,
      "step": 44970
    },
    {
      "epoch": 13.878432582536254,
      "grad_norm": 0.09341323375701904,
      "learning_rate": 3.6121567417463745e-05,
      "loss": 0.0001,
      "step": 44980
    },
    {
      "epoch": 13.881518049984573,
      "grad_norm": 2.49086856842041,
      "learning_rate": 3.6118481950015434e-05,
      "loss": 0.0035,
      "step": 44990
    },
    {
      "epoch": 13.884603517432891,
      "grad_norm": 0.0021039405837655067,
      "learning_rate": 3.611539648256711e-05,
      "loss": 0.0007,
      "step": 45000
    },
    {
      "epoch": 13.88768898488121,
      "grad_norm": 0.004486575722694397,
      "learning_rate": 3.611231101511879e-05,
      "loss": 0.0019,
      "step": 45010
    },
    {
      "epoch": 13.890774452329527,
      "grad_norm": 0.0015078773722052574,
      "learning_rate": 3.6109225547670475e-05,
      "loss": 0.0026,
      "step": 45020
    },
    {
      "epoch": 13.893859919777846,
      "grad_norm": 0.00038416869938373566,
      "learning_rate": 3.610614008022216e-05,
      "loss": 0.0022,
      "step": 45030
    },
    {
      "epoch": 13.896945387226165,
      "grad_norm": 0.015052393078804016,
      "learning_rate": 3.610305461277383e-05,
      "loss": 0.002,
      "step": 45040
    },
    {
      "epoch": 13.900030854674483,
      "grad_norm": 0.00019763153977692127,
      "learning_rate": 3.6099969145325516e-05,
      "loss": 0.0039,
      "step": 45050
    },
    {
      "epoch": 13.903116322122802,
      "grad_norm": 0.0007592669571749866,
      "learning_rate": 3.6096883677877205e-05,
      "loss": 0.0072,
      "step": 45060
    },
    {
      "epoch": 13.90620178957112,
      "grad_norm": 3.6015357181895524e-05,
      "learning_rate": 3.609379821042888e-05,
      "loss": 0.0081,
      "step": 45070
    },
    {
      "epoch": 13.909287257019438,
      "grad_norm": 0.00023878640786278993,
      "learning_rate": 3.609071274298056e-05,
      "loss": 0.0171,
      "step": 45080
    },
    {
      "epoch": 13.912372724467756,
      "grad_norm": 0.025184692814946175,
      "learning_rate": 3.6087627275532246e-05,
      "loss": 0.0099,
      "step": 45090
    },
    {
      "epoch": 13.915458191916075,
      "grad_norm": 0.005422513000667095,
      "learning_rate": 3.608454180808393e-05,
      "loss": 0.0002,
      "step": 45100
    },
    {
      "epoch": 13.918543659364394,
      "grad_norm": 0.3317764699459076,
      "learning_rate": 3.6081456340635604e-05,
      "loss": 0.006,
      "step": 45110
    },
    {
      "epoch": 13.921629126812713,
      "grad_norm": 0.0003088866942562163,
      "learning_rate": 3.6078370873187286e-05,
      "loss": 0.0052,
      "step": 45120
    },
    {
      "epoch": 13.924714594261031,
      "grad_norm": 0.06210382655262947,
      "learning_rate": 3.6075285405738976e-05,
      "loss": 0.0008,
      "step": 45130
    },
    {
      "epoch": 13.927800061709348,
      "grad_norm": 1.275436520576477,
      "learning_rate": 3.607219993829065e-05,
      "loss": 0.0028,
      "step": 45140
    },
    {
      "epoch": 13.930885529157667,
      "grad_norm": 0.00175473524723202,
      "learning_rate": 3.6069114470842334e-05,
      "loss": 0.0002,
      "step": 45150
    },
    {
      "epoch": 13.933970996605986,
      "grad_norm": 0.025603272020816803,
      "learning_rate": 3.6066029003394016e-05,
      "loss": 0.0015,
      "step": 45160
    },
    {
      "epoch": 13.937056464054304,
      "grad_norm": 0.0019597026985138655,
      "learning_rate": 3.60629435359457e-05,
      "loss": 0.0003,
      "step": 45170
    },
    {
      "epoch": 13.940141931502623,
      "grad_norm": 0.002310175681486726,
      "learning_rate": 3.6059858068497374e-05,
      "loss": 0.0046,
      "step": 45180
    },
    {
      "epoch": 13.943227398950942,
      "grad_norm": 0.0012365138391032815,
      "learning_rate": 3.6056772601049064e-05,
      "loss": 0.0005,
      "step": 45190
    },
    {
      "epoch": 13.946312866399259,
      "grad_norm": 3.275197982788086,
      "learning_rate": 3.6053687133600746e-05,
      "loss": 0.0045,
      "step": 45200
    },
    {
      "epoch": 13.949398333847578,
      "grad_norm": 0.0014694916317239404,
      "learning_rate": 3.605060166615242e-05,
      "loss": 0.0001,
      "step": 45210
    },
    {
      "epoch": 13.952483801295896,
      "grad_norm": 0.7766355276107788,
      "learning_rate": 3.6047516198704104e-05,
      "loss": 0.0013,
      "step": 45220
    },
    {
      "epoch": 13.955569268744215,
      "grad_norm": 0.015139644034206867,
      "learning_rate": 3.604443073125579e-05,
      "loss": 0.0005,
      "step": 45230
    },
    {
      "epoch": 13.958654736192534,
      "grad_norm": 0.0015338556841015816,
      "learning_rate": 3.604134526380747e-05,
      "loss": 0.001,
      "step": 45240
    },
    {
      "epoch": 13.96174020364085,
      "grad_norm": 0.0011637272546067834,
      "learning_rate": 3.603825979635915e-05,
      "loss": 0.0,
      "step": 45250
    },
    {
      "epoch": 13.96482567108917,
      "grad_norm": 0.00904819741845131,
      "learning_rate": 3.6035174328910834e-05,
      "loss": 0.0039,
      "step": 45260
    },
    {
      "epoch": 13.967911138537488,
      "grad_norm": 0.0017675184644758701,
      "learning_rate": 3.603208886146252e-05,
      "loss": 0.0012,
      "step": 45270
    },
    {
      "epoch": 13.970996605985807,
      "grad_norm": 2.2225406169891357,
      "learning_rate": 3.602900339401419e-05,
      "loss": 0.0117,
      "step": 45280
    },
    {
      "epoch": 13.974082073434126,
      "grad_norm": 0.01770961657166481,
      "learning_rate": 3.6025917926565875e-05,
      "loss": 0.0003,
      "step": 45290
    },
    {
      "epoch": 13.977167540882444,
      "grad_norm": 0.22051279246807098,
      "learning_rate": 3.602283245911756e-05,
      "loss": 0.0029,
      "step": 45300
    },
    {
      "epoch": 13.980253008330763,
      "grad_norm": 0.9849894642829895,
      "learning_rate": 3.601974699166924e-05,
      "loss": 0.0008,
      "step": 45310
    },
    {
      "epoch": 13.98333847577908,
      "grad_norm": 0.0006483260076493025,
      "learning_rate": 3.601666152422092e-05,
      "loss": 0.0026,
      "step": 45320
    },
    {
      "epoch": 13.986423943227399,
      "grad_norm": 0.28525224328041077,
      "learning_rate": 3.6013576056772605e-05,
      "loss": 0.0005,
      "step": 45330
    },
    {
      "epoch": 13.989509410675717,
      "grad_norm": 0.19277323782444,
      "learning_rate": 3.601049058932429e-05,
      "loss": 0.0014,
      "step": 45340
    },
    {
      "epoch": 13.992594878124036,
      "grad_norm": 0.09794505685567856,
      "learning_rate": 3.600740512187596e-05,
      "loss": 0.0008,
      "step": 45350
    },
    {
      "epoch": 13.995680345572355,
      "grad_norm": 0.003955688793212175,
      "learning_rate": 3.6004319654427645e-05,
      "loss": 0.0,
      "step": 45360
    },
    {
      "epoch": 13.998765813020672,
      "grad_norm": 0.0002083398576360196,
      "learning_rate": 3.600123418697933e-05,
      "loss": 0.0043,
      "step": 45370
    },
    {
      "epoch": 14.0,
      "eval_accuracy_branch1": 0.9994309578233654,
      "eval_accuracy_branch2": 0.39535893058649924,
      "eval_f1_branch1": 0.9989806702391213,
      "eval_f1_branch2": 0.37122745744940466,
      "eval_loss": 0.000332456809701398,
      "eval_precision_branch1": 0.9989914769947901,
      "eval_precision_branch2": 0.5341990738323305,
      "eval_recall_branch1": 0.9989745495006244,
      "eval_recall_branch2": 0.5182431063915974,
      "eval_runtime": 240.3415,
      "eval_samples_per_second": 431.399,
      "eval_steps_per_second": 53.927,
      "step": 45374
    },
    {
      "epoch": 14.00185128046899,
      "grad_norm": 0.0009981828043237329,
      "learning_rate": 3.599814871953101e-05,
      "loss": 0.0006,
      "step": 45380
    },
    {
      "epoch": 14.00493674791731,
      "grad_norm": 0.041932787746191025,
      "learning_rate": 3.599506325208269e-05,
      "loss": 0.0024,
      "step": 45390
    },
    {
      "epoch": 14.008022215365628,
      "grad_norm": 0.018973395228385925,
      "learning_rate": 3.5991977784634375e-05,
      "loss": 0.0015,
      "step": 45400
    },
    {
      "epoch": 14.011107682813947,
      "grad_norm": 0.039368703961372375,
      "learning_rate": 3.598889231718606e-05,
      "loss": 0.0011,
      "step": 45410
    },
    {
      "epoch": 14.014193150262265,
      "grad_norm": 0.02377752959728241,
      "learning_rate": 3.5985806849737734e-05,
      "loss": 0.0001,
      "step": 45420
    },
    {
      "epoch": 14.017278617710582,
      "grad_norm": 5.458488885778934e-05,
      "learning_rate": 3.5982721382289416e-05,
      "loss": 0.0003,
      "step": 45430
    },
    {
      "epoch": 14.020364085158901,
      "grad_norm": 0.005877756513655186,
      "learning_rate": 3.59796359148411e-05,
      "loss": 0.0001,
      "step": 45440
    },
    {
      "epoch": 14.02344955260722,
      "grad_norm": 0.0046384925954043865,
      "learning_rate": 3.597655044739278e-05,
      "loss": 0.0008,
      "step": 45450
    },
    {
      "epoch": 14.026535020055539,
      "grad_norm": 0.04604736343026161,
      "learning_rate": 3.5973464979944463e-05,
      "loss": 0.0004,
      "step": 45460
    },
    {
      "epoch": 14.029620487503857,
      "grad_norm": 0.03858635947108269,
      "learning_rate": 3.5970379512496146e-05,
      "loss": 0.0002,
      "step": 45470
    },
    {
      "epoch": 14.032705954952176,
      "grad_norm": 0.07210753858089447,
      "learning_rate": 3.596729404504783e-05,
      "loss": 0.0035,
      "step": 45480
    },
    {
      "epoch": 14.035791422400493,
      "grad_norm": 3.3112428188323975,
      "learning_rate": 3.5964208577599504e-05,
      "loss": 0.005,
      "step": 45490
    },
    {
      "epoch": 14.038876889848812,
      "grad_norm": 0.9156138896942139,
      "learning_rate": 3.596112311015119e-05,
      "loss": 0.001,
      "step": 45500
    },
    {
      "epoch": 14.04196235729713,
      "grad_norm": 1.8284263610839844,
      "learning_rate": 3.595803764270287e-05,
      "loss": 0.0016,
      "step": 45510
    },
    {
      "epoch": 14.045047824745449,
      "grad_norm": 3.224539977964014e-05,
      "learning_rate": 3.595495217525455e-05,
      "loss": 0.0014,
      "step": 45520
    },
    {
      "epoch": 14.048133292193768,
      "grad_norm": 0.10835037380456924,
      "learning_rate": 3.5951866707806234e-05,
      "loss": 0.0011,
      "step": 45530
    },
    {
      "epoch": 14.051218759642087,
      "grad_norm": 0.024096887558698654,
      "learning_rate": 3.5948781240357916e-05,
      "loss": 0.0001,
      "step": 45540
    },
    {
      "epoch": 14.054304227090404,
      "grad_norm": 0.0015382809797301888,
      "learning_rate": 3.59456957729096e-05,
      "loss": 0.0001,
      "step": 45550
    },
    {
      "epoch": 14.057389694538722,
      "grad_norm": 0.0012884613825008273,
      "learning_rate": 3.5942610305461275e-05,
      "loss": 0.0,
      "step": 45560
    },
    {
      "epoch": 14.060475161987041,
      "grad_norm": 0.11485517770051956,
      "learning_rate": 3.5939524838012964e-05,
      "loss": 0.0007,
      "step": 45570
    },
    {
      "epoch": 14.06356062943536,
      "grad_norm": 0.0004717371775768697,
      "learning_rate": 3.593643937056464e-05,
      "loss": 0.0033,
      "step": 45580
    },
    {
      "epoch": 14.066646096883678,
      "grad_norm": 0.011228310875594616,
      "learning_rate": 3.593335390311632e-05,
      "loss": 0.0002,
      "step": 45590
    },
    {
      "epoch": 14.069731564331997,
      "grad_norm": 0.0014658913714811206,
      "learning_rate": 3.5930268435668005e-05,
      "loss": 0.0063,
      "step": 45600
    },
    {
      "epoch": 14.072817031780314,
      "grad_norm": 0.01836610771715641,
      "learning_rate": 3.592718296821969e-05,
      "loss": 0.0002,
      "step": 45610
    },
    {
      "epoch": 14.075902499228633,
      "grad_norm": 0.010928122326731682,
      "learning_rate": 3.592409750077137e-05,
      "loss": 0.0012,
      "step": 45620
    },
    {
      "epoch": 14.078987966676952,
      "grad_norm": 0.0001869217085186392,
      "learning_rate": 3.5921012033323045e-05,
      "loss": 0.0087,
      "step": 45630
    },
    {
      "epoch": 14.08207343412527,
      "grad_norm": 0.0005361610092222691,
      "learning_rate": 3.5917926565874734e-05,
      "loss": 0.001,
      "step": 45640
    },
    {
      "epoch": 14.085158901573589,
      "grad_norm": 0.016748065128922462,
      "learning_rate": 3.591484109842642e-05,
      "loss": 0.0002,
      "step": 45650
    },
    {
      "epoch": 14.088244369021908,
      "grad_norm": 0.013469701632857323,
      "learning_rate": 3.591175563097809e-05,
      "loss": 0.0025,
      "step": 45660
    },
    {
      "epoch": 14.091329836470225,
      "grad_norm": 0.019653024151921272,
      "learning_rate": 3.5908670163529775e-05,
      "loss": 0.0012,
      "step": 45670
    },
    {
      "epoch": 14.094415303918543,
      "grad_norm": 0.0006898147403262556,
      "learning_rate": 3.590558469608146e-05,
      "loss": 0.003,
      "step": 45680
    },
    {
      "epoch": 14.097500771366862,
      "grad_norm": 0.3250177800655365,
      "learning_rate": 3.590249922863314e-05,
      "loss": 0.0028,
      "step": 45690
    },
    {
      "epoch": 14.10058623881518,
      "grad_norm": 0.004214177373796701,
      "learning_rate": 3.5899413761184816e-05,
      "loss": 0.001,
      "step": 45700
    },
    {
      "epoch": 14.1036717062635,
      "grad_norm": 0.1492876261472702,
      "learning_rate": 3.5896328293736505e-05,
      "loss": 0.0031,
      "step": 45710
    },
    {
      "epoch": 14.106757173711816,
      "grad_norm": 0.00017044339620042592,
      "learning_rate": 3.589324282628819e-05,
      "loss": 0.0001,
      "step": 45720
    },
    {
      "epoch": 14.109842641160135,
      "grad_norm": 0.00088488933397457,
      "learning_rate": 3.589015735883986e-05,
      "loss": 0.002,
      "step": 45730
    },
    {
      "epoch": 14.112928108608454,
      "grad_norm": 0.0022616360802203417,
      "learning_rate": 3.588707189139155e-05,
      "loss": 0.0065,
      "step": 45740
    },
    {
      "epoch": 14.116013576056773,
      "grad_norm": 0.035295214504003525,
      "learning_rate": 3.588398642394323e-05,
      "loss": 0.0013,
      "step": 45750
    },
    {
      "epoch": 14.119099043505091,
      "grad_norm": 1.4661711247754283e-05,
      "learning_rate": 3.588090095649491e-05,
      "loss": 0.0046,
      "step": 45760
    },
    {
      "epoch": 14.12218451095341,
      "grad_norm": 0.02489403635263443,
      "learning_rate": 3.587781548904659e-05,
      "loss": 0.0004,
      "step": 45770
    },
    {
      "epoch": 14.125269978401727,
      "grad_norm": 7.534242467954755e-05,
      "learning_rate": 3.5874730021598276e-05,
      "loss": 0.0003,
      "step": 45780
    },
    {
      "epoch": 14.128355445850046,
      "grad_norm": 0.01233177725225687,
      "learning_rate": 3.587164455414996e-05,
      "loss": 0.0024,
      "step": 45790
    },
    {
      "epoch": 14.131440913298364,
      "grad_norm": 0.00998804159462452,
      "learning_rate": 3.5868559086701634e-05,
      "loss": 0.0003,
      "step": 45800
    },
    {
      "epoch": 14.134526380746683,
      "grad_norm": 0.0006626427639275789,
      "learning_rate": 3.586547361925332e-05,
      "loss": 0.0022,
      "step": 45810
    },
    {
      "epoch": 14.137611848195002,
      "grad_norm": 0.0034464870113879442,
      "learning_rate": 3.5862388151805e-05,
      "loss": 0.0055,
      "step": 45820
    },
    {
      "epoch": 14.14069731564332,
      "grad_norm": 0.004704504273831844,
      "learning_rate": 3.585930268435668e-05,
      "loss": 0.0003,
      "step": 45830
    },
    {
      "epoch": 14.143782783091638,
      "grad_norm": 0.04665369167923927,
      "learning_rate": 3.5856217216908364e-05,
      "loss": 0.0005,
      "step": 45840
    },
    {
      "epoch": 14.146868250539956,
      "grad_norm": 0.00028443257906474173,
      "learning_rate": 3.5853131749460046e-05,
      "loss": 0.0006,
      "step": 45850
    },
    {
      "epoch": 14.149953717988275,
      "grad_norm": 0.03125445172190666,
      "learning_rate": 3.585004628201173e-05,
      "loss": 0.0003,
      "step": 45860
    },
    {
      "epoch": 14.153039185436594,
      "grad_norm": 0.0019987765699625015,
      "learning_rate": 3.5846960814563404e-05,
      "loss": 0.0,
      "step": 45870
    },
    {
      "epoch": 14.156124652884913,
      "grad_norm": 0.13844262063503265,
      "learning_rate": 3.5843875347115094e-05,
      "loss": 0.0007,
      "step": 45880
    },
    {
      "epoch": 14.159210120333231,
      "grad_norm": 0.005137134809046984,
      "learning_rate": 3.584078987966677e-05,
      "loss": 0.0017,
      "step": 45890
    },
    {
      "epoch": 14.162295587781548,
      "grad_norm": 0.1937578320503235,
      "learning_rate": 3.583770441221845e-05,
      "loss": 0.0064,
      "step": 45900
    },
    {
      "epoch": 14.165381055229867,
      "grad_norm": 0.00018031550280284137,
      "learning_rate": 3.5834618944770134e-05,
      "loss": 0.001,
      "step": 45910
    },
    {
      "epoch": 14.168466522678186,
      "grad_norm": 0.029408331960439682,
      "learning_rate": 3.583153347732182e-05,
      "loss": 0.0002,
      "step": 45920
    },
    {
      "epoch": 14.171551990126504,
      "grad_norm": 0.026705265045166016,
      "learning_rate": 3.58284480098735e-05,
      "loss": 0.0024,
      "step": 45930
    },
    {
      "epoch": 14.174637457574823,
      "grad_norm": 0.0006164883961901069,
      "learning_rate": 3.5825362542425175e-05,
      "loss": 0.0011,
      "step": 45940
    },
    {
      "epoch": 14.177722925023142,
      "grad_norm": 0.47387218475341797,
      "learning_rate": 3.5822277074976864e-05,
      "loss": 0.0018,
      "step": 45950
    },
    {
      "epoch": 14.180808392471459,
      "grad_norm": 0.00010624463902786374,
      "learning_rate": 3.581919160752854e-05,
      "loss": 0.0001,
      "step": 45960
    },
    {
      "epoch": 14.183893859919777,
      "grad_norm": 0.14810682833194733,
      "learning_rate": 3.581610614008022e-05,
      "loss": 0.0002,
      "step": 45970
    },
    {
      "epoch": 14.186979327368096,
      "grad_norm": 1.9087928533554077,
      "learning_rate": 3.5813020672631905e-05,
      "loss": 0.0053,
      "step": 45980
    },
    {
      "epoch": 14.190064794816415,
      "grad_norm": 0.015441203489899635,
      "learning_rate": 3.580993520518359e-05,
      "loss": 0.0005,
      "step": 45990
    },
    {
      "epoch": 14.193150262264734,
      "grad_norm": 4.5592329115606844e-05,
      "learning_rate": 3.580684973773527e-05,
      "loss": 0.0005,
      "step": 46000
    },
    {
      "epoch": 14.196235729713052,
      "grad_norm": 0.00016183036495931447,
      "learning_rate": 3.580376427028695e-05,
      "loss": 0.0007,
      "step": 46010
    },
    {
      "epoch": 14.19932119716137,
      "grad_norm": 0.0034258284140378237,
      "learning_rate": 3.5800678802838635e-05,
      "loss": 0.003,
      "step": 46020
    },
    {
      "epoch": 14.202406664609688,
      "grad_norm": 0.0019470278639346361,
      "learning_rate": 3.579759333539031e-05,
      "loss": 0.0005,
      "step": 46030
    },
    {
      "epoch": 14.205492132058007,
      "grad_norm": 0.00020356006280053407,
      "learning_rate": 3.579450786794199e-05,
      "loss": 0.0003,
      "step": 46040
    },
    {
      "epoch": 14.208577599506325,
      "grad_norm": 8.471550972899422e-05,
      "learning_rate": 3.5791422400493675e-05,
      "loss": 0.0085,
      "step": 46050
    },
    {
      "epoch": 14.211663066954644,
      "grad_norm": 0.31787219643592834,
      "learning_rate": 3.578833693304536e-05,
      "loss": 0.0004,
      "step": 46060
    },
    {
      "epoch": 14.214748534402961,
      "grad_norm": 0.0001572070614201948,
      "learning_rate": 3.578525146559704e-05,
      "loss": 0.0013,
      "step": 46070
    },
    {
      "epoch": 14.21783400185128,
      "grad_norm": 0.04273151233792305,
      "learning_rate": 3.578216599814872e-05,
      "loss": 0.0012,
      "step": 46080
    },
    {
      "epoch": 14.220919469299599,
      "grad_norm": 0.01616933010518551,
      "learning_rate": 3.5779080530700405e-05,
      "loss": 0.0002,
      "step": 46090
    },
    {
      "epoch": 14.224004936747917,
      "grad_norm": 0.0001445274247089401,
      "learning_rate": 3.577599506325208e-05,
      "loss": 0.0011,
      "step": 46100
    },
    {
      "epoch": 14.227090404196236,
      "grad_norm": 0.03217335790395737,
      "learning_rate": 3.5772909595803763e-05,
      "loss": 0.0113,
      "step": 46110
    },
    {
      "epoch": 14.230175871644555,
      "grad_norm": 0.003956661093980074,
      "learning_rate": 3.576982412835545e-05,
      "loss": 0.0087,
      "step": 46120
    },
    {
      "epoch": 14.233261339092872,
      "grad_norm": 0.01605263352394104,
      "learning_rate": 3.576673866090713e-05,
      "loss": 0.0014,
      "step": 46130
    },
    {
      "epoch": 14.23634680654119,
      "grad_norm": 0.10541427880525589,
      "learning_rate": 3.576365319345881e-05,
      "loss": 0.0026,
      "step": 46140
    },
    {
      "epoch": 14.23943227398951,
      "grad_norm": 0.0007008117972873151,
      "learning_rate": 3.576056772601049e-05,
      "loss": 0.0004,
      "step": 46150
    },
    {
      "epoch": 14.242517741437828,
      "grad_norm": 6.667774869129062e-05,
      "learning_rate": 3.5757482258562176e-05,
      "loss": 0.0044,
      "step": 46160
    },
    {
      "epoch": 14.245603208886147,
      "grad_norm": 0.001077529857866466,
      "learning_rate": 3.575439679111385e-05,
      "loss": 0.0011,
      "step": 46170
    },
    {
      "epoch": 14.248688676334465,
      "grad_norm": 0.004319841507822275,
      "learning_rate": 3.5751311323665534e-05,
      "loss": 0.0187,
      "step": 46180
    },
    {
      "epoch": 14.251774143782782,
      "grad_norm": 0.0004260583082213998,
      "learning_rate": 3.574822585621722e-05,
      "loss": 0.0001,
      "step": 46190
    },
    {
      "epoch": 14.254859611231101,
      "grad_norm": 0.00199749949388206,
      "learning_rate": 3.57451403887689e-05,
      "loss": 0.0003,
      "step": 46200
    },
    {
      "epoch": 14.25794507867942,
      "grad_norm": 0.041887957602739334,
      "learning_rate": 3.574205492132058e-05,
      "loss": 0.0027,
      "step": 46210
    },
    {
      "epoch": 14.261030546127738,
      "grad_norm": 0.022010087966918945,
      "learning_rate": 3.5738969453872264e-05,
      "loss": 0.0004,
      "step": 46220
    },
    {
      "epoch": 14.264116013576057,
      "grad_norm": 0.0034110203851014376,
      "learning_rate": 3.5735883986423946e-05,
      "loss": 0.0037,
      "step": 46230
    },
    {
      "epoch": 14.267201481024376,
      "grad_norm": 0.00018358508532401174,
      "learning_rate": 3.573279851897562e-05,
      "loss": 0.0032,
      "step": 46240
    },
    {
      "epoch": 14.270286948472693,
      "grad_norm": 1.1825977563858032,
      "learning_rate": 3.572971305152731e-05,
      "loss": 0.0006,
      "step": 46250
    },
    {
      "epoch": 14.273372415921012,
      "grad_norm": 0.6085691452026367,
      "learning_rate": 3.5726627584078994e-05,
      "loss": 0.0082,
      "step": 46260
    },
    {
      "epoch": 14.27645788336933,
      "grad_norm": 1.4571401152352337e-05,
      "learning_rate": 3.572354211663067e-05,
      "loss": 0.0002,
      "step": 46270
    },
    {
      "epoch": 14.279543350817649,
      "grad_norm": 0.513967752456665,
      "learning_rate": 3.572045664918235e-05,
      "loss": 0.0015,
      "step": 46280
    },
    {
      "epoch": 14.282628818265968,
      "grad_norm": 0.04030420631170273,
      "learning_rate": 3.5717371181734034e-05,
      "loss": 0.0062,
      "step": 46290
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 0.1888897866010666,
      "learning_rate": 3.571428571428572e-05,
      "loss": 0.0035,
      "step": 46300
    },
    {
      "epoch": 14.288799753162603,
      "grad_norm": 0.0001721057778922841,
      "learning_rate": 3.571120024683739e-05,
      "loss": 0.0011,
      "step": 46310
    },
    {
      "epoch": 14.291885220610922,
      "grad_norm": 0.00015603900828864425,
      "learning_rate": 3.570811477938908e-05,
      "loss": 0.0041,
      "step": 46320
    },
    {
      "epoch": 14.29497068805924,
      "grad_norm": 1.1131950616836548,
      "learning_rate": 3.5705029311940764e-05,
      "loss": 0.0063,
      "step": 46330
    },
    {
      "epoch": 14.29805615550756,
      "grad_norm": 0.47550633549690247,
      "learning_rate": 3.570194384449244e-05,
      "loss": 0.0006,
      "step": 46340
    },
    {
      "epoch": 14.301141622955878,
      "grad_norm": 0.07380980253219604,
      "learning_rate": 3.569885837704412e-05,
      "loss": 0.0015,
      "step": 46350
    },
    {
      "epoch": 14.304227090404197,
      "grad_norm": 0.013040748424828053,
      "learning_rate": 3.5695772909595805e-05,
      "loss": 0.0002,
      "step": 46360
    },
    {
      "epoch": 14.307312557852514,
      "grad_norm": 0.00667842011898756,
      "learning_rate": 3.569268744214749e-05,
      "loss": 0.0032,
      "step": 46370
    },
    {
      "epoch": 14.310398025300833,
      "grad_norm": 0.00611451780423522,
      "learning_rate": 3.568960197469916e-05,
      "loss": 0.0004,
      "step": 46380
    },
    {
      "epoch": 14.313483492749151,
      "grad_norm": 0.01290785800665617,
      "learning_rate": 3.568651650725085e-05,
      "loss": 0.0017,
      "step": 46390
    },
    {
      "epoch": 14.31656896019747,
      "grad_norm": 0.000371859990991652,
      "learning_rate": 3.5683431039802535e-05,
      "loss": 0.0069,
      "step": 46400
    },
    {
      "epoch": 14.319654427645789,
      "grad_norm": 0.04221464321017265,
      "learning_rate": 3.568034557235421e-05,
      "loss": 0.0002,
      "step": 46410
    },
    {
      "epoch": 14.322739895094108,
      "grad_norm": 0.011267654597759247,
      "learning_rate": 3.567726010490589e-05,
      "loss": 0.0001,
      "step": 46420
    },
    {
      "epoch": 14.325825362542425,
      "grad_norm": 0.22671665251255035,
      "learning_rate": 3.5674174637457576e-05,
      "loss": 0.0003,
      "step": 46430
    },
    {
      "epoch": 14.328910829990743,
      "grad_norm": 0.006012627389281988,
      "learning_rate": 3.567108917000926e-05,
      "loss": 0.0005,
      "step": 46440
    },
    {
      "epoch": 14.331996297439062,
      "grad_norm": 0.00719875656068325,
      "learning_rate": 3.5668003702560934e-05,
      "loss": 0.0004,
      "step": 46450
    },
    {
      "epoch": 14.33508176488738,
      "grad_norm": 0.012265823781490326,
      "learning_rate": 3.566491823511262e-05,
      "loss": 0.0096,
      "step": 46460
    },
    {
      "epoch": 14.3381672323357,
      "grad_norm": 0.00042997137643396854,
      "learning_rate": 3.5661832767664306e-05,
      "loss": 0.002,
      "step": 46470
    },
    {
      "epoch": 14.341252699784018,
      "grad_norm": 0.0009149119723588228,
      "learning_rate": 3.565874730021598e-05,
      "loss": 0.0016,
      "step": 46480
    },
    {
      "epoch": 14.344338167232335,
      "grad_norm": 0.2983285188674927,
      "learning_rate": 3.565566183276767e-05,
      "loss": 0.0016,
      "step": 46490
    },
    {
      "epoch": 14.347423634680654,
      "grad_norm": 0.00379095203243196,
      "learning_rate": 3.5652576365319346e-05,
      "loss": 0.0013,
      "step": 46500
    },
    {
      "epoch": 14.350509102128973,
      "grad_norm": 0.04977390915155411,
      "learning_rate": 3.564949089787103e-05,
      "loss": 0.0014,
      "step": 46510
    },
    {
      "epoch": 14.353594569577291,
      "grad_norm": 1.90396249294281,
      "learning_rate": 3.564640543042271e-05,
      "loss": 0.0022,
      "step": 46520
    },
    {
      "epoch": 14.35668003702561,
      "grad_norm": 0.0065953535959124565,
      "learning_rate": 3.5643319962974394e-05,
      "loss": 0.0001,
      "step": 46530
    },
    {
      "epoch": 14.359765504473927,
      "grad_norm": 0.013871011324226856,
      "learning_rate": 3.5640234495526076e-05,
      "loss": 0.0047,
      "step": 46540
    },
    {
      "epoch": 14.362850971922246,
      "grad_norm": 0.0004966401029378176,
      "learning_rate": 3.563714902807775e-05,
      "loss": 0.0069,
      "step": 46550
    },
    {
      "epoch": 14.365936439370564,
      "grad_norm": 0.010304839350283146,
      "learning_rate": 3.563406356062944e-05,
      "loss": 0.0018,
      "step": 46560
    },
    {
      "epoch": 14.369021906818883,
      "grad_norm": 0.23362305760383606,
      "learning_rate": 3.563097809318112e-05,
      "loss": 0.0126,
      "step": 46570
    },
    {
      "epoch": 14.372107374267202,
      "grad_norm": 0.0012922079768031836,
      "learning_rate": 3.56278926257328e-05,
      "loss": 0.0043,
      "step": 46580
    },
    {
      "epoch": 14.37519284171552,
      "grad_norm": 3.266799831180833e-05,
      "learning_rate": 3.562480715828448e-05,
      "loss": 0.0005,
      "step": 46590
    },
    {
      "epoch": 14.378278309163838,
      "grad_norm": 0.11822536587715149,
      "learning_rate": 3.5621721690836164e-05,
      "loss": 0.0015,
      "step": 46600
    },
    {
      "epoch": 14.381363776612156,
      "grad_norm": 0.29390451312065125,
      "learning_rate": 3.561863622338785e-05,
      "loss": 0.0011,
      "step": 46610
    },
    {
      "epoch": 14.384449244060475,
      "grad_norm": 0.3414399027824402,
      "learning_rate": 3.561555075593952e-05,
      "loss": 0.0003,
      "step": 46620
    },
    {
      "epoch": 14.387534711508794,
      "grad_norm": 0.03280363976955414,
      "learning_rate": 3.561246528849121e-05,
      "loss": 0.0008,
      "step": 46630
    },
    {
      "epoch": 14.390620178957112,
      "grad_norm": 0.003046161960810423,
      "learning_rate": 3.560937982104289e-05,
      "loss": 0.0004,
      "step": 46640
    },
    {
      "epoch": 14.393705646405431,
      "grad_norm": 0.03802158683538437,
      "learning_rate": 3.560629435359457e-05,
      "loss": 0.0004,
      "step": 46650
    },
    {
      "epoch": 14.396791113853748,
      "grad_norm": 0.02421407215297222,
      "learning_rate": 3.560320888614625e-05,
      "loss": 0.0008,
      "step": 46660
    },
    {
      "epoch": 14.399876581302067,
      "grad_norm": 0.03453556075692177,
      "learning_rate": 3.5600123418697935e-05,
      "loss": 0.0006,
      "step": 46670
    },
    {
      "epoch": 14.402962048750386,
      "grad_norm": 0.0004947865381836891,
      "learning_rate": 3.559703795124962e-05,
      "loss": 0.0072,
      "step": 46680
    },
    {
      "epoch": 14.406047516198704,
      "grad_norm": 0.0015741381794214249,
      "learning_rate": 3.559395248380129e-05,
      "loss": 0.0003,
      "step": 46690
    },
    {
      "epoch": 14.409132983647023,
      "grad_norm": 0.3416192829608917,
      "learning_rate": 3.559086701635298e-05,
      "loss": 0.0009,
      "step": 46700
    },
    {
      "epoch": 14.412218451095342,
      "grad_norm": 0.01551293209195137,
      "learning_rate": 3.558778154890466e-05,
      "loss": 0.0081,
      "step": 46710
    },
    {
      "epoch": 14.415303918543659,
      "grad_norm": 0.0018348494777455926,
      "learning_rate": 3.558469608145634e-05,
      "loss": 0.0049,
      "step": 46720
    },
    {
      "epoch": 14.418389385991977,
      "grad_norm": 3.761152038350701e-05,
      "learning_rate": 3.558161061400803e-05,
      "loss": 0.0039,
      "step": 46730
    },
    {
      "epoch": 14.421474853440296,
      "grad_norm": 0.9504326581954956,
      "learning_rate": 3.5578525146559705e-05,
      "loss": 0.001,
      "step": 46740
    },
    {
      "epoch": 14.424560320888615,
      "grad_norm": 0.01056001242250204,
      "learning_rate": 3.557543967911139e-05,
      "loss": 0.0147,
      "step": 46750
    },
    {
      "epoch": 14.427645788336934,
      "grad_norm": 0.0609251894056797,
      "learning_rate": 3.557235421166307e-05,
      "loss": 0.0018,
      "step": 46760
    },
    {
      "epoch": 14.430731255785252,
      "grad_norm": 1.140013337135315,
      "learning_rate": 3.556926874421475e-05,
      "loss": 0.0013,
      "step": 46770
    },
    {
      "epoch": 14.43381672323357,
      "grad_norm": 0.0008973858202807605,
      "learning_rate": 3.556618327676643e-05,
      "loss": 0.0013,
      "step": 46780
    },
    {
      "epoch": 14.436902190681888,
      "grad_norm": 0.002632107585668564,
      "learning_rate": 3.556309780931811e-05,
      "loss": 0.0006,
      "step": 46790
    },
    {
      "epoch": 14.439987658130207,
      "grad_norm": 1.7144261598587036,
      "learning_rate": 3.55600123418698e-05,
      "loss": 0.0058,
      "step": 46800
    },
    {
      "epoch": 14.443073125578525,
      "grad_norm": 0.04167243838310242,
      "learning_rate": 3.5556926874421476e-05,
      "loss": 0.0009,
      "step": 46810
    },
    {
      "epoch": 14.446158593026844,
      "grad_norm": 0.0030027672182768583,
      "learning_rate": 3.555384140697316e-05,
      "loss": 0.0008,
      "step": 46820
    },
    {
      "epoch": 14.449244060475163,
      "grad_norm": 1.3489015102386475,
      "learning_rate": 3.555075593952484e-05,
      "loss": 0.0038,
      "step": 46830
    },
    {
      "epoch": 14.45232952792348,
      "grad_norm": 2.977616786956787,
      "learning_rate": 3.554767047207652e-05,
      "loss": 0.004,
      "step": 46840
    },
    {
      "epoch": 14.455414995371799,
      "grad_norm": 0.006435351446270943,
      "learning_rate": 3.55445850046282e-05,
      "loss": 0.0003,
      "step": 46850
    },
    {
      "epoch": 14.458500462820117,
      "grad_norm": 0.04346805438399315,
      "learning_rate": 3.554149953717988e-05,
      "loss": 0.0026,
      "step": 46860
    },
    {
      "epoch": 14.461585930268436,
      "grad_norm": 0.05206984654068947,
      "learning_rate": 3.553841406973157e-05,
      "loss": 0.0122,
      "step": 46870
    },
    {
      "epoch": 14.464671397716755,
      "grad_norm": 0.19513119757175446,
      "learning_rate": 3.5535328602283246e-05,
      "loss": 0.0039,
      "step": 46880
    },
    {
      "epoch": 14.467756865165072,
      "grad_norm": 0.11866395175457001,
      "learning_rate": 3.553224313483493e-05,
      "loss": 0.0038,
      "step": 46890
    },
    {
      "epoch": 14.47084233261339,
      "grad_norm": 0.2464693784713745,
      "learning_rate": 3.552915766738661e-05,
      "loss": 0.0007,
      "step": 46900
    },
    {
      "epoch": 14.473927800061709,
      "grad_norm": 3.3406572341918945,
      "learning_rate": 3.5526072199938294e-05,
      "loss": 0.0126,
      "step": 46910
    },
    {
      "epoch": 14.477013267510028,
      "grad_norm": 0.00016083654190879315,
      "learning_rate": 3.552298673248997e-05,
      "loss": 0.0046,
      "step": 46920
    },
    {
      "epoch": 14.480098734958347,
      "grad_norm": 0.26290056109428406,
      "learning_rate": 3.551990126504165e-05,
      "loss": 0.0017,
      "step": 46930
    },
    {
      "epoch": 14.483184202406665,
      "grad_norm": 0.00019130652071908116,
      "learning_rate": 3.551681579759334e-05,
      "loss": 0.0082,
      "step": 46940
    },
    {
      "epoch": 14.486269669854982,
      "grad_norm": 0.0025649552699178457,
      "learning_rate": 3.551373033014502e-05,
      "loss": 0.0034,
      "step": 46950
    },
    {
      "epoch": 14.489355137303301,
      "grad_norm": 0.376308411359787,
      "learning_rate": 3.55106448626967e-05,
      "loss": 0.0027,
      "step": 46960
    },
    {
      "epoch": 14.49244060475162,
      "grad_norm": 0.0001916008914122358,
      "learning_rate": 3.550755939524838e-05,
      "loss": 0.0009,
      "step": 46970
    },
    {
      "epoch": 14.495526072199938,
      "grad_norm": 0.011204295791685581,
      "learning_rate": 3.5504473927800064e-05,
      "loss": 0.0018,
      "step": 46980
    },
    {
      "epoch": 14.498611539648257,
      "grad_norm": 0.15839998424053192,
      "learning_rate": 3.550138846035175e-05,
      "loss": 0.0025,
      "step": 46990
    },
    {
      "epoch": 14.501697007096576,
      "grad_norm": 0.009547695517539978,
      "learning_rate": 3.549830299290343e-05,
      "loss": 0.004,
      "step": 47000
    },
    {
      "epoch": 14.504782474544893,
      "grad_norm": 0.11147385835647583,
      "learning_rate": 3.549521752545511e-05,
      "loss": 0.0089,
      "step": 47010
    },
    {
      "epoch": 14.507867941993212,
      "grad_norm": 0.0010923846857622266,
      "learning_rate": 3.549213205800679e-05,
      "loss": 0.004,
      "step": 47020
    },
    {
      "epoch": 14.51095340944153,
      "grad_norm": 0.02066216431558132,
      "learning_rate": 3.548904659055847e-05,
      "loss": 0.0048,
      "step": 47030
    },
    {
      "epoch": 14.514038876889849,
      "grad_norm": 0.00020580750424414873,
      "learning_rate": 3.548596112311015e-05,
      "loss": 0.0001,
      "step": 47040
    },
    {
      "epoch": 14.517124344338168,
      "grad_norm": 0.05763167515397072,
      "learning_rate": 3.5482875655661835e-05,
      "loss": 0.0044,
      "step": 47050
    },
    {
      "epoch": 14.520209811786486,
      "grad_norm": 0.8465002775192261,
      "learning_rate": 3.547979018821352e-05,
      "loss": 0.0005,
      "step": 47060
    },
    {
      "epoch": 14.523295279234803,
      "grad_norm": 8.904731657821685e-05,
      "learning_rate": 3.54767047207652e-05,
      "loss": 0.0049,
      "step": 47070
    },
    {
      "epoch": 14.526380746683122,
      "grad_norm": 0.0049934228882193565,
      "learning_rate": 3.547361925331688e-05,
      "loss": 0.0031,
      "step": 47080
    },
    {
      "epoch": 14.52946621413144,
      "grad_norm": 0.0065198857337236404,
      "learning_rate": 3.547053378586856e-05,
      "loss": 0.0002,
      "step": 47090
    },
    {
      "epoch": 14.53255168157976,
      "grad_norm": 0.24961358308792114,
      "learning_rate": 3.546744831842024e-05,
      "loss": 0.0005,
      "step": 47100
    },
    {
      "epoch": 14.535637149028078,
      "grad_norm": 0.1716638207435608,
      "learning_rate": 3.546436285097192e-05,
      "loss": 0.0091,
      "step": 47110
    },
    {
      "epoch": 14.538722616476397,
      "grad_norm": 0.008337641134858131,
      "learning_rate": 3.5461277383523606e-05,
      "loss": 0.0014,
      "step": 47120
    },
    {
      "epoch": 14.541808083924714,
      "grad_norm": 1.7039185762405396,
      "learning_rate": 3.545819191607529e-05,
      "loss": 0.001,
      "step": 47130
    },
    {
      "epoch": 14.544893551373033,
      "grad_norm": 0.27191004157066345,
      "learning_rate": 3.545510644862697e-05,
      "loss": 0.008,
      "step": 47140
    },
    {
      "epoch": 14.547979018821351,
      "grad_norm": 0.0009922070894390345,
      "learning_rate": 3.545202098117865e-05,
      "loss": 0.0007,
      "step": 47150
    },
    {
      "epoch": 14.55106448626967,
      "grad_norm": 0.3877570629119873,
      "learning_rate": 3.544893551373033e-05,
      "loss": 0.0047,
      "step": 47160
    },
    {
      "epoch": 14.554149953717989,
      "grad_norm": 0.002288979711011052,
      "learning_rate": 3.544585004628201e-05,
      "loss": 0.0007,
      "step": 47170
    },
    {
      "epoch": 14.557235421166308,
      "grad_norm": 0.0884087011218071,
      "learning_rate": 3.5442764578833694e-05,
      "loss": 0.0013,
      "step": 47180
    },
    {
      "epoch": 14.560320888614624,
      "grad_norm": 0.4865807592868805,
      "learning_rate": 3.5439679111385376e-05,
      "loss": 0.0021,
      "step": 47190
    },
    {
      "epoch": 14.563406356062943,
      "grad_norm": 0.003562870202586055,
      "learning_rate": 3.543659364393706e-05,
      "loss": 0.0007,
      "step": 47200
    },
    {
      "epoch": 14.566491823511262,
      "grad_norm": 2.104768991470337,
      "learning_rate": 3.543350817648874e-05,
      "loss": 0.0104,
      "step": 47210
    },
    {
      "epoch": 14.56957729095958,
      "grad_norm": 0.012774169445037842,
      "learning_rate": 3.5430422709040424e-05,
      "loss": 0.0001,
      "step": 47220
    },
    {
      "epoch": 14.5726627584079,
      "grad_norm": 5.1450948376441374e-05,
      "learning_rate": 3.54273372415921e-05,
      "loss": 0.0004,
      "step": 47230
    },
    {
      "epoch": 14.575748225856216,
      "grad_norm": 0.004876174032688141,
      "learning_rate": 3.542425177414379e-05,
      "loss": 0.0007,
      "step": 47240
    },
    {
      "epoch": 14.578833693304535,
      "grad_norm": 0.007493462413549423,
      "learning_rate": 3.5421166306695464e-05,
      "loss": 0.0006,
      "step": 47250
    },
    {
      "epoch": 14.581919160752854,
      "grad_norm": 0.004685031250119209,
      "learning_rate": 3.541808083924715e-05,
      "loss": 0.0003,
      "step": 47260
    },
    {
      "epoch": 14.585004628201172,
      "grad_norm": 0.17252647876739502,
      "learning_rate": 3.541499537179883e-05,
      "loss": 0.012,
      "step": 47270
    },
    {
      "epoch": 14.588090095649491,
      "grad_norm": 0.01089374627918005,
      "learning_rate": 3.541190990435051e-05,
      "loss": 0.0,
      "step": 47280
    },
    {
      "epoch": 14.59117556309781,
      "grad_norm": 8.895152859622613e-05,
      "learning_rate": 3.5408824436902194e-05,
      "loss": 0.0013,
      "step": 47290
    },
    {
      "epoch": 14.594261030546129,
      "grad_norm": 0.0031634029000997543,
      "learning_rate": 3.540573896945387e-05,
      "loss": 0.0002,
      "step": 47300
    },
    {
      "epoch": 14.597346497994446,
      "grad_norm": 0.00041676228283904493,
      "learning_rate": 3.540265350200556e-05,
      "loss": 0.0034,
      "step": 47310
    },
    {
      "epoch": 14.600431965442764,
      "grad_norm": 0.019243724644184113,
      "learning_rate": 3.5399568034557235e-05,
      "loss": 0.0008,
      "step": 47320
    },
    {
      "epoch": 14.603517432891083,
      "grad_norm": 0.00042399464291520417,
      "learning_rate": 3.539648256710892e-05,
      "loss": 0.0104,
      "step": 47330
    },
    {
      "epoch": 14.606602900339402,
      "grad_norm": 0.006462033372372389,
      "learning_rate": 3.53933970996606e-05,
      "loss": 0.0001,
      "step": 47340
    },
    {
      "epoch": 14.60968836778772,
      "grad_norm": 0.0002488211030140519,
      "learning_rate": 3.539031163221228e-05,
      "loss": 0.0002,
      "step": 47350
    },
    {
      "epoch": 14.612773835236037,
      "grad_norm": 0.010786009952425957,
      "learning_rate": 3.5387226164763965e-05,
      "loss": 0.0,
      "step": 47360
    },
    {
      "epoch": 14.615859302684356,
      "grad_norm": 0.0010544622782617807,
      "learning_rate": 3.538414069731564e-05,
      "loss": 0.001,
      "step": 47370
    },
    {
      "epoch": 14.618944770132675,
      "grad_norm": 0.002474172506481409,
      "learning_rate": 3.538105522986733e-05,
      "loss": 0.0022,
      "step": 47380
    },
    {
      "epoch": 14.622030237580994,
      "grad_norm": 0.422439306974411,
      "learning_rate": 3.5377969762419005e-05,
      "loss": 0.003,
      "step": 47390
    },
    {
      "epoch": 14.625115705029312,
      "grad_norm": 0.00024160997418221086,
      "learning_rate": 3.537488429497069e-05,
      "loss": 0.001,
      "step": 47400
    },
    {
      "epoch": 14.628201172477631,
      "grad_norm": 0.23175464570522308,
      "learning_rate": 3.537179882752237e-05,
      "loss": 0.0005,
      "step": 47410
    },
    {
      "epoch": 14.631286639925948,
      "grad_norm": 3.997000217437744,
      "learning_rate": 3.536871336007405e-05,
      "loss": 0.0022,
      "step": 47420
    },
    {
      "epoch": 14.634372107374267,
      "grad_norm": 0.030464734882116318,
      "learning_rate": 3.5365627892625735e-05,
      "loss": 0.0023,
      "step": 47430
    },
    {
      "epoch": 14.637457574822585,
      "grad_norm": 0.006424077786505222,
      "learning_rate": 3.536254242517741e-05,
      "loss": 0.0015,
      "step": 47440
    },
    {
      "epoch": 14.640543042270904,
      "grad_norm": 0.0060154227539896965,
      "learning_rate": 3.53594569577291e-05,
      "loss": 0.0011,
      "step": 47450
    },
    {
      "epoch": 14.643628509719223,
      "grad_norm": 2.2159242630004883,
      "learning_rate": 3.535637149028078e-05,
      "loss": 0.0012,
      "step": 47460
    },
    {
      "epoch": 14.646713977167542,
      "grad_norm": 1.8324062693864107e-05,
      "learning_rate": 3.535328602283246e-05,
      "loss": 0.002,
      "step": 47470
    },
    {
      "epoch": 14.649799444615859,
      "grad_norm": 0.0019602226093411446,
      "learning_rate": 3.535020055538414e-05,
      "loss": 0.0016,
      "step": 47480
    },
    {
      "epoch": 14.652884912064177,
      "grad_norm": 0.00030113174580037594,
      "learning_rate": 3.534711508793582e-05,
      "loss": 0.0003,
      "step": 47490
    },
    {
      "epoch": 14.655970379512496,
      "grad_norm": 0.000834415084682405,
      "learning_rate": 3.5344029620487506e-05,
      "loss": 0.003,
      "step": 47500
    },
    {
      "epoch": 14.659055846960815,
      "grad_norm": 0.0037327134050428867,
      "learning_rate": 3.534094415303919e-05,
      "loss": 0.0,
      "step": 47510
    },
    {
      "epoch": 14.662141314409133,
      "grad_norm": 0.0007363589247688651,
      "learning_rate": 3.533785868559087e-05,
      "loss": 0.0013,
      "step": 47520
    },
    {
      "epoch": 14.665226781857452,
      "grad_norm": 0.011611158959567547,
      "learning_rate": 3.533477321814255e-05,
      "loss": 0.0003,
      "step": 47530
    },
    {
      "epoch": 14.66831224930577,
      "grad_norm": 2.576464248704724e-05,
      "learning_rate": 3.533168775069423e-05,
      "loss": 0.0105,
      "step": 47540
    },
    {
      "epoch": 14.671397716754088,
      "grad_norm": 0.27494481205940247,
      "learning_rate": 3.532860228324592e-05,
      "loss": 0.0001,
      "step": 47550
    },
    {
      "epoch": 14.674483184202407,
      "grad_norm": 0.0024816945660859346,
      "learning_rate": 3.5325516815797594e-05,
      "loss": 0.0013,
      "step": 47560
    },
    {
      "epoch": 14.677568651650725,
      "grad_norm": 0.3404668867588043,
      "learning_rate": 3.5322431348349276e-05,
      "loss": 0.0011,
      "step": 47570
    },
    {
      "epoch": 14.680654119099044,
      "grad_norm": 0.0001248848275281489,
      "learning_rate": 3.531934588090096e-05,
      "loss": 0.0041,
      "step": 47580
    },
    {
      "epoch": 14.683739586547361,
      "grad_norm": 0.0013153175823390484,
      "learning_rate": 3.531626041345264e-05,
      "loss": 0.0003,
      "step": 47590
    },
    {
      "epoch": 14.68682505399568,
      "grad_norm": 0.002103837439790368,
      "learning_rate": 3.5313174946004324e-05,
      "loss": 0.0035,
      "step": 47600
    },
    {
      "epoch": 14.689910521443998,
      "grad_norm": 4.182380199432373,
      "learning_rate": 3.5310089478556e-05,
      "loss": 0.0046,
      "step": 47610
    },
    {
      "epoch": 14.692995988892317,
      "grad_norm": 0.0006109824171289802,
      "learning_rate": 3.530700401110769e-05,
      "loss": 0.0021,
      "step": 47620
    },
    {
      "epoch": 14.696081456340636,
      "grad_norm": 0.012538118287920952,
      "learning_rate": 3.5303918543659364e-05,
      "loss": 0.0039,
      "step": 47630
    },
    {
      "epoch": 14.699166923788955,
      "grad_norm": 1.0283676385879517,
      "learning_rate": 3.530083307621105e-05,
      "loss": 0.0009,
      "step": 47640
    },
    {
      "epoch": 14.702252391237273,
      "grad_norm": 1.415024757385254,
      "learning_rate": 3.529774760876273e-05,
      "loss": 0.0045,
      "step": 47650
    },
    {
      "epoch": 14.70533785868559,
      "grad_norm": 0.00418877275660634,
      "learning_rate": 3.529466214131441e-05,
      "loss": 0.0088,
      "step": 47660
    },
    {
      "epoch": 14.708423326133909,
      "grad_norm": 0.5611722469329834,
      "learning_rate": 3.5291576673866094e-05,
      "loss": 0.0007,
      "step": 47670
    },
    {
      "epoch": 14.711508793582228,
      "grad_norm": 2.8171891244710423e-05,
      "learning_rate": 3.528849120641777e-05,
      "loss": 0.0064,
      "step": 47680
    },
    {
      "epoch": 14.714594261030546,
      "grad_norm": 0.03951377049088478,
      "learning_rate": 3.528540573896946e-05,
      "loss": 0.0099,
      "step": 47690
    },
    {
      "epoch": 14.717679728478865,
      "grad_norm": 0.0023370974231511354,
      "learning_rate": 3.5282320271521135e-05,
      "loss": 0.0014,
      "step": 47700
    },
    {
      "epoch": 14.720765195927182,
      "grad_norm": 0.1755780130624771,
      "learning_rate": 3.527923480407282e-05,
      "loss": 0.0018,
      "step": 47710
    },
    {
      "epoch": 14.7238506633755,
      "grad_norm": 0.24491174519062042,
      "learning_rate": 3.52761493366245e-05,
      "loss": 0.0138,
      "step": 47720
    },
    {
      "epoch": 14.72693613082382,
      "grad_norm": 0.0016480466583743691,
      "learning_rate": 3.527306386917618e-05,
      "loss": 0.0004,
      "step": 47730
    },
    {
      "epoch": 14.730021598272138,
      "grad_norm": 0.003759547136723995,
      "learning_rate": 3.5269978401727865e-05,
      "loss": 0.0032,
      "step": 47740
    },
    {
      "epoch": 14.733107065720457,
      "grad_norm": 0.012906703166663647,
      "learning_rate": 3.526689293427955e-05,
      "loss": 0.0006,
      "step": 47750
    },
    {
      "epoch": 14.736192533168776,
      "grad_norm": 0.04608803614974022,
      "learning_rate": 3.526380746683123e-05,
      "loss": 0.0067,
      "step": 47760
    },
    {
      "epoch": 14.739278000617093,
      "grad_norm": 0.0006463712197728455,
      "learning_rate": 3.5260721999382906e-05,
      "loss": 0.0012,
      "step": 47770
    },
    {
      "epoch": 14.742363468065411,
      "grad_norm": 0.0009250002913177013,
      "learning_rate": 3.525763653193459e-05,
      "loss": 0.0024,
      "step": 47780
    },
    {
      "epoch": 14.74544893551373,
      "grad_norm": 0.0007033268921077251,
      "learning_rate": 3.525455106448627e-05,
      "loss": 0.0002,
      "step": 47790
    },
    {
      "epoch": 14.748534402962049,
      "grad_norm": 0.0008856061031110585,
      "learning_rate": 3.525146559703795e-05,
      "loss": 0.0051,
      "step": 47800
    },
    {
      "epoch": 14.751619870410368,
      "grad_norm": 0.0005381396622397006,
      "learning_rate": 3.5248380129589635e-05,
      "loss": 0.0039,
      "step": 47810
    },
    {
      "epoch": 14.754705337858686,
      "grad_norm": 0.2358151525259018,
      "learning_rate": 3.524529466214132e-05,
      "loss": 0.0127,
      "step": 47820
    },
    {
      "epoch": 14.757790805307003,
      "grad_norm": 0.004511093255132437,
      "learning_rate": 3.5242209194693e-05,
      "loss": 0.0015,
      "step": 47830
    },
    {
      "epoch": 14.760876272755322,
      "grad_norm": 0.00518748490139842,
      "learning_rate": 3.5239123727244676e-05,
      "loss": 0.0001,
      "step": 47840
    },
    {
      "epoch": 14.76396174020364,
      "grad_norm": 2.4554898738861084,
      "learning_rate": 3.523603825979636e-05,
      "loss": 0.011,
      "step": 47850
    },
    {
      "epoch": 14.76704720765196,
      "grad_norm": 0.0008750739507377148,
      "learning_rate": 3.523295279234805e-05,
      "loss": 0.0015,
      "step": 47860
    },
    {
      "epoch": 14.770132675100278,
      "grad_norm": 0.004125683102756739,
      "learning_rate": 3.5229867324899724e-05,
      "loss": 0.0011,
      "step": 47870
    },
    {
      "epoch": 14.773218142548597,
      "grad_norm": 2.3427801352227107e-05,
      "learning_rate": 3.5226781857451406e-05,
      "loss": 0.0008,
      "step": 47880
    },
    {
      "epoch": 14.776303609996914,
      "grad_norm": 0.00023846318072173744,
      "learning_rate": 3.522369639000309e-05,
      "loss": 0.0009,
      "step": 47890
    },
    {
      "epoch": 14.779389077445233,
      "grad_norm": 0.06522470712661743,
      "learning_rate": 3.522061092255477e-05,
      "loss": 0.0002,
      "step": 47900
    },
    {
      "epoch": 14.782474544893551,
      "grad_norm": 0.020248940214514732,
      "learning_rate": 3.521752545510645e-05,
      "loss": 0.0026,
      "step": 47910
    },
    {
      "epoch": 14.78556001234187,
      "grad_norm": 2.123403310775757,
      "learning_rate": 3.521443998765813e-05,
      "loss": 0.0025,
      "step": 47920
    },
    {
      "epoch": 14.788645479790189,
      "grad_norm": 0.004251766484230757,
      "learning_rate": 3.521135452020982e-05,
      "loss": 0.0008,
      "step": 47930
    },
    {
      "epoch": 14.791730947238507,
      "grad_norm": 0.026041481643915176,
      "learning_rate": 3.5208269052761494e-05,
      "loss": 0.0043,
      "step": 47940
    },
    {
      "epoch": 14.794816414686824,
      "grad_norm": 0.052560023963451385,
      "learning_rate": 3.5205183585313177e-05,
      "loss": 0.0016,
      "step": 47950
    },
    {
      "epoch": 14.797901882135143,
      "grad_norm": 0.002840216737240553,
      "learning_rate": 3.520209811786486e-05,
      "loss": 0.0002,
      "step": 47960
    },
    {
      "epoch": 14.800987349583462,
      "grad_norm": 0.000375888601411134,
      "learning_rate": 3.519901265041654e-05,
      "loss": 0.0007,
      "step": 47970
    },
    {
      "epoch": 14.80407281703178,
      "grad_norm": 1.9041619300842285,
      "learning_rate": 3.519592718296822e-05,
      "loss": 0.0012,
      "step": 47980
    },
    {
      "epoch": 14.8071582844801,
      "grad_norm": 0.00039198476588353515,
      "learning_rate": 3.51928417155199e-05,
      "loss": 0.0002,
      "step": 47990
    },
    {
      "epoch": 14.810243751928418,
      "grad_norm": 0.046638160943984985,
      "learning_rate": 3.518975624807159e-05,
      "loss": 0.0087,
      "step": 48000
    },
    {
      "epoch": 14.813329219376735,
      "grad_norm": 0.0002909393224399537,
      "learning_rate": 3.5186670780623265e-05,
      "loss": 0.0008,
      "step": 48010
    },
    {
      "epoch": 14.816414686825054,
      "grad_norm": 0.00013690500054508448,
      "learning_rate": 3.518358531317495e-05,
      "loss": 0.001,
      "step": 48020
    },
    {
      "epoch": 14.819500154273372,
      "grad_norm": 0.005381244234740734,
      "learning_rate": 3.518049984572663e-05,
      "loss": 0.0096,
      "step": 48030
    },
    {
      "epoch": 14.822585621721691,
      "grad_norm": 0.04097181558609009,
      "learning_rate": 3.517741437827831e-05,
      "loss": 0.0007,
      "step": 48040
    },
    {
      "epoch": 14.82567108917001,
      "grad_norm": 0.0010633697966113687,
      "learning_rate": 3.517432891082999e-05,
      "loss": 0.0009,
      "step": 48050
    },
    {
      "epoch": 14.828756556618327,
      "grad_norm": 0.009222520515322685,
      "learning_rate": 3.517124344338168e-05,
      "loss": 0.0002,
      "step": 48060
    },
    {
      "epoch": 14.831842024066646,
      "grad_norm": 0.0003984015202149749,
      "learning_rate": 3.516815797593336e-05,
      "loss": 0.004,
      "step": 48070
    },
    {
      "epoch": 14.834927491514964,
      "grad_norm": 0.0009683558018878102,
      "learning_rate": 3.5165072508485035e-05,
      "loss": 0.0001,
      "step": 48080
    },
    {
      "epoch": 14.838012958963283,
      "grad_norm": 0.055811770260334015,
      "learning_rate": 3.516198704103672e-05,
      "loss": 0.0011,
      "step": 48090
    },
    {
      "epoch": 14.841098426411602,
      "grad_norm": 0.3594570755958557,
      "learning_rate": 3.51589015735884e-05,
      "loss": 0.0029,
      "step": 48100
    },
    {
      "epoch": 14.84418389385992,
      "grad_norm": 0.6347674131393433,
      "learning_rate": 3.515581610614008e-05,
      "loss": 0.0032,
      "step": 48110
    },
    {
      "epoch": 14.847269361308237,
      "grad_norm": 0.34129711985588074,
      "learning_rate": 3.515273063869176e-05,
      "loss": 0.0007,
      "step": 48120
    },
    {
      "epoch": 14.850354828756556,
      "grad_norm": 0.0011402001837268472,
      "learning_rate": 3.514964517124345e-05,
      "loss": 0.0031,
      "step": 48130
    },
    {
      "epoch": 14.853440296204875,
      "grad_norm": 0.00148794858250767,
      "learning_rate": 3.514655970379513e-05,
      "loss": 0.0014,
      "step": 48140
    },
    {
      "epoch": 14.856525763653194,
      "grad_norm": 2.086583845084533e-05,
      "learning_rate": 3.5143474236346806e-05,
      "loss": 0.001,
      "step": 48150
    },
    {
      "epoch": 14.859611231101512,
      "grad_norm": 0.05724500119686127,
      "learning_rate": 3.514038876889849e-05,
      "loss": 0.0034,
      "step": 48160
    },
    {
      "epoch": 14.862696698549831,
      "grad_norm": 0.00032392836874350905,
      "learning_rate": 3.513730330145017e-05,
      "loss": 0.0009,
      "step": 48170
    },
    {
      "epoch": 14.865782165998148,
      "grad_norm": 0.13440485298633575,
      "learning_rate": 3.513421783400185e-05,
      "loss": 0.0014,
      "step": 48180
    },
    {
      "epoch": 14.868867633446467,
      "grad_norm": 4.275722676538862e-05,
      "learning_rate": 3.513113236655353e-05,
      "loss": 0.0035,
      "step": 48190
    },
    {
      "epoch": 14.871953100894785,
      "grad_norm": 0.3280148208141327,
      "learning_rate": 3.512804689910522e-05,
      "loss": 0.0069,
      "step": 48200
    },
    {
      "epoch": 14.875038568343104,
      "grad_norm": 0.006994504481554031,
      "learning_rate": 3.51249614316569e-05,
      "loss": 0.0089,
      "step": 48210
    },
    {
      "epoch": 14.878124035791423,
      "grad_norm": 0.006900349166244268,
      "learning_rate": 3.5121875964208576e-05,
      "loss": 0.0014,
      "step": 48220
    },
    {
      "epoch": 14.881209503239742,
      "grad_norm": 0.5804875493049622,
      "learning_rate": 3.511879049676026e-05,
      "loss": 0.0056,
      "step": 48230
    },
    {
      "epoch": 14.884294970688059,
      "grad_norm": 0.5432905554771423,
      "learning_rate": 3.511570502931194e-05,
      "loss": 0.0026,
      "step": 48240
    },
    {
      "epoch": 14.887380438136377,
      "grad_norm": 0.0003851523797493428,
      "learning_rate": 3.5112619561863624e-05,
      "loss": 0.0002,
      "step": 48250
    },
    {
      "epoch": 14.890465905584696,
      "grad_norm": 0.0015176753513514996,
      "learning_rate": 3.51095340944153e-05,
      "loss": 0.0004,
      "step": 48260
    },
    {
      "epoch": 14.893551373033015,
      "grad_norm": 1.9425848722457886,
      "learning_rate": 3.510644862696699e-05,
      "loss": 0.0051,
      "step": 48270
    },
    {
      "epoch": 14.896636840481333,
      "grad_norm": 0.004421928431838751,
      "learning_rate": 3.510336315951867e-05,
      "loss": 0.0034,
      "step": 48280
    },
    {
      "epoch": 14.899722307929652,
      "grad_norm": 0.008031506091356277,
      "learning_rate": 3.510027769207035e-05,
      "loss": 0.0001,
      "step": 48290
    },
    {
      "epoch": 14.902807775377969,
      "grad_norm": 0.0006103769410401583,
      "learning_rate": 3.5097192224622036e-05,
      "loss": 0.0016,
      "step": 48300
    },
    {
      "epoch": 14.905893242826288,
      "grad_norm": 0.0004005120135843754,
      "learning_rate": 3.509410675717371e-05,
      "loss": 0.0012,
      "step": 48310
    },
    {
      "epoch": 14.908978710274607,
      "grad_norm": 0.12316260486841202,
      "learning_rate": 3.5091021289725394e-05,
      "loss": 0.0052,
      "step": 48320
    },
    {
      "epoch": 14.912064177722925,
      "grad_norm": 0.003206216497346759,
      "learning_rate": 3.508793582227708e-05,
      "loss": 0.0033,
      "step": 48330
    },
    {
      "epoch": 14.915149645171244,
      "grad_norm": 0.09616310149431229,
      "learning_rate": 3.508485035482876e-05,
      "loss": 0.0005,
      "step": 48340
    },
    {
      "epoch": 14.918235112619563,
      "grad_norm": 0.002401567529886961,
      "learning_rate": 3.508176488738044e-05,
      "loss": 0.0013,
      "step": 48350
    },
    {
      "epoch": 14.92132058006788,
      "grad_norm": 5.5833643273217604e-05,
      "learning_rate": 3.507867941993212e-05,
      "loss": 0.0009,
      "step": 48360
    },
    {
      "epoch": 14.924406047516198,
      "grad_norm": 0.061035118997097015,
      "learning_rate": 3.507559395248381e-05,
      "loss": 0.0,
      "step": 48370
    },
    {
      "epoch": 14.927491514964517,
      "grad_norm": 0.00017430100706405938,
      "learning_rate": 3.507250848503548e-05,
      "loss": 0.0044,
      "step": 48380
    },
    {
      "epoch": 14.930576982412836,
      "grad_norm": 0.00021424522856250405,
      "learning_rate": 3.5069423017587165e-05,
      "loss": 0.0003,
      "step": 48390
    },
    {
      "epoch": 14.933662449861155,
      "grad_norm": 0.00398478377610445,
      "learning_rate": 3.506633755013885e-05,
      "loss": 0.0,
      "step": 48400
    },
    {
      "epoch": 14.936747917309471,
      "grad_norm": 0.0014335560845211148,
      "learning_rate": 3.506325208269053e-05,
      "loss": 0.0001,
      "step": 48410
    },
    {
      "epoch": 14.93983338475779,
      "grad_norm": 0.1408683806657791,
      "learning_rate": 3.506016661524221e-05,
      "loss": 0.0025,
      "step": 48420
    },
    {
      "epoch": 14.942918852206109,
      "grad_norm": 0.03370482102036476,
      "learning_rate": 3.505708114779389e-05,
      "loss": 0.0007,
      "step": 48430
    },
    {
      "epoch": 14.946004319654428,
      "grad_norm": 0.000326911685988307,
      "learning_rate": 3.505399568034558e-05,
      "loss": 0.0001,
      "step": 48440
    },
    {
      "epoch": 14.949089787102746,
      "grad_norm": 0.0017927692970260978,
      "learning_rate": 3.505091021289725e-05,
      "loss": 0.0009,
      "step": 48450
    },
    {
      "epoch": 14.952175254551065,
      "grad_norm": 0.0007057492039166391,
      "learning_rate": 3.5047824745448935e-05,
      "loss": 0.0001,
      "step": 48460
    },
    {
      "epoch": 14.955260721999384,
      "grad_norm": 0.007547643035650253,
      "learning_rate": 3.504473927800062e-05,
      "loss": 0.0047,
      "step": 48470
    },
    {
      "epoch": 14.9583461894477,
      "grad_norm": 0.7312452793121338,
      "learning_rate": 3.50416538105523e-05,
      "loss": 0.0039,
      "step": 48480
    },
    {
      "epoch": 14.96143165689602,
      "grad_norm": 0.0005305826780386269,
      "learning_rate": 3.503856834310398e-05,
      "loss": 0.0006,
      "step": 48490
    },
    {
      "epoch": 14.964517124344338,
      "grad_norm": 0.08716046810150146,
      "learning_rate": 3.503548287565566e-05,
      "loss": 0.0004,
      "step": 48500
    },
    {
      "epoch": 14.967602591792657,
      "grad_norm": 0.5649344325065613,
      "learning_rate": 3.503239740820735e-05,
      "loss": 0.0012,
      "step": 48510
    },
    {
      "epoch": 14.970688059240976,
      "grad_norm": 5.849109649658203,
      "learning_rate": 3.5029311940759024e-05,
      "loss": 0.0143,
      "step": 48520
    },
    {
      "epoch": 14.973773526689293,
      "grad_norm": 0.042160775512456894,
      "learning_rate": 3.5026226473310706e-05,
      "loss": 0.0001,
      "step": 48530
    },
    {
      "epoch": 14.976858994137611,
      "grad_norm": 0.0010589560260996222,
      "learning_rate": 3.5023141005862395e-05,
      "loss": 0.0004,
      "step": 48540
    },
    {
      "epoch": 14.97994446158593,
      "grad_norm": 2.7819874958368018e-05,
      "learning_rate": 3.502005553841407e-05,
      "loss": 0.0002,
      "step": 48550
    },
    {
      "epoch": 14.983029929034249,
      "grad_norm": 0.15040507912635803,
      "learning_rate": 3.5016970070965753e-05,
      "loss": 0.0002,
      "step": 48560
    },
    {
      "epoch": 14.986115396482568,
      "grad_norm": 0.00360582466237247,
      "learning_rate": 3.5013884603517436e-05,
      "loss": 0.0009,
      "step": 48570
    },
    {
      "epoch": 14.989200863930886,
      "grad_norm": 0.008640281856060028,
      "learning_rate": 3.501079913606912e-05,
      "loss": 0.0001,
      "step": 48580
    },
    {
      "epoch": 14.992286331379203,
      "grad_norm": 0.0027484374586492777,
      "learning_rate": 3.5007713668620794e-05,
      "loss": 0.0013,
      "step": 48590
    },
    {
      "epoch": 14.995371798827522,
      "grad_norm": 0.0006994246505200863,
      "learning_rate": 3.5004628201172477e-05,
      "loss": 0.0004,
      "step": 48600
    },
    {
      "epoch": 14.99845726627584,
      "grad_norm": 0.004736248403787613,
      "learning_rate": 3.5001542733724166e-05,
      "loss": 0.0002,
      "step": 48610
    },
    {
      "epoch": 15.0,
      "eval_accuracy_branch1": 0.999450247388675,
      "eval_accuracy_branch2": 0.4489839221473144,
      "eval_f1_branch1": 0.9993872636490457,
      "eval_f1_branch2": 0.44876292940812623,
      "eval_loss": 0.0007823662017472088,
      "eval_precision_branch1": 0.9993445417379392,
      "eval_precision_branch2": 0.5130302311413034,
      "eval_recall_branch1": 0.9994313357824052,
      "eval_recall_branch2": 0.5126153757125083,
      "eval_runtime": 241.1166,
      "eval_samples_per_second": 430.012,
      "eval_steps_per_second": 53.754,
      "step": 48615
    },
    {
      "epoch": 15.00154273372416,
      "grad_norm": 0.006355360150337219,
      "learning_rate": 3.499845726627584e-05,
      "loss": 0.0168,
      "step": 48620
    },
    {
      "epoch": 15.004628201172478,
      "grad_norm": 0.0011557117104530334,
      "learning_rate": 3.4995371798827524e-05,
      "loss": 0.0043,
      "step": 48630
    },
    {
      "epoch": 15.007713668620797,
      "grad_norm": 0.7139520049095154,
      "learning_rate": 3.4992286331379207e-05,
      "loss": 0.0004,
      "step": 48640
    },
    {
      "epoch": 15.010799136069114,
      "grad_norm": 0.4745669662952423,
      "learning_rate": 3.498920086393089e-05,
      "loss": 0.0003,
      "step": 48650
    },
    {
      "epoch": 15.013884603517432,
      "grad_norm": 0.0005942653515376151,
      "learning_rate": 3.4986115396482565e-05,
      "loss": 0.0,
      "step": 48660
    },
    {
      "epoch": 15.016970070965751,
      "grad_norm": 0.00045685755321756005,
      "learning_rate": 3.498302992903425e-05,
      "loss": 0.0058,
      "step": 48670
    },
    {
      "epoch": 15.02005553841407,
      "grad_norm": 0.002529829042032361,
      "learning_rate": 3.4979944461585936e-05,
      "loss": 0.0001,
      "step": 48680
    },
    {
      "epoch": 15.023141005862389,
      "grad_norm": 0.0002126159379258752,
      "learning_rate": 3.497685899413761e-05,
      "loss": 0.0009,
      "step": 48690
    },
    {
      "epoch": 15.026226473310707,
      "grad_norm": 0.00020027779100928456,
      "learning_rate": 3.4973773526689295e-05,
      "loss": 0.0025,
      "step": 48700
    },
    {
      "epoch": 15.029311940759024,
      "grad_norm": 0.0031876899302005768,
      "learning_rate": 3.497068805924098e-05,
      "loss": 0.0018,
      "step": 48710
    },
    {
      "epoch": 15.032397408207343,
      "grad_norm": 5.354588574846275e-05,
      "learning_rate": 3.496760259179266e-05,
      "loss": 0.0,
      "step": 48720
    },
    {
      "epoch": 15.035482875655662,
      "grad_norm": 0.0010615168139338493,
      "learning_rate": 3.496451712434434e-05,
      "loss": 0.0002,
      "step": 48730
    },
    {
      "epoch": 15.03856834310398,
      "grad_norm": 0.0041252425871789455,
      "learning_rate": 3.496143165689602e-05,
      "loss": 0.0001,
      "step": 48740
    },
    {
      "epoch": 15.0416538105523,
      "grad_norm": 0.004610112868249416,
      "learning_rate": 3.495834618944771e-05,
      "loss": 0.0,
      "step": 48750
    },
    {
      "epoch": 15.044739278000618,
      "grad_norm": 0.0002390196023043245,
      "learning_rate": 3.495526072199938e-05,
      "loss": 0.0002,
      "step": 48760
    },
    {
      "epoch": 15.047824745448935,
      "grad_norm": 0.014935561455786228,
      "learning_rate": 3.4952175254551065e-05,
      "loss": 0.0001,
      "step": 48770
    },
    {
      "epoch": 15.050910212897254,
      "grad_norm": 0.00019298824190627784,
      "learning_rate": 3.494908978710275e-05,
      "loss": 0.0051,
      "step": 48780
    },
    {
      "epoch": 15.053995680345572,
      "grad_norm": 0.0012595710577443242,
      "learning_rate": 3.494600431965443e-05,
      "loss": 0.002,
      "step": 48790
    },
    {
      "epoch": 15.057081147793891,
      "grad_norm": 0.003526159795001149,
      "learning_rate": 3.494291885220611e-05,
      "loss": 0.0001,
      "step": 48800
    },
    {
      "epoch": 15.06016661524221,
      "grad_norm": 0.8467859625816345,
      "learning_rate": 3.4939833384757795e-05,
      "loss": 0.0008,
      "step": 48810
    },
    {
      "epoch": 15.063252082690527,
      "grad_norm": 0.03912064805626869,
      "learning_rate": 3.493674791730948e-05,
      "loss": 0.0019,
      "step": 48820
    },
    {
      "epoch": 15.066337550138845,
      "grad_norm": 0.002616720972582698,
      "learning_rate": 3.493366244986115e-05,
      "loss": 0.0001,
      "step": 48830
    },
    {
      "epoch": 15.069423017587164,
      "grad_norm": 1.6752543449401855,
      "learning_rate": 3.4930576982412836e-05,
      "loss": 0.0062,
      "step": 48840
    },
    {
      "epoch": 15.072508485035483,
      "grad_norm": 5.615914778900333e-05,
      "learning_rate": 3.492749151496452e-05,
      "loss": 0.0002,
      "step": 48850
    },
    {
      "epoch": 15.075593952483802,
      "grad_norm": 1.7560909986495972,
      "learning_rate": 3.49244060475162e-05,
      "loss": 0.0009,
      "step": 48860
    },
    {
      "epoch": 15.07867941993212,
      "grad_norm": 0.0015330753521993756,
      "learning_rate": 3.492132058006788e-05,
      "loss": 0.0002,
      "step": 48870
    },
    {
      "epoch": 15.081764887380437,
      "grad_norm": 0.08122283965349197,
      "learning_rate": 3.4918235112619566e-05,
      "loss": 0.0009,
      "step": 48880
    },
    {
      "epoch": 15.084850354828756,
      "grad_norm": 0.002226053737103939,
      "learning_rate": 3.491514964517125e-05,
      "loss": 0.0018,
      "step": 48890
    },
    {
      "epoch": 15.087935822277075,
      "grad_norm": 0.0037710799369961023,
      "learning_rate": 3.4912064177722924e-05,
      "loss": 0.0019,
      "step": 48900
    },
    {
      "epoch": 15.091021289725393,
      "grad_norm": 0.0005422132671810687,
      "learning_rate": 3.4908978710274606e-05,
      "loss": 0.0001,
      "step": 48910
    },
    {
      "epoch": 15.094106757173712,
      "grad_norm": 0.024288276210427284,
      "learning_rate": 3.490589324282629e-05,
      "loss": 0.0004,
      "step": 48920
    },
    {
      "epoch": 15.097192224622031,
      "grad_norm": 8.741282726987265e-06,
      "learning_rate": 3.490280777537797e-05,
      "loss": 0.0001,
      "step": 48930
    },
    {
      "epoch": 15.100277692070348,
      "grad_norm": 0.01033852994441986,
      "learning_rate": 3.4899722307929654e-05,
      "loss": 0.0001,
      "step": 48940
    },
    {
      "epoch": 15.103363159518667,
      "grad_norm": 0.004281977657228708,
      "learning_rate": 3.4896636840481336e-05,
      "loss": 0.0024,
      "step": 48950
    },
    {
      "epoch": 15.106448626966985,
      "grad_norm": 0.0022620484232902527,
      "learning_rate": 3.489355137303302e-05,
      "loss": 0.0002,
      "step": 48960
    },
    {
      "epoch": 15.109534094415304,
      "grad_norm": 0.0011175628751516342,
      "learning_rate": 3.4890465905584694e-05,
      "loss": 0.0,
      "step": 48970
    },
    {
      "epoch": 15.112619561863623,
      "grad_norm": 0.28125452995300293,
      "learning_rate": 3.488738043813638e-05,
      "loss": 0.0013,
      "step": 48980
    },
    {
      "epoch": 15.115705029311941,
      "grad_norm": 0.309894323348999,
      "learning_rate": 3.488429497068806e-05,
      "loss": 0.0022,
      "step": 48990
    },
    {
      "epoch": 15.118790496760258,
      "grad_norm": 0.002130209468305111,
      "learning_rate": 3.488120950323974e-05,
      "loss": 0.0074,
      "step": 49000
    },
    {
      "epoch": 15.121875964208577,
      "grad_norm": 0.001495067379437387,
      "learning_rate": 3.4878124035791424e-05,
      "loss": 0.0016,
      "step": 49010
    },
    {
      "epoch": 15.124961431656896,
      "grad_norm": 0.5030136704444885,
      "learning_rate": 3.487503856834311e-05,
      "loss": 0.0139,
      "step": 49020
    },
    {
      "epoch": 15.128046899105215,
      "grad_norm": 0.47729626297950745,
      "learning_rate": 3.487195310089479e-05,
      "loss": 0.0037,
      "step": 49030
    },
    {
      "epoch": 15.131132366553533,
      "grad_norm": 0.14038126170635223,
      "learning_rate": 3.4868867633446465e-05,
      "loss": 0.0112,
      "step": 49040
    },
    {
      "epoch": 15.134217834001852,
      "grad_norm": 0.015642579644918442,
      "learning_rate": 3.4865782165998154e-05,
      "loss": 0.0002,
      "step": 49050
    },
    {
      "epoch": 15.137303301450169,
      "grad_norm": 0.00011249661474721506,
      "learning_rate": 3.486269669854983e-05,
      "loss": 0.0001,
      "step": 49060
    },
    {
      "epoch": 15.140388768898488,
      "grad_norm": 0.0013355497503653169,
      "learning_rate": 3.485961123110151e-05,
      "loss": 0.0026,
      "step": 49070
    },
    {
      "epoch": 15.143474236346806,
      "grad_norm": 1.0627179145812988,
      "learning_rate": 3.4856525763653195e-05,
      "loss": 0.0013,
      "step": 49080
    },
    {
      "epoch": 15.146559703795125,
      "grad_norm": 4.8964691162109375,
      "learning_rate": 3.485344029620488e-05,
      "loss": 0.0077,
      "step": 49090
    },
    {
      "epoch": 15.149645171243444,
      "grad_norm": 0.00034159718779847026,
      "learning_rate": 3.485035482875656e-05,
      "loss": 0.0026,
      "step": 49100
    },
    {
      "epoch": 15.152730638691763,
      "grad_norm": 0.8757126331329346,
      "learning_rate": 3.4847269361308235e-05,
      "loss": 0.0017,
      "step": 49110
    },
    {
      "epoch": 15.15581610614008,
      "grad_norm": 0.00022728998737875372,
      "learning_rate": 3.4844183893859925e-05,
      "loss": 0.0027,
      "step": 49120
    },
    {
      "epoch": 15.158901573588398,
      "grad_norm": 0.09059645980596542,
      "learning_rate": 3.48410984264116e-05,
      "loss": 0.0004,
      "step": 49130
    },
    {
      "epoch": 15.161987041036717,
      "grad_norm": 0.008803156204521656,
      "learning_rate": 3.483801295896328e-05,
      "loss": 0.0014,
      "step": 49140
    },
    {
      "epoch": 15.165072508485036,
      "grad_norm": 0.0027810053434222937,
      "learning_rate": 3.4834927491514965e-05,
      "loss": 0.0001,
      "step": 49150
    },
    {
      "epoch": 15.168157975933354,
      "grad_norm": 0.005792620591819286,
      "learning_rate": 3.483184202406665e-05,
      "loss": 0.0001,
      "step": 49160
    },
    {
      "epoch": 15.171243443381673,
      "grad_norm": 0.013647902756929398,
      "learning_rate": 3.482875655661833e-05,
      "loss": 0.0035,
      "step": 49170
    },
    {
      "epoch": 15.17432891082999,
      "grad_norm": 0.0006768788443878293,
      "learning_rate": 3.4825671089170006e-05,
      "loss": 0.0006,
      "step": 49180
    },
    {
      "epoch": 15.177414378278309,
      "grad_norm": 3.3896727561950684,
      "learning_rate": 3.4822585621721695e-05,
      "loss": 0.0032,
      "step": 49190
    },
    {
      "epoch": 15.180499845726628,
      "grad_norm": 0.0002654366544447839,
      "learning_rate": 3.481950015427338e-05,
      "loss": 0.0031,
      "step": 49200
    },
    {
      "epoch": 15.183585313174946,
      "grad_norm": 2.108094486175105e-05,
      "learning_rate": 3.4816414686825053e-05,
      "loss": 0.0004,
      "step": 49210
    },
    {
      "epoch": 15.186670780623265,
      "grad_norm": 0.00012588640674948692,
      "learning_rate": 3.4813329219376736e-05,
      "loss": 0.0004,
      "step": 49220
    },
    {
      "epoch": 15.189756248071582,
      "grad_norm": 0.005117734894156456,
      "learning_rate": 3.481024375192842e-05,
      "loss": 0.0001,
      "step": 49230
    },
    {
      "epoch": 15.1928417155199,
      "grad_norm": 0.00014379448839463294,
      "learning_rate": 3.48071582844801e-05,
      "loss": 0.0001,
      "step": 49240
    },
    {
      "epoch": 15.19592718296822,
      "grad_norm": 0.008838243782520294,
      "learning_rate": 3.480407281703178e-05,
      "loss": 0.0,
      "step": 49250
    },
    {
      "epoch": 15.199012650416538,
      "grad_norm": 0.0016434883000329137,
      "learning_rate": 3.4800987349583466e-05,
      "loss": 0.0001,
      "step": 49260
    },
    {
      "epoch": 15.202098117864857,
      "grad_norm": 0.0052685728296637535,
      "learning_rate": 3.479790188213515e-05,
      "loss": 0.0,
      "step": 49270
    },
    {
      "epoch": 15.205183585313176,
      "grad_norm": 0.001580781419761479,
      "learning_rate": 3.4794816414686824e-05,
      "loss": 0.0,
      "step": 49280
    },
    {
      "epoch": 15.208269052761493,
      "grad_norm": 0.9511842727661133,
      "learning_rate": 3.479173094723851e-05,
      "loss": 0.0012,
      "step": 49290
    },
    {
      "epoch": 15.211354520209811,
      "grad_norm": 0.0004197862872388214,
      "learning_rate": 3.478864547979019e-05,
      "loss": 0.0003,
      "step": 49300
    },
    {
      "epoch": 15.21443998765813,
      "grad_norm": 0.0007992987520992756,
      "learning_rate": 3.478556001234187e-05,
      "loss": 0.0004,
      "step": 49310
    },
    {
      "epoch": 15.217525455106449,
      "grad_norm": 0.0018807339947670698,
      "learning_rate": 3.4782474544893554e-05,
      "loss": 0.0004,
      "step": 49320
    },
    {
      "epoch": 15.220610922554767,
      "grad_norm": 0.00699713034555316,
      "learning_rate": 3.4779389077445236e-05,
      "loss": 0.0009,
      "step": 49330
    },
    {
      "epoch": 15.223696390003086,
      "grad_norm": 0.0744648277759552,
      "learning_rate": 3.477630360999692e-05,
      "loss": 0.0007,
      "step": 49340
    },
    {
      "epoch": 15.226781857451403,
      "grad_norm": 0.0003719379601534456,
      "learning_rate": 3.4773218142548595e-05,
      "loss": 0.0006,
      "step": 49350
    },
    {
      "epoch": 15.229867324899722,
      "grad_norm": 0.0004774025874212384,
      "learning_rate": 3.4770132675100284e-05,
      "loss": 0.0001,
      "step": 49360
    },
    {
      "epoch": 15.23295279234804,
      "grad_norm": 0.0007575094350613654,
      "learning_rate": 3.476704720765196e-05,
      "loss": 0.0011,
      "step": 49370
    },
    {
      "epoch": 15.23603825979636,
      "grad_norm": 0.052561573684215546,
      "learning_rate": 3.476396174020364e-05,
      "loss": 0.0,
      "step": 49380
    },
    {
      "epoch": 15.239123727244678,
      "grad_norm": 0.011273101903498173,
      "learning_rate": 3.4760876272755325e-05,
      "loss": 0.0032,
      "step": 49390
    },
    {
      "epoch": 15.242209194692997,
      "grad_norm": 0.00014792873116675764,
      "learning_rate": 3.475779080530701e-05,
      "loss": 0.0004,
      "step": 49400
    },
    {
      "epoch": 15.245294662141314,
      "grad_norm": 0.0005950254271738231,
      "learning_rate": 3.475470533785869e-05,
      "loss": 0.0123,
      "step": 49410
    },
    {
      "epoch": 15.248380129589632,
      "grad_norm": 9.591575690137688e-06,
      "learning_rate": 3.4751619870410365e-05,
      "loss": 0.0046,
      "step": 49420
    },
    {
      "epoch": 15.251465597037951,
      "grad_norm": 0.00011166905460413545,
      "learning_rate": 3.4748534402962054e-05,
      "loss": 0.0036,
      "step": 49430
    },
    {
      "epoch": 15.25455106448627,
      "grad_norm": 8.253835403593257e-05,
      "learning_rate": 3.474544893551373e-05,
      "loss": 0.0003,
      "step": 49440
    },
    {
      "epoch": 15.257636531934589,
      "grad_norm": 2.7426681518554688,
      "learning_rate": 3.474236346806541e-05,
      "loss": 0.0046,
      "step": 49450
    },
    {
      "epoch": 15.260721999382907,
      "grad_norm": 1.2307547330856323,
      "learning_rate": 3.4739278000617095e-05,
      "loss": 0.005,
      "step": 49460
    },
    {
      "epoch": 15.263807466831224,
      "grad_norm": 4.429774344316684e-05,
      "learning_rate": 3.473619253316878e-05,
      "loss": 0.0004,
      "step": 49470
    },
    {
      "epoch": 15.266892934279543,
      "grad_norm": 0.009674918837845325,
      "learning_rate": 3.473310706572046e-05,
      "loss": 0.0004,
      "step": 49480
    },
    {
      "epoch": 15.269978401727862,
      "grad_norm": 0.002143808640539646,
      "learning_rate": 3.4730021598272136e-05,
      "loss": 0.0,
      "step": 49490
    },
    {
      "epoch": 15.27306386917618,
      "grad_norm": 0.0010856477310881019,
      "learning_rate": 3.4726936130823825e-05,
      "loss": 0.0031,
      "step": 49500
    },
    {
      "epoch": 15.2761493366245,
      "grad_norm": 0.6330952644348145,
      "learning_rate": 3.47238506633755e-05,
      "loss": 0.0019,
      "step": 49510
    },
    {
      "epoch": 15.279234804072818,
      "grad_norm": 0.00023406009131576866,
      "learning_rate": 3.472076519592718e-05,
      "loss": 0.0005,
      "step": 49520
    },
    {
      "epoch": 15.282320271521135,
      "grad_norm": 0.1271374225616455,
      "learning_rate": 3.4717679728478866e-05,
      "loss": 0.0167,
      "step": 49530
    },
    {
      "epoch": 15.285405738969454,
      "grad_norm": 8.229504601331428e-05,
      "learning_rate": 3.471459426103055e-05,
      "loss": 0.0011,
      "step": 49540
    },
    {
      "epoch": 15.288491206417772,
      "grad_norm": 0.057941608130931854,
      "learning_rate": 3.471150879358223e-05,
      "loss": 0.0015,
      "step": 49550
    },
    {
      "epoch": 15.291576673866091,
      "grad_norm": 0.3004050552845001,
      "learning_rate": 3.470842332613391e-05,
      "loss": 0.0028,
      "step": 49560
    },
    {
      "epoch": 15.29466214131441,
      "grad_norm": 0.0696198120713234,
      "learning_rate": 3.4705337858685596e-05,
      "loss": 0.0001,
      "step": 49570
    },
    {
      "epoch": 15.297747608762727,
      "grad_norm": 0.000170602259458974,
      "learning_rate": 3.470225239123727e-05,
      "loss": 0.0048,
      "step": 49580
    },
    {
      "epoch": 15.300833076211045,
      "grad_norm": 0.005171968601644039,
      "learning_rate": 3.4699166923788954e-05,
      "loss": 0.0037,
      "step": 49590
    },
    {
      "epoch": 15.303918543659364,
      "grad_norm": 0.0041456809267401695,
      "learning_rate": 3.469608145634064e-05,
      "loss": 0.0004,
      "step": 49600
    },
    {
      "epoch": 15.307004011107683,
      "grad_norm": 0.06472140550613403,
      "learning_rate": 3.469299598889232e-05,
      "loss": 0.0021,
      "step": 49610
    },
    {
      "epoch": 15.310089478556002,
      "grad_norm": 0.5728073716163635,
      "learning_rate": 3.4689910521444e-05,
      "loss": 0.0113,
      "step": 49620
    },
    {
      "epoch": 15.31317494600432,
      "grad_norm": 0.6491972804069519,
      "learning_rate": 3.4686825053995684e-05,
      "loss": 0.0018,
      "step": 49630
    },
    {
      "epoch": 15.316260413452637,
      "grad_norm": 0.005350742023438215,
      "learning_rate": 3.4683739586547366e-05,
      "loss": 0.0003,
      "step": 49640
    },
    {
      "epoch": 15.319345880900956,
      "grad_norm": 0.0006903568282723427,
      "learning_rate": 3.468065411909904e-05,
      "loss": 0.0007,
      "step": 49650
    },
    {
      "epoch": 15.322431348349275,
      "grad_norm": 0.0005107233300805092,
      "learning_rate": 3.4677568651650724e-05,
      "loss": 0.005,
      "step": 49660
    },
    {
      "epoch": 15.325516815797593,
      "grad_norm": 0.003896306036040187,
      "learning_rate": 3.4674483184202414e-05,
      "loss": 0.0046,
      "step": 49670
    },
    {
      "epoch": 15.328602283245912,
      "grad_norm": 0.3031373918056488,
      "learning_rate": 3.467139771675409e-05,
      "loss": 0.0053,
      "step": 49680
    },
    {
      "epoch": 15.33168775069423,
      "grad_norm": 0.007770818192511797,
      "learning_rate": 3.466831224930577e-05,
      "loss": 0.002,
      "step": 49690
    },
    {
      "epoch": 15.334773218142548,
      "grad_norm": 0.033684615045785904,
      "learning_rate": 3.4665226781857454e-05,
      "loss": 0.0013,
      "step": 49700
    },
    {
      "epoch": 15.337858685590867,
      "grad_norm": 0.010597088374197483,
      "learning_rate": 3.466214131440914e-05,
      "loss": 0.0004,
      "step": 49710
    },
    {
      "epoch": 15.340944153039185,
      "grad_norm": 0.001580979092977941,
      "learning_rate": 3.465905584696081e-05,
      "loss": 0.0033,
      "step": 49720
    },
    {
      "epoch": 15.344029620487504,
      "grad_norm": 0.7016262412071228,
      "learning_rate": 3.4655970379512495e-05,
      "loss": 0.0038,
      "step": 49730
    },
    {
      "epoch": 15.347115087935823,
      "grad_norm": 0.6891815066337585,
      "learning_rate": 3.4652884912064184e-05,
      "loss": 0.0113,
      "step": 49740
    },
    {
      "epoch": 15.350200555384141,
      "grad_norm": 0.40040722489356995,
      "learning_rate": 3.464979944461586e-05,
      "loss": 0.0004,
      "step": 49750
    },
    {
      "epoch": 15.353286022832458,
      "grad_norm": 0.00024598694290034473,
      "learning_rate": 3.464671397716754e-05,
      "loss": 0.0017,
      "step": 49760
    },
    {
      "epoch": 15.356371490280777,
      "grad_norm": 0.47193142771720886,
      "learning_rate": 3.4643628509719225e-05,
      "loss": 0.0006,
      "step": 49770
    },
    {
      "epoch": 15.359456957729096,
      "grad_norm": 0.0004015232261735946,
      "learning_rate": 3.464054304227091e-05,
      "loss": 0.0027,
      "step": 49780
    },
    {
      "epoch": 15.362542425177415,
      "grad_norm": 0.01475872565060854,
      "learning_rate": 3.463745757482258e-05,
      "loss": 0.0003,
      "step": 49790
    },
    {
      "epoch": 15.365627892625733,
      "grad_norm": 0.040781959891319275,
      "learning_rate": 3.463437210737427e-05,
      "loss": 0.0001,
      "step": 49800
    },
    {
      "epoch": 15.368713360074052,
      "grad_norm": 0.06668321788311005,
      "learning_rate": 3.4631286639925955e-05,
      "loss": 0.0001,
      "step": 49810
    },
    {
      "epoch": 15.371798827522369,
      "grad_norm": 0.0027054387610405684,
      "learning_rate": 3.462820117247763e-05,
      "loss": 0.0017,
      "step": 49820
    },
    {
      "epoch": 15.374884294970688,
      "grad_norm": 0.0007157148793339729,
      "learning_rate": 3.462511570502931e-05,
      "loss": 0.0,
      "step": 49830
    },
    {
      "epoch": 15.377969762419006,
      "grad_norm": 6.673621101072058e-05,
      "learning_rate": 3.4622030237580995e-05,
      "loss": 0.0001,
      "step": 49840
    },
    {
      "epoch": 15.381055229867325,
      "grad_norm": 2.729254265432246e-05,
      "learning_rate": 3.461894477013268e-05,
      "loss": 0.0051,
      "step": 49850
    },
    {
      "epoch": 15.384140697315644,
      "grad_norm": 5.2241055527701974e-05,
      "learning_rate": 3.4615859302684354e-05,
      "loss": 0.0005,
      "step": 49860
    },
    {
      "epoch": 15.387226164763963,
      "grad_norm": 0.030452480539679527,
      "learning_rate": 3.461277383523604e-05,
      "loss": 0.0032,
      "step": 49870
    },
    {
      "epoch": 15.39031163221228,
      "grad_norm": 0.003385670483112335,
      "learning_rate": 3.4609688367787725e-05,
      "loss": 0.0002,
      "step": 49880
    },
    {
      "epoch": 15.393397099660598,
      "grad_norm": 0.009233231656253338,
      "learning_rate": 3.46066029003394e-05,
      "loss": 0.0029,
      "step": 49890
    },
    {
      "epoch": 15.396482567108917,
      "grad_norm": 0.0016341086011379957,
      "learning_rate": 3.4603517432891083e-05,
      "loss": 0.0027,
      "step": 49900
    },
    {
      "epoch": 15.399568034557236,
      "grad_norm": 0.0004884009249508381,
      "learning_rate": 3.4600431965442766e-05,
      "loss": 0.0001,
      "step": 49910
    },
    {
      "epoch": 15.402653502005554,
      "grad_norm": 0.0009617220493964851,
      "learning_rate": 3.459734649799445e-05,
      "loss": 0.0002,
      "step": 49920
    },
    {
      "epoch": 15.405738969453873,
      "grad_norm": 0.023111211135983467,
      "learning_rate": 3.4594261030546124e-05,
      "loss": 0.0001,
      "step": 49930
    },
    {
      "epoch": 15.40882443690219,
      "grad_norm": 0.0038001053035259247,
      "learning_rate": 3.459117556309781e-05,
      "loss": 0.0001,
      "step": 49940
    },
    {
      "epoch": 15.411909904350509,
      "grad_norm": 0.4060501158237457,
      "learning_rate": 3.4588090095649496e-05,
      "loss": 0.0011,
      "step": 49950
    },
    {
      "epoch": 15.414995371798828,
      "grad_norm": 0.0001099544097087346,
      "learning_rate": 3.458500462820117e-05,
      "loss": 0.0016,
      "step": 49960
    },
    {
      "epoch": 15.418080839247146,
      "grad_norm": 0.0005775453755632043,
      "learning_rate": 3.4581919160752854e-05,
      "loss": 0.0009,
      "step": 49970
    },
    {
      "epoch": 15.421166306695465,
      "grad_norm": 0.0011616898700594902,
      "learning_rate": 3.4578833693304536e-05,
      "loss": 0.0016,
      "step": 49980
    },
    {
      "epoch": 15.424251774143784,
      "grad_norm": 0.00010909482080023736,
      "learning_rate": 3.457574822585622e-05,
      "loss": 0.0003,
      "step": 49990
    },
    {
      "epoch": 15.4273372415921,
      "grad_norm": 0.0031813536770641804,
      "learning_rate": 3.4572662758407895e-05,
      "loss": 0.0006,
      "step": 50000
    },
    {
      "epoch": 15.43042270904042,
      "grad_norm": 0.005433409474790096,
      "learning_rate": 3.4569577290959584e-05,
      "loss": 0.0012,
      "step": 50010
    },
    {
      "epoch": 15.433508176488738,
      "grad_norm": 0.255003958940506,
      "learning_rate": 3.4566491823511266e-05,
      "loss": 0.0007,
      "step": 50020
    },
    {
      "epoch": 15.436593643937057,
      "grad_norm": 0.004005000926554203,
      "learning_rate": 3.456340635606294e-05,
      "loss": 0.0029,
      "step": 50030
    },
    {
      "epoch": 15.439679111385376,
      "grad_norm": 0.14704866707324982,
      "learning_rate": 3.4560320888614625e-05,
      "loss": 0.0006,
      "step": 50040
    },
    {
      "epoch": 15.442764578833692,
      "grad_norm": 0.014225725084543228,
      "learning_rate": 3.455723542116631e-05,
      "loss": 0.0002,
      "step": 50050
    },
    {
      "epoch": 15.445850046282011,
      "grad_norm": 3.438308000564575,
      "learning_rate": 3.455414995371799e-05,
      "loss": 0.0029,
      "step": 50060
    },
    {
      "epoch": 15.44893551373033,
      "grad_norm": 0.09728146344423294,
      "learning_rate": 3.455106448626967e-05,
      "loss": 0.0028,
      "step": 50070
    },
    {
      "epoch": 15.452020981178649,
      "grad_norm": 0.0001932879677042365,
      "learning_rate": 3.4547979018821354e-05,
      "loss": 0.001,
      "step": 50080
    },
    {
      "epoch": 15.455106448626967,
      "grad_norm": 0.032895199954509735,
      "learning_rate": 3.454489355137304e-05,
      "loss": 0.0003,
      "step": 50090
    },
    {
      "epoch": 15.458191916075286,
      "grad_norm": 0.018785521388053894,
      "learning_rate": 3.454180808392471e-05,
      "loss": 0.003,
      "step": 50100
    },
    {
      "epoch": 15.461277383523603,
      "grad_norm": 0.14655247330665588,
      "learning_rate": 3.45387226164764e-05,
      "loss": 0.0008,
      "step": 50110
    },
    {
      "epoch": 15.464362850971922,
      "grad_norm": 0.006506459787487984,
      "learning_rate": 3.453563714902808e-05,
      "loss": 0.0,
      "step": 50120
    },
    {
      "epoch": 15.46744831842024,
      "grad_norm": 0.0004765092162415385,
      "learning_rate": 3.453255168157976e-05,
      "loss": 0.0001,
      "step": 50130
    },
    {
      "epoch": 15.47053378586856,
      "grad_norm": 0.0006232070154510438,
      "learning_rate": 3.452946621413144e-05,
      "loss": 0.0007,
      "step": 50140
    },
    {
      "epoch": 15.473619253316878,
      "grad_norm": 0.04589499905705452,
      "learning_rate": 3.4526380746683125e-05,
      "loss": 0.0013,
      "step": 50150
    },
    {
      "epoch": 15.476704720765197,
      "grad_norm": 0.003642800496891141,
      "learning_rate": 3.452329527923481e-05,
      "loss": 0.0002,
      "step": 50160
    },
    {
      "epoch": 15.479790188213514,
      "grad_norm": 1.9349842071533203,
      "learning_rate": 3.452020981178648e-05,
      "loss": 0.0022,
      "step": 50170
    },
    {
      "epoch": 15.482875655661832,
      "grad_norm": 0.13738687336444855,
      "learning_rate": 3.451712434433817e-05,
      "loss": 0.0014,
      "step": 50180
    },
    {
      "epoch": 15.485961123110151,
      "grad_norm": 3.130501136183739e-05,
      "learning_rate": 3.451403887688985e-05,
      "loss": 0.0007,
      "step": 50190
    },
    {
      "epoch": 15.48904659055847,
      "grad_norm": 0.0003590748237911612,
      "learning_rate": 3.451095340944153e-05,
      "loss": 0.0003,
      "step": 50200
    },
    {
      "epoch": 15.492132058006788,
      "grad_norm": 0.0012320734094828367,
      "learning_rate": 3.450786794199321e-05,
      "loss": 0.0007,
      "step": 50210
    },
    {
      "epoch": 15.495217525455107,
      "grad_norm": 0.0008872844045981765,
      "learning_rate": 3.4504782474544896e-05,
      "loss": 0.0,
      "step": 50220
    },
    {
      "epoch": 15.498302992903424,
      "grad_norm": 4.312060627853498e-05,
      "learning_rate": 3.450169700709658e-05,
      "loss": 0.0,
      "step": 50230
    },
    {
      "epoch": 15.501388460351743,
      "grad_norm": 0.0006122621707618237,
      "learning_rate": 3.4498611539648254e-05,
      "loss": 0.0007,
      "step": 50240
    },
    {
      "epoch": 15.504473927800062,
      "grad_norm": 0.031727828085422516,
      "learning_rate": 3.449552607219994e-05,
      "loss": 0.0015,
      "step": 50250
    },
    {
      "epoch": 15.50755939524838,
      "grad_norm": 0.0008004807168617845,
      "learning_rate": 3.449244060475162e-05,
      "loss": 0.0003,
      "step": 50260
    },
    {
      "epoch": 15.510644862696699,
      "grad_norm": 0.0019128916319459677,
      "learning_rate": 3.44893551373033e-05,
      "loss": 0.0032,
      "step": 50270
    },
    {
      "epoch": 15.513730330145018,
      "grad_norm": 0.014056201092898846,
      "learning_rate": 3.4486269669854984e-05,
      "loss": 0.0011,
      "step": 50280
    },
    {
      "epoch": 15.516815797593335,
      "grad_norm": 0.05540747568011284,
      "learning_rate": 3.4483184202406666e-05,
      "loss": 0.0016,
      "step": 50290
    },
    {
      "epoch": 15.519901265041653,
      "grad_norm": 1.1756268739700317,
      "learning_rate": 3.448009873495835e-05,
      "loss": 0.0053,
      "step": 50300
    },
    {
      "epoch": 15.522986732489972,
      "grad_norm": 0.0012340095127001405,
      "learning_rate": 3.4477013267510024e-05,
      "loss": 0.0,
      "step": 50310
    },
    {
      "epoch": 15.526072199938291,
      "grad_norm": 0.0002226398792117834,
      "learning_rate": 3.4473927800061714e-05,
      "loss": 0.0039,
      "step": 50320
    },
    {
      "epoch": 15.52915766738661,
      "grad_norm": 0.956731915473938,
      "learning_rate": 3.447084233261339e-05,
      "loss": 0.0014,
      "step": 50330
    },
    {
      "epoch": 15.532243134834928,
      "grad_norm": 0.009029097855091095,
      "learning_rate": 3.446775686516507e-05,
      "loss": 0.0015,
      "step": 50340
    },
    {
      "epoch": 15.535328602283245,
      "grad_norm": 0.021690046414732933,
      "learning_rate": 3.446467139771676e-05,
      "loss": 0.0074,
      "step": 50350
    },
    {
      "epoch": 15.538414069731564,
      "grad_norm": 0.001461759558878839,
      "learning_rate": 3.446158593026844e-05,
      "loss": 0.0001,
      "step": 50360
    },
    {
      "epoch": 15.541499537179883,
      "grad_norm": 0.00015022508159745485,
      "learning_rate": 3.445850046282012e-05,
      "loss": 0.0003,
      "step": 50370
    },
    {
      "epoch": 15.544585004628201,
      "grad_norm": 0.0009200805216096342,
      "learning_rate": 3.44554149953718e-05,
      "loss": 0.0,
      "step": 50380
    },
    {
      "epoch": 15.54767047207652,
      "grad_norm": 5.292836431181058e-05,
      "learning_rate": 3.4452329527923484e-05,
      "loss": 0.0009,
      "step": 50390
    },
    {
      "epoch": 15.550755939524837,
      "grad_norm": 0.017539007589221,
      "learning_rate": 3.444924406047516e-05,
      "loss": 0.0,
      "step": 50400
    },
    {
      "epoch": 15.553841406973156,
      "grad_norm": 0.01809002086520195,
      "learning_rate": 3.444615859302684e-05,
      "loss": 0.0015,
      "step": 50410
    },
    {
      "epoch": 15.556926874421475,
      "grad_norm": 3.1462931632995605,
      "learning_rate": 3.444307312557853e-05,
      "loss": 0.0149,
      "step": 50420
    },
    {
      "epoch": 15.560012341869793,
      "grad_norm": 0.0024888883344829082,
      "learning_rate": 3.443998765813021e-05,
      "loss": 0.0025,
      "step": 50430
    },
    {
      "epoch": 15.563097809318112,
      "grad_norm": 0.0009368220926262438,
      "learning_rate": 3.443690219068189e-05,
      "loss": 0.0004,
      "step": 50440
    },
    {
      "epoch": 15.56618327676643,
      "grad_norm": 0.000961621233727783,
      "learning_rate": 3.443381672323357e-05,
      "loss": 0.0001,
      "step": 50450
    },
    {
      "epoch": 15.569268744214748,
      "grad_norm": 0.0043044984340667725,
      "learning_rate": 3.4430731255785255e-05,
      "loss": 0.0027,
      "step": 50460
    },
    {
      "epoch": 15.572354211663066,
      "grad_norm": 0.004801785107702017,
      "learning_rate": 3.442764578833694e-05,
      "loss": 0.0003,
      "step": 50470
    },
    {
      "epoch": 15.575439679111385,
      "grad_norm": 0.0019241856643930078,
      "learning_rate": 3.442456032088861e-05,
      "loss": 0.0075,
      "step": 50480
    },
    {
      "epoch": 15.578525146559704,
      "grad_norm": 0.019505523145198822,
      "learning_rate": 3.44214748534403e-05,
      "loss": 0.0069,
      "step": 50490
    },
    {
      "epoch": 15.581610614008023,
      "grad_norm": 1.3358434438705444,
      "learning_rate": 3.441838938599198e-05,
      "loss": 0.0035,
      "step": 50500
    },
    {
      "epoch": 15.584696081456341,
      "grad_norm": 0.008660120889544487,
      "learning_rate": 3.441530391854366e-05,
      "loss": 0.0031,
      "step": 50510
    },
    {
      "epoch": 15.587781548904658,
      "grad_norm": 0.057967498898506165,
      "learning_rate": 3.441221845109534e-05,
      "loss": 0.002,
      "step": 50520
    },
    {
      "epoch": 15.590867016352977,
      "grad_norm": 0.07132873684167862,
      "learning_rate": 3.4409132983647025e-05,
      "loss": 0.0008,
      "step": 50530
    },
    {
      "epoch": 15.593952483801296,
      "grad_norm": 0.0011947943130508065,
      "learning_rate": 3.440604751619871e-05,
      "loss": 0.0106,
      "step": 50540
    },
    {
      "epoch": 15.597037951249614,
      "grad_norm": 0.3066139817237854,
      "learning_rate": 3.4402962048750383e-05,
      "loss": 0.0003,
      "step": 50550
    },
    {
      "epoch": 15.600123418697933,
      "grad_norm": 0.00565383629873395,
      "learning_rate": 3.439987658130207e-05,
      "loss": 0.0125,
      "step": 50560
    },
    {
      "epoch": 15.603208886146252,
      "grad_norm": 0.052637163549661636,
      "learning_rate": 3.439679111385375e-05,
      "loss": 0.0004,
      "step": 50570
    },
    {
      "epoch": 15.606294353594569,
      "grad_norm": 0.20512655377388,
      "learning_rate": 3.439370564640543e-05,
      "loss": 0.0012,
      "step": 50580
    },
    {
      "epoch": 15.609379821042888,
      "grad_norm": 0.00023758402676321566,
      "learning_rate": 3.439062017895711e-05,
      "loss": 0.0007,
      "step": 50590
    },
    {
      "epoch": 15.612465288491206,
      "grad_norm": 0.00048771261936053634,
      "learning_rate": 3.4387534711508796e-05,
      "loss": 0.0001,
      "step": 50600
    },
    {
      "epoch": 15.615550755939525,
      "grad_norm": 0.18612317740917206,
      "learning_rate": 3.438444924406048e-05,
      "loss": 0.0053,
      "step": 50610
    },
    {
      "epoch": 15.618636223387844,
      "grad_norm": 0.03240207955241203,
      "learning_rate": 3.438136377661216e-05,
      "loss": 0.0006,
      "step": 50620
    },
    {
      "epoch": 15.621721690836162,
      "grad_norm": 0.011779384687542915,
      "learning_rate": 3.437827830916384e-05,
      "loss": 0.0036,
      "step": 50630
    },
    {
      "epoch": 15.62480715828448,
      "grad_norm": 0.015082928352057934,
      "learning_rate": 3.437519284171552e-05,
      "loss": 0.0047,
      "step": 50640
    },
    {
      "epoch": 15.627892625732798,
      "grad_norm": 0.09415671229362488,
      "learning_rate": 3.43721073742672e-05,
      "loss": 0.0028,
      "step": 50650
    },
    {
      "epoch": 15.630978093181117,
      "grad_norm": 1.8918280601501465,
      "learning_rate": 3.4369021906818884e-05,
      "loss": 0.0092,
      "step": 50660
    },
    {
      "epoch": 15.634063560629436,
      "grad_norm": 0.1963139772415161,
      "learning_rate": 3.4365936439370566e-05,
      "loss": 0.0003,
      "step": 50670
    },
    {
      "epoch": 15.637149028077754,
      "grad_norm": 0.5299078822135925,
      "learning_rate": 3.436285097192225e-05,
      "loss": 0.001,
      "step": 50680
    },
    {
      "epoch": 15.640234495526073,
      "grad_norm": 0.0070536476559937,
      "learning_rate": 3.435976550447393e-05,
      "loss": 0.0003,
      "step": 50690
    },
    {
      "epoch": 15.64331996297439,
      "grad_norm": 0.08051806688308716,
      "learning_rate": 3.4356680037025614e-05,
      "loss": 0.002,
      "step": 50700
    },
    {
      "epoch": 15.646405430422709,
      "grad_norm": 0.03877496346831322,
      "learning_rate": 3.435359456957729e-05,
      "loss": 0.0016,
      "step": 50710
    },
    {
      "epoch": 15.649490897871027,
      "grad_norm": 0.28861120343208313,
      "learning_rate": 3.435050910212897e-05,
      "loss": 0.0011,
      "step": 50720
    },
    {
      "epoch": 15.652576365319346,
      "grad_norm": 0.646586537361145,
      "learning_rate": 3.4347423634680654e-05,
      "loss": 0.0004,
      "step": 50730
    },
    {
      "epoch": 15.655661832767665,
      "grad_norm": 0.0005105813615955412,
      "learning_rate": 3.434433816723234e-05,
      "loss": 0.0006,
      "step": 50740
    },
    {
      "epoch": 15.658747300215982,
      "grad_norm": 0.0026671418454498053,
      "learning_rate": 3.434125269978402e-05,
      "loss": 0.0001,
      "step": 50750
    },
    {
      "epoch": 15.6618327676643,
      "grad_norm": 0.0003159511834383011,
      "learning_rate": 3.43381672323357e-05,
      "loss": 0.0018,
      "step": 50760
    },
    {
      "epoch": 15.66491823511262,
      "grad_norm": 0.001141892746090889,
      "learning_rate": 3.4335081764887384e-05,
      "loss": 0.0,
      "step": 50770
    },
    {
      "epoch": 15.668003702560938,
      "grad_norm": 0.002068788278847933,
      "learning_rate": 3.433199629743906e-05,
      "loss": 0.0012,
      "step": 50780
    },
    {
      "epoch": 15.671089170009257,
      "grad_norm": 0.0004321853048168123,
      "learning_rate": 3.432891082999074e-05,
      "loss": 0.0029,
      "step": 50790
    },
    {
      "epoch": 15.674174637457575,
      "grad_norm": 0.00196980987675488,
      "learning_rate": 3.4325825362542425e-05,
      "loss": 0.0001,
      "step": 50800
    },
    {
      "epoch": 15.677260104905894,
      "grad_norm": 0.0016636601649224758,
      "learning_rate": 3.432273989509411e-05,
      "loss": 0.0005,
      "step": 50810
    },
    {
      "epoch": 15.680345572354211,
      "grad_norm": 0.00018670965800993145,
      "learning_rate": 3.431965442764579e-05,
      "loss": 0.0006,
      "step": 50820
    },
    {
      "epoch": 15.68343103980253,
      "grad_norm": 0.01464249286800623,
      "learning_rate": 3.431656896019747e-05,
      "loss": 0.0037,
      "step": 50830
    },
    {
      "epoch": 15.686516507250849,
      "grad_norm": 0.0026016158517450094,
      "learning_rate": 3.4313483492749155e-05,
      "loss": 0.0001,
      "step": 50840
    },
    {
      "epoch": 15.689601974699167,
      "grad_norm": 0.0015381303383037448,
      "learning_rate": 3.431039802530083e-05,
      "loss": 0.0023,
      "step": 50850
    },
    {
      "epoch": 15.692687442147486,
      "grad_norm": 0.012543696910142899,
      "learning_rate": 3.430731255785252e-05,
      "loss": 0.001,
      "step": 50860
    },
    {
      "epoch": 15.695772909595803,
      "grad_norm": 0.3335762619972229,
      "learning_rate": 3.4304227090404196e-05,
      "loss": 0.0001,
      "step": 50870
    },
    {
      "epoch": 15.698858377044122,
      "grad_norm": 0.014532742090523243,
      "learning_rate": 3.430114162295588e-05,
      "loss": 0.0037,
      "step": 50880
    },
    {
      "epoch": 15.70194384449244,
      "grad_norm": 0.0019647253211587667,
      "learning_rate": 3.429805615550756e-05,
      "loss": 0.0123,
      "step": 50890
    },
    {
      "epoch": 15.70502931194076,
      "grad_norm": 0.11005853116512299,
      "learning_rate": 3.429497068805924e-05,
      "loss": 0.0003,
      "step": 50900
    },
    {
      "epoch": 15.708114779389078,
      "grad_norm": 0.45857882499694824,
      "learning_rate": 3.4291885220610926e-05,
      "loss": 0.0002,
      "step": 50910
    },
    {
      "epoch": 15.711200246837397,
      "grad_norm": 0.003209360409528017,
      "learning_rate": 3.42887997531626e-05,
      "loss": 0.0001,
      "step": 50920
    },
    {
      "epoch": 15.714285714285714,
      "grad_norm": 0.0001578253140905872,
      "learning_rate": 3.428571428571429e-05,
      "loss": 0.0019,
      "step": 50930
    },
    {
      "epoch": 15.717371181734032,
      "grad_norm": 0.047719404101371765,
      "learning_rate": 3.428262881826597e-05,
      "loss": 0.0032,
      "step": 50940
    },
    {
      "epoch": 15.720456649182351,
      "grad_norm": 0.0023243713658303022,
      "learning_rate": 3.427954335081765e-05,
      "loss": 0.0001,
      "step": 50950
    },
    {
      "epoch": 15.72354211663067,
      "grad_norm": 0.0067557888105511665,
      "learning_rate": 3.427645788336933e-05,
      "loss": 0.0055,
      "step": 50960
    },
    {
      "epoch": 15.726627584078988,
      "grad_norm": 4.513742624112638e-06,
      "learning_rate": 3.4273372415921014e-05,
      "loss": 0.004,
      "step": 50970
    },
    {
      "epoch": 15.729713051527307,
      "grad_norm": 1.6686229705810547,
      "learning_rate": 3.4270286948472696e-05,
      "loss": 0.0021,
      "step": 50980
    },
    {
      "epoch": 15.732798518975624,
      "grad_norm": 0.0003776129160542041,
      "learning_rate": 3.426720148102437e-05,
      "loss": 0.001,
      "step": 50990
    },
    {
      "epoch": 15.735883986423943,
      "grad_norm": 0.009912221692502499,
      "learning_rate": 3.426411601357606e-05,
      "loss": 0.0,
      "step": 51000
    },
    {
      "epoch": 15.738969453872262,
      "grad_norm": 1.060266375541687,
      "learning_rate": 3.4261030546127743e-05,
      "loss": 0.0057,
      "step": 51010
    },
    {
      "epoch": 15.74205492132058,
      "grad_norm": 1.1696469300659373e-05,
      "learning_rate": 3.425794507867942e-05,
      "loss": 0.0004,
      "step": 51020
    },
    {
      "epoch": 15.745140388768899,
      "grad_norm": 0.000198668465600349,
      "learning_rate": 3.42548596112311e-05,
      "loss": 0.009,
      "step": 51030
    },
    {
      "epoch": 15.748225856217218,
      "grad_norm": 0.0019435638096183538,
      "learning_rate": 3.4251774143782784e-05,
      "loss": 0.0008,
      "step": 51040
    },
    {
      "epoch": 15.751311323665535,
      "grad_norm": 0.0003001594159286469,
      "learning_rate": 3.424868867633447e-05,
      "loss": 0.0019,
      "step": 51050
    },
    {
      "epoch": 15.754396791113853,
      "grad_norm": 0.0003663468814920634,
      "learning_rate": 3.424560320888614e-05,
      "loss": 0.0006,
      "step": 51060
    },
    {
      "epoch": 15.757482258562172,
      "grad_norm": 5.075895387562923e-05,
      "learning_rate": 3.424251774143783e-05,
      "loss": 0.0006,
      "step": 51070
    },
    {
      "epoch": 15.76056772601049,
      "grad_norm": 0.013460133224725723,
      "learning_rate": 3.4239432273989514e-05,
      "loss": 0.0043,
      "step": 51080
    },
    {
      "epoch": 15.76365319345881,
      "grad_norm": 0.00833148043602705,
      "learning_rate": 3.423634680654119e-05,
      "loss": 0.006,
      "step": 51090
    },
    {
      "epoch": 15.766738660907127,
      "grad_norm": 0.0026747980155050755,
      "learning_rate": 3.423326133909288e-05,
      "loss": 0.0055,
      "step": 51100
    },
    {
      "epoch": 15.769824128355445,
      "grad_norm": 0.0002850911987479776,
      "learning_rate": 3.4230175871644555e-05,
      "loss": 0.0005,
      "step": 51110
    },
    {
      "epoch": 15.772909595803764,
      "grad_norm": 0.00012652612349484116,
      "learning_rate": 3.422709040419624e-05,
      "loss": 0.0001,
      "step": 51120
    },
    {
      "epoch": 15.775995063252083,
      "grad_norm": 7.655773639678955,
      "learning_rate": 3.422400493674792e-05,
      "loss": 0.0188,
      "step": 51130
    },
    {
      "epoch": 15.779080530700401,
      "grad_norm": 0.06638272851705551,
      "learning_rate": 3.42209194692996e-05,
      "loss": 0.0011,
      "step": 51140
    },
    {
      "epoch": 15.78216599814872,
      "grad_norm": 0.003788069589063525,
      "learning_rate": 3.4217834001851285e-05,
      "loss": 0.0019,
      "step": 51150
    },
    {
      "epoch": 15.785251465597039,
      "grad_norm": 0.22507494688034058,
      "learning_rate": 3.421474853440296e-05,
      "loss": 0.0019,
      "step": 51160
    },
    {
      "epoch": 15.788336933045356,
      "grad_norm": 0.980227530002594,
      "learning_rate": 3.421166306695465e-05,
      "loss": 0.0029,
      "step": 51170
    },
    {
      "epoch": 15.791422400493675,
      "grad_norm": 0.0003237900382373482,
      "learning_rate": 3.4208577599506325e-05,
      "loss": 0.0067,
      "step": 51180
    },
    {
      "epoch": 15.794507867941993,
      "grad_norm": 0.0005663764895871282,
      "learning_rate": 3.420549213205801e-05,
      "loss": 0.0106,
      "step": 51190
    },
    {
      "epoch": 15.797593335390312,
      "grad_norm": 0.000143594152177684,
      "learning_rate": 3.420240666460969e-05,
      "loss": 0.001,
      "step": 51200
    },
    {
      "epoch": 15.80067880283863,
      "grad_norm": 9.971165127353743e-05,
      "learning_rate": 3.419932119716137e-05,
      "loss": 0.0018,
      "step": 51210
    },
    {
      "epoch": 15.803764270286948,
      "grad_norm": 5.237139339442365e-05,
      "learning_rate": 3.4196235729713055e-05,
      "loss": 0.0013,
      "step": 51220
    },
    {
      "epoch": 15.806849737735266,
      "grad_norm": 0.0026603154838085175,
      "learning_rate": 3.419315026226473e-05,
      "loss": 0.0026,
      "step": 51230
    },
    {
      "epoch": 15.809935205183585,
      "grad_norm": 0.0015844630543142557,
      "learning_rate": 3.419006479481642e-05,
      "loss": 0.0175,
      "step": 51240
    },
    {
      "epoch": 15.813020672631904,
      "grad_norm": 0.007453818339854479,
      "learning_rate": 3.4186979327368096e-05,
      "loss": 0.0028,
      "step": 51250
    },
    {
      "epoch": 15.816106140080223,
      "grad_norm": 0.00010950902651529759,
      "learning_rate": 3.418389385991978e-05,
      "loss": 0.0079,
      "step": 51260
    },
    {
      "epoch": 15.819191607528541,
      "grad_norm": 0.029834885150194168,
      "learning_rate": 3.418080839247146e-05,
      "loss": 0.0036,
      "step": 51270
    },
    {
      "epoch": 15.822277074976858,
      "grad_norm": 1.9760787836275995e-05,
      "learning_rate": 3.417772292502314e-05,
      "loss": 0.0071,
      "step": 51280
    },
    {
      "epoch": 15.825362542425177,
      "grad_norm": 0.9009636640548706,
      "learning_rate": 3.4174637457574826e-05,
      "loss": 0.004,
      "step": 51290
    },
    {
      "epoch": 15.828448009873496,
      "grad_norm": 0.2842368483543396,
      "learning_rate": 3.41715519901265e-05,
      "loss": 0.0013,
      "step": 51300
    },
    {
      "epoch": 15.831533477321814,
      "grad_norm": 0.0010592411272227764,
      "learning_rate": 3.416846652267819e-05,
      "loss": 0.006,
      "step": 51310
    },
    {
      "epoch": 15.834618944770133,
      "grad_norm": 0.0005961166461929679,
      "learning_rate": 3.4165381055229866e-05,
      "loss": 0.005,
      "step": 51320
    },
    {
      "epoch": 15.837704412218452,
      "grad_norm": 0.0009716509957797825,
      "learning_rate": 3.416229558778155e-05,
      "loss": 0.001,
      "step": 51330
    },
    {
      "epoch": 15.840789879666769,
      "grad_norm": 2.4587363895989256e-06,
      "learning_rate": 3.415921012033324e-05,
      "loss": 0.0002,
      "step": 51340
    },
    {
      "epoch": 15.843875347115087,
      "grad_norm": 0.0010550705483183265,
      "learning_rate": 3.4156124652884914e-05,
      "loss": 0.0017,
      "step": 51350
    },
    {
      "epoch": 15.846960814563406,
      "grad_norm": 0.00012156914453953505,
      "learning_rate": 3.4153039185436596e-05,
      "loss": 0.0004,
      "step": 51360
    },
    {
      "epoch": 15.850046282011725,
      "grad_norm": 1.6882669925689697,
      "learning_rate": 3.414995371798828e-05,
      "loss": 0.0025,
      "step": 51370
    },
    {
      "epoch": 15.853131749460044,
      "grad_norm": 0.005332598928362131,
      "learning_rate": 3.414686825053996e-05,
      "loss": 0.0024,
      "step": 51380
    },
    {
      "epoch": 15.856217216908362,
      "grad_norm": 3.0787353515625,
      "learning_rate": 3.414378278309164e-05,
      "loss": 0.0035,
      "step": 51390
    },
    {
      "epoch": 15.85930268435668,
      "grad_norm": 0.009393631480634212,
      "learning_rate": 3.414069731564332e-05,
      "loss": 0.0001,
      "step": 51400
    },
    {
      "epoch": 15.862388151804998,
      "grad_norm": 0.0015604087384417653,
      "learning_rate": 3.413761184819501e-05,
      "loss": 0.0004,
      "step": 51410
    },
    {
      "epoch": 15.865473619253317,
      "grad_norm": 0.31877759099006653,
      "learning_rate": 3.4134526380746684e-05,
      "loss": 0.0016,
      "step": 51420
    },
    {
      "epoch": 15.868559086701636,
      "grad_norm": 0.0019756632391363382,
      "learning_rate": 3.413144091329837e-05,
      "loss": 0.0025,
      "step": 51430
    },
    {
      "epoch": 15.871644554149954,
      "grad_norm": 0.020922917872667313,
      "learning_rate": 3.412835544585005e-05,
      "loss": 0.0001,
      "step": 51440
    },
    {
      "epoch": 15.874730021598273,
      "grad_norm": 3.360706090927124,
      "learning_rate": 3.412526997840173e-05,
      "loss": 0.0064,
      "step": 51450
    },
    {
      "epoch": 15.87781548904659,
      "grad_norm": 0.2568894028663635,
      "learning_rate": 3.412218451095341e-05,
      "loss": 0.0003,
      "step": 51460
    },
    {
      "epoch": 15.880900956494909,
      "grad_norm": 2.072709798812866,
      "learning_rate": 3.411909904350509e-05,
      "loss": 0.0019,
      "step": 51470
    },
    {
      "epoch": 15.883986423943227,
      "grad_norm": 2.7009496989194304e-05,
      "learning_rate": 3.411601357605678e-05,
      "loss": 0.0001,
      "step": 51480
    },
    {
      "epoch": 15.887071891391546,
      "grad_norm": 1.5465842485427856,
      "learning_rate": 3.4112928108608455e-05,
      "loss": 0.0042,
      "step": 51490
    },
    {
      "epoch": 15.890157358839865,
      "grad_norm": 0.1066332533955574,
      "learning_rate": 3.410984264116014e-05,
      "loss": 0.0018,
      "step": 51500
    },
    {
      "epoch": 15.893242826288184,
      "grad_norm": 0.0003452681703492999,
      "learning_rate": 3.410675717371182e-05,
      "loss": 0.0005,
      "step": 51510
    },
    {
      "epoch": 15.8963282937365,
      "grad_norm": 4.125154495239258,
      "learning_rate": 3.41036717062635e-05,
      "loss": 0.0148,
      "step": 51520
    },
    {
      "epoch": 15.89941376118482,
      "grad_norm": 0.027058269828557968,
      "learning_rate": 3.410058623881518e-05,
      "loss": 0.0005,
      "step": 51530
    },
    {
      "epoch": 15.902499228633138,
      "grad_norm": 0.0016306544421240687,
      "learning_rate": 3.409750077136686e-05,
      "loss": 0.0003,
      "step": 51540
    },
    {
      "epoch": 15.905584696081457,
      "grad_norm": 0.143769308924675,
      "learning_rate": 3.409441530391855e-05,
      "loss": 0.0006,
      "step": 51550
    },
    {
      "epoch": 15.908670163529775,
      "grad_norm": 0.18849347531795502,
      "learning_rate": 3.4091329836470226e-05,
      "loss": 0.0023,
      "step": 51560
    },
    {
      "epoch": 15.911755630978092,
      "grad_norm": 0.04871658608317375,
      "learning_rate": 3.408824436902191e-05,
      "loss": 0.0004,
      "step": 51570
    },
    {
      "epoch": 15.914841098426411,
      "grad_norm": 0.06566779315471649,
      "learning_rate": 3.408515890157359e-05,
      "loss": 0.0006,
      "step": 51580
    },
    {
      "epoch": 15.91792656587473,
      "grad_norm": 0.0009375017834827304,
      "learning_rate": 3.408207343412527e-05,
      "loss": 0.0031,
      "step": 51590
    },
    {
      "epoch": 15.921012033323048,
      "grad_norm": 0.0016306990291923285,
      "learning_rate": 3.407898796667695e-05,
      "loss": 0.0089,
      "step": 51600
    },
    {
      "epoch": 15.924097500771367,
      "grad_norm": 2.4888724510674365e-05,
      "learning_rate": 3.407590249922864e-05,
      "loss": 0.0001,
      "step": 51610
    },
    {
      "epoch": 15.927182968219686,
      "grad_norm": 0.0008060873369686306,
      "learning_rate": 3.407281703178032e-05,
      "loss": 0.0005,
      "step": 51620
    },
    {
      "epoch": 15.930268435668003,
      "grad_norm": 0.0006321659311652184,
      "learning_rate": 3.4069731564331996e-05,
      "loss": 0.0006,
      "step": 51630
    },
    {
      "epoch": 15.933353903116322,
      "grad_norm": 0.6572558879852295,
      "learning_rate": 3.406664609688368e-05,
      "loss": 0.0005,
      "step": 51640
    },
    {
      "epoch": 15.93643937056464,
      "grad_norm": 0.03176950290799141,
      "learning_rate": 3.406356062943536e-05,
      "loss": 0.0,
      "step": 51650
    },
    {
      "epoch": 15.939524838012959,
      "grad_norm": 0.09092312306165695,
      "learning_rate": 3.4060475161987044e-05,
      "loss": 0.0002,
      "step": 51660
    },
    {
      "epoch": 15.942610305461278,
      "grad_norm": 0.007855517789721489,
      "learning_rate": 3.405738969453872e-05,
      "loss": 0.0001,
      "step": 51670
    },
    {
      "epoch": 15.945695772909596,
      "grad_norm": 0.0004295371181797236,
      "learning_rate": 3.405430422709041e-05,
      "loss": 0.0003,
      "step": 51680
    },
    {
      "epoch": 15.948781240357913,
      "grad_norm": 0.0001479995989939198,
      "learning_rate": 3.405121875964209e-05,
      "loss": 0.0001,
      "step": 51690
    },
    {
      "epoch": 15.951866707806232,
      "grad_norm": 3.304136043880135e-05,
      "learning_rate": 3.404813329219377e-05,
      "loss": 0.0001,
      "step": 51700
    },
    {
      "epoch": 15.954952175254551,
      "grad_norm": 0.00012824489385820925,
      "learning_rate": 3.404504782474545e-05,
      "loss": 0.0001,
      "step": 51710
    },
    {
      "epoch": 15.95803764270287,
      "grad_norm": 0.005019245203584433,
      "learning_rate": 3.404196235729713e-05,
      "loss": 0.001,
      "step": 51720
    },
    {
      "epoch": 15.961123110151188,
      "grad_norm": 1.009238600730896,
      "learning_rate": 3.4038876889848814e-05,
      "loss": 0.0007,
      "step": 51730
    },
    {
      "epoch": 15.964208577599507,
      "grad_norm": 0.010734857991337776,
      "learning_rate": 3.403579142240049e-05,
      "loss": 0.0003,
      "step": 51740
    },
    {
      "epoch": 15.967294045047824,
      "grad_norm": 0.0005903964047320187,
      "learning_rate": 3.403270595495218e-05,
      "loss": 0.0009,
      "step": 51750
    },
    {
      "epoch": 15.970379512496143,
      "grad_norm": 0.007246050052344799,
      "learning_rate": 3.402962048750386e-05,
      "loss": 0.0026,
      "step": 51760
    },
    {
      "epoch": 15.973464979944461,
      "grad_norm": 0.0004553654871415347,
      "learning_rate": 3.402653502005554e-05,
      "loss": 0.0009,
      "step": 51770
    },
    {
      "epoch": 15.97655044739278,
      "grad_norm": 0.00021345695131458342,
      "learning_rate": 3.402344955260722e-05,
      "loss": 0.0009,
      "step": 51780
    },
    {
      "epoch": 15.979635914841099,
      "grad_norm": 0.001792572787962854,
      "learning_rate": 3.40203640851589e-05,
      "loss": 0.0001,
      "step": 51790
    },
    {
      "epoch": 15.982721382289418,
      "grad_norm": 0.19355744123458862,
      "learning_rate": 3.4017278617710585e-05,
      "loss": 0.001,
      "step": 51800
    },
    {
      "epoch": 15.985806849737735,
      "grad_norm": 0.0003373640065547079,
      "learning_rate": 3.401419315026227e-05,
      "loss": 0.0002,
      "step": 51810
    },
    {
      "epoch": 15.988892317186053,
      "grad_norm": 0.004998167511075735,
      "learning_rate": 3.401110768281395e-05,
      "loss": 0.0092,
      "step": 51820
    },
    {
      "epoch": 15.991977784634372,
      "grad_norm": 1.4160865545272827,
      "learning_rate": 3.400802221536563e-05,
      "loss": 0.005,
      "step": 51830
    },
    {
      "epoch": 15.99506325208269,
      "grad_norm": 0.0037974799051880836,
      "learning_rate": 3.400493674791731e-05,
      "loss": 0.0002,
      "step": 51840
    },
    {
      "epoch": 15.99814871953101,
      "grad_norm": 0.2575035095214844,
      "learning_rate": 3.4001851280469e-05,
      "loss": 0.0027,
      "step": 51850
    },
    {
      "epoch": 16.0,
      "eval_accuracy_branch1": 0.9990162321692081,
      "eval_accuracy_branch2": 0.3964777253744587,
      "eval_f1_branch1": 0.998748177672828,
      "eval_f1_branch2": 0.38670837338100184,
      "eval_loss": 0.00028628340805880725,
      "eval_precision_branch1": 0.9987171788413538,
      "eval_precision_branch2": 0.4910240921577273,
      "eval_recall_branch1": 0.9987817010809217,
      "eval_recall_branch2": 0.49336680072914557,
      "eval_runtime": 238.5573,
      "eval_samples_per_second": 434.625,
      "eval_steps_per_second": 54.331,
      "step": 51856
    },
    {
      "epoch": 16.001234186979328,
      "grad_norm": 0.0003160525520797819,
      "learning_rate": 3.399876581302067e-05,
      "loss": 0.0017,
      "step": 51860
    },
    {
      "epoch": 16.004319654427647,
      "grad_norm": 0.7377088069915771,
      "learning_rate": 3.3995680345572355e-05,
      "loss": 0.0003,
      "step": 51870
    },
    {
      "epoch": 16.007405121875966,
      "grad_norm": 0.0003109471872448921,
      "learning_rate": 3.399259487812404e-05,
      "loss": 0.0005,
      "step": 51880
    },
    {
      "epoch": 16.010490589324284,
      "grad_norm": 1.5545520782470703,
      "learning_rate": 3.398950941067572e-05,
      "loss": 0.0017,
      "step": 51890
    },
    {
      "epoch": 16.0135760567726,
      "grad_norm": 0.001330011524260044,
      "learning_rate": 3.39864239432274e-05,
      "loss": 0.0,
      "step": 51900
    },
    {
      "epoch": 16.01666152422092,
      "grad_norm": 0.0055104088969528675,
      "learning_rate": 3.398333847577908e-05,
      "loss": 0.005,
      "step": 51910
    },
    {
      "epoch": 16.019746991669237,
      "grad_norm": 0.004196960479021072,
      "learning_rate": 3.398025300833077e-05,
      "loss": 0.0009,
      "step": 51920
    },
    {
      "epoch": 16.022832459117556,
      "grad_norm": 0.0002201988099841401,
      "learning_rate": 3.397716754088244e-05,
      "loss": 0.0012,
      "step": 51930
    },
    {
      "epoch": 16.025917926565874,
      "grad_norm": 9.018710989039391e-05,
      "learning_rate": 3.3974082073434126e-05,
      "loss": 0.0029,
      "step": 51940
    },
    {
      "epoch": 16.029003394014193,
      "grad_norm": 0.1312808394432068,
      "learning_rate": 3.397099660598581e-05,
      "loss": 0.0003,
      "step": 51950
    },
    {
      "epoch": 16.032088861462512,
      "grad_norm": 6.900203152326867e-05,
      "learning_rate": 3.396791113853749e-05,
      "loss": 0.0,
      "step": 51960
    },
    {
      "epoch": 16.03517432891083,
      "grad_norm": 0.1454455554485321,
      "learning_rate": 3.396482567108917e-05,
      "loss": 0.0154,
      "step": 51970
    },
    {
      "epoch": 16.03825979635915,
      "grad_norm": 1.7238621711730957,
      "learning_rate": 3.396174020364085e-05,
      "loss": 0.0022,
      "step": 51980
    },
    {
      "epoch": 16.041345263807468,
      "grad_norm": 0.0009805505396798253,
      "learning_rate": 3.395865473619254e-05,
      "loss": 0.0008,
      "step": 51990
    },
    {
      "epoch": 16.044430731255787,
      "grad_norm": 0.12076584994792938,
      "learning_rate": 3.3955569268744214e-05,
      "loss": 0.0001,
      "step": 52000
    },
    {
      "epoch": 16.047516198704102,
      "grad_norm": 0.3167468011379242,
      "learning_rate": 3.3952483801295896e-05,
      "loss": 0.0008,
      "step": 52010
    },
    {
      "epoch": 16.05060166615242,
      "grad_norm": 0.02005075104534626,
      "learning_rate": 3.394939833384758e-05,
      "loss": 0.0034,
      "step": 52020
    },
    {
      "epoch": 16.05368713360074,
      "grad_norm": 0.054503459483385086,
      "learning_rate": 3.394631286639926e-05,
      "loss": 0.0064,
      "step": 52030
    },
    {
      "epoch": 16.056772601049058,
      "grad_norm": 1.2064157724380493,
      "learning_rate": 3.3943227398950944e-05,
      "loss": 0.0085,
      "step": 52040
    },
    {
      "epoch": 16.059858068497377,
      "grad_norm": 0.04033505544066429,
      "learning_rate": 3.394014193150262e-05,
      "loss": 0.0006,
      "step": 52050
    },
    {
      "epoch": 16.062943535945696,
      "grad_norm": 0.03153521940112114,
      "learning_rate": 3.393705646405431e-05,
      "loss": 0.0006,
      "step": 52060
    },
    {
      "epoch": 16.066029003394014,
      "grad_norm": 0.0007127321441657841,
      "learning_rate": 3.3933970996605984e-05,
      "loss": 0.0,
      "step": 52070
    },
    {
      "epoch": 16.069114470842333,
      "grad_norm": 0.0007205803995020688,
      "learning_rate": 3.393088552915767e-05,
      "loss": 0.0004,
      "step": 52080
    },
    {
      "epoch": 16.07219993829065,
      "grad_norm": 0.02872382663190365,
      "learning_rate": 3.3927800061709356e-05,
      "loss": 0.0001,
      "step": 52090
    },
    {
      "epoch": 16.07528540573897,
      "grad_norm": 0.000264129601418972,
      "learning_rate": 3.392471459426103e-05,
      "loss": 0.0,
      "step": 52100
    },
    {
      "epoch": 16.07837087318729,
      "grad_norm": 0.0001444967492716387,
      "learning_rate": 3.3921629126812714e-05,
      "loss": 0.0028,
      "step": 52110
    },
    {
      "epoch": 16.081456340635608,
      "grad_norm": 7.924198143882677e-05,
      "learning_rate": 3.39185436593644e-05,
      "loss": 0.0001,
      "step": 52120
    },
    {
      "epoch": 16.084541808083923,
      "grad_norm": 0.00021134749113116413,
      "learning_rate": 3.391545819191608e-05,
      "loss": 0.0009,
      "step": 52130
    },
    {
      "epoch": 16.087627275532242,
      "grad_norm": 0.001227506436407566,
      "learning_rate": 3.3912372724467755e-05,
      "loss": 0.0009,
      "step": 52140
    },
    {
      "epoch": 16.09071274298056,
      "grad_norm": 0.0015688592102378607,
      "learning_rate": 3.390928725701944e-05,
      "loss": 0.0001,
      "step": 52150
    },
    {
      "epoch": 16.09379821042888,
      "grad_norm": 1.9550718069076538,
      "learning_rate": 3.390620178957113e-05,
      "loss": 0.0077,
      "step": 52160
    },
    {
      "epoch": 16.096883677877198,
      "grad_norm": 0.00015689963765908033,
      "learning_rate": 3.39031163221228e-05,
      "loss": 0.0001,
      "step": 52170
    },
    {
      "epoch": 16.099969145325517,
      "grad_norm": 3.624667078838684e-05,
      "learning_rate": 3.3900030854674485e-05,
      "loss": 0.0008,
      "step": 52180
    },
    {
      "epoch": 16.103054612773835,
      "grad_norm": 0.00036514364182949066,
      "learning_rate": 3.389694538722617e-05,
      "loss": 0.0038,
      "step": 52190
    },
    {
      "epoch": 16.106140080222154,
      "grad_norm": 2.9010383514105342e-05,
      "learning_rate": 3.389385991977785e-05,
      "loss": 0.0077,
      "step": 52200
    },
    {
      "epoch": 16.109225547670473,
      "grad_norm": 0.0018103274051100016,
      "learning_rate": 3.389077445232953e-05,
      "loss": 0.0001,
      "step": 52210
    },
    {
      "epoch": 16.11231101511879,
      "grad_norm": 0.015161693096160889,
      "learning_rate": 3.388768898488121e-05,
      "loss": 0.0001,
      "step": 52220
    },
    {
      "epoch": 16.11539648256711,
      "grad_norm": 0.00031062561902217567,
      "learning_rate": 3.38846035174329e-05,
      "loss": 0.0062,
      "step": 52230
    },
    {
      "epoch": 16.11848195001543,
      "grad_norm": 0.09112787991762161,
      "learning_rate": 3.388151804998457e-05,
      "loss": 0.0007,
      "step": 52240
    },
    {
      "epoch": 16.121567417463744,
      "grad_norm": 0.0011802829103544354,
      "learning_rate": 3.3878432582536255e-05,
      "loss": 0.0018,
      "step": 52250
    },
    {
      "epoch": 16.124652884912063,
      "grad_norm": 0.002375467214733362,
      "learning_rate": 3.387534711508794e-05,
      "loss": 0.0019,
      "step": 52260
    },
    {
      "epoch": 16.12773835236038,
      "grad_norm": 8.830650040181354e-05,
      "learning_rate": 3.387226164763962e-05,
      "loss": 0.0045,
      "step": 52270
    },
    {
      "epoch": 16.1308238198087,
      "grad_norm": 0.00012088923540432006,
      "learning_rate": 3.38691761801913e-05,
      "loss": 0.0035,
      "step": 52280
    },
    {
      "epoch": 16.13390928725702,
      "grad_norm": 0.000182070565642789,
      "learning_rate": 3.386609071274298e-05,
      "loss": 0.0016,
      "step": 52290
    },
    {
      "epoch": 16.136994754705338,
      "grad_norm": 1.1709338426589966,
      "learning_rate": 3.386300524529467e-05,
      "loss": 0.0028,
      "step": 52300
    },
    {
      "epoch": 16.140080222153657,
      "grad_norm": 1.2148946552770212e-05,
      "learning_rate": 3.3859919777846344e-05,
      "loss": 0.0017,
      "step": 52310
    },
    {
      "epoch": 16.143165689601975,
      "grad_norm": 0.0015171765116974711,
      "learning_rate": 3.3856834310398026e-05,
      "loss": 0.0003,
      "step": 52320
    },
    {
      "epoch": 16.146251157050294,
      "grad_norm": 0.00016818798030726612,
      "learning_rate": 3.385374884294971e-05,
      "loss": 0.0025,
      "step": 52330
    },
    {
      "epoch": 16.149336624498613,
      "grad_norm": 0.025311755016446114,
      "learning_rate": 3.385066337550139e-05,
      "loss": 0.0001,
      "step": 52340
    },
    {
      "epoch": 16.15242209194693,
      "grad_norm": 1.05083429813385,
      "learning_rate": 3.3847577908053073e-05,
      "loss": 0.0015,
      "step": 52350
    },
    {
      "epoch": 16.155507559395247,
      "grad_norm": 0.0009481742745265365,
      "learning_rate": 3.3844492440604756e-05,
      "loss": 0.0017,
      "step": 52360
    },
    {
      "epoch": 16.158593026843565,
      "grad_norm": 0.00021322656539268792,
      "learning_rate": 3.384140697315644e-05,
      "loss": 0.0002,
      "step": 52370
    },
    {
      "epoch": 16.161678494291884,
      "grad_norm": 1.2394366264343262,
      "learning_rate": 3.3838321505708114e-05,
      "loss": 0.0047,
      "step": 52380
    },
    {
      "epoch": 16.164763961740203,
      "grad_norm": 0.0015367403393611312,
      "learning_rate": 3.3835236038259797e-05,
      "loss": 0.0067,
      "step": 52390
    },
    {
      "epoch": 16.16784942918852,
      "grad_norm": 1.6498228311538696,
      "learning_rate": 3.383215057081148e-05,
      "loss": 0.0011,
      "step": 52400
    },
    {
      "epoch": 16.17093489663684,
      "grad_norm": 3.9614086151123047,
      "learning_rate": 3.382906510336316e-05,
      "loss": 0.004,
      "step": 52410
    },
    {
      "epoch": 16.17402036408516,
      "grad_norm": 0.003687045071274042,
      "learning_rate": 3.3825979635914844e-05,
      "loss": 0.0002,
      "step": 52420
    },
    {
      "epoch": 16.177105831533478,
      "grad_norm": 0.027983693405985832,
      "learning_rate": 3.3822894168466526e-05,
      "loss": 0.0006,
      "step": 52430
    },
    {
      "epoch": 16.180191298981796,
      "grad_norm": 0.03234488517045975,
      "learning_rate": 3.381980870101821e-05,
      "loss": 0.0013,
      "step": 52440
    },
    {
      "epoch": 16.183276766430115,
      "grad_norm": 0.001401350717060268,
      "learning_rate": 3.3816723233569885e-05,
      "loss": 0.0001,
      "step": 52450
    },
    {
      "epoch": 16.186362233878434,
      "grad_norm": 0.2039169818162918,
      "learning_rate": 3.381363776612157e-05,
      "loss": 0.0014,
      "step": 52460
    },
    {
      "epoch": 16.189447701326753,
      "grad_norm": 0.017952386289834976,
      "learning_rate": 3.381055229867325e-05,
      "loss": 0.0025,
      "step": 52470
    },
    {
      "epoch": 16.192533168775068,
      "grad_norm": 1.0881236791610718,
      "learning_rate": 3.380746683122493e-05,
      "loss": 0.002,
      "step": 52480
    },
    {
      "epoch": 16.195618636223386,
      "grad_norm": 3.3405674912501127e-05,
      "learning_rate": 3.3804381363776615e-05,
      "loss": 0.0003,
      "step": 52490
    },
    {
      "epoch": 16.198704103671705,
      "grad_norm": 2.0430026054382324,
      "learning_rate": 3.38012958963283e-05,
      "loss": 0.0019,
      "step": 52500
    },
    {
      "epoch": 16.201789571120024,
      "grad_norm": 0.030130211263895035,
      "learning_rate": 3.379821042887998e-05,
      "loss": 0.0035,
      "step": 52510
    },
    {
      "epoch": 16.204875038568343,
      "grad_norm": 0.0015379831893369555,
      "learning_rate": 3.3795124961431655e-05,
      "loss": 0.0008,
      "step": 52520
    },
    {
      "epoch": 16.20796050601666,
      "grad_norm": 1.2051655176037457e-05,
      "learning_rate": 3.379203949398334e-05,
      "loss": 0.0025,
      "step": 52530
    },
    {
      "epoch": 16.21104597346498,
      "grad_norm": 0.00030129856895655394,
      "learning_rate": 3.378895402653502e-05,
      "loss": 0.0004,
      "step": 52540
    },
    {
      "epoch": 16.2141314409133,
      "grad_norm": 0.0035535823553800583,
      "learning_rate": 3.37858685590867e-05,
      "loss": 0.0009,
      "step": 52550
    },
    {
      "epoch": 16.217216908361618,
      "grad_norm": 0.0004624032007995993,
      "learning_rate": 3.3782783091638385e-05,
      "loss": 0.0001,
      "step": 52560
    },
    {
      "epoch": 16.220302375809936,
      "grad_norm": 5.02287093695486e-06,
      "learning_rate": 3.377969762419007e-05,
      "loss": 0.0113,
      "step": 52570
    },
    {
      "epoch": 16.223387843258255,
      "grad_norm": 7.633892528247088e-05,
      "learning_rate": 3.377661215674175e-05,
      "loss": 0.0002,
      "step": 52580
    },
    {
      "epoch": 16.226473310706574,
      "grad_norm": 0.001425069640390575,
      "learning_rate": 3.3773526689293426e-05,
      "loss": 0.0004,
      "step": 52590
    },
    {
      "epoch": 16.22955877815489,
      "grad_norm": 0.0002138299314538017,
      "learning_rate": 3.377044122184511e-05,
      "loss": 0.0007,
      "step": 52600
    },
    {
      "epoch": 16.232644245603208,
      "grad_norm": 0.0010721422731876373,
      "learning_rate": 3.376735575439679e-05,
      "loss": 0.0,
      "step": 52610
    },
    {
      "epoch": 16.235729713051526,
      "grad_norm": 0.006158761214464903,
      "learning_rate": 3.376427028694847e-05,
      "loss": 0.0001,
      "step": 52620
    },
    {
      "epoch": 16.238815180499845,
      "grad_norm": 0.00041060184594243765,
      "learning_rate": 3.3761184819500156e-05,
      "loss": 0.0001,
      "step": 52630
    },
    {
      "epoch": 16.241900647948164,
      "grad_norm": 9.440427675144747e-05,
      "learning_rate": 3.375809935205184e-05,
      "loss": 0.0051,
      "step": 52640
    },
    {
      "epoch": 16.244986115396483,
      "grad_norm": 1.5986011028289795,
      "learning_rate": 3.375501388460352e-05,
      "loss": 0.0019,
      "step": 52650
    },
    {
      "epoch": 16.2480715828448,
      "grad_norm": 0.0001431939599569887,
      "learning_rate": 3.3751928417155196e-05,
      "loss": 0.0051,
      "step": 52660
    },
    {
      "epoch": 16.25115705029312,
      "grad_norm": 2.7877329557668418e-05,
      "learning_rate": 3.3748842949706886e-05,
      "loss": 0.0033,
      "step": 52670
    },
    {
      "epoch": 16.25424251774144,
      "grad_norm": 0.007814576849341393,
      "learning_rate": 3.374575748225857e-05,
      "loss": 0.0005,
      "step": 52680
    },
    {
      "epoch": 16.257327985189757,
      "grad_norm": 0.532203197479248,
      "learning_rate": 3.3742672014810244e-05,
      "loss": 0.0005,
      "step": 52690
    },
    {
      "epoch": 16.260413452638076,
      "grad_norm": 0.00012097493163309991,
      "learning_rate": 3.3739586547361926e-05,
      "loss": 0.0005,
      "step": 52700
    },
    {
      "epoch": 16.26349892008639,
      "grad_norm": 0.6317716240882874,
      "learning_rate": 3.373650107991361e-05,
      "loss": 0.0041,
      "step": 52710
    },
    {
      "epoch": 16.26658438753471,
      "grad_norm": 0.350616991519928,
      "learning_rate": 3.373341561246529e-05,
      "loss": 0.0019,
      "step": 52720
    },
    {
      "epoch": 16.26966985498303,
      "grad_norm": 0.0005873452755622566,
      "learning_rate": 3.373033014501697e-05,
      "loss": 0.0072,
      "step": 52730
    },
    {
      "epoch": 16.272755322431347,
      "grad_norm": 0.0034919888712465763,
      "learning_rate": 3.3727244677568656e-05,
      "loss": 0.0031,
      "step": 52740
    },
    {
      "epoch": 16.275840789879666,
      "grad_norm": 0.0004857124004047364,
      "learning_rate": 3.372415921012034e-05,
      "loss": 0.0008,
      "step": 52750
    },
    {
      "epoch": 16.278926257327985,
      "grad_norm": 0.41179144382476807,
      "learning_rate": 3.3721073742672014e-05,
      "loss": 0.0091,
      "step": 52760
    },
    {
      "epoch": 16.282011724776304,
      "grad_norm": 0.04140131548047066,
      "learning_rate": 3.37179882752237e-05,
      "loss": 0.0007,
      "step": 52770
    },
    {
      "epoch": 16.285097192224622,
      "grad_norm": 0.00021392674534581602,
      "learning_rate": 3.371490280777538e-05,
      "loss": 0.001,
      "step": 52780
    },
    {
      "epoch": 16.28818265967294,
      "grad_norm": 0.034066092222929,
      "learning_rate": 3.371181734032706e-05,
      "loss": 0.0002,
      "step": 52790
    },
    {
      "epoch": 16.29126812712126,
      "grad_norm": 0.001824134960770607,
      "learning_rate": 3.370873187287874e-05,
      "loss": 0.0001,
      "step": 52800
    },
    {
      "epoch": 16.29435359456958,
      "grad_norm": 0.0018200502963736653,
      "learning_rate": 3.370564640543043e-05,
      "loss": 0.0015,
      "step": 52810
    },
    {
      "epoch": 16.297439062017897,
      "grad_norm": 4.921479194308631e-05,
      "learning_rate": 3.370256093798211e-05,
      "loss": 0.0064,
      "step": 52820
    },
    {
      "epoch": 16.300524529466212,
      "grad_norm": 0.003583485260605812,
      "learning_rate": 3.3699475470533785e-05,
      "loss": 0.0,
      "step": 52830
    },
    {
      "epoch": 16.30360999691453,
      "grad_norm": 0.2584468722343445,
      "learning_rate": 3.369639000308547e-05,
      "loss": 0.0034,
      "step": 52840
    },
    {
      "epoch": 16.30669546436285,
      "grad_norm": 0.15157856047153473,
      "learning_rate": 3.369330453563715e-05,
      "loss": 0.0003,
      "step": 52850
    },
    {
      "epoch": 16.30978093181117,
      "grad_norm": 0.01981498673558235,
      "learning_rate": 3.369021906818883e-05,
      "loss": 0.0004,
      "step": 52860
    },
    {
      "epoch": 16.312866399259487,
      "grad_norm": 0.005034006200730801,
      "learning_rate": 3.368713360074051e-05,
      "loss": 0.0,
      "step": 52870
    },
    {
      "epoch": 16.315951866707806,
      "grad_norm": 0.0019790639635175467,
      "learning_rate": 3.36840481332922e-05,
      "loss": 0.0004,
      "step": 52880
    },
    {
      "epoch": 16.319037334156125,
      "grad_norm": 0.0029183176811784506,
      "learning_rate": 3.368096266584388e-05,
      "loss": 0.0002,
      "step": 52890
    },
    {
      "epoch": 16.322122801604444,
      "grad_norm": 0.012829581275582314,
      "learning_rate": 3.3677877198395555e-05,
      "loss": 0.003,
      "step": 52900
    },
    {
      "epoch": 16.325208269052762,
      "grad_norm": 5.0189151806989685e-05,
      "learning_rate": 3.3674791730947245e-05,
      "loss": 0.0005,
      "step": 52910
    },
    {
      "epoch": 16.32829373650108,
      "grad_norm": 0.0066385045647621155,
      "learning_rate": 3.367170626349892e-05,
      "loss": 0.0006,
      "step": 52920
    },
    {
      "epoch": 16.3313792039494,
      "grad_norm": 0.00012938100553583354,
      "learning_rate": 3.36686207960506e-05,
      "loss": 0.0002,
      "step": 52930
    },
    {
      "epoch": 16.33446467139772,
      "grad_norm": 2.2161195278167725,
      "learning_rate": 3.3665535328602285e-05,
      "loss": 0.0125,
      "step": 52940
    },
    {
      "epoch": 16.337550138846034,
      "grad_norm": 0.008498992770910263,
      "learning_rate": 3.366244986115397e-05,
      "loss": 0.0003,
      "step": 52950
    },
    {
      "epoch": 16.340635606294352,
      "grad_norm": 0.00435488810762763,
      "learning_rate": 3.365936439370565e-05,
      "loss": 0.003,
      "step": 52960
    },
    {
      "epoch": 16.34372107374267,
      "grad_norm": 0.4286479651927948,
      "learning_rate": 3.3656278926257326e-05,
      "loss": 0.0003,
      "step": 52970
    },
    {
      "epoch": 16.34680654119099,
      "grad_norm": 1.3550947904586792,
      "learning_rate": 3.3653193458809015e-05,
      "loss": 0.0008,
      "step": 52980
    },
    {
      "epoch": 16.34989200863931,
      "grad_norm": 0.0001621039118617773,
      "learning_rate": 3.365010799136069e-05,
      "loss": 0.0003,
      "step": 52990
    },
    {
      "epoch": 16.352977476087627,
      "grad_norm": 0.029941704124212265,
      "learning_rate": 3.3647022523912373e-05,
      "loss": 0.0036,
      "step": 53000
    },
    {
      "epoch": 16.356062943535946,
      "grad_norm": 5.138346386956982e-05,
      "learning_rate": 3.3643937056464056e-05,
      "loss": 0.0001,
      "step": 53010
    },
    {
      "epoch": 16.359148410984265,
      "grad_norm": 0.021991971880197525,
      "learning_rate": 3.364085158901574e-05,
      "loss": 0.001,
      "step": 53020
    },
    {
      "epoch": 16.362233878432583,
      "grad_norm": 0.0003414099046494812,
      "learning_rate": 3.363776612156742e-05,
      "loss": 0.0024,
      "step": 53030
    },
    {
      "epoch": 16.365319345880902,
      "grad_norm": 0.00015262558008544147,
      "learning_rate": 3.3634680654119097e-05,
      "loss": 0.0007,
      "step": 53040
    },
    {
      "epoch": 16.36840481332922,
      "grad_norm": 0.00010557969653746113,
      "learning_rate": 3.3631595186670786e-05,
      "loss": 0.0009,
      "step": 53050
    },
    {
      "epoch": 16.37149028077754,
      "grad_norm": 0.001304501318372786,
      "learning_rate": 3.362850971922246e-05,
      "loss": 0.0017,
      "step": 53060
    },
    {
      "epoch": 16.374575748225855,
      "grad_norm": 0.00048657049774192274,
      "learning_rate": 3.3625424251774144e-05,
      "loss": 0.0021,
      "step": 53070
    },
    {
      "epoch": 16.377661215674173,
      "grad_norm": 0.04107666015625,
      "learning_rate": 3.3622338784325826e-05,
      "loss": 0.0001,
      "step": 53080
    },
    {
      "epoch": 16.380746683122492,
      "grad_norm": 0.008223370648920536,
      "learning_rate": 3.361925331687751e-05,
      "loss": 0.0023,
      "step": 53090
    },
    {
      "epoch": 16.38383215057081,
      "grad_norm": 0.0001808023953344673,
      "learning_rate": 3.361616784942919e-05,
      "loss": 0.0006,
      "step": 53100
    },
    {
      "epoch": 16.38691761801913,
      "grad_norm": 1.5965938568115234,
      "learning_rate": 3.361308238198087e-05,
      "loss": 0.0015,
      "step": 53110
    },
    {
      "epoch": 16.39000308546745,
      "grad_norm": 0.008195940405130386,
      "learning_rate": 3.3609996914532556e-05,
      "loss": 0.0065,
      "step": 53120
    },
    {
      "epoch": 16.393088552915767,
      "grad_norm": 0.0005050252075307071,
      "learning_rate": 3.360691144708423e-05,
      "loss": 0.0036,
      "step": 53130
    },
    {
      "epoch": 16.396174020364086,
      "grad_norm": 0.004265229683369398,
      "learning_rate": 3.3603825979635915e-05,
      "loss": 0.0002,
      "step": 53140
    },
    {
      "epoch": 16.399259487812405,
      "grad_norm": 0.006328147370368242,
      "learning_rate": 3.3600740512187604e-05,
      "loss": 0.0002,
      "step": 53150
    },
    {
      "epoch": 16.402344955260723,
      "grad_norm": 0.13770416378974915,
      "learning_rate": 3.359765504473928e-05,
      "loss": 0.0001,
      "step": 53160
    },
    {
      "epoch": 16.405430422709042,
      "grad_norm": 0.007339139003306627,
      "learning_rate": 3.359456957729096e-05,
      "loss": 0.0001,
      "step": 53170
    },
    {
      "epoch": 16.408515890157357,
      "grad_norm": 3.286117862444371e-05,
      "learning_rate": 3.3591484109842644e-05,
      "loss": 0.0001,
      "step": 53180
    },
    {
      "epoch": 16.411601357605676,
      "grad_norm": 8.608771167928353e-05,
      "learning_rate": 3.358839864239433e-05,
      "loss": 0.0001,
      "step": 53190
    },
    {
      "epoch": 16.414686825053995,
      "grad_norm": 1.0174198150634766,
      "learning_rate": 3.3585313174946e-05,
      "loss": 0.0006,
      "step": 53200
    },
    {
      "epoch": 16.417772292502313,
      "grad_norm": 0.872035801410675,
      "learning_rate": 3.3582227707497685e-05,
      "loss": 0.001,
      "step": 53210
    },
    {
      "epoch": 16.420857759950632,
      "grad_norm": 0.0023425156250596046,
      "learning_rate": 3.3579142240049374e-05,
      "loss": 0.0006,
      "step": 53220
    },
    {
      "epoch": 16.42394322739895,
      "grad_norm": 3.176912784576416,
      "learning_rate": 3.357605677260105e-05,
      "loss": 0.0032,
      "step": 53230
    },
    {
      "epoch": 16.42702869484727,
      "grad_norm": 0.0010550027946010232,
      "learning_rate": 3.357297130515273e-05,
      "loss": 0.0,
      "step": 53240
    },
    {
      "epoch": 16.430114162295588,
      "grad_norm": 1.2396639585494995,
      "learning_rate": 3.3569885837704415e-05,
      "loss": 0.0021,
      "step": 53250
    },
    {
      "epoch": 16.433199629743907,
      "grad_norm": 0.001535850460641086,
      "learning_rate": 3.35668003702561e-05,
      "loss": 0.0,
      "step": 53260
    },
    {
      "epoch": 16.436285097192226,
      "grad_norm": 0.012274292297661304,
      "learning_rate": 3.356371490280777e-05,
      "loss": 0.0034,
      "step": 53270
    },
    {
      "epoch": 16.439370564640544,
      "grad_norm": 0.0012008780613541603,
      "learning_rate": 3.3560629435359456e-05,
      "loss": 0.0001,
      "step": 53280
    },
    {
      "epoch": 16.442456032088863,
      "grad_norm": 0.018753770738840103,
      "learning_rate": 3.3557543967911145e-05,
      "loss": 0.0013,
      "step": 53290
    },
    {
      "epoch": 16.44554149953718,
      "grad_norm": 0.43983545899391174,
      "learning_rate": 3.355445850046282e-05,
      "loss": 0.0009,
      "step": 53300
    },
    {
      "epoch": 16.448626966985497,
      "grad_norm": 2.8874861527583562e-05,
      "learning_rate": 3.35513730330145e-05,
      "loss": 0.0001,
      "step": 53310
    },
    {
      "epoch": 16.451712434433816,
      "grad_norm": 0.0032452165614813566,
      "learning_rate": 3.3548287565566186e-05,
      "loss": 0.0,
      "step": 53320
    },
    {
      "epoch": 16.454797901882134,
      "grad_norm": 0.2617891728878021,
      "learning_rate": 3.354520209811787e-05,
      "loss": 0.0087,
      "step": 53330
    },
    {
      "epoch": 16.457883369330453,
      "grad_norm": 0.04473865404725075,
      "learning_rate": 3.3542116630669544e-05,
      "loss": 0.003,
      "step": 53340
    },
    {
      "epoch": 16.460968836778772,
      "grad_norm": 0.00045464359573088586,
      "learning_rate": 3.3539031163221226e-05,
      "loss": 0.0011,
      "step": 53350
    },
    {
      "epoch": 16.46405430422709,
      "grad_norm": 1.5927807908155955e-05,
      "learning_rate": 3.3535945695772916e-05,
      "loss": 0.0039,
      "step": 53360
    },
    {
      "epoch": 16.46713977167541,
      "grad_norm": 0.0982724130153656,
      "learning_rate": 3.353286022832459e-05,
      "loss": 0.0001,
      "step": 53370
    },
    {
      "epoch": 16.470225239123728,
      "grad_norm": 0.07363015413284302,
      "learning_rate": 3.3529774760876274e-05,
      "loss": 0.0139,
      "step": 53380
    },
    {
      "epoch": 16.473310706572047,
      "grad_norm": 0.0006908217328600585,
      "learning_rate": 3.3526689293427956e-05,
      "loss": 0.0007,
      "step": 53390
    },
    {
      "epoch": 16.476396174020365,
      "grad_norm": 0.004118360113352537,
      "learning_rate": 3.352360382597964e-05,
      "loss": 0.0001,
      "step": 53400
    },
    {
      "epoch": 16.479481641468684,
      "grad_norm": 0.33629801869392395,
      "learning_rate": 3.3520518358531314e-05,
      "loss": 0.0026,
      "step": 53410
    },
    {
      "epoch": 16.482567108917,
      "grad_norm": 0.00022437992447521538,
      "learning_rate": 3.3517432891083004e-05,
      "loss": 0.0014,
      "step": 53420
    },
    {
      "epoch": 16.485652576365318,
      "grad_norm": 0.22439450025558472,
      "learning_rate": 3.3514347423634686e-05,
      "loss": 0.001,
      "step": 53430
    },
    {
      "epoch": 16.488738043813637,
      "grad_norm": 0.008029816672205925,
      "learning_rate": 3.351126195618636e-05,
      "loss": 0.0,
      "step": 53440
    },
    {
      "epoch": 16.491823511261956,
      "grad_norm": 0.00020422745728865266,
      "learning_rate": 3.3508176488738044e-05,
      "loss": 0.0007,
      "step": 53450
    },
    {
      "epoch": 16.494908978710274,
      "grad_norm": 0.003680397989228368,
      "learning_rate": 3.350509102128973e-05,
      "loss": 0.0005,
      "step": 53460
    },
    {
      "epoch": 16.497994446158593,
      "grad_norm": 0.0013279153499752283,
      "learning_rate": 3.350200555384141e-05,
      "loss": 0.0005,
      "step": 53470
    },
    {
      "epoch": 16.50107991360691,
      "grad_norm": 0.11444266140460968,
      "learning_rate": 3.3498920086393085e-05,
      "loss": 0.0001,
      "step": 53480
    },
    {
      "epoch": 16.50416538105523,
      "grad_norm": 0.704193651676178,
      "learning_rate": 3.3495834618944774e-05,
      "loss": 0.0003,
      "step": 53490
    },
    {
      "epoch": 16.50725084850355,
      "grad_norm": 0.0004902013461105525,
      "learning_rate": 3.349274915149646e-05,
      "loss": 0.0001,
      "step": 53500
    },
    {
      "epoch": 16.510336315951868,
      "grad_norm": 0.1387738287448883,
      "learning_rate": 3.348966368404813e-05,
      "loss": 0.0021,
      "step": 53510
    },
    {
      "epoch": 16.513421783400187,
      "grad_norm": 0.00040060814353637397,
      "learning_rate": 3.3486578216599815e-05,
      "loss": 0.0117,
      "step": 53520
    },
    {
      "epoch": 16.516507250848505,
      "grad_norm": 0.0011612660018727183,
      "learning_rate": 3.34834927491515e-05,
      "loss": 0.0011,
      "step": 53530
    },
    {
      "epoch": 16.51959271829682,
      "grad_norm": 0.008238793350756168,
      "learning_rate": 3.348040728170318e-05,
      "loss": 0.0016,
      "step": 53540
    },
    {
      "epoch": 16.52267818574514,
      "grad_norm": 0.010208780877292156,
      "learning_rate": 3.347732181425486e-05,
      "loss": 0.001,
      "step": 53550
    },
    {
      "epoch": 16.525763653193458,
      "grad_norm": 0.008196903392672539,
      "learning_rate": 3.3474236346806545e-05,
      "loss": 0.0003,
      "step": 53560
    },
    {
      "epoch": 16.528849120641777,
      "grad_norm": 0.0008215171401388943,
      "learning_rate": 3.347115087935823e-05,
      "loss": 0.0003,
      "step": 53570
    },
    {
      "epoch": 16.531934588090095,
      "grad_norm": 0.006464114412665367,
      "learning_rate": 3.34680654119099e-05,
      "loss": 0.0015,
      "step": 53580
    },
    {
      "epoch": 16.535020055538414,
      "grad_norm": 0.0651276558637619,
      "learning_rate": 3.3464979944461585e-05,
      "loss": 0.003,
      "step": 53590
    },
    {
      "epoch": 16.538105522986733,
      "grad_norm": 0.014239265583455563,
      "learning_rate": 3.346189447701327e-05,
      "loss": 0.0021,
      "step": 53600
    },
    {
      "epoch": 16.54119099043505,
      "grad_norm": 0.02305159717798233,
      "learning_rate": 3.345880900956495e-05,
      "loss": 0.0046,
      "step": 53610
    },
    {
      "epoch": 16.54427645788337,
      "grad_norm": 0.008261242881417274,
      "learning_rate": 3.345572354211663e-05,
      "loss": 0.0063,
      "step": 53620
    },
    {
      "epoch": 16.54736192533169,
      "grad_norm": 0.00019069916743319482,
      "learning_rate": 3.3452638074668315e-05,
      "loss": 0.0021,
      "step": 53630
    },
    {
      "epoch": 16.550447392780008,
      "grad_norm": 0.09563180059194565,
      "learning_rate": 3.344955260722e-05,
      "loss": 0.0045,
      "step": 53640
    },
    {
      "epoch": 16.553532860228323,
      "grad_norm": 0.09372544288635254,
      "learning_rate": 3.3446467139771673e-05,
      "loss": 0.0038,
      "step": 53650
    },
    {
      "epoch": 16.55661832767664,
      "grad_norm": 0.0008808000129647553,
      "learning_rate": 3.344338167232336e-05,
      "loss": 0.0002,
      "step": 53660
    },
    {
      "epoch": 16.55970379512496,
      "grad_norm": 0.0002933540672529489,
      "learning_rate": 3.344029620487504e-05,
      "loss": 0.002,
      "step": 53670
    },
    {
      "epoch": 16.56278926257328,
      "grad_norm": 0.3324207365512848,
      "learning_rate": 3.343721073742672e-05,
      "loss": 0.0015,
      "step": 53680
    },
    {
      "epoch": 16.565874730021598,
      "grad_norm": 5.7089331676252186e-05,
      "learning_rate": 3.34341252699784e-05,
      "loss": 0.0014,
      "step": 53690
    },
    {
      "epoch": 16.568960197469917,
      "grad_norm": 0.0010804453631862998,
      "learning_rate": 3.3431039802530086e-05,
      "loss": 0.0002,
      "step": 53700
    },
    {
      "epoch": 16.572045664918235,
      "grad_norm": 1.388909935951233,
      "learning_rate": 3.342795433508177e-05,
      "loss": 0.0089,
      "step": 53710
    },
    {
      "epoch": 16.575131132366554,
      "grad_norm": 0.0235091894865036,
      "learning_rate": 3.3424868867633444e-05,
      "loss": 0.0036,
      "step": 53720
    },
    {
      "epoch": 16.578216599814873,
      "grad_norm": 0.4972059726715088,
      "learning_rate": 3.342178340018513e-05,
      "loss": 0.0008,
      "step": 53730
    },
    {
      "epoch": 16.58130206726319,
      "grad_norm": 3.6003846162202535e-06,
      "learning_rate": 3.341869793273681e-05,
      "loss": 0.0008,
      "step": 53740
    },
    {
      "epoch": 16.58438753471151,
      "grad_norm": 0.0021999890450388193,
      "learning_rate": 3.341561246528849e-05,
      "loss": 0.0032,
      "step": 53750
    },
    {
      "epoch": 16.58747300215983,
      "grad_norm": 0.5618091821670532,
      "learning_rate": 3.3412526997840174e-05,
      "loss": 0.0007,
      "step": 53760
    },
    {
      "epoch": 16.590558469608144,
      "grad_norm": 0.0024732304736971855,
      "learning_rate": 3.3409441530391856e-05,
      "loss": 0.0003,
      "step": 53770
    },
    {
      "epoch": 16.593643937056463,
      "grad_norm": 0.0002732647699303925,
      "learning_rate": 3.340635606294354e-05,
      "loss": 0.0,
      "step": 53780
    },
    {
      "epoch": 16.59672940450478,
      "grad_norm": 0.04446402192115784,
      "learning_rate": 3.3403270595495215e-05,
      "loss": 0.0005,
      "step": 53790
    },
    {
      "epoch": 16.5998148719531,
      "grad_norm": 6.743508129147813e-05,
      "learning_rate": 3.3400185128046904e-05,
      "loss": 0.0002,
      "step": 53800
    },
    {
      "epoch": 16.60290033940142,
      "grad_norm": 6.007964475429617e-05,
      "learning_rate": 3.339709966059858e-05,
      "loss": 0.0002,
      "step": 53810
    },
    {
      "epoch": 16.605985806849738,
      "grad_norm": 0.001598717411980033,
      "learning_rate": 3.339401419315026e-05,
      "loss": 0.0005,
      "step": 53820
    },
    {
      "epoch": 16.609071274298056,
      "grad_norm": 2.708470582962036,
      "learning_rate": 3.3390928725701945e-05,
      "loss": 0.0017,
      "step": 53830
    },
    {
      "epoch": 16.612156741746375,
      "grad_norm": 0.0011367101687937975,
      "learning_rate": 3.338784325825363e-05,
      "loss": 0.0027,
      "step": 53840
    },
    {
      "epoch": 16.615242209194694,
      "grad_norm": 0.037153176963329315,
      "learning_rate": 3.338475779080531e-05,
      "loss": 0.0038,
      "step": 53850
    },
    {
      "epoch": 16.618327676643013,
      "grad_norm": 0.0217332411557436,
      "learning_rate": 3.3381672323356985e-05,
      "loss": 0.0002,
      "step": 53860
    },
    {
      "epoch": 16.62141314409133,
      "grad_norm": 0.0005279455799609423,
      "learning_rate": 3.3378586855908674e-05,
      "loss": 0.0068,
      "step": 53870
    },
    {
      "epoch": 16.62449861153965,
      "grad_norm": 0.016676736995577812,
      "learning_rate": 3.337550138846035e-05,
      "loss": 0.0014,
      "step": 53880
    },
    {
      "epoch": 16.627584078987965,
      "grad_norm": 0.6555125713348389,
      "learning_rate": 3.337241592101203e-05,
      "loss": 0.0009,
      "step": 53890
    },
    {
      "epoch": 16.630669546436284,
      "grad_norm": 3.3737971782684326,
      "learning_rate": 3.336933045356372e-05,
      "loss": 0.0031,
      "step": 53900
    },
    {
      "epoch": 16.633755013884603,
      "grad_norm": 0.0010317080887034535,
      "learning_rate": 3.33662449861154e-05,
      "loss": 0.0017,
      "step": 53910
    },
    {
      "epoch": 16.63684048133292,
      "grad_norm": 0.12315055727958679,
      "learning_rate": 3.336315951866708e-05,
      "loss": 0.0034,
      "step": 53920
    },
    {
      "epoch": 16.63992594878124,
      "grad_norm": 0.23502123355865479,
      "learning_rate": 3.336007405121876e-05,
      "loss": 0.0036,
      "step": 53930
    },
    {
      "epoch": 16.64301141622956,
      "grad_norm": 0.0010429571848362684,
      "learning_rate": 3.3356988583770445e-05,
      "loss": 0.0039,
      "step": 53940
    },
    {
      "epoch": 16.646096883677878,
      "grad_norm": 0.046308763325214386,
      "learning_rate": 3.335390311632213e-05,
      "loss": 0.0017,
      "step": 53950
    },
    {
      "epoch": 16.649182351126196,
      "grad_norm": 2.646157741546631,
      "learning_rate": 3.33508176488738e-05,
      "loss": 0.0029,
      "step": 53960
    },
    {
      "epoch": 16.652267818574515,
      "grad_norm": 0.00019471898849587888,
      "learning_rate": 3.334773218142549e-05,
      "loss": 0.0065,
      "step": 53970
    },
    {
      "epoch": 16.655353286022834,
      "grad_norm": 0.00019638203957583755,
      "learning_rate": 3.334464671397717e-05,
      "loss": 0.0141,
      "step": 53980
    },
    {
      "epoch": 16.658438753471152,
      "grad_norm": 4.525591430137865e-05,
      "learning_rate": 3.334156124652885e-05,
      "loss": 0.0005,
      "step": 53990
    },
    {
      "epoch": 16.661524220919468,
      "grad_norm": 0.8761107325553894,
      "learning_rate": 3.333847577908053e-05,
      "loss": 0.0025,
      "step": 54000
    },
    {
      "epoch": 16.664609688367786,
      "grad_norm": 1.517524242401123,
      "learning_rate": 3.3335390311632216e-05,
      "loss": 0.0046,
      "step": 54010
    },
    {
      "epoch": 16.667695155816105,
      "grad_norm": 0.010357450693845749,
      "learning_rate": 3.33323048441839e-05,
      "loss": 0.0011,
      "step": 54020
    },
    {
      "epoch": 16.670780623264424,
      "grad_norm": 0.38598138093948364,
      "learning_rate": 3.3329219376735574e-05,
      "loss": 0.0005,
      "step": 54030
    },
    {
      "epoch": 16.673866090712743,
      "grad_norm": 2.643138577695936e-05,
      "learning_rate": 3.332613390928726e-05,
      "loss": 0.0001,
      "step": 54040
    },
    {
      "epoch": 16.67695155816106,
      "grad_norm": 0.008364624343812466,
      "learning_rate": 3.332304844183894e-05,
      "loss": 0.0064,
      "step": 54050
    },
    {
      "epoch": 16.68003702560938,
      "grad_norm": 0.0014609682839363813,
      "learning_rate": 3.331996297439062e-05,
      "loss": 0.0002,
      "step": 54060
    },
    {
      "epoch": 16.6831224930577,
      "grad_norm": 0.0005850470624864101,
      "learning_rate": 3.3316877506942304e-05,
      "loss": 0.0042,
      "step": 54070
    },
    {
      "epoch": 16.686207960506017,
      "grad_norm": 0.002349792281165719,
      "learning_rate": 3.3313792039493986e-05,
      "loss": 0.0001,
      "step": 54080
    },
    {
      "epoch": 16.689293427954336,
      "grad_norm": 4.314541001804173e-05,
      "learning_rate": 3.331070657204567e-05,
      "loss": 0.0,
      "step": 54090
    },
    {
      "epoch": 16.692378895402655,
      "grad_norm": 0.0007884706719778478,
      "learning_rate": 3.3307621104597344e-05,
      "loss": 0.0076,
      "step": 54100
    },
    {
      "epoch": 16.695464362850974,
      "grad_norm": 0.000927008455619216,
      "learning_rate": 3.3304535637149034e-05,
      "loss": 0.0004,
      "step": 54110
    },
    {
      "epoch": 16.69854983029929,
      "grad_norm": 0.003995485603809357,
      "learning_rate": 3.330145016970071e-05,
      "loss": 0.0041,
      "step": 54120
    },
    {
      "epoch": 16.701635297747607,
      "grad_norm": 0.03058715909719467,
      "learning_rate": 3.329836470225239e-05,
      "loss": 0.0215,
      "step": 54130
    },
    {
      "epoch": 16.704720765195926,
      "grad_norm": 9.238424536306411e-05,
      "learning_rate": 3.3295279234804074e-05,
      "loss": 0.0009,
      "step": 54140
    },
    {
      "epoch": 16.707806232644245,
      "grad_norm": 0.9789652824401855,
      "learning_rate": 3.329219376735576e-05,
      "loss": 0.0017,
      "step": 54150
    },
    {
      "epoch": 16.710891700092564,
      "grad_norm": 0.01237143762409687,
      "learning_rate": 3.328910829990744e-05,
      "loss": 0.0001,
      "step": 54160
    },
    {
      "epoch": 16.713977167540882,
      "grad_norm": 0.0005521945422515273,
      "learning_rate": 3.328602283245912e-05,
      "loss": 0.0067,
      "step": 54170
    },
    {
      "epoch": 16.7170626349892,
      "grad_norm": 1.8346258401870728,
      "learning_rate": 3.3282937365010804e-05,
      "loss": 0.0018,
      "step": 54180
    },
    {
      "epoch": 16.72014810243752,
      "grad_norm": 0.004583049565553665,
      "learning_rate": 3.327985189756248e-05,
      "loss": 0.0052,
      "step": 54190
    },
    {
      "epoch": 16.72323356988584,
      "grad_norm": 0.00016049144323915243,
      "learning_rate": 3.327676643011416e-05,
      "loss": 0.0034,
      "step": 54200
    },
    {
      "epoch": 16.726319037334157,
      "grad_norm": 0.0005860829842276871,
      "learning_rate": 3.3273680962665845e-05,
      "loss": 0.0088,
      "step": 54210
    },
    {
      "epoch": 16.729404504782476,
      "grad_norm": 0.0002223265910288319,
      "learning_rate": 3.327059549521753e-05,
      "loss": 0.0003,
      "step": 54220
    },
    {
      "epoch": 16.732489972230795,
      "grad_norm": 0.00017090408073272556,
      "learning_rate": 3.326751002776921e-05,
      "loss": 0.0002,
      "step": 54230
    },
    {
      "epoch": 16.73557543967911,
      "grad_norm": 0.00020369712729007006,
      "learning_rate": 3.326442456032089e-05,
      "loss": 0.0001,
      "step": 54240
    },
    {
      "epoch": 16.73866090712743,
      "grad_norm": 0.066207654774189,
      "learning_rate": 3.3261339092872575e-05,
      "loss": 0.0006,
      "step": 54250
    },
    {
      "epoch": 16.741746374575747,
      "grad_norm": 0.001651197555474937,
      "learning_rate": 3.325825362542425e-05,
      "loss": 0.0001,
      "step": 54260
    },
    {
      "epoch": 16.744831842024066,
      "grad_norm": 0.009771698154509068,
      "learning_rate": 3.325516815797593e-05,
      "loss": 0.0004,
      "step": 54270
    },
    {
      "epoch": 16.747917309472385,
      "grad_norm": 0.0032006758265197277,
      "learning_rate": 3.3252082690527615e-05,
      "loss": 0.0003,
      "step": 54280
    },
    {
      "epoch": 16.751002776920703,
      "grad_norm": 1.4650264978408813,
      "learning_rate": 3.32489972230793e-05,
      "loss": 0.0025,
      "step": 54290
    },
    {
      "epoch": 16.754088244369022,
      "grad_norm": 0.00021886236208956689,
      "learning_rate": 3.324591175563098e-05,
      "loss": 0.0012,
      "step": 54300
    },
    {
      "epoch": 16.75717371181734,
      "grad_norm": 0.0011137060355395079,
      "learning_rate": 3.324282628818266e-05,
      "loss": 0.0002,
      "step": 54310
    },
    {
      "epoch": 16.76025917926566,
      "grad_norm": 0.0017397997435182333,
      "learning_rate": 3.3239740820734345e-05,
      "loss": 0.0016,
      "step": 54320
    },
    {
      "epoch": 16.76334464671398,
      "grad_norm": 0.023363083600997925,
      "learning_rate": 3.323665535328602e-05,
      "loss": 0.0007,
      "step": 54330
    },
    {
      "epoch": 16.766430114162297,
      "grad_norm": 0.0001830302062444389,
      "learning_rate": 3.3233569885837703e-05,
      "loss": 0.0016,
      "step": 54340
    },
    {
      "epoch": 16.769515581610612,
      "grad_norm": 0.0001762883475748822,
      "learning_rate": 3.3230484418389386e-05,
      "loss": 0.0015,
      "step": 54350
    },
    {
      "epoch": 16.77260104905893,
      "grad_norm": 0.01585785299539566,
      "learning_rate": 3.322739895094107e-05,
      "loss": 0.0003,
      "step": 54360
    },
    {
      "epoch": 16.77568651650725,
      "grad_norm": 1.1293437480926514,
      "learning_rate": 3.322431348349275e-05,
      "loss": 0.004,
      "step": 54370
    },
    {
      "epoch": 16.77877198395557,
      "grad_norm": 0.04042584449052811,
      "learning_rate": 3.322122801604443e-05,
      "loss": 0.002,
      "step": 54380
    },
    {
      "epoch": 16.781857451403887,
      "grad_norm": 1.1147843599319458,
      "learning_rate": 3.3218142548596116e-05,
      "loss": 0.0091,
      "step": 54390
    },
    {
      "epoch": 16.784942918852206,
      "grad_norm": 0.0005104127922095358,
      "learning_rate": 3.321505708114779e-05,
      "loss": 0.0034,
      "step": 54400
    },
    {
      "epoch": 16.788028386300525,
      "grad_norm": 0.002276162849739194,
      "learning_rate": 3.321197161369948e-05,
      "loss": 0.002,
      "step": 54410
    },
    {
      "epoch": 16.791113853748843,
      "grad_norm": 0.09241580218076706,
      "learning_rate": 3.320888614625116e-05,
      "loss": 0.0013,
      "step": 54420
    },
    {
      "epoch": 16.794199321197162,
      "grad_norm": 0.00038301313179545105,
      "learning_rate": 3.320580067880284e-05,
      "loss": 0.0005,
      "step": 54430
    },
    {
      "epoch": 16.79728478864548,
      "grad_norm": 0.04794475808739662,
      "learning_rate": 3.320271521135452e-05,
      "loss": 0.0013,
      "step": 54440
    },
    {
      "epoch": 16.8003702560938,
      "grad_norm": 0.0006654404569417238,
      "learning_rate": 3.3199629743906204e-05,
      "loss": 0.0015,
      "step": 54450
    },
    {
      "epoch": 16.80345572354212,
      "grad_norm": 0.01078755408525467,
      "learning_rate": 3.3196544276457886e-05,
      "loss": 0.0002,
      "step": 54460
    },
    {
      "epoch": 16.806541190990433,
      "grad_norm": 1.717440682114102e-05,
      "learning_rate": 3.319345880900956e-05,
      "loss": 0.0049,
      "step": 54470
    },
    {
      "epoch": 16.809626658438752,
      "grad_norm": 9.026060070027597e-06,
      "learning_rate": 3.319037334156125e-05,
      "loss": 0.0004,
      "step": 54480
    },
    {
      "epoch": 16.81271212588707,
      "grad_norm": 1.0976590601785574e-05,
      "learning_rate": 3.3187287874112934e-05,
      "loss": 0.0008,
      "step": 54490
    },
    {
      "epoch": 16.81579759333539,
      "grad_norm": 0.010086541064083576,
      "learning_rate": 3.318420240666461e-05,
      "loss": 0.0005,
      "step": 54500
    },
    {
      "epoch": 16.81888306078371,
      "grad_norm": 0.0964592769742012,
      "learning_rate": 3.318111693921629e-05,
      "loss": 0.0007,
      "step": 54510
    },
    {
      "epoch": 16.821968528232027,
      "grad_norm": 7.898634066805243e-05,
      "learning_rate": 3.3178031471767974e-05,
      "loss": 0.0002,
      "step": 54520
    },
    {
      "epoch": 16.825053995680346,
      "grad_norm": 0.07230914384126663,
      "learning_rate": 3.317494600431966e-05,
      "loss": 0.0006,
      "step": 54530
    },
    {
      "epoch": 16.828139463128664,
      "grad_norm": 0.006253780797123909,
      "learning_rate": 3.317186053687133e-05,
      "loss": 0.0005,
      "step": 54540
    },
    {
      "epoch": 16.831224930576983,
      "grad_norm": 0.6162072420120239,
      "learning_rate": 3.316877506942302e-05,
      "loss": 0.0003,
      "step": 54550
    },
    {
      "epoch": 16.834310398025302,
      "grad_norm": 0.0009629958658479154,
      "learning_rate": 3.3165689601974704e-05,
      "loss": 0.0076,
      "step": 54560
    },
    {
      "epoch": 16.83739586547362,
      "grad_norm": 5.7485820434521884e-05,
      "learning_rate": 3.316260413452638e-05,
      "loss": 0.0003,
      "step": 54570
    },
    {
      "epoch": 16.84048133292194,
      "grad_norm": 0.002316927071660757,
      "learning_rate": 3.315951866707806e-05,
      "loss": 0.0039,
      "step": 54580
    },
    {
      "epoch": 16.843566800370255,
      "grad_norm": 1.9370489120483398,
      "learning_rate": 3.3156433199629745e-05,
      "loss": 0.0034,
      "step": 54590
    },
    {
      "epoch": 16.846652267818573,
      "grad_norm": 0.012148179113864899,
      "learning_rate": 3.315334773218143e-05,
      "loss": 0.0029,
      "step": 54600
    },
    {
      "epoch": 16.849737735266892,
      "grad_norm": 0.03629571199417114,
      "learning_rate": 3.31502622647331e-05,
      "loss": 0.0019,
      "step": 54610
    },
    {
      "epoch": 16.85282320271521,
      "grad_norm": 0.00016314350068569183,
      "learning_rate": 3.314717679728479e-05,
      "loss": 0.0001,
      "step": 54620
    },
    {
      "epoch": 16.85590867016353,
      "grad_norm": 5.2725303248735145e-05,
      "learning_rate": 3.3144091329836475e-05,
      "loss": 0.0004,
      "step": 54630
    },
    {
      "epoch": 16.858994137611848,
      "grad_norm": 0.019956590607762337,
      "learning_rate": 3.314100586238815e-05,
      "loss": 0.0019,
      "step": 54640
    },
    {
      "epoch": 16.862079605060167,
      "grad_norm": 0.0018219195771962404,
      "learning_rate": 3.313792039493983e-05,
      "loss": 0.0,
      "step": 54650
    },
    {
      "epoch": 16.865165072508486,
      "grad_norm": 0.00038764122291468084,
      "learning_rate": 3.3134834927491516e-05,
      "loss": 0.0006,
      "step": 54660
    },
    {
      "epoch": 16.868250539956804,
      "grad_norm": 0.01307798083871603,
      "learning_rate": 3.31317494600432e-05,
      "loss": 0.0003,
      "step": 54670
    },
    {
      "epoch": 16.871336007405123,
      "grad_norm": 2.3320124455494806e-05,
      "learning_rate": 3.312866399259488e-05,
      "loss": 0.0002,
      "step": 54680
    },
    {
      "epoch": 16.874421474853442,
      "grad_norm": 0.00020589261839631945,
      "learning_rate": 3.312557852514656e-05,
      "loss": 0.0047,
      "step": 54690
    },
    {
      "epoch": 16.877506942301757,
      "grad_norm": 4.9426612349634524e-06,
      "learning_rate": 3.3122493057698245e-05,
      "loss": 0.0043,
      "step": 54700
    },
    {
      "epoch": 16.880592409750076,
      "grad_norm": 0.007397318724542856,
      "learning_rate": 3.311940759024992e-05,
      "loss": 0.0004,
      "step": 54710
    },
    {
      "epoch": 16.883677877198394,
      "grad_norm": 0.00019212832557968795,
      "learning_rate": 3.311632212280161e-05,
      "loss": 0.0002,
      "step": 54720
    },
    {
      "epoch": 16.886763344646713,
      "grad_norm": 0.0022436310537159443,
      "learning_rate": 3.3113236655353286e-05,
      "loss": 0.0001,
      "step": 54730
    },
    {
      "epoch": 16.889848812095032,
      "grad_norm": 0.003228304907679558,
      "learning_rate": 3.311015118790497e-05,
      "loss": 0.0002,
      "step": 54740
    },
    {
      "epoch": 16.89293427954335,
      "grad_norm": 0.915371835231781,
      "learning_rate": 3.310706572045665e-05,
      "loss": 0.0005,
      "step": 54750
    },
    {
      "epoch": 16.89601974699167,
      "grad_norm": 0.0014279833994805813,
      "learning_rate": 3.3103980253008334e-05,
      "loss": 0.0001,
      "step": 54760
    },
    {
      "epoch": 16.899105214439988,
      "grad_norm": 0.006344054359942675,
      "learning_rate": 3.3100894785560016e-05,
      "loss": 0.0002,
      "step": 54770
    },
    {
      "epoch": 16.902190681888307,
      "grad_norm": 0.005452292971313,
      "learning_rate": 3.309780931811169e-05,
      "loss": 0.0007,
      "step": 54780
    },
    {
      "epoch": 16.905276149336625,
      "grad_norm": 0.9639641642570496,
      "learning_rate": 3.309472385066338e-05,
      "loss": 0.0006,
      "step": 54790
    },
    {
      "epoch": 16.908361616784944,
      "grad_norm": 2.4604891223134473e-05,
      "learning_rate": 3.309163838321506e-05,
      "loss": 0.0,
      "step": 54800
    },
    {
      "epoch": 16.911447084233263,
      "grad_norm": 6.172080611577258e-05,
      "learning_rate": 3.308855291576674e-05,
      "loss": 0.0057,
      "step": 54810
    },
    {
      "epoch": 16.914532551681578,
      "grad_norm": 0.029202871024608612,
      "learning_rate": 3.308546744831842e-05,
      "loss": 0.0043,
      "step": 54820
    },
    {
      "epoch": 16.917618019129897,
      "grad_norm": 0.008704859763383865,
      "learning_rate": 3.3082381980870104e-05,
      "loss": 0.0002,
      "step": 54830
    },
    {
      "epoch": 16.920703486578216,
      "grad_norm": 0.03066646121442318,
      "learning_rate": 3.3079296513421787e-05,
      "loss": 0.0005,
      "step": 54840
    },
    {
      "epoch": 16.923788954026534,
      "grad_norm": 0.0005148699274286628,
      "learning_rate": 3.307621104597346e-05,
      "loss": 0.0031,
      "step": 54850
    },
    {
      "epoch": 16.926874421474853,
      "grad_norm": 0.0002892827906180173,
      "learning_rate": 3.307312557852515e-05,
      "loss": 0.0,
      "step": 54860
    },
    {
      "epoch": 16.92995988892317,
      "grad_norm": 0.14668716490268707,
      "learning_rate": 3.307004011107683e-05,
      "loss": 0.0045,
      "step": 54870
    },
    {
      "epoch": 16.93304535637149,
      "grad_norm": 0.005110686179250479,
      "learning_rate": 3.306695464362851e-05,
      "loss": 0.0,
      "step": 54880
    },
    {
      "epoch": 16.93613082381981,
      "grad_norm": 9.576736920280382e-05,
      "learning_rate": 3.306386917618019e-05,
      "loss": 0.0,
      "step": 54890
    },
    {
      "epoch": 16.939216291268128,
      "grad_norm": 0.005128426477313042,
      "learning_rate": 3.3060783708731875e-05,
      "loss": 0.0002,
      "step": 54900
    },
    {
      "epoch": 16.942301758716447,
      "grad_norm": 0.00022367102792486548,
      "learning_rate": 3.305769824128356e-05,
      "loss": 0.0007,
      "step": 54910
    },
    {
      "epoch": 16.945387226164765,
      "grad_norm": 0.5578346252441406,
      "learning_rate": 3.305461277383524e-05,
      "loss": 0.0009,
      "step": 54920
    },
    {
      "epoch": 16.948472693613084,
      "grad_norm": 0.01387875434011221,
      "learning_rate": 3.305152730638692e-05,
      "loss": 0.0006,
      "step": 54930
    },
    {
      "epoch": 16.9515581610614,
      "grad_norm": 1.866104685177561e-05,
      "learning_rate": 3.30484418389386e-05,
      "loss": 0.0001,
      "step": 54940
    },
    {
      "epoch": 16.954643628509718,
      "grad_norm": 0.0008069665054790676,
      "learning_rate": 3.304535637149028e-05,
      "loss": 0.0015,
      "step": 54950
    },
    {
      "epoch": 16.957729095958037,
      "grad_norm": 0.0003197735350113362,
      "learning_rate": 3.304227090404197e-05,
      "loss": 0.0011,
      "step": 54960
    },
    {
      "epoch": 16.960814563406355,
      "grad_norm": 0.00010965986439259723,
      "learning_rate": 3.3039185436593645e-05,
      "loss": 0.0006,
      "step": 54970
    },
    {
      "epoch": 16.963900030854674,
      "grad_norm": 0.0011448694858700037,
      "learning_rate": 3.303609996914533e-05,
      "loss": 0.0028,
      "step": 54980
    },
    {
      "epoch": 16.966985498302993,
      "grad_norm": 2.1232519149780273,
      "learning_rate": 3.303301450169701e-05,
      "loss": 0.0154,
      "step": 54990
    },
    {
      "epoch": 16.97007096575131,
      "grad_norm": 8.764572157815564e-06,
      "learning_rate": 3.302992903424869e-05,
      "loss": 0.0004,
      "step": 55000
    },
    {
      "epoch": 16.97315643319963,
      "grad_norm": 0.006029148120433092,
      "learning_rate": 3.302684356680037e-05,
      "loss": 0.0005,
      "step": 55010
    },
    {
      "epoch": 16.97624190064795,
      "grad_norm": 0.0003738171944860369,
      "learning_rate": 3.302375809935205e-05,
      "loss": 0.0102,
      "step": 55020
    },
    {
      "epoch": 16.979327368096268,
      "grad_norm": 0.116773821413517,
      "learning_rate": 3.302067263190374e-05,
      "loss": 0.0012,
      "step": 55030
    },
    {
      "epoch": 16.982412835544586,
      "grad_norm": 0.32923421263694763,
      "learning_rate": 3.3017587164455416e-05,
      "loss": 0.0059,
      "step": 55040
    },
    {
      "epoch": 16.9854983029929,
      "grad_norm": 0.004053177312016487,
      "learning_rate": 3.30145016970071e-05,
      "loss": 0.0004,
      "step": 55050
    },
    {
      "epoch": 16.98858377044122,
      "grad_norm": 0.17009545862674713,
      "learning_rate": 3.301141622955878e-05,
      "loss": 0.0001,
      "step": 55060
    },
    {
      "epoch": 16.99166923788954,
      "grad_norm": 0.009250025264918804,
      "learning_rate": 3.300833076211046e-05,
      "loss": 0.0027,
      "step": 55070
    },
    {
      "epoch": 16.994754705337858,
      "grad_norm": 0.3323020040988922,
      "learning_rate": 3.300524529466214e-05,
      "loss": 0.0004,
      "step": 55080
    },
    {
      "epoch": 16.997840172786177,
      "grad_norm": 0.0005551556823775172,
      "learning_rate": 3.300215982721382e-05,
      "loss": 0.0036,
      "step": 55090
    },
    {
      "epoch": 17.0,
      "eval_accuracy_branch1": 0.9990162321692081,
      "eval_accuracy_branch2": 0.4140215850235815,
      "eval_f1_branch1": 0.9986130034379843,
      "eval_f1_branch2": 0.4087382831104713,
      "eval_loss": 0.0011264384957030416,
      "eval_precision_branch1": 0.9985931712083933,
      "eval_precision_branch2": 0.501494475443919,
      "eval_recall_branch1": 0.9986397687084912,
      "eval_recall_branch2": 0.5012224762014988,
      "eval_runtime": 239.7109,
      "eval_samples_per_second": 432.534,
      "eval_steps_per_second": 54.069,
      "step": 55097
    },
    {
      "epoch": 17.000925640234495,
      "grad_norm": 0.40488889813423157,
      "learning_rate": 3.299907435976551e-05,
      "loss": 0.3458,
      "step": 55100
    },
    {
      "epoch": 17.004011107682814,
      "grad_norm": 0.032467737793922424,
      "learning_rate": 3.2995988892317186e-05,
      "loss": 0.0001,
      "step": 55110
    },
    {
      "epoch": 17.007096575131133,
      "grad_norm": 0.0007044444209896028,
      "learning_rate": 3.299290342486887e-05,
      "loss": 0.0001,
      "step": 55120
    },
    {
      "epoch": 17.01018204257945,
      "grad_norm": 0.0004370740498416126,
      "learning_rate": 3.298981795742055e-05,
      "loss": 0.0001,
      "step": 55130
    },
    {
      "epoch": 17.01326751002777,
      "grad_norm": 0.07589022070169449,
      "learning_rate": 3.2986732489972234e-05,
      "loss": 0.0042,
      "step": 55140
    },
    {
      "epoch": 17.01635297747609,
      "grad_norm": 0.015444601885974407,
      "learning_rate": 3.298364702252391e-05,
      "loss": 0.002,
      "step": 55150
    },
    {
      "epoch": 17.019438444924408,
      "grad_norm": 0.0022173484321683645,
      "learning_rate": 3.298056155507559e-05,
      "loss": 0.0,
      "step": 55160
    },
    {
      "epoch": 17.022523912372723,
      "grad_norm": 0.012555333785712719,
      "learning_rate": 3.297747608762728e-05,
      "loss": 0.0005,
      "step": 55170
    },
    {
      "epoch": 17.02560937982104,
      "grad_norm": 0.005864214152097702,
      "learning_rate": 3.297439062017896e-05,
      "loss": 0.0011,
      "step": 55180
    },
    {
      "epoch": 17.02869484726936,
      "grad_norm": 0.014907590113580227,
      "learning_rate": 3.297130515273064e-05,
      "loss": 0.0002,
      "step": 55190
    },
    {
      "epoch": 17.03178031471768,
      "grad_norm": 5.86047644901555e-05,
      "learning_rate": 3.296821968528232e-05,
      "loss": 0.0018,
      "step": 55200
    },
    {
      "epoch": 17.034865782165998,
      "grad_norm": 0.02033829316496849,
      "learning_rate": 3.2965134217834004e-05,
      "loss": 0.0021,
      "step": 55210
    },
    {
      "epoch": 17.037951249614316,
      "grad_norm": 0.000769813428632915,
      "learning_rate": 3.296204875038568e-05,
      "loss": 0.0014,
      "step": 55220
    },
    {
      "epoch": 17.041036717062635,
      "grad_norm": 0.5952396988868713,
      "learning_rate": 3.295896328293737e-05,
      "loss": 0.0034,
      "step": 55230
    },
    {
      "epoch": 17.044122184510954,
      "grad_norm": 0.019626803696155548,
      "learning_rate": 3.295587781548905e-05,
      "loss": 0.0007,
      "step": 55240
    },
    {
      "epoch": 17.047207651959273,
      "grad_norm": 0.00019270942721050233,
      "learning_rate": 3.295279234804073e-05,
      "loss": 0.0,
      "step": 55250
    },
    {
      "epoch": 17.05029311940759,
      "grad_norm": 0.00040831201476976275,
      "learning_rate": 3.294970688059241e-05,
      "loss": 0.0,
      "step": 55260
    },
    {
      "epoch": 17.05337858685591,
      "grad_norm": 0.029922131448984146,
      "learning_rate": 3.294662141314409e-05,
      "loss": 0.0,
      "step": 55270
    },
    {
      "epoch": 17.05646405430423,
      "grad_norm": 7.580786132166395e-06,
      "learning_rate": 3.2943535945695775e-05,
      "loss": 0.0138,
      "step": 55280
    },
    {
      "epoch": 17.059549521752544,
      "grad_norm": 0.00045827782014384866,
      "learning_rate": 3.294045047824746e-05,
      "loss": 0.0009,
      "step": 55290
    },
    {
      "epoch": 17.062634989200863,
      "grad_norm": 0.0012172202114015818,
      "learning_rate": 3.293736501079914e-05,
      "loss": 0.0,
      "step": 55300
    },
    {
      "epoch": 17.06572045664918,
      "grad_norm": 0.004415149334818125,
      "learning_rate": 3.293427954335082e-05,
      "loss": 0.0001,
      "step": 55310
    },
    {
      "epoch": 17.0688059240975,
      "grad_norm": 0.003655708162114024,
      "learning_rate": 3.29311940759025e-05,
      "loss": 0.0009,
      "step": 55320
    },
    {
      "epoch": 17.07189139154582,
      "grad_norm": 0.011899632401764393,
      "learning_rate": 3.292810860845418e-05,
      "loss": 0.0,
      "step": 55330
    },
    {
      "epoch": 17.074976858994138,
      "grad_norm": 0.0010949787683784962,
      "learning_rate": 3.292502314100586e-05,
      "loss": 0.0003,
      "step": 55340
    },
    {
      "epoch": 17.078062326442456,
      "grad_norm": 0.00019538469496183097,
      "learning_rate": 3.2921937673557545e-05,
      "loss": 0.0063,
      "step": 55350
    },
    {
      "epoch": 17.081147793890775,
      "grad_norm": 0.0019788413774222136,
      "learning_rate": 3.291885220610923e-05,
      "loss": 0.0005,
      "step": 55360
    },
    {
      "epoch": 17.084233261339094,
      "grad_norm": 0.00017758643662091345,
      "learning_rate": 3.291576673866091e-05,
      "loss": 0.0,
      "step": 55370
    },
    {
      "epoch": 17.087318728787412,
      "grad_norm": 1.6062462236732244e-05,
      "learning_rate": 3.291268127121259e-05,
      "loss": 0.0005,
      "step": 55380
    },
    {
      "epoch": 17.09040419623573,
      "grad_norm": 0.010774290189146996,
      "learning_rate": 3.290959580376427e-05,
      "loss": 0.0005,
      "step": 55390
    },
    {
      "epoch": 17.09348966368405,
      "grad_norm": 0.000612907693721354,
      "learning_rate": 3.290651033631595e-05,
      "loss": 0.0001,
      "step": 55400
    },
    {
      "epoch": 17.096575131132365,
      "grad_norm": 4.3929743696935475e-05,
      "learning_rate": 3.2903424868867634e-05,
      "loss": 0.0001,
      "step": 55410
    },
    {
      "epoch": 17.099660598580684,
      "grad_norm": 0.016228919848799706,
      "learning_rate": 3.2900339401419316e-05,
      "loss": 0.0004,
      "step": 55420
    },
    {
      "epoch": 17.102746066029002,
      "grad_norm": 0.0006660394719801843,
      "learning_rate": 3.2897253933971e-05,
      "loss": 0.0008,
      "step": 55430
    },
    {
      "epoch": 17.10583153347732,
      "grad_norm": 0.051829107105731964,
      "learning_rate": 3.289416846652268e-05,
      "loss": 0.0002,
      "step": 55440
    },
    {
      "epoch": 17.10891700092564,
      "grad_norm": 0.0013105206890031695,
      "learning_rate": 3.2891082999074363e-05,
      "loss": 0.0001,
      "step": 55450
    },
    {
      "epoch": 17.11200246837396,
      "grad_norm": 6.122062768554315e-05,
      "learning_rate": 3.288799753162604e-05,
      "loss": 0.0,
      "step": 55460
    },
    {
      "epoch": 17.115087935822277,
      "grad_norm": 1.362060308456421,
      "learning_rate": 3.288491206417773e-05,
      "loss": 0.0024,
      "step": 55470
    },
    {
      "epoch": 17.118173403270596,
      "grad_norm": 0.0012934230035170913,
      "learning_rate": 3.2881826596729404e-05,
      "loss": 0.0017,
      "step": 55480
    },
    {
      "epoch": 17.121258870718915,
      "grad_norm": 0.0010014408035203815,
      "learning_rate": 3.2878741129281087e-05,
      "loss": 0.0027,
      "step": 55490
    },
    {
      "epoch": 17.124344338167234,
      "grad_norm": 0.004271034151315689,
      "learning_rate": 3.287565566183277e-05,
      "loss": 0.0033,
      "step": 55500
    },
    {
      "epoch": 17.127429805615552,
      "grad_norm": 0.36096248030662537,
      "learning_rate": 3.287257019438445e-05,
      "loss": 0.002,
      "step": 55510
    },
    {
      "epoch": 17.130515273063867,
      "grad_norm": 0.00014310705591924489,
      "learning_rate": 3.2869484726936134e-05,
      "loss": 0.0,
      "step": 55520
    },
    {
      "epoch": 17.133600740512186,
      "grad_norm": 0.0790630504488945,
      "learning_rate": 3.286639925948781e-05,
      "loss": 0.0013,
      "step": 55530
    },
    {
      "epoch": 17.136686207960505,
      "grad_norm": 0.00019308808259665966,
      "learning_rate": 3.28633137920395e-05,
      "loss": 0.0014,
      "step": 55540
    },
    {
      "epoch": 17.139771675408824,
      "grad_norm": 2.2368854843080044e-05,
      "learning_rate": 3.2860228324591175e-05,
      "loss": 0.0,
      "step": 55550
    },
    {
      "epoch": 17.142857142857142,
      "grad_norm": 0.0002420806122245267,
      "learning_rate": 3.285714285714286e-05,
      "loss": 0.0001,
      "step": 55560
    },
    {
      "epoch": 17.14594261030546,
      "grad_norm": 0.00027766029234044254,
      "learning_rate": 3.285405738969454e-05,
      "loss": 0.0004,
      "step": 55570
    },
    {
      "epoch": 17.14902807775378,
      "grad_norm": 0.01334533840417862,
      "learning_rate": 3.285097192224622e-05,
      "loss": 0.0039,
      "step": 55580
    },
    {
      "epoch": 17.1521135452021,
      "grad_norm": 0.11055132746696472,
      "learning_rate": 3.2847886454797905e-05,
      "loss": 0.0026,
      "step": 55590
    },
    {
      "epoch": 17.155199012650417,
      "grad_norm": 0.553037166595459,
      "learning_rate": 3.284480098734958e-05,
      "loss": 0.0064,
      "step": 55600
    },
    {
      "epoch": 17.158284480098736,
      "grad_norm": 0.019127119332551956,
      "learning_rate": 3.284171551990127e-05,
      "loss": 0.0007,
      "step": 55610
    },
    {
      "epoch": 17.161369947547055,
      "grad_norm": 0.0034672669135034084,
      "learning_rate": 3.2838630052452945e-05,
      "loss": 0.0005,
      "step": 55620
    },
    {
      "epoch": 17.164455414995373,
      "grad_norm": 8.05846430012025e-05,
      "learning_rate": 3.283554458500463e-05,
      "loss": 0.0013,
      "step": 55630
    },
    {
      "epoch": 17.16754088244369,
      "grad_norm": 0.14381028711795807,
      "learning_rate": 3.283245911755631e-05,
      "loss": 0.0002,
      "step": 55640
    },
    {
      "epoch": 17.170626349892007,
      "grad_norm": 1.756868839263916,
      "learning_rate": 3.282937365010799e-05,
      "loss": 0.001,
      "step": 55650
    },
    {
      "epoch": 17.173711817340326,
      "grad_norm": 0.06435447931289673,
      "learning_rate": 3.2826288182659675e-05,
      "loss": 0.0004,
      "step": 55660
    },
    {
      "epoch": 17.176797284788645,
      "grad_norm": 0.04273992031812668,
      "learning_rate": 3.282320271521135e-05,
      "loss": 0.0007,
      "step": 55670
    },
    {
      "epoch": 17.179882752236963,
      "grad_norm": 0.0003166378883179277,
      "learning_rate": 3.282011724776304e-05,
      "loss": 0.0001,
      "step": 55680
    },
    {
      "epoch": 17.182968219685282,
      "grad_norm": 0.01840442419052124,
      "learning_rate": 3.2817031780314716e-05,
      "loss": 0.0006,
      "step": 55690
    },
    {
      "epoch": 17.1860536871336,
      "grad_norm": 0.029487671330571175,
      "learning_rate": 3.28139463128664e-05,
      "loss": 0.0004,
      "step": 55700
    },
    {
      "epoch": 17.18913915458192,
      "grad_norm": 0.9074591398239136,
      "learning_rate": 3.281086084541809e-05,
      "loss": 0.0074,
      "step": 55710
    },
    {
      "epoch": 17.19222462203024,
      "grad_norm": 0.0035197369288653135,
      "learning_rate": 3.280777537796976e-05,
      "loss": 0.0001,
      "step": 55720
    },
    {
      "epoch": 17.195310089478557,
      "grad_norm": 0.002549439901486039,
      "learning_rate": 3.2804689910521446e-05,
      "loss": 0.0009,
      "step": 55730
    },
    {
      "epoch": 17.198395556926876,
      "grad_norm": 0.03131282329559326,
      "learning_rate": 3.280160444307313e-05,
      "loss": 0.0017,
      "step": 55740
    },
    {
      "epoch": 17.201481024375195,
      "grad_norm": 0.21420101821422577,
      "learning_rate": 3.279851897562481e-05,
      "loss": 0.0062,
      "step": 55750
    },
    {
      "epoch": 17.20456649182351,
      "grad_norm": 0.005518373567610979,
      "learning_rate": 3.279543350817649e-05,
      "loss": 0.0002,
      "step": 55760
    },
    {
      "epoch": 17.20765195927183,
      "grad_norm": 0.00017077177471946925,
      "learning_rate": 3.279234804072817e-05,
      "loss": 0.0,
      "step": 55770
    },
    {
      "epoch": 17.210737426720147,
      "grad_norm": 0.000989214633591473,
      "learning_rate": 3.278926257327986e-05,
      "loss": 0.0005,
      "step": 55780
    },
    {
      "epoch": 17.213822894168466,
      "grad_norm": 0.013507365249097347,
      "learning_rate": 3.2786177105831534e-05,
      "loss": 0.0002,
      "step": 55790
    },
    {
      "epoch": 17.216908361616785,
      "grad_norm": 0.6268377304077148,
      "learning_rate": 3.2783091638383216e-05,
      "loss": 0.0004,
      "step": 55800
    },
    {
      "epoch": 17.219993829065103,
      "grad_norm": 8.194003748940304e-05,
      "learning_rate": 3.27800061709349e-05,
      "loss": 0.0005,
      "step": 55810
    },
    {
      "epoch": 17.223079296513422,
      "grad_norm": 1.486323253629962e-05,
      "learning_rate": 3.277692070348658e-05,
      "loss": 0.0003,
      "step": 55820
    },
    {
      "epoch": 17.22616476396174,
      "grad_norm": 0.0005799800273962319,
      "learning_rate": 3.2773835236038264e-05,
      "loss": 0.0003,
      "step": 55830
    },
    {
      "epoch": 17.22925023141006,
      "grad_norm": 0.0016772024100646377,
      "learning_rate": 3.277074976858994e-05,
      "loss": 0.0019,
      "step": 55840
    },
    {
      "epoch": 17.23233569885838,
      "grad_norm": 1.4442312021856196e-05,
      "learning_rate": 3.276766430114163e-05,
      "loss": 0.0169,
      "step": 55850
    },
    {
      "epoch": 17.235421166306697,
      "grad_norm": 2.6102027893066406,
      "learning_rate": 3.2764578833693304e-05,
      "loss": 0.0033,
      "step": 55860
    },
    {
      "epoch": 17.238506633755012,
      "grad_norm": 1.5095316171646118,
      "learning_rate": 3.276149336624499e-05,
      "loss": 0.0013,
      "step": 55870
    },
    {
      "epoch": 17.24159210120333,
      "grad_norm": 0.0012619701446965337,
      "learning_rate": 3.275840789879667e-05,
      "loss": 0.0196,
      "step": 55880
    },
    {
      "epoch": 17.24467756865165,
      "grad_norm": 9.637609764467925e-05,
      "learning_rate": 3.275532243134835e-05,
      "loss": 0.0006,
      "step": 55890
    },
    {
      "epoch": 17.24776303609997,
      "grad_norm": 0.02023976668715477,
      "learning_rate": 3.2752236963900034e-05,
      "loss": 0.0031,
      "step": 55900
    },
    {
      "epoch": 17.250848503548287,
      "grad_norm": 0.13565991818904877,
      "learning_rate": 3.274915149645171e-05,
      "loss": 0.0175,
      "step": 55910
    },
    {
      "epoch": 17.253933970996606,
      "grad_norm": 0.010538455098867416,
      "learning_rate": 3.27460660290034e-05,
      "loss": 0.0089,
      "step": 55920
    },
    {
      "epoch": 17.257019438444924,
      "grad_norm": 0.001890551415272057,
      "learning_rate": 3.2742980561555075e-05,
      "loss": 0.0004,
      "step": 55930
    },
    {
      "epoch": 17.260104905893243,
      "grad_norm": 0.23452603816986084,
      "learning_rate": 3.273989509410676e-05,
      "loss": 0.0002,
      "step": 55940
    },
    {
      "epoch": 17.263190373341562,
      "grad_norm": 0.00031333803781308234,
      "learning_rate": 3.273680962665844e-05,
      "loss": 0.0042,
      "step": 55950
    },
    {
      "epoch": 17.26627584078988,
      "grad_norm": 4.652729034423828,
      "learning_rate": 3.273372415921012e-05,
      "loss": 0.0096,
      "step": 55960
    },
    {
      "epoch": 17.2693613082382,
      "grad_norm": 0.024472268298268318,
      "learning_rate": 3.2730638691761805e-05,
      "loss": 0.0001,
      "step": 55970
    },
    {
      "epoch": 17.272446775686518,
      "grad_norm": 0.02771664969623089,
      "learning_rate": 3.272755322431349e-05,
      "loss": 0.005,
      "step": 55980
    },
    {
      "epoch": 17.275532243134833,
      "grad_norm": 0.005852716509252787,
      "learning_rate": 3.272446775686517e-05,
      "loss": 0.0051,
      "step": 55990
    },
    {
      "epoch": 17.278617710583152,
      "grad_norm": 0.003600104246288538,
      "learning_rate": 3.2721382289416845e-05,
      "loss": 0.0005,
      "step": 56000
    },
    {
      "epoch": 17.28170317803147,
      "grad_norm": 1.729341983795166,
      "learning_rate": 3.271829682196853e-05,
      "loss": 0.0182,
      "step": 56010
    },
    {
      "epoch": 17.28478864547979,
      "grad_norm": 0.010866554453969002,
      "learning_rate": 3.271521135452021e-05,
      "loss": 0.0,
      "step": 56020
    },
    {
      "epoch": 17.287874112928108,
      "grad_norm": 0.0035492670722305775,
      "learning_rate": 3.271212588707189e-05,
      "loss": 0.0019,
      "step": 56030
    },
    {
      "epoch": 17.290959580376427,
      "grad_norm": 0.00044208404142409563,
      "learning_rate": 3.2709040419623575e-05,
      "loss": 0.0064,
      "step": 56040
    },
    {
      "epoch": 17.294045047824746,
      "grad_norm": 0.003066337900236249,
      "learning_rate": 3.270595495217526e-05,
      "loss": 0.0005,
      "step": 56050
    },
    {
      "epoch": 17.297130515273064,
      "grad_norm": 0.01183332223445177,
      "learning_rate": 3.270286948472694e-05,
      "loss": 0.0002,
      "step": 56060
    },
    {
      "epoch": 17.300215982721383,
      "grad_norm": 0.0029054242186248302,
      "learning_rate": 3.2699784017278616e-05,
      "loss": 0.0009,
      "step": 56070
    },
    {
      "epoch": 17.303301450169702,
      "grad_norm": 0.029208634048700333,
      "learning_rate": 3.26966985498303e-05,
      "loss": 0.0174,
      "step": 56080
    },
    {
      "epoch": 17.30638691761802,
      "grad_norm": 0.012478327378630638,
      "learning_rate": 3.269361308238198e-05,
      "loss": 0.0005,
      "step": 56090
    },
    {
      "epoch": 17.30947238506634,
      "grad_norm": 0.0010612283367663622,
      "learning_rate": 3.2690527614933663e-05,
      "loss": 0.0,
      "step": 56100
    },
    {
      "epoch": 17.312557852514654,
      "grad_norm": 0.00018419086700305343,
      "learning_rate": 3.2687442147485346e-05,
      "loss": 0.0035,
      "step": 56110
    },
    {
      "epoch": 17.315643319962973,
      "grad_norm": 0.011526692658662796,
      "learning_rate": 3.268435668003703e-05,
      "loss": 0.0006,
      "step": 56120
    },
    {
      "epoch": 17.318728787411292,
      "grad_norm": 0.001090614008717239,
      "learning_rate": 3.268127121258871e-05,
      "loss": 0.0001,
      "step": 56130
    },
    {
      "epoch": 17.32181425485961,
      "grad_norm": 0.05805636942386627,
      "learning_rate": 3.267818574514039e-05,
      "loss": 0.001,
      "step": 56140
    },
    {
      "epoch": 17.32489972230793,
      "grad_norm": 0.6704342365264893,
      "learning_rate": 3.267510027769207e-05,
      "loss": 0.0023,
      "step": 56150
    },
    {
      "epoch": 17.327985189756248,
      "grad_norm": 0.012227946892380714,
      "learning_rate": 3.267201481024376e-05,
      "loss": 0.0001,
      "step": 56160
    },
    {
      "epoch": 17.331070657204567,
      "grad_norm": 5.600327858701348e-05,
      "learning_rate": 3.2668929342795434e-05,
      "loss": 0.0004,
      "step": 56170
    },
    {
      "epoch": 17.334156124652885,
      "grad_norm": 0.0276582520455122,
      "learning_rate": 3.2665843875347117e-05,
      "loss": 0.0033,
      "step": 56180
    },
    {
      "epoch": 17.337241592101204,
      "grad_norm": 0.1992841362953186,
      "learning_rate": 3.26627584078988e-05,
      "loss": 0.0002,
      "step": 56190
    },
    {
      "epoch": 17.340327059549523,
      "grad_norm": 0.0023541757836937904,
      "learning_rate": 3.265967294045048e-05,
      "loss": 0.0094,
      "step": 56200
    },
    {
      "epoch": 17.34341252699784,
      "grad_norm": 0.025466222316026688,
      "learning_rate": 3.265658747300216e-05,
      "loss": 0.0016,
      "step": 56210
    },
    {
      "epoch": 17.34649799444616,
      "grad_norm": 0.0033176210708916187,
      "learning_rate": 3.2653502005553846e-05,
      "loss": 0.0005,
      "step": 56220
    },
    {
      "epoch": 17.349583461894476,
      "grad_norm": 0.009640980511903763,
      "learning_rate": 3.265041653810553e-05,
      "loss": 0.0012,
      "step": 56230
    },
    {
      "epoch": 17.352668929342794,
      "grad_norm": 8.465169958071783e-05,
      "learning_rate": 3.2647331070657205e-05,
      "loss": 0.0,
      "step": 56240
    },
    {
      "epoch": 17.355754396791113,
      "grad_norm": 4.735790571430698e-05,
      "learning_rate": 3.264424560320889e-05,
      "loss": 0.0028,
      "step": 56250
    },
    {
      "epoch": 17.35883986423943,
      "grad_norm": 0.0022995995823293924,
      "learning_rate": 3.264116013576057e-05,
      "loss": 0.0012,
      "step": 56260
    },
    {
      "epoch": 17.36192533168775,
      "grad_norm": 0.21607273817062378,
      "learning_rate": 3.263807466831225e-05,
      "loss": 0.0003,
      "step": 56270
    },
    {
      "epoch": 17.36501079913607,
      "grad_norm": 0.038084473460912704,
      "learning_rate": 3.263498920086393e-05,
      "loss": 0.0004,
      "step": 56280
    },
    {
      "epoch": 17.368096266584388,
      "grad_norm": 6.055137055227533e-05,
      "learning_rate": 3.263190373341562e-05,
      "loss": 0.0008,
      "step": 56290
    },
    {
      "epoch": 17.371181734032707,
      "grad_norm": 0.005742320790886879,
      "learning_rate": 3.26288182659673e-05,
      "loss": 0.0089,
      "step": 56300
    },
    {
      "epoch": 17.374267201481025,
      "grad_norm": 0.0004873103753197938,
      "learning_rate": 3.2625732798518975e-05,
      "loss": 0.0028,
      "step": 56310
    },
    {
      "epoch": 17.377352668929344,
      "grad_norm": 1.2727173566818237,
      "learning_rate": 3.262264733107066e-05,
      "loss": 0.0129,
      "step": 56320
    },
    {
      "epoch": 17.380438136377663,
      "grad_norm": 0.023538406938314438,
      "learning_rate": 3.261956186362234e-05,
      "loss": 0.0001,
      "step": 56330
    },
    {
      "epoch": 17.383523603825978,
      "grad_norm": 0.001485668821260333,
      "learning_rate": 3.261647639617402e-05,
      "loss": 0.0001,
      "step": 56340
    },
    {
      "epoch": 17.386609071274297,
      "grad_norm": 0.04465252906084061,
      "learning_rate": 3.26133909287257e-05,
      "loss": 0.0001,
      "step": 56350
    },
    {
      "epoch": 17.389694538722615,
      "grad_norm": 6.822057184763253e-05,
      "learning_rate": 3.261030546127739e-05,
      "loss": 0.0005,
      "step": 56360
    },
    {
      "epoch": 17.392780006170934,
      "grad_norm": 0.0016325105680152774,
      "learning_rate": 3.260721999382907e-05,
      "loss": 0.0001,
      "step": 56370
    },
    {
      "epoch": 17.395865473619253,
      "grad_norm": 0.0029673639219254255,
      "learning_rate": 3.2604134526380746e-05,
      "loss": 0.0,
      "step": 56380
    },
    {
      "epoch": 17.39895094106757,
      "grad_norm": 3.256006311858073e-05,
      "learning_rate": 3.260104905893243e-05,
      "loss": 0.0013,
      "step": 56390
    },
    {
      "epoch": 17.40203640851589,
      "grad_norm": 0.00011792022996814921,
      "learning_rate": 3.259796359148411e-05,
      "loss": 0.0003,
      "step": 56400
    },
    {
      "epoch": 17.40512187596421,
      "grad_norm": 0.002983327955007553,
      "learning_rate": 3.259487812403579e-05,
      "loss": 0.0022,
      "step": 56410
    },
    {
      "epoch": 17.408207343412528,
      "grad_norm": 2.9863767623901367,
      "learning_rate": 3.259179265658747e-05,
      "loss": 0.0041,
      "step": 56420
    },
    {
      "epoch": 17.411292810860846,
      "grad_norm": 0.016209306195378304,
      "learning_rate": 3.258870718913916e-05,
      "loss": 0.0001,
      "step": 56430
    },
    {
      "epoch": 17.414378278309165,
      "grad_norm": 0.000699923955835402,
      "learning_rate": 3.258562172169084e-05,
      "loss": 0.0,
      "step": 56440
    },
    {
      "epoch": 17.417463745757484,
      "grad_norm": 0.003895719302818179,
      "learning_rate": 3.2582536254242516e-05,
      "loss": 0.0007,
      "step": 56450
    },
    {
      "epoch": 17.4205492132058,
      "grad_norm": 0.0003751817566808313,
      "learning_rate": 3.2579450786794206e-05,
      "loss": 0.0025,
      "step": 56460
    },
    {
      "epoch": 17.423634680654118,
      "grad_norm": 0.03615405410528183,
      "learning_rate": 3.257636531934588e-05,
      "loss": 0.0096,
      "step": 56470
    },
    {
      "epoch": 17.426720148102437,
      "grad_norm": 0.003783357795327902,
      "learning_rate": 3.2573279851897564e-05,
      "loss": 0.0001,
      "step": 56480
    },
    {
      "epoch": 17.429805615550755,
      "grad_norm": 0.0003171878051944077,
      "learning_rate": 3.2570194384449246e-05,
      "loss": 0.0006,
      "step": 56490
    },
    {
      "epoch": 17.432891082999074,
      "grad_norm": 0.0035110253375023603,
      "learning_rate": 3.256710891700093e-05,
      "loss": 0.0005,
      "step": 56500
    },
    {
      "epoch": 17.435976550447393,
      "grad_norm": 0.4710922837257385,
      "learning_rate": 3.256402344955261e-05,
      "loss": 0.0003,
      "step": 56510
    },
    {
      "epoch": 17.43906201789571,
      "grad_norm": 0.04458233341574669,
      "learning_rate": 3.256093798210429e-05,
      "loss": 0.0001,
      "step": 56520
    },
    {
      "epoch": 17.44214748534403,
      "grad_norm": 0.018523192033171654,
      "learning_rate": 3.2557852514655976e-05,
      "loss": 0.0022,
      "step": 56530
    },
    {
      "epoch": 17.44523295279235,
      "grad_norm": 1.4704914974572603e-06,
      "learning_rate": 3.255476704720765e-05,
      "loss": 0.0004,
      "step": 56540
    },
    {
      "epoch": 17.448318420240668,
      "grad_norm": 0.012449721805751324,
      "learning_rate": 3.2551681579759334e-05,
      "loss": 0.0044,
      "step": 56550
    },
    {
      "epoch": 17.451403887688986,
      "grad_norm": 0.0016416755970567465,
      "learning_rate": 3.254859611231102e-05,
      "loss": 0.0,
      "step": 56560
    },
    {
      "epoch": 17.454489355137305,
      "grad_norm": 0.009312707930803299,
      "learning_rate": 3.25455106448627e-05,
      "loss": 0.0019,
      "step": 56570
    },
    {
      "epoch": 17.45757482258562,
      "grad_norm": 0.01429928932338953,
      "learning_rate": 3.254242517741438e-05,
      "loss": 0.0016,
      "step": 56580
    },
    {
      "epoch": 17.46066029003394,
      "grad_norm": 0.037905946373939514,
      "learning_rate": 3.253933970996606e-05,
      "loss": 0.0026,
      "step": 56590
    },
    {
      "epoch": 17.463745757482258,
      "grad_norm": 0.001028525410220027,
      "learning_rate": 3.253625424251775e-05,
      "loss": 0.0005,
      "step": 56600
    },
    {
      "epoch": 17.466831224930576,
      "grad_norm": 0.028337130323052406,
      "learning_rate": 3.253316877506942e-05,
      "loss": 0.0002,
      "step": 56610
    },
    {
      "epoch": 17.469916692378895,
      "grad_norm": 0.0549190454185009,
      "learning_rate": 3.2530083307621105e-05,
      "loss": 0.0002,
      "step": 56620
    },
    {
      "epoch": 17.473002159827214,
      "grad_norm": 0.0004460547643247992,
      "learning_rate": 3.252699784017279e-05,
      "loss": 0.0046,
      "step": 56630
    },
    {
      "epoch": 17.476087627275533,
      "grad_norm": 0.0015926783671602607,
      "learning_rate": 3.252391237272447e-05,
      "loss": 0.0006,
      "step": 56640
    },
    {
      "epoch": 17.47917309472385,
      "grad_norm": 0.21812839806079865,
      "learning_rate": 3.252082690527615e-05,
      "loss": 0.0002,
      "step": 56650
    },
    {
      "epoch": 17.48225856217217,
      "grad_norm": 0.017832351848483086,
      "learning_rate": 3.251774143782783e-05,
      "loss": 0.0007,
      "step": 56660
    },
    {
      "epoch": 17.48534402962049,
      "grad_norm": 0.170697882771492,
      "learning_rate": 3.251465597037952e-05,
      "loss": 0.004,
      "step": 56670
    },
    {
      "epoch": 17.488429497068807,
      "grad_norm": 0.0035591197665780783,
      "learning_rate": 3.251157050293119e-05,
      "loss": 0.0004,
      "step": 56680
    },
    {
      "epoch": 17.491514964517123,
      "grad_norm": 0.843798041343689,
      "learning_rate": 3.2508485035482875e-05,
      "loss": 0.0015,
      "step": 56690
    },
    {
      "epoch": 17.49460043196544,
      "grad_norm": 0.0008953662472777069,
      "learning_rate": 3.2505399568034565e-05,
      "loss": 0.0029,
      "step": 56700
    },
    {
      "epoch": 17.49768589941376,
      "grad_norm": 0.0002563459565863013,
      "learning_rate": 3.250231410058624e-05,
      "loss": 0.0006,
      "step": 56710
    },
    {
      "epoch": 17.50077136686208,
      "grad_norm": 0.00047125708078965545,
      "learning_rate": 3.249922863313792e-05,
      "loss": 0.0001,
      "step": 56720
    },
    {
      "epoch": 17.503856834310398,
      "grad_norm": 0.0004952606395818293,
      "learning_rate": 3.2496143165689605e-05,
      "loss": 0.0001,
      "step": 56730
    },
    {
      "epoch": 17.506942301758716,
      "grad_norm": 3.202870720997453e-05,
      "learning_rate": 3.249305769824129e-05,
      "loss": 0.0,
      "step": 56740
    },
    {
      "epoch": 17.510027769207035,
      "grad_norm": 7.787095455569215e-06,
      "learning_rate": 3.2489972230792964e-05,
      "loss": 0.0003,
      "step": 56750
    },
    {
      "epoch": 17.513113236655354,
      "grad_norm": 0.005314980633556843,
      "learning_rate": 3.2486886763344646e-05,
      "loss": 0.0002,
      "step": 56760
    },
    {
      "epoch": 17.516198704103672,
      "grad_norm": 0.4931606650352478,
      "learning_rate": 3.2483801295896335e-05,
      "loss": 0.0003,
      "step": 56770
    },
    {
      "epoch": 17.51928417155199,
      "grad_norm": 0.0014729469548910856,
      "learning_rate": 3.248071582844801e-05,
      "loss": 0.0001,
      "step": 56780
    },
    {
      "epoch": 17.52236963900031,
      "grad_norm": 9.751074685482308e-05,
      "learning_rate": 3.2477630360999693e-05,
      "loss": 0.0,
      "step": 56790
    },
    {
      "epoch": 17.52545510644863,
      "grad_norm": 0.043155744671821594,
      "learning_rate": 3.2474544893551376e-05,
      "loss": 0.0001,
      "step": 56800
    },
    {
      "epoch": 17.528540573896944,
      "grad_norm": 7.939727220218629e-05,
      "learning_rate": 3.247145942610306e-05,
      "loss": 0.0013,
      "step": 56810
    },
    {
      "epoch": 17.531626041345262,
      "grad_norm": 1.414482831954956,
      "learning_rate": 3.2468373958654734e-05,
      "loss": 0.0006,
      "step": 56820
    },
    {
      "epoch": 17.53471150879358,
      "grad_norm": 0.0037600102368742228,
      "learning_rate": 3.2465288491206417e-05,
      "loss": 0.0067,
      "step": 56830
    },
    {
      "epoch": 17.5377969762419,
      "grad_norm": 0.009670612402260303,
      "learning_rate": 3.2462203023758106e-05,
      "loss": 0.0036,
      "step": 56840
    },
    {
      "epoch": 17.54088244369022,
      "grad_norm": 0.0973573699593544,
      "learning_rate": 3.245911755630978e-05,
      "loss": 0.0007,
      "step": 56850
    },
    {
      "epoch": 17.543967911138537,
      "grad_norm": 0.0026815268211066723,
      "learning_rate": 3.2456032088861464e-05,
      "loss": 0.0023,
      "step": 56860
    },
    {
      "epoch": 17.547053378586856,
      "grad_norm": 9.604101251170505e-06,
      "learning_rate": 3.2452946621413146e-05,
      "loss": 0.0079,
      "step": 56870
    },
    {
      "epoch": 17.550138846035175,
      "grad_norm": 0.13547585904598236,
      "learning_rate": 3.244986115396483e-05,
      "loss": 0.0107,
      "step": 56880
    },
    {
      "epoch": 17.553224313483494,
      "grad_norm": 0.01772197149693966,
      "learning_rate": 3.2446775686516505e-05,
      "loss": 0.0005,
      "step": 56890
    },
    {
      "epoch": 17.556309780931812,
      "grad_norm": 0.0041740406304597855,
      "learning_rate": 3.244369021906819e-05,
      "loss": 0.0011,
      "step": 56900
    },
    {
      "epoch": 17.55939524838013,
      "grad_norm": 0.00010238301911158487,
      "learning_rate": 3.2440604751619876e-05,
      "loss": 0.001,
      "step": 56910
    },
    {
      "epoch": 17.56248071582845,
      "grad_norm": 0.09459934383630753,
      "learning_rate": 3.243751928417155e-05,
      "loss": 0.0001,
      "step": 56920
    },
    {
      "epoch": 17.565566183276765,
      "grad_norm": 2.6761059761047363,
      "learning_rate": 3.2434433816723235e-05,
      "loss": 0.0172,
      "step": 56930
    },
    {
      "epoch": 17.568651650725084,
      "grad_norm": 9.087400940188672e-06,
      "learning_rate": 3.243134834927492e-05,
      "loss": 0.0018,
      "step": 56940
    },
    {
      "epoch": 17.571737118173402,
      "grad_norm": 0.006669230293482542,
      "learning_rate": 3.24282628818266e-05,
      "loss": 0.0014,
      "step": 56950
    },
    {
      "epoch": 17.57482258562172,
      "grad_norm": 6.905275949975476e-05,
      "learning_rate": 3.2425177414378275e-05,
      "loss": 0.0011,
      "step": 56960
    },
    {
      "epoch": 17.57790805307004,
      "grad_norm": 0.5430917143821716,
      "learning_rate": 3.2422091946929964e-05,
      "loss": 0.0002,
      "step": 56970
    },
    {
      "epoch": 17.58099352051836,
      "grad_norm": 0.016120709478855133,
      "learning_rate": 3.241900647948165e-05,
      "loss": 0.0003,
      "step": 56980
    },
    {
      "epoch": 17.584078987966677,
      "grad_norm": 0.00983830913901329,
      "learning_rate": 3.241592101203332e-05,
      "loss": 0.0044,
      "step": 56990
    },
    {
      "epoch": 17.587164455414996,
      "grad_norm": 8.259282913058996e-05,
      "learning_rate": 3.2412835544585005e-05,
      "loss": 0.0033,
      "step": 57000
    },
    {
      "epoch": 17.590249922863315,
      "grad_norm": 0.1831056922674179,
      "learning_rate": 3.240975007713669e-05,
      "loss": 0.0024,
      "step": 57010
    },
    {
      "epoch": 17.593335390311633,
      "grad_norm": 0.004612790420651436,
      "learning_rate": 3.240666460968837e-05,
      "loss": 0.0006,
      "step": 57020
    },
    {
      "epoch": 17.596420857759952,
      "grad_norm": 0.006036718375980854,
      "learning_rate": 3.240357914224005e-05,
      "loss": 0.0014,
      "step": 57030
    },
    {
      "epoch": 17.599506325208267,
      "grad_norm": 0.8074741959571838,
      "learning_rate": 3.2400493674791735e-05,
      "loss": 0.0113,
      "step": 57040
    },
    {
      "epoch": 17.602591792656586,
      "grad_norm": 0.22296147048473358,
      "learning_rate": 3.239740820734342e-05,
      "loss": 0.0016,
      "step": 57050
    },
    {
      "epoch": 17.605677260104905,
      "grad_norm": 3.0305069230962545e-05,
      "learning_rate": 3.239432273989509e-05,
      "loss": 0.0,
      "step": 57060
    },
    {
      "epoch": 17.608762727553223,
      "grad_norm": 0.0355973094701767,
      "learning_rate": 3.2391237272446776e-05,
      "loss": 0.0012,
      "step": 57070
    },
    {
      "epoch": 17.611848195001542,
      "grad_norm": 0.1963939219713211,
      "learning_rate": 3.238815180499846e-05,
      "loss": 0.0012,
      "step": 57080
    },
    {
      "epoch": 17.61493366244986,
      "grad_norm": 0.016670087352395058,
      "learning_rate": 3.238506633755014e-05,
      "loss": 0.0001,
      "step": 57090
    },
    {
      "epoch": 17.61801912989818,
      "grad_norm": 0.00031514454167336226,
      "learning_rate": 3.238198087010182e-05,
      "loss": 0.0008,
      "step": 57100
    },
    {
      "epoch": 17.6211045973465,
      "grad_norm": 1.1157079825352412e-05,
      "learning_rate": 3.2378895402653506e-05,
      "loss": 0.0055,
      "step": 57110
    },
    {
      "epoch": 17.624190064794817,
      "grad_norm": 0.00136417499743402,
      "learning_rate": 3.237580993520519e-05,
      "loss": 0.001,
      "step": 57120
    },
    {
      "epoch": 17.627275532243136,
      "grad_norm": 5.465847789309919e-05,
      "learning_rate": 3.2372724467756864e-05,
      "loss": 0.0007,
      "step": 57130
    },
    {
      "epoch": 17.630360999691455,
      "grad_norm": 0.16802838444709778,
      "learning_rate": 3.2369639000308546e-05,
      "loss": 0.0006,
      "step": 57140
    },
    {
      "epoch": 17.633446467139773,
      "grad_norm": 0.01080782525241375,
      "learning_rate": 3.236655353286023e-05,
      "loss": 0.0003,
      "step": 57150
    },
    {
      "epoch": 17.63653193458809,
      "grad_norm": 2.8234775066375732,
      "learning_rate": 3.236346806541191e-05,
      "loss": 0.0139,
      "step": 57160
    },
    {
      "epoch": 17.639617402036407,
      "grad_norm": 1.3687925275007728e-05,
      "learning_rate": 3.2360382597963594e-05,
      "loss": 0.0013,
      "step": 57170
    },
    {
      "epoch": 17.642702869484726,
      "grad_norm": 0.00024170709366444498,
      "learning_rate": 3.2357297130515276e-05,
      "loss": 0.0014,
      "step": 57180
    },
    {
      "epoch": 17.645788336933045,
      "grad_norm": 4.272903242963366e-05,
      "learning_rate": 3.235421166306696e-05,
      "loss": 0.0002,
      "step": 57190
    },
    {
      "epoch": 17.648873804381363,
      "grad_norm": 0.0005527269095182419,
      "learning_rate": 3.2351126195618634e-05,
      "loss": 0.0003,
      "step": 57200
    },
    {
      "epoch": 17.651959271829682,
      "grad_norm": 0.11407134681940079,
      "learning_rate": 3.234804072817032e-05,
      "loss": 0.0005,
      "step": 57210
    },
    {
      "epoch": 17.655044739278,
      "grad_norm": 0.0003514417912811041,
      "learning_rate": 3.2344955260722e-05,
      "loss": 0.0002,
      "step": 57220
    },
    {
      "epoch": 17.65813020672632,
      "grad_norm": 0.010652854107320309,
      "learning_rate": 3.234186979327368e-05,
      "loss": 0.01,
      "step": 57230
    },
    {
      "epoch": 17.66121567417464,
      "grad_norm": 0.45029565691947937,
      "learning_rate": 3.2338784325825364e-05,
      "loss": 0.0002,
      "step": 57240
    },
    {
      "epoch": 17.664301141622957,
      "grad_norm": 0.005602499470114708,
      "learning_rate": 3.233569885837705e-05,
      "loss": 0.0001,
      "step": 57250
    },
    {
      "epoch": 17.667386609071276,
      "grad_norm": 0.00814682524651289,
      "learning_rate": 3.233261339092873e-05,
      "loss": 0.0002,
      "step": 57260
    },
    {
      "epoch": 17.670472076519594,
      "grad_norm": 0.00026062451070174575,
      "learning_rate": 3.2329527923480405e-05,
      "loss": 0.0016,
      "step": 57270
    },
    {
      "epoch": 17.67355754396791,
      "grad_norm": 0.0010610678000375628,
      "learning_rate": 3.2326442456032094e-05,
      "loss": 0.0005,
      "step": 57280
    },
    {
      "epoch": 17.67664301141623,
      "grad_norm": 6.360741281241644e-06,
      "learning_rate": 3.232335698858377e-05,
      "loss": 0.0042,
      "step": 57290
    },
    {
      "epoch": 17.679728478864547,
      "grad_norm": 0.0006873774109408259,
      "learning_rate": 3.232027152113545e-05,
      "loss": 0.0026,
      "step": 57300
    },
    {
      "epoch": 17.682813946312866,
      "grad_norm": 0.3754138946533203,
      "learning_rate": 3.2317186053687135e-05,
      "loss": 0.0002,
      "step": 57310
    },
    {
      "epoch": 17.685899413761184,
      "grad_norm": 0.0001160047686425969,
      "learning_rate": 3.231410058623882e-05,
      "loss": 0.0002,
      "step": 57320
    },
    {
      "epoch": 17.688984881209503,
      "grad_norm": 0.0005384788964875042,
      "learning_rate": 3.23110151187905e-05,
      "loss": 0.0001,
      "step": 57330
    },
    {
      "epoch": 17.692070348657822,
      "grad_norm": 0.0007201733533293009,
      "learning_rate": 3.2307929651342175e-05,
      "loss": 0.0001,
      "step": 57340
    },
    {
      "epoch": 17.69515581610614,
      "grad_norm": 0.012639504857361317,
      "learning_rate": 3.2304844183893865e-05,
      "loss": 0.0,
      "step": 57350
    },
    {
      "epoch": 17.69824128355446,
      "grad_norm": 0.00019432860426604748,
      "learning_rate": 3.230175871644554e-05,
      "loss": 0.0084,
      "step": 57360
    },
    {
      "epoch": 17.701326751002778,
      "grad_norm": 0.0006764595163986087,
      "learning_rate": 3.229867324899722e-05,
      "loss": 0.0017,
      "step": 57370
    },
    {
      "epoch": 17.704412218451097,
      "grad_norm": 0.0013950173743069172,
      "learning_rate": 3.2295587781548905e-05,
      "loss": 0.0,
      "step": 57380
    },
    {
      "epoch": 17.707497685899412,
      "grad_norm": 0.011302110739052296,
      "learning_rate": 3.229250231410059e-05,
      "loss": 0.006,
      "step": 57390
    },
    {
      "epoch": 17.71058315334773,
      "grad_norm": 0.006335034966468811,
      "learning_rate": 3.228941684665227e-05,
      "loss": 0.0009,
      "step": 57400
    },
    {
      "epoch": 17.71366862079605,
      "grad_norm": 0.030571622774004936,
      "learning_rate": 3.2286331379203946e-05,
      "loss": 0.0054,
      "step": 57410
    },
    {
      "epoch": 17.716754088244368,
      "grad_norm": 0.00014992247452028096,
      "learning_rate": 3.2283245911755635e-05,
      "loss": 0.0064,
      "step": 57420
    },
    {
      "epoch": 17.719839555692687,
      "grad_norm": 0.0002509009500499815,
      "learning_rate": 3.228016044430731e-05,
      "loss": 0.0022,
      "step": 57430
    },
    {
      "epoch": 17.722925023141006,
      "grad_norm": 0.005911962129175663,
      "learning_rate": 3.2277074976858993e-05,
      "loss": 0.0032,
      "step": 57440
    },
    {
      "epoch": 17.726010490589324,
      "grad_norm": 0.0014931648038327694,
      "learning_rate": 3.2273989509410676e-05,
      "loss": 0.0032,
      "step": 57450
    },
    {
      "epoch": 17.729095958037643,
      "grad_norm": 0.0021710980217903852,
      "learning_rate": 3.227090404196236e-05,
      "loss": 0.0002,
      "step": 57460
    },
    {
      "epoch": 17.73218142548596,
      "grad_norm": 0.003878999035805464,
      "learning_rate": 3.226781857451404e-05,
      "loss": 0.0006,
      "step": 57470
    },
    {
      "epoch": 17.73526689293428,
      "grad_norm": 2.031285524368286,
      "learning_rate": 3.2264733107065717e-05,
      "loss": 0.0021,
      "step": 57480
    },
    {
      "epoch": 17.7383523603826,
      "grad_norm": 0.05491296574473381,
      "learning_rate": 3.2261647639617406e-05,
      "loss": 0.0003,
      "step": 57490
    },
    {
      "epoch": 17.741437827830918,
      "grad_norm": 0.00018504627223592252,
      "learning_rate": 3.225856217216909e-05,
      "loss": 0.0029,
      "step": 57500
    },
    {
      "epoch": 17.744523295279233,
      "grad_norm": 0.3788813054561615,
      "learning_rate": 3.2255476704720764e-05,
      "loss": 0.0043,
      "step": 57510
    },
    {
      "epoch": 17.747608762727552,
      "grad_norm": 0.00021526387718040496,
      "learning_rate": 3.225239123727245e-05,
      "loss": 0.0002,
      "step": 57520
    },
    {
      "epoch": 17.75069423017587,
      "grad_norm": 0.0012727060820907354,
      "learning_rate": 3.224930576982413e-05,
      "loss": 0.0,
      "step": 57530
    },
    {
      "epoch": 17.75377969762419,
      "grad_norm": 0.0006336992955766618,
      "learning_rate": 3.224622030237581e-05,
      "loss": 0.0001,
      "step": 57540
    },
    {
      "epoch": 17.756865165072508,
      "grad_norm": 0.018144158646464348,
      "learning_rate": 3.2243134834927494e-05,
      "loss": 0.0008,
      "step": 57550
    },
    {
      "epoch": 17.759950632520827,
      "grad_norm": 0.000516818487085402,
      "learning_rate": 3.2240049367479176e-05,
      "loss": 0.0001,
      "step": 57560
    },
    {
      "epoch": 17.763036099969145,
      "grad_norm": 0.000501292000990361,
      "learning_rate": 3.223696390003086e-05,
      "loss": 0.0007,
      "step": 57570
    },
    {
      "epoch": 17.766121567417464,
      "grad_norm": 0.0010981963714584708,
      "learning_rate": 3.2233878432582535e-05,
      "loss": 0.0032,
      "step": 57580
    },
    {
      "epoch": 17.769207034865783,
      "grad_norm": 2.582139253616333,
      "learning_rate": 3.2230792965134224e-05,
      "loss": 0.0076,
      "step": 57590
    },
    {
      "epoch": 17.7722925023141,
      "grad_norm": 0.002047204179689288,
      "learning_rate": 3.22277074976859e-05,
      "loss": 0.0028,
      "step": 57600
    },
    {
      "epoch": 17.77537796976242,
      "grad_norm": 0.05936228111386299,
      "learning_rate": 3.222462203023758e-05,
      "loss": 0.0008,
      "step": 57610
    },
    {
      "epoch": 17.77846343721074,
      "grad_norm": 0.00017883129476103932,
      "learning_rate": 3.2221536562789264e-05,
      "loss": 0.0003,
      "step": 57620
    },
    {
      "epoch": 17.781548904659054,
      "grad_norm": 4.467540264129639,
      "learning_rate": 3.221845109534095e-05,
      "loss": 0.0039,
      "step": 57630
    },
    {
      "epoch": 17.784634372107373,
      "grad_norm": 0.0029206103645265102,
      "learning_rate": 3.221536562789263e-05,
      "loss": 0.0001,
      "step": 57640
    },
    {
      "epoch": 17.78771983955569,
      "grad_norm": 0.0004980823141522706,
      "learning_rate": 3.2212280160444305e-05,
      "loss": 0.0048,
      "step": 57650
    },
    {
      "epoch": 17.79080530700401,
      "grad_norm": 0.0001396694133291021,
      "learning_rate": 3.2209194692995994e-05,
      "loss": 0.0001,
      "step": 57660
    },
    {
      "epoch": 17.79389077445233,
      "grad_norm": 0.7241494655609131,
      "learning_rate": 3.220610922554767e-05,
      "loss": 0.0028,
      "step": 57670
    },
    {
      "epoch": 17.796976241900648,
      "grad_norm": 0.048406388610601425,
      "learning_rate": 3.220302375809935e-05,
      "loss": 0.0001,
      "step": 57680
    },
    {
      "epoch": 17.800061709348967,
      "grad_norm": 3.50343034369871e-05,
      "learning_rate": 3.2199938290651035e-05,
      "loss": 0.0089,
      "step": 57690
    },
    {
      "epoch": 17.803147176797285,
      "grad_norm": 0.0016075677704066038,
      "learning_rate": 3.219685282320272e-05,
      "loss": 0.0004,
      "step": 57700
    },
    {
      "epoch": 17.806232644245604,
      "grad_norm": 0.0017493250779807568,
      "learning_rate": 3.21937673557544e-05,
      "loss": 0.0003,
      "step": 57710
    },
    {
      "epoch": 17.809318111693923,
      "grad_norm": 0.0032671482767909765,
      "learning_rate": 3.2190681888306076e-05,
      "loss": 0.0001,
      "step": 57720
    },
    {
      "epoch": 17.81240357914224,
      "grad_norm": 1.2431492805480957,
      "learning_rate": 3.2187596420857765e-05,
      "loss": 0.004,
      "step": 57730
    },
    {
      "epoch": 17.815489046590557,
      "grad_norm": 0.0011136027751490474,
      "learning_rate": 3.218451095340944e-05,
      "loss": 0.0036,
      "step": 57740
    },
    {
      "epoch": 17.818574514038875,
      "grad_norm": 0.24082159996032715,
      "learning_rate": 3.218142548596112e-05,
      "loss": 0.0039,
      "step": 57750
    },
    {
      "epoch": 17.821659981487194,
      "grad_norm": 0.7132843136787415,
      "learning_rate": 3.2178340018512806e-05,
      "loss": 0.0019,
      "step": 57760
    },
    {
      "epoch": 17.824745448935513,
      "grad_norm": 7.77711029513739e-05,
      "learning_rate": 3.217525455106449e-05,
      "loss": 0.0005,
      "step": 57770
    },
    {
      "epoch": 17.82783091638383,
      "grad_norm": 2.8754557206411846e-05,
      "learning_rate": 3.217216908361617e-05,
      "loss": 0.0031,
      "step": 57780
    },
    {
      "epoch": 17.83091638383215,
      "grad_norm": 0.004650907590985298,
      "learning_rate": 3.216908361616785e-05,
      "loss": 0.0029,
      "step": 57790
    },
    {
      "epoch": 17.83400185128047,
      "grad_norm": 0.00034240997047163546,
      "learning_rate": 3.2165998148719536e-05,
      "loss": 0.0003,
      "step": 57800
    },
    {
      "epoch": 17.837087318728788,
      "grad_norm": 1.0165468454360962,
      "learning_rate": 3.216291268127121e-05,
      "loss": 0.0009,
      "step": 57810
    },
    {
      "epoch": 17.840172786177106,
      "grad_norm": 0.005177914630621672,
      "learning_rate": 3.2159827213822894e-05,
      "loss": 0.0005,
      "step": 57820
    },
    {
      "epoch": 17.843258253625425,
      "grad_norm": 0.0024769511073827744,
      "learning_rate": 3.2156741746374576e-05,
      "loss": 0.0001,
      "step": 57830
    },
    {
      "epoch": 17.846343721073744,
      "grad_norm": 0.0024823613930493593,
      "learning_rate": 3.215365627892626e-05,
      "loss": 0.0001,
      "step": 57840
    },
    {
      "epoch": 17.849429188522063,
      "grad_norm": 0.08186237514019012,
      "learning_rate": 3.215057081147794e-05,
      "loss": 0.0001,
      "step": 57850
    },
    {
      "epoch": 17.85251465597038,
      "grad_norm": 0.005897220224142075,
      "learning_rate": 3.2147485344029624e-05,
      "loss": 0.005,
      "step": 57860
    },
    {
      "epoch": 17.855600123418697,
      "grad_norm": 0.005923083983361721,
      "learning_rate": 3.2144399876581306e-05,
      "loss": 0.0,
      "step": 57870
    },
    {
      "epoch": 17.858685590867015,
      "grad_norm": 0.23684236407279968,
      "learning_rate": 3.214131440913298e-05,
      "loss": 0.0002,
      "step": 57880
    },
    {
      "epoch": 17.861771058315334,
      "grad_norm": 0.0007099742069840431,
      "learning_rate": 3.2138228941684664e-05,
      "loss": 0.003,
      "step": 57890
    },
    {
      "epoch": 17.864856525763653,
      "grad_norm": 0.2150173932313919,
      "learning_rate": 3.2135143474236353e-05,
      "loss": 0.0034,
      "step": 57900
    },
    {
      "epoch": 17.86794199321197,
      "grad_norm": 0.005110547412186861,
      "learning_rate": 3.213205800678803e-05,
      "loss": 0.0009,
      "step": 57910
    },
    {
      "epoch": 17.87102746066029,
      "grad_norm": 0.012945618480443954,
      "learning_rate": 3.212897253933971e-05,
      "loss": 0.0001,
      "step": 57920
    },
    {
      "epoch": 17.87411292810861,
      "grad_norm": 0.0002766319375950843,
      "learning_rate": 3.2125887071891394e-05,
      "loss": 0.0038,
      "step": 57930
    },
    {
      "epoch": 17.877198395556928,
      "grad_norm": 8.71742577146506e-06,
      "learning_rate": 3.212280160444308e-05,
      "loss": 0.0033,
      "step": 57940
    },
    {
      "epoch": 17.880283863005246,
      "grad_norm": 0.0003536791482474655,
      "learning_rate": 3.211971613699475e-05,
      "loss": 0.0017,
      "step": 57950
    },
    {
      "epoch": 17.883369330453565,
      "grad_norm": 0.07934631407260895,
      "learning_rate": 3.2116630669546435e-05,
      "loss": 0.0082,
      "step": 57960
    },
    {
      "epoch": 17.886454797901884,
      "grad_norm": 0.0006454979302361608,
      "learning_rate": 3.2113545202098124e-05,
      "loss": 0.0002,
      "step": 57970
    },
    {
      "epoch": 17.8895402653502,
      "grad_norm": 0.13400663435459137,
      "learning_rate": 3.21104597346498e-05,
      "loss": 0.0002,
      "step": 57980
    },
    {
      "epoch": 17.892625732798518,
      "grad_norm": 0.28420257568359375,
      "learning_rate": 3.210737426720148e-05,
      "loss": 0.0026,
      "step": 57990
    },
    {
      "epoch": 17.895711200246836,
      "grad_norm": 0.0039954157546162605,
      "learning_rate": 3.2104288799753165e-05,
      "loss": 0.0003,
      "step": 58000
    },
    {
      "epoch": 17.898796667695155,
      "grad_norm": 0.0007066481630317867,
      "learning_rate": 3.210120333230485e-05,
      "loss": 0.001,
      "step": 58010
    },
    {
      "epoch": 17.901882135143474,
      "grad_norm": 0.11318811029195786,
      "learning_rate": 3.209811786485652e-05,
      "loss": 0.0011,
      "step": 58020
    },
    {
      "epoch": 17.904967602591793,
      "grad_norm": 0.0019731405191123486,
      "learning_rate": 3.209503239740821e-05,
      "loss": 0.0002,
      "step": 58030
    },
    {
      "epoch": 17.90805307004011,
      "grad_norm": 0.0003663150127977133,
      "learning_rate": 3.2091946929959895e-05,
      "loss": 0.0002,
      "step": 58040
    },
    {
      "epoch": 17.91113853748843,
      "grad_norm": 0.0014543565921485424,
      "learning_rate": 3.208886146251157e-05,
      "loss": 0.0078,
      "step": 58050
    },
    {
      "epoch": 17.91422400493675,
      "grad_norm": 0.010347774252295494,
      "learning_rate": 3.208577599506325e-05,
      "loss": 0.0,
      "step": 58060
    },
    {
      "epoch": 17.917309472385067,
      "grad_norm": 0.017951687797904015,
      "learning_rate": 3.2082690527614935e-05,
      "loss": 0.004,
      "step": 58070
    },
    {
      "epoch": 17.920394939833386,
      "grad_norm": 0.012139626778662205,
      "learning_rate": 3.207960506016662e-05,
      "loss": 0.0002,
      "step": 58080
    },
    {
      "epoch": 17.923480407281705,
      "grad_norm": 0.1931629478931427,
      "learning_rate": 3.2076519592718293e-05,
      "loss": 0.0007,
      "step": 58090
    },
    {
      "epoch": 17.92656587473002,
      "grad_norm": 0.007244840729981661,
      "learning_rate": 3.207343412526998e-05,
      "loss": 0.0007,
      "step": 58100
    },
    {
      "epoch": 17.92965134217834,
      "grad_norm": 0.010798921808600426,
      "learning_rate": 3.2070348657821665e-05,
      "loss": 0.0002,
      "step": 58110
    },
    {
      "epoch": 17.932736809626658,
      "grad_norm": 0.0032818149775266647,
      "learning_rate": 3.206726319037334e-05,
      "loss": 0.0047,
      "step": 58120
    },
    {
      "epoch": 17.935822277074976,
      "grad_norm": 7.42556803743355e-05,
      "learning_rate": 3.206417772292502e-05,
      "loss": 0.0004,
      "step": 58130
    },
    {
      "epoch": 17.938907744523295,
      "grad_norm": 0.15898828208446503,
      "learning_rate": 3.2061092255476706e-05,
      "loss": 0.0002,
      "step": 58140
    },
    {
      "epoch": 17.941993211971614,
      "grad_norm": 0.0009233765304088593,
      "learning_rate": 3.205800678802839e-05,
      "loss": 0.0007,
      "step": 58150
    },
    {
      "epoch": 17.945078679419932,
      "grad_norm": 3.723555346368812e-05,
      "learning_rate": 3.2054921320580064e-05,
      "loss": 0.001,
      "step": 58160
    },
    {
      "epoch": 17.94816414686825,
      "grad_norm": 2.298482650076039e-05,
      "learning_rate": 3.205183585313175e-05,
      "loss": 0.0017,
      "step": 58170
    },
    {
      "epoch": 17.95124961431657,
      "grad_norm": 0.0015908938366919756,
      "learning_rate": 3.2048750385683436e-05,
      "loss": 0.0016,
      "step": 58180
    },
    {
      "epoch": 17.95433508176489,
      "grad_norm": 0.001219138503074646,
      "learning_rate": 3.204566491823511e-05,
      "loss": 0.0001,
      "step": 58190
    },
    {
      "epoch": 17.957420549213207,
      "grad_norm": 0.05217677727341652,
      "learning_rate": 3.2042579450786794e-05,
      "loss": 0.0,
      "step": 58200
    },
    {
      "epoch": 17.960506016661526,
      "grad_norm": 0.07065287232398987,
      "learning_rate": 3.2039493983338476e-05,
      "loss": 0.002,
      "step": 58210
    },
    {
      "epoch": 17.96359148410984,
      "grad_norm": 0.03962131217122078,
      "learning_rate": 3.203640851589016e-05,
      "loss": 0.0002,
      "step": 58220
    },
    {
      "epoch": 17.96667695155816,
      "grad_norm": 0.00014048129378352314,
      "learning_rate": 3.2033323048441835e-05,
      "loss": 0.0033,
      "step": 58230
    },
    {
      "epoch": 17.96976241900648,
      "grad_norm": 0.006146898493170738,
      "learning_rate": 3.2030237580993524e-05,
      "loss": 0.0002,
      "step": 58240
    },
    {
      "epoch": 17.972847886454797,
      "grad_norm": 0.00043484120396897197,
      "learning_rate": 3.2027152113545206e-05,
      "loss": 0.0019,
      "step": 58250
    },
    {
      "epoch": 17.975933353903116,
      "grad_norm": 6.625234527746215e-05,
      "learning_rate": 3.202406664609688e-05,
      "loss": 0.0038,
      "step": 58260
    },
    {
      "epoch": 17.979018821351435,
      "grad_norm": 0.01937677338719368,
      "learning_rate": 3.202098117864857e-05,
      "loss": 0.0014,
      "step": 58270
    },
    {
      "epoch": 17.982104288799754,
      "grad_norm": 0.03509639576077461,
      "learning_rate": 3.201789571120025e-05,
      "loss": 0.0001,
      "step": 58280
    },
    {
      "epoch": 17.985189756248072,
      "grad_norm": 0.12113071233034134,
      "learning_rate": 3.201481024375193e-05,
      "loss": 0.0037,
      "step": 58290
    },
    {
      "epoch": 17.98827522369639,
      "grad_norm": 0.00021638358884956688,
      "learning_rate": 3.201172477630361e-05,
      "loss": 0.0003,
      "step": 58300
    },
    {
      "epoch": 17.99136069114471,
      "grad_norm": 0.23954106867313385,
      "learning_rate": 3.2008639308855294e-05,
      "loss": 0.0084,
      "step": 58310
    },
    {
      "epoch": 17.99444615859303,
      "grad_norm": 0.02454349584877491,
      "learning_rate": 3.200555384140698e-05,
      "loss": 0.0001,
      "step": 58320
    },
    {
      "epoch": 17.997531626041344,
      "grad_norm": 0.007711031939834356,
      "learning_rate": 3.200246837395865e-05,
      "loss": 0.0001,
      "step": 58330
    },
    {
      "epoch": 18.0,
      "eval_accuracy_branch1": 0.9995466952152233,
      "eval_accuracy_branch2": 0.39879247321161615,
      "eval_f1_branch1": 0.9993053860223415,
      "eval_f1_branch2": 0.3859752365384787,
      "eval_loss": 0.00010530055442359298,
      "eval_precision_branch1": 0.9992859491259729,
      "eval_precision_branch2": 0.5040924154939104,
      "eval_recall_branch1": 0.9993275028423395,
      "eval_recall_branch2": 0.5028210989265357,
      "eval_runtime": 240.504,
      "eval_samples_per_second": 431.107,
      "eval_steps_per_second": 53.891,
      "step": 58338
    },
    {
      "epoch": 18.000617093489662,
      "grad_norm": 4.57612350146519e-06,
      "learning_rate": 3.199938290651034e-05,
      "loss": 0.002,
      "step": 58340
    },
    {
      "epoch": 18.00370256093798,
      "grad_norm": 0.008192350156605244,
      "learning_rate": 3.199629743906202e-05,
      "loss": 0.0001,
      "step": 58350
    },
    {
      "epoch": 18.0067880283863,
      "grad_norm": 0.00046355760423466563,
      "learning_rate": 3.19932119716137e-05,
      "loss": 0.0001,
      "step": 58360
    },
    {
      "epoch": 18.00987349583462,
      "grad_norm": 0.11029648035764694,
      "learning_rate": 3.199012650416538e-05,
      "loss": 0.0001,
      "step": 58370
    },
    {
      "epoch": 18.012958963282937,
      "grad_norm": 0.04090207442641258,
      "learning_rate": 3.1987041036717065e-05,
      "loss": 0.0103,
      "step": 58380
    },
    {
      "epoch": 18.016044430731256,
      "grad_norm": 0.0006329251918941736,
      "learning_rate": 3.198395556926875e-05,
      "loss": 0.0004,
      "step": 58390
    },
    {
      "epoch": 18.019129898179575,
      "grad_norm": 0.0007633843342773616,
      "learning_rate": 3.198087010182042e-05,
      "loss": 0.0003,
      "step": 58400
    },
    {
      "epoch": 18.022215365627893,
      "grad_norm": 0.0002399002987658605,
      "learning_rate": 3.197778463437211e-05,
      "loss": 0.0021,
      "step": 58410
    },
    {
      "epoch": 18.025300833076212,
      "grad_norm": 1.5652590990066528,
      "learning_rate": 3.197469916692379e-05,
      "loss": 0.0008,
      "step": 58420
    },
    {
      "epoch": 18.02838630052453,
      "grad_norm": 0.0001863611105363816,
      "learning_rate": 3.197161369947547e-05,
      "loss": 0.0004,
      "step": 58430
    },
    {
      "epoch": 18.03147176797285,
      "grad_norm": 0.001115652616135776,
      "learning_rate": 3.196852823202715e-05,
      "loss": 0.0,
      "step": 58440
    },
    {
      "epoch": 18.034557235421165,
      "grad_norm": 0.000216378626646474,
      "learning_rate": 3.1965442764578836e-05,
      "loss": 0.0007,
      "step": 58450
    },
    {
      "epoch": 18.037642702869483,
      "grad_norm": 9.580622281646356e-05,
      "learning_rate": 3.196235729713052e-05,
      "loss": 0.0004,
      "step": 58460
    },
    {
      "epoch": 18.040728170317802,
      "grad_norm": 0.00025539915077388287,
      "learning_rate": 3.1959271829682194e-05,
      "loss": 0.0,
      "step": 58470
    },
    {
      "epoch": 18.04381363776612,
      "grad_norm": 0.00010103412205353379,
      "learning_rate": 3.195618636223388e-05,
      "loss": 0.0002,
      "step": 58480
    },
    {
      "epoch": 18.04689910521444,
      "grad_norm": 0.5020760297775269,
      "learning_rate": 3.195310089478556e-05,
      "loss": 0.0004,
      "step": 58490
    },
    {
      "epoch": 18.04998457266276,
      "grad_norm": 0.0013111922889947891,
      "learning_rate": 3.195001542733724e-05,
      "loss": 0.0,
      "step": 58500
    },
    {
      "epoch": 18.053070040111077,
      "grad_norm": 0.27093860507011414,
      "learning_rate": 3.194692995988893e-05,
      "loss": 0.0008,
      "step": 58510
    },
    {
      "epoch": 18.056155507559396,
      "grad_norm": 0.001937073073349893,
      "learning_rate": 3.1943844492440606e-05,
      "loss": 0.0017,
      "step": 58520
    },
    {
      "epoch": 18.059240975007715,
      "grad_norm": 0.06036258116364479,
      "learning_rate": 3.194075902499229e-05,
      "loss": 0.0015,
      "step": 58530
    },
    {
      "epoch": 18.062326442456033,
      "grad_norm": 0.10033389180898666,
      "learning_rate": 3.193767355754397e-05,
      "loss": 0.0018,
      "step": 58540
    },
    {
      "epoch": 18.065411909904352,
      "grad_norm": 0.017122238874435425,
      "learning_rate": 3.1934588090095654e-05,
      "loss": 0.0,
      "step": 58550
    },
    {
      "epoch": 18.06849737735267,
      "grad_norm": 5.2329043683130294e-05,
      "learning_rate": 3.193150262264733e-05,
      "loss": 0.0001,
      "step": 58560
    },
    {
      "epoch": 18.071582844800986,
      "grad_norm": 2.1073030893603573e-06,
      "learning_rate": 3.192841715519901e-05,
      "loss": 0.0,
      "step": 58570
    },
    {
      "epoch": 18.074668312249305,
      "grad_norm": 0.00048396456986665726,
      "learning_rate": 3.19253316877507e-05,
      "loss": 0.0002,
      "step": 58580
    },
    {
      "epoch": 18.077753779697623,
      "grad_norm": 0.0004052477888762951,
      "learning_rate": 3.192224622030238e-05,
      "loss": 0.0,
      "step": 58590
    },
    {
      "epoch": 18.080839247145942,
      "grad_norm": 7.339592411881313e-05,
      "learning_rate": 3.191916075285406e-05,
      "loss": 0.0036,
      "step": 58600
    },
    {
      "epoch": 18.08392471459426,
      "grad_norm": 0.0024098569992929697,
      "learning_rate": 3.191607528540574e-05,
      "loss": 0.0001,
      "step": 58610
    },
    {
      "epoch": 18.08701018204258,
      "grad_norm": 0.00244540860876441,
      "learning_rate": 3.1912989817957424e-05,
      "loss": 0.0003,
      "step": 58620
    },
    {
      "epoch": 18.090095649490898,
      "grad_norm": 0.0031216805800795555,
      "learning_rate": 3.19099043505091e-05,
      "loss": 0.0162,
      "step": 58630
    },
    {
      "epoch": 18.093181116939217,
      "grad_norm": 0.03658357635140419,
      "learning_rate": 3.190681888306078e-05,
      "loss": 0.0014,
      "step": 58640
    },
    {
      "epoch": 18.096266584387536,
      "grad_norm": 6.184673839015886e-05,
      "learning_rate": 3.190373341561247e-05,
      "loss": 0.0005,
      "step": 58650
    },
    {
      "epoch": 18.099352051835854,
      "grad_norm": 0.00030737134511582553,
      "learning_rate": 3.190064794816415e-05,
      "loss": 0.0,
      "step": 58660
    },
    {
      "epoch": 18.102437519284173,
      "grad_norm": 1.9528191089630127,
      "learning_rate": 3.189756248071583e-05,
      "loss": 0.001,
      "step": 58670
    },
    {
      "epoch": 18.10552298673249,
      "grad_norm": 0.0005113680381327868,
      "learning_rate": 3.189447701326751e-05,
      "loss": 0.0,
      "step": 58680
    },
    {
      "epoch": 18.108608454180807,
      "grad_norm": 0.020241262391209602,
      "learning_rate": 3.1891391545819195e-05,
      "loss": 0.0002,
      "step": 58690
    },
    {
      "epoch": 18.111693921629126,
      "grad_norm": 0.16494572162628174,
      "learning_rate": 3.188830607837087e-05,
      "loss": 0.001,
      "step": 58700
    },
    {
      "epoch": 18.114779389077444,
      "grad_norm": 0.0014179411809891462,
      "learning_rate": 3.188522061092255e-05,
      "loss": 0.0,
      "step": 58710
    },
    {
      "epoch": 18.117864856525763,
      "grad_norm": 8.644709305372089e-05,
      "learning_rate": 3.188213514347424e-05,
      "loss": 0.0034,
      "step": 58720
    },
    {
      "epoch": 18.120950323974082,
      "grad_norm": 0.006199500523507595,
      "learning_rate": 3.187904967602592e-05,
      "loss": 0.0003,
      "step": 58730
    },
    {
      "epoch": 18.1240357914224,
      "grad_norm": 0.0036085161846131086,
      "learning_rate": 3.18759642085776e-05,
      "loss": 0.0007,
      "step": 58740
    },
    {
      "epoch": 18.12712125887072,
      "grad_norm": 0.04361695796251297,
      "learning_rate": 3.187287874112928e-05,
      "loss": 0.0,
      "step": 58750
    },
    {
      "epoch": 18.130206726319038,
      "grad_norm": 0.00038502365350723267,
      "learning_rate": 3.1869793273680965e-05,
      "loss": 0.0,
      "step": 58760
    },
    {
      "epoch": 18.133292193767357,
      "grad_norm": 0.006577454507350922,
      "learning_rate": 3.186670780623265e-05,
      "loss": 0.0018,
      "step": 58770
    },
    {
      "epoch": 18.136377661215676,
      "grad_norm": 0.00024083987227641046,
      "learning_rate": 3.186362233878433e-05,
      "loss": 0.0012,
      "step": 58780
    },
    {
      "epoch": 18.139463128663994,
      "grad_norm": 0.0014394136378541589,
      "learning_rate": 3.186053687133601e-05,
      "loss": 0.0,
      "step": 58790
    },
    {
      "epoch": 18.14254859611231,
      "grad_norm": 0.00035967069561593235,
      "learning_rate": 3.185745140388769e-05,
      "loss": 0.0012,
      "step": 58800
    },
    {
      "epoch": 18.145634063560628,
      "grad_norm": 0.0003034065885003656,
      "learning_rate": 3.185436593643937e-05,
      "loss": 0.001,
      "step": 58810
    },
    {
      "epoch": 18.148719531008947,
      "grad_norm": 0.18737299740314484,
      "learning_rate": 3.185128046899105e-05,
      "loss": 0.0003,
      "step": 58820
    },
    {
      "epoch": 18.151804998457266,
      "grad_norm": 0.029644740745425224,
      "learning_rate": 3.1848195001542736e-05,
      "loss": 0.0001,
      "step": 58830
    },
    {
      "epoch": 18.154890465905584,
      "grad_norm": 0.0002827109710779041,
      "learning_rate": 3.184510953409442e-05,
      "loss": 0.0012,
      "step": 58840
    },
    {
      "epoch": 18.157975933353903,
      "grad_norm": 6.663012754870579e-05,
      "learning_rate": 3.18420240666461e-05,
      "loss": 0.0001,
      "step": 58850
    },
    {
      "epoch": 18.16106140080222,
      "grad_norm": 0.005913218948990107,
      "learning_rate": 3.183893859919778e-05,
      "loss": 0.0002,
      "step": 58860
    },
    {
      "epoch": 18.16414686825054,
      "grad_norm": 0.38506215810775757,
      "learning_rate": 3.183585313174946e-05,
      "loss": 0.0065,
      "step": 58870
    },
    {
      "epoch": 18.16723233569886,
      "grad_norm": 0.04780854284763336,
      "learning_rate": 3.183276766430114e-05,
      "loss": 0.0009,
      "step": 58880
    },
    {
      "epoch": 18.170317803147178,
      "grad_norm": 0.0025119297206401825,
      "learning_rate": 3.1829682196852824e-05,
      "loss": 0.0006,
      "step": 58890
    },
    {
      "epoch": 18.173403270595497,
      "grad_norm": 0.004009166732430458,
      "learning_rate": 3.1826596729404506e-05,
      "loss": 0.0001,
      "step": 58900
    },
    {
      "epoch": 18.176488738043815,
      "grad_norm": 0.013869334012269974,
      "learning_rate": 3.182351126195619e-05,
      "loss": 0.0,
      "step": 58910
    },
    {
      "epoch": 18.17957420549213,
      "grad_norm": 0.0005675681168213487,
      "learning_rate": 3.182042579450787e-05,
      "loss": 0.0001,
      "step": 58920
    },
    {
      "epoch": 18.18265967294045,
      "grad_norm": 0.2190701961517334,
      "learning_rate": 3.1817340327059554e-05,
      "loss": 0.0001,
      "step": 58930
    },
    {
      "epoch": 18.185745140388768,
      "grad_norm": 0.09857423603534698,
      "learning_rate": 3.181425485961123e-05,
      "loss": 0.0002,
      "step": 58940
    },
    {
      "epoch": 18.188830607837087,
      "grad_norm": 0.00192316307220608,
      "learning_rate": 3.181116939216291e-05,
      "loss": 0.0002,
      "step": 58950
    },
    {
      "epoch": 18.191916075285405,
      "grad_norm": 1.3099905252456665,
      "learning_rate": 3.1808083924714594e-05,
      "loss": 0.0006,
      "step": 58960
    },
    {
      "epoch": 18.195001542733724,
      "grad_norm": 6.963669875403866e-05,
      "learning_rate": 3.180499845726628e-05,
      "loss": 0.0001,
      "step": 58970
    },
    {
      "epoch": 18.198087010182043,
      "grad_norm": 0.4991516172885895,
      "learning_rate": 3.180191298981796e-05,
      "loss": 0.0076,
      "step": 58980
    },
    {
      "epoch": 18.20117247763036,
      "grad_norm": 0.03170500323176384,
      "learning_rate": 3.179882752236964e-05,
      "loss": 0.0011,
      "step": 58990
    },
    {
      "epoch": 18.20425794507868,
      "grad_norm": 0.0002600091102067381,
      "learning_rate": 3.1795742054921324e-05,
      "loss": 0.0001,
      "step": 59000
    },
    {
      "epoch": 18.207343412527,
      "grad_norm": 0.00047098600771278143,
      "learning_rate": 3.1792656587473e-05,
      "loss": 0.0012,
      "step": 59010
    },
    {
      "epoch": 18.210428879975318,
      "grad_norm": 2.1324729459593073e-05,
      "learning_rate": 3.178957112002469e-05,
      "loss": 0.0,
      "step": 59020
    },
    {
      "epoch": 18.213514347423633,
      "grad_norm": 0.0011431428138166666,
      "learning_rate": 3.1786485652576365e-05,
      "loss": 0.0006,
      "step": 59030
    },
    {
      "epoch": 18.21659981487195,
      "grad_norm": 0.08268396556377411,
      "learning_rate": 3.178340018512805e-05,
      "loss": 0.0003,
      "step": 59040
    },
    {
      "epoch": 18.21968528232027,
      "grad_norm": 0.2016947716474533,
      "learning_rate": 3.178031471767973e-05,
      "loss": 0.0005,
      "step": 59050
    },
    {
      "epoch": 18.22277074976859,
      "grad_norm": 0.00037716206861659884,
      "learning_rate": 3.177722925023141e-05,
      "loss": 0.0027,
      "step": 59060
    },
    {
      "epoch": 18.225856217216908,
      "grad_norm": 0.002301956759765744,
      "learning_rate": 3.1774143782783095e-05,
      "loss": 0.0001,
      "step": 59070
    },
    {
      "epoch": 18.228941684665227,
      "grad_norm": 0.005033104680478573,
      "learning_rate": 3.177105831533477e-05,
      "loss": 0.0226,
      "step": 59080
    },
    {
      "epoch": 18.232027152113545,
      "grad_norm": 0.15316402912139893,
      "learning_rate": 3.176797284788646e-05,
      "loss": 0.0001,
      "step": 59090
    },
    {
      "epoch": 18.235112619561864,
      "grad_norm": 2.3419699573423713e-05,
      "learning_rate": 3.1764887380438136e-05,
      "loss": 0.0011,
      "step": 59100
    },
    {
      "epoch": 18.238198087010183,
      "grad_norm": 0.022012799978256226,
      "learning_rate": 3.176180191298982e-05,
      "loss": 0.0,
      "step": 59110
    },
    {
      "epoch": 18.2412835544585,
      "grad_norm": 0.0557396337389946,
      "learning_rate": 3.17587164455415e-05,
      "loss": 0.0006,
      "step": 59120
    },
    {
      "epoch": 18.24436902190682,
      "grad_norm": 0.01678454503417015,
      "learning_rate": 3.175563097809318e-05,
      "loss": 0.0003,
      "step": 59130
    },
    {
      "epoch": 18.24745448935514,
      "grad_norm": 0.33255741000175476,
      "learning_rate": 3.1752545510644865e-05,
      "loss": 0.0006,
      "step": 59140
    },
    {
      "epoch": 18.250539956803454,
      "grad_norm": 1.9229196368542034e-06,
      "learning_rate": 3.174946004319654e-05,
      "loss": 0.001,
      "step": 59150
    },
    {
      "epoch": 18.253625424251773,
      "grad_norm": 0.022592395544052124,
      "learning_rate": 3.174637457574823e-05,
      "loss": 0.0,
      "step": 59160
    },
    {
      "epoch": 18.25671089170009,
      "grad_norm": 0.00739162927493453,
      "learning_rate": 3.1743289108299906e-05,
      "loss": 0.0014,
      "step": 59170
    },
    {
      "epoch": 18.25979635914841,
      "grad_norm": 0.0004049447597935796,
      "learning_rate": 3.174020364085159e-05,
      "loss": 0.0005,
      "step": 59180
    },
    {
      "epoch": 18.26288182659673,
      "grad_norm": 0.0005894005880691111,
      "learning_rate": 3.173711817340327e-05,
      "loss": 0.0024,
      "step": 59190
    },
    {
      "epoch": 18.265967294045048,
      "grad_norm": 0.02174416370689869,
      "learning_rate": 3.1734032705954954e-05,
      "loss": 0.0002,
      "step": 59200
    },
    {
      "epoch": 18.269052761493366,
      "grad_norm": 0.051214128732681274,
      "learning_rate": 3.1730947238506636e-05,
      "loss": 0.0,
      "step": 59210
    },
    {
      "epoch": 18.272138228941685,
      "grad_norm": 0.008066496811807156,
      "learning_rate": 3.172786177105831e-05,
      "loss": 0.0027,
      "step": 59220
    },
    {
      "epoch": 18.275223696390004,
      "grad_norm": 0.0016661856789141893,
      "learning_rate": 3.172477630361e-05,
      "loss": 0.0,
      "step": 59230
    },
    {
      "epoch": 18.278309163838323,
      "grad_norm": 0.02799335867166519,
      "learning_rate": 3.1721690836161683e-05,
      "loss": 0.0003,
      "step": 59240
    },
    {
      "epoch": 18.28139463128664,
      "grad_norm": 0.004867450799793005,
      "learning_rate": 3.171860536871336e-05,
      "loss": 0.0,
      "step": 59250
    },
    {
      "epoch": 18.28448009873496,
      "grad_norm": 0.006480088923126459,
      "learning_rate": 3.171551990126505e-05,
      "loss": 0.0017,
      "step": 59260
    },
    {
      "epoch": 18.287565566183275,
      "grad_norm": 0.7454094886779785,
      "learning_rate": 3.1712434433816724e-05,
      "loss": 0.009,
      "step": 59270
    },
    {
      "epoch": 18.290651033631594,
      "grad_norm": 0.00023429883003700525,
      "learning_rate": 3.1709348966368407e-05,
      "loss": 0.0001,
      "step": 59280
    },
    {
      "epoch": 18.293736501079913,
      "grad_norm": 0.0006567279924638569,
      "learning_rate": 3.170626349892009e-05,
      "loss": 0.0013,
      "step": 59290
    },
    {
      "epoch": 18.29682196852823,
      "grad_norm": 0.12554064393043518,
      "learning_rate": 3.170317803147177e-05,
      "loss": 0.0051,
      "step": 59300
    },
    {
      "epoch": 18.29990743597655,
      "grad_norm": 0.00241855438798666,
      "learning_rate": 3.1700092564023454e-05,
      "loss": 0.0002,
      "step": 59310
    },
    {
      "epoch": 18.30299290342487,
      "grad_norm": 0.0013380920281633735,
      "learning_rate": 3.169700709657513e-05,
      "loss": 0.0011,
      "step": 59320
    },
    {
      "epoch": 18.306078370873188,
      "grad_norm": 0.001603878801688552,
      "learning_rate": 3.169392162912682e-05,
      "loss": 0.0001,
      "step": 59330
    },
    {
      "epoch": 18.309163838321506,
      "grad_norm": 0.006557852029800415,
      "learning_rate": 3.1690836161678495e-05,
      "loss": 0.0021,
      "step": 59340
    },
    {
      "epoch": 18.312249305769825,
      "grad_norm": 0.007865495048463345,
      "learning_rate": 3.168775069423018e-05,
      "loss": 0.0156,
      "step": 59350
    },
    {
      "epoch": 18.315334773218144,
      "grad_norm": 0.0009286910062655807,
      "learning_rate": 3.168466522678186e-05,
      "loss": 0.0003,
      "step": 59360
    },
    {
      "epoch": 18.318420240666462,
      "grad_norm": 0.019859956577420235,
      "learning_rate": 3.168157975933354e-05,
      "loss": 0.0005,
      "step": 59370
    },
    {
      "epoch": 18.321505708114778,
      "grad_norm": 0.002351726172491908,
      "learning_rate": 3.1678494291885225e-05,
      "loss": 0.0007,
      "step": 59380
    },
    {
      "epoch": 18.324591175563096,
      "grad_norm": 0.19805389642715454,
      "learning_rate": 3.16754088244369e-05,
      "loss": 0.0039,
      "step": 59390
    },
    {
      "epoch": 18.327676643011415,
      "grad_norm": 0.0015034284442663193,
      "learning_rate": 3.167232335698859e-05,
      "loss": 0.0058,
      "step": 59400
    },
    {
      "epoch": 18.330762110459734,
      "grad_norm": 0.058171167969703674,
      "learning_rate": 3.1669237889540265e-05,
      "loss": 0.0019,
      "step": 59410
    },
    {
      "epoch": 18.333847577908053,
      "grad_norm": 0.001511895563453436,
      "learning_rate": 3.166615242209195e-05,
      "loss": 0.0001,
      "step": 59420
    },
    {
      "epoch": 18.33693304535637,
      "grad_norm": 0.0012461580336093903,
      "learning_rate": 3.166306695464363e-05,
      "loss": 0.0008,
      "step": 59430
    },
    {
      "epoch": 18.34001851280469,
      "grad_norm": 1.4626905918121338,
      "learning_rate": 3.165998148719531e-05,
      "loss": 0.0123,
      "step": 59440
    },
    {
      "epoch": 18.34310398025301,
      "grad_norm": 0.0027816484216600657,
      "learning_rate": 3.1656896019746995e-05,
      "loss": 0.0009,
      "step": 59450
    },
    {
      "epoch": 18.346189447701327,
      "grad_norm": 0.0019106976687908173,
      "learning_rate": 3.165381055229867e-05,
      "loss": 0.0003,
      "step": 59460
    },
    {
      "epoch": 18.349274915149646,
      "grad_norm": 8.181772864190862e-05,
      "learning_rate": 3.165072508485036e-05,
      "loss": 0.0009,
      "step": 59470
    },
    {
      "epoch": 18.352360382597965,
      "grad_norm": 0.0028350765351206064,
      "learning_rate": 3.1647639617402036e-05,
      "loss": 0.0001,
      "step": 59480
    },
    {
      "epoch": 18.355445850046284,
      "grad_norm": 0.01820061355829239,
      "learning_rate": 3.164455414995372e-05,
      "loss": 0.0002,
      "step": 59490
    },
    {
      "epoch": 18.3585313174946,
      "grad_norm": 3.516784191131592,
      "learning_rate": 3.16414686825054e-05,
      "loss": 0.0019,
      "step": 59500
    },
    {
      "epoch": 18.361616784942917,
      "grad_norm": 3.774597406387329,
      "learning_rate": 3.163838321505708e-05,
      "loss": 0.0047,
      "step": 59510
    },
    {
      "epoch": 18.364702252391236,
      "grad_norm": 0.00020413741003721952,
      "learning_rate": 3.1635297747608766e-05,
      "loss": 0.0068,
      "step": 59520
    },
    {
      "epoch": 18.367787719839555,
      "grad_norm": 0.7346348166465759,
      "learning_rate": 3.163221228016045e-05,
      "loss": 0.0014,
      "step": 59530
    },
    {
      "epoch": 18.370873187287874,
      "grad_norm": 3.6420366764068604,
      "learning_rate": 3.162912681271213e-05,
      "loss": 0.0031,
      "step": 59540
    },
    {
      "epoch": 18.373958654736192,
      "grad_norm": 8.402840467169881e-05,
      "learning_rate": 3.1626041345263806e-05,
      "loss": 0.0065,
      "step": 59550
    },
    {
      "epoch": 18.37704412218451,
      "grad_norm": 0.00034392831730656326,
      "learning_rate": 3.162295587781549e-05,
      "loss": 0.0009,
      "step": 59560
    },
    {
      "epoch": 18.38012958963283,
      "grad_norm": 0.002802920760586858,
      "learning_rate": 3.161987041036717e-05,
      "loss": 0.0007,
      "step": 59570
    },
    {
      "epoch": 18.38321505708115,
      "grad_norm": 4.9969818064710125e-05,
      "learning_rate": 3.1616784942918854e-05,
      "loss": 0.0004,
      "step": 59580
    },
    {
      "epoch": 18.386300524529467,
      "grad_norm": 0.01437768992036581,
      "learning_rate": 3.1613699475470536e-05,
      "loss": 0.0008,
      "step": 59590
    },
    {
      "epoch": 18.389385991977786,
      "grad_norm": 0.0009399396367371082,
      "learning_rate": 3.161061400802222e-05,
      "loss": 0.0006,
      "step": 59600
    },
    {
      "epoch": 18.392471459426105,
      "grad_norm": 0.02358679473400116,
      "learning_rate": 3.16075285405739e-05,
      "loss": 0.0031,
      "step": 59610
    },
    {
      "epoch": 18.39555692687442,
      "grad_norm": 0.6735307574272156,
      "learning_rate": 3.160444307312558e-05,
      "loss": 0.0015,
      "step": 59620
    },
    {
      "epoch": 18.39864239432274,
      "grad_norm": 0.0005244374042376876,
      "learning_rate": 3.160135760567726e-05,
      "loss": 0.0011,
      "step": 59630
    },
    {
      "epoch": 18.401727861771057,
      "grad_norm": 0.014067099429666996,
      "learning_rate": 3.159827213822895e-05,
      "loss": 0.0003,
      "step": 59640
    },
    {
      "epoch": 18.404813329219376,
      "grad_norm": 0.006918300874531269,
      "learning_rate": 3.1595186670780624e-05,
      "loss": 0.0037,
      "step": 59650
    },
    {
      "epoch": 18.407898796667695,
      "grad_norm": 2.452256558171939e-05,
      "learning_rate": 3.159210120333231e-05,
      "loss": 0.0012,
      "step": 59660
    },
    {
      "epoch": 18.410984264116014,
      "grad_norm": 0.0001597426162334159,
      "learning_rate": 3.158901573588399e-05,
      "loss": 0.0001,
      "step": 59670
    },
    {
      "epoch": 18.414069731564332,
      "grad_norm": 0.019870756193995476,
      "learning_rate": 3.158593026843567e-05,
      "loss": 0.0012,
      "step": 59680
    },
    {
      "epoch": 18.41715519901265,
      "grad_norm": 0.00017778543406166136,
      "learning_rate": 3.158284480098735e-05,
      "loss": 0.0001,
      "step": 59690
    },
    {
      "epoch": 18.42024066646097,
      "grad_norm": 0.0012119379825890064,
      "learning_rate": 3.157975933353903e-05,
      "loss": 0.0003,
      "step": 59700
    },
    {
      "epoch": 18.42332613390929,
      "grad_norm": 0.0013083514058962464,
      "learning_rate": 3.157667386609072e-05,
      "loss": 0.001,
      "step": 59710
    },
    {
      "epoch": 18.426411601357607,
      "grad_norm": 5.7734534493647516e-05,
      "learning_rate": 3.1573588398642395e-05,
      "loss": 0.0016,
      "step": 59720
    },
    {
      "epoch": 18.429497068805922,
      "grad_norm": 0.0008989508496597409,
      "learning_rate": 3.157050293119408e-05,
      "loss": 0.0,
      "step": 59730
    },
    {
      "epoch": 18.43258253625424,
      "grad_norm": 0.0002995696850121021,
      "learning_rate": 3.156741746374576e-05,
      "loss": 0.0002,
      "step": 59740
    },
    {
      "epoch": 18.43566800370256,
      "grad_norm": 0.19506552815437317,
      "learning_rate": 3.156433199629744e-05,
      "loss": 0.0001,
      "step": 59750
    },
    {
      "epoch": 18.43875347115088,
      "grad_norm": 0.10536926239728928,
      "learning_rate": 3.156124652884912e-05,
      "loss": 0.001,
      "step": 59760
    },
    {
      "epoch": 18.441838938599197,
      "grad_norm": 0.0013672704808413982,
      "learning_rate": 3.15581610614008e-05,
      "loss": 0.0057,
      "step": 59770
    },
    {
      "epoch": 18.444924406047516,
      "grad_norm": 2.1943719387054443,
      "learning_rate": 3.155507559395249e-05,
      "loss": 0.0012,
      "step": 59780
    },
    {
      "epoch": 18.448009873495835,
      "grad_norm": 0.00013161911920178682,
      "learning_rate": 3.1551990126504165e-05,
      "loss": 0.0009,
      "step": 59790
    },
    {
      "epoch": 18.451095340944153,
      "grad_norm": 0.0036090428475290537,
      "learning_rate": 3.154890465905585e-05,
      "loss": 0.0004,
      "step": 59800
    },
    {
      "epoch": 18.454180808392472,
      "grad_norm": 0.40341201424598694,
      "learning_rate": 3.154581919160753e-05,
      "loss": 0.0067,
      "step": 59810
    },
    {
      "epoch": 18.45726627584079,
      "grad_norm": 2.5068995455512777e-05,
      "learning_rate": 3.154273372415921e-05,
      "loss": 0.0009,
      "step": 59820
    },
    {
      "epoch": 18.46035174328911,
      "grad_norm": 0.0001255708048120141,
      "learning_rate": 3.153964825671089e-05,
      "loss": 0.0012,
      "step": 59830
    },
    {
      "epoch": 18.46343721073743,
      "grad_norm": 1.8942953829537146e-05,
      "learning_rate": 3.153656278926258e-05,
      "loss": 0.0005,
      "step": 59840
    },
    {
      "epoch": 18.466522678185743,
      "grad_norm": 0.0008405534899793565,
      "learning_rate": 3.153347732181426e-05,
      "loss": 0.0069,
      "step": 59850
    },
    {
      "epoch": 18.469608145634062,
      "grad_norm": 0.00013260623381938785,
      "learning_rate": 3.1530391854365936e-05,
      "loss": 0.0,
      "step": 59860
    },
    {
      "epoch": 18.47269361308238,
      "grad_norm": 0.03423331677913666,
      "learning_rate": 3.152730638691762e-05,
      "loss": 0.0002,
      "step": 59870
    },
    {
      "epoch": 18.4757790805307,
      "grad_norm": 0.007518945261836052,
      "learning_rate": 3.15242209194693e-05,
      "loss": 0.0017,
      "step": 59880
    },
    {
      "epoch": 18.47886454797902,
      "grad_norm": 0.0063855005428195,
      "learning_rate": 3.1521135452020983e-05,
      "loss": 0.0,
      "step": 59890
    },
    {
      "epoch": 18.481950015427337,
      "grad_norm": 0.1611274629831314,
      "learning_rate": 3.151804998457266e-05,
      "loss": 0.0001,
      "step": 59900
    },
    {
      "epoch": 18.485035482875656,
      "grad_norm": 3.3182939660036936e-05,
      "learning_rate": 3.151496451712435e-05,
      "loss": 0.0101,
      "step": 59910
    },
    {
      "epoch": 18.488120950323975,
      "grad_norm": 0.000851346121635288,
      "learning_rate": 3.151187904967603e-05,
      "loss": 0.0051,
      "step": 59920
    },
    {
      "epoch": 18.491206417772293,
      "grad_norm": 0.914197564125061,
      "learning_rate": 3.1508793582227707e-05,
      "loss": 0.0011,
      "step": 59930
    },
    {
      "epoch": 18.494291885220612,
      "grad_norm": 0.012416674755513668,
      "learning_rate": 3.150570811477939e-05,
      "loss": 0.0072,
      "step": 59940
    },
    {
      "epoch": 18.49737735266893,
      "grad_norm": 0.0006481021991930902,
      "learning_rate": 3.150262264733107e-05,
      "loss": 0.0068,
      "step": 59950
    },
    {
      "epoch": 18.50046282011725,
      "grad_norm": 0.0020664664916694164,
      "learning_rate": 3.1499537179882754e-05,
      "loss": 0.0001,
      "step": 59960
    },
    {
      "epoch": 18.503548287565565,
      "grad_norm": 0.01648324728012085,
      "learning_rate": 3.149645171243443e-05,
      "loss": 0.0077,
      "step": 59970
    },
    {
      "epoch": 18.506633755013883,
      "grad_norm": 0.011341231875121593,
      "learning_rate": 3.149336624498612e-05,
      "loss": 0.0003,
      "step": 59980
    },
    {
      "epoch": 18.509719222462202,
      "grad_norm": 3.5785665204457473e-06,
      "learning_rate": 3.14902807775378e-05,
      "loss": 0.0001,
      "step": 59990
    },
    {
      "epoch": 18.51280468991052,
      "grad_norm": 0.07712330669164658,
      "learning_rate": 3.148719531008948e-05,
      "loss": 0.0007,
      "step": 60000
    },
    {
      "epoch": 18.51589015735884,
      "grad_norm": 0.016761459410190582,
      "learning_rate": 3.148410984264116e-05,
      "loss": 0.0028,
      "step": 60010
    },
    {
      "epoch": 18.518975624807158,
      "grad_norm": 0.0007822188199497759,
      "learning_rate": 3.148102437519284e-05,
      "loss": 0.0003,
      "step": 60020
    },
    {
      "epoch": 18.522061092255477,
      "grad_norm": 0.017596114426851273,
      "learning_rate": 3.1477938907744525e-05,
      "loss": 0.0029,
      "step": 60030
    },
    {
      "epoch": 18.525146559703796,
      "grad_norm": 0.01413209643214941,
      "learning_rate": 3.14748534402962e-05,
      "loss": 0.0,
      "step": 60040
    },
    {
      "epoch": 18.528232027152114,
      "grad_norm": 0.0010458295000717044,
      "learning_rate": 3.147176797284789e-05,
      "loss": 0.0004,
      "step": 60050
    },
    {
      "epoch": 18.531317494600433,
      "grad_norm": 2.8666203022003174,
      "learning_rate": 3.146868250539957e-05,
      "loss": 0.0085,
      "step": 60060
    },
    {
      "epoch": 18.534402962048752,
      "grad_norm": 0.002597765764221549,
      "learning_rate": 3.146559703795125e-05,
      "loss": 0.0002,
      "step": 60070
    },
    {
      "epoch": 18.537488429497067,
      "grad_norm": 0.003707698080688715,
      "learning_rate": 3.146251157050294e-05,
      "loss": 0.0004,
      "step": 60080
    },
    {
      "epoch": 18.540573896945386,
      "grad_norm": 5.344125383999199e-05,
      "learning_rate": 3.145942610305461e-05,
      "loss": 0.0005,
      "step": 60090
    },
    {
      "epoch": 18.543659364393704,
      "grad_norm": 0.00043571804417297244,
      "learning_rate": 3.1456340635606295e-05,
      "loss": 0.0043,
      "step": 60100
    },
    {
      "epoch": 18.546744831842023,
      "grad_norm": 9.609288099454716e-06,
      "learning_rate": 3.145325516815798e-05,
      "loss": 0.0001,
      "step": 60110
    },
    {
      "epoch": 18.549830299290342,
      "grad_norm": 0.45254409313201904,
      "learning_rate": 3.145016970070966e-05,
      "loss": 0.0025,
      "step": 60120
    },
    {
      "epoch": 18.55291576673866,
      "grad_norm": 0.051431477069854736,
      "learning_rate": 3.144708423326134e-05,
      "loss": 0.007,
      "step": 60130
    },
    {
      "epoch": 18.55600123418698,
      "grad_norm": 6.868588388897479e-05,
      "learning_rate": 3.144399876581302e-05,
      "loss": 0.0001,
      "step": 60140
    },
    {
      "epoch": 18.559086701635298,
      "grad_norm": 0.0002133255184162408,
      "learning_rate": 3.144091329836471e-05,
      "loss": 0.0025,
      "step": 60150
    },
    {
      "epoch": 18.562172169083617,
      "grad_norm": 0.0004259778361301869,
      "learning_rate": 3.143782783091638e-05,
      "loss": 0.0,
      "step": 60160
    },
    {
      "epoch": 18.565257636531936,
      "grad_norm": 0.0015452360967174172,
      "learning_rate": 3.1434742363468066e-05,
      "loss": 0.0002,
      "step": 60170
    },
    {
      "epoch": 18.568343103980254,
      "grad_norm": 0.012556626461446285,
      "learning_rate": 3.143165689601975e-05,
      "loss": 0.0003,
      "step": 60180
    },
    {
      "epoch": 18.571428571428573,
      "grad_norm": 6.223766831681132e-06,
      "learning_rate": 3.142857142857143e-05,
      "loss": 0.0,
      "step": 60190
    },
    {
      "epoch": 18.57451403887689,
      "grad_norm": 0.0002017332153627649,
      "learning_rate": 3.142548596112311e-05,
      "loss": 0.0,
      "step": 60200
    },
    {
      "epoch": 18.577599506325207,
      "grad_norm": 0.0033861761912703514,
      "learning_rate": 3.142240049367479e-05,
      "loss": 0.0002,
      "step": 60210
    },
    {
      "epoch": 18.580684973773526,
      "grad_norm": 0.00012307097495067865,
      "learning_rate": 3.141931502622648e-05,
      "loss": 0.0001,
      "step": 60220
    },
    {
      "epoch": 18.583770441221844,
      "grad_norm": 4.9037509597837925e-05,
      "learning_rate": 3.1416229558778154e-05,
      "loss": 0.0011,
      "step": 60230
    },
    {
      "epoch": 18.586855908670163,
      "grad_norm": 0.006600342225283384,
      "learning_rate": 3.1413144091329836e-05,
      "loss": 0.0031,
      "step": 60240
    },
    {
      "epoch": 18.58994137611848,
      "grad_norm": 0.0020420465152710676,
      "learning_rate": 3.141005862388152e-05,
      "loss": 0.0001,
      "step": 60250
    },
    {
      "epoch": 18.5930268435668,
      "grad_norm": 0.012527262791991234,
      "learning_rate": 3.14069731564332e-05,
      "loss": 0.0004,
      "step": 60260
    },
    {
      "epoch": 18.59611231101512,
      "grad_norm": 0.016719017177820206,
      "learning_rate": 3.1403887688984884e-05,
      "loss": 0.0,
      "step": 60270
    },
    {
      "epoch": 18.599197778463438,
      "grad_norm": 1.6050300473580137e-05,
      "learning_rate": 3.140080222153656e-05,
      "loss": 0.0035,
      "step": 60280
    },
    {
      "epoch": 18.602283245911757,
      "grad_norm": 0.002307618735358119,
      "learning_rate": 3.139771675408825e-05,
      "loss": 0.0001,
      "step": 60290
    },
    {
      "epoch": 18.605368713360075,
      "grad_norm": 0.00030682916985824704,
      "learning_rate": 3.1394631286639924e-05,
      "loss": 0.0,
      "step": 60300
    },
    {
      "epoch": 18.608454180808394,
      "grad_norm": 0.10087060183286667,
      "learning_rate": 3.139154581919161e-05,
      "loss": 0.0074,
      "step": 60310
    },
    {
      "epoch": 18.61153964825671,
      "grad_norm": 0.002479193964973092,
      "learning_rate": 3.1388460351743296e-05,
      "loss": 0.0013,
      "step": 60320
    },
    {
      "epoch": 18.614625115705028,
      "grad_norm": 2.227713108062744,
      "learning_rate": 3.138537488429497e-05,
      "loss": 0.0029,
      "step": 60330
    },
    {
      "epoch": 18.617710583153347,
      "grad_norm": 0.00018284823454450816,
      "learning_rate": 3.1382289416846654e-05,
      "loss": 0.0083,
      "step": 60340
    },
    {
      "epoch": 18.620796050601665,
      "grad_norm": 1.3482325812219642e-05,
      "learning_rate": 3.137920394939834e-05,
      "loss": 0.0013,
      "step": 60350
    },
    {
      "epoch": 18.623881518049984,
      "grad_norm": 0.041337911039590836,
      "learning_rate": 3.137611848195002e-05,
      "loss": 0.0033,
      "step": 60360
    },
    {
      "epoch": 18.626966985498303,
      "grad_norm": 0.03711511194705963,
      "learning_rate": 3.1373033014501695e-05,
      "loss": 0.0012,
      "step": 60370
    },
    {
      "epoch": 18.63005245294662,
      "grad_norm": 0.00017496422515250742,
      "learning_rate": 3.136994754705338e-05,
      "loss": 0.0019,
      "step": 60380
    },
    {
      "epoch": 18.63313792039494,
      "grad_norm": 0.00048171126400120556,
      "learning_rate": 3.136686207960507e-05,
      "loss": 0.0032,
      "step": 60390
    },
    {
      "epoch": 18.63622338784326,
      "grad_norm": 0.484835684299469,
      "learning_rate": 3.136377661215674e-05,
      "loss": 0.0015,
      "step": 60400
    },
    {
      "epoch": 18.639308855291578,
      "grad_norm": 0.09481346607208252,
      "learning_rate": 3.1360691144708425e-05,
      "loss": 0.0002,
      "step": 60410
    },
    {
      "epoch": 18.642394322739896,
      "grad_norm": 0.0029063564725220203,
      "learning_rate": 3.135760567726011e-05,
      "loss": 0.0037,
      "step": 60420
    },
    {
      "epoch": 18.645479790188215,
      "grad_norm": 0.00014684053894598037,
      "learning_rate": 3.135452020981179e-05,
      "loss": 0.0003,
      "step": 60430
    },
    {
      "epoch": 18.64856525763653,
      "grad_norm": 0.005581308621913195,
      "learning_rate": 3.1351434742363465e-05,
      "loss": 0.0003,
      "step": 60440
    },
    {
      "epoch": 18.65165072508485,
      "grad_norm": 0.0022597291972488165,
      "learning_rate": 3.134834927491515e-05,
      "loss": 0.0,
      "step": 60450
    },
    {
      "epoch": 18.654736192533168,
      "grad_norm": 2.1276955521898344e-05,
      "learning_rate": 3.134526380746684e-05,
      "loss": 0.0016,
      "step": 60460
    },
    {
      "epoch": 18.657821659981487,
      "grad_norm": 0.00013764388859272003,
      "learning_rate": 3.134217834001851e-05,
      "loss": 0.0003,
      "step": 60470
    },
    {
      "epoch": 18.660907127429805,
      "grad_norm": 0.0016483545769006014,
      "learning_rate": 3.1339092872570195e-05,
      "loss": 0.0092,
      "step": 60480
    },
    {
      "epoch": 18.663992594878124,
      "grad_norm": 3.1762499809265137,
      "learning_rate": 3.133600740512188e-05,
      "loss": 0.0021,
      "step": 60490
    },
    {
      "epoch": 18.667078062326443,
      "grad_norm": 0.0005092429928481579,
      "learning_rate": 3.133292193767356e-05,
      "loss": 0.0003,
      "step": 60500
    },
    {
      "epoch": 18.67016352977476,
      "grad_norm": 0.211385577917099,
      "learning_rate": 3.132983647022524e-05,
      "loss": 0.0058,
      "step": 60510
    },
    {
      "epoch": 18.67324899722308,
      "grad_norm": 0.0039213877171278,
      "learning_rate": 3.132675100277692e-05,
      "loss": 0.0011,
      "step": 60520
    },
    {
      "epoch": 18.6763344646714,
      "grad_norm": 3.04522967338562,
      "learning_rate": 3.132366553532861e-05,
      "loss": 0.0069,
      "step": 60530
    },
    {
      "epoch": 18.679419932119718,
      "grad_norm": 0.0015688141575083137,
      "learning_rate": 3.1320580067880283e-05,
      "loss": 0.0002,
      "step": 60540
    },
    {
      "epoch": 18.682505399568036,
      "grad_norm": 0.000664804654661566,
      "learning_rate": 3.1317494600431966e-05,
      "loss": 0.0027,
      "step": 60550
    },
    {
      "epoch": 18.68559086701635,
      "grad_norm": 0.0007029882399365306,
      "learning_rate": 3.131440913298365e-05,
      "loss": 0.0005,
      "step": 60560
    },
    {
      "epoch": 18.68867633446467,
      "grad_norm": 7.522408122895285e-05,
      "learning_rate": 3.131132366553533e-05,
      "loss": 0.0005,
      "step": 60570
    },
    {
      "epoch": 18.69176180191299,
      "grad_norm": 0.11121904850006104,
      "learning_rate": 3.130823819808701e-05,
      "loss": 0.0002,
      "step": 60580
    },
    {
      "epoch": 18.694847269361308,
      "grad_norm": 0.00041263512684963644,
      "learning_rate": 3.1305152730638696e-05,
      "loss": 0.0081,
      "step": 60590
    },
    {
      "epoch": 18.697932736809626,
      "grad_norm": 0.0017965195002034307,
      "learning_rate": 3.130206726319038e-05,
      "loss": 0.0001,
      "step": 60600
    },
    {
      "epoch": 18.701018204257945,
      "grad_norm": 5.967686593066901e-05,
      "learning_rate": 3.1298981795742054e-05,
      "loss": 0.0011,
      "step": 60610
    },
    {
      "epoch": 18.704103671706264,
      "grad_norm": 0.00013427539670374244,
      "learning_rate": 3.1295896328293737e-05,
      "loss": 0.0024,
      "step": 60620
    },
    {
      "epoch": 18.707189139154583,
      "grad_norm": 0.0011372559238225222,
      "learning_rate": 3.129281086084542e-05,
      "loss": 0.0002,
      "step": 60630
    },
    {
      "epoch": 18.7102746066029,
      "grad_norm": 1.7524787187576294,
      "learning_rate": 3.12897253933971e-05,
      "loss": 0.0041,
      "step": 60640
    },
    {
      "epoch": 18.71336007405122,
      "grad_norm": 0.010279824025928974,
      "learning_rate": 3.1286639925948784e-05,
      "loss": 0.0127,
      "step": 60650
    },
    {
      "epoch": 18.71644554149954,
      "grad_norm": 5.130208137416048e-06,
      "learning_rate": 3.1283554458500466e-05,
      "loss": 0.0,
      "step": 60660
    },
    {
      "epoch": 18.719531008947854,
      "grad_norm": 0.00021871746866963804,
      "learning_rate": 3.128046899105215e-05,
      "loss": 0.0,
      "step": 60670
    },
    {
      "epoch": 18.722616476396173,
      "grad_norm": 0.007660301867872477,
      "learning_rate": 3.1277383523603825e-05,
      "loss": 0.0007,
      "step": 60680
    },
    {
      "epoch": 18.72570194384449,
      "grad_norm": 0.003925866913050413,
      "learning_rate": 3.127429805615551e-05,
      "loss": 0.002,
      "step": 60690
    },
    {
      "epoch": 18.72878741129281,
      "grad_norm": 5.089303272143297e-07,
      "learning_rate": 3.127121258870719e-05,
      "loss": 0.0,
      "step": 60700
    },
    {
      "epoch": 18.73187287874113,
      "grad_norm": 0.0001863984507508576,
      "learning_rate": 3.126812712125887e-05,
      "loss": 0.0018,
      "step": 60710
    },
    {
      "epoch": 18.734958346189448,
      "grad_norm": 0.5913718938827515,
      "learning_rate": 3.1265041653810555e-05,
      "loss": 0.002,
      "step": 60720
    },
    {
      "epoch": 18.738043813637766,
      "grad_norm": 0.0012362560955807567,
      "learning_rate": 3.126195618636224e-05,
      "loss": 0.0014,
      "step": 60730
    },
    {
      "epoch": 18.741129281086085,
      "grad_norm": 0.000534455175511539,
      "learning_rate": 3.125887071891392e-05,
      "loss": 0.0001,
      "step": 60740
    },
    {
      "epoch": 18.744214748534404,
      "grad_norm": 0.004189712926745415,
      "learning_rate": 3.1255785251465595e-05,
      "loss": 0.0002,
      "step": 60750
    },
    {
      "epoch": 18.747300215982722,
      "grad_norm": 0.02098155952990055,
      "learning_rate": 3.125269978401728e-05,
      "loss": 0.0006,
      "step": 60760
    },
    {
      "epoch": 18.75038568343104,
      "grad_norm": 0.0019186820136383176,
      "learning_rate": 3.124961431656896e-05,
      "loss": 0.0014,
      "step": 60770
    },
    {
      "epoch": 18.75347115087936,
      "grad_norm": 0.0011395943583920598,
      "learning_rate": 3.124652884912064e-05,
      "loss": 0.0031,
      "step": 60780
    },
    {
      "epoch": 18.756556618327675,
      "grad_norm": 1.8343006372451782,
      "learning_rate": 3.1243443381672325e-05,
      "loss": 0.006,
      "step": 60790
    },
    {
      "epoch": 18.759642085775994,
      "grad_norm": 0.03032301738858223,
      "learning_rate": 3.124035791422401e-05,
      "loss": 0.0007,
      "step": 60800
    },
    {
      "epoch": 18.762727553224313,
      "grad_norm": 9.861838043434545e-05,
      "learning_rate": 3.123727244677569e-05,
      "loss": 0.0002,
      "step": 60810
    },
    {
      "epoch": 18.76581302067263,
      "grad_norm": 0.0010125954868271947,
      "learning_rate": 3.1234186979327366e-05,
      "loss": 0.0104,
      "step": 60820
    },
    {
      "epoch": 18.76889848812095,
      "grad_norm": 0.0008356604375876486,
      "learning_rate": 3.1231101511879055e-05,
      "loss": 0.0007,
      "step": 60830
    },
    {
      "epoch": 18.77198395556927,
      "grad_norm": 0.0021396621596068144,
      "learning_rate": 3.122801604443073e-05,
      "loss": 0.0003,
      "step": 60840
    },
    {
      "epoch": 18.775069423017587,
      "grad_norm": 0.12030940502882004,
      "learning_rate": 3.122493057698241e-05,
      "loss": 0.0024,
      "step": 60850
    },
    {
      "epoch": 18.778154890465906,
      "grad_norm": 0.000927338027395308,
      "learning_rate": 3.1221845109534096e-05,
      "loss": 0.0,
      "step": 60860
    },
    {
      "epoch": 18.781240357914225,
      "grad_norm": 0.0001252810616279021,
      "learning_rate": 3.121875964208578e-05,
      "loss": 0.0011,
      "step": 60870
    },
    {
      "epoch": 18.784325825362544,
      "grad_norm": 0.04879359155893326,
      "learning_rate": 3.121567417463746e-05,
      "loss": 0.0016,
      "step": 60880
    },
    {
      "epoch": 18.787411292810862,
      "grad_norm": 0.009701935574412346,
      "learning_rate": 3.1212588707189136e-05,
      "loss": 0.0001,
      "step": 60890
    },
    {
      "epoch": 18.79049676025918,
      "grad_norm": 0.0019435732392594218,
      "learning_rate": 3.1209503239740826e-05,
      "loss": 0.0001,
      "step": 60900
    },
    {
      "epoch": 18.793582227707496,
      "grad_norm": 0.2834005355834961,
      "learning_rate": 3.12064177722925e-05,
      "loss": 0.0144,
      "step": 60910
    },
    {
      "epoch": 18.796667695155815,
      "grad_norm": 0.0028335633687675,
      "learning_rate": 3.1203332304844184e-05,
      "loss": 0.0002,
      "step": 60920
    },
    {
      "epoch": 18.799753162604134,
      "grad_norm": 0.00013421534094959497,
      "learning_rate": 3.1200246837395866e-05,
      "loss": 0.0001,
      "step": 60930
    },
    {
      "epoch": 18.802838630052452,
      "grad_norm": 0.011957583017647266,
      "learning_rate": 3.119716136994755e-05,
      "loss": 0.0008,
      "step": 60940
    },
    {
      "epoch": 18.80592409750077,
      "grad_norm": 0.011195821687579155,
      "learning_rate": 3.119407590249923e-05,
      "loss": 0.0009,
      "step": 60950
    },
    {
      "epoch": 18.80900956494909,
      "grad_norm": 0.016342811286449432,
      "learning_rate": 3.119099043505091e-05,
      "loss": 0.0001,
      "step": 60960
    },
    {
      "epoch": 18.81209503239741,
      "grad_norm": 1.0677329555619508e-05,
      "learning_rate": 3.1187904967602596e-05,
      "loss": 0.003,
      "step": 60970
    },
    {
      "epoch": 18.815180499845727,
      "grad_norm": 0.0218521635979414,
      "learning_rate": 3.118481950015428e-05,
      "loss": 0.0003,
      "step": 60980
    },
    {
      "epoch": 18.818265967294046,
      "grad_norm": 0.11172925680875778,
      "learning_rate": 3.1181734032705954e-05,
      "loss": 0.0006,
      "step": 60990
    },
    {
      "epoch": 18.821351434742365,
      "grad_norm": 0.11417888849973679,
      "learning_rate": 3.117864856525764e-05,
      "loss": 0.0011,
      "step": 61000
    },
    {
      "epoch": 18.824436902190683,
      "grad_norm": 1.6019409894943237,
      "learning_rate": 3.117556309780932e-05,
      "loss": 0.0009,
      "step": 61010
    },
    {
      "epoch": 18.827522369639,
      "grad_norm": 0.0011174489045515656,
      "learning_rate": 3.1172477630361e-05,
      "loss": 0.0001,
      "step": 61020
    },
    {
      "epoch": 18.830607837087317,
      "grad_norm": 0.007012822199612856,
      "learning_rate": 3.116939216291268e-05,
      "loss": 0.0028,
      "step": 61030
    },
    {
      "epoch": 18.833693304535636,
      "grad_norm": 0.0010245958110317588,
      "learning_rate": 3.116630669546437e-05,
      "loss": 0.0246,
      "step": 61040
    },
    {
      "epoch": 18.836778771983955,
      "grad_norm": 0.0019969535060226917,
      "learning_rate": 3.116322122801605e-05,
      "loss": 0.0003,
      "step": 61050
    },
    {
      "epoch": 18.839864239432274,
      "grad_norm": 0.0027032729703933,
      "learning_rate": 3.1160135760567725e-05,
      "loss": 0.0022,
      "step": 61060
    },
    {
      "epoch": 18.842949706880592,
      "grad_norm": 0.0008835979388095438,
      "learning_rate": 3.1157050293119414e-05,
      "loss": 0.001,
      "step": 61070
    },
    {
      "epoch": 18.84603517432891,
      "grad_norm": 0.0019332128576934338,
      "learning_rate": 3.115396482567109e-05,
      "loss": 0.0003,
      "step": 61080
    },
    {
      "epoch": 18.84912064177723,
      "grad_norm": 0.00018448891933076084,
      "learning_rate": 3.115087935822277e-05,
      "loss": 0.006,
      "step": 61090
    },
    {
      "epoch": 18.85220610922555,
      "grad_norm": 0.00016072019934654236,
      "learning_rate": 3.1147793890774455e-05,
      "loss": 0.0007,
      "step": 61100
    },
    {
      "epoch": 18.855291576673867,
      "grad_norm": 5.4815733165014535e-05,
      "learning_rate": 3.114470842332614e-05,
      "loss": 0.0005,
      "step": 61110
    },
    {
      "epoch": 18.858377044122186,
      "grad_norm": 9.072721695702057e-06,
      "learning_rate": 3.114162295587782e-05,
      "loss": 0.006,
      "step": 61120
    },
    {
      "epoch": 18.861462511570505,
      "grad_norm": 5.2218914788682014e-05,
      "learning_rate": 3.1138537488429495e-05,
      "loss": 0.0005,
      "step": 61130
    },
    {
      "epoch": 18.86454797901882,
      "grad_norm": 0.6878337264060974,
      "learning_rate": 3.1135452020981185e-05,
      "loss": 0.0007,
      "step": 61140
    },
    {
      "epoch": 18.86763344646714,
      "grad_norm": 0.007871638983488083,
      "learning_rate": 3.113236655353286e-05,
      "loss": 0.0004,
      "step": 61150
    },
    {
      "epoch": 18.870718913915457,
      "grad_norm": 2.0671252059401013e-05,
      "learning_rate": 3.112928108608454e-05,
      "loss": 0.0009,
      "step": 61160
    },
    {
      "epoch": 18.873804381363776,
      "grad_norm": 0.0004245045711286366,
      "learning_rate": 3.1126195618636225e-05,
      "loss": 0.0003,
      "step": 61170
    },
    {
      "epoch": 18.876889848812095,
      "grad_norm": 0.008781996555626392,
      "learning_rate": 3.112311015118791e-05,
      "loss": 0.0011,
      "step": 61180
    },
    {
      "epoch": 18.879975316260413,
      "grad_norm": 0.00030565893393941224,
      "learning_rate": 3.112002468373959e-05,
      "loss": 0.0005,
      "step": 61190
    },
    {
      "epoch": 18.883060783708732,
      "grad_norm": 1.3992156709718984e-05,
      "learning_rate": 3.1116939216291266e-05,
      "loss": 0.0002,
      "step": 61200
    },
    {
      "epoch": 18.88614625115705,
      "grad_norm": 0.001355930813588202,
      "learning_rate": 3.1113853748842955e-05,
      "loss": 0.0009,
      "step": 61210
    },
    {
      "epoch": 18.88923171860537,
      "grad_norm": 0.0003015093388967216,
      "learning_rate": 3.111076828139463e-05,
      "loss": 0.0025,
      "step": 61220
    },
    {
      "epoch": 18.89231718605369,
      "grad_norm": 0.04384112358093262,
      "learning_rate": 3.1107682813946313e-05,
      "loss": 0.0002,
      "step": 61230
    },
    {
      "epoch": 18.895402653502007,
      "grad_norm": 0.5927857756614685,
      "learning_rate": 3.1104597346497996e-05,
      "loss": 0.0009,
      "step": 61240
    },
    {
      "epoch": 18.898488120950326,
      "grad_norm": 7.876729796407744e-05,
      "learning_rate": 3.110151187904968e-05,
      "loss": 0.0001,
      "step": 61250
    },
    {
      "epoch": 18.90157358839864,
      "grad_norm": 0.5066462755203247,
      "learning_rate": 3.109842641160136e-05,
      "loss": 0.0005,
      "step": 61260
    },
    {
      "epoch": 18.90465905584696,
      "grad_norm": 5.426037387223914e-05,
      "learning_rate": 3.1095340944153037e-05,
      "loss": 0.0001,
      "step": 61270
    },
    {
      "epoch": 18.90774452329528,
      "grad_norm": 4.658791294787079e-05,
      "learning_rate": 3.1092255476704726e-05,
      "loss": 0.0002,
      "step": 61280
    },
    {
      "epoch": 18.910829990743597,
      "grad_norm": 0.0012867520563304424,
      "learning_rate": 3.10891700092564e-05,
      "loss": 0.0006,
      "step": 61290
    },
    {
      "epoch": 18.913915458191916,
      "grad_norm": 0.0001277352130273357,
      "learning_rate": 3.1086084541808084e-05,
      "loss": 0.0001,
      "step": 61300
    },
    {
      "epoch": 18.917000925640234,
      "grad_norm": 6.233596650417894e-05,
      "learning_rate": 3.1082999074359766e-05,
      "loss": 0.0003,
      "step": 61310
    },
    {
      "epoch": 18.920086393088553,
      "grad_norm": 4.278698543203063e-05,
      "learning_rate": 3.107991360691145e-05,
      "loss": 0.0001,
      "step": 61320
    },
    {
      "epoch": 18.923171860536872,
      "grad_norm": 0.0007792437099851668,
      "learning_rate": 3.107682813946313e-05,
      "loss": 0.0,
      "step": 61330
    },
    {
      "epoch": 18.92625732798519,
      "grad_norm": 0.0002094627998303622,
      "learning_rate": 3.1073742672014814e-05,
      "loss": 0.0005,
      "step": 61340
    },
    {
      "epoch": 18.92934279543351,
      "grad_norm": 2.6597581381793134e-05,
      "learning_rate": 3.1070657204566496e-05,
      "loss": 0.0016,
      "step": 61350
    },
    {
      "epoch": 18.932428262881828,
      "grad_norm": 3.229685535188764e-05,
      "learning_rate": 3.106757173711817e-05,
      "loss": 0.0001,
      "step": 61360
    },
    {
      "epoch": 18.935513730330143,
      "grad_norm": 0.007452548481523991,
      "learning_rate": 3.1064486269669855e-05,
      "loss": 0.0001,
      "step": 61370
    },
    {
      "epoch": 18.938599197778462,
      "grad_norm": 0.0003585787781048566,
      "learning_rate": 3.1061400802221544e-05,
      "loss": 0.0021,
      "step": 61380
    },
    {
      "epoch": 18.94168466522678,
      "grad_norm": 0.00474774744361639,
      "learning_rate": 3.105831533477322e-05,
      "loss": 0.0,
      "step": 61390
    },
    {
      "epoch": 18.9447701326751,
      "grad_norm": 0.0005456742946989834,
      "learning_rate": 3.10552298673249e-05,
      "loss": 0.0002,
      "step": 61400
    },
    {
      "epoch": 18.947855600123418,
      "grad_norm": 5.436562423710711e-05,
      "learning_rate": 3.1052144399876584e-05,
      "loss": 0.0009,
      "step": 61410
    },
    {
      "epoch": 18.950941067571737,
      "grad_norm": 2.572947778389789e-05,
      "learning_rate": 3.104905893242827e-05,
      "loss": 0.0,
      "step": 61420
    },
    {
      "epoch": 18.954026535020056,
      "grad_norm": 0.008294446393847466,
      "learning_rate": 3.104597346497994e-05,
      "loss": 0.0013,
      "step": 61430
    },
    {
      "epoch": 18.957112002468374,
      "grad_norm": 6.77811840432696e-05,
      "learning_rate": 3.1042887997531625e-05,
      "loss": 0.0009,
      "step": 61440
    },
    {
      "epoch": 18.960197469916693,
      "grad_norm": 7.842493505449966e-05,
      "learning_rate": 3.1039802530083314e-05,
      "loss": 0.0,
      "step": 61450
    },
    {
      "epoch": 18.963282937365012,
      "grad_norm": 0.049827590584754944,
      "learning_rate": 3.103671706263499e-05,
      "loss": 0.0002,
      "step": 61460
    },
    {
      "epoch": 18.96636840481333,
      "grad_norm": 7.149757584556937e-05,
      "learning_rate": 3.103363159518667e-05,
      "loss": 0.0001,
      "step": 61470
    },
    {
      "epoch": 18.96945387226165,
      "grad_norm": 0.042849693447351456,
      "learning_rate": 3.1030546127738355e-05,
      "loss": 0.0001,
      "step": 61480
    },
    {
      "epoch": 18.972539339709964,
      "grad_norm": 5.8349819482828025e-06,
      "learning_rate": 3.102746066029004e-05,
      "loss": 0.0001,
      "step": 61490
    },
    {
      "epoch": 18.975624807158283,
      "grad_norm": 0.00019923258514609188,
      "learning_rate": 3.102437519284171e-05,
      "loss": 0.0008,
      "step": 61500
    },
    {
      "epoch": 18.978710274606602,
      "grad_norm": 0.003095109947025776,
      "learning_rate": 3.1021289725393396e-05,
      "loss": 0.0002,
      "step": 61510
    },
    {
      "epoch": 18.98179574205492,
      "grad_norm": 0.0014598486013710499,
      "learning_rate": 3.1018204257945085e-05,
      "loss": 0.0,
      "step": 61520
    },
    {
      "epoch": 18.98488120950324,
      "grad_norm": 0.4005333483219147,
      "learning_rate": 3.101511879049676e-05,
      "loss": 0.0002,
      "step": 61530
    },
    {
      "epoch": 18.987966676951558,
      "grad_norm": 0.0001915290777105838,
      "learning_rate": 3.101203332304844e-05,
      "loss": 0.0,
      "step": 61540
    },
    {
      "epoch": 18.991052144399877,
      "grad_norm": 0.05241606384515762,
      "learning_rate": 3.1008947855600126e-05,
      "loss": 0.0037,
      "step": 61550
    },
    {
      "epoch": 18.994137611848195,
      "grad_norm": 0.0009786362061277032,
      "learning_rate": 3.100586238815181e-05,
      "loss": 0.0001,
      "step": 61560
    },
    {
      "epoch": 18.997223079296514,
      "grad_norm": 0.000750891980715096,
      "learning_rate": 3.1002776920703484e-05,
      "loss": 0.0001,
      "step": 61570
    },
    {
      "epoch": 19.0,
      "eval_accuracy_branch1": 0.9998263939122132,
      "eval_accuracy_branch2": 0.4194612424409016,
      "eval_f1_branch1": 0.9997376696263085,
      "eval_f1_branch2": 0.41453265391400607,
      "eval_loss": 0.00020223515457473695,
      "eval_precision_branch1": 0.9997404624331434,
      "eval_precision_branch2": 0.5076416213406661,
      "eval_recall_branch1": 0.9997352304398142,
      "eval_recall_branch2": 0.5063004542692631,
      "eval_runtime": 241.7774,
      "eval_samples_per_second": 428.837,
      "eval_steps_per_second": 53.607,
      "step": 61579
    },
    {
      "epoch": 19.000308546744833,
      "grad_norm": 0.0027173226699233055,
      "learning_rate": 3.099969145325517e-05,
      "loss": 0.004,
      "step": 61580
    },
    {
      "epoch": 19.00339401419315,
      "grad_norm": 0.6456302404403687,
      "learning_rate": 3.0996605985806855e-05,
      "loss": 0.0005,
      "step": 61590
    },
    {
      "epoch": 19.00647948164147,
      "grad_norm": 0.5081993341445923,
      "learning_rate": 3.099352051835853e-05,
      "loss": 0.0015,
      "step": 61600
    },
    {
      "epoch": 19.009564949089786,
      "grad_norm": 0.0038900140207260847,
      "learning_rate": 3.0990435050910214e-05,
      "loss": 0.0012,
      "step": 61610
    },
    {
      "epoch": 19.012650416538104,
      "grad_norm": 0.0069983405992388725,
      "learning_rate": 3.0987349583461896e-05,
      "loss": 0.0002,
      "step": 61620
    },
    {
      "epoch": 19.015735883986423,
      "grad_norm": 0.000988415558822453,
      "learning_rate": 3.098426411601358e-05,
      "loss": 0.001,
      "step": 61630
    },
    {
      "epoch": 19.01882135143474,
      "grad_norm": 0.015342178754508495,
      "learning_rate": 3.0981178648565254e-05,
      "loss": 0.0003,
      "step": 61640
    },
    {
      "epoch": 19.02190681888306,
      "grad_norm": 0.0006172988214530051,
      "learning_rate": 3.0978093181116944e-05,
      "loss": 0.0151,
      "step": 61650
    },
    {
      "epoch": 19.02499228633138,
      "grad_norm": 0.00497673312202096,
      "learning_rate": 3.0975007713668626e-05,
      "loss": 0.0,
      "step": 61660
    },
    {
      "epoch": 19.028077753779698,
      "grad_norm": 0.011608488857746124,
      "learning_rate": 3.09719222462203e-05,
      "loss": 0.0,
      "step": 61670
    },
    {
      "epoch": 19.031163221228017,
      "grad_norm": 1.4713985365233384e-05,
      "learning_rate": 3.0968836778771984e-05,
      "loss": 0.0004,
      "step": 61680
    },
    {
      "epoch": 19.034248688676335,
      "grad_norm": 0.001933632418513298,
      "learning_rate": 3.096575131132367e-05,
      "loss": 0.0001,
      "step": 61690
    },
    {
      "epoch": 19.037334156124654,
      "grad_norm": 0.4750811457633972,
      "learning_rate": 3.096266584387535e-05,
      "loss": 0.0002,
      "step": 61700
    },
    {
      "epoch": 19.040419623572973,
      "grad_norm": 2.8152853701612912e-05,
      "learning_rate": 3.0959580376427025e-05,
      "loss": 0.0017,
      "step": 61710
    },
    {
      "epoch": 19.043505091021288,
      "grad_norm": 3.590321648516692e-05,
      "learning_rate": 3.0956494908978714e-05,
      "loss": 0.0,
      "step": 61720
    },
    {
      "epoch": 19.046590558469607,
      "grad_norm": 0.0005961209535598755,
      "learning_rate": 3.0953409441530397e-05,
      "loss": 0.0005,
      "step": 61730
    },
    {
      "epoch": 19.049676025917925,
      "grad_norm": 1.4503000974655151,
      "learning_rate": 3.095032397408207e-05,
      "loss": 0.0008,
      "step": 61740
    },
    {
      "epoch": 19.052761493366244,
      "grad_norm": 0.5878691077232361,
      "learning_rate": 3.0947238506633755e-05,
      "loss": 0.0014,
      "step": 61750
    },
    {
      "epoch": 19.055846960814563,
      "grad_norm": 0.00022450104006566107,
      "learning_rate": 3.094415303918544e-05,
      "loss": 0.0007,
      "step": 61760
    },
    {
      "epoch": 19.05893242826288,
      "grad_norm": 0.0004972611786797643,
      "learning_rate": 3.094106757173712e-05,
      "loss": 0.0004,
      "step": 61770
    },
    {
      "epoch": 19.0620178957112,
      "grad_norm": 0.014170503243803978,
      "learning_rate": 3.0937982104288795e-05,
      "loss": 0.0001,
      "step": 61780
    },
    {
      "epoch": 19.06510336315952,
      "grad_norm": 1.2670087926380802e-05,
      "learning_rate": 3.0934896636840485e-05,
      "loss": 0.0001,
      "step": 61790
    },
    {
      "epoch": 19.068188830607838,
      "grad_norm": 2.4207554815802723e-05,
      "learning_rate": 3.093181116939217e-05,
      "loss": 0.0,
      "step": 61800
    },
    {
      "epoch": 19.071274298056156,
      "grad_norm": 0.07216246426105499,
      "learning_rate": 3.092872570194384e-05,
      "loss": 0.0001,
      "step": 61810
    },
    {
      "epoch": 19.074359765504475,
      "grad_norm": 8.113678632071242e-05,
      "learning_rate": 3.092564023449553e-05,
      "loss": 0.0,
      "step": 61820
    },
    {
      "epoch": 19.077445232952794,
      "grad_norm": 0.10810703039169312,
      "learning_rate": 3.092255476704721e-05,
      "loss": 0.0003,
      "step": 61830
    },
    {
      "epoch": 19.08053070040111,
      "grad_norm": 1.946776501426939e-05,
      "learning_rate": 3.091946929959889e-05,
      "loss": 0.0016,
      "step": 61840
    },
    {
      "epoch": 19.083616167849428,
      "grad_norm": 3.780539191211574e-05,
      "learning_rate": 3.091638383215057e-05,
      "loss": 0.0,
      "step": 61850
    },
    {
      "epoch": 19.086701635297747,
      "grad_norm": 0.0063857887871563435,
      "learning_rate": 3.0913298364702255e-05,
      "loss": 0.0,
      "step": 61860
    },
    {
      "epoch": 19.089787102746065,
      "grad_norm": 1.5885334014892578,
      "learning_rate": 3.091021289725394e-05,
      "loss": 0.002,
      "step": 61870
    },
    {
      "epoch": 19.092872570194384,
      "grad_norm": 2.051478862762451,
      "learning_rate": 3.0907127429805613e-05,
      "loss": 0.0019,
      "step": 61880
    },
    {
      "epoch": 19.095958037642703,
      "grad_norm": 0.019790055230259895,
      "learning_rate": 3.09040419623573e-05,
      "loss": 0.0,
      "step": 61890
    },
    {
      "epoch": 19.09904350509102,
      "grad_norm": 0.050196681171655655,
      "learning_rate": 3.090095649490898e-05,
      "loss": 0.0003,
      "step": 61900
    },
    {
      "epoch": 19.10212897253934,
      "grad_norm": 0.6297298073768616,
      "learning_rate": 3.089787102746066e-05,
      "loss": 0.0027,
      "step": 61910
    },
    {
      "epoch": 19.10521443998766,
      "grad_norm": 1.925798278534785e-05,
      "learning_rate": 3.089478556001234e-05,
      "loss": 0.0,
      "step": 61920
    },
    {
      "epoch": 19.108299907435978,
      "grad_norm": 2.8787130759155843e-06,
      "learning_rate": 3.0891700092564026e-05,
      "loss": 0.0001,
      "step": 61930
    },
    {
      "epoch": 19.111385374884296,
      "grad_norm": 0.0010257535614073277,
      "learning_rate": 3.088861462511571e-05,
      "loss": 0.0005,
      "step": 61940
    },
    {
      "epoch": 19.114470842332615,
      "grad_norm": 1.5436515808105469,
      "learning_rate": 3.0885529157667384e-05,
      "loss": 0.0014,
      "step": 61950
    },
    {
      "epoch": 19.11755630978093,
      "grad_norm": 0.019695281982421875,
      "learning_rate": 3.088244369021907e-05,
      "loss": 0.0004,
      "step": 61960
    },
    {
      "epoch": 19.12064177722925,
      "grad_norm": 0.09974908828735352,
      "learning_rate": 3.087935822277075e-05,
      "loss": 0.0005,
      "step": 61970
    },
    {
      "epoch": 19.123727244677568,
      "grad_norm": 0.05269831791520119,
      "learning_rate": 3.087627275532243e-05,
      "loss": 0.001,
      "step": 61980
    },
    {
      "epoch": 19.126812712125886,
      "grad_norm": 0.0035350883845239878,
      "learning_rate": 3.0873187287874114e-05,
      "loss": 0.0037,
      "step": 61990
    },
    {
      "epoch": 19.129898179574205,
      "grad_norm": 0.05104285106062889,
      "learning_rate": 3.0870101820425796e-05,
      "loss": 0.0011,
      "step": 62000
    },
    {
      "epoch": 19.132983647022524,
      "grad_norm": 0.009489412419497967,
      "learning_rate": 3.086701635297748e-05,
      "loss": 0.0003,
      "step": 62010
    },
    {
      "epoch": 19.136069114470843,
      "grad_norm": 0.0012052287347614765,
      "learning_rate": 3.0863930885529155e-05,
      "loss": 0.0016,
      "step": 62020
    },
    {
      "epoch": 19.13915458191916,
      "grad_norm": 0.006592556368559599,
      "learning_rate": 3.0860845418080844e-05,
      "loss": 0.0089,
      "step": 62030
    },
    {
      "epoch": 19.14224004936748,
      "grad_norm": 0.0036934076342731714,
      "learning_rate": 3.085775995063252e-05,
      "loss": 0.0017,
      "step": 62040
    },
    {
      "epoch": 19.1453255168158,
      "grad_norm": 1.424641728401184,
      "learning_rate": 3.08546744831842e-05,
      "loss": 0.0028,
      "step": 62050
    },
    {
      "epoch": 19.148410984264117,
      "grad_norm": 0.0003988644457422197,
      "learning_rate": 3.0851589015735884e-05,
      "loss": 0.0,
      "step": 62060
    },
    {
      "epoch": 19.151496451712433,
      "grad_norm": 0.03999282047152519,
      "learning_rate": 3.084850354828757e-05,
      "loss": 0.0072,
      "step": 62070
    },
    {
      "epoch": 19.15458191916075,
      "grad_norm": 0.0004480525676626712,
      "learning_rate": 3.084541808083925e-05,
      "loss": 0.0001,
      "step": 62080
    },
    {
      "epoch": 19.15766738660907,
      "grad_norm": 0.0005332808359526098,
      "learning_rate": 3.084233261339093e-05,
      "loss": 0.0003,
      "step": 62090
    },
    {
      "epoch": 19.16075285405739,
      "grad_norm": 0.011948716826736927,
      "learning_rate": 3.0839247145942614e-05,
      "loss": 0.0003,
      "step": 62100
    },
    {
      "epoch": 19.163838321505708,
      "grad_norm": 0.058306679129600525,
      "learning_rate": 3.083616167849429e-05,
      "loss": 0.0002,
      "step": 62110
    },
    {
      "epoch": 19.166923788954026,
      "grad_norm": 4.536359483608976e-05,
      "learning_rate": 3.083307621104597e-05,
      "loss": 0.0026,
      "step": 62120
    },
    {
      "epoch": 19.170009256402345,
      "grad_norm": 0.00013070138811599463,
      "learning_rate": 3.082999074359766e-05,
      "loss": 0.0013,
      "step": 62130
    },
    {
      "epoch": 19.173094723850664,
      "grad_norm": 0.00014825924881733954,
      "learning_rate": 3.082690527614934e-05,
      "loss": 0.0,
      "step": 62140
    },
    {
      "epoch": 19.176180191298982,
      "grad_norm": 0.0010791778331622481,
      "learning_rate": 3.082381980870102e-05,
      "loss": 0.0005,
      "step": 62150
    },
    {
      "epoch": 19.1792656587473,
      "grad_norm": 2.3314429199672304e-05,
      "learning_rate": 3.08207343412527e-05,
      "loss": 0.0031,
      "step": 62160
    },
    {
      "epoch": 19.18235112619562,
      "grad_norm": 0.23617367446422577,
      "learning_rate": 3.0817648873804385e-05,
      "loss": 0.0002,
      "step": 62170
    },
    {
      "epoch": 19.18543659364394,
      "grad_norm": 2.7508301734924316,
      "learning_rate": 3.081456340635606e-05,
      "loss": 0.0082,
      "step": 62180
    },
    {
      "epoch": 19.188522061092254,
      "grad_norm": 0.0768107920885086,
      "learning_rate": 3.081147793890774e-05,
      "loss": 0.0009,
      "step": 62190
    },
    {
      "epoch": 19.191607528540573,
      "grad_norm": 0.0005271444097161293,
      "learning_rate": 3.080839247145943e-05,
      "loss": 0.0003,
      "step": 62200
    },
    {
      "epoch": 19.19469299598889,
      "grad_norm": 3.040370225906372,
      "learning_rate": 3.080530700401111e-05,
      "loss": 0.0041,
      "step": 62210
    },
    {
      "epoch": 19.19777846343721,
      "grad_norm": 0.26394933462142944,
      "learning_rate": 3.080222153656279e-05,
      "loss": 0.0003,
      "step": 62220
    },
    {
      "epoch": 19.20086393088553,
      "grad_norm": 0.005013660993427038,
      "learning_rate": 3.079913606911447e-05,
      "loss": 0.0001,
      "step": 62230
    },
    {
      "epoch": 19.203949398333847,
      "grad_norm": 0.05965689942240715,
      "learning_rate": 3.0796050601666155e-05,
      "loss": 0.0005,
      "step": 62240
    },
    {
      "epoch": 19.207034865782166,
      "grad_norm": 0.0018418452236801386,
      "learning_rate": 3.079296513421784e-05,
      "loss": 0.002,
      "step": 62250
    },
    {
      "epoch": 19.210120333230485,
      "grad_norm": 0.15956957638263702,
      "learning_rate": 3.0789879666769514e-05,
      "loss": 0.0002,
      "step": 62260
    },
    {
      "epoch": 19.213205800678804,
      "grad_norm": 2.027440132224001e-05,
      "learning_rate": 3.07867941993212e-05,
      "loss": 0.0043,
      "step": 62270
    },
    {
      "epoch": 19.216291268127122,
      "grad_norm": 0.0005511115887202322,
      "learning_rate": 3.078370873187288e-05,
      "loss": 0.0001,
      "step": 62280
    },
    {
      "epoch": 19.21937673557544,
      "grad_norm": 1.538919605081901e-05,
      "learning_rate": 3.078062326442456e-05,
      "loss": 0.0005,
      "step": 62290
    },
    {
      "epoch": 19.22246220302376,
      "grad_norm": 0.0005937973037362099,
      "learning_rate": 3.0777537796976244e-05,
      "loss": 0.0024,
      "step": 62300
    },
    {
      "epoch": 19.225547670472075,
      "grad_norm": 0.0025454277638345957,
      "learning_rate": 3.0774452329527926e-05,
      "loss": 0.0001,
      "step": 62310
    },
    {
      "epoch": 19.228633137920394,
      "grad_norm": 0.011959713883697987,
      "learning_rate": 3.077136686207961e-05,
      "loss": 0.0014,
      "step": 62320
    },
    {
      "epoch": 19.231718605368712,
      "grad_norm": 0.5693950653076172,
      "learning_rate": 3.0768281394631284e-05,
      "loss": 0.0003,
      "step": 62330
    },
    {
      "epoch": 19.23480407281703,
      "grad_norm": 1.7274465560913086,
      "learning_rate": 3.0765195927182973e-05,
      "loss": 0.0102,
      "step": 62340
    },
    {
      "epoch": 19.23788954026535,
      "grad_norm": 0.00140095641836524,
      "learning_rate": 3.076211045973465e-05,
      "loss": 0.0006,
      "step": 62350
    },
    {
      "epoch": 19.24097500771367,
      "grad_norm": 5.860254532308318e-06,
      "learning_rate": 3.075902499228633e-05,
      "loss": 0.0041,
      "step": 62360
    },
    {
      "epoch": 19.244060475161987,
      "grad_norm": 0.0004429640539456159,
      "learning_rate": 3.0755939524838014e-05,
      "loss": 0.0001,
      "step": 62370
    },
    {
      "epoch": 19.247145942610306,
      "grad_norm": 0.00011186244955752045,
      "learning_rate": 3.0752854057389697e-05,
      "loss": 0.0005,
      "step": 62380
    },
    {
      "epoch": 19.250231410058625,
      "grad_norm": 0.0007893259753473103,
      "learning_rate": 3.074976858994138e-05,
      "loss": 0.0,
      "step": 62390
    },
    {
      "epoch": 19.253316877506943,
      "grad_norm": 0.45072147250175476,
      "learning_rate": 3.074668312249306e-05,
      "loss": 0.0011,
      "step": 62400
    },
    {
      "epoch": 19.256402344955262,
      "grad_norm": 0.0006407498149201274,
      "learning_rate": 3.0743597655044744e-05,
      "loss": 0.0064,
      "step": 62410
    },
    {
      "epoch": 19.25948781240358,
      "grad_norm": 0.00014328431279864162,
      "learning_rate": 3.074051218759642e-05,
      "loss": 0.0008,
      "step": 62420
    },
    {
      "epoch": 19.262573279851896,
      "grad_norm": 0.0005600378499366343,
      "learning_rate": 3.07374267201481e-05,
      "loss": 0.0005,
      "step": 62430
    },
    {
      "epoch": 19.265658747300215,
      "grad_norm": 0.18444769084453583,
      "learning_rate": 3.0734341252699785e-05,
      "loss": 0.0006,
      "step": 62440
    },
    {
      "epoch": 19.268744214748533,
      "grad_norm": 0.005941557697951794,
      "learning_rate": 3.073125578525147e-05,
      "loss": 0.0021,
      "step": 62450
    },
    {
      "epoch": 19.271829682196852,
      "grad_norm": 0.0026099581737071276,
      "learning_rate": 3.072817031780315e-05,
      "loss": 0.0001,
      "step": 62460
    },
    {
      "epoch": 19.27491514964517,
      "grad_norm": 0.03862603381276131,
      "learning_rate": 3.072508485035483e-05,
      "loss": 0.0079,
      "step": 62470
    },
    {
      "epoch": 19.27800061709349,
      "grad_norm": 2.6625852115103044e-05,
      "learning_rate": 3.0721999382906515e-05,
      "loss": 0.0001,
      "step": 62480
    },
    {
      "epoch": 19.28108608454181,
      "grad_norm": 0.0036855132784694433,
      "learning_rate": 3.071891391545819e-05,
      "loss": 0.0002,
      "step": 62490
    },
    {
      "epoch": 19.284171551990127,
      "grad_norm": 0.16248038411140442,
      "learning_rate": 3.071582844800987e-05,
      "loss": 0.0055,
      "step": 62500
    },
    {
      "epoch": 19.287257019438446,
      "grad_norm": 7.717724656686187e-06,
      "learning_rate": 3.0712742980561555e-05,
      "loss": 0.0004,
      "step": 62510
    },
    {
      "epoch": 19.290342486886765,
      "grad_norm": 0.0003029774525202811,
      "learning_rate": 3.070965751311324e-05,
      "loss": 0.0004,
      "step": 62520
    },
    {
      "epoch": 19.293427954335083,
      "grad_norm": 6.136407318990678e-05,
      "learning_rate": 3.070657204566492e-05,
      "loss": 0.0002,
      "step": 62530
    },
    {
      "epoch": 19.2965134217834,
      "grad_norm": 9.01279054232873e-06,
      "learning_rate": 3.07034865782166e-05,
      "loss": 0.0,
      "step": 62540
    },
    {
      "epoch": 19.299598889231717,
      "grad_norm": 0.0356612429022789,
      "learning_rate": 3.0700401110768285e-05,
      "loss": 0.0002,
      "step": 62550
    },
    {
      "epoch": 19.302684356680036,
      "grad_norm": 0.006943031679838896,
      "learning_rate": 3.069731564331996e-05,
      "loss": 0.0,
      "step": 62560
    },
    {
      "epoch": 19.305769824128355,
      "grad_norm": 0.00020922173280268908,
      "learning_rate": 3.069423017587164e-05,
      "loss": 0.0004,
      "step": 62570
    },
    {
      "epoch": 19.308855291576673,
      "grad_norm": 0.001775028882548213,
      "learning_rate": 3.0691144708423326e-05,
      "loss": 0.0,
      "step": 62580
    },
    {
      "epoch": 19.311940759024992,
      "grad_norm": 1.4218620663086767e-06,
      "learning_rate": 3.068805924097501e-05,
      "loss": 0.0012,
      "step": 62590
    },
    {
      "epoch": 19.31502622647331,
      "grad_norm": 0.00166686053853482,
      "learning_rate": 3.068497377352669e-05,
      "loss": 0.0002,
      "step": 62600
    },
    {
      "epoch": 19.31811169392163,
      "grad_norm": 5.011802204535343e-05,
      "learning_rate": 3.068188830607837e-05,
      "loss": 0.0007,
      "step": 62610
    },
    {
      "epoch": 19.32119716136995,
      "grad_norm": 0.06838326901197433,
      "learning_rate": 3.0678802838630056e-05,
      "loss": 0.0001,
      "step": 62620
    },
    {
      "epoch": 19.324282628818267,
      "grad_norm": 0.03252580389380455,
      "learning_rate": 3.067571737118173e-05,
      "loss": 0.0141,
      "step": 62630
    },
    {
      "epoch": 19.327368096266586,
      "grad_norm": 0.0044687963090837,
      "learning_rate": 3.067263190373342e-05,
      "loss": 0.0031,
      "step": 62640
    },
    {
      "epoch": 19.330453563714904,
      "grad_norm": 1.8333223124500364e-05,
      "learning_rate": 3.0669546436285096e-05,
      "loss": 0.0007,
      "step": 62650
    },
    {
      "epoch": 19.33353903116322,
      "grad_norm": 0.00012624428200069815,
      "learning_rate": 3.066646096883678e-05,
      "loss": 0.0006,
      "step": 62660
    },
    {
      "epoch": 19.33662449861154,
      "grad_norm": 0.029963180422782898,
      "learning_rate": 3.066337550138846e-05,
      "loss": 0.0,
      "step": 62670
    },
    {
      "epoch": 19.339709966059857,
      "grad_norm": 0.00017906512948684394,
      "learning_rate": 3.0660290033940144e-05,
      "loss": 0.0093,
      "step": 62680
    },
    {
      "epoch": 19.342795433508176,
      "grad_norm": 0.0007041748031042516,
      "learning_rate": 3.0657204566491826e-05,
      "loss": 0.0012,
      "step": 62690
    },
    {
      "epoch": 19.345880900956494,
      "grad_norm": 0.007681539747864008,
      "learning_rate": 3.06541190990435e-05,
      "loss": 0.0005,
      "step": 62700
    },
    {
      "epoch": 19.348966368404813,
      "grad_norm": 0.007459599059075117,
      "learning_rate": 3.065103363159519e-05,
      "loss": 0.0077,
      "step": 62710
    },
    {
      "epoch": 19.352051835853132,
      "grad_norm": 1.7791109085083008,
      "learning_rate": 3.0647948164146874e-05,
      "loss": 0.0026,
      "step": 62720
    },
    {
      "epoch": 19.35513730330145,
      "grad_norm": 0.000644066312815994,
      "learning_rate": 3.064486269669855e-05,
      "loss": 0.0036,
      "step": 62730
    },
    {
      "epoch": 19.35822277074977,
      "grad_norm": 0.011498915031552315,
      "learning_rate": 3.064177722925023e-05,
      "loss": 0.0083,
      "step": 62740
    },
    {
      "epoch": 19.361308238198088,
      "grad_norm": 0.026771368458867073,
      "learning_rate": 3.0638691761801914e-05,
      "loss": 0.0001,
      "step": 62750
    },
    {
      "epoch": 19.364393705646407,
      "grad_norm": 0.00015662606165278703,
      "learning_rate": 3.06356062943536e-05,
      "loss": 0.0003,
      "step": 62760
    },
    {
      "epoch": 19.367479173094726,
      "grad_norm": 0.31888413429260254,
      "learning_rate": 3.063252082690527e-05,
      "loss": 0.0008,
      "step": 62770
    },
    {
      "epoch": 19.37056464054304,
      "grad_norm": 0.08508763462305069,
      "learning_rate": 3.062943535945696e-05,
      "loss": 0.002,
      "step": 62780
    },
    {
      "epoch": 19.37365010799136,
      "grad_norm": 0.001335685607045889,
      "learning_rate": 3.0626349892008644e-05,
      "loss": 0.0015,
      "step": 62790
    },
    {
      "epoch": 19.376735575439678,
      "grad_norm": 0.0008739984477870166,
      "learning_rate": 3.062326442456032e-05,
      "loss": 0.0013,
      "step": 62800
    },
    {
      "epoch": 19.379821042887997,
      "grad_norm": 0.0020000895019620657,
      "learning_rate": 3.0620178957112e-05,
      "loss": 0.0002,
      "step": 62810
    },
    {
      "epoch": 19.382906510336316,
      "grad_norm": 0.00018735427875071764,
      "learning_rate": 3.0617093489663685e-05,
      "loss": 0.0002,
      "step": 62820
    },
    {
      "epoch": 19.385991977784634,
      "grad_norm": 0.5652110576629639,
      "learning_rate": 3.061400802221537e-05,
      "loss": 0.0003,
      "step": 62830
    },
    {
      "epoch": 19.389077445232953,
      "grad_norm": 8.052372140809894e-05,
      "learning_rate": 3.061092255476704e-05,
      "loss": 0.0,
      "step": 62840
    },
    {
      "epoch": 19.392162912681272,
      "grad_norm": 2.1830041077919304e-05,
      "learning_rate": 3.060783708731873e-05,
      "loss": 0.0006,
      "step": 62850
    },
    {
      "epoch": 19.39524838012959,
      "grad_norm": 2.173681787098758e-05,
      "learning_rate": 3.0604751619870415e-05,
      "loss": 0.0002,
      "step": 62860
    },
    {
      "epoch": 19.39833384757791,
      "grad_norm": 5.4834770708112046e-05,
      "learning_rate": 3.060166615242209e-05,
      "loss": 0.0005,
      "step": 62870
    },
    {
      "epoch": 19.401419315026228,
      "grad_norm": 0.03133656084537506,
      "learning_rate": 3.059858068497378e-05,
      "loss": 0.0,
      "step": 62880
    },
    {
      "epoch": 19.404504782474547,
      "grad_norm": 0.004328286740928888,
      "learning_rate": 3.0595495217525455e-05,
      "loss": 0.0002,
      "step": 62890
    },
    {
      "epoch": 19.407590249922862,
      "grad_norm": 0.00010063996887765825,
      "learning_rate": 3.059240975007714e-05,
      "loss": 0.0001,
      "step": 62900
    },
    {
      "epoch": 19.41067571737118,
      "grad_norm": 0.0019568002317100763,
      "learning_rate": 3.058932428262882e-05,
      "loss": 0.0,
      "step": 62910
    },
    {
      "epoch": 19.4137611848195,
      "grad_norm": 0.034559376537799835,
      "learning_rate": 3.05862388151805e-05,
      "loss": 0.002,
      "step": 62920
    },
    {
      "epoch": 19.416846652267818,
      "grad_norm": 2.356416553084273e-05,
      "learning_rate": 3.0583153347732185e-05,
      "loss": 0.0011,
      "step": 62930
    },
    {
      "epoch": 19.419932119716137,
      "grad_norm": 0.38160887360572815,
      "learning_rate": 3.058006788028386e-05,
      "loss": 0.0009,
      "step": 62940
    },
    {
      "epoch": 19.423017587164455,
      "grad_norm": 0.0008752526482567191,
      "learning_rate": 3.057698241283555e-05,
      "loss": 0.0045,
      "step": 62950
    },
    {
      "epoch": 19.426103054612774,
      "grad_norm": 0.05205328017473221,
      "learning_rate": 3.0573896945387226e-05,
      "loss": 0.0001,
      "step": 62960
    },
    {
      "epoch": 19.429188522061093,
      "grad_norm": 0.027980253100395203,
      "learning_rate": 3.057081147793891e-05,
      "loss": 0.0,
      "step": 62970
    },
    {
      "epoch": 19.43227398950941,
      "grad_norm": 0.2630002498626709,
      "learning_rate": 3.056772601049059e-05,
      "loss": 0.0094,
      "step": 62980
    },
    {
      "epoch": 19.43535945695773,
      "grad_norm": 0.024363713338971138,
      "learning_rate": 3.0564640543042273e-05,
      "loss": 0.0006,
      "step": 62990
    },
    {
      "epoch": 19.43844492440605,
      "grad_norm": 0.0003699080552905798,
      "learning_rate": 3.0561555075593956e-05,
      "loss": 0.0004,
      "step": 63000
    },
    {
      "epoch": 19.441530391854364,
      "grad_norm": 0.0025557565968483686,
      "learning_rate": 3.055846960814563e-05,
      "loss": 0.0001,
      "step": 63010
    },
    {
      "epoch": 19.444615859302683,
      "grad_norm": 0.0012127440422773361,
      "learning_rate": 3.055538414069732e-05,
      "loss": 0.0001,
      "step": 63020
    },
    {
      "epoch": 19.447701326751,
      "grad_norm": 1.8250879293191247e-05,
      "learning_rate": 3.0552298673249e-05,
      "loss": 0.004,
      "step": 63030
    },
    {
      "epoch": 19.45078679419932,
      "grad_norm": 0.0002981203142553568,
      "learning_rate": 3.054921320580068e-05,
      "loss": 0.0001,
      "step": 63040
    },
    {
      "epoch": 19.45387226164764,
      "grad_norm": 0.006454478949308395,
      "learning_rate": 3.054612773835236e-05,
      "loss": 0.0069,
      "step": 63050
    },
    {
      "epoch": 19.456957729095958,
      "grad_norm": 0.07558874040842056,
      "learning_rate": 3.0543042270904044e-05,
      "loss": 0.0032,
      "step": 63060
    },
    {
      "epoch": 19.460043196544277,
      "grad_norm": 0.0002296603051945567,
      "learning_rate": 3.0539956803455727e-05,
      "loss": 0.0004,
      "step": 63070
    },
    {
      "epoch": 19.463128663992595,
      "grad_norm": 0.014410510659217834,
      "learning_rate": 3.05368713360074e-05,
      "loss": 0.0016,
      "step": 63080
    },
    {
      "epoch": 19.466214131440914,
      "grad_norm": 5.127458095550537,
      "learning_rate": 3.053378586855909e-05,
      "loss": 0.0067,
      "step": 63090
    },
    {
      "epoch": 19.469299598889233,
      "grad_norm": 6.519818998640403e-05,
      "learning_rate": 3.053070040111077e-05,
      "loss": 0.0009,
      "step": 63100
    },
    {
      "epoch": 19.47238506633755,
      "grad_norm": 2.9182045182096772e-05,
      "learning_rate": 3.052761493366245e-05,
      "loss": 0.0,
      "step": 63110
    },
    {
      "epoch": 19.47547053378587,
      "grad_norm": 0.002273107646033168,
      "learning_rate": 3.052452946621414e-05,
      "loss": 0.0001,
      "step": 63120
    },
    {
      "epoch": 19.478556001234185,
      "grad_norm": 0.00772660318762064,
      "learning_rate": 3.0521443998765815e-05,
      "loss": 0.0004,
      "step": 63130
    },
    {
      "epoch": 19.481641468682504,
      "grad_norm": 0.020588962361216545,
      "learning_rate": 3.05183585313175e-05,
      "loss": 0.0,
      "step": 63140
    },
    {
      "epoch": 19.484726936130823,
      "grad_norm": 0.002307683462277055,
      "learning_rate": 3.0515273063869176e-05,
      "loss": 0.0001,
      "step": 63150
    },
    {
      "epoch": 19.48781240357914,
      "grad_norm": 0.00038635998498648405,
      "learning_rate": 3.051218759642086e-05,
      "loss": 0.0009,
      "step": 63160
    },
    {
      "epoch": 19.49089787102746,
      "grad_norm": 0.11429361253976822,
      "learning_rate": 3.0509102128972538e-05,
      "loss": 0.0018,
      "step": 63170
    },
    {
      "epoch": 19.49398333847578,
      "grad_norm": 0.006941384170204401,
      "learning_rate": 3.0506016661524224e-05,
      "loss": 0.0025,
      "step": 63180
    },
    {
      "epoch": 19.497068805924098,
      "grad_norm": 0.004330010619014502,
      "learning_rate": 3.0502931194075906e-05,
      "loss": 0.0097,
      "step": 63190
    },
    {
      "epoch": 19.500154273372416,
      "grad_norm": 0.00406197365373373,
      "learning_rate": 3.0499845726627585e-05,
      "loss": 0.0046,
      "step": 63200
    },
    {
      "epoch": 19.503239740820735,
      "grad_norm": 0.0008159700082615018,
      "learning_rate": 3.0496760259179268e-05,
      "loss": 0.0027,
      "step": 63210
    },
    {
      "epoch": 19.506325208269054,
      "grad_norm": 2.8970316634513438e-06,
      "learning_rate": 3.0493674791730947e-05,
      "loss": 0.0006,
      "step": 63220
    },
    {
      "epoch": 19.509410675717373,
      "grad_norm": 0.05710647627711296,
      "learning_rate": 3.0490589324282633e-05,
      "loss": 0.0005,
      "step": 63230
    },
    {
      "epoch": 19.51249614316569,
      "grad_norm": 0.011406095698475838,
      "learning_rate": 3.048750385683431e-05,
      "loss": 0.001,
      "step": 63240
    },
    {
      "epoch": 19.515581610614007,
      "grad_norm": 0.726071298122406,
      "learning_rate": 3.0484418389385994e-05,
      "loss": 0.0009,
      "step": 63250
    },
    {
      "epoch": 19.518667078062325,
      "grad_norm": 0.00544116273522377,
      "learning_rate": 3.0481332921937677e-05,
      "loss": 0.0,
      "step": 63260
    },
    {
      "epoch": 19.521752545510644,
      "grad_norm": 0.09665990620851517,
      "learning_rate": 3.0478247454489356e-05,
      "loss": 0.0015,
      "step": 63270
    },
    {
      "epoch": 19.524838012958963,
      "grad_norm": 0.00048504729056730866,
      "learning_rate": 3.0475161987041038e-05,
      "loss": 0.0004,
      "step": 63280
    },
    {
      "epoch": 19.52792348040728,
      "grad_norm": 0.0009480965090915561,
      "learning_rate": 3.0472076519592717e-05,
      "loss": 0.0008,
      "step": 63290
    },
    {
      "epoch": 19.5310089478556,
      "grad_norm": 0.0034120366908609867,
      "learning_rate": 3.0468991052144403e-05,
      "loss": 0.0011,
      "step": 63300
    },
    {
      "epoch": 19.53409441530392,
      "grad_norm": 0.0006002677837386727,
      "learning_rate": 3.0465905584696082e-05,
      "loss": 0.003,
      "step": 63310
    },
    {
      "epoch": 19.537179882752238,
      "grad_norm": 0.00031420207233168185,
      "learning_rate": 3.0462820117247765e-05,
      "loss": 0.0002,
      "step": 63320
    },
    {
      "epoch": 19.540265350200556,
      "grad_norm": 9.83211248239968e-06,
      "learning_rate": 3.0459734649799447e-05,
      "loss": 0.0003,
      "step": 63330
    },
    {
      "epoch": 19.543350817648875,
      "grad_norm": 0.39124858379364014,
      "learning_rate": 3.0456649182351126e-05,
      "loss": 0.0006,
      "step": 63340
    },
    {
      "epoch": 19.546436285097194,
      "grad_norm": 0.000287348753772676,
      "learning_rate": 3.0453563714902812e-05,
      "loss": 0.001,
      "step": 63350
    },
    {
      "epoch": 19.54952175254551,
      "grad_norm": 7.104777978383936e-06,
      "learning_rate": 3.0450478247454488e-05,
      "loss": 0.0002,
      "step": 63360
    },
    {
      "epoch": 19.552607219993828,
      "grad_norm": 0.02206113003194332,
      "learning_rate": 3.0447392780006174e-05,
      "loss": 0.0001,
      "step": 63370
    },
    {
      "epoch": 19.555692687442146,
      "grad_norm": 0.00028570654103532434,
      "learning_rate": 3.0444307312557853e-05,
      "loss": 0.0022,
      "step": 63380
    },
    {
      "epoch": 19.558778154890465,
      "grad_norm": 0.001416031620465219,
      "learning_rate": 3.0441221845109535e-05,
      "loss": 0.0109,
      "step": 63390
    },
    {
      "epoch": 19.561863622338784,
      "grad_norm": 2.405363011348527e-05,
      "learning_rate": 3.0438136377661218e-05,
      "loss": 0.0001,
      "step": 63400
    },
    {
      "epoch": 19.564949089787103,
      "grad_norm": 0.0017200664151459932,
      "learning_rate": 3.0435050910212897e-05,
      "loss": 0.0007,
      "step": 63410
    },
    {
      "epoch": 19.56803455723542,
      "grad_norm": 0.00037413666723296046,
      "learning_rate": 3.0431965442764583e-05,
      "loss": 0.0001,
      "step": 63420
    },
    {
      "epoch": 19.57112002468374,
      "grad_norm": 0.21350005269050598,
      "learning_rate": 3.042887997531626e-05,
      "loss": 0.0043,
      "step": 63430
    },
    {
      "epoch": 19.57420549213206,
      "grad_norm": 0.1768481731414795,
      "learning_rate": 3.0425794507867944e-05,
      "loss": 0.0004,
      "step": 63440
    },
    {
      "epoch": 19.577290959580377,
      "grad_norm": 0.0023216367699205875,
      "learning_rate": 3.0422709040419623e-05,
      "loss": 0.0034,
      "step": 63450
    },
    {
      "epoch": 19.580376427028696,
      "grad_norm": 0.0037847692146897316,
      "learning_rate": 3.0419623572971306e-05,
      "loss": 0.0044,
      "step": 63460
    },
    {
      "epoch": 19.583461894477015,
      "grad_norm": 1.15736985206604,
      "learning_rate": 3.0416538105522992e-05,
      "loss": 0.0022,
      "step": 63470
    },
    {
      "epoch": 19.58654736192533,
      "grad_norm": 0.00012173292634543031,
      "learning_rate": 3.0413452638074667e-05,
      "loss": 0.0022,
      "step": 63480
    },
    {
      "epoch": 19.58963282937365,
      "grad_norm": 1.6069531440734863,
      "learning_rate": 3.0410367170626353e-05,
      "loss": 0.0014,
      "step": 63490
    },
    {
      "epoch": 19.592718296821968,
      "grad_norm": 0.31191161274909973,
      "learning_rate": 3.0407281703178032e-05,
      "loss": 0.0036,
      "step": 63500
    },
    {
      "epoch": 19.595803764270286,
      "grad_norm": 0.5112947225570679,
      "learning_rate": 3.0404196235729715e-05,
      "loss": 0.0042,
      "step": 63510
    },
    {
      "epoch": 19.598889231718605,
      "grad_norm": 0.001958504319190979,
      "learning_rate": 3.0401110768281394e-05,
      "loss": 0.0075,
      "step": 63520
    },
    {
      "epoch": 19.601974699166924,
      "grad_norm": 0.00046990910777822137,
      "learning_rate": 3.0398025300833076e-05,
      "loss": 0.0012,
      "step": 63530
    },
    {
      "epoch": 19.605060166615242,
      "grad_norm": 0.0008329050033353269,
      "learning_rate": 3.0394939833384762e-05,
      "loss": 0.0001,
      "step": 63540
    },
    {
      "epoch": 19.60814563406356,
      "grad_norm": 0.004486988298594952,
      "learning_rate": 3.0391854365936438e-05,
      "loss": 0.0008,
      "step": 63550
    },
    {
      "epoch": 19.61123110151188,
      "grad_norm": 0.056198373436927795,
      "learning_rate": 3.0388768898488124e-05,
      "loss": 0.0054,
      "step": 63560
    },
    {
      "epoch": 19.6143165689602,
      "grad_norm": 0.002440669108182192,
      "learning_rate": 3.0385683431039803e-05,
      "loss": 0.0004,
      "step": 63570
    },
    {
      "epoch": 19.617402036408517,
      "grad_norm": 0.0004968633293174207,
      "learning_rate": 3.0382597963591485e-05,
      "loss": 0.0006,
      "step": 63580
    },
    {
      "epoch": 19.620487503856836,
      "grad_norm": 0.23968660831451416,
      "learning_rate": 3.037951249614317e-05,
      "loss": 0.0001,
      "step": 63590
    },
    {
      "epoch": 19.62357297130515,
      "grad_norm": 0.0009833683725446463,
      "learning_rate": 3.0376427028694847e-05,
      "loss": 0.0014,
      "step": 63600
    },
    {
      "epoch": 19.62665843875347,
      "grad_norm": 1.853441062849015e-05,
      "learning_rate": 3.0373341561246533e-05,
      "loss": 0.0007,
      "step": 63610
    },
    {
      "epoch": 19.62974390620179,
      "grad_norm": 0.08185669779777527,
      "learning_rate": 3.0370256093798212e-05,
      "loss": 0.0005,
      "step": 63620
    },
    {
      "epoch": 19.632829373650107,
      "grad_norm": 0.11256307363510132,
      "learning_rate": 3.0367170626349894e-05,
      "loss": 0.0023,
      "step": 63630
    },
    {
      "epoch": 19.635914841098426,
      "grad_norm": 1.6043416261672974,
      "learning_rate": 3.0364085158901574e-05,
      "loss": 0.0014,
      "step": 63640
    },
    {
      "epoch": 19.639000308546745,
      "grad_norm": 5.315210000844672e-05,
      "learning_rate": 3.0360999691453256e-05,
      "loss": 0.0015,
      "step": 63650
    },
    {
      "epoch": 19.642085775995064,
      "grad_norm": 0.0639147162437439,
      "learning_rate": 3.0357914224004942e-05,
      "loss": 0.0005,
      "step": 63660
    },
    {
      "epoch": 19.645171243443382,
      "grad_norm": 0.003440042259171605,
      "learning_rate": 3.0354828756556618e-05,
      "loss": 0.0003,
      "step": 63670
    },
    {
      "epoch": 19.6482567108917,
      "grad_norm": 0.0019241549307480454,
      "learning_rate": 3.0351743289108303e-05,
      "loss": 0.0042,
      "step": 63680
    },
    {
      "epoch": 19.65134217834002,
      "grad_norm": 0.0002021694672293961,
      "learning_rate": 3.0348657821659983e-05,
      "loss": 0.0003,
      "step": 63690
    },
    {
      "epoch": 19.65442764578834,
      "grad_norm": 0.000271186581812799,
      "learning_rate": 3.0345572354211665e-05,
      "loss": 0.0002,
      "step": 63700
    },
    {
      "epoch": 19.657513113236654,
      "grad_norm": 4.57240421383176e-05,
      "learning_rate": 3.0342486886763344e-05,
      "loss": 0.0004,
      "step": 63710
    },
    {
      "epoch": 19.660598580684972,
      "grad_norm": 0.4742509126663208,
      "learning_rate": 3.0339401419315027e-05,
      "loss": 0.0018,
      "step": 63720
    },
    {
      "epoch": 19.66368404813329,
      "grad_norm": 0.01320828776806593,
      "learning_rate": 3.0336315951866712e-05,
      "loss": 0.0001,
      "step": 63730
    },
    {
      "epoch": 19.66676951558161,
      "grad_norm": 0.004251973703503609,
      "learning_rate": 3.033323048441839e-05,
      "loss": 0.0004,
      "step": 63740
    },
    {
      "epoch": 19.66985498302993,
      "grad_norm": 0.5681961178779602,
      "learning_rate": 3.0330145016970074e-05,
      "loss": 0.0029,
      "step": 63750
    },
    {
      "epoch": 19.672940450478247,
      "grad_norm": 0.0010325544280931354,
      "learning_rate": 3.0327059549521753e-05,
      "loss": 0.0124,
      "step": 63760
    },
    {
      "epoch": 19.676025917926566,
      "grad_norm": 0.004935447592288256,
      "learning_rate": 3.0323974082073436e-05,
      "loss": 0.0024,
      "step": 63770
    },
    {
      "epoch": 19.679111385374885,
      "grad_norm": 0.001188558293506503,
      "learning_rate": 3.0320888614625115e-05,
      "loss": 0.0001,
      "step": 63780
    },
    {
      "epoch": 19.682196852823203,
      "grad_norm": 0.32000255584716797,
      "learning_rate": 3.0317803147176797e-05,
      "loss": 0.0009,
      "step": 63790
    },
    {
      "epoch": 19.685282320271522,
      "grad_norm": 2.5254805223084986e-05,
      "learning_rate": 3.0314717679728483e-05,
      "loss": 0.0,
      "step": 63800
    },
    {
      "epoch": 19.68836778771984,
      "grad_norm": 0.567481279373169,
      "learning_rate": 3.0311632212280162e-05,
      "loss": 0.0006,
      "step": 63810
    },
    {
      "epoch": 19.69145325516816,
      "grad_norm": 0.0002592719974927604,
      "learning_rate": 3.0308546744831845e-05,
      "loss": 0.0005,
      "step": 63820
    },
    {
      "epoch": 19.694538722616475,
      "grad_norm": 0.005438130348920822,
      "learning_rate": 3.0305461277383524e-05,
      "loss": 0.0,
      "step": 63830
    },
    {
      "epoch": 19.697624190064793,
      "grad_norm": 0.06177808716893196,
      "learning_rate": 3.0302375809935206e-05,
      "loss": 0.0001,
      "step": 63840
    },
    {
      "epoch": 19.700709657513112,
      "grad_norm": 0.000693397072609514,
      "learning_rate": 3.0299290342486885e-05,
      "loss": 0.0003,
      "step": 63850
    },
    {
      "epoch": 19.70379512496143,
      "grad_norm": 0.00010118049249285832,
      "learning_rate": 3.029620487503857e-05,
      "loss": 0.0005,
      "step": 63860
    },
    {
      "epoch": 19.70688059240975,
      "grad_norm": 3.589061737060547,
      "learning_rate": 3.0293119407590254e-05,
      "loss": 0.004,
      "step": 63870
    },
    {
      "epoch": 19.70996605985807,
      "grad_norm": 0.004714705981314182,
      "learning_rate": 3.0290033940141933e-05,
      "loss": 0.0015,
      "step": 63880
    },
    {
      "epoch": 19.713051527306387,
      "grad_norm": 0.0012535712448880076,
      "learning_rate": 3.0286948472693615e-05,
      "loss": 0.0006,
      "step": 63890
    },
    {
      "epoch": 19.716136994754706,
      "grad_norm": 0.0001929538557305932,
      "learning_rate": 3.0283863005245294e-05,
      "loss": 0.0,
      "step": 63900
    },
    {
      "epoch": 19.719222462203025,
      "grad_norm": 1.9239410903537646e-05,
      "learning_rate": 3.0280777537796977e-05,
      "loss": 0.0,
      "step": 63910
    },
    {
      "epoch": 19.722307929651343,
      "grad_norm": 1.7890341723614256e-06,
      "learning_rate": 3.0277692070348656e-05,
      "loss": 0.0,
      "step": 63920
    },
    {
      "epoch": 19.725393397099662,
      "grad_norm": 3.611660213209689e-05,
      "learning_rate": 3.027460660290034e-05,
      "loss": 0.0003,
      "step": 63930
    },
    {
      "epoch": 19.72847886454798,
      "grad_norm": 0.00434230687096715,
      "learning_rate": 3.0271521135452024e-05,
      "loss": 0.0031,
      "step": 63940
    },
    {
      "epoch": 19.731564331996296,
      "grad_norm": 3.3998003345914185e-05,
      "learning_rate": 3.0268435668003703e-05,
      "loss": 0.0004,
      "step": 63950
    },
    {
      "epoch": 19.734649799444615,
      "grad_norm": 4.814067870029248e-05,
      "learning_rate": 3.0265350200555386e-05,
      "loss": 0.0004,
      "step": 63960
    },
    {
      "epoch": 19.737735266892933,
      "grad_norm": 0.0019112199079245329,
      "learning_rate": 3.0262264733107065e-05,
      "loss": 0.0013,
      "step": 63970
    },
    {
      "epoch": 19.740820734341252,
      "grad_norm": 0.0003305401187390089,
      "learning_rate": 3.025917926565875e-05,
      "loss": 0.0008,
      "step": 63980
    },
    {
      "epoch": 19.74390620178957,
      "grad_norm": 0.019082387909293175,
      "learning_rate": 3.0256093798210426e-05,
      "loss": 0.0095,
      "step": 63990
    },
    {
      "epoch": 19.74699166923789,
      "grad_norm": 0.000288660463411361,
      "learning_rate": 3.0253008330762112e-05,
      "loss": 0.0023,
      "step": 64000
    },
    {
      "epoch": 19.75007713668621,
      "grad_norm": 0.07757719606161118,
      "learning_rate": 3.0249922863313795e-05,
      "loss": 0.0004,
      "step": 64010
    },
    {
      "epoch": 19.753162604134527,
      "grad_norm": 1.9177303314208984,
      "learning_rate": 3.0246837395865474e-05,
      "loss": 0.002,
      "step": 64020
    },
    {
      "epoch": 19.756248071582846,
      "grad_norm": 0.006802248768508434,
      "learning_rate": 3.0243751928417156e-05,
      "loss": 0.0002,
      "step": 64030
    },
    {
      "epoch": 19.759333539031164,
      "grad_norm": 0.42179593443870544,
      "learning_rate": 3.0240666460968835e-05,
      "loss": 0.0092,
      "step": 64040
    },
    {
      "epoch": 19.762419006479483,
      "grad_norm": 0.0007067151600494981,
      "learning_rate": 3.023758099352052e-05,
      "loss": 0.0,
      "step": 64050
    },
    {
      "epoch": 19.7655044739278,
      "grad_norm": 0.020379064604640007,
      "learning_rate": 3.0234495526072204e-05,
      "loss": 0.0011,
      "step": 64060
    },
    {
      "epoch": 19.768589941376117,
      "grad_norm": 0.00041530613088980317,
      "learning_rate": 3.0231410058623883e-05,
      "loss": 0.0001,
      "step": 64070
    },
    {
      "epoch": 19.771675408824436,
      "grad_norm": 1.5364204955403693e-05,
      "learning_rate": 3.0228324591175565e-05,
      "loss": 0.0032,
      "step": 64080
    },
    {
      "epoch": 19.774760876272754,
      "grad_norm": 0.0003857017436530441,
      "learning_rate": 3.0225239123727244e-05,
      "loss": 0.0002,
      "step": 64090
    },
    {
      "epoch": 19.777846343721073,
      "grad_norm": 0.10806026309728622,
      "learning_rate": 3.022215365627893e-05,
      "loss": 0.0001,
      "step": 64100
    },
    {
      "epoch": 19.780931811169392,
      "grad_norm": 0.00349379051476717,
      "learning_rate": 3.0219068188830606e-05,
      "loss": 0.0009,
      "step": 64110
    },
    {
      "epoch": 19.78401727861771,
      "grad_norm": 0.4083188474178314,
      "learning_rate": 3.0215982721382292e-05,
      "loss": 0.0007,
      "step": 64120
    },
    {
      "epoch": 19.78710274606603,
      "grad_norm": 0.025777427479624748,
      "learning_rate": 3.0212897253933974e-05,
      "loss": 0.0001,
      "step": 64130
    },
    {
      "epoch": 19.790188213514348,
      "grad_norm": 0.00017191001097671688,
      "learning_rate": 3.0209811786485653e-05,
      "loss": 0.0,
      "step": 64140
    },
    {
      "epoch": 19.793273680962667,
      "grad_norm": 6.88859581714496e-05,
      "learning_rate": 3.0206726319037336e-05,
      "loss": 0.0006,
      "step": 64150
    },
    {
      "epoch": 19.796359148410986,
      "grad_norm": 0.0002253632846986875,
      "learning_rate": 3.0203640851589015e-05,
      "loss": 0.0001,
      "step": 64160
    },
    {
      "epoch": 19.799444615859304,
      "grad_norm": 2.0253730781405466e-06,
      "learning_rate": 3.02005553841407e-05,
      "loss": 0.0016,
      "step": 64170
    },
    {
      "epoch": 19.80253008330762,
      "grad_norm": 0.0023258065339177847,
      "learning_rate": 3.0197469916692376e-05,
      "loss": 0.0012,
      "step": 64180
    },
    {
      "epoch": 19.805615550755938,
      "grad_norm": 0.00490533746778965,
      "learning_rate": 3.0194384449244062e-05,
      "loss": 0.0,
      "step": 64190
    },
    {
      "epoch": 19.808701018204257,
      "grad_norm": 0.016507882624864578,
      "learning_rate": 3.0191298981795745e-05,
      "loss": 0.0036,
      "step": 64200
    },
    {
      "epoch": 19.811786485652576,
      "grad_norm": 2.520909947634209e-05,
      "learning_rate": 3.0188213514347424e-05,
      "loss": 0.0001,
      "step": 64210
    },
    {
      "epoch": 19.814871953100894,
      "grad_norm": 0.015296591445803642,
      "learning_rate": 3.018512804689911e-05,
      "loss": 0.0003,
      "step": 64220
    },
    {
      "epoch": 19.817957420549213,
      "grad_norm": 0.142878919839859,
      "learning_rate": 3.0182042579450785e-05,
      "loss": 0.0002,
      "step": 64230
    },
    {
      "epoch": 19.821042887997532,
      "grad_norm": 0.00023246192722581327,
      "learning_rate": 3.017895711200247e-05,
      "loss": 0.0005,
      "step": 64240
    },
    {
      "epoch": 19.82412835544585,
      "grad_norm": 0.0003636076289694756,
      "learning_rate": 3.017587164455415e-05,
      "loss": 0.0004,
      "step": 64250
    },
    {
      "epoch": 19.82721382289417,
      "grad_norm": 0.0003621239447966218,
      "learning_rate": 3.0172786177105833e-05,
      "loss": 0.0003,
      "step": 64260
    },
    {
      "epoch": 19.830299290342488,
      "grad_norm": 2.2093427181243896,
      "learning_rate": 3.0169700709657515e-05,
      "loss": 0.003,
      "step": 64270
    },
    {
      "epoch": 19.833384757790807,
      "grad_norm": 0.0005710923578590155,
      "learning_rate": 3.0166615242209194e-05,
      "loss": 0.0038,
      "step": 64280
    },
    {
      "epoch": 19.836470225239125,
      "grad_norm": 0.0007508674170821905,
      "learning_rate": 3.016352977476088e-05,
      "loss": 0.0003,
      "step": 64290
    },
    {
      "epoch": 19.83955569268744,
      "grad_norm": 0.5905855894088745,
      "learning_rate": 3.0160444307312556e-05,
      "loss": 0.0005,
      "step": 64300
    },
    {
      "epoch": 19.84264116013576,
      "grad_norm": 0.0002709653927013278,
      "learning_rate": 3.0157358839864242e-05,
      "loss": 0.0,
      "step": 64310
    },
    {
      "epoch": 19.845726627584078,
      "grad_norm": 0.788102924823761,
      "learning_rate": 3.015427337241592e-05,
      "loss": 0.0004,
      "step": 64320
    },
    {
      "epoch": 19.848812095032397,
      "grad_norm": 0.0046406821347773075,
      "learning_rate": 3.0151187904967603e-05,
      "loss": 0.0037,
      "step": 64330
    },
    {
      "epoch": 19.851897562480715,
      "grad_norm": 0.00912815984338522,
      "learning_rate": 3.014810243751929e-05,
      "loss": 0.0007,
      "step": 64340
    },
    {
      "epoch": 19.854983029929034,
      "grad_norm": 1.1676915884017944,
      "learning_rate": 3.0145016970070965e-05,
      "loss": 0.0063,
      "step": 64350
    },
    {
      "epoch": 19.858068497377353,
      "grad_norm": 0.830432653427124,
      "learning_rate": 3.014193150262265e-05,
      "loss": 0.0006,
      "step": 64360
    },
    {
      "epoch": 19.86115396482567,
      "grad_norm": 0.0002418086223769933,
      "learning_rate": 3.013884603517433e-05,
      "loss": 0.0,
      "step": 64370
    },
    {
      "epoch": 19.86423943227399,
      "grad_norm": 0.0005780159845016897,
      "learning_rate": 3.0135760567726012e-05,
      "loss": 0.0014,
      "step": 64380
    },
    {
      "epoch": 19.86732489972231,
      "grad_norm": 0.0006459782598540187,
      "learning_rate": 3.013267510027769e-05,
      "loss": 0.0011,
      "step": 64390
    },
    {
      "epoch": 19.870410367170628,
      "grad_norm": 0.0006410191999748349,
      "learning_rate": 3.0129589632829374e-05,
      "loss": 0.0052,
      "step": 64400
    },
    {
      "epoch": 19.873495834618943,
      "grad_norm": 0.0003181317588314414,
      "learning_rate": 3.012650416538106e-05,
      "loss": 0.0017,
      "step": 64410
    },
    {
      "epoch": 19.87658130206726,
      "grad_norm": 0.0017891157185658813,
      "learning_rate": 3.0123418697932736e-05,
      "loss": 0.0003,
      "step": 64420
    },
    {
      "epoch": 19.87966676951558,
      "grad_norm": 1.582054392201826e-05,
      "learning_rate": 3.012033323048442e-05,
      "loss": 0.0001,
      "step": 64430
    },
    {
      "epoch": 19.8827522369639,
      "grad_norm": 0.0002692016714718193,
      "learning_rate": 3.01172477630361e-05,
      "loss": 0.0003,
      "step": 64440
    },
    {
      "epoch": 19.885837704412218,
      "grad_norm": 0.00048303077346645296,
      "learning_rate": 3.0114162295587783e-05,
      "loss": 0.0,
      "step": 64450
    },
    {
      "epoch": 19.888923171860537,
      "grad_norm": 0.00017696271243039519,
      "learning_rate": 3.011107682813947e-05,
      "loss": 0.0002,
      "step": 64460
    },
    {
      "epoch": 19.892008639308855,
      "grad_norm": 3.182891845703125,
      "learning_rate": 3.0107991360691145e-05,
      "loss": 0.0034,
      "step": 64470
    },
    {
      "epoch": 19.895094106757174,
      "grad_norm": 0.014960291795432568,
      "learning_rate": 3.010490589324283e-05,
      "loss": 0.0071,
      "step": 64480
    },
    {
      "epoch": 19.898179574205493,
      "grad_norm": 0.001613110420294106,
      "learning_rate": 3.010182042579451e-05,
      "loss": 0.0003,
      "step": 64490
    },
    {
      "epoch": 19.90126504165381,
      "grad_norm": 0.010171367786824703,
      "learning_rate": 3.0098734958346192e-05,
      "loss": 0.0002,
      "step": 64500
    },
    {
      "epoch": 19.90435050910213,
      "grad_norm": 0.4750154912471771,
      "learning_rate": 3.009564949089787e-05,
      "loss": 0.005,
      "step": 64510
    },
    {
      "epoch": 19.90743597655045,
      "grad_norm": 0.00017996708629652858,
      "learning_rate": 3.0092564023449554e-05,
      "loss": 0.0014,
      "step": 64520
    },
    {
      "epoch": 19.910521443998764,
      "grad_norm": 0.0003062244795728475,
      "learning_rate": 3.008947855600124e-05,
      "loss": 0.0005,
      "step": 64530
    },
    {
      "epoch": 19.913606911447083,
      "grad_norm": 0.0004746593185700476,
      "learning_rate": 3.0086393088552915e-05,
      "loss": 0.0004,
      "step": 64540
    },
    {
      "epoch": 19.9166923788954,
      "grad_norm": 7.271395588759333e-05,
      "learning_rate": 3.00833076211046e-05,
      "loss": 0.0001,
      "step": 64550
    },
    {
      "epoch": 19.91977784634372,
      "grad_norm": 0.006393025629222393,
      "learning_rate": 3.008022215365628e-05,
      "loss": 0.0,
      "step": 64560
    },
    {
      "epoch": 19.92286331379204,
      "grad_norm": 6.78635187796317e-05,
      "learning_rate": 3.0077136686207963e-05,
      "loss": 0.0008,
      "step": 64570
    },
    {
      "epoch": 19.925948781240358,
      "grad_norm": 0.006930143106728792,
      "learning_rate": 3.007405121875964e-05,
      "loss": 0.0001,
      "step": 64580
    },
    {
      "epoch": 19.929034248688676,
      "grad_norm": 0.02310589700937271,
      "learning_rate": 3.0070965751311324e-05,
      "loss": 0.0,
      "step": 64590
    },
    {
      "epoch": 19.932119716136995,
      "grad_norm": 0.00011162002920173109,
      "learning_rate": 3.006788028386301e-05,
      "loss": 0.0,
      "step": 64600
    },
    {
      "epoch": 19.935205183585314,
      "grad_norm": 0.1735779494047165,
      "learning_rate": 3.006479481641469e-05,
      "loss": 0.0003,
      "step": 64610
    },
    {
      "epoch": 19.938290651033633,
      "grad_norm": 0.0032783232163637877,
      "learning_rate": 3.006170934896637e-05,
      "loss": 0.0,
      "step": 64620
    },
    {
      "epoch": 19.94137611848195,
      "grad_norm": 2.9781394914607517e-05,
      "learning_rate": 3.005862388151805e-05,
      "loss": 0.0,
      "step": 64630
    },
    {
      "epoch": 19.94446158593027,
      "grad_norm": 0.0023845683317631483,
      "learning_rate": 3.0055538414069733e-05,
      "loss": 0.0,
      "step": 64640
    },
    {
      "epoch": 19.947547053378585,
      "grad_norm": 0.14196933805942535,
      "learning_rate": 3.0052452946621412e-05,
      "loss": 0.0003,
      "step": 64650
    },
    {
      "epoch": 19.950632520826904,
      "grad_norm": 0.016983963549137115,
      "learning_rate": 3.0049367479173095e-05,
      "loss": 0.0001,
      "step": 64660
    },
    {
      "epoch": 19.953717988275223,
      "grad_norm": 0.015743868425488472,
      "learning_rate": 3.004628201172478e-05,
      "loss": 0.0002,
      "step": 64670
    },
    {
      "epoch": 19.95680345572354,
      "grad_norm": 0.06338083744049072,
      "learning_rate": 3.004319654427646e-05,
      "loss": 0.0001,
      "step": 64680
    },
    {
      "epoch": 19.95988892317186,
      "grad_norm": 0.0064394534565508366,
      "learning_rate": 3.0040111076828142e-05,
      "loss": 0.0001,
      "step": 64690
    },
    {
      "epoch": 19.96297439062018,
      "grad_norm": 0.0006087911897338927,
      "learning_rate": 3.003702560937982e-05,
      "loss": 0.0027,
      "step": 64700
    },
    {
      "epoch": 19.966059858068498,
      "grad_norm": 0.00031479381141252816,
      "learning_rate": 3.0033940141931504e-05,
      "loss": 0.0001,
      "step": 64710
    },
    {
      "epoch": 19.969145325516816,
      "grad_norm": 0.0008995783282443881,
      "learning_rate": 3.0030854674483183e-05,
      "loss": 0.0007,
      "step": 64720
    },
    {
      "epoch": 19.972230792965135,
      "grad_norm": 0.005479545798152685,
      "learning_rate": 3.002776920703487e-05,
      "loss": 0.0,
      "step": 64730
    },
    {
      "epoch": 19.975316260413454,
      "grad_norm": 0.003007570980116725,
      "learning_rate": 3.002468373958655e-05,
      "loss": 0.0001,
      "step": 64740
    },
    {
      "epoch": 19.978401727861772,
      "grad_norm": 0.0003581697528716177,
      "learning_rate": 3.002159827213823e-05,
      "loss": 0.0001,
      "step": 64750
    },
    {
      "epoch": 19.981487195310088,
      "grad_norm": 0.17641136050224304,
      "learning_rate": 3.0018512804689913e-05,
      "loss": 0.0026,
      "step": 64760
    },
    {
      "epoch": 19.984572662758406,
      "grad_norm": 0.7422496676445007,
      "learning_rate": 3.0015427337241592e-05,
      "loss": 0.0004,
      "step": 64770
    },
    {
      "epoch": 19.987658130206725,
      "grad_norm": 0.0013988668797537684,
      "learning_rate": 3.0012341869793274e-05,
      "loss": 0.0001,
      "step": 64780
    },
    {
      "epoch": 19.990743597655044,
      "grad_norm": 1.2361779226921499e-05,
      "learning_rate": 3.0009256402344953e-05,
      "loss": 0.0044,
      "step": 64790
    },
    {
      "epoch": 19.993829065103363,
      "grad_norm": 0.002720748772844672,
      "learning_rate": 3.000617093489664e-05,
      "loss": 0.0005,
      "step": 64800
    },
    {
      "epoch": 19.99691453255168,
      "grad_norm": 0.0024260524660348892,
      "learning_rate": 3.000308546744832e-05,
      "loss": 0.0002,
      "step": 64810
    },
    {
      "epoch": 20.0,
      "grad_norm": 26.173484802246094,
      "learning_rate": 3e-05,
      "loss": 0.1472,
      "step": 64820
    },
    {
      "epoch": 20.0,
      "eval_accuracy_branch1": 0.9997010117377005,
      "eval_accuracy_branch2": 0.4750441248806458,
      "eval_f1_branch1": 0.9995310388500211,
      "eval_f1_branch2": 0.470992358600969,
      "eval_loss": 0.0001357423170702532,
      "eval_precision_branch1": 0.9995363019607514,
      "eval_precision_branch2": 0.5014641168925751,
      "eval_recall_branch1": 0.9995269054225631,
      "eval_recall_branch2": 0.501605856312028,
      "eval_runtime": 239.2072,
      "eval_samples_per_second": 433.444,
      "eval_steps_per_second": 54.183,
      "step": 64820
    },
    {
      "epoch": 20.00308546744832,
      "grad_norm": 4.319306754041463e-05,
      "learning_rate": 2.9996914532551683e-05,
      "loss": 0.0018,
      "step": 64830
    },
    {
      "epoch": 20.006170934896637,
      "grad_norm": 2.717686176300049,
      "learning_rate": 2.9993829065103362e-05,
      "loss": 0.0047,
      "step": 64840
    },
    {
      "epoch": 20.009256402344956,
      "grad_norm": 0.5564598441123962,
      "learning_rate": 2.9990743597655048e-05,
      "loss": 0.0004,
      "step": 64850
    },
    {
      "epoch": 20.012341869793275,
      "grad_norm": 0.007645077537745237,
      "learning_rate": 2.9987658130206724e-05,
      "loss": 0.0001,
      "step": 64860
    },
    {
      "epoch": 20.015427337241594,
      "grad_norm": 0.0005872822366654873,
      "learning_rate": 2.998457266275841e-05,
      "loss": 0.0005,
      "step": 64870
    },
    {
      "epoch": 20.01851280468991,
      "grad_norm": 2.050805233011488e-05,
      "learning_rate": 2.9981487195310092e-05,
      "loss": 0.0001,
      "step": 64880
    },
    {
      "epoch": 20.021598272138228,
      "grad_norm": 1.7800720930099487,
      "learning_rate": 2.997840172786177e-05,
      "loss": 0.0071,
      "step": 64890
    },
    {
      "epoch": 20.024683739586546,
      "grad_norm": 0.001097674947232008,
      "learning_rate": 2.9975316260413454e-05,
      "loss": 0.0001,
      "step": 64900
    },
    {
      "epoch": 20.027769207034865,
      "grad_norm": 0.07771530747413635,
      "learning_rate": 2.9972230792965133e-05,
      "loss": 0.0052,
      "step": 64910
    },
    {
      "epoch": 20.030854674483184,
      "grad_norm": 0.00036635773722082376,
      "learning_rate": 2.996914532551682e-05,
      "loss": 0.0004,
      "step": 64920
    },
    {
      "epoch": 20.033940141931502,
      "grad_norm": 0.0008414986659772694,
      "learning_rate": 2.99660598580685e-05,
      "loss": 0.0009,
      "step": 64930
    },
    {
      "epoch": 20.03702560937982,
      "grad_norm": 0.014339118264615536,
      "learning_rate": 2.996297439062018e-05,
      "loss": 0.0056,
      "step": 64940
    },
    {
      "epoch": 20.04011107682814,
      "grad_norm": 0.007540320511907339,
      "learning_rate": 2.9959888923171863e-05,
      "loss": 0.0037,
      "step": 64950
    },
    {
      "epoch": 20.04319654427646,
      "grad_norm": 0.03975413367152214,
      "learning_rate": 2.9956803455723542e-05,
      "loss": 0.0,
      "step": 64960
    },
    {
      "epoch": 20.046282011724777,
      "grad_norm": 0.13250894844532013,
      "learning_rate": 2.9953717988275228e-05,
      "loss": 0.0002,
      "step": 64970
    },
    {
      "epoch": 20.049367479173096,
      "grad_norm": 0.00011383503442630172,
      "learning_rate": 2.9950632520826903e-05,
      "loss": 0.0002,
      "step": 64980
    },
    {
      "epoch": 20.052452946621415,
      "grad_norm": 0.005019726697355509,
      "learning_rate": 2.994754705337859e-05,
      "loss": 0.0,
      "step": 64990
    },
    {
      "epoch": 20.05553841406973,
      "grad_norm": 4.7266010369639844e-05,
      "learning_rate": 2.9944461585930272e-05,
      "loss": 0.004,
      "step": 65000
    },
    {
      "epoch": 20.05862388151805,
      "grad_norm": 0.000867322669364512,
      "learning_rate": 2.994137611848195e-05,
      "loss": 0.0025,
      "step": 65010
    },
    {
      "epoch": 20.061709348966367,
      "grad_norm": 0.39936673641204834,
      "learning_rate": 2.9938290651033633e-05,
      "loss": 0.0001,
      "step": 65020
    },
    {
      "epoch": 20.064794816414686,
      "grad_norm": 0.5604605078697205,
      "learning_rate": 2.9935205183585312e-05,
      "loss": 0.0005,
      "step": 65030
    },
    {
      "epoch": 20.067880283863005,
      "grad_norm": 0.009921780787408352,
      "learning_rate": 2.9932119716137e-05,
      "loss": 0.0,
      "step": 65040
    },
    {
      "epoch": 20.070965751311324,
      "grad_norm": 0.004026526119560003,
      "learning_rate": 2.9929034248688674e-05,
      "loss": 0.0007,
      "step": 65050
    },
    {
      "epoch": 20.074051218759642,
      "grad_norm": 0.00011481014371383935,
      "learning_rate": 2.992594878124036e-05,
      "loss": 0.0039,
      "step": 65060
    },
    {
      "epoch": 20.07713668620796,
      "grad_norm": 0.1304710954427719,
      "learning_rate": 2.9922863313792042e-05,
      "loss": 0.0036,
      "step": 65070
    },
    {
      "epoch": 20.08022215365628,
      "grad_norm": 0.0005790620925836265,
      "learning_rate": 2.991977784634372e-05,
      "loss": 0.0027,
      "step": 65080
    },
    {
      "epoch": 20.0833076211046,
      "grad_norm": 0.005511058960109949,
      "learning_rate": 2.9916692378895407e-05,
      "loss": 0.0024,
      "step": 65090
    },
    {
      "epoch": 20.086393088552917,
      "grad_norm": 0.0009696671040728688,
      "learning_rate": 2.9913606911447083e-05,
      "loss": 0.0004,
      "step": 65100
    },
    {
      "epoch": 20.089478556001236,
      "grad_norm": 3.2570977055002004e-05,
      "learning_rate": 2.991052144399877e-05,
      "loss": 0.0003,
      "step": 65110
    },
    {
      "epoch": 20.09256402344955,
      "grad_norm": 0.0005339583731256425,
      "learning_rate": 2.9907435976550448e-05,
      "loss": 0.0006,
      "step": 65120
    },
    {
      "epoch": 20.09564949089787,
      "grad_norm": 6.678657518932596e-05,
      "learning_rate": 2.990435050910213e-05,
      "loss": 0.0001,
      "step": 65130
    },
    {
      "epoch": 20.09873495834619,
      "grad_norm": 0.06706530600786209,
      "learning_rate": 2.9901265041653813e-05,
      "loss": 0.0002,
      "step": 65140
    },
    {
      "epoch": 20.101820425794507,
      "grad_norm": 0.0007373492117039859,
      "learning_rate": 2.9898179574205492e-05,
      "loss": 0.0,
      "step": 65150
    },
    {
      "epoch": 20.104905893242826,
      "grad_norm": 0.008721761405467987,
      "learning_rate": 2.9895094106757178e-05,
      "loss": 0.0016,
      "step": 65160
    },
    {
      "epoch": 20.107991360691145,
      "grad_norm": 1.2323099374771118,
      "learning_rate": 2.9892008639308854e-05,
      "loss": 0.0016,
      "step": 65170
    },
    {
      "epoch": 20.111076828139463,
      "grad_norm": 0.00020748841052409261,
      "learning_rate": 2.988892317186054e-05,
      "loss": 0.0018,
      "step": 65180
    },
    {
      "epoch": 20.114162295587782,
      "grad_norm": 5.5199609050760046e-05,
      "learning_rate": 2.988583770441222e-05,
      "loss": 0.0026,
      "step": 65190
    },
    {
      "epoch": 20.1172477630361,
      "grad_norm": 0.00023535768559668213,
      "learning_rate": 2.98827522369639e-05,
      "loss": 0.0001,
      "step": 65200
    },
    {
      "epoch": 20.12033323048442,
      "grad_norm": 2.0003257304779254e-05,
      "learning_rate": 2.9879666769515587e-05,
      "loss": 0.0009,
      "step": 65210
    },
    {
      "epoch": 20.12341869793274,
      "grad_norm": 0.013982835225760937,
      "learning_rate": 2.9876581302067263e-05,
      "loss": 0.0015,
      "step": 65220
    },
    {
      "epoch": 20.126504165381053,
      "grad_norm": 0.00036389403976500034,
      "learning_rate": 2.987349583461895e-05,
      "loss": 0.0003,
      "step": 65230
    },
    {
      "epoch": 20.129589632829372,
      "grad_norm": 0.00150237453635782,
      "learning_rate": 2.9870410367170628e-05,
      "loss": 0.0013,
      "step": 65240
    },
    {
      "epoch": 20.13267510027769,
      "grad_norm": 0.0013826227514073253,
      "learning_rate": 2.986732489972231e-05,
      "loss": 0.0022,
      "step": 65250
    },
    {
      "epoch": 20.13576056772601,
      "grad_norm": 1.0370068594056647e-05,
      "learning_rate": 2.986423943227399e-05,
      "loss": 0.0006,
      "step": 65260
    },
    {
      "epoch": 20.13884603517433,
      "grad_norm": 8.514742512488738e-05,
      "learning_rate": 2.986115396482567e-05,
      "loss": 0.0036,
      "step": 65270
    },
    {
      "epoch": 20.141931502622647,
      "grad_norm": 0.0017619264544919133,
      "learning_rate": 2.9858068497377357e-05,
      "loss": 0.0039,
      "step": 65280
    },
    {
      "epoch": 20.145016970070966,
      "grad_norm": 0.0007816151482984424,
      "learning_rate": 2.9854983029929033e-05,
      "loss": 0.0004,
      "step": 65290
    },
    {
      "epoch": 20.148102437519285,
      "grad_norm": 0.029755907133221626,
      "learning_rate": 2.985189756248072e-05,
      "loss": 0.0019,
      "step": 65300
    },
    {
      "epoch": 20.151187904967603,
      "grad_norm": 0.398662269115448,
      "learning_rate": 2.9848812095032398e-05,
      "loss": 0.0012,
      "step": 65310
    },
    {
      "epoch": 20.154273372415922,
      "grad_norm": 6.383047002600506e-05,
      "learning_rate": 2.984572662758408e-05,
      "loss": 0.0017,
      "step": 65320
    },
    {
      "epoch": 20.15735883986424,
      "grad_norm": 0.08763760328292847,
      "learning_rate": 2.9842641160135763e-05,
      "loss": 0.0001,
      "step": 65330
    },
    {
      "epoch": 20.16044430731256,
      "grad_norm": 2.5159897804260254,
      "learning_rate": 2.9839555692687442e-05,
      "loss": 0.0036,
      "step": 65340
    },
    {
      "epoch": 20.163529774760875,
      "grad_norm": 0.0005155300605110824,
      "learning_rate": 2.9836470225239128e-05,
      "loss": 0.0029,
      "step": 65350
    },
    {
      "epoch": 20.166615242209193,
      "grad_norm": 0.10413256287574768,
      "learning_rate": 2.9833384757790807e-05,
      "loss": 0.0011,
      "step": 65360
    },
    {
      "epoch": 20.169700709657512,
      "grad_norm": 6.200426287250593e-05,
      "learning_rate": 2.983029929034249e-05,
      "loss": 0.0,
      "step": 65370
    },
    {
      "epoch": 20.17278617710583,
      "grad_norm": 5.298164523992455e-06,
      "learning_rate": 2.982721382289417e-05,
      "loss": 0.0,
      "step": 65380
    },
    {
      "epoch": 20.17587164455415,
      "grad_norm": 0.008162105455994606,
      "learning_rate": 2.982412835544585e-05,
      "loss": 0.0004,
      "step": 65390
    },
    {
      "epoch": 20.178957112002468,
      "grad_norm": 4.584335329127498e-06,
      "learning_rate": 2.9821042887997537e-05,
      "loss": 0.0003,
      "step": 65400
    },
    {
      "epoch": 20.182042579450787,
      "grad_norm": 0.0013084656093269587,
      "learning_rate": 2.9817957420549213e-05,
      "loss": 0.0001,
      "step": 65410
    },
    {
      "epoch": 20.185128046899106,
      "grad_norm": 0.00699131703004241,
      "learning_rate": 2.98148719531009e-05,
      "loss": 0.0002,
      "step": 65420
    },
    {
      "epoch": 20.188213514347424,
      "grad_norm": 6.863809630885953e-06,
      "learning_rate": 2.9811786485652578e-05,
      "loss": 0.0,
      "step": 65430
    },
    {
      "epoch": 20.191298981795743,
      "grad_norm": 0.37047696113586426,
      "learning_rate": 2.980870101820426e-05,
      "loss": 0.0002,
      "step": 65440
    },
    {
      "epoch": 20.194384449244062,
      "grad_norm": 0.7020037770271301,
      "learning_rate": 2.980561555075594e-05,
      "loss": 0.0003,
      "step": 65450
    },
    {
      "epoch": 20.19746991669238,
      "grad_norm": 0.0004668983456213027,
      "learning_rate": 2.980253008330762e-05,
      "loss": 0.0016,
      "step": 65460
    },
    {
      "epoch": 20.200555384140696,
      "grad_norm": 9.802309796214104e-05,
      "learning_rate": 2.9799444615859308e-05,
      "loss": 0.0,
      "step": 65470
    },
    {
      "epoch": 20.203640851589014,
      "grad_norm": 0.0001428285031579435,
      "learning_rate": 2.9796359148410987e-05,
      "loss": 0.0001,
      "step": 65480
    },
    {
      "epoch": 20.206726319037333,
      "grad_norm": 2.9537459340645e-05,
      "learning_rate": 2.979327368096267e-05,
      "loss": 0.0004,
      "step": 65490
    },
    {
      "epoch": 20.209811786485652,
      "grad_norm": 0.0043118116445839405,
      "learning_rate": 2.9790188213514348e-05,
      "loss": 0.0017,
      "step": 65500
    },
    {
      "epoch": 20.21289725393397,
      "grad_norm": 0.0009685475379228592,
      "learning_rate": 2.978710274606603e-05,
      "loss": 0.0011,
      "step": 65510
    },
    {
      "epoch": 20.21598272138229,
      "grad_norm": 7.209026080090553e-05,
      "learning_rate": 2.978401727861771e-05,
      "loss": 0.0016,
      "step": 65520
    },
    {
      "epoch": 20.219068188830608,
      "grad_norm": 0.0005724100046791136,
      "learning_rate": 2.9780931811169392e-05,
      "loss": 0.0001,
      "step": 65530
    },
    {
      "epoch": 20.222153656278927,
      "grad_norm": 0.00011169196659466252,
      "learning_rate": 2.9777846343721078e-05,
      "loss": 0.0002,
      "step": 65540
    },
    {
      "epoch": 20.225239123727246,
      "grad_norm": 0.0008495370857417583,
      "learning_rate": 2.9774760876272757e-05,
      "loss": 0.0003,
      "step": 65550
    },
    {
      "epoch": 20.228324591175564,
      "grad_norm": 0.0001680285349721089,
      "learning_rate": 2.977167540882444e-05,
      "loss": 0.0003,
      "step": 65560
    },
    {
      "epoch": 20.231410058623883,
      "grad_norm": 2.174933069909457e-05,
      "learning_rate": 2.976858994137612e-05,
      "loss": 0.0001,
      "step": 65570
    },
    {
      "epoch": 20.2344955260722,
      "grad_norm": 0.0008537946850992739,
      "learning_rate": 2.97655044739278e-05,
      "loss": 0.0001,
      "step": 65580
    },
    {
      "epoch": 20.237580993520517,
      "grad_norm": 2.270287586725317e-05,
      "learning_rate": 2.976241900647948e-05,
      "loss": 0.0002,
      "step": 65590
    },
    {
      "epoch": 20.240666460968836,
      "grad_norm": 0.00010860740439966321,
      "learning_rate": 2.9759333539031163e-05,
      "loss": 0.0,
      "step": 65600
    },
    {
      "epoch": 20.243751928417154,
      "grad_norm": 0.0016575397457927465,
      "learning_rate": 2.975624807158285e-05,
      "loss": 0.0,
      "step": 65610
    },
    {
      "epoch": 20.246837395865473,
      "grad_norm": 0.0037316097877919674,
      "learning_rate": 2.9753162604134528e-05,
      "loss": 0.0002,
      "step": 65620
    },
    {
      "epoch": 20.24992286331379,
      "grad_norm": 8.736276868148707e-06,
      "learning_rate": 2.975007713668621e-05,
      "loss": 0.0007,
      "step": 65630
    },
    {
      "epoch": 20.25300833076211,
      "grad_norm": 0.011751247569918633,
      "learning_rate": 2.974699166923789e-05,
      "loss": 0.0,
      "step": 65640
    },
    {
      "epoch": 20.25609379821043,
      "grad_norm": 0.2551460862159729,
      "learning_rate": 2.9743906201789572e-05,
      "loss": 0.0053,
      "step": 65650
    },
    {
      "epoch": 20.259179265658748,
      "grad_norm": 0.0002522389986552298,
      "learning_rate": 2.974082073434125e-05,
      "loss": 0.0001,
      "step": 65660
    },
    {
      "epoch": 20.262264733107067,
      "grad_norm": 0.00031001094612292945,
      "learning_rate": 2.9737735266892937e-05,
      "loss": 0.0005,
      "step": 65670
    },
    {
      "epoch": 20.265350200555385,
      "grad_norm": 0.004985973704606295,
      "learning_rate": 2.973464979944462e-05,
      "loss": 0.0005,
      "step": 65680
    },
    {
      "epoch": 20.268435668003704,
      "grad_norm": 8.792719745542854e-05,
      "learning_rate": 2.97315643319963e-05,
      "loss": 0.0134,
      "step": 65690
    },
    {
      "epoch": 20.27152113545202,
      "grad_norm": 0.10047100484371185,
      "learning_rate": 2.972847886454798e-05,
      "loss": 0.0002,
      "step": 65700
    },
    {
      "epoch": 20.274606602900338,
      "grad_norm": 0.00025951428688131273,
      "learning_rate": 2.972539339709966e-05,
      "loss": 0.002,
      "step": 65710
    },
    {
      "epoch": 20.277692070348657,
      "grad_norm": 0.0005609855288639665,
      "learning_rate": 2.9722307929651342e-05,
      "loss": 0.0004,
      "step": 65720
    },
    {
      "epoch": 20.280777537796975,
      "grad_norm": 0.009769846685230732,
      "learning_rate": 2.971922246220302e-05,
      "loss": 0.001,
      "step": 65730
    },
    {
      "epoch": 20.283863005245294,
      "grad_norm": 0.00018612797430250794,
      "learning_rate": 2.9716136994754707e-05,
      "loss": 0.0004,
      "step": 65740
    },
    {
      "epoch": 20.286948472693613,
      "grad_norm": 0.0013100530486553907,
      "learning_rate": 2.971305152730639e-05,
      "loss": 0.0052,
      "step": 65750
    },
    {
      "epoch": 20.29003394014193,
      "grad_norm": 0.00217764382250607,
      "learning_rate": 2.970996605985807e-05,
      "loss": 0.0003,
      "step": 65760
    },
    {
      "epoch": 20.29311940759025,
      "grad_norm": 0.002923772670328617,
      "learning_rate": 2.970688059240975e-05,
      "loss": 0.0006,
      "step": 65770
    },
    {
      "epoch": 20.29620487503857,
      "grad_norm": 0.015935370698571205,
      "learning_rate": 2.970379512496143e-05,
      "loss": 0.0031,
      "step": 65780
    },
    {
      "epoch": 20.299290342486888,
      "grad_norm": 0.0050608497112989426,
      "learning_rate": 2.9700709657513116e-05,
      "loss": 0.0,
      "step": 65790
    },
    {
      "epoch": 20.302375809935207,
      "grad_norm": 0.023753881454467773,
      "learning_rate": 2.96976241900648e-05,
      "loss": 0.0006,
      "step": 65800
    },
    {
      "epoch": 20.305461277383525,
      "grad_norm": 0.0001466642861487344,
      "learning_rate": 2.9694538722616478e-05,
      "loss": 0.0008,
      "step": 65810
    },
    {
      "epoch": 20.30854674483184,
      "grad_norm": 0.0067480457946658134,
      "learning_rate": 2.969145325516816e-05,
      "loss": 0.0005,
      "step": 65820
    },
    {
      "epoch": 20.31163221228016,
      "grad_norm": 0.004657546989619732,
      "learning_rate": 2.968836778771984e-05,
      "loss": 0.0061,
      "step": 65830
    },
    {
      "epoch": 20.314717679728478,
      "grad_norm": 5.91051830269862e-05,
      "learning_rate": 2.9685282320271522e-05,
      "loss": 0.0008,
      "step": 65840
    },
    {
      "epoch": 20.317803147176797,
      "grad_norm": 0.10561235249042511,
      "learning_rate": 2.96821968528232e-05,
      "loss": 0.0001,
      "step": 65850
    },
    {
      "epoch": 20.320888614625115,
      "grad_norm": 0.000706972845364362,
      "learning_rate": 2.9679111385374887e-05,
      "loss": 0.0006,
      "step": 65860
    },
    {
      "epoch": 20.323974082073434,
      "grad_norm": 0.2670813798904419,
      "learning_rate": 2.967602591792657e-05,
      "loss": 0.0002,
      "step": 65870
    },
    {
      "epoch": 20.327059549521753,
      "grad_norm": 0.0004453317087609321,
      "learning_rate": 2.967294045047825e-05,
      "loss": 0.0004,
      "step": 65880
    },
    {
      "epoch": 20.33014501697007,
      "grad_norm": 1.424928903579712,
      "learning_rate": 2.966985498302993e-05,
      "loss": 0.0033,
      "step": 65890
    },
    {
      "epoch": 20.33323048441839,
      "grad_norm": 1.135872483253479,
      "learning_rate": 2.966676951558161e-05,
      "loss": 0.0008,
      "step": 65900
    },
    {
      "epoch": 20.33631595186671,
      "grad_norm": 0.00024673351435922086,
      "learning_rate": 2.9663684048133296e-05,
      "loss": 0.0012,
      "step": 65910
    },
    {
      "epoch": 20.339401419315028,
      "grad_norm": 0.002897142432630062,
      "learning_rate": 2.966059858068497e-05,
      "loss": 0.0,
      "step": 65920
    },
    {
      "epoch": 20.342486886763346,
      "grad_norm": 0.0013559383805841208,
      "learning_rate": 2.9657513113236657e-05,
      "loss": 0.0,
      "step": 65930
    },
    {
      "epoch": 20.34557235421166,
      "grad_norm": 0.0015523487236350775,
      "learning_rate": 2.965442764578834e-05,
      "loss": 0.0061,
      "step": 65940
    },
    {
      "epoch": 20.34865782165998,
      "grad_norm": 0.005688910372555256,
      "learning_rate": 2.965134217834002e-05,
      "loss": 0.0001,
      "step": 65950
    },
    {
      "epoch": 20.3517432891083,
      "grad_norm": 0.007066608872264624,
      "learning_rate": 2.96482567108917e-05,
      "loss": 0.0002,
      "step": 65960
    },
    {
      "epoch": 20.354828756556618,
      "grad_norm": 0.00036759936483576894,
      "learning_rate": 2.964517124344338e-05,
      "loss": 0.0001,
      "step": 65970
    },
    {
      "epoch": 20.357914224004936,
      "grad_norm": 0.00021789919992443174,
      "learning_rate": 2.9642085775995066e-05,
      "loss": 0.0,
      "step": 65980
    },
    {
      "epoch": 20.360999691453255,
      "grad_norm": 0.0011606266489252448,
      "learning_rate": 2.9639000308546742e-05,
      "loss": 0.0002,
      "step": 65990
    },
    {
      "epoch": 20.364085158901574,
      "grad_norm": 8.557158434996381e-05,
      "learning_rate": 2.9635914841098428e-05,
      "loss": 0.0001,
      "step": 66000
    },
    {
      "epoch": 20.367170626349893,
      "grad_norm": 5.9326168411644176e-05,
      "learning_rate": 2.963282937365011e-05,
      "loss": 0.0005,
      "step": 66010
    },
    {
      "epoch": 20.37025609379821,
      "grad_norm": 0.0006656450568698347,
      "learning_rate": 2.962974390620179e-05,
      "loss": 0.0012,
      "step": 66020
    },
    {
      "epoch": 20.37334156124653,
      "grad_norm": 0.0036202636547386646,
      "learning_rate": 2.9626658438753475e-05,
      "loss": 0.0007,
      "step": 66030
    },
    {
      "epoch": 20.37642702869485,
      "grad_norm": 2.2240950784180313e-05,
      "learning_rate": 2.962357297130515e-05,
      "loss": 0.0106,
      "step": 66040
    },
    {
      "epoch": 20.379512496143164,
      "grad_norm": 0.0005245288484729826,
      "learning_rate": 2.9620487503856837e-05,
      "loss": 0.0012,
      "step": 66050
    },
    {
      "epoch": 20.382597963591483,
      "grad_norm": 1.4992725482443348e-05,
      "learning_rate": 2.9617402036408516e-05,
      "loss": 0.0001,
      "step": 66060
    },
    {
      "epoch": 20.3856834310398,
      "grad_norm": 0.0009835470700636506,
      "learning_rate": 2.96143165689602e-05,
      "loss": 0.0,
      "step": 66070
    },
    {
      "epoch": 20.38876889848812,
      "grad_norm": 3.453533645370044e-05,
      "learning_rate": 2.961123110151188e-05,
      "loss": 0.0002,
      "step": 66080
    },
    {
      "epoch": 20.39185436593644,
      "grad_norm": 0.00010258431575493887,
      "learning_rate": 2.960814563406356e-05,
      "loss": 0.0011,
      "step": 66090
    },
    {
      "epoch": 20.394939833384758,
      "grad_norm": 1.9934830106649315e-06,
      "learning_rate": 2.9605060166615246e-05,
      "loss": 0.0001,
      "step": 66100
    },
    {
      "epoch": 20.398025300833076,
      "grad_norm": 0.0003572838904801756,
      "learning_rate": 2.9601974699166922e-05,
      "loss": 0.0046,
      "step": 66110
    },
    {
      "epoch": 20.401110768281395,
      "grad_norm": 0.001182427047751844,
      "learning_rate": 2.9598889231718608e-05,
      "loss": 0.0037,
      "step": 66120
    },
    {
      "epoch": 20.404196235729714,
      "grad_norm": 5.818010322400369e-05,
      "learning_rate": 2.9595803764270287e-05,
      "loss": 0.0021,
      "step": 66130
    },
    {
      "epoch": 20.407281703178032,
      "grad_norm": 0.0005561583675444126,
      "learning_rate": 2.959271829682197e-05,
      "loss": 0.0,
      "step": 66140
    },
    {
      "epoch": 20.41036717062635,
      "grad_norm": 5.559645433095284e-05,
      "learning_rate": 2.9589632829373655e-05,
      "loss": 0.0026,
      "step": 66150
    },
    {
      "epoch": 20.41345263807467,
      "grad_norm": 5.6407930969726294e-05,
      "learning_rate": 2.958654736192533e-05,
      "loss": 0.0001,
      "step": 66160
    },
    {
      "epoch": 20.416538105522985,
      "grad_norm": 4.129674380237702e-06,
      "learning_rate": 2.9583461894477017e-05,
      "loss": 0.0002,
      "step": 66170
    },
    {
      "epoch": 20.419623572971304,
      "grad_norm": 0.1682804375886917,
      "learning_rate": 2.9580376427028696e-05,
      "loss": 0.0003,
      "step": 66180
    },
    {
      "epoch": 20.422709040419623,
      "grad_norm": 1.6073623555712402e-05,
      "learning_rate": 2.9577290959580378e-05,
      "loss": 0.0002,
      "step": 66190
    },
    {
      "epoch": 20.42579450786794,
      "grad_norm": 0.0004405938379932195,
      "learning_rate": 2.957420549213206e-05,
      "loss": 0.0,
      "step": 66200
    },
    {
      "epoch": 20.42887997531626,
      "grad_norm": 0.00011516975064296275,
      "learning_rate": 2.957112002468374e-05,
      "loss": 0.0011,
      "step": 66210
    },
    {
      "epoch": 20.43196544276458,
      "grad_norm": 0.00021533589460887015,
      "learning_rate": 2.9568034557235426e-05,
      "loss": 0.0,
      "step": 66220
    },
    {
      "epoch": 20.435050910212897,
      "grad_norm": 0.001619288814254105,
      "learning_rate": 2.95649490897871e-05,
      "loss": 0.0001,
      "step": 66230
    },
    {
      "epoch": 20.438136377661216,
      "grad_norm": 0.5232439637184143,
      "learning_rate": 2.9561863622338787e-05,
      "loss": 0.0041,
      "step": 66240
    },
    {
      "epoch": 20.441221845109535,
      "grad_norm": 0.0011743608629330993,
      "learning_rate": 2.9558778154890466e-05,
      "loss": 0.0009,
      "step": 66250
    },
    {
      "epoch": 20.444307312557854,
      "grad_norm": 0.1982944756746292,
      "learning_rate": 2.955569268744215e-05,
      "loss": 0.0006,
      "step": 66260
    },
    {
      "epoch": 20.447392780006172,
      "grad_norm": 0.03898168355226517,
      "learning_rate": 2.9552607219993835e-05,
      "loss": 0.0001,
      "step": 66270
    },
    {
      "epoch": 20.45047824745449,
      "grad_norm": 0.0047829365357756615,
      "learning_rate": 2.954952175254551e-05,
      "loss": 0.0001,
      "step": 66280
    },
    {
      "epoch": 20.453563714902806,
      "grad_norm": 0.019188491627573967,
      "learning_rate": 2.9546436285097196e-05,
      "loss": 0.0006,
      "step": 66290
    },
    {
      "epoch": 20.456649182351125,
      "grad_norm": 2.3702670659986325e-05,
      "learning_rate": 2.9543350817648875e-05,
      "loss": 0.0001,
      "step": 66300
    },
    {
      "epoch": 20.459734649799444,
      "grad_norm": 0.007394077721983194,
      "learning_rate": 2.9540265350200558e-05,
      "loss": 0.0007,
      "step": 66310
    },
    {
      "epoch": 20.462820117247762,
      "grad_norm": 0.0013189241290092468,
      "learning_rate": 2.9537179882752237e-05,
      "loss": 0.0025,
      "step": 66320
    },
    {
      "epoch": 20.46590558469608,
      "grad_norm": 0.0010282498551532626,
      "learning_rate": 2.953409441530392e-05,
      "loss": 0.0,
      "step": 66330
    },
    {
      "epoch": 20.4689910521444,
      "grad_norm": 0.0014669373631477356,
      "learning_rate": 2.9531008947855605e-05,
      "loss": 0.0001,
      "step": 66340
    },
    {
      "epoch": 20.47207651959272,
      "grad_norm": 0.20877666771411896,
      "learning_rate": 2.952792348040728e-05,
      "loss": 0.0002,
      "step": 66350
    },
    {
      "epoch": 20.475161987041037,
      "grad_norm": 0.0037203130777925253,
      "learning_rate": 2.9524838012958967e-05,
      "loss": 0.0084,
      "step": 66360
    },
    {
      "epoch": 20.478247454489356,
      "grad_norm": 2.279057264328003,
      "learning_rate": 2.9521752545510646e-05,
      "loss": 0.0032,
      "step": 66370
    },
    {
      "epoch": 20.481332921937675,
      "grad_norm": 0.00014099106192588806,
      "learning_rate": 2.9518667078062328e-05,
      "loss": 0.0011,
      "step": 66380
    },
    {
      "epoch": 20.484418389385993,
      "grad_norm": 0.021108776330947876,
      "learning_rate": 2.9515581610614007e-05,
      "loss": 0.0037,
      "step": 66390
    },
    {
      "epoch": 20.48750385683431,
      "grad_norm": 0.00444350391626358,
      "learning_rate": 2.951249614316569e-05,
      "loss": 0.0002,
      "step": 66400
    },
    {
      "epoch": 20.490589324282627,
      "grad_norm": 0.00028984647360630333,
      "learning_rate": 2.9509410675717376e-05,
      "loss": 0.001,
      "step": 66410
    },
    {
      "epoch": 20.493674791730946,
      "grad_norm": 0.40269604325294495,
      "learning_rate": 2.9506325208269055e-05,
      "loss": 0.0021,
      "step": 66420
    },
    {
      "epoch": 20.496760259179265,
      "grad_norm": 0.0004227945173624903,
      "learning_rate": 2.9503239740820737e-05,
      "loss": 0.0016,
      "step": 66430
    },
    {
      "epoch": 20.499845726627584,
      "grad_norm": 0.5614710450172424,
      "learning_rate": 2.9500154273372416e-05,
      "loss": 0.0026,
      "step": 66440
    },
    {
      "epoch": 20.502931194075902,
      "grad_norm": 0.003321740310639143,
      "learning_rate": 2.94970688059241e-05,
      "loss": 0.0033,
      "step": 66450
    },
    {
      "epoch": 20.50601666152422,
      "grad_norm": 0.8748687505722046,
      "learning_rate": 2.9493983338475778e-05,
      "loss": 0.0004,
      "step": 66460
    },
    {
      "epoch": 20.50910212897254,
      "grad_norm": 2.542759284551721e-05,
      "learning_rate": 2.949089787102746e-05,
      "loss": 0.0018,
      "step": 66470
    },
    {
      "epoch": 20.51218759642086,
      "grad_norm": 3.0710336432093754e-05,
      "learning_rate": 2.9487812403579146e-05,
      "loss": 0.0005,
      "step": 66480
    },
    {
      "epoch": 20.515273063869177,
      "grad_norm": 0.004705045837908983,
      "learning_rate": 2.9484726936130825e-05,
      "loss": 0.0,
      "step": 66490
    },
    {
      "epoch": 20.518358531317496,
      "grad_norm": 0.0005353775923140347,
      "learning_rate": 2.9481641468682508e-05,
      "loss": 0.0035,
      "step": 66500
    },
    {
      "epoch": 20.521443998765815,
      "grad_norm": 0.2068294882774353,
      "learning_rate": 2.9478556001234187e-05,
      "loss": 0.0028,
      "step": 66510
    },
    {
      "epoch": 20.52452946621413,
      "grad_norm": 0.0002642177860252559,
      "learning_rate": 2.947547053378587e-05,
      "loss": 0.0,
      "step": 66520
    },
    {
      "epoch": 20.52761493366245,
      "grad_norm": 0.0003070809179916978,
      "learning_rate": 2.947238506633755e-05,
      "loss": 0.0008,
      "step": 66530
    },
    {
      "epoch": 20.530700401110767,
      "grad_norm": 0.00026625729515217245,
      "learning_rate": 2.9469299598889234e-05,
      "loss": 0.0073,
      "step": 66540
    },
    {
      "epoch": 20.533785868559086,
      "grad_norm": 0.002053107600659132,
      "learning_rate": 2.9466214131440917e-05,
      "loss": 0.0001,
      "step": 66550
    },
    {
      "epoch": 20.536871336007405,
      "grad_norm": 0.0006580030894838274,
      "learning_rate": 2.9463128663992596e-05,
      "loss": 0.0013,
      "step": 66560
    },
    {
      "epoch": 20.539956803455723,
      "grad_norm": 0.6007614135742188,
      "learning_rate": 2.946004319654428e-05,
      "loss": 0.0009,
      "step": 66570
    },
    {
      "epoch": 20.543042270904042,
      "grad_norm": 0.01306142471730709,
      "learning_rate": 2.9456957729095957e-05,
      "loss": 0.0002,
      "step": 66580
    },
    {
      "epoch": 20.54612773835236,
      "grad_norm": 0.4848612844944,
      "learning_rate": 2.945387226164764e-05,
      "loss": 0.0003,
      "step": 66590
    },
    {
      "epoch": 20.54921320580068,
      "grad_norm": 2.321847677230835,
      "learning_rate": 2.945078679419932e-05,
      "loss": 0.002,
      "step": 66600
    },
    {
      "epoch": 20.552298673249,
      "grad_norm": 0.00031710759503766894,
      "learning_rate": 2.9447701326751005e-05,
      "loss": 0.0,
      "step": 66610
    },
    {
      "epoch": 20.555384140697317,
      "grad_norm": 0.0003885338082909584,
      "learning_rate": 2.9444615859302687e-05,
      "loss": 0.0005,
      "step": 66620
    },
    {
      "epoch": 20.558469608145636,
      "grad_norm": 1.2740495204925537,
      "learning_rate": 2.9441530391854366e-05,
      "loss": 0.0015,
      "step": 66630
    },
    {
      "epoch": 20.56155507559395,
      "grad_norm": 2.4739094442338683e-05,
      "learning_rate": 2.943844492440605e-05,
      "loss": 0.0,
      "step": 66640
    },
    {
      "epoch": 20.56464054304227,
      "grad_norm": 0.01112284418195486,
      "learning_rate": 2.9435359456957728e-05,
      "loss": 0.0074,
      "step": 66650
    },
    {
      "epoch": 20.56772601049059,
      "grad_norm": 2.673778908501845e-05,
      "learning_rate": 2.9432273989509414e-05,
      "loss": 0.0,
      "step": 66660
    },
    {
      "epoch": 20.570811477938907,
      "grad_norm": 2.2914226065040566e-05,
      "learning_rate": 2.9429188522061096e-05,
      "loss": 0.0026,
      "step": 66670
    },
    {
      "epoch": 20.573896945387226,
      "grad_norm": 1.059434175491333,
      "learning_rate": 2.9426103054612775e-05,
      "loss": 0.0021,
      "step": 66680
    },
    {
      "epoch": 20.576982412835545,
      "grad_norm": 0.0010651182383298874,
      "learning_rate": 2.9423017587164458e-05,
      "loss": 0.0003,
      "step": 66690
    },
    {
      "epoch": 20.580067880283863,
      "grad_norm": 1.62890792125836e-05,
      "learning_rate": 2.9419932119716137e-05,
      "loss": 0.0001,
      "step": 66700
    },
    {
      "epoch": 20.583153347732182,
      "grad_norm": 4.177608934696764e-05,
      "learning_rate": 2.941684665226782e-05,
      "loss": 0.0001,
      "step": 66710
    },
    {
      "epoch": 20.5862388151805,
      "grad_norm": 0.00026700651505962014,
      "learning_rate": 2.94137611848195e-05,
      "loss": 0.0002,
      "step": 66720
    },
    {
      "epoch": 20.58932428262882,
      "grad_norm": 2.2595582777285017e-05,
      "learning_rate": 2.9410675717371184e-05,
      "loss": 0.0008,
      "step": 66730
    },
    {
      "epoch": 20.592409750077138,
      "grad_norm": 0.10334338247776031,
      "learning_rate": 2.9407590249922867e-05,
      "loss": 0.0001,
      "step": 66740
    },
    {
      "epoch": 20.595495217525453,
      "grad_norm": 0.1761186271905899,
      "learning_rate": 2.9404504782474546e-05,
      "loss": 0.0001,
      "step": 66750
    },
    {
      "epoch": 20.598580684973772,
      "grad_norm": 0.0164966844022274,
      "learning_rate": 2.940141931502623e-05,
      "loss": 0.0001,
      "step": 66760
    },
    {
      "epoch": 20.60166615242209,
      "grad_norm": 0.028281286358833313,
      "learning_rate": 2.9398333847577908e-05,
      "loss": 0.0001,
      "step": 66770
    },
    {
      "epoch": 20.60475161987041,
      "grad_norm": 0.0001614929351489991,
      "learning_rate": 2.9395248380129593e-05,
      "loss": 0.0051,
      "step": 66780
    },
    {
      "epoch": 20.607837087318728,
      "grad_norm": 5.471434269566089e-05,
      "learning_rate": 2.939216291268127e-05,
      "loss": 0.0,
      "step": 66790
    },
    {
      "epoch": 20.610922554767047,
      "grad_norm": 0.004062524996697903,
      "learning_rate": 2.9389077445232955e-05,
      "loss": 0.0002,
      "step": 66800
    },
    {
      "epoch": 20.614008022215366,
      "grad_norm": 5.310099004418589e-05,
      "learning_rate": 2.9385991977784637e-05,
      "loss": 0.0,
      "step": 66810
    },
    {
      "epoch": 20.617093489663684,
      "grad_norm": 4.805341632163618e-06,
      "learning_rate": 2.9382906510336317e-05,
      "loss": 0.0001,
      "step": 66820
    },
    {
      "epoch": 20.620178957112003,
      "grad_norm": 0.0001437251194147393,
      "learning_rate": 2.9379821042888e-05,
      "loss": 0.0011,
      "step": 66830
    },
    {
      "epoch": 20.623264424560322,
      "grad_norm": 8.883190457709134e-05,
      "learning_rate": 2.9376735575439678e-05,
      "loss": 0.0,
      "step": 66840
    },
    {
      "epoch": 20.62634989200864,
      "grad_norm": 0.00024132378166541457,
      "learning_rate": 2.9373650107991364e-05,
      "loss": 0.0012,
      "step": 66850
    },
    {
      "epoch": 20.62943535945696,
      "grad_norm": 0.0004348595975898206,
      "learning_rate": 2.937056464054304e-05,
      "loss": 0.0004,
      "step": 66860
    },
    {
      "epoch": 20.632520826905274,
      "grad_norm": 1.7774151274352334e-05,
      "learning_rate": 2.9367479173094726e-05,
      "loss": 0.0002,
      "step": 66870
    },
    {
      "epoch": 20.635606294353593,
      "grad_norm": 2.1935522454441525e-05,
      "learning_rate": 2.9364393705646408e-05,
      "loss": 0.0002,
      "step": 66880
    },
    {
      "epoch": 20.638691761801912,
      "grad_norm": 8.16492029116489e-05,
      "learning_rate": 2.9361308238198087e-05,
      "loss": 0.0008,
      "step": 66890
    },
    {
      "epoch": 20.64177722925023,
      "grad_norm": 0.02249479666352272,
      "learning_rate": 2.9358222770749773e-05,
      "loss": 0.0004,
      "step": 66900
    },
    {
      "epoch": 20.64486269669855,
      "grad_norm": 2.1340508460998535,
      "learning_rate": 2.935513730330145e-05,
      "loss": 0.0055,
      "step": 66910
    },
    {
      "epoch": 20.647948164146868,
      "grad_norm": 0.002461687196046114,
      "learning_rate": 2.9352051835853135e-05,
      "loss": 0.0,
      "step": 66920
    },
    {
      "epoch": 20.651033631595187,
      "grad_norm": 0.0010422158520668745,
      "learning_rate": 2.9348966368404814e-05,
      "loss": 0.0,
      "step": 66930
    },
    {
      "epoch": 20.654119099043506,
      "grad_norm": 3.890213974955259e-06,
      "learning_rate": 2.9345880900956496e-05,
      "loss": 0.0003,
      "step": 66940
    },
    {
      "epoch": 20.657204566491824,
      "grad_norm": 0.20725108683109283,
      "learning_rate": 2.934279543350818e-05,
      "loss": 0.0003,
      "step": 66950
    },
    {
      "epoch": 20.660290033940143,
      "grad_norm": 0.0002503581054043025,
      "learning_rate": 2.9339709966059858e-05,
      "loss": 0.0014,
      "step": 66960
    },
    {
      "epoch": 20.66337550138846,
      "grad_norm": 1.8029275452136062e-05,
      "learning_rate": 2.9336624498611544e-05,
      "loss": 0.0,
      "step": 66970
    },
    {
      "epoch": 20.66646096883678,
      "grad_norm": 0.0005079471739009023,
      "learning_rate": 2.933353903116322e-05,
      "loss": 0.0003,
      "step": 66980
    },
    {
      "epoch": 20.669546436285096,
      "grad_norm": 1.5544919967651367,
      "learning_rate": 2.9330453563714905e-05,
      "loss": 0.0023,
      "step": 66990
    },
    {
      "epoch": 20.672631903733414,
      "grad_norm": 0.00819797907024622,
      "learning_rate": 2.9327368096266584e-05,
      "loss": 0.0001,
      "step": 67000
    },
    {
      "epoch": 20.675717371181733,
      "grad_norm": 1.4623041352024302e-05,
      "learning_rate": 2.9324282628818267e-05,
      "loss": 0.0016,
      "step": 67010
    },
    {
      "epoch": 20.67880283863005,
      "grad_norm": 0.0001858315517893061,
      "learning_rate": 2.9321197161369953e-05,
      "loss": 0.0003,
      "step": 67020
    },
    {
      "epoch": 20.68188830607837,
      "grad_norm": 2.8114869594573975,
      "learning_rate": 2.9318111693921628e-05,
      "loss": 0.0162,
      "step": 67030
    },
    {
      "epoch": 20.68497377352669,
      "grad_norm": 2.477259397506714,
      "learning_rate": 2.9315026226473314e-05,
      "loss": 0.0076,
      "step": 67040
    },
    {
      "epoch": 20.688059240975008,
      "grad_norm": 0.0021981794852763414,
      "learning_rate": 2.9311940759024993e-05,
      "loss": 0.001,
      "step": 67050
    },
    {
      "epoch": 20.691144708423327,
      "grad_norm": 5.139295899425633e-05,
      "learning_rate": 2.9308855291576676e-05,
      "loss": 0.0035,
      "step": 67060
    },
    {
      "epoch": 20.694230175871645,
      "grad_norm": 6.004732131259516e-05,
      "learning_rate": 2.9305769824128358e-05,
      "loss": 0.0006,
      "step": 67070
    },
    {
      "epoch": 20.697315643319964,
      "grad_norm": 1.9905121326446533,
      "learning_rate": 2.9302684356680037e-05,
      "loss": 0.0019,
      "step": 67080
    },
    {
      "epoch": 20.700401110768283,
      "grad_norm": 0.08901339024305344,
      "learning_rate": 2.9299598889231723e-05,
      "loss": 0.0028,
      "step": 67090
    },
    {
      "epoch": 20.703486578216598,
      "grad_norm": 4.452711582183838,
      "learning_rate": 2.92965134217834e-05,
      "loss": 0.008,
      "step": 67100
    },
    {
      "epoch": 20.706572045664917,
      "grad_norm": 2.4543298422941007e-05,
      "learning_rate": 2.9293427954335085e-05,
      "loss": 0.0003,
      "step": 67110
    },
    {
      "epoch": 20.709657513113235,
      "grad_norm": 4.215756416670047e-05,
      "learning_rate": 2.9290342486886764e-05,
      "loss": 0.0003,
      "step": 67120
    },
    {
      "epoch": 20.712742980561554,
      "grad_norm": 0.0004154668131377548,
      "learning_rate": 2.9287257019438446e-05,
      "loss": 0.0011,
      "step": 67130
    },
    {
      "epoch": 20.715828448009873,
      "grad_norm": 0.00016319628048222512,
      "learning_rate": 2.9284171551990132e-05,
      "loss": 0.0002,
      "step": 67140
    },
    {
      "epoch": 20.71891391545819,
      "grad_norm": 0.608848512172699,
      "learning_rate": 2.9281086084541808e-05,
      "loss": 0.0015,
      "step": 67150
    },
    {
      "epoch": 20.72199938290651,
      "grad_norm": 0.3310367166996002,
      "learning_rate": 2.9278000617093494e-05,
      "loss": 0.0005,
      "step": 67160
    },
    {
      "epoch": 20.72508485035483,
      "grad_norm": 0.00018481128790881485,
      "learning_rate": 2.9274915149645173e-05,
      "loss": 0.0016,
      "step": 67170
    },
    {
      "epoch": 20.728170317803148,
      "grad_norm": 0.007561628241091967,
      "learning_rate": 2.9271829682196855e-05,
      "loss": 0.0133,
      "step": 67180
    },
    {
      "epoch": 20.731255785251467,
      "grad_norm": 0.009318482130765915,
      "learning_rate": 2.9268744214748534e-05,
      "loss": 0.0015,
      "step": 67190
    },
    {
      "epoch": 20.734341252699785,
      "grad_norm": 2.6082663680426776e-05,
      "learning_rate": 2.9265658747300217e-05,
      "loss": 0.0052,
      "step": 67200
    },
    {
      "epoch": 20.737426720148104,
      "grad_norm": 0.00017544608272146434,
      "learning_rate": 2.9262573279851903e-05,
      "loss": 0.0001,
      "step": 67210
    },
    {
      "epoch": 20.740512187596423,
      "grad_norm": 5.300262273522094e-05,
      "learning_rate": 2.925948781240358e-05,
      "loss": 0.002,
      "step": 67220
    },
    {
      "epoch": 20.743597655044738,
      "grad_norm": 0.16762778162956238,
      "learning_rate": 2.9256402344955264e-05,
      "loss": 0.0014,
      "step": 67230
    },
    {
      "epoch": 20.746683122493057,
      "grad_norm": 0.754589855670929,
      "learning_rate": 2.9253316877506943e-05,
      "loss": 0.0053,
      "step": 67240
    },
    {
      "epoch": 20.749768589941375,
      "grad_norm": 0.02119658887386322,
      "learning_rate": 2.9250231410058626e-05,
      "loss": 0.0047,
      "step": 67250
    },
    {
      "epoch": 20.752854057389694,
      "grad_norm": 0.00011071561311837286,
      "learning_rate": 2.9247145942610305e-05,
      "loss": 0.0019,
      "step": 67260
    },
    {
      "epoch": 20.755939524838013,
      "grad_norm": 0.0024798663798719645,
      "learning_rate": 2.9244060475161987e-05,
      "loss": 0.0092,
      "step": 67270
    },
    {
      "epoch": 20.75902499228633,
      "grad_norm": 0.00011269946116954088,
      "learning_rate": 2.9240975007713673e-05,
      "loss": 0.0009,
      "step": 67280
    },
    {
      "epoch": 20.76211045973465,
      "grad_norm": 0.004809182602912188,
      "learning_rate": 2.9237889540265352e-05,
      "loss": 0.0019,
      "step": 67290
    },
    {
      "epoch": 20.76519592718297,
      "grad_norm": 0.0008641753229312599,
      "learning_rate": 2.9234804072817035e-05,
      "loss": 0.0025,
      "step": 67300
    },
    {
      "epoch": 20.768281394631288,
      "grad_norm": 0.0014561553252860904,
      "learning_rate": 2.9231718605368714e-05,
      "loss": 0.0045,
      "step": 67310
    },
    {
      "epoch": 20.771366862079606,
      "grad_norm": 0.007726550102233887,
      "learning_rate": 2.9228633137920396e-05,
      "loss": 0.0,
      "step": 67320
    },
    {
      "epoch": 20.774452329527925,
      "grad_norm": 0.0010232317727059126,
      "learning_rate": 2.9225547670472075e-05,
      "loss": 0.0002,
      "step": 67330
    },
    {
      "epoch": 20.77753779697624,
      "grad_norm": 0.0002774686727207154,
      "learning_rate": 2.9222462203023758e-05,
      "loss": 0.0001,
      "step": 67340
    },
    {
      "epoch": 20.78062326442456,
      "grad_norm": 0.26255929470062256,
      "learning_rate": 2.9219376735575444e-05,
      "loss": 0.0003,
      "step": 67350
    },
    {
      "epoch": 20.783708731872878,
      "grad_norm": 0.00011920564429601654,
      "learning_rate": 2.9216291268127123e-05,
      "loss": 0.0,
      "step": 67360
    },
    {
      "epoch": 20.786794199321196,
      "grad_norm": 0.0012511861277744174,
      "learning_rate": 2.9213205800678805e-05,
      "loss": 0.0001,
      "step": 67370
    },
    {
      "epoch": 20.789879666769515,
      "grad_norm": 0.0021257258486002684,
      "learning_rate": 2.9210120333230484e-05,
      "loss": 0.0001,
      "step": 67380
    },
    {
      "epoch": 20.792965134217834,
      "grad_norm": 0.00020864106772933155,
      "learning_rate": 2.9207034865782167e-05,
      "loss": 0.0004,
      "step": 67390
    },
    {
      "epoch": 20.796050601666153,
      "grad_norm": 0.00023855392646510154,
      "learning_rate": 2.9203949398333846e-05,
      "loss": 0.0001,
      "step": 67400
    },
    {
      "epoch": 20.79913606911447,
      "grad_norm": 0.0026706226635724306,
      "learning_rate": 2.9200863930885532e-05,
      "loss": 0.0002,
      "step": 67410
    },
    {
      "epoch": 20.80222153656279,
      "grad_norm": 0.6094943881034851,
      "learning_rate": 2.9197778463437214e-05,
      "loss": 0.0002,
      "step": 67420
    },
    {
      "epoch": 20.80530700401111,
      "grad_norm": 0.0016417084261775017,
      "learning_rate": 2.9194692995988893e-05,
      "loss": 0.0005,
      "step": 67430
    },
    {
      "epoch": 20.808392471459427,
      "grad_norm": 0.00021541437308769673,
      "learning_rate": 2.9191607528540576e-05,
      "loss": 0.0005,
      "step": 67440
    },
    {
      "epoch": 20.811477938907746,
      "grad_norm": 0.0026248288340866566,
      "learning_rate": 2.9188522061092255e-05,
      "loss": 0.0006,
      "step": 67450
    },
    {
      "epoch": 20.81456340635606,
      "grad_norm": 0.05465710163116455,
      "learning_rate": 2.9185436593643938e-05,
      "loss": 0.0015,
      "step": 67460
    },
    {
      "epoch": 20.81764887380438,
      "grad_norm": 0.0004311258380766958,
      "learning_rate": 2.9182351126195617e-05,
      "loss": 0.0004,
      "step": 67470
    },
    {
      "epoch": 20.8207343412527,
      "grad_norm": 0.3641529083251953,
      "learning_rate": 2.9179265658747302e-05,
      "loss": 0.0003,
      "step": 67480
    },
    {
      "epoch": 20.823819808701018,
      "grad_norm": 0.00016528939886484295,
      "learning_rate": 2.9176180191298985e-05,
      "loss": 0.0006,
      "step": 67490
    },
    {
      "epoch": 20.826905276149336,
      "grad_norm": 2.993000862261397e-06,
      "learning_rate": 2.9173094723850664e-05,
      "loss": 0.0,
      "step": 67500
    },
    {
      "epoch": 20.829990743597655,
      "grad_norm": 0.0009900068398565054,
      "learning_rate": 2.9170009256402347e-05,
      "loss": 0.0012,
      "step": 67510
    },
    {
      "epoch": 20.833076211045974,
      "grad_norm": 0.00025993125746026635,
      "learning_rate": 2.9166923788954026e-05,
      "loss": 0.0,
      "step": 67520
    },
    {
      "epoch": 20.836161678494292,
      "grad_norm": 0.33802756667137146,
      "learning_rate": 2.916383832150571e-05,
      "loss": 0.0001,
      "step": 67530
    },
    {
      "epoch": 20.83924714594261,
      "grad_norm": 0.00013476370077114552,
      "learning_rate": 2.9160752854057394e-05,
      "loss": 0.0013,
      "step": 67540
    },
    {
      "epoch": 20.84233261339093,
      "grad_norm": 0.00282629719004035,
      "learning_rate": 2.9157667386609073e-05,
      "loss": 0.0021,
      "step": 67550
    },
    {
      "epoch": 20.84541808083925,
      "grad_norm": 0.13193264603614807,
      "learning_rate": 2.9154581919160756e-05,
      "loss": 0.0002,
      "step": 67560
    },
    {
      "epoch": 20.848503548287567,
      "grad_norm": 0.00020382661023177207,
      "learning_rate": 2.9151496451712435e-05,
      "loss": 0.0086,
      "step": 67570
    },
    {
      "epoch": 20.851589015735883,
      "grad_norm": 0.0005354817258194089,
      "learning_rate": 2.9148410984264117e-05,
      "loss": 0.0027,
      "step": 67580
    },
    {
      "epoch": 20.8546744831842,
      "grad_norm": 0.0011229704832658172,
      "learning_rate": 2.9145325516815796e-05,
      "loss": 0.0001,
      "step": 67590
    },
    {
      "epoch": 20.85775995063252,
      "grad_norm": 3.418413325562142e-05,
      "learning_rate": 2.9142240049367482e-05,
      "loss": 0.0041,
      "step": 67600
    },
    {
      "epoch": 20.86084541808084,
      "grad_norm": 0.00712639931589365,
      "learning_rate": 2.9139154581919165e-05,
      "loss": 0.0004,
      "step": 67610
    },
    {
      "epoch": 20.863930885529157,
      "grad_norm": 0.07848178595304489,
      "learning_rate": 2.9136069114470844e-05,
      "loss": 0.0002,
      "step": 67620
    },
    {
      "epoch": 20.867016352977476,
      "grad_norm": 0.9199457168579102,
      "learning_rate": 2.9132983647022526e-05,
      "loss": 0.0003,
      "step": 67630
    },
    {
      "epoch": 20.870101820425795,
      "grad_norm": 1.5330449969042093e-05,
      "learning_rate": 2.9129898179574205e-05,
      "loss": 0.0004,
      "step": 67640
    },
    {
      "epoch": 20.873187287874114,
      "grad_norm": 1.2022545888612512e-05,
      "learning_rate": 2.912681271212589e-05,
      "loss": 0.0036,
      "step": 67650
    },
    {
      "epoch": 20.876272755322432,
      "grad_norm": 0.0002458065573591739,
      "learning_rate": 2.9123727244677567e-05,
      "loss": 0.0021,
      "step": 67660
    },
    {
      "epoch": 20.87935822277075,
      "grad_norm": 0.0011043065460398793,
      "learning_rate": 2.9120641777229253e-05,
      "loss": 0.0105,
      "step": 67670
    },
    {
      "epoch": 20.88244369021907,
      "grad_norm": 0.002272996585816145,
      "learning_rate": 2.9117556309780935e-05,
      "loss": 0.0005,
      "step": 67680
    },
    {
      "epoch": 20.885529157667385,
      "grad_norm": 0.0025612316094338894,
      "learning_rate": 2.9114470842332614e-05,
      "loss": 0.0001,
      "step": 67690
    },
    {
      "epoch": 20.888614625115704,
      "grad_norm": 0.00011934786016354337,
      "learning_rate": 2.9111385374884297e-05,
      "loss": 0.0001,
      "step": 67700
    },
    {
      "epoch": 20.891700092564022,
      "grad_norm": 0.0008468253654427826,
      "learning_rate": 2.9108299907435976e-05,
      "loss": 0.0004,
      "step": 67710
    },
    {
      "epoch": 20.89478556001234,
      "grad_norm": 0.00027745880652219057,
      "learning_rate": 2.910521443998766e-05,
      "loss": 0.0013,
      "step": 67720
    },
    {
      "epoch": 20.89787102746066,
      "grad_norm": 0.002403443679213524,
      "learning_rate": 2.9102128972539337e-05,
      "loss": 0.0,
      "step": 67730
    },
    {
      "epoch": 20.90095649490898,
      "grad_norm": 0.031419433653354645,
      "learning_rate": 2.9099043505091023e-05,
      "loss": 0.0,
      "step": 67740
    },
    {
      "epoch": 20.904041962357297,
      "grad_norm": 0.0006125004729256034,
      "learning_rate": 2.9095958037642706e-05,
      "loss": 0.0003,
      "step": 67750
    },
    {
      "epoch": 20.907127429805616,
      "grad_norm": 0.0001788440567906946,
      "learning_rate": 2.9092872570194385e-05,
      "loss": 0.0001,
      "step": 67760
    },
    {
      "epoch": 20.910212897253935,
      "grad_norm": 0.18136988580226898,
      "learning_rate": 2.9089787102746067e-05,
      "loss": 0.0003,
      "step": 67770
    },
    {
      "epoch": 20.913298364702253,
      "grad_norm": 0.0017232289537787437,
      "learning_rate": 2.9086701635297746e-05,
      "loss": 0.0001,
      "step": 67780
    },
    {
      "epoch": 20.916383832150572,
      "grad_norm": 1.020954550767783e-05,
      "learning_rate": 2.9083616167849432e-05,
      "loss": 0.0032,
      "step": 67790
    },
    {
      "epoch": 20.91946929959889,
      "grad_norm": 1.8596767404233105e-05,
      "learning_rate": 2.908053070040111e-05,
      "loss": 0.0001,
      "step": 67800
    },
    {
      "epoch": 20.922554767047206,
      "grad_norm": 0.04663670435547829,
      "learning_rate": 2.9077445232952794e-05,
      "loss": 0.0001,
      "step": 67810
    },
    {
      "epoch": 20.925640234495525,
      "grad_norm": 6.632834993069991e-05,
      "learning_rate": 2.9074359765504476e-05,
      "loss": 0.0,
      "step": 67820
    },
    {
      "epoch": 20.928725701943844,
      "grad_norm": 0.004422187805175781,
      "learning_rate": 2.9071274298056155e-05,
      "loss": 0.0014,
      "step": 67830
    },
    {
      "epoch": 20.931811169392162,
      "grad_norm": 0.04116674140095711,
      "learning_rate": 2.906818883060784e-05,
      "loss": 0.0001,
      "step": 67840
    },
    {
      "epoch": 20.93489663684048,
      "grad_norm": 3.70330548286438,
      "learning_rate": 2.9065103363159517e-05,
      "loss": 0.0104,
      "step": 67850
    },
    {
      "epoch": 20.9379821042888,
      "grad_norm": 0.0001653036888455972,
      "learning_rate": 2.9062017895711203e-05,
      "loss": 0.0006,
      "step": 67860
    },
    {
      "epoch": 20.94106757173712,
      "grad_norm": 0.0002454937784932554,
      "learning_rate": 2.9058932428262882e-05,
      "loss": 0.0004,
      "step": 67870
    },
    {
      "epoch": 20.944153039185437,
      "grad_norm": 0.008040916174650192,
      "learning_rate": 2.9055846960814564e-05,
      "loss": 0.0003,
      "step": 67880
    },
    {
      "epoch": 20.947238506633756,
      "grad_norm": 0.0037977988831698895,
      "learning_rate": 2.9052761493366247e-05,
      "loss": 0.0017,
      "step": 67890
    },
    {
      "epoch": 20.950323974082075,
      "grad_norm": 0.002222444163635373,
      "learning_rate": 2.9049676025917926e-05,
      "loss": 0.0004,
      "step": 67900
    },
    {
      "epoch": 20.953409441530393,
      "grad_norm": 0.02758534625172615,
      "learning_rate": 2.9046590558469612e-05,
      "loss": 0.0,
      "step": 67910
    },
    {
      "epoch": 20.956494908978712,
      "grad_norm": 4.231631464790553e-06,
      "learning_rate": 2.904350509102129e-05,
      "loss": 0.0041,
      "step": 67920
    },
    {
      "epoch": 20.959580376427027,
      "grad_norm": 0.00039582353201694787,
      "learning_rate": 2.9040419623572973e-05,
      "loss": 0.0013,
      "step": 67930
    },
    {
      "epoch": 20.962665843875346,
      "grad_norm": 4.13838388340082e-05,
      "learning_rate": 2.9037334156124656e-05,
      "loss": 0.0002,
      "step": 67940
    },
    {
      "epoch": 20.965751311323665,
      "grad_norm": 6.810771992604714e-06,
      "learning_rate": 2.9034248688676335e-05,
      "loss": 0.0002,
      "step": 67950
    },
    {
      "epoch": 20.968836778771983,
      "grad_norm": 0.006377244368195534,
      "learning_rate": 2.903116322122802e-05,
      "loss": 0.0014,
      "step": 67960
    },
    {
      "epoch": 20.971922246220302,
      "grad_norm": 0.0001227116590598598,
      "learning_rate": 2.9028077753779696e-05,
      "loss": 0.0,
      "step": 67970
    },
    {
      "epoch": 20.97500771366862,
      "grad_norm": 0.0003081766190007329,
      "learning_rate": 2.9024992286331382e-05,
      "loss": 0.0014,
      "step": 67980
    },
    {
      "epoch": 20.97809318111694,
      "grad_norm": 0.007160479668527842,
      "learning_rate": 2.902190681888306e-05,
      "loss": 0.0024,
      "step": 67990
    },
    {
      "epoch": 20.98117864856526,
      "grad_norm": 0.3356787860393524,
      "learning_rate": 2.9018821351434744e-05,
      "loss": 0.0009,
      "step": 68000
    },
    {
      "epoch": 20.984264116013577,
      "grad_norm": 0.0012534823035821319,
      "learning_rate": 2.9015735883986426e-05,
      "loss": 0.0005,
      "step": 68010
    },
    {
      "epoch": 20.987349583461896,
      "grad_norm": 0.0013974322937428951,
      "learning_rate": 2.9012650416538105e-05,
      "loss": 0.0001,
      "step": 68020
    },
    {
      "epoch": 20.990435050910214,
      "grad_norm": 0.000267893192358315,
      "learning_rate": 2.900956494908979e-05,
      "loss": 0.0002,
      "step": 68030
    },
    {
      "epoch": 20.99352051835853,
      "grad_norm": 0.001460478757508099,
      "learning_rate": 2.900647948164147e-05,
      "loss": 0.0064,
      "step": 68040
    },
    {
      "epoch": 20.99660598580685,
      "grad_norm": 0.0004704818711616099,
      "learning_rate": 2.9003394014193153e-05,
      "loss": 0.0004,
      "step": 68050
    },
    {
      "epoch": 20.999691453255167,
      "grad_norm": 0.0009166403324343264,
      "learning_rate": 2.9000308546744832e-05,
      "loss": 0.0001,
      "step": 68060
    },
    {
      "epoch": 21.0,
      "eval_accuracy_branch1": 0.9997588804336295,
      "eval_accuracy_branch2": 0.4283633768313031,
      "eval_f1_branch1": 0.9996974714173237,
      "eval_f1_branch2": 0.428241785983855,
      "eval_loss": 9.033968672156334e-05,
      "eval_precision_branch1": 0.9997156436788195,
      "eval_precision_branch2": 0.487082466053153,
      "eval_recall_branch1": 0.9996795053272393,
      "eval_recall_branch2": 0.48737739070050057,
      "eval_runtime": 313.2079,
      "eval_samples_per_second": 331.036,
      "eval_steps_per_second": 41.381,
      "step": 68061
    },
    {
      "epoch": 21.002776920703486,
      "grad_norm": 6.41147416899912e-05,
      "learning_rate": 2.8997223079296514e-05,
      "loss": 0.0,
      "step": 68070
    },
    {
      "epoch": 21.005862388151805,
      "grad_norm": 0.0016077521722763777,
      "learning_rate": 2.89941376118482e-05,
      "loss": 0.0001,
      "step": 68080
    },
    {
      "epoch": 21.008947855600123,
      "grad_norm": 5.907170361751923e-06,
      "learning_rate": 2.8991052144399876e-05,
      "loss": 0.0,
      "step": 68090
    },
    {
      "epoch": 21.012033323048442,
      "grad_norm": 0.0037764122243970633,
      "learning_rate": 2.8987966676951562e-05,
      "loss": 0.0003,
      "step": 68100
    },
    {
      "epoch": 21.01511879049676,
      "grad_norm": 2.2169686417328194e-05,
      "learning_rate": 2.898488120950324e-05,
      "loss": 0.0012,
      "step": 68110
    },
    {
      "epoch": 21.01820425794508,
      "grad_norm": 0.7735820412635803,
      "learning_rate": 2.8981795742054923e-05,
      "loss": 0.0004,
      "step": 68120
    },
    {
      "epoch": 21.021289725393398,
      "grad_norm": 0.03258472681045532,
      "learning_rate": 2.8978710274606602e-05,
      "loss": 0.0002,
      "step": 68130
    },
    {
      "epoch": 21.024375192841717,
      "grad_norm": 0.40293243527412415,
      "learning_rate": 2.8975624807158285e-05,
      "loss": 0.0002,
      "step": 68140
    },
    {
      "epoch": 21.027460660290036,
      "grad_norm": 0.15742671489715576,
      "learning_rate": 2.897253933970997e-05,
      "loss": 0.0002,
      "step": 68150
    },
    {
      "epoch": 21.03054612773835,
      "grad_norm": 0.005521134007722139,
      "learning_rate": 2.8969453872261647e-05,
      "loss": 0.0001,
      "step": 68160
    },
    {
      "epoch": 21.03363159518667,
      "grad_norm": 0.8178395628929138,
      "learning_rate": 2.8966368404813332e-05,
      "loss": 0.0003,
      "step": 68170
    },
    {
      "epoch": 21.036717062634988,
      "grad_norm": 0.0001519857905805111,
      "learning_rate": 2.896328293736501e-05,
      "loss": 0.0004,
      "step": 68180
    },
    {
      "epoch": 21.039802530083307,
      "grad_norm": 0.0020728190429508686,
      "learning_rate": 2.8960197469916694e-05,
      "loss": 0.0038,
      "step": 68190
    },
    {
      "epoch": 21.042887997531626,
      "grad_norm": 7.968171121319756e-05,
      "learning_rate": 2.8957112002468373e-05,
      "loss": 0.0001,
      "step": 68200
    },
    {
      "epoch": 21.045973464979944,
      "grad_norm": 0.0054190270602703094,
      "learning_rate": 2.8954026535020056e-05,
      "loss": 0.0016,
      "step": 68210
    },
    {
      "epoch": 21.049058932428263,
      "grad_norm": 5.689457339030923e-06,
      "learning_rate": 2.895094106757174e-05,
      "loss": 0.0,
      "step": 68220
    },
    {
      "epoch": 21.052144399876582,
      "grad_norm": 0.2420484721660614,
      "learning_rate": 2.894785560012342e-05,
      "loss": 0.0002,
      "step": 68230
    },
    {
      "epoch": 21.0552298673249,
      "grad_norm": 0.01564723439514637,
      "learning_rate": 2.8944770132675103e-05,
      "loss": 0.0004,
      "step": 68240
    },
    {
      "epoch": 21.05831533477322,
      "grad_norm": 0.01952332630753517,
      "learning_rate": 2.8941684665226782e-05,
      "loss": 0.0,
      "step": 68250
    },
    {
      "epoch": 21.061400802221538,
      "grad_norm": 0.0004587116127368063,
      "learning_rate": 2.8938599197778465e-05,
      "loss": 0.0,
      "step": 68260
    },
    {
      "epoch": 21.064486269669857,
      "grad_norm": 6.108467914600624e-06,
      "learning_rate": 2.8935513730330144e-05,
      "loss": 0.0068,
      "step": 68270
    },
    {
      "epoch": 21.067571737118172,
      "grad_norm": 3.5737142752623186e-05,
      "learning_rate": 2.8932428262881826e-05,
      "loss": 0.0018,
      "step": 68280
    },
    {
      "epoch": 21.07065720456649,
      "grad_norm": 7.4995482464146335e-06,
      "learning_rate": 2.8929342795433512e-05,
      "loss": 0.0018,
      "step": 68290
    },
    {
      "epoch": 21.07374267201481,
      "grad_norm": 0.00017647944332566112,
      "learning_rate": 2.892625732798519e-05,
      "loss": 0.0,
      "step": 68300
    },
    {
      "epoch": 21.076828139463128,
      "grad_norm": 0.007627138867974281,
      "learning_rate": 2.8923171860536874e-05,
      "loss": 0.0002,
      "step": 68310
    },
    {
      "epoch": 21.079913606911447,
      "grad_norm": 0.0008542024297639728,
      "learning_rate": 2.8920086393088553e-05,
      "loss": 0.0,
      "step": 68320
    },
    {
      "epoch": 21.082999074359766,
      "grad_norm": 0.00889111589640379,
      "learning_rate": 2.8917000925640235e-05,
      "loss": 0.0033,
      "step": 68330
    },
    {
      "epoch": 21.086084541808084,
      "grad_norm": 0.09468536823987961,
      "learning_rate": 2.8913915458191914e-05,
      "loss": 0.002,
      "step": 68340
    },
    {
      "epoch": 21.089170009256403,
      "grad_norm": 0.5819263458251953,
      "learning_rate": 2.89108299907436e-05,
      "loss": 0.0003,
      "step": 68350
    },
    {
      "epoch": 21.09225547670472,
      "grad_norm": 0.0003824697632808238,
      "learning_rate": 2.8907744523295283e-05,
      "loss": 0.0003,
      "step": 68360
    },
    {
      "epoch": 21.09534094415304,
      "grad_norm": 8.818774949759245e-05,
      "learning_rate": 2.890465905584696e-05,
      "loss": 0.0107,
      "step": 68370
    },
    {
      "epoch": 21.09842641160136,
      "grad_norm": 0.11973853409290314,
      "learning_rate": 2.8901573588398644e-05,
      "loss": 0.0006,
      "step": 68380
    },
    {
      "epoch": 21.101511879049674,
      "grad_norm": 0.00045503690489567816,
      "learning_rate": 2.8898488120950323e-05,
      "loss": 0.0,
      "step": 68390
    },
    {
      "epoch": 21.104597346497993,
      "grad_norm": 0.0006037481944076717,
      "learning_rate": 2.8895402653502006e-05,
      "loss": 0.0,
      "step": 68400
    },
    {
      "epoch": 21.10768281394631,
      "grad_norm": 0.023988807573914528,
      "learning_rate": 2.889231718605369e-05,
      "loss": 0.0,
      "step": 68410
    },
    {
      "epoch": 21.11076828139463,
      "grad_norm": 0.7146458029747009,
      "learning_rate": 2.888923171860537e-05,
      "loss": 0.0023,
      "step": 68420
    },
    {
      "epoch": 21.11385374884295,
      "grad_norm": 0.00010639960964908823,
      "learning_rate": 2.8886146251157053e-05,
      "loss": 0.0,
      "step": 68430
    },
    {
      "epoch": 21.116939216291268,
      "grad_norm": 1.752609372138977,
      "learning_rate": 2.8883060783708732e-05,
      "loss": 0.0018,
      "step": 68440
    },
    {
      "epoch": 21.120024683739587,
      "grad_norm": 0.00019935666932724416,
      "learning_rate": 2.8879975316260415e-05,
      "loss": 0.0004,
      "step": 68450
    },
    {
      "epoch": 21.123110151187905,
      "grad_norm": 2.1157700302865123e-07,
      "learning_rate": 2.8876889848812094e-05,
      "loss": 0.0003,
      "step": 68460
    },
    {
      "epoch": 21.126195618636224,
      "grad_norm": 0.0007436712039634585,
      "learning_rate": 2.887380438136378e-05,
      "loss": 0.0,
      "step": 68470
    },
    {
      "epoch": 21.129281086084543,
      "grad_norm": 0.36011186242103577,
      "learning_rate": 2.8870718913915462e-05,
      "loss": 0.0002,
      "step": 68480
    },
    {
      "epoch": 21.13236655353286,
      "grad_norm": 0.027962928637862206,
      "learning_rate": 2.886763344646714e-05,
      "loss": 0.0027,
      "step": 68490
    },
    {
      "epoch": 21.13545202098118,
      "grad_norm": 0.001980987610295415,
      "learning_rate": 2.8864547979018824e-05,
      "loss": 0.0009,
      "step": 68500
    },
    {
      "epoch": 21.138537488429495,
      "grad_norm": 0.0001828028034651652,
      "learning_rate": 2.8861462511570503e-05,
      "loss": 0.0001,
      "step": 68510
    },
    {
      "epoch": 21.141622955877814,
      "grad_norm": 0.04400249570608139,
      "learning_rate": 2.8858377044122185e-05,
      "loss": 0.0001,
      "step": 68520
    },
    {
      "epoch": 21.144708423326133,
      "grad_norm": 0.001120797940529883,
      "learning_rate": 2.8855291576673864e-05,
      "loss": 0.0001,
      "step": 68530
    },
    {
      "epoch": 21.14779389077445,
      "grad_norm": 7.3539467848604545e-06,
      "learning_rate": 2.885220610922555e-05,
      "loss": 0.0018,
      "step": 68540
    },
    {
      "epoch": 21.15087935822277,
      "grad_norm": 5.997813059366308e-05,
      "learning_rate": 2.8849120641777233e-05,
      "loss": 0.0014,
      "step": 68550
    },
    {
      "epoch": 21.15396482567109,
      "grad_norm": 0.0016381252789869905,
      "learning_rate": 2.8846035174328912e-05,
      "loss": 0.0001,
      "step": 68560
    },
    {
      "epoch": 21.157050293119408,
      "grad_norm": 0.00010057630424853414,
      "learning_rate": 2.8842949706880594e-05,
      "loss": 0.0001,
      "step": 68570
    },
    {
      "epoch": 21.160135760567726,
      "grad_norm": 0.03981342539191246,
      "learning_rate": 2.8839864239432273e-05,
      "loss": 0.0001,
      "step": 68580
    },
    {
      "epoch": 21.163221228016045,
      "grad_norm": 0.0022932393476366997,
      "learning_rate": 2.883677877198396e-05,
      "loss": 0.0008,
      "step": 68590
    },
    {
      "epoch": 21.166306695464364,
      "grad_norm": 0.00010690512863220647,
      "learning_rate": 2.8833693304535635e-05,
      "loss": 0.0018,
      "step": 68600
    },
    {
      "epoch": 21.169392162912683,
      "grad_norm": 0.00046929088421165943,
      "learning_rate": 2.883060783708732e-05,
      "loss": 0.0001,
      "step": 68610
    },
    {
      "epoch": 21.172477630361,
      "grad_norm": 0.00131893006619066,
      "learning_rate": 2.8827522369639003e-05,
      "loss": 0.0006,
      "step": 68620
    },
    {
      "epoch": 21.175563097809317,
      "grad_norm": 3.9678758184891194e-05,
      "learning_rate": 2.8824436902190682e-05,
      "loss": 0.0001,
      "step": 68630
    },
    {
      "epoch": 21.178648565257635,
      "grad_norm": 0.00018271137378178537,
      "learning_rate": 2.8821351434742365e-05,
      "loss": 0.0,
      "step": 68640
    },
    {
      "epoch": 21.181734032705954,
      "grad_norm": 8.828529098536819e-05,
      "learning_rate": 2.8818265967294044e-05,
      "loss": 0.0021,
      "step": 68650
    },
    {
      "epoch": 21.184819500154273,
      "grad_norm": 5.646469799103215e-05,
      "learning_rate": 2.881518049984573e-05,
      "loss": 0.0,
      "step": 68660
    },
    {
      "epoch": 21.18790496760259,
      "grad_norm": 0.1541440337896347,
      "learning_rate": 2.8812095032397405e-05,
      "loss": 0.0001,
      "step": 68670
    },
    {
      "epoch": 21.19099043505091,
      "grad_norm": 0.00010761988960439339,
      "learning_rate": 2.880900956494909e-05,
      "loss": 0.0,
      "step": 68680
    },
    {
      "epoch": 21.19407590249923,
      "grad_norm": 1.100836288969731e-05,
      "learning_rate": 2.8805924097500774e-05,
      "loss": 0.0,
      "step": 68690
    },
    {
      "epoch": 21.197161369947548,
      "grad_norm": 0.041750334203243256,
      "learning_rate": 2.8802838630052453e-05,
      "loss": 0.0001,
      "step": 68700
    },
    {
      "epoch": 21.200246837395866,
      "grad_norm": 0.00800569448620081,
      "learning_rate": 2.879975316260414e-05,
      "loss": 0.0002,
      "step": 68710
    },
    {
      "epoch": 21.203332304844185,
      "grad_norm": 0.02505197376012802,
      "learning_rate": 2.8796667695155814e-05,
      "loss": 0.001,
      "step": 68720
    },
    {
      "epoch": 21.206417772292504,
      "grad_norm": 0.014514927752315998,
      "learning_rate": 2.87935822277075e-05,
      "loss": 0.0006,
      "step": 68730
    },
    {
      "epoch": 21.20950323974082,
      "grad_norm": 0.04208766296505928,
      "learning_rate": 2.879049676025918e-05,
      "loss": 0.0008,
      "step": 68740
    },
    {
      "epoch": 21.212588707189138,
      "grad_norm": 0.0037831980735063553,
      "learning_rate": 2.8787411292810862e-05,
      "loss": 0.0001,
      "step": 68750
    },
    {
      "epoch": 21.215674174637456,
      "grad_norm": 0.0019364617764949799,
      "learning_rate": 2.8784325825362544e-05,
      "loss": 0.0,
      "step": 68760
    },
    {
      "epoch": 21.218759642085775,
      "grad_norm": 0.01039337832480669,
      "learning_rate": 2.8781240357914223e-05,
      "loss": 0.0004,
      "step": 68770
    },
    {
      "epoch": 21.221845109534094,
      "grad_norm": 0.02924913540482521,
      "learning_rate": 2.877815489046591e-05,
      "loss": 0.0001,
      "step": 68780
    },
    {
      "epoch": 21.224930576982413,
      "grad_norm": 0.0016732587246224284,
      "learning_rate": 2.8775069423017585e-05,
      "loss": 0.0024,
      "step": 68790
    },
    {
      "epoch": 21.22801604443073,
      "grad_norm": 7.094311149558052e-05,
      "learning_rate": 2.877198395556927e-05,
      "loss": 0.005,
      "step": 68800
    },
    {
      "epoch": 21.23110151187905,
      "grad_norm": 3.238263161620125e-05,
      "learning_rate": 2.8768898488120953e-05,
      "loss": 0.0026,
      "step": 68810
    },
    {
      "epoch": 21.23418697932737,
      "grad_norm": 2.571924233052414e-05,
      "learning_rate": 2.8765813020672632e-05,
      "loss": 0.0004,
      "step": 68820
    },
    {
      "epoch": 21.237272446775687,
      "grad_norm": 8.428970613749698e-05,
      "learning_rate": 2.8762727553224318e-05,
      "loss": 0.0,
      "step": 68830
    },
    {
      "epoch": 21.240357914224006,
      "grad_norm": 0.007553335279226303,
      "learning_rate": 2.8759642085775994e-05,
      "loss": 0.0,
      "step": 68840
    },
    {
      "epoch": 21.243443381672325,
      "grad_norm": 0.0017933679046109319,
      "learning_rate": 2.875655661832768e-05,
      "loss": 0.0009,
      "step": 68850
    },
    {
      "epoch": 21.24652884912064,
      "grad_norm": 0.00030143841286189854,
      "learning_rate": 2.875347115087936e-05,
      "loss": 0.0005,
      "step": 68860
    },
    {
      "epoch": 21.24961431656896,
      "grad_norm": 0.0007101336377672851,
      "learning_rate": 2.875038568343104e-05,
      "loss": 0.0,
      "step": 68870
    },
    {
      "epoch": 21.252699784017278,
      "grad_norm": 0.01179331075400114,
      "learning_rate": 2.8747300215982724e-05,
      "loss": 0.0001,
      "step": 68880
    },
    {
      "epoch": 21.255785251465596,
      "grad_norm": 2.8143282179371454e-05,
      "learning_rate": 2.8744214748534403e-05,
      "loss": 0.0029,
      "step": 68890
    },
    {
      "epoch": 21.258870718913915,
      "grad_norm": 0.007816367782652378,
      "learning_rate": 2.874112928108609e-05,
      "loss": 0.0028,
      "step": 68900
    },
    {
      "epoch": 21.261956186362234,
      "grad_norm": 0.017711877822875977,
      "learning_rate": 2.8738043813637765e-05,
      "loss": 0.0078,
      "step": 68910
    },
    {
      "epoch": 21.265041653810552,
      "grad_norm": 0.001238968106918037,
      "learning_rate": 2.873495834618945e-05,
      "loss": 0.0001,
      "step": 68920
    },
    {
      "epoch": 21.26812712125887,
      "grad_norm": 1.1231124517507851e-05,
      "learning_rate": 2.873187287874113e-05,
      "loss": 0.0,
      "step": 68930
    },
    {
      "epoch": 21.27121258870719,
      "grad_norm": 1.0182985067367554,
      "learning_rate": 2.8728787411292812e-05,
      "loss": 0.0007,
      "step": 68940
    },
    {
      "epoch": 21.27429805615551,
      "grad_norm": 0.07006444036960602,
      "learning_rate": 2.8725701943844498e-05,
      "loss": 0.0009,
      "step": 68950
    },
    {
      "epoch": 21.277383523603827,
      "grad_norm": 0.004195734858512878,
      "learning_rate": 2.8722616476396174e-05,
      "loss": 0.0004,
      "step": 68960
    },
    {
      "epoch": 21.280468991052146,
      "grad_norm": 0.0006662519299425185,
      "learning_rate": 2.871953100894786e-05,
      "loss": 0.0015,
      "step": 68970
    },
    {
      "epoch": 21.28355445850046,
      "grad_norm": 0.03630375489592552,
      "learning_rate": 2.871644554149954e-05,
      "loss": 0.0001,
      "step": 68980
    },
    {
      "epoch": 21.28663992594878,
      "grad_norm": 0.02224484644830227,
      "learning_rate": 2.871336007405122e-05,
      "loss": 0.0008,
      "step": 68990
    },
    {
      "epoch": 21.2897253933971,
      "grad_norm": 0.010363244451582432,
      "learning_rate": 2.87102746066029e-05,
      "loss": 0.0,
      "step": 69000
    },
    {
      "epoch": 21.292810860845417,
      "grad_norm": 0.03383089601993561,
      "learning_rate": 2.8707189139154583e-05,
      "loss": 0.0011,
      "step": 69010
    },
    {
      "epoch": 21.295896328293736,
      "grad_norm": 0.0015348802553489804,
      "learning_rate": 2.870410367170627e-05,
      "loss": 0.0042,
      "step": 69020
    },
    {
      "epoch": 21.298981795742055,
      "grad_norm": 0.42452722787857056,
      "learning_rate": 2.8701018204257944e-05,
      "loss": 0.001,
      "step": 69030
    },
    {
      "epoch": 21.302067263190374,
      "grad_norm": 0.00033484946470707655,
      "learning_rate": 2.869793273680963e-05,
      "loss": 0.0,
      "step": 69040
    },
    {
      "epoch": 21.305152730638692,
      "grad_norm": 0.0028706674929708242,
      "learning_rate": 2.869484726936131e-05,
      "loss": 0.0001,
      "step": 69050
    },
    {
      "epoch": 21.30823819808701,
      "grad_norm": 0.0002240631147287786,
      "learning_rate": 2.869176180191299e-05,
      "loss": 0.0001,
      "step": 69060
    },
    {
      "epoch": 21.31132366553533,
      "grad_norm": 8.140443969750777e-05,
      "learning_rate": 2.868867633446467e-05,
      "loss": 0.0002,
      "step": 69070
    },
    {
      "epoch": 21.31440913298365,
      "grad_norm": 1.366091692034388e-05,
      "learning_rate": 2.8685590867016353e-05,
      "loss": 0.0004,
      "step": 69080
    },
    {
      "epoch": 21.317494600431964,
      "grad_norm": 0.0003309015301056206,
      "learning_rate": 2.868250539956804e-05,
      "loss": 0.0,
      "step": 69090
    },
    {
      "epoch": 21.320580067880282,
      "grad_norm": 0.0026645055040717125,
      "learning_rate": 2.8679419932119718e-05,
      "loss": 0.0012,
      "step": 69100
    },
    {
      "epoch": 21.3236655353286,
      "grad_norm": 8.438228542217985e-05,
      "learning_rate": 2.86763344646714e-05,
      "loss": 0.0058,
      "step": 69110
    },
    {
      "epoch": 21.32675100277692,
      "grad_norm": 1.869054904091172e-05,
      "learning_rate": 2.867324899722308e-05,
      "loss": 0.0035,
      "step": 69120
    },
    {
      "epoch": 21.32983647022524,
      "grad_norm": 0.25228050351142883,
      "learning_rate": 2.8670163529774762e-05,
      "loss": 0.0066,
      "step": 69130
    },
    {
      "epoch": 21.332921937673557,
      "grad_norm": 3.588029358070344e-05,
      "learning_rate": 2.866707806232644e-05,
      "loss": 0.0034,
      "step": 69140
    },
    {
      "epoch": 21.336007405121876,
      "grad_norm": 0.02030128240585327,
      "learning_rate": 2.8663992594878124e-05,
      "loss": 0.0061,
      "step": 69150
    },
    {
      "epoch": 21.339092872570195,
      "grad_norm": 6.913467950653285e-05,
      "learning_rate": 2.866090712742981e-05,
      "loss": 0.0,
      "step": 69160
    },
    {
      "epoch": 21.342178340018513,
      "grad_norm": 0.0016031517880037427,
      "learning_rate": 2.865782165998149e-05,
      "loss": 0.004,
      "step": 69170
    },
    {
      "epoch": 21.345263807466832,
      "grad_norm": 2.5427205562591553,
      "learning_rate": 2.865473619253317e-05,
      "loss": 0.0017,
      "step": 69180
    },
    {
      "epoch": 21.34834927491515,
      "grad_norm": 0.0026954447384923697,
      "learning_rate": 2.865165072508485e-05,
      "loss": 0.0005,
      "step": 69190
    },
    {
      "epoch": 21.35143474236347,
      "grad_norm": 0.07000727206468582,
      "learning_rate": 2.8648565257636533e-05,
      "loss": 0.0001,
      "step": 69200
    },
    {
      "epoch": 21.354520209811785,
      "grad_norm": 0.20601728558540344,
      "learning_rate": 2.8645479790188212e-05,
      "loss": 0.0001,
      "step": 69210
    },
    {
      "epoch": 21.357605677260104,
      "grad_norm": 0.001562795601785183,
      "learning_rate": 2.8642394322739898e-05,
      "loss": 0.003,
      "step": 69220
    },
    {
      "epoch": 21.360691144708422,
      "grad_norm": 0.00011686123616527766,
      "learning_rate": 2.863930885529158e-05,
      "loss": 0.0002,
      "step": 69230
    },
    {
      "epoch": 21.36377661215674,
      "grad_norm": 1.688283919065725e-05,
      "learning_rate": 2.863622338784326e-05,
      "loss": 0.0018,
      "step": 69240
    },
    {
      "epoch": 21.36686207960506,
      "grad_norm": 0.00028594667674042284,
      "learning_rate": 2.863313792039494e-05,
      "loss": 0.0015,
      "step": 69250
    },
    {
      "epoch": 21.36994754705338,
      "grad_norm": 0.005597813054919243,
      "learning_rate": 2.863005245294662e-05,
      "loss": 0.0004,
      "step": 69260
    },
    {
      "epoch": 21.373033014501697,
      "grad_norm": 0.00011012064351234585,
      "learning_rate": 2.8626966985498303e-05,
      "loss": 0.0006,
      "step": 69270
    },
    {
      "epoch": 21.376118481950016,
      "grad_norm": 0.00034256375511176884,
      "learning_rate": 2.862388151804999e-05,
      "loss": 0.0008,
      "step": 69280
    },
    {
      "epoch": 21.379203949398335,
      "grad_norm": 0.00028305273735895753,
      "learning_rate": 2.8620796050601668e-05,
      "loss": 0.0,
      "step": 69290
    },
    {
      "epoch": 21.382289416846653,
      "grad_norm": 3.9141268644016236e-05,
      "learning_rate": 2.861771058315335e-05,
      "loss": 0.0013,
      "step": 69300
    },
    {
      "epoch": 21.385374884294972,
      "grad_norm": 0.00010869738616747782,
      "learning_rate": 2.861462511570503e-05,
      "loss": 0.001,
      "step": 69310
    },
    {
      "epoch": 21.38846035174329,
      "grad_norm": 0.07342740893363953,
      "learning_rate": 2.8611539648256712e-05,
      "loss": 0.0013,
      "step": 69320
    },
    {
      "epoch": 21.391545819191606,
      "grad_norm": 7.114203413038922e-07,
      "learning_rate": 2.860845418080839e-05,
      "loss": 0.0004,
      "step": 69330
    },
    {
      "epoch": 21.394631286639925,
      "grad_norm": 1.5527938604354858,
      "learning_rate": 2.8605368713360077e-05,
      "loss": 0.0031,
      "step": 69340
    },
    {
      "epoch": 21.397716754088243,
      "grad_norm": 0.00027221321943216026,
      "learning_rate": 2.860228324591176e-05,
      "loss": 0.0,
      "step": 69350
    },
    {
      "epoch": 21.400802221536562,
      "grad_norm": 0.0131734199821949,
      "learning_rate": 2.859919777846344e-05,
      "loss": 0.0047,
      "step": 69360
    },
    {
      "epoch": 21.40388768898488,
      "grad_norm": 2.186602978326846e-05,
      "learning_rate": 2.859611231101512e-05,
      "loss": 0.0006,
      "step": 69370
    },
    {
      "epoch": 21.4069731564332,
      "grad_norm": 0.025039274245500565,
      "learning_rate": 2.85930268435668e-05,
      "loss": 0.0002,
      "step": 69380
    },
    {
      "epoch": 21.41005862388152,
      "grad_norm": 2.12662672996521,
      "learning_rate": 2.8589941376118483e-05,
      "loss": 0.0038,
      "step": 69390
    },
    {
      "epoch": 21.413144091329837,
      "grad_norm": 2.143898854001236e-07,
      "learning_rate": 2.8586855908670162e-05,
      "loss": 0.0009,
      "step": 69400
    },
    {
      "epoch": 21.416229558778156,
      "grad_norm": 0.00010501509677851573,
      "learning_rate": 2.8583770441221848e-05,
      "loss": 0.0047,
      "step": 69410
    },
    {
      "epoch": 21.419315026226474,
      "grad_norm": 9.542326552036684e-06,
      "learning_rate": 2.858068497377353e-05,
      "loss": 0.0002,
      "step": 69420
    },
    {
      "epoch": 21.422400493674793,
      "grad_norm": 3.0010058253537863e-05,
      "learning_rate": 2.857759950632521e-05,
      "loss": 0.0,
      "step": 69430
    },
    {
      "epoch": 21.425485961123112,
      "grad_norm": 0.000538871216122061,
      "learning_rate": 2.8574514038876892e-05,
      "loss": 0.003,
      "step": 69440
    },
    {
      "epoch": 21.428571428571427,
      "grad_norm": 0.0001409148535458371,
      "learning_rate": 2.857142857142857e-05,
      "loss": 0.0,
      "step": 69450
    },
    {
      "epoch": 21.431656896019746,
      "grad_norm": 0.00021463505981955677,
      "learning_rate": 2.8568343103980257e-05,
      "loss": 0.0,
      "step": 69460
    },
    {
      "epoch": 21.434742363468064,
      "grad_norm": 0.0025071159470826387,
      "learning_rate": 2.8565257636531932e-05,
      "loss": 0.0001,
      "step": 69470
    },
    {
      "epoch": 21.437827830916383,
      "grad_norm": 0.00026011685258708894,
      "learning_rate": 2.8562172169083618e-05,
      "loss": 0.0,
      "step": 69480
    },
    {
      "epoch": 21.440913298364702,
      "grad_norm": 0.004113341681659222,
      "learning_rate": 2.85590867016353e-05,
      "loss": 0.0083,
      "step": 69490
    },
    {
      "epoch": 21.44399876581302,
      "grad_norm": 9.102872718358412e-05,
      "learning_rate": 2.855600123418698e-05,
      "loss": 0.0026,
      "step": 69500
    },
    {
      "epoch": 21.44708423326134,
      "grad_norm": 0.0034381337463855743,
      "learning_rate": 2.8552915766738662e-05,
      "loss": 0.0002,
      "step": 69510
    },
    {
      "epoch": 21.450169700709658,
      "grad_norm": 0.024813076481223106,
      "learning_rate": 2.854983029929034e-05,
      "loss": 0.0004,
      "step": 69520
    },
    {
      "epoch": 21.453255168157977,
      "grad_norm": 0.00022631025058217347,
      "learning_rate": 2.8546744831842027e-05,
      "loss": 0.0026,
      "step": 69530
    },
    {
      "epoch": 21.456340635606296,
      "grad_norm": 0.00030373811023309827,
      "learning_rate": 2.8543659364393703e-05,
      "loss": 0.0023,
      "step": 69540
    },
    {
      "epoch": 21.459426103054614,
      "grad_norm": 0.000517423206474632,
      "learning_rate": 2.854057389694539e-05,
      "loss": 0.0002,
      "step": 69550
    },
    {
      "epoch": 21.46251157050293,
      "grad_norm": 0.0016030559781938791,
      "learning_rate": 2.853748842949707e-05,
      "loss": 0.0038,
      "step": 69560
    },
    {
      "epoch": 21.465597037951248,
      "grad_norm": 0.03366091102361679,
      "learning_rate": 2.853440296204875e-05,
      "loss": 0.0046,
      "step": 69570
    },
    {
      "epoch": 21.468682505399567,
      "grad_norm": 0.001994099235162139,
      "learning_rate": 2.8531317494600436e-05,
      "loss": 0.0005,
      "step": 69580
    },
    {
      "epoch": 21.471767972847886,
      "grad_norm": 4.499790884437971e-05,
      "learning_rate": 2.8528232027152112e-05,
      "loss": 0.0002,
      "step": 69590
    },
    {
      "epoch": 21.474853440296204,
      "grad_norm": 5.157768555363873e-06,
      "learning_rate": 2.8525146559703798e-05,
      "loss": 0.0031,
      "step": 69600
    },
    {
      "epoch": 21.477938907744523,
      "grad_norm": 2.0016422271728516,
      "learning_rate": 2.8522061092255477e-05,
      "loss": 0.0009,
      "step": 69610
    },
    {
      "epoch": 21.481024375192842,
      "grad_norm": 0.19019575417041779,
      "learning_rate": 2.851897562480716e-05,
      "loss": 0.0003,
      "step": 69620
    },
    {
      "epoch": 21.48410984264116,
      "grad_norm": 2.576112365204608e-06,
      "learning_rate": 2.8515890157358842e-05,
      "loss": 0.0057,
      "step": 69630
    },
    {
      "epoch": 21.48719531008948,
      "grad_norm": 0.03926028683781624,
      "learning_rate": 2.851280468991052e-05,
      "loss": 0.0014,
      "step": 69640
    },
    {
      "epoch": 21.490280777537798,
      "grad_norm": 0.004568546544760466,
      "learning_rate": 2.8509719222462207e-05,
      "loss": 0.0001,
      "step": 69650
    },
    {
      "epoch": 21.493366244986117,
      "grad_norm": 3.314339483040385e-05,
      "learning_rate": 2.8506633755013883e-05,
      "loss": 0.0022,
      "step": 69660
    },
    {
      "epoch": 21.496451712434435,
      "grad_norm": 0.14940603077411652,
      "learning_rate": 2.850354828756557e-05,
      "loss": 0.0001,
      "step": 69670
    },
    {
      "epoch": 21.49953717988275,
      "grad_norm": 0.003172095865011215,
      "learning_rate": 2.850046282011725e-05,
      "loss": 0.0001,
      "step": 69680
    },
    {
      "epoch": 21.50262264733107,
      "grad_norm": 1.5185975826170761e-05,
      "learning_rate": 2.849737735266893e-05,
      "loss": 0.0026,
      "step": 69690
    },
    {
      "epoch": 21.505708114779388,
      "grad_norm": 0.0008001565583981574,
      "learning_rate": 2.8494291885220616e-05,
      "loss": 0.0012,
      "step": 69700
    },
    {
      "epoch": 21.508793582227707,
      "grad_norm": 0.002867328003048897,
      "learning_rate": 2.849120641777229e-05,
      "loss": 0.0045,
      "step": 69710
    },
    {
      "epoch": 21.511879049676025,
      "grad_norm": 0.0017833828460425138,
      "learning_rate": 2.8488120950323977e-05,
      "loss": 0.0001,
      "step": 69720
    },
    {
      "epoch": 21.514964517124344,
      "grad_norm": 0.00024264745297841728,
      "learning_rate": 2.8485035482875657e-05,
      "loss": 0.0025,
      "step": 69730
    },
    {
      "epoch": 21.518049984572663,
      "grad_norm": 0.006926186382770538,
      "learning_rate": 2.848195001542734e-05,
      "loss": 0.0002,
      "step": 69740
    },
    {
      "epoch": 21.52113545202098,
      "grad_norm": 0.0002574410755187273,
      "learning_rate": 2.847886454797902e-05,
      "loss": 0.001,
      "step": 69750
    },
    {
      "epoch": 21.5242209194693,
      "grad_norm": 1.8877486581914127e-05,
      "learning_rate": 2.84757790805307e-05,
      "loss": 0.0,
      "step": 69760
    },
    {
      "epoch": 21.52730638691762,
      "grad_norm": 7.729777280474082e-05,
      "learning_rate": 2.8472693613082386e-05,
      "loss": 0.0002,
      "step": 69770
    },
    {
      "epoch": 21.530391854365938,
      "grad_norm": 1.2979636192321777,
      "learning_rate": 2.8469608145634062e-05,
      "loss": 0.0009,
      "step": 69780
    },
    {
      "epoch": 21.533477321814257,
      "grad_norm": 6.095929165894631e-06,
      "learning_rate": 2.8466522678185748e-05,
      "loss": 0.0003,
      "step": 69790
    },
    {
      "epoch": 21.53656278926257,
      "grad_norm": 0.15878215432167053,
      "learning_rate": 2.8463437210737427e-05,
      "loss": 0.0002,
      "step": 69800
    },
    {
      "epoch": 21.53964825671089,
      "grad_norm": 0.0024497434496879578,
      "learning_rate": 2.846035174328911e-05,
      "loss": 0.0001,
      "step": 69810
    },
    {
      "epoch": 21.54273372415921,
      "grad_norm": 0.00037102794158272445,
      "learning_rate": 2.8457266275840795e-05,
      "loss": 0.0001,
      "step": 69820
    },
    {
      "epoch": 21.545819191607528,
      "grad_norm": 0.019131792709231377,
      "learning_rate": 2.845418080839247e-05,
      "loss": 0.0032,
      "step": 69830
    },
    {
      "epoch": 21.548904659055847,
      "grad_norm": 0.0018606515368446708,
      "learning_rate": 2.8451095340944157e-05,
      "loss": 0.0006,
      "step": 69840
    },
    {
      "epoch": 21.551990126504165,
      "grad_norm": 0.0002451647014822811,
      "learning_rate": 2.8448009873495836e-05,
      "loss": 0.0003,
      "step": 69850
    },
    {
      "epoch": 21.555075593952484,
      "grad_norm": 0.002919405000284314,
      "learning_rate": 2.844492440604752e-05,
      "loss": 0.0004,
      "step": 69860
    },
    {
      "epoch": 21.558161061400803,
      "grad_norm": 0.004568330477923155,
      "learning_rate": 2.8441838938599198e-05,
      "loss": 0.001,
      "step": 69870
    },
    {
      "epoch": 21.56124652884912,
      "grad_norm": 8.590811194153503e-05,
      "learning_rate": 2.843875347115088e-05,
      "loss": 0.0008,
      "step": 69880
    },
    {
      "epoch": 21.56433199629744,
      "grad_norm": 0.0006487456266768277,
      "learning_rate": 2.8435668003702566e-05,
      "loss": 0.0001,
      "step": 69890
    },
    {
      "epoch": 21.56741746374576,
      "grad_norm": 0.003423805348575115,
      "learning_rate": 2.843258253625424e-05,
      "loss": 0.0,
      "step": 69900
    },
    {
      "epoch": 21.570502931194078,
      "grad_norm": 0.0014334343140944839,
      "learning_rate": 2.8429497068805928e-05,
      "loss": 0.0024,
      "step": 69910
    },
    {
      "epoch": 21.573588398642393,
      "grad_norm": 0.000621016719378531,
      "learning_rate": 2.8426411601357607e-05,
      "loss": 0.0001,
      "step": 69920
    },
    {
      "epoch": 21.57667386609071,
      "grad_norm": 0.3122577369213104,
      "learning_rate": 2.842332613390929e-05,
      "loss": 0.0003,
      "step": 69930
    },
    {
      "epoch": 21.57975933353903,
      "grad_norm": 7.665956218261272e-06,
      "learning_rate": 2.8420240666460968e-05,
      "loss": 0.0001,
      "step": 69940
    },
    {
      "epoch": 21.58284480098735,
      "grad_norm": 0.7085664868354797,
      "learning_rate": 2.841715519901265e-05,
      "loss": 0.0016,
      "step": 69950
    },
    {
      "epoch": 21.585930268435668,
      "grad_norm": 0.0008673504926264286,
      "learning_rate": 2.8414069731564337e-05,
      "loss": 0.0014,
      "step": 69960
    },
    {
      "epoch": 21.589015735883986,
      "grad_norm": 1.8747876993074897e-06,
      "learning_rate": 2.8410984264116016e-05,
      "loss": 0.0001,
      "step": 69970
    },
    {
      "epoch": 21.592101203332305,
      "grad_norm": 7.584935519844294e-05,
      "learning_rate": 2.8407898796667698e-05,
      "loss": 0.0036,
      "step": 69980
    },
    {
      "epoch": 21.595186670780624,
      "grad_norm": 0.0031510177068412304,
      "learning_rate": 2.8404813329219377e-05,
      "loss": 0.0,
      "step": 69990
    },
    {
      "epoch": 21.598272138228943,
      "grad_norm": 0.00024286670668516308,
      "learning_rate": 2.840172786177106e-05,
      "loss": 0.0015,
      "step": 70000
    },
    {
      "epoch": 21.60135760567726,
      "grad_norm": 0.0012335173087194562,
      "learning_rate": 2.839864239432274e-05,
      "loss": 0.0035,
      "step": 70010
    },
    {
      "epoch": 21.60444307312558,
      "grad_norm": 0.003101661102846265,
      "learning_rate": 2.839555692687442e-05,
      "loss": 0.0001,
      "step": 70020
    },
    {
      "epoch": 21.607528540573895,
      "grad_norm": 3.0444874937529676e-05,
      "learning_rate": 2.8392471459426107e-05,
      "loss": 0.0022,
      "step": 70030
    },
    {
      "epoch": 21.610614008022214,
      "grad_norm": 0.31652435660362244,
      "learning_rate": 2.8389385991977786e-05,
      "loss": 0.0003,
      "step": 70040
    },
    {
      "epoch": 21.613699475470533,
      "grad_norm": 2.120880344591569e-05,
      "learning_rate": 2.838630052452947e-05,
      "loss": 0.0001,
      "step": 70050
    },
    {
      "epoch": 21.61678494291885,
      "grad_norm": 0.0013786006020382047,
      "learning_rate": 2.8383215057081148e-05,
      "loss": 0.0,
      "step": 70060
    },
    {
      "epoch": 21.61987041036717,
      "grad_norm": 2.421595127088949e-05,
      "learning_rate": 2.838012958963283e-05,
      "loss": 0.001,
      "step": 70070
    },
    {
      "epoch": 21.62295587781549,
      "grad_norm": 3.0389662697416497e-06,
      "learning_rate": 2.837704412218451e-05,
      "loss": 0.0001,
      "step": 70080
    },
    {
      "epoch": 21.626041345263808,
      "grad_norm": 0.00014789140550419688,
      "learning_rate": 2.8373958654736195e-05,
      "loss": 0.0,
      "step": 70090
    },
    {
      "epoch": 21.629126812712126,
      "grad_norm": 0.0001325515186181292,
      "learning_rate": 2.8370873187287878e-05,
      "loss": 0.0,
      "step": 70100
    },
    {
      "epoch": 21.632212280160445,
      "grad_norm": 0.0007275678217411041,
      "learning_rate": 2.8367787719839557e-05,
      "loss": 0.0008,
      "step": 70110
    },
    {
      "epoch": 21.635297747608764,
      "grad_norm": 0.00015597164747305214,
      "learning_rate": 2.836470225239124e-05,
      "loss": 0.0001,
      "step": 70120
    },
    {
      "epoch": 21.638383215057083,
      "grad_norm": 3.000031392730307e-05,
      "learning_rate": 2.836161678494292e-05,
      "loss": 0.0001,
      "step": 70130
    },
    {
      "epoch": 21.6414686825054,
      "grad_norm": 0.0018177652964368463,
      "learning_rate": 2.83585313174946e-05,
      "loss": 0.0006,
      "step": 70140
    },
    {
      "epoch": 21.644554149953716,
      "grad_norm": 1.823488673835527e-05,
      "learning_rate": 2.8355445850046287e-05,
      "loss": 0.0003,
      "step": 70150
    },
    {
      "epoch": 21.647639617402035,
      "grad_norm": 1.6552305169170722e-05,
      "learning_rate": 2.8352360382597966e-05,
      "loss": 0.0009,
      "step": 70160
    },
    {
      "epoch": 21.650725084850354,
      "grad_norm": 0.0002504469593986869,
      "learning_rate": 2.8349274915149648e-05,
      "loss": 0.0,
      "step": 70170
    },
    {
      "epoch": 21.653810552298673,
      "grad_norm": 0.0011415430344641209,
      "learning_rate": 2.8346189447701327e-05,
      "loss": 0.0001,
      "step": 70180
    },
    {
      "epoch": 21.65689601974699,
      "grad_norm": 0.0031555735040456057,
      "learning_rate": 2.834310398025301e-05,
      "loss": 0.0001,
      "step": 70190
    },
    {
      "epoch": 21.65998148719531,
      "grad_norm": 0.001074688509106636,
      "learning_rate": 2.834001851280469e-05,
      "loss": 0.0,
      "step": 70200
    },
    {
      "epoch": 21.66306695464363,
      "grad_norm": 8.543807052774355e-05,
      "learning_rate": 2.8336933045356375e-05,
      "loss": 0.0033,
      "step": 70210
    },
    {
      "epoch": 21.666152422091947,
      "grad_norm": 0.055243756622076035,
      "learning_rate": 2.8333847577908057e-05,
      "loss": 0.0009,
      "step": 70220
    },
    {
      "epoch": 21.669237889540266,
      "grad_norm": 0.029331812635064125,
      "learning_rate": 2.8330762110459736e-05,
      "loss": 0.0004,
      "step": 70230
    },
    {
      "epoch": 21.672323356988585,
      "grad_norm": 0.17510469257831573,
      "learning_rate": 2.832767664301142e-05,
      "loss": 0.0019,
      "step": 70240
    },
    {
      "epoch": 21.675408824436904,
      "grad_norm": 0.00032103603007271886,
      "learning_rate": 2.8324591175563098e-05,
      "loss": 0.0,
      "step": 70250
    },
    {
      "epoch": 21.678494291885222,
      "grad_norm": 0.13085676729679108,
      "learning_rate": 2.832150570811478e-05,
      "loss": 0.0002,
      "step": 70260
    },
    {
      "epoch": 21.681579759333538,
      "grad_norm": 0.306600421667099,
      "learning_rate": 2.831842024066646e-05,
      "loss": 0.002,
      "step": 70270
    },
    {
      "epoch": 21.684665226781856,
      "grad_norm": 0.00011094199726358056,
      "learning_rate": 2.8315334773218145e-05,
      "loss": 0.0041,
      "step": 70280
    },
    {
      "epoch": 21.687750694230175,
      "grad_norm": 0.109404057264328,
      "learning_rate": 2.8312249305769828e-05,
      "loss": 0.0004,
      "step": 70290
    },
    {
      "epoch": 21.690836161678494,
      "grad_norm": 3.352081330376677e-05,
      "learning_rate": 2.8309163838321507e-05,
      "loss": 0.0001,
      "step": 70300
    },
    {
      "epoch": 21.693921629126812,
      "grad_norm": 0.2088005691766739,
      "learning_rate": 2.830607837087319e-05,
      "loss": 0.0001,
      "step": 70310
    },
    {
      "epoch": 21.69700709657513,
      "grad_norm": 0.0004822583287023008,
      "learning_rate": 2.830299290342487e-05,
      "loss": 0.0002,
      "step": 70320
    },
    {
      "epoch": 21.70009256402345,
      "grad_norm": 0.0003838346747215837,
      "learning_rate": 2.829990743597655e-05,
      "loss": 0.0,
      "step": 70330
    },
    {
      "epoch": 21.70317803147177,
      "grad_norm": 0.009376868605613708,
      "learning_rate": 2.829682196852823e-05,
      "loss": 0.0,
      "step": 70340
    },
    {
      "epoch": 21.706263498920087,
      "grad_norm": 0.00410537188872695,
      "learning_rate": 2.8293736501079916e-05,
      "loss": 0.0001,
      "step": 70350
    },
    {
      "epoch": 21.709348966368406,
      "grad_norm": 5.941866447756183e-07,
      "learning_rate": 2.82906510336316e-05,
      "loss": 0.0,
      "step": 70360
    },
    {
      "epoch": 21.712434433816725,
      "grad_norm": 0.0002716835297178477,
      "learning_rate": 2.8287565566183277e-05,
      "loss": 0.0,
      "step": 70370
    },
    {
      "epoch": 21.71551990126504,
      "grad_norm": 0.003099660621955991,
      "learning_rate": 2.828448009873496e-05,
      "loss": 0.0005,
      "step": 70380
    },
    {
      "epoch": 21.71860536871336,
      "grad_norm": 4.9719437811290845e-05,
      "learning_rate": 2.828139463128664e-05,
      "loss": 0.0,
      "step": 70390
    },
    {
      "epoch": 21.721690836161677,
      "grad_norm": 0.0004875404410995543,
      "learning_rate": 2.8278309163838325e-05,
      "loss": 0.0013,
      "step": 70400
    },
    {
      "epoch": 21.724776303609996,
      "grad_norm": 0.00010438157187309116,
      "learning_rate": 2.827522369639e-05,
      "loss": 0.0,
      "step": 70410
    },
    {
      "epoch": 21.727861771058315,
      "grad_norm": 0.00010498188203200698,
      "learning_rate": 2.8272138228941686e-05,
      "loss": 0.0001,
      "step": 70420
    },
    {
      "epoch": 21.730947238506634,
      "grad_norm": 0.02621038630604744,
      "learning_rate": 2.826905276149337e-05,
      "loss": 0.0069,
      "step": 70430
    },
    {
      "epoch": 21.734032705954952,
      "grad_norm": 0.0009792294586077332,
      "learning_rate": 2.8265967294045048e-05,
      "loss": 0.0001,
      "step": 70440
    },
    {
      "epoch": 21.73711817340327,
      "grad_norm": 3.1358088108390803e-06,
      "learning_rate": 2.826288182659673e-05,
      "loss": 0.0,
      "step": 70450
    },
    {
      "epoch": 21.74020364085159,
      "grad_norm": 0.001224877662025392,
      "learning_rate": 2.825979635914841e-05,
      "loss": 0.0027,
      "step": 70460
    },
    {
      "epoch": 21.74328910829991,
      "grad_norm": 0.0001671362842898816,
      "learning_rate": 2.8256710891700095e-05,
      "loss": 0.0,
      "step": 70470
    },
    {
      "epoch": 21.746374575748227,
      "grad_norm": 2.1082307284814306e-05,
      "learning_rate": 2.8253625424251775e-05,
      "loss": 0.0001,
      "step": 70480
    },
    {
      "epoch": 21.749460043196546,
      "grad_norm": 0.033528901636600494,
      "learning_rate": 2.8250539956803457e-05,
      "loss": 0.0001,
      "step": 70490
    },
    {
      "epoch": 21.75254551064486,
      "grad_norm": 0.07452220469713211,
      "learning_rate": 2.824745448935514e-05,
      "loss": 0.001,
      "step": 70500
    },
    {
      "epoch": 21.75563097809318,
      "grad_norm": 6.034730904502794e-05,
      "learning_rate": 2.824436902190682e-05,
      "loss": 0.0,
      "step": 70510
    },
    {
      "epoch": 21.7587164455415,
      "grad_norm": 7.029083917586831e-06,
      "learning_rate": 2.8241283554458504e-05,
      "loss": 0.0001,
      "step": 70520
    },
    {
      "epoch": 21.761801912989817,
      "grad_norm": 4.474321394809522e-05,
      "learning_rate": 2.823819808701018e-05,
      "loss": 0.0002,
      "step": 70530
    },
    {
      "epoch": 21.764887380438136,
      "grad_norm": 0.10054577887058258,
      "learning_rate": 2.8235112619561866e-05,
      "loss": 0.0001,
      "step": 70540
    },
    {
      "epoch": 21.767972847886455,
      "grad_norm": 1.662597469476168e-06,
      "learning_rate": 2.823202715211355e-05,
      "loss": 0.0,
      "step": 70550
    },
    {
      "epoch": 21.771058315334773,
      "grad_norm": 0.0033542229793965816,
      "learning_rate": 2.8228941684665228e-05,
      "loss": 0.0003,
      "step": 70560
    },
    {
      "epoch": 21.774143782783092,
      "grad_norm": 0.0005564210005104542,
      "learning_rate": 2.822585621721691e-05,
      "loss": 0.0,
      "step": 70570
    },
    {
      "epoch": 21.77722925023141,
      "grad_norm": 0.00010482241486897692,
      "learning_rate": 2.822277074976859e-05,
      "loss": 0.0003,
      "step": 70580
    },
    {
      "epoch": 21.78031471767973,
      "grad_norm": 0.003450112883001566,
      "learning_rate": 2.8219685282320275e-05,
      "loss": 0.0111,
      "step": 70590
    },
    {
      "epoch": 21.78340018512805,
      "grad_norm": 8.284857904072851e-05,
      "learning_rate": 2.821659981487195e-05,
      "loss": 0.0,
      "step": 70600
    },
    {
      "epoch": 21.786485652576367,
      "grad_norm": 0.00019011032418347895,
      "learning_rate": 2.8213514347423637e-05,
      "loss": 0.0002,
      "step": 70610
    },
    {
      "epoch": 21.789571120024682,
      "grad_norm": 0.00040466876816935837,
      "learning_rate": 2.821042887997532e-05,
      "loss": 0.0001,
      "step": 70620
    },
    {
      "epoch": 21.792656587473,
      "grad_norm": 0.0009912486420944333,
      "learning_rate": 2.8207343412526998e-05,
      "loss": 0.0004,
      "step": 70630
    },
    {
      "epoch": 21.79574205492132,
      "grad_norm": 0.011109511367976665,
      "learning_rate": 2.8204257945078684e-05,
      "loss": 0.0009,
      "step": 70640
    },
    {
      "epoch": 21.79882752236964,
      "grad_norm": 0.004188075195997953,
      "learning_rate": 2.820117247763036e-05,
      "loss": 0.0,
      "step": 70650
    },
    {
      "epoch": 21.801912989817957,
      "grad_norm": 0.00834440067410469,
      "learning_rate": 2.8198087010182046e-05,
      "loss": 0.0,
      "step": 70660
    },
    {
      "epoch": 21.804998457266276,
      "grad_norm": 0.1108982115983963,
      "learning_rate": 2.8195001542733725e-05,
      "loss": 0.0006,
      "step": 70670
    },
    {
      "epoch": 21.808083924714595,
      "grad_norm": 0.0008473609341308475,
      "learning_rate": 2.8191916075285407e-05,
      "loss": 0.0049,
      "step": 70680
    },
    {
      "epoch": 21.811169392162913,
      "grad_norm": 0.004521808121353388,
      "learning_rate": 2.818883060783709e-05,
      "loss": 0.0002,
      "step": 70690
    },
    {
      "epoch": 21.814254859611232,
      "grad_norm": 0.7848399877548218,
      "learning_rate": 2.818574514038877e-05,
      "loss": 0.0016,
      "step": 70700
    },
    {
      "epoch": 21.81734032705955,
      "grad_norm": 0.00013022140774410218,
      "learning_rate": 2.8182659672940455e-05,
      "loss": 0.0001,
      "step": 70710
    },
    {
      "epoch": 21.82042579450787,
      "grad_norm": 0.007501563057303429,
      "learning_rate": 2.817957420549213e-05,
      "loss": 0.0001,
      "step": 70720
    },
    {
      "epoch": 21.823511261956185,
      "grad_norm": 0.001620148541405797,
      "learning_rate": 2.8176488738043816e-05,
      "loss": 0.0004,
      "step": 70730
    },
    {
      "epoch": 21.826596729404503,
      "grad_norm": 0.10994596034288406,
      "learning_rate": 2.8173403270595495e-05,
      "loss": 0.0001,
      "step": 70740
    },
    {
      "epoch": 21.829682196852822,
      "grad_norm": 7.94104635133408e-05,
      "learning_rate": 2.8170317803147178e-05,
      "loss": 0.0005,
      "step": 70750
    },
    {
      "epoch": 21.83276766430114,
      "grad_norm": 0.00010451438720338047,
      "learning_rate": 2.8167232335698864e-05,
      "loss": 0.0001,
      "step": 70760
    },
    {
      "epoch": 21.83585313174946,
      "grad_norm": 0.0028205462731420994,
      "learning_rate": 2.816414686825054e-05,
      "loss": 0.0002,
      "step": 70770
    },
    {
      "epoch": 21.83893859919778,
      "grad_norm": 6.121997284935787e-05,
      "learning_rate": 2.8161061400802225e-05,
      "loss": 0.0,
      "step": 70780
    },
    {
      "epoch": 21.842024066646097,
      "grad_norm": 0.00031511206179857254,
      "learning_rate": 2.8157975933353904e-05,
      "loss": 0.0008,
      "step": 70790
    },
    {
      "epoch": 21.845109534094416,
      "grad_norm": 2.1227219104766846,
      "learning_rate": 2.8154890465905587e-05,
      "loss": 0.0011,
      "step": 70800
    },
    {
      "epoch": 21.848195001542734,
      "grad_norm": 1.0988998413085938,
      "learning_rate": 2.8151804998457266e-05,
      "loss": 0.0016,
      "step": 70810
    },
    {
      "epoch": 21.851280468991053,
      "grad_norm": 0.0018749559530988336,
      "learning_rate": 2.8148719531008948e-05,
      "loss": 0.0008,
      "step": 70820
    },
    {
      "epoch": 21.854365936439372,
      "grad_norm": 0.29243141412734985,
      "learning_rate": 2.8145634063560634e-05,
      "loss": 0.0001,
      "step": 70830
    },
    {
      "epoch": 21.85745140388769,
      "grad_norm": 0.004637221340090036,
      "learning_rate": 2.814254859611231e-05,
      "loss": 0.0001,
      "step": 70840
    },
    {
      "epoch": 21.860536871336006,
      "grad_norm": 0.00022052654821891338,
      "learning_rate": 2.8139463128663996e-05,
      "loss": 0.0025,
      "step": 70850
    },
    {
      "epoch": 21.863622338784324,
      "grad_norm": 1.0964463949203491,
      "learning_rate": 2.8136377661215675e-05,
      "loss": 0.0126,
      "step": 70860
    },
    {
      "epoch": 21.866707806232643,
      "grad_norm": 6.44120664219372e-05,
      "learning_rate": 2.8133292193767357e-05,
      "loss": 0.0012,
      "step": 70870
    },
    {
      "epoch": 21.869793273680962,
      "grad_norm": 0.011361772194504738,
      "learning_rate": 2.8130206726319036e-05,
      "loss": 0.0,
      "step": 70880
    },
    {
      "epoch": 21.87287874112928,
      "grad_norm": 0.07054663449525833,
      "learning_rate": 2.812712125887072e-05,
      "loss": 0.0001,
      "step": 70890
    },
    {
      "epoch": 21.8759642085776,
      "grad_norm": 2.7423404389992356e-05,
      "learning_rate": 2.8124035791422405e-05,
      "loss": 0.0034,
      "step": 70900
    },
    {
      "epoch": 21.879049676025918,
      "grad_norm": 5.217971192905679e-07,
      "learning_rate": 2.8120950323974084e-05,
      "loss": 0.0006,
      "step": 70910
    },
    {
      "epoch": 21.882135143474237,
      "grad_norm": 0.0006495098932646215,
      "learning_rate": 2.8117864856525766e-05,
      "loss": 0.0002,
      "step": 70920
    },
    {
      "epoch": 21.885220610922556,
      "grad_norm": 0.00011649111547740176,
      "learning_rate": 2.8114779389077445e-05,
      "loss": 0.0017,
      "step": 70930
    },
    {
      "epoch": 21.888306078370874,
      "grad_norm": 0.004414508119225502,
      "learning_rate": 2.8111693921629128e-05,
      "loss": 0.0,
      "step": 70940
    },
    {
      "epoch": 21.891391545819193,
      "grad_norm": 0.000541095098014921,
      "learning_rate": 2.8108608454180807e-05,
      "loss": 0.0006,
      "step": 70950
    },
    {
      "epoch": 21.89447701326751,
      "grad_norm": 7.781965541653335e-05,
      "learning_rate": 2.810552298673249e-05,
      "loss": 0.0,
      "step": 70960
    },
    {
      "epoch": 21.897562480715827,
      "grad_norm": 0.13898544013500214,
      "learning_rate": 2.8102437519284175e-05,
      "loss": 0.0003,
      "step": 70970
    },
    {
      "epoch": 21.900647948164146,
      "grad_norm": 5.3919986385153607e-05,
      "learning_rate": 2.8099352051835854e-05,
      "loss": 0.0001,
      "step": 70980
    },
    {
      "epoch": 21.903733415612464,
      "grad_norm": 0.00014780295896343887,
      "learning_rate": 2.8096266584387537e-05,
      "loss": 0.0,
      "step": 70990
    },
    {
      "epoch": 21.906818883060783,
      "grad_norm": 0.0006382768624462187,
      "learning_rate": 2.8093181116939216e-05,
      "loss": 0.0,
      "step": 71000
    },
    {
      "epoch": 21.909904350509102,
      "grad_norm": 1.3388283832682646e-06,
      "learning_rate": 2.80900956494909e-05,
      "loss": 0.001,
      "step": 71010
    },
    {
      "epoch": 21.91298981795742,
      "grad_norm": 0.006885230541229248,
      "learning_rate": 2.8087010182042584e-05,
      "loss": 0.0002,
      "step": 71020
    },
    {
      "epoch": 21.91607528540574,
      "grad_norm": 3.78645199816674e-05,
      "learning_rate": 2.8083924714594263e-05,
      "loss": 0.0,
      "step": 71030
    },
    {
      "epoch": 21.919160752854058,
      "grad_norm": 0.000398939591832459,
      "learning_rate": 2.8080839247145946e-05,
      "loss": 0.0,
      "step": 71040
    },
    {
      "epoch": 21.922246220302377,
      "grad_norm": 0.028768355026841164,
      "learning_rate": 2.8077753779697625e-05,
      "loss": 0.0022,
      "step": 71050
    },
    {
      "epoch": 21.925331687750695,
      "grad_norm": 0.0009553903364576399,
      "learning_rate": 2.8074668312249307e-05,
      "loss": 0.0001,
      "step": 71060
    },
    {
      "epoch": 21.928417155199014,
      "grad_norm": 1.2089656593161635e-05,
      "learning_rate": 2.8071582844800986e-05,
      "loss": 0.0,
      "step": 71070
    },
    {
      "epoch": 21.93150262264733,
      "grad_norm": 0.0008757412433624268,
      "learning_rate": 2.806849737735267e-05,
      "loss": 0.0,
      "step": 71080
    },
    {
      "epoch": 21.934588090095648,
      "grad_norm": 0.009840600192546844,
      "learning_rate": 2.8065411909904355e-05,
      "loss": 0.0024,
      "step": 71090
    },
    {
      "epoch": 21.937673557543967,
      "grad_norm": 0.7362813353538513,
      "learning_rate": 2.8062326442456034e-05,
      "loss": 0.0038,
      "step": 71100
    },
    {
      "epoch": 21.940759024992285,
      "grad_norm": 0.00012063667236361653,
      "learning_rate": 2.8059240975007716e-05,
      "loss": 0.0,
      "step": 71110
    },
    {
      "epoch": 21.943844492440604,
      "grad_norm": 0.00019635392527561635,
      "learning_rate": 2.8056155507559395e-05,
      "loss": 0.0042,
      "step": 71120
    },
    {
      "epoch": 21.946929959888923,
      "grad_norm": 0.00018188329704571515,
      "learning_rate": 2.8053070040111078e-05,
      "loss": 0.0004,
      "step": 71130
    },
    {
      "epoch": 21.95001542733724,
      "grad_norm": 0.018164386972784996,
      "learning_rate": 2.8049984572662757e-05,
      "loss": 0.0,
      "step": 71140
    },
    {
      "epoch": 21.95310089478556,
      "grad_norm": 0.03302496299147606,
      "learning_rate": 2.8046899105214443e-05,
      "loss": 0.0045,
      "step": 71150
    },
    {
      "epoch": 21.95618636223388,
      "grad_norm": 0.003929977770894766,
      "learning_rate": 2.8043813637766125e-05,
      "loss": 0.0,
      "step": 71160
    },
    {
      "epoch": 21.959271829682198,
      "grad_norm": 0.0001882448559626937,
      "learning_rate": 2.8040728170317804e-05,
      "loss": 0.0001,
      "step": 71170
    },
    {
      "epoch": 21.962357297130517,
      "grad_norm": 0.6179346442222595,
      "learning_rate": 2.8037642702869487e-05,
      "loss": 0.0003,
      "step": 71180
    },
    {
      "epoch": 21.965442764578835,
      "grad_norm": 0.01459513045847416,
      "learning_rate": 2.8034557235421166e-05,
      "loss": 0.0002,
      "step": 71190
    },
    {
      "epoch": 21.96852823202715,
      "grad_norm": 0.09187816828489304,
      "learning_rate": 2.803147176797285e-05,
      "loss": 0.0001,
      "step": 71200
    },
    {
      "epoch": 21.97161369947547,
      "grad_norm": 0.005113369785249233,
      "learning_rate": 2.8028386300524528e-05,
      "loss": 0.0005,
      "step": 71210
    },
    {
      "epoch": 21.974699166923788,
      "grad_norm": 0.016208818182349205,
      "learning_rate": 2.8025300833076213e-05,
      "loss": 0.0047,
      "step": 71220
    },
    {
      "epoch": 21.977784634372107,
      "grad_norm": 0.04763979837298393,
      "learning_rate": 2.8022215365627896e-05,
      "loss": 0.0001,
      "step": 71230
    },
    {
      "epoch": 21.980870101820425,
      "grad_norm": 0.0004852566053159535,
      "learning_rate": 2.8019129898179575e-05,
      "loss": 0.0001,
      "step": 71240
    },
    {
      "epoch": 21.983955569268744,
      "grad_norm": 2.5678175006760284e-05,
      "learning_rate": 2.8016044430731257e-05,
      "loss": 0.0,
      "step": 71250
    },
    {
      "epoch": 21.987041036717063,
      "grad_norm": 9.440068242838606e-05,
      "learning_rate": 2.8012958963282937e-05,
      "loss": 0.0,
      "step": 71260
    },
    {
      "epoch": 21.99012650416538,
      "grad_norm": 0.2904016971588135,
      "learning_rate": 2.8009873495834622e-05,
      "loss": 0.0021,
      "step": 71270
    },
    {
      "epoch": 21.9932119716137,
      "grad_norm": 0.017526332288980484,
      "learning_rate": 2.8006788028386298e-05,
      "loss": 0.0003,
      "step": 71280
    },
    {
      "epoch": 21.99629743906202,
      "grad_norm": 0.024095183238387108,
      "learning_rate": 2.8003702560937984e-05,
      "loss": 0.0001,
      "step": 71290
    },
    {
      "epoch": 21.999382906510338,
      "grad_norm": 0.00013134587788954377,
      "learning_rate": 2.8000617093489666e-05,
      "loss": 0.0002,
      "step": 71300
    },
    {
      "epoch": 22.0,
      "eval_accuracy_branch1": 0.9996817221723908,
      "eval_accuracy_branch2": 0.42441866072548057,
      "eval_f1_branch1": 0.9995906000690714,
      "eval_f1_branch2": 0.4218871934400027,
      "eval_loss": 0.0003982205525971949,
      "eval_precision_branch1": 0.9996172804422023,
      "eval_precision_branch2": 0.5025944612064327,
      "eval_recall_branch1": 0.9995645027686257,
      "eval_recall_branch2": 0.502285813489193,
      "eval_runtime": 243.2924,
      "eval_samples_per_second": 426.166,
      "eval_steps_per_second": 53.273,
      "step": 71302
    },
    {
      "epoch": 22.002468373958656,
      "grad_norm": 0.00012014573439955711,
      "learning_rate": 2.7997531626041346e-05,
      "loss": 0.0003,
      "step": 71310
    },
    {
      "epoch": 22.00555384140697,
      "grad_norm": 0.004431705456227064,
      "learning_rate": 2.7994446158593028e-05,
      "loss": 0.0,
      "step": 71320
    },
    {
      "epoch": 22.00863930885529,
      "grad_norm": 0.0009760374086908996,
      "learning_rate": 2.7991360691144707e-05,
      "loss": 0.0,
      "step": 71330
    },
    {
      "epoch": 22.01172477630361,
      "grad_norm": 0.004457677248865366,
      "learning_rate": 2.7988275223696393e-05,
      "loss": 0.0006,
      "step": 71340
    },
    {
      "epoch": 22.014810243751928,
      "grad_norm": 0.013739625923335552,
      "learning_rate": 2.798518975624807e-05,
      "loss": 0.0002,
      "step": 71350
    },
    {
      "epoch": 22.017895711200246,
      "grad_norm": 0.0013281914871186018,
      "learning_rate": 2.7982104288799755e-05,
      "loss": 0.0002,
      "step": 71360
    },
    {
      "epoch": 22.020981178648565,
      "grad_norm": 0.00011808901763288304,
      "learning_rate": 2.7979018821351437e-05,
      "loss": 0.0,
      "step": 71370
    },
    {
      "epoch": 22.024066646096884,
      "grad_norm": 3.8852953910827637,
      "learning_rate": 2.7975933353903116e-05,
      "loss": 0.0035,
      "step": 71380
    },
    {
      "epoch": 22.027152113545203,
      "grad_norm": 0.00016222028352785856,
      "learning_rate": 2.7972847886454802e-05,
      "loss": 0.0007,
      "step": 71390
    },
    {
      "epoch": 22.03023758099352,
      "grad_norm": 0.0033347303979098797,
      "learning_rate": 2.7969762419006478e-05,
      "loss": 0.0024,
      "step": 71400
    },
    {
      "epoch": 22.03332304844184,
      "grad_norm": 0.0002596660633571446,
      "learning_rate": 2.7966676951558164e-05,
      "loss": 0.0004,
      "step": 71410
    },
    {
      "epoch": 22.03640851589016,
      "grad_norm": 2.4232902433141135e-05,
      "learning_rate": 2.7963591484109846e-05,
      "loss": 0.0,
      "step": 71420
    },
    {
      "epoch": 22.039493983338478,
      "grad_norm": 0.29925984144210815,
      "learning_rate": 2.7960506016661525e-05,
      "loss": 0.0005,
      "step": 71430
    },
    {
      "epoch": 22.042579450786793,
      "grad_norm": 3.668122008093633e-05,
      "learning_rate": 2.7957420549213208e-05,
      "loss": 0.0089,
      "step": 71440
    },
    {
      "epoch": 22.04566491823511,
      "grad_norm": 0.0015341107500717044,
      "learning_rate": 2.7954335081764887e-05,
      "loss": 0.0,
      "step": 71450
    },
    {
      "epoch": 22.04875038568343,
      "grad_norm": 0.010086665861308575,
      "learning_rate": 2.7951249614316573e-05,
      "loss": 0.0,
      "step": 71460
    },
    {
      "epoch": 22.05183585313175,
      "grad_norm": 1.8882778022089042e-05,
      "learning_rate": 2.7948164146868248e-05,
      "loss": 0.0009,
      "step": 71470
    },
    {
      "epoch": 22.054921320580068,
      "grad_norm": 0.22337263822555542,
      "learning_rate": 2.7945078679419934e-05,
      "loss": 0.0008,
      "step": 71480
    },
    {
      "epoch": 22.058006788028386,
      "grad_norm": 0.00017327928799204528,
      "learning_rate": 2.7941993211971617e-05,
      "loss": 0.0012,
      "step": 71490
    },
    {
      "epoch": 22.061092255476705,
      "grad_norm": 0.030103011056780815,
      "learning_rate": 2.7938907744523296e-05,
      "loss": 0.0002,
      "step": 71500
    },
    {
      "epoch": 22.064177722925024,
      "grad_norm": 0.0006182395736686885,
      "learning_rate": 2.793582227707498e-05,
      "loss": 0.0,
      "step": 71510
    },
    {
      "epoch": 22.067263190373342,
      "grad_norm": 0.005080335773527622,
      "learning_rate": 2.7932736809626657e-05,
      "loss": 0.0,
      "step": 71520
    },
    {
      "epoch": 22.07034865782166,
      "grad_norm": 4.976141281076707e-05,
      "learning_rate": 2.7929651342178343e-05,
      "loss": 0.0048,
      "step": 71530
    },
    {
      "epoch": 22.07343412526998,
      "grad_norm": 0.0003339617687743157,
      "learning_rate": 2.7926565874730022e-05,
      "loss": 0.0002,
      "step": 71540
    },
    {
      "epoch": 22.076519592718295,
      "grad_norm": 0.12554582953453064,
      "learning_rate": 2.7923480407281705e-05,
      "loss": 0.0001,
      "step": 71550
    },
    {
      "epoch": 22.079605060166614,
      "grad_norm": 0.0026058738585561514,
      "learning_rate": 2.7920394939833387e-05,
      "loss": 0.0001,
      "step": 71560
    },
    {
      "epoch": 22.082690527614933,
      "grad_norm": 0.06590525805950165,
      "learning_rate": 2.7917309472385066e-05,
      "loss": 0.0001,
      "step": 71570
    },
    {
      "epoch": 22.08577599506325,
      "grad_norm": 0.09269502013921738,
      "learning_rate": 2.7914224004936752e-05,
      "loss": 0.0001,
      "step": 71580
    },
    {
      "epoch": 22.08886146251157,
      "grad_norm": 0.000578280771151185,
      "learning_rate": 2.7911138537488428e-05,
      "loss": 0.0,
      "step": 71590
    },
    {
      "epoch": 22.09194692995989,
      "grad_norm": 0.00012049601355101913,
      "learning_rate": 2.7908053070040114e-05,
      "loss": 0.0,
      "step": 71600
    },
    {
      "epoch": 22.095032397408207,
      "grad_norm": 0.008047813549637794,
      "learning_rate": 2.7904967602591793e-05,
      "loss": 0.0001,
      "step": 71610
    },
    {
      "epoch": 22.098117864856526,
      "grad_norm": 0.0010573508916422725,
      "learning_rate": 2.7901882135143475e-05,
      "loss": 0.0006,
      "step": 71620
    },
    {
      "epoch": 22.101203332304845,
      "grad_norm": 0.3097599446773529,
      "learning_rate": 2.789879666769516e-05,
      "loss": 0.0019,
      "step": 71630
    },
    {
      "epoch": 22.104288799753164,
      "grad_norm": 0.011688871309161186,
      "learning_rate": 2.7895711200246837e-05,
      "loss": 0.0001,
      "step": 71640
    },
    {
      "epoch": 22.107374267201482,
      "grad_norm": 0.00032273755641654134,
      "learning_rate": 2.7892625732798523e-05,
      "loss": 0.0,
      "step": 71650
    },
    {
      "epoch": 22.1104597346498,
      "grad_norm": 0.00012087727373000234,
      "learning_rate": 2.7889540265350202e-05,
      "loss": 0.0001,
      "step": 71660
    },
    {
      "epoch": 22.113545202098116,
      "grad_norm": 2.0042105461470783e-05,
      "learning_rate": 2.7886454797901884e-05,
      "loss": 0.0132,
      "step": 71670
    },
    {
      "epoch": 22.116630669546435,
      "grad_norm": 0.0649661272764206,
      "learning_rate": 2.7883369330453563e-05,
      "loss": 0.0012,
      "step": 71680
    },
    {
      "epoch": 22.119716136994754,
      "grad_norm": 0.037166524678468704,
      "learning_rate": 2.7880283863005246e-05,
      "loss": 0.0003,
      "step": 71690
    },
    {
      "epoch": 22.122801604443072,
      "grad_norm": 0.0005054121138527989,
      "learning_rate": 2.787719839555693e-05,
      "loss": 0.0097,
      "step": 71700
    },
    {
      "epoch": 22.12588707189139,
      "grad_norm": 0.04135039076209068,
      "learning_rate": 2.7874112928108607e-05,
      "loss": 0.0005,
      "step": 71710
    },
    {
      "epoch": 22.12897253933971,
      "grad_norm": 0.2697352170944214,
      "learning_rate": 2.7871027460660293e-05,
      "loss": 0.0001,
      "step": 71720
    },
    {
      "epoch": 22.13205800678803,
      "grad_norm": 4.046069534524577e-06,
      "learning_rate": 2.7867941993211972e-05,
      "loss": 0.0001,
      "step": 71730
    },
    {
      "epoch": 22.135143474236347,
      "grad_norm": 0.00900473166257143,
      "learning_rate": 2.7864856525763655e-05,
      "loss": 0.0001,
      "step": 71740
    },
    {
      "epoch": 22.138228941684666,
      "grad_norm": 1.3678180039278232e-05,
      "learning_rate": 2.7861771058315334e-05,
      "loss": 0.001,
      "step": 71750
    },
    {
      "epoch": 22.141314409132985,
      "grad_norm": 7.802809705026448e-05,
      "learning_rate": 2.7858685590867016e-05,
      "loss": 0.0,
      "step": 71760
    },
    {
      "epoch": 22.144399876581303,
      "grad_norm": 0.0003112088597845286,
      "learning_rate": 2.7855600123418702e-05,
      "loss": 0.0075,
      "step": 71770
    },
    {
      "epoch": 22.147485344029622,
      "grad_norm": 0.0001812148984754458,
      "learning_rate": 2.785251465597038e-05,
      "loss": 0.0,
      "step": 71780
    },
    {
      "epoch": 22.150570811477937,
      "grad_norm": 0.000176492307218723,
      "learning_rate": 2.7849429188522064e-05,
      "loss": 0.0001,
      "step": 71790
    },
    {
      "epoch": 22.153656278926256,
      "grad_norm": 1.4116079000814352e-05,
      "learning_rate": 2.7846343721073743e-05,
      "loss": 0.0001,
      "step": 71800
    },
    {
      "epoch": 22.156741746374575,
      "grad_norm": 1.596035872353241e-05,
      "learning_rate": 2.7843258253625425e-05,
      "loss": 0.0,
      "step": 71810
    },
    {
      "epoch": 22.159827213822894,
      "grad_norm": 0.4098692238330841,
      "learning_rate": 2.7840172786177104e-05,
      "loss": 0.0004,
      "step": 71820
    },
    {
      "epoch": 22.162912681271212,
      "grad_norm": 0.0028903710190206766,
      "learning_rate": 2.7837087318728787e-05,
      "loss": 0.0001,
      "step": 71830
    },
    {
      "epoch": 22.16599814871953,
      "grad_norm": 0.0001286315091419965,
      "learning_rate": 2.7834001851280473e-05,
      "loss": 0.0001,
      "step": 71840
    },
    {
      "epoch": 22.16908361616785,
      "grad_norm": 0.013646586798131466,
      "learning_rate": 2.7830916383832152e-05,
      "loss": 0.0012,
      "step": 71850
    },
    {
      "epoch": 22.17216908361617,
      "grad_norm": 3.986376032116823e-05,
      "learning_rate": 2.7827830916383834e-05,
      "loss": 0.0015,
      "step": 71860
    },
    {
      "epoch": 22.175254551064487,
      "grad_norm": 0.0004458580515347421,
      "learning_rate": 2.7824745448935513e-05,
      "loss": 0.0,
      "step": 71870
    },
    {
      "epoch": 22.178340018512806,
      "grad_norm": 0.0009914623806253076,
      "learning_rate": 2.7821659981487196e-05,
      "loss": 0.0066,
      "step": 71880
    },
    {
      "epoch": 22.181425485961125,
      "grad_norm": 1.173120199382538e-05,
      "learning_rate": 2.7818574514038882e-05,
      "loss": 0.0004,
      "step": 71890
    },
    {
      "epoch": 22.18451095340944,
      "grad_norm": 0.0011385639663785696,
      "learning_rate": 2.781548904659056e-05,
      "loss": 0.0001,
      "step": 71900
    },
    {
      "epoch": 22.18759642085776,
      "grad_norm": 0.000298328377539292,
      "learning_rate": 2.7812403579142243e-05,
      "loss": 0.0034,
      "step": 71910
    },
    {
      "epoch": 22.190681888306077,
      "grad_norm": 3.2731993542256532e-06,
      "learning_rate": 2.7809318111693922e-05,
      "loss": 0.0002,
      "step": 71920
    },
    {
      "epoch": 22.193767355754396,
      "grad_norm": 1.2803210020065308,
      "learning_rate": 2.7806232644245605e-05,
      "loss": 0.0003,
      "step": 71930
    },
    {
      "epoch": 22.196852823202715,
      "grad_norm": 0.00017107307212427258,
      "learning_rate": 2.7803147176797284e-05,
      "loss": 0.0006,
      "step": 71940
    },
    {
      "epoch": 22.199938290651033,
      "grad_norm": 0.00187831895891577,
      "learning_rate": 2.7800061709348966e-05,
      "loss": 0.0008,
      "step": 71950
    },
    {
      "epoch": 22.203023758099352,
      "grad_norm": 1.448486566543579,
      "learning_rate": 2.7796976241900652e-05,
      "loss": 0.0006,
      "step": 71960
    },
    {
      "epoch": 22.20610922554767,
      "grad_norm": 0.0023390627466142178,
      "learning_rate": 2.779389077445233e-05,
      "loss": 0.0,
      "step": 71970
    },
    {
      "epoch": 22.20919469299599,
      "grad_norm": 0.00020030436280649155,
      "learning_rate": 2.7790805307004014e-05,
      "loss": 0.0026,
      "step": 71980
    },
    {
      "epoch": 22.21228016044431,
      "grad_norm": 0.0149220060557127,
      "learning_rate": 2.7787719839555693e-05,
      "loss": 0.0005,
      "step": 71990
    },
    {
      "epoch": 22.215365627892627,
      "grad_norm": 1.005039734991442e-06,
      "learning_rate": 2.7784634372107375e-05,
      "loss": 0.0002,
      "step": 72000
    },
    {
      "epoch": 22.218451095340946,
      "grad_norm": 7.674240623600781e-05,
      "learning_rate": 2.7781548904659055e-05,
      "loss": 0.0001,
      "step": 72010
    },
    {
      "epoch": 22.22153656278926,
      "grad_norm": 3.167754650115967,
      "learning_rate": 2.777846343721074e-05,
      "loss": 0.0035,
      "step": 72020
    },
    {
      "epoch": 22.22462203023758,
      "grad_norm": 0.041696857661008835,
      "learning_rate": 2.7775377969762423e-05,
      "loss": 0.0045,
      "step": 72030
    },
    {
      "epoch": 22.2277074976859,
      "grad_norm": 2.01234743144596e-05,
      "learning_rate": 2.7772292502314102e-05,
      "loss": 0.0028,
      "step": 72040
    },
    {
      "epoch": 22.230792965134217,
      "grad_norm": 0.15421324968338013,
      "learning_rate": 2.7769207034865784e-05,
      "loss": 0.0002,
      "step": 72050
    },
    {
      "epoch": 22.233878432582536,
      "grad_norm": 0.06940919160842896,
      "learning_rate": 2.7766121567417464e-05,
      "loss": 0.0009,
      "step": 72060
    },
    {
      "epoch": 22.236963900030855,
      "grad_norm": 4.8182606406044215e-05,
      "learning_rate": 2.7763036099969146e-05,
      "loss": 0.0001,
      "step": 72070
    },
    {
      "epoch": 22.240049367479173,
      "grad_norm": 0.0001620741531951353,
      "learning_rate": 2.7759950632520825e-05,
      "loss": 0.003,
      "step": 72080
    },
    {
      "epoch": 22.243134834927492,
      "grad_norm": 0.008860020898282528,
      "learning_rate": 2.775686516507251e-05,
      "loss": 0.0,
      "step": 72090
    },
    {
      "epoch": 22.24622030237581,
      "grad_norm": 2.297953187735402e-06,
      "learning_rate": 2.7753779697624193e-05,
      "loss": 0.0218,
      "step": 72100
    },
    {
      "epoch": 22.24930576982413,
      "grad_norm": 2.282027890032623e-05,
      "learning_rate": 2.7750694230175873e-05,
      "loss": 0.0,
      "step": 72110
    },
    {
      "epoch": 22.252391237272448,
      "grad_norm": 1.5255842208862305,
      "learning_rate": 2.7747608762727555e-05,
      "loss": 0.0014,
      "step": 72120
    },
    {
      "epoch": 22.255476704720767,
      "grad_norm": 0.16665232181549072,
      "learning_rate": 2.7744523295279234e-05,
      "loss": 0.0004,
      "step": 72130
    },
    {
      "epoch": 22.258562172169082,
      "grad_norm": 3.6485137115960242e-06,
      "learning_rate": 2.774143782783092e-05,
      "loss": 0.0017,
      "step": 72140
    },
    {
      "epoch": 22.2616476396174,
      "grad_norm": 0.00016770765068940818,
      "learning_rate": 2.7738352360382596e-05,
      "loss": 0.0004,
      "step": 72150
    },
    {
      "epoch": 22.26473310706572,
      "grad_norm": 0.005517496261745691,
      "learning_rate": 2.773526689293428e-05,
      "loss": 0.0102,
      "step": 72160
    },
    {
      "epoch": 22.26781857451404,
      "grad_norm": 1.2484490071074106e-05,
      "learning_rate": 2.7732181425485964e-05,
      "loss": 0.0102,
      "step": 72170
    },
    {
      "epoch": 22.270904041962357,
      "grad_norm": 0.08916839957237244,
      "learning_rate": 2.7729095958037643e-05,
      "loss": 0.0001,
      "step": 72180
    },
    {
      "epoch": 22.273989509410676,
      "grad_norm": 0.1917545050382614,
      "learning_rate": 2.7726010490589326e-05,
      "loss": 0.0003,
      "step": 72190
    },
    {
      "epoch": 22.277074976858994,
      "grad_norm": 1.4656432540505193e-05,
      "learning_rate": 2.7722925023141005e-05,
      "loss": 0.0022,
      "step": 72200
    },
    {
      "epoch": 22.280160444307313,
      "grad_norm": 0.0013075945898890495,
      "learning_rate": 2.771983955569269e-05,
      "loss": 0.0,
      "step": 72210
    },
    {
      "epoch": 22.283245911755632,
      "grad_norm": 3.593864221329568e-06,
      "learning_rate": 2.7716754088244366e-05,
      "loss": 0.0002,
      "step": 72220
    },
    {
      "epoch": 22.28633137920395,
      "grad_norm": 0.0034426087513566017,
      "learning_rate": 2.7713668620796052e-05,
      "loss": 0.0,
      "step": 72230
    },
    {
      "epoch": 22.28941684665227,
      "grad_norm": 0.015977701172232628,
      "learning_rate": 2.7710583153347735e-05,
      "loss": 0.0001,
      "step": 72240
    },
    {
      "epoch": 22.292502314100588,
      "grad_norm": 0.3168126940727234,
      "learning_rate": 2.7707497685899414e-05,
      "loss": 0.0011,
      "step": 72250
    },
    {
      "epoch": 22.295587781548903,
      "grad_norm": 3.677880158647895e-05,
      "learning_rate": 2.77044122184511e-05,
      "loss": 0.0,
      "step": 72260
    },
    {
      "epoch": 22.298673248997222,
      "grad_norm": 0.0017917437944561243,
      "learning_rate": 2.7701326751002775e-05,
      "loss": 0.0002,
      "step": 72270
    },
    {
      "epoch": 22.30175871644554,
      "grad_norm": 0.0023611232172697783,
      "learning_rate": 2.769824128355446e-05,
      "loss": 0.0008,
      "step": 72280
    },
    {
      "epoch": 22.30484418389386,
      "grad_norm": 2.1179328541620634e-05,
      "learning_rate": 2.7695155816106144e-05,
      "loss": 0.0006,
      "step": 72290
    },
    {
      "epoch": 22.307929651342178,
      "grad_norm": 0.1984335333108902,
      "learning_rate": 2.7692070348657823e-05,
      "loss": 0.0001,
      "step": 72300
    },
    {
      "epoch": 22.311015118790497,
      "grad_norm": 3.354856380610727e-05,
      "learning_rate": 2.7688984881209505e-05,
      "loss": 0.0006,
      "step": 72310
    },
    {
      "epoch": 22.314100586238816,
      "grad_norm": 0.08838850259780884,
      "learning_rate": 2.7685899413761184e-05,
      "loss": 0.0111,
      "step": 72320
    },
    {
      "epoch": 22.317186053687134,
      "grad_norm": 2.0946616132277995e-05,
      "learning_rate": 2.768281394631287e-05,
      "loss": 0.0002,
      "step": 72330
    },
    {
      "epoch": 22.320271521135453,
      "grad_norm": 3.3524599984957604e-07,
      "learning_rate": 2.7679728478864546e-05,
      "loss": 0.0,
      "step": 72340
    },
    {
      "epoch": 22.32335698858377,
      "grad_norm": 0.0003258794022258371,
      "learning_rate": 2.767664301141623e-05,
      "loss": 0.0,
      "step": 72350
    },
    {
      "epoch": 22.32644245603209,
      "grad_norm": 0.006127422209829092,
      "learning_rate": 2.7673557543967914e-05,
      "loss": 0.0001,
      "step": 72360
    },
    {
      "epoch": 22.329527923480406,
      "grad_norm": 0.00020844046957790852,
      "learning_rate": 2.7670472076519593e-05,
      "loss": 0.001,
      "step": 72370
    },
    {
      "epoch": 22.332613390928724,
      "grad_norm": 0.0031273069325834513,
      "learning_rate": 2.766738660907128e-05,
      "loss": 0.0002,
      "step": 72380
    },
    {
      "epoch": 22.335698858377043,
      "grad_norm": 0.014437271282076836,
      "learning_rate": 2.7664301141622955e-05,
      "loss": 0.0027,
      "step": 72390
    },
    {
      "epoch": 22.33878432582536,
      "grad_norm": 0.0002722111821640283,
      "learning_rate": 2.766121567417464e-05,
      "loss": 0.0,
      "step": 72400
    },
    {
      "epoch": 22.34186979327368,
      "grad_norm": 0.0006663493695668876,
      "learning_rate": 2.765813020672632e-05,
      "loss": 0.0003,
      "step": 72410
    },
    {
      "epoch": 22.344955260722,
      "grad_norm": 1.4589725651603658e-05,
      "learning_rate": 2.7655044739278002e-05,
      "loss": 0.0004,
      "step": 72420
    },
    {
      "epoch": 22.348040728170318,
      "grad_norm": 0.8336048126220703,
      "learning_rate": 2.7651959271829685e-05,
      "loss": 0.0006,
      "step": 72430
    },
    {
      "epoch": 22.351126195618637,
      "grad_norm": 3.2610216749162646e-06,
      "learning_rate": 2.7648873804381364e-05,
      "loss": 0.001,
      "step": 72440
    },
    {
      "epoch": 22.354211663066955,
      "grad_norm": 0.6501707434654236,
      "learning_rate": 2.764578833693305e-05,
      "loss": 0.0012,
      "step": 72450
    },
    {
      "epoch": 22.357297130515274,
      "grad_norm": 0.5025074481964111,
      "learning_rate": 2.7642702869484725e-05,
      "loss": 0.0004,
      "step": 72460
    },
    {
      "epoch": 22.360382597963593,
      "grad_norm": 0.0017896037315949798,
      "learning_rate": 2.763961740203641e-05,
      "loss": 0.0005,
      "step": 72470
    },
    {
      "epoch": 22.36346806541191,
      "grad_norm": 0.0030185177456587553,
      "learning_rate": 2.763653193458809e-05,
      "loss": 0.0003,
      "step": 72480
    },
    {
      "epoch": 22.366553532860227,
      "grad_norm": 0.0001671495265327394,
      "learning_rate": 2.7633446467139773e-05,
      "loss": 0.0019,
      "step": 72490
    },
    {
      "epoch": 22.369639000308545,
      "grad_norm": 0.0358145572245121,
      "learning_rate": 2.7630360999691455e-05,
      "loss": 0.0002,
      "step": 72500
    },
    {
      "epoch": 22.372724467756864,
      "grad_norm": 7.719386303506326e-06,
      "learning_rate": 2.7627275532243134e-05,
      "loss": 0.0001,
      "step": 72510
    },
    {
      "epoch": 22.375809935205183,
      "grad_norm": 0.00018779822858050466,
      "learning_rate": 2.762419006479482e-05,
      "loss": 0.001,
      "step": 72520
    },
    {
      "epoch": 22.3788954026535,
      "grad_norm": 0.00253463676199317,
      "learning_rate": 2.76211045973465e-05,
      "loss": 0.0006,
      "step": 72530
    },
    {
      "epoch": 22.38198087010182,
      "grad_norm": 0.00010478109470568597,
      "learning_rate": 2.7618019129898182e-05,
      "loss": 0.0001,
      "step": 72540
    },
    {
      "epoch": 22.38506633755014,
      "grad_norm": 0.00046872851089574397,
      "learning_rate": 2.761493366244986e-05,
      "loss": 0.0,
      "step": 72550
    },
    {
      "epoch": 22.388151804998458,
      "grad_norm": 3.6065211296081543,
      "learning_rate": 2.7611848195001543e-05,
      "loss": 0.0027,
      "step": 72560
    },
    {
      "epoch": 22.391237272446777,
      "grad_norm": 0.012573025189340115,
      "learning_rate": 2.760876272755323e-05,
      "loss": 0.0,
      "step": 72570
    },
    {
      "epoch": 22.394322739895095,
      "grad_norm": 0.005575388204306364,
      "learning_rate": 2.7605677260104905e-05,
      "loss": 0.0017,
      "step": 72580
    },
    {
      "epoch": 22.397408207343414,
      "grad_norm": 0.00021719670621678233,
      "learning_rate": 2.760259179265659e-05,
      "loss": 0.0,
      "step": 72590
    },
    {
      "epoch": 22.400493674791733,
      "grad_norm": 0.552865207195282,
      "learning_rate": 2.759950632520827e-05,
      "loss": 0.0009,
      "step": 72600
    },
    {
      "epoch": 22.403579142240048,
      "grad_norm": 0.023595523089170456,
      "learning_rate": 2.7596420857759952e-05,
      "loss": 0.0035,
      "step": 72610
    },
    {
      "epoch": 22.406664609688367,
      "grad_norm": 0.00016494198644068092,
      "learning_rate": 2.759333539031163e-05,
      "loss": 0.0001,
      "step": 72620
    },
    {
      "epoch": 22.409750077136685,
      "grad_norm": 8.487076411256567e-05,
      "learning_rate": 2.7590249922863314e-05,
      "loss": 0.0011,
      "step": 72630
    },
    {
      "epoch": 22.412835544585004,
      "grad_norm": 0.00019712034554686397,
      "learning_rate": 2.7587164455415e-05,
      "loss": 0.0004,
      "step": 72640
    },
    {
      "epoch": 22.415921012033323,
      "grad_norm": 2.8749484044965357e-05,
      "learning_rate": 2.758407898796668e-05,
      "loss": 0.0011,
      "step": 72650
    },
    {
      "epoch": 22.41900647948164,
      "grad_norm": 1.0015182851930149e-05,
      "learning_rate": 2.758099352051836e-05,
      "loss": 0.0041,
      "step": 72660
    },
    {
      "epoch": 22.42209194692996,
      "grad_norm": 0.001648465171456337,
      "learning_rate": 2.757790805307004e-05,
      "loss": 0.0001,
      "step": 72670
    },
    {
      "epoch": 22.42517741437828,
      "grad_norm": 0.00042254364234395325,
      "learning_rate": 2.7574822585621723e-05,
      "loss": 0.0032,
      "step": 72680
    },
    {
      "epoch": 22.428262881826598,
      "grad_norm": 3.1741760722070467e-06,
      "learning_rate": 2.7571737118173402e-05,
      "loss": 0.0014,
      "step": 72690
    },
    {
      "epoch": 22.431348349274916,
      "grad_norm": 3.1911006317386637e-06,
      "learning_rate": 2.7568651650725085e-05,
      "loss": 0.0001,
      "step": 72700
    },
    {
      "epoch": 22.434433816723235,
      "grad_norm": 5.611702363239601e-05,
      "learning_rate": 2.756556618327677e-05,
      "loss": 0.0,
      "step": 72710
    },
    {
      "epoch": 22.43751928417155,
      "grad_norm": 0.0004498428897932172,
      "learning_rate": 2.756248071582845e-05,
      "loss": 0.0,
      "step": 72720
    },
    {
      "epoch": 22.44060475161987,
      "grad_norm": 0.009110206738114357,
      "learning_rate": 2.7559395248380132e-05,
      "loss": 0.0001,
      "step": 72730
    },
    {
      "epoch": 22.443690219068188,
      "grad_norm": 0.0008061699336394668,
      "learning_rate": 2.755630978093181e-05,
      "loss": 0.0009,
      "step": 72740
    },
    {
      "epoch": 22.446775686516506,
      "grad_norm": 0.0008176245028153062,
      "learning_rate": 2.7553224313483493e-05,
      "loss": 0.0007,
      "step": 72750
    },
    {
      "epoch": 22.449861153964825,
      "grad_norm": 1.9454481601715088,
      "learning_rate": 2.755013884603518e-05,
      "loss": 0.0016,
      "step": 72760
    },
    {
      "epoch": 22.452946621413144,
      "grad_norm": 1.0797813956742175e-05,
      "learning_rate": 2.7547053378586855e-05,
      "loss": 0.0012,
      "step": 72770
    },
    {
      "epoch": 22.456032088861463,
      "grad_norm": 0.001377697684802115,
      "learning_rate": 2.754396791113854e-05,
      "loss": 0.0008,
      "step": 72780
    },
    {
      "epoch": 22.45911755630978,
      "grad_norm": 0.000165996010764502,
      "learning_rate": 2.754088244369022e-05,
      "loss": 0.0003,
      "step": 72790
    },
    {
      "epoch": 22.4622030237581,
      "grad_norm": 0.003804800333455205,
      "learning_rate": 2.7537796976241902e-05,
      "loss": 0.0002,
      "step": 72800
    },
    {
      "epoch": 22.46528849120642,
      "grad_norm": 1.8337512301513925e-05,
      "learning_rate": 2.753471150879358e-05,
      "loss": 0.0,
      "step": 72810
    },
    {
      "epoch": 22.468373958654738,
      "grad_norm": 2.579384636192117e-05,
      "learning_rate": 2.7531626041345264e-05,
      "loss": 0.0058,
      "step": 72820
    },
    {
      "epoch": 22.471459426103056,
      "grad_norm": 0.002606332302093506,
      "learning_rate": 2.752854057389695e-05,
      "loss": 0.0,
      "step": 72830
    },
    {
      "epoch": 22.47454489355137,
      "grad_norm": 1.587804581504315e-05,
      "learning_rate": 2.752545510644863e-05,
      "loss": 0.0012,
      "step": 72840
    },
    {
      "epoch": 22.47763036099969,
      "grad_norm": 1.1204949259990826e-05,
      "learning_rate": 2.752236963900031e-05,
      "loss": 0.0,
      "step": 72850
    },
    {
      "epoch": 22.48071582844801,
      "grad_norm": 0.00016849087842274457,
      "learning_rate": 2.751928417155199e-05,
      "loss": 0.0099,
      "step": 72860
    },
    {
      "epoch": 22.483801295896328,
      "grad_norm": 0.020303867757320404,
      "learning_rate": 2.7516198704103673e-05,
      "loss": 0.0,
      "step": 72870
    },
    {
      "epoch": 22.486886763344646,
      "grad_norm": 0.2203240692615509,
      "learning_rate": 2.7513113236655352e-05,
      "loss": 0.0004,
      "step": 72880
    },
    {
      "epoch": 22.489972230792965,
      "grad_norm": 3.660273432615213e-05,
      "learning_rate": 2.7510027769207035e-05,
      "loss": 0.0016,
      "step": 72890
    },
    {
      "epoch": 22.493057698241284,
      "grad_norm": 0.023817691951990128,
      "learning_rate": 2.750694230175872e-05,
      "loss": 0.0,
      "step": 72900
    },
    {
      "epoch": 22.496143165689602,
      "grad_norm": 0.0023328838869929314,
      "learning_rate": 2.75038568343104e-05,
      "loss": 0.0001,
      "step": 72910
    },
    {
      "epoch": 22.49922863313792,
      "grad_norm": 4.3476866267155856e-05,
      "learning_rate": 2.7500771366862082e-05,
      "loss": 0.0002,
      "step": 72920
    },
    {
      "epoch": 22.50231410058624,
      "grad_norm": 0.0003913559194188565,
      "learning_rate": 2.749768589941376e-05,
      "loss": 0.0006,
      "step": 72930
    },
    {
      "epoch": 22.50539956803456,
      "grad_norm": 1.5862769942032173e-05,
      "learning_rate": 2.7494600431965444e-05,
      "loss": 0.0,
      "step": 72940
    },
    {
      "epoch": 22.508485035482877,
      "grad_norm": 8.399371290579438e-05,
      "learning_rate": 2.7491514964517123e-05,
      "loss": 0.0002,
      "step": 72950
    },
    {
      "epoch": 22.511570502931193,
      "grad_norm": 0.00013694787048734725,
      "learning_rate": 2.748842949706881e-05,
      "loss": 0.0004,
      "step": 72960
    },
    {
      "epoch": 22.51465597037951,
      "grad_norm": 0.072500079870224,
      "learning_rate": 2.748534402962049e-05,
      "loss": 0.0008,
      "step": 72970
    },
    {
      "epoch": 22.51774143782783,
      "grad_norm": 0.04198843985795975,
      "learning_rate": 2.748225856217217e-05,
      "loss": 0.0,
      "step": 72980
    },
    {
      "epoch": 22.52082690527615,
      "grad_norm": 0.012523910962045193,
      "learning_rate": 2.7479173094723853e-05,
      "loss": 0.0,
      "step": 72990
    },
    {
      "epoch": 22.523912372724467,
      "grad_norm": 0.0020086243748664856,
      "learning_rate": 2.7476087627275532e-05,
      "loss": 0.0005,
      "step": 73000
    },
    {
      "epoch": 22.526997840172786,
      "grad_norm": 2.958836375910323e-06,
      "learning_rate": 2.7473002159827214e-05,
      "loss": 0.0006,
      "step": 73010
    },
    {
      "epoch": 22.530083307621105,
      "grad_norm": 0.01415842492133379,
      "learning_rate": 2.7469916692378893e-05,
      "loss": 0.0004,
      "step": 73020
    },
    {
      "epoch": 22.533168775069424,
      "grad_norm": 6.83284379192628e-05,
      "learning_rate": 2.746683122493058e-05,
      "loss": 0.0,
      "step": 73030
    },
    {
      "epoch": 22.536254242517742,
      "grad_norm": 5.883403355255723e-05,
      "learning_rate": 2.746374575748226e-05,
      "loss": 0.0,
      "step": 73040
    },
    {
      "epoch": 22.53933970996606,
      "grad_norm": 0.1363973170518875,
      "learning_rate": 2.746066029003394e-05,
      "loss": 0.0003,
      "step": 73050
    },
    {
      "epoch": 22.54242517741438,
      "grad_norm": 2.0252560716471635e-05,
      "learning_rate": 2.7457574822585623e-05,
      "loss": 0.0,
      "step": 73060
    },
    {
      "epoch": 22.545510644862695,
      "grad_norm": 0.0006995942094363272,
      "learning_rate": 2.7454489355137302e-05,
      "loss": 0.0001,
      "step": 73070
    },
    {
      "epoch": 22.548596112311014,
      "grad_norm": 0.008800161071121693,
      "learning_rate": 2.7451403887688988e-05,
      "loss": 0.0,
      "step": 73080
    },
    {
      "epoch": 22.551681579759332,
      "grad_norm": 4.908635310130194e-05,
      "learning_rate": 2.7448318420240664e-05,
      "loss": 0.0002,
      "step": 73090
    },
    {
      "epoch": 22.55476704720765,
      "grad_norm": 0.019367875531315804,
      "learning_rate": 2.744523295279235e-05,
      "loss": 0.0017,
      "step": 73100
    },
    {
      "epoch": 22.55785251465597,
      "grad_norm": 0.01806105114519596,
      "learning_rate": 2.7442147485344032e-05,
      "loss": 0.0001,
      "step": 73110
    },
    {
      "epoch": 22.56093798210429,
      "grad_norm": 3.268931322963908e-05,
      "learning_rate": 2.743906201789571e-05,
      "loss": 0.0,
      "step": 73120
    },
    {
      "epoch": 22.564023449552607,
      "grad_norm": 0.020344847813248634,
      "learning_rate": 2.7435976550447394e-05,
      "loss": 0.0001,
      "step": 73130
    },
    {
      "epoch": 22.567108917000926,
      "grad_norm": 0.00046818851842544973,
      "learning_rate": 2.7432891082999073e-05,
      "loss": 0.0,
      "step": 73140
    },
    {
      "epoch": 22.570194384449245,
      "grad_norm": 0.0391647033393383,
      "learning_rate": 2.742980561555076e-05,
      "loss": 0.0027,
      "step": 73150
    },
    {
      "epoch": 22.573279851897563,
      "grad_norm": 0.01217726618051529,
      "learning_rate": 2.7426720148102434e-05,
      "loss": 0.0,
      "step": 73160
    },
    {
      "epoch": 22.576365319345882,
      "grad_norm": 9.971675171982497e-05,
      "learning_rate": 2.742363468065412e-05,
      "loss": 0.0001,
      "step": 73170
    },
    {
      "epoch": 22.5794507867942,
      "grad_norm": 0.16563604772090912,
      "learning_rate": 2.7420549213205803e-05,
      "loss": 0.0001,
      "step": 73180
    },
    {
      "epoch": 22.582536254242516,
      "grad_norm": 0.0001817372685763985,
      "learning_rate": 2.7417463745757482e-05,
      "loss": 0.0,
      "step": 73190
    },
    {
      "epoch": 22.585621721690835,
      "grad_norm": 0.002038177102804184,
      "learning_rate": 2.7414378278309168e-05,
      "loss": 0.0044,
      "step": 73200
    },
    {
      "epoch": 22.588707189139154,
      "grad_norm": 0.00017758047033566982,
      "learning_rate": 2.7411292810860843e-05,
      "loss": 0.0,
      "step": 73210
    },
    {
      "epoch": 22.591792656587472,
      "grad_norm": 0.022074351087212563,
      "learning_rate": 2.740820734341253e-05,
      "loss": 0.0,
      "step": 73220
    },
    {
      "epoch": 22.59487812403579,
      "grad_norm": 4.4222568249097094e-05,
      "learning_rate": 2.7405121875964212e-05,
      "loss": 0.0,
      "step": 73230
    },
    {
      "epoch": 22.59796359148411,
      "grad_norm": 3.1190433219308034e-05,
      "learning_rate": 2.740203640851589e-05,
      "loss": 0.0,
      "step": 73240
    },
    {
      "epoch": 22.60104905893243,
      "grad_norm": 0.00027810828760266304,
      "learning_rate": 2.7398950941067573e-05,
      "loss": 0.0024,
      "step": 73250
    },
    {
      "epoch": 22.604134526380747,
      "grad_norm": 3.8797619342803955,
      "learning_rate": 2.7395865473619252e-05,
      "loss": 0.0038,
      "step": 73260
    },
    {
      "epoch": 22.607219993829066,
      "grad_norm": 1.240060806274414,
      "learning_rate": 2.7392780006170938e-05,
      "loss": 0.0047,
      "step": 73270
    },
    {
      "epoch": 22.610305461277385,
      "grad_norm": 0.0003325005527585745,
      "learning_rate": 2.7389694538722614e-05,
      "loss": 0.0075,
      "step": 73280
    },
    {
      "epoch": 22.613390928725703,
      "grad_norm": 7.3719747888389975e-06,
      "learning_rate": 2.73866090712743e-05,
      "loss": 0.0,
      "step": 73290
    },
    {
      "epoch": 22.616476396174022,
      "grad_norm": 0.0048675620928406715,
      "learning_rate": 2.7383523603825982e-05,
      "loss": 0.0001,
      "step": 73300
    },
    {
      "epoch": 22.619561863622337,
      "grad_norm": 4.2892421333817765e-05,
      "learning_rate": 2.738043813637766e-05,
      "loss": 0.0,
      "step": 73310
    },
    {
      "epoch": 22.622647331070656,
      "grad_norm": 7.411217666231096e-06,
      "learning_rate": 2.7377352668929347e-05,
      "loss": 0.0001,
      "step": 73320
    },
    {
      "epoch": 22.625732798518975,
      "grad_norm": 0.4386974573135376,
      "learning_rate": 2.7374267201481023e-05,
      "loss": 0.0003,
      "step": 73330
    },
    {
      "epoch": 22.628818265967293,
      "grad_norm": 1.241684458364034e-05,
      "learning_rate": 2.737118173403271e-05,
      "loss": 0.0016,
      "step": 73340
    },
    {
      "epoch": 22.631903733415612,
      "grad_norm": 0.117083340883255,
      "learning_rate": 2.7368096266584388e-05,
      "loss": 0.0001,
      "step": 73350
    },
    {
      "epoch": 22.63498920086393,
      "grad_norm": 0.0008352806326001883,
      "learning_rate": 2.736501079913607e-05,
      "loss": 0.0,
      "step": 73360
    },
    {
      "epoch": 22.63807466831225,
      "grad_norm": 1.062040428223554e-05,
      "learning_rate": 2.7361925331687753e-05,
      "loss": 0.0008,
      "step": 73370
    },
    {
      "epoch": 22.64116013576057,
      "grad_norm": 0.28579971194267273,
      "learning_rate": 2.7358839864239432e-05,
      "loss": 0.0002,
      "step": 73380
    },
    {
      "epoch": 22.644245603208887,
      "grad_norm": 0.001240686746314168,
      "learning_rate": 2.7355754396791118e-05,
      "loss": 0.0,
      "step": 73390
    },
    {
      "epoch": 22.647331070657206,
      "grad_norm": 0.3009055256843567,
      "learning_rate": 2.7352668929342794e-05,
      "loss": 0.0017,
      "step": 73400
    },
    {
      "epoch": 22.650416538105524,
      "grad_norm": 5.811480718875828e-07,
      "learning_rate": 2.734958346189448e-05,
      "loss": 0.0013,
      "step": 73410
    },
    {
      "epoch": 22.65350200555384,
      "grad_norm": 0.03315546736121178,
      "learning_rate": 2.734649799444616e-05,
      "loss": 0.0001,
      "step": 73420
    },
    {
      "epoch": 22.65658747300216,
      "grad_norm": 1.4329856412587105e-06,
      "learning_rate": 2.734341252699784e-05,
      "loss": 0.0006,
      "step": 73430
    },
    {
      "epoch": 22.659672940450477,
      "grad_norm": 4.9826990107249e-06,
      "learning_rate": 2.7340327059549527e-05,
      "loss": 0.0002,
      "step": 73440
    },
    {
      "epoch": 22.662758407898796,
      "grad_norm": 0.00040813841042108834,
      "learning_rate": 2.7337241592101203e-05,
      "loss": 0.0,
      "step": 73450
    },
    {
      "epoch": 22.665843875347115,
      "grad_norm": 2.2097266992204823e-05,
      "learning_rate": 2.733415612465289e-05,
      "loss": 0.0053,
      "step": 73460
    },
    {
      "epoch": 22.668929342795433,
      "grad_norm": 0.0005295594455674291,
      "learning_rate": 2.7331070657204567e-05,
      "loss": 0.0001,
      "step": 73470
    },
    {
      "epoch": 22.672014810243752,
      "grad_norm": 7.563896815554472e-06,
      "learning_rate": 2.732798518975625e-05,
      "loss": 0.0002,
      "step": 73480
    },
    {
      "epoch": 22.67510027769207,
      "grad_norm": 0.06140463426709175,
      "learning_rate": 2.732489972230793e-05,
      "loss": 0.002,
      "step": 73490
    },
    {
      "epoch": 22.67818574514039,
      "grad_norm": 0.0006915659760124981,
      "learning_rate": 2.732181425485961e-05,
      "loss": 0.0002,
      "step": 73500
    },
    {
      "epoch": 22.681271212588708,
      "grad_norm": 0.13217060267925262,
      "learning_rate": 2.7318728787411297e-05,
      "loss": 0.0061,
      "step": 73510
    },
    {
      "epoch": 22.684356680037027,
      "grad_norm": 0.006796045694500208,
      "learning_rate": 2.7315643319962973e-05,
      "loss": 0.0025,
      "step": 73520
    },
    {
      "epoch": 22.687442147485346,
      "grad_norm": 0.00025207860744558275,
      "learning_rate": 2.731255785251466e-05,
      "loss": 0.0009,
      "step": 73530
    },
    {
      "epoch": 22.69052761493366,
      "grad_norm": 0.03850133717060089,
      "learning_rate": 2.7309472385066338e-05,
      "loss": 0.0001,
      "step": 73540
    },
    {
      "epoch": 22.69361308238198,
      "grad_norm": 4.0653840187587775e-06,
      "learning_rate": 2.730638691761802e-05,
      "loss": 0.0003,
      "step": 73550
    },
    {
      "epoch": 22.696698549830298,
      "grad_norm": 0.3026990294456482,
      "learning_rate": 2.73033014501697e-05,
      "loss": 0.0033,
      "step": 73560
    },
    {
      "epoch": 22.699784017278617,
      "grad_norm": 8.053316560108215e-05,
      "learning_rate": 2.7300215982721382e-05,
      "loss": 0.0003,
      "step": 73570
    },
    {
      "epoch": 22.702869484726936,
      "grad_norm": 0.011429010890424252,
      "learning_rate": 2.7297130515273068e-05,
      "loss": 0.0001,
      "step": 73580
    },
    {
      "epoch": 22.705954952175254,
      "grad_norm": 4.24746103817597e-05,
      "learning_rate": 2.7294045047824747e-05,
      "loss": 0.0,
      "step": 73590
    },
    {
      "epoch": 22.709040419623573,
      "grad_norm": 0.00038566256989724934,
      "learning_rate": 2.729095958037643e-05,
      "loss": 0.0,
      "step": 73600
    },
    {
      "epoch": 22.712125887071892,
      "grad_norm": 0.0014854351757094264,
      "learning_rate": 2.728787411292811e-05,
      "loss": 0.0001,
      "step": 73610
    },
    {
      "epoch": 22.71521135452021,
      "grad_norm": 0.00169721944257617,
      "learning_rate": 2.728478864547979e-05,
      "loss": 0.004,
      "step": 73620
    },
    {
      "epoch": 22.71829682196853,
      "grad_norm": 0.01589716412127018,
      "learning_rate": 2.7281703178031477e-05,
      "loss": 0.0034,
      "step": 73630
    },
    {
      "epoch": 22.721382289416848,
      "grad_norm": 0.6245870590209961,
      "learning_rate": 2.7278617710583153e-05,
      "loss": 0.0003,
      "step": 73640
    },
    {
      "epoch": 22.724467756865167,
      "grad_norm": 0.006739865988492966,
      "learning_rate": 2.727553224313484e-05,
      "loss": 0.0,
      "step": 73650
    },
    {
      "epoch": 22.727553224313482,
      "grad_norm": 2.0240548110450618e-05,
      "learning_rate": 2.7272446775686518e-05,
      "loss": 0.0,
      "step": 73660
    },
    {
      "epoch": 22.7306386917618,
      "grad_norm": 0.5060136318206787,
      "learning_rate": 2.72693613082382e-05,
      "loss": 0.0005,
      "step": 73670
    },
    {
      "epoch": 22.73372415921012,
      "grad_norm": 6.902845052536577e-05,
      "learning_rate": 2.726627584078988e-05,
      "loss": 0.0004,
      "step": 73680
    },
    {
      "epoch": 22.736809626658438,
      "grad_norm": 0.8192566633224487,
      "learning_rate": 2.726319037334156e-05,
      "loss": 0.0046,
      "step": 73690
    },
    {
      "epoch": 22.739895094106757,
      "grad_norm": 0.0008084771106950939,
      "learning_rate": 2.7260104905893247e-05,
      "loss": 0.0,
      "step": 73700
    },
    {
      "epoch": 22.742980561555076,
      "grad_norm": 0.07561878114938736,
      "learning_rate": 2.7257019438444927e-05,
      "loss": 0.0001,
      "step": 73710
    },
    {
      "epoch": 22.746066029003394,
      "grad_norm": 3.980666951974854e-05,
      "learning_rate": 2.725393397099661e-05,
      "loss": 0.0099,
      "step": 73720
    },
    {
      "epoch": 22.749151496451713,
      "grad_norm": 0.00018062096205540001,
      "learning_rate": 2.7250848503548288e-05,
      "loss": 0.0001,
      "step": 73730
    },
    {
      "epoch": 22.75223696390003,
      "grad_norm": 0.0004124788101762533,
      "learning_rate": 2.724776303609997e-05,
      "loss": 0.003,
      "step": 73740
    },
    {
      "epoch": 22.75532243134835,
      "grad_norm": 0.0059865438379347324,
      "learning_rate": 2.724467756865165e-05,
      "loss": 0.0001,
      "step": 73750
    },
    {
      "epoch": 22.75840789879667,
      "grad_norm": 3.047797008548514e-06,
      "learning_rate": 2.7241592101203332e-05,
      "loss": 0.0032,
      "step": 73760
    },
    {
      "epoch": 22.761493366244984,
      "grad_norm": 4.004000220447779e-05,
      "learning_rate": 2.7238506633755018e-05,
      "loss": 0.0022,
      "step": 73770
    },
    {
      "epoch": 22.764578833693303,
      "grad_norm": 7.114787877071649e-05,
      "learning_rate": 2.7235421166306697e-05,
      "loss": 0.0,
      "step": 73780
    },
    {
      "epoch": 22.76766430114162,
      "grad_norm": 0.00031626367126591504,
      "learning_rate": 2.723233569885838e-05,
      "loss": 0.0008,
      "step": 73790
    },
    {
      "epoch": 22.77074976858994,
      "grad_norm": 0.00037329827318899333,
      "learning_rate": 2.722925023141006e-05,
      "loss": 0.0062,
      "step": 73800
    },
    {
      "epoch": 22.77383523603826,
      "grad_norm": 0.0012370022013783455,
      "learning_rate": 2.722616476396174e-05,
      "loss": 0.0,
      "step": 73810
    },
    {
      "epoch": 22.776920703486578,
      "grad_norm": 0.00015455728862434626,
      "learning_rate": 2.722307929651342e-05,
      "loss": 0.0048,
      "step": 73820
    },
    {
      "epoch": 22.780006170934897,
      "grad_norm": 0.31896793842315674,
      "learning_rate": 2.7219993829065106e-05,
      "loss": 0.0036,
      "step": 73830
    },
    {
      "epoch": 22.783091638383215,
      "grad_norm": 0.0372505784034729,
      "learning_rate": 2.721690836161679e-05,
      "loss": 0.0002,
      "step": 73840
    },
    {
      "epoch": 22.786177105831534,
      "grad_norm": 0.008491531014442444,
      "learning_rate": 2.7213822894168468e-05,
      "loss": 0.001,
      "step": 73850
    },
    {
      "epoch": 22.789262573279853,
      "grad_norm": 0.0011000644881278276,
      "learning_rate": 2.721073742672015e-05,
      "loss": 0.0002,
      "step": 73860
    },
    {
      "epoch": 22.79234804072817,
      "grad_norm": 0.012456166557967663,
      "learning_rate": 2.720765195927183e-05,
      "loss": 0.0006,
      "step": 73870
    },
    {
      "epoch": 22.79543350817649,
      "grad_norm": 0.0019765382166951895,
      "learning_rate": 2.7204566491823512e-05,
      "loss": 0.0004,
      "step": 73880
    },
    {
      "epoch": 22.798518975624805,
      "grad_norm": 8.285584954137448e-06,
      "learning_rate": 2.720148102437519e-05,
      "loss": 0.0009,
      "step": 73890
    },
    {
      "epoch": 22.801604443073124,
      "grad_norm": 7.228534377645701e-05,
      "learning_rate": 2.7198395556926877e-05,
      "loss": 0.0012,
      "step": 73900
    },
    {
      "epoch": 22.804689910521443,
      "grad_norm": 0.0025898024905472994,
      "learning_rate": 2.719531008947856e-05,
      "loss": 0.0001,
      "step": 73910
    },
    {
      "epoch": 22.80777537796976,
      "grad_norm": 0.0007668635225854814,
      "learning_rate": 2.7192224622030238e-05,
      "loss": 0.0,
      "step": 73920
    },
    {
      "epoch": 22.81086084541808,
      "grad_norm": 5.143661975860596,
      "learning_rate": 2.718913915458192e-05,
      "loss": 0.0078,
      "step": 73930
    },
    {
      "epoch": 22.8139463128664,
      "grad_norm": 9.29775160329882e-06,
      "learning_rate": 2.71860536871336e-05,
      "loss": 0.0001,
      "step": 73940
    },
    {
      "epoch": 22.817031780314718,
      "grad_norm": 0.0003970906836912036,
      "learning_rate": 2.7182968219685286e-05,
      "loss": 0.0001,
      "step": 73950
    },
    {
      "epoch": 22.820117247763037,
      "grad_norm": 1.2336595318629406e-05,
      "learning_rate": 2.717988275223696e-05,
      "loss": 0.0005,
      "step": 73960
    },
    {
      "epoch": 22.823202715211355,
      "grad_norm": 1.8395741790300235e-05,
      "learning_rate": 2.7176797284788647e-05,
      "loss": 0.0032,
      "step": 73970
    },
    {
      "epoch": 22.826288182659674,
      "grad_norm": 4.248895168304443,
      "learning_rate": 2.717371181734033e-05,
      "loss": 0.0063,
      "step": 73980
    },
    {
      "epoch": 22.829373650107993,
      "grad_norm": 0.00032402106444351375,
      "learning_rate": 2.717062634989201e-05,
      "loss": 0.0061,
      "step": 73990
    },
    {
      "epoch": 22.83245911755631,
      "grad_norm": 0.021319352090358734,
      "learning_rate": 2.716754088244369e-05,
      "loss": 0.0006,
      "step": 74000
    },
    {
      "epoch": 22.835544585004627,
      "grad_norm": 0.0003234664327464998,
      "learning_rate": 2.716445541499537e-05,
      "loss": 0.003,
      "step": 74010
    },
    {
      "epoch": 22.838630052452945,
      "grad_norm": 0.0015756356297060847,
      "learning_rate": 2.7161369947547056e-05,
      "loss": 0.0001,
      "step": 74020
    },
    {
      "epoch": 22.841715519901264,
      "grad_norm": 0.00015918903227429837,
      "learning_rate": 2.7158284480098732e-05,
      "loss": 0.005,
      "step": 74030
    },
    {
      "epoch": 22.844800987349583,
      "grad_norm": 0.00011320942576276138,
      "learning_rate": 2.7155199012650418e-05,
      "loss": 0.0009,
      "step": 74040
    },
    {
      "epoch": 22.8478864547979,
      "grad_norm": 3.075559106946457e-06,
      "learning_rate": 2.71521135452021e-05,
      "loss": 0.0005,
      "step": 74050
    },
    {
      "epoch": 22.85097192224622,
      "grad_norm": 2.2633716071140952e-05,
      "learning_rate": 2.714902807775378e-05,
      "loss": 0.0016,
      "step": 74060
    },
    {
      "epoch": 22.85405738969454,
      "grad_norm": 1.7918207959155552e-05,
      "learning_rate": 2.7145942610305465e-05,
      "loss": 0.0034,
      "step": 74070
    },
    {
      "epoch": 22.857142857142858,
      "grad_norm": 0.15300093591213226,
      "learning_rate": 2.714285714285714e-05,
      "loss": 0.0002,
      "step": 74080
    },
    {
      "epoch": 22.860228324591176,
      "grad_norm": 0.00027917977422475815,
      "learning_rate": 2.7139771675408827e-05,
      "loss": 0.0001,
      "step": 74090
    },
    {
      "epoch": 22.863313792039495,
      "grad_norm": 0.0004740501462947577,
      "learning_rate": 2.713668620796051e-05,
      "loss": 0.0,
      "step": 74100
    },
    {
      "epoch": 22.866399259487814,
      "grad_norm": 0.005151580087840557,
      "learning_rate": 2.713360074051219e-05,
      "loss": 0.0196,
      "step": 74110
    },
    {
      "epoch": 22.86948472693613,
      "grad_norm": 0.00017014445620588958,
      "learning_rate": 2.713051527306387e-05,
      "loss": 0.0002,
      "step": 74120
    },
    {
      "epoch": 22.872570194384448,
      "grad_norm": 0.0015386726008728147,
      "learning_rate": 2.712742980561555e-05,
      "loss": 0.0022,
      "step": 74130
    },
    {
      "epoch": 22.875655661832766,
      "grad_norm": 1.793380215531215e-05,
      "learning_rate": 2.7124344338167236e-05,
      "loss": 0.0002,
      "step": 74140
    },
    {
      "epoch": 22.878741129281085,
      "grad_norm": 3.494995553410263e-06,
      "learning_rate": 2.712125887071891e-05,
      "loss": 0.0002,
      "step": 74150
    },
    {
      "epoch": 22.881826596729404,
      "grad_norm": 0.00024081699666567147,
      "learning_rate": 2.7118173403270597e-05,
      "loss": 0.0029,
      "step": 74160
    },
    {
      "epoch": 22.884912064177723,
      "grad_norm": 1.330697432422312e-05,
      "learning_rate": 2.711508793582228e-05,
      "loss": 0.0001,
      "step": 74170
    },
    {
      "epoch": 22.88799753162604,
      "grad_norm": 0.0007384364143945277,
      "learning_rate": 2.711200246837396e-05,
      "loss": 0.0,
      "step": 74180
    },
    {
      "epoch": 22.89108299907436,
      "grad_norm": 0.0015319451922550797,
      "learning_rate": 2.7108917000925645e-05,
      "loss": 0.0045,
      "step": 74190
    },
    {
      "epoch": 22.89416846652268,
      "grad_norm": 0.005133025348186493,
      "learning_rate": 2.710583153347732e-05,
      "loss": 0.0021,
      "step": 74200
    },
    {
      "epoch": 22.897253933970998,
      "grad_norm": 0.0071611301973462105,
      "learning_rate": 2.7102746066029006e-05,
      "loss": 0.0,
      "step": 74210
    },
    {
      "epoch": 22.900339401419316,
      "grad_norm": 2.3601730845257407e-06,
      "learning_rate": 2.7099660598580685e-05,
      "loss": 0.0001,
      "step": 74220
    },
    {
      "epoch": 22.903424868867635,
      "grad_norm": 0.0005875577335245907,
      "learning_rate": 2.7096575131132368e-05,
      "loss": 0.0,
      "step": 74230
    },
    {
      "epoch": 22.906510336315954,
      "grad_norm": 0.0013488399563357234,
      "learning_rate": 2.709348966368405e-05,
      "loss": 0.0002,
      "step": 74240
    },
    {
      "epoch": 22.90959580376427,
      "grad_norm": 4.6759880206082016e-05,
      "learning_rate": 2.709040419623573e-05,
      "loss": 0.0006,
      "step": 74250
    },
    {
      "epoch": 22.912681271212588,
      "grad_norm": 0.001973565900698304,
      "learning_rate": 2.7087318728787415e-05,
      "loss": 0.0001,
      "step": 74260
    },
    {
      "epoch": 22.915766738660906,
      "grad_norm": 0.0023819217458367348,
      "learning_rate": 2.708423326133909e-05,
      "loss": 0.0004,
      "step": 74270
    },
    {
      "epoch": 22.918852206109225,
      "grad_norm": 0.003320943797007203,
      "learning_rate": 2.7081147793890777e-05,
      "loss": 0.0003,
      "step": 74280
    },
    {
      "epoch": 22.921937673557544,
      "grad_norm": 0.00010406469664303586,
      "learning_rate": 2.7078062326442456e-05,
      "loss": 0.0001,
      "step": 74290
    },
    {
      "epoch": 22.925023141005862,
      "grad_norm": 0.06819511204957962,
      "learning_rate": 2.707497685899414e-05,
      "loss": 0.0001,
      "step": 74300
    },
    {
      "epoch": 22.92810860845418,
      "grad_norm": 6.051371656212723e-06,
      "learning_rate": 2.7071891391545824e-05,
      "loss": 0.0,
      "step": 74310
    },
    {
      "epoch": 22.9311940759025,
      "grad_norm": 0.02225301042199135,
      "learning_rate": 2.70688059240975e-05,
      "loss": 0.0001,
      "step": 74320
    },
    {
      "epoch": 22.93427954335082,
      "grad_norm": 0.002254176652058959,
      "learning_rate": 2.7065720456649186e-05,
      "loss": 0.0001,
      "step": 74330
    },
    {
      "epoch": 22.937365010799137,
      "grad_norm": 1.3691643476486206,
      "learning_rate": 2.7062634989200865e-05,
      "loss": 0.0008,
      "step": 74340
    },
    {
      "epoch": 22.940450478247456,
      "grad_norm": 3.551601184881292e-05,
      "learning_rate": 2.7059549521752548e-05,
      "loss": 0.0,
      "step": 74350
    },
    {
      "epoch": 22.94353594569577,
      "grad_norm": 0.013168076053261757,
      "learning_rate": 2.7056464054304227e-05,
      "loss": 0.0,
      "step": 74360
    },
    {
      "epoch": 22.94662141314409,
      "grad_norm": 6.21673780187848e-06,
      "learning_rate": 2.705337858685591e-05,
      "loss": 0.0032,
      "step": 74370
    },
    {
      "epoch": 22.94970688059241,
      "grad_norm": 0.0070929573848843575,
      "learning_rate": 2.7050293119407595e-05,
      "loss": 0.0028,
      "step": 74380
    },
    {
      "epoch": 22.952792348040727,
      "grad_norm": 0.774236798286438,
      "learning_rate": 2.704720765195927e-05,
      "loss": 0.0013,
      "step": 74390
    },
    {
      "epoch": 22.955877815489046,
      "grad_norm": 2.842563480953686e-05,
      "learning_rate": 2.7044122184510957e-05,
      "loss": 0.0003,
      "step": 74400
    },
    {
      "epoch": 22.958963282937365,
      "grad_norm": 0.012197266332805157,
      "learning_rate": 2.7041036717062636e-05,
      "loss": 0.0002,
      "step": 74410
    },
    {
      "epoch": 22.962048750385684,
      "grad_norm": 0.0003363434807397425,
      "learning_rate": 2.7037951249614318e-05,
      "loss": 0.0001,
      "step": 74420
    },
    {
      "epoch": 22.965134217834002,
      "grad_norm": 0.0014112942153587937,
      "learning_rate": 2.7034865782165997e-05,
      "loss": 0.002,
      "step": 74430
    },
    {
      "epoch": 22.96821968528232,
      "grad_norm": 0.045846957713365555,
      "learning_rate": 2.703178031471768e-05,
      "loss": 0.0006,
      "step": 74440
    },
    {
      "epoch": 22.97130515273064,
      "grad_norm": 7.988204743014649e-06,
      "learning_rate": 2.7028694847269366e-05,
      "loss": 0.0,
      "step": 74450
    },
    {
      "epoch": 22.97439062017896,
      "grad_norm": 1.6283849477767944,
      "learning_rate": 2.7025609379821045e-05,
      "loss": 0.0013,
      "step": 74460
    },
    {
      "epoch": 22.977476087627277,
      "grad_norm": 0.00021575392747763544,
      "learning_rate": 2.7022523912372727e-05,
      "loss": 0.0,
      "step": 74470
    },
    {
      "epoch": 22.980561555075592,
      "grad_norm": 0.00021047776681371033,
      "learning_rate": 2.7019438444924406e-05,
      "loss": 0.0043,
      "step": 74480
    },
    {
      "epoch": 22.98364702252391,
      "grad_norm": 0.0006948679219931364,
      "learning_rate": 2.701635297747609e-05,
      "loss": 0.0001,
      "step": 74490
    },
    {
      "epoch": 22.98673248997223,
      "grad_norm": 0.39726048707962036,
      "learning_rate": 2.7013267510027775e-05,
      "loss": 0.0006,
      "step": 74500
    },
    {
      "epoch": 22.98981795742055,
      "grad_norm": 0.2874748706817627,
      "learning_rate": 2.701018204257945e-05,
      "loss": 0.0095,
      "step": 74510
    },
    {
      "epoch": 22.992903424868867,
      "grad_norm": 0.000734450644813478,
      "learning_rate": 2.7007096575131136e-05,
      "loss": 0.0,
      "step": 74520
    },
    {
      "epoch": 22.995988892317186,
      "grad_norm": 0.09117773175239563,
      "learning_rate": 2.7004011107682815e-05,
      "loss": 0.0001,
      "step": 74530
    },
    {
      "epoch": 22.999074359765505,
      "grad_norm": 0.042720016092061996,
      "learning_rate": 2.7000925640234498e-05,
      "loss": 0.0004,
      "step": 74540
    },
    {
      "epoch": 23.0,
      "eval_accuracy_branch1": 0.9997974595642487,
      "eval_accuracy_branch2": 0.4734238013946356,
      "eval_f1_branch1": 0.9997297621445135,
      "eval_f1_branch2": 0.47198091185029484,
      "eval_loss": 0.00019362159946467727,
      "eval_precision_branch1": 0.9997346425772622,
      "eval_precision_branch2": 0.5121926374809517,
      "eval_recall_branch1": 0.9997251680032266,
      "eval_recall_branch2": 0.5129987558230376,
      "eval_runtime": 239.4287,
      "eval_samples_per_second": 433.043,
      "eval_steps_per_second": 54.133,
      "step": 74543
    },
    {
      "epoch": 23.002159827213823,
      "grad_norm": 0.0004629064060281962,
      "learning_rate": 2.6997840172786177e-05,
      "loss": 0.1061,
      "step": 74550
    },
    {
      "epoch": 23.005245294662142,
      "grad_norm": 0.00444794399663806,
      "learning_rate": 2.699475470533786e-05,
      "loss": 0.0016,
      "step": 74560
    },
    {
      "epoch": 23.00833076211046,
      "grad_norm": 5.296117524267174e-05,
      "learning_rate": 2.6991669237889545e-05,
      "loss": 0.0,
      "step": 74570
    },
    {
      "epoch": 23.01141622955878,
      "grad_norm": 0.0005645962082780898,
      "learning_rate": 2.6988583770441224e-05,
      "loss": 0.0002,
      "step": 74580
    },
    {
      "epoch": 23.014501697007095,
      "grad_norm": 0.004746702499687672,
      "learning_rate": 2.6985498302992907e-05,
      "loss": 0.003,
      "step": 74590
    },
    {
      "epoch": 23.017587164455414,
      "grad_norm": 0.015463420189917088,
      "learning_rate": 2.6982412835544586e-05,
      "loss": 0.0,
      "step": 74600
    },
    {
      "epoch": 23.020672631903732,
      "grad_norm": 0.0008575125248171389,
      "learning_rate": 2.6979327368096268e-05,
      "loss": 0.0,
      "step": 74610
    },
    {
      "epoch": 23.02375809935205,
      "grad_norm": 0.00020705464703496546,
      "learning_rate": 2.6976241900647947e-05,
      "loss": 0.0,
      "step": 74620
    },
    {
      "epoch": 23.02684356680037,
      "grad_norm": 5.713239443139173e-05,
      "learning_rate": 2.697315643319963e-05,
      "loss": 0.0007,
      "step": 74630
    },
    {
      "epoch": 23.02992903424869,
      "grad_norm": 7.588638982269913e-05,
      "learning_rate": 2.6970070965751316e-05,
      "loss": 0.0,
      "step": 74640
    },
    {
      "epoch": 23.033014501697007,
      "grad_norm": 0.018696513026952744,
      "learning_rate": 2.6966985498302995e-05,
      "loss": 0.0,
      "step": 74650
    },
    {
      "epoch": 23.036099969145326,
      "grad_norm": 0.006478011608123779,
      "learning_rate": 2.6963900030854677e-05,
      "loss": 0.0005,
      "step": 74660
    },
    {
      "epoch": 23.039185436593645,
      "grad_norm": 0.00014927340089343488,
      "learning_rate": 2.6960814563406356e-05,
      "loss": 0.0021,
      "step": 74670
    },
    {
      "epoch": 23.042270904041963,
      "grad_norm": 0.008639567531645298,
      "learning_rate": 2.695772909595804e-05,
      "loss": 0.0001,
      "step": 74680
    },
    {
      "epoch": 23.045356371490282,
      "grad_norm": 0.0009235065663233399,
      "learning_rate": 2.6954643628509718e-05,
      "loss": 0.0016,
      "step": 74690
    },
    {
      "epoch": 23.0484418389386,
      "grad_norm": 0.00019025466463062912,
      "learning_rate": 2.6951558161061404e-05,
      "loss": 0.0003,
      "step": 74700
    },
    {
      "epoch": 23.051527306386916,
      "grad_norm": 0.003050697036087513,
      "learning_rate": 2.6948472693613086e-05,
      "loss": 0.0,
      "step": 74710
    },
    {
      "epoch": 23.054612773835235,
      "grad_norm": 0.0009607966640032828,
      "learning_rate": 2.6945387226164765e-05,
      "loss": 0.0001,
      "step": 74720
    },
    {
      "epoch": 23.057698241283553,
      "grad_norm": 0.001772568211890757,
      "learning_rate": 2.6942301758716448e-05,
      "loss": 0.0057,
      "step": 74730
    },
    {
      "epoch": 23.060783708731872,
      "grad_norm": 0.04181945323944092,
      "learning_rate": 2.6939216291268127e-05,
      "loss": 0.0002,
      "step": 74740
    },
    {
      "epoch": 23.06386917618019,
      "grad_norm": 9.72169164015213e-06,
      "learning_rate": 2.693613082381981e-05,
      "loss": 0.0011,
      "step": 74750
    },
    {
      "epoch": 23.06695464362851,
      "grad_norm": 0.0016449170652776957,
      "learning_rate": 2.693304535637149e-05,
      "loss": 0.0037,
      "step": 74760
    },
    {
      "epoch": 23.07004011107683,
      "grad_norm": 0.195356085896492,
      "learning_rate": 2.6929959888923174e-05,
      "loss": 0.0004,
      "step": 74770
    },
    {
      "epoch": 23.073125578525147,
      "grad_norm": 1.1639046669006348,
      "learning_rate": 2.6926874421474857e-05,
      "loss": 0.001,
      "step": 74780
    },
    {
      "epoch": 23.076211045973466,
      "grad_norm": 0.0033510939683765173,
      "learning_rate": 2.6923788954026536e-05,
      "loss": 0.0001,
      "step": 74790
    },
    {
      "epoch": 23.079296513421784,
      "grad_norm": 0.0001410303229931742,
      "learning_rate": 2.692070348657822e-05,
      "loss": 0.0019,
      "step": 74800
    },
    {
      "epoch": 23.082381980870103,
      "grad_norm": 0.002175775123760104,
      "learning_rate": 2.6917618019129897e-05,
      "loss": 0.0001,
      "step": 74810
    },
    {
      "epoch": 23.085467448318422,
      "grad_norm": 2.557105517553282e-06,
      "learning_rate": 2.6914532551681583e-05,
      "loss": 0.0001,
      "step": 74820
    },
    {
      "epoch": 23.088552915766737,
      "grad_norm": 0.0006605774979107082,
      "learning_rate": 2.691144708423326e-05,
      "loss": 0.0001,
      "step": 74830
    },
    {
      "epoch": 23.091638383215056,
      "grad_norm": 2.9119688406353816e-05,
      "learning_rate": 2.6908361616784945e-05,
      "loss": 0.0005,
      "step": 74840
    },
    {
      "epoch": 23.094723850663375,
      "grad_norm": 0.6551048755645752,
      "learning_rate": 2.6905276149336627e-05,
      "loss": 0.0004,
      "step": 74850
    },
    {
      "epoch": 23.097809318111693,
      "grad_norm": 0.0015511581441387534,
      "learning_rate": 2.6902190681888306e-05,
      "loss": 0.0006,
      "step": 74860
    },
    {
      "epoch": 23.100894785560012,
      "grad_norm": 0.015679681673645973,
      "learning_rate": 2.689910521443999e-05,
      "loss": 0.0,
      "step": 74870
    },
    {
      "epoch": 23.10398025300833,
      "grad_norm": 5.309288462740369e-05,
      "learning_rate": 2.6896019746991668e-05,
      "loss": 0.0002,
      "step": 74880
    },
    {
      "epoch": 23.10706572045665,
      "grad_norm": 0.4587904214859009,
      "learning_rate": 2.6892934279543354e-05,
      "loss": 0.0022,
      "step": 74890
    },
    {
      "epoch": 23.110151187904968,
      "grad_norm": 0.0015643403166905046,
      "learning_rate": 2.688984881209503e-05,
      "loss": 0.0007,
      "step": 74900
    },
    {
      "epoch": 23.113236655353287,
      "grad_norm": 0.0003250357403885573,
      "learning_rate": 2.6886763344646715e-05,
      "loss": 0.0012,
      "step": 74910
    },
    {
      "epoch": 23.116322122801606,
      "grad_norm": 1.3627004623413086,
      "learning_rate": 2.6883677877198398e-05,
      "loss": 0.002,
      "step": 74920
    },
    {
      "epoch": 23.119407590249924,
      "grad_norm": 0.0028897009324282408,
      "learning_rate": 2.6880592409750077e-05,
      "loss": 0.0029,
      "step": 74930
    },
    {
      "epoch": 23.122493057698243,
      "grad_norm": 2.7249924983152596e-07,
      "learning_rate": 2.6877506942301763e-05,
      "loss": 0.0,
      "step": 74940
    },
    {
      "epoch": 23.125578525146558,
      "grad_norm": 3.2464965897816e-06,
      "learning_rate": 2.687442147485344e-05,
      "loss": 0.0,
      "step": 74950
    },
    {
      "epoch": 23.128663992594877,
      "grad_norm": 0.0019044014625251293,
      "learning_rate": 2.6871336007405124e-05,
      "loss": 0.0034,
      "step": 74960
    },
    {
      "epoch": 23.131749460043196,
      "grad_norm": 0.09236499667167664,
      "learning_rate": 2.6868250539956807e-05,
      "loss": 0.0035,
      "step": 74970
    },
    {
      "epoch": 23.134834927491514,
      "grad_norm": 0.0002758974442258477,
      "learning_rate": 2.6865165072508486e-05,
      "loss": 0.0005,
      "step": 74980
    },
    {
      "epoch": 23.137920394939833,
      "grad_norm": 0.00017988411127589643,
      "learning_rate": 2.686207960506017e-05,
      "loss": 0.001,
      "step": 74990
    },
    {
      "epoch": 23.141005862388152,
      "grad_norm": 0.0045646182261407375,
      "learning_rate": 2.6858994137611848e-05,
      "loss": 0.008,
      "step": 75000
    },
    {
      "epoch": 23.14409132983647,
      "grad_norm": 0.0004526394768618047,
      "learning_rate": 2.6855908670163533e-05,
      "loss": 0.0,
      "step": 75010
    },
    {
      "epoch": 23.14717679728479,
      "grad_norm": 0.010605624876916409,
      "learning_rate": 2.685282320271521e-05,
      "loss": 0.0003,
      "step": 75020
    },
    {
      "epoch": 23.150262264733108,
      "grad_norm": 0.007515003904700279,
      "learning_rate": 2.6849737735266895e-05,
      "loss": 0.0001,
      "step": 75030
    },
    {
      "epoch": 23.153347732181427,
      "grad_norm": 0.0347701758146286,
      "learning_rate": 2.6846652267818577e-05,
      "loss": 0.0005,
      "step": 75040
    },
    {
      "epoch": 23.156433199629745,
      "grad_norm": 0.0005976707325316966,
      "learning_rate": 2.6843566800370257e-05,
      "loss": 0.0001,
      "step": 75050
    },
    {
      "epoch": 23.15951866707806,
      "grad_norm": 1.5726833225926384e-05,
      "learning_rate": 2.684048133292194e-05,
      "loss": 0.0003,
      "step": 75060
    },
    {
      "epoch": 23.16260413452638,
      "grad_norm": 0.6345023512840271,
      "learning_rate": 2.6837395865473618e-05,
      "loss": 0.0011,
      "step": 75070
    },
    {
      "epoch": 23.165689601974698,
      "grad_norm": 3.980704059358686e-05,
      "learning_rate": 2.6834310398025304e-05,
      "loss": 0.0004,
      "step": 75080
    },
    {
      "epoch": 23.168775069423017,
      "grad_norm": 0.000503824558109045,
      "learning_rate": 2.6831224930576983e-05,
      "loss": 0.0001,
      "step": 75090
    },
    {
      "epoch": 23.171860536871336,
      "grad_norm": 0.0026574924122542143,
      "learning_rate": 2.6828139463128666e-05,
      "loss": 0.0012,
      "step": 75100
    },
    {
      "epoch": 23.174946004319654,
      "grad_norm": 2.2712636109645246e-06,
      "learning_rate": 2.6825053995680348e-05,
      "loss": 0.0,
      "step": 75110
    },
    {
      "epoch": 23.178031471767973,
      "grad_norm": 0.11614705622196198,
      "learning_rate": 2.6821968528232027e-05,
      "loss": 0.0072,
      "step": 75120
    },
    {
      "epoch": 23.18111693921629,
      "grad_norm": 0.04441462457180023,
      "learning_rate": 2.6818883060783713e-05,
      "loss": 0.0001,
      "step": 75130
    },
    {
      "epoch": 23.18420240666461,
      "grad_norm": 0.1760019212961197,
      "learning_rate": 2.681579759333539e-05,
      "loss": 0.0001,
      "step": 75140
    },
    {
      "epoch": 23.18728787411293,
      "grad_norm": 0.0035672090016305447,
      "learning_rate": 2.6812712125887075e-05,
      "loss": 0.0019,
      "step": 75150
    },
    {
      "epoch": 23.190373341561248,
      "grad_norm": 0.04505026340484619,
      "learning_rate": 2.6809626658438754e-05,
      "loss": 0.0001,
      "step": 75160
    },
    {
      "epoch": 23.193458809009567,
      "grad_norm": 7.1234526330954395e-06,
      "learning_rate": 2.6806541190990436e-05,
      "loss": 0.0,
      "step": 75170
    },
    {
      "epoch": 23.19654427645788,
      "grad_norm": 3.474546194076538,
      "learning_rate": 2.680345572354212e-05,
      "loss": 0.0019,
      "step": 75180
    },
    {
      "epoch": 23.1996297439062,
      "grad_norm": 0.00010757471318356693,
      "learning_rate": 2.6800370256093798e-05,
      "loss": 0.0,
      "step": 75190
    },
    {
      "epoch": 23.20271521135452,
      "grad_norm": 0.0003315859939903021,
      "learning_rate": 2.6797284788645484e-05,
      "loss": 0.0001,
      "step": 75200
    },
    {
      "epoch": 23.205800678802838,
      "grad_norm": 1.326581696048379e-05,
      "learning_rate": 2.6794199321197163e-05,
      "loss": 0.0,
      "step": 75210
    },
    {
      "epoch": 23.208886146251157,
      "grad_norm": 0.0029129129834473133,
      "learning_rate": 2.6791113853748845e-05,
      "loss": 0.0,
      "step": 75220
    },
    {
      "epoch": 23.211971613699475,
      "grad_norm": 5.678443358192453e-06,
      "learning_rate": 2.6788028386300524e-05,
      "loss": 0.0001,
      "step": 75230
    },
    {
      "epoch": 23.215057081147794,
      "grad_norm": 0.005117079243063927,
      "learning_rate": 2.6784942918852207e-05,
      "loss": 0.0001,
      "step": 75240
    },
    {
      "epoch": 23.218142548596113,
      "grad_norm": 1.379682362312451e-05,
      "learning_rate": 2.6781857451403893e-05,
      "loss": 0.0076,
      "step": 75250
    },
    {
      "epoch": 23.22122801604443,
      "grad_norm": 0.0016921362839639187,
      "learning_rate": 2.6778771983955568e-05,
      "loss": 0.0001,
      "step": 75260
    },
    {
      "epoch": 23.22431348349275,
      "grad_norm": 0.001879984512925148,
      "learning_rate": 2.6775686516507254e-05,
      "loss": 0.0022,
      "step": 75270
    },
    {
      "epoch": 23.22739895094107,
      "grad_norm": 0.00046632616431452334,
      "learning_rate": 2.6772601049058933e-05,
      "loss": 0.0,
      "step": 75280
    },
    {
      "epoch": 23.230484418389388,
      "grad_norm": 0.00018323847325518727,
      "learning_rate": 2.6769515581610616e-05,
      "loss": 0.0,
      "step": 75290
    },
    {
      "epoch": 23.233569885837703,
      "grad_norm": 6.609742285945686e-06,
      "learning_rate": 2.6766430114162295e-05,
      "loss": 0.0094,
      "step": 75300
    },
    {
      "epoch": 23.23665535328602,
      "grad_norm": 4.3785737943835557e-05,
      "learning_rate": 2.6763344646713977e-05,
      "loss": 0.0003,
      "step": 75310
    },
    {
      "epoch": 23.23974082073434,
      "grad_norm": 0.00023289684031624347,
      "learning_rate": 2.6760259179265663e-05,
      "loss": 0.0003,
      "step": 75320
    },
    {
      "epoch": 23.24282628818266,
      "grad_norm": 8.151154906954616e-05,
      "learning_rate": 2.675717371181734e-05,
      "loss": 0.0001,
      "step": 75330
    },
    {
      "epoch": 23.245911755630978,
      "grad_norm": 9.79761443886673e-06,
      "learning_rate": 2.6754088244369025e-05,
      "loss": 0.0014,
      "step": 75340
    },
    {
      "epoch": 23.248997223079297,
      "grad_norm": 2.0023767319798935e-06,
      "learning_rate": 2.6751002776920704e-05,
      "loss": 0.0,
      "step": 75350
    },
    {
      "epoch": 23.252082690527615,
      "grad_norm": 0.00039244405343197286,
      "learning_rate": 2.6747917309472386e-05,
      "loss": 0.0,
      "step": 75360
    },
    {
      "epoch": 23.255168157975934,
      "grad_norm": 0.0015989859821274877,
      "learning_rate": 2.6744831842024072e-05,
      "loss": 0.0001,
      "step": 75370
    },
    {
      "epoch": 23.258253625424253,
      "grad_norm": 0.00910109095275402,
      "learning_rate": 2.6741746374575748e-05,
      "loss": 0.0,
      "step": 75380
    },
    {
      "epoch": 23.26133909287257,
      "grad_norm": 0.00025719506083987653,
      "learning_rate": 2.6738660907127434e-05,
      "loss": 0.0,
      "step": 75390
    },
    {
      "epoch": 23.26442456032089,
      "grad_norm": 1.249341858056141e-05,
      "learning_rate": 2.6735575439679113e-05,
      "loss": 0.0014,
      "step": 75400
    },
    {
      "epoch": 23.267510027769205,
      "grad_norm": 0.0003437022678554058,
      "learning_rate": 2.6732489972230795e-05,
      "loss": 0.0007,
      "step": 75410
    },
    {
      "epoch": 23.270595495217524,
      "grad_norm": 2.2735708625987172e-05,
      "learning_rate": 2.6729404504782474e-05,
      "loss": 0.0,
      "step": 75420
    },
    {
      "epoch": 23.273680962665843,
      "grad_norm": 0.00029588682809844613,
      "learning_rate": 2.6726319037334157e-05,
      "loss": 0.0002,
      "step": 75430
    },
    {
      "epoch": 23.27676643011416,
      "grad_norm": 0.0003532330447342247,
      "learning_rate": 2.6723233569885843e-05,
      "loss": 0.0022,
      "step": 75440
    },
    {
      "epoch": 23.27985189756248,
      "grad_norm": 0.31184840202331543,
      "learning_rate": 2.672014810243752e-05,
      "loss": 0.0003,
      "step": 75450
    },
    {
      "epoch": 23.2829373650108,
      "grad_norm": 1.4509391784667969,
      "learning_rate": 2.6717062634989204e-05,
      "loss": 0.0008,
      "step": 75460
    },
    {
      "epoch": 23.286022832459118,
      "grad_norm": 1.5814599464647472e-05,
      "learning_rate": 2.6713977167540883e-05,
      "loss": 0.001,
      "step": 75470
    },
    {
      "epoch": 23.289108299907436,
      "grad_norm": 5.845318810315803e-05,
      "learning_rate": 2.6710891700092566e-05,
      "loss": 0.0001,
      "step": 75480
    },
    {
      "epoch": 23.292193767355755,
      "grad_norm": 0.0034567054826766253,
      "learning_rate": 2.6707806232644245e-05,
      "loss": 0.0,
      "step": 75490
    },
    {
      "epoch": 23.295279234804074,
      "grad_norm": 0.0025552960578352213,
      "learning_rate": 2.6704720765195927e-05,
      "loss": 0.0,
      "step": 75500
    },
    {
      "epoch": 23.298364702252393,
      "grad_norm": 0.005856464151293039,
      "learning_rate": 2.6701635297747613e-05,
      "loss": 0.0006,
      "step": 75510
    },
    {
      "epoch": 23.30145016970071,
      "grad_norm": 0.0021685175597667694,
      "learning_rate": 2.6698549830299292e-05,
      "loss": 0.0005,
      "step": 75520
    },
    {
      "epoch": 23.304535637149026,
      "grad_norm": 0.0001569310697959736,
      "learning_rate": 2.6695464362850975e-05,
      "loss": 0.0002,
      "step": 75530
    },
    {
      "epoch": 23.307621104597345,
      "grad_norm": 0.022707678377628326,
      "learning_rate": 2.6692378895402654e-05,
      "loss": 0.0031,
      "step": 75540
    },
    {
      "epoch": 23.310706572045664,
      "grad_norm": 0.010282018221914768,
      "learning_rate": 2.6689293427954336e-05,
      "loss": 0.0008,
      "step": 75550
    },
    {
      "epoch": 23.313792039493983,
      "grad_norm": 0.0007742407033219934,
      "learning_rate": 2.6686207960506015e-05,
      "loss": 0.0,
      "step": 75560
    },
    {
      "epoch": 23.3168775069423,
      "grad_norm": 0.06254513561725616,
      "learning_rate": 2.6683122493057698e-05,
      "loss": 0.0012,
      "step": 75570
    },
    {
      "epoch": 23.31996297439062,
      "grad_norm": 0.00015028777124825865,
      "learning_rate": 2.6680037025609384e-05,
      "loss": 0.0,
      "step": 75580
    },
    {
      "epoch": 23.32304844183894,
      "grad_norm": 2.9108804255884024e-07,
      "learning_rate": 2.6676951558161063e-05,
      "loss": 0.0004,
      "step": 75590
    },
    {
      "epoch": 23.326133909287257,
      "grad_norm": 2.258939275634475e-05,
      "learning_rate": 2.6673866090712745e-05,
      "loss": 0.0001,
      "step": 75600
    },
    {
      "epoch": 23.329219376735576,
      "grad_norm": 0.00032097010989673436,
      "learning_rate": 2.6670780623264424e-05,
      "loss": 0.0013,
      "step": 75610
    },
    {
      "epoch": 23.332304844183895,
      "grad_norm": 1.6957447528839111,
      "learning_rate": 2.6667695155816107e-05,
      "loss": 0.0011,
      "step": 75620
    },
    {
      "epoch": 23.335390311632214,
      "grad_norm": 8.128731133183464e-05,
      "learning_rate": 2.6664609688367786e-05,
      "loss": 0.0,
      "step": 75630
    },
    {
      "epoch": 23.338475779080532,
      "grad_norm": 0.02135203219950199,
      "learning_rate": 2.6661524220919472e-05,
      "loss": 0.0001,
      "step": 75640
    },
    {
      "epoch": 23.341561246528848,
      "grad_norm": 0.9645313024520874,
      "learning_rate": 2.6658438753471154e-05,
      "loss": 0.0029,
      "step": 75650
    },
    {
      "epoch": 23.344646713977166,
      "grad_norm": 0.04466862976551056,
      "learning_rate": 2.6655353286022833e-05,
      "loss": 0.0001,
      "step": 75660
    },
    {
      "epoch": 23.347732181425485,
      "grad_norm": 2.158190965652466,
      "learning_rate": 2.6652267818574516e-05,
      "loss": 0.0107,
      "step": 75670
    },
    {
      "epoch": 23.350817648873804,
      "grad_norm": 0.0015740040689706802,
      "learning_rate": 2.6649182351126195e-05,
      "loss": 0.0033,
      "step": 75680
    },
    {
      "epoch": 23.353903116322122,
      "grad_norm": 0.0003376459644641727,
      "learning_rate": 2.6646096883677877e-05,
      "loss": 0.0008,
      "step": 75690
    },
    {
      "epoch": 23.35698858377044,
      "grad_norm": 0.0008906836737878621,
      "learning_rate": 2.6643011416229557e-05,
      "loss": 0.0001,
      "step": 75700
    },
    {
      "epoch": 23.36007405121876,
      "grad_norm": 1.396730021951953e-05,
      "learning_rate": 2.6639925948781242e-05,
      "loss": 0.0004,
      "step": 75710
    },
    {
      "epoch": 23.36315951866708,
      "grad_norm": 0.0021547682117670774,
      "learning_rate": 2.6636840481332925e-05,
      "loss": 0.0002,
      "step": 75720
    },
    {
      "epoch": 23.366244986115397,
      "grad_norm": 3.514277341309935e-05,
      "learning_rate": 2.6633755013884604e-05,
      "loss": 0.0031,
      "step": 75730
    },
    {
      "epoch": 23.369330453563716,
      "grad_norm": 0.00040853876271285117,
      "learning_rate": 2.6630669546436286e-05,
      "loss": 0.0004,
      "step": 75740
    },
    {
      "epoch": 23.372415921012035,
      "grad_norm": 0.06038760393857956,
      "learning_rate": 2.6627584078987966e-05,
      "loss": 0.0,
      "step": 75750
    },
    {
      "epoch": 23.37550138846035,
      "grad_norm": 1.4888255596160889,
      "learning_rate": 2.662449861153965e-05,
      "loss": 0.0012,
      "step": 75760
    },
    {
      "epoch": 23.37858685590867,
      "grad_norm": 0.0014461566461250186,
      "learning_rate": 2.6621413144091327e-05,
      "loss": 0.0,
      "step": 75770
    },
    {
      "epoch": 23.381672323356987,
      "grad_norm": 0.001153674558736384,
      "learning_rate": 2.6618327676643013e-05,
      "loss": 0.0002,
      "step": 75780
    },
    {
      "epoch": 23.384757790805306,
      "grad_norm": 0.0011452166363596916,
      "learning_rate": 2.6615242209194695e-05,
      "loss": 0.0017,
      "step": 75790
    },
    {
      "epoch": 23.387843258253625,
      "grad_norm": 1.1181426048278809,
      "learning_rate": 2.6612156741746375e-05,
      "loss": 0.001,
      "step": 75800
    },
    {
      "epoch": 23.390928725701944,
      "grad_norm": 0.0005509605398401618,
      "learning_rate": 2.6609071274298057e-05,
      "loss": 0.0027,
      "step": 75810
    },
    {
      "epoch": 23.394014193150262,
      "grad_norm": 0.0006612755823880434,
      "learning_rate": 2.6605985806849736e-05,
      "loss": 0.0001,
      "step": 75820
    },
    {
      "epoch": 23.39709966059858,
      "grad_norm": 7.948048619255133e-08,
      "learning_rate": 2.6602900339401422e-05,
      "loss": 0.0001,
      "step": 75830
    },
    {
      "epoch": 23.4001851280469,
      "grad_norm": 0.0006515198037959635,
      "learning_rate": 2.6599814871953104e-05,
      "loss": 0.0001,
      "step": 75840
    },
    {
      "epoch": 23.40327059549522,
      "grad_norm": 0.0003172077995259315,
      "learning_rate": 2.6596729404504784e-05,
      "loss": 0.0005,
      "step": 75850
    },
    {
      "epoch": 23.406356062943537,
      "grad_norm": 0.009985568933188915,
      "learning_rate": 2.6593643937056466e-05,
      "loss": 0.0002,
      "step": 75860
    },
    {
      "epoch": 23.409441530391856,
      "grad_norm": 0.010214924812316895,
      "learning_rate": 2.6590558469608145e-05,
      "loss": 0.0016,
      "step": 75870
    },
    {
      "epoch": 23.41252699784017,
      "grad_norm": 2.0732431948999874e-05,
      "learning_rate": 2.658747300215983e-05,
      "loss": 0.0015,
      "step": 75880
    },
    {
      "epoch": 23.41561246528849,
      "grad_norm": 1.3445413969748188e-05,
      "learning_rate": 2.6584387534711507e-05,
      "loss": 0.0002,
      "step": 75890
    },
    {
      "epoch": 23.41869793273681,
      "grad_norm": 0.015038947574794292,
      "learning_rate": 2.6581302067263193e-05,
      "loss": 0.0009,
      "step": 75900
    },
    {
      "epoch": 23.421783400185127,
      "grad_norm": 6.956941797398031e-05,
      "learning_rate": 2.6578216599814875e-05,
      "loss": 0.0001,
      "step": 75910
    },
    {
      "epoch": 23.424868867633446,
      "grad_norm": 0.002759055234491825,
      "learning_rate": 2.6575131132366554e-05,
      "loss": 0.0031,
      "step": 75920
    },
    {
      "epoch": 23.427954335081765,
      "grad_norm": 6.924705758137861e-06,
      "learning_rate": 2.6572045664918237e-05,
      "loss": 0.0001,
      "step": 75930
    },
    {
      "epoch": 23.431039802530083,
      "grad_norm": 0.006411322392523289,
      "learning_rate": 2.6568960197469916e-05,
      "loss": 0.0041,
      "step": 75940
    },
    {
      "epoch": 23.434125269978402,
      "grad_norm": 0.0010765308979898691,
      "learning_rate": 2.65658747300216e-05,
      "loss": 0.0,
      "step": 75950
    },
    {
      "epoch": 23.43721073742672,
      "grad_norm": 7.723359885858372e-05,
      "learning_rate": 2.6562789262573277e-05,
      "loss": 0.0002,
      "step": 75960
    },
    {
      "epoch": 23.44029620487504,
      "grad_norm": 3.793164432863705e-05,
      "learning_rate": 2.6559703795124963e-05,
      "loss": 0.0001,
      "step": 75970
    },
    {
      "epoch": 23.44338167232336,
      "grad_norm": 0.002548849442973733,
      "learning_rate": 2.6556618327676646e-05,
      "loss": 0.0003,
      "step": 75980
    },
    {
      "epoch": 23.446467139771677,
      "grad_norm": 0.0003144037036690861,
      "learning_rate": 2.6553532860228325e-05,
      "loss": 0.0,
      "step": 75990
    },
    {
      "epoch": 23.449552607219992,
      "grad_norm": 0.008319426327943802,
      "learning_rate": 2.655044739278001e-05,
      "loss": 0.0,
      "step": 76000
    },
    {
      "epoch": 23.45263807466831,
      "grad_norm": 0.0006750005413778126,
      "learning_rate": 2.6547361925331686e-05,
      "loss": 0.0,
      "step": 76010
    },
    {
      "epoch": 23.45572354211663,
      "grad_norm": 1.0249501428916119e-05,
      "learning_rate": 2.6544276457883372e-05,
      "loss": 0.0001,
      "step": 76020
    },
    {
      "epoch": 23.45880900956495,
      "grad_norm": 0.0017311573028564453,
      "learning_rate": 2.654119099043505e-05,
      "loss": 0.0,
      "step": 76030
    },
    {
      "epoch": 23.461894477013267,
      "grad_norm": 2.0795145246665925e-05,
      "learning_rate": 2.6538105522986734e-05,
      "loss": 0.0003,
      "step": 76040
    },
    {
      "epoch": 23.464979944461586,
      "grad_norm": 0.12613114714622498,
      "learning_rate": 2.6535020055538416e-05,
      "loss": 0.0001,
      "step": 76050
    },
    {
      "epoch": 23.468065411909905,
      "grad_norm": 5.5928358051460236e-05,
      "learning_rate": 2.6531934588090095e-05,
      "loss": 0.0003,
      "step": 76060
    },
    {
      "epoch": 23.471150879358223,
      "grad_norm": 0.0014599018031731248,
      "learning_rate": 2.652884912064178e-05,
      "loss": 0.0,
      "step": 76070
    },
    {
      "epoch": 23.474236346806542,
      "grad_norm": 0.00019663716375362128,
      "learning_rate": 2.6525763653193457e-05,
      "loss": 0.0002,
      "step": 76080
    },
    {
      "epoch": 23.47732181425486,
      "grad_norm": 0.00011486199946375564,
      "learning_rate": 2.6522678185745143e-05,
      "loss": 0.0,
      "step": 76090
    },
    {
      "epoch": 23.48040728170318,
      "grad_norm": 4.7546061978209764e-05,
      "learning_rate": 2.6519592718296822e-05,
      "loss": 0.0,
      "step": 76100
    },
    {
      "epoch": 23.483492749151495,
      "grad_norm": 8.082966087386012e-05,
      "learning_rate": 2.6516507250848504e-05,
      "loss": 0.0001,
      "step": 76110
    },
    {
      "epoch": 23.486578216599813,
      "grad_norm": 0.0012444041203707457,
      "learning_rate": 2.651342178340019e-05,
      "loss": 0.0,
      "step": 76120
    },
    {
      "epoch": 23.489663684048132,
      "grad_norm": 0.02124839648604393,
      "learning_rate": 2.6510336315951866e-05,
      "loss": 0.0,
      "step": 76130
    },
    {
      "epoch": 23.49274915149645,
      "grad_norm": 0.004339615348726511,
      "learning_rate": 2.650725084850355e-05,
      "loss": 0.0001,
      "step": 76140
    },
    {
      "epoch": 23.49583461894477,
      "grad_norm": 1.4042359907762147e-05,
      "learning_rate": 2.650416538105523e-05,
      "loss": 0.0,
      "step": 76150
    },
    {
      "epoch": 23.49892008639309,
      "grad_norm": 0.03877435624599457,
      "learning_rate": 2.6501079913606913e-05,
      "loss": 0.0,
      "step": 76160
    },
    {
      "epoch": 23.502005553841407,
      "grad_norm": 7.49096943764016e-05,
      "learning_rate": 2.6497994446158592e-05,
      "loss": 0.0,
      "step": 76170
    },
    {
      "epoch": 23.505091021289726,
      "grad_norm": 0.019030405208468437,
      "learning_rate": 2.6494908978710275e-05,
      "loss": 0.0,
      "step": 76180
    },
    {
      "epoch": 23.508176488738044,
      "grad_norm": 0.0010185691062361002,
      "learning_rate": 2.649182351126196e-05,
      "loss": 0.0,
      "step": 76190
    },
    {
      "epoch": 23.511261956186363,
      "grad_norm": 1.5179113688645884e-05,
      "learning_rate": 2.6488738043813636e-05,
      "loss": 0.0,
      "step": 76200
    },
    {
      "epoch": 23.514347423634682,
      "grad_norm": 1.1192119018232916e-05,
      "learning_rate": 2.6485652576365322e-05,
      "loss": 0.0,
      "step": 76210
    },
    {
      "epoch": 23.517432891083,
      "grad_norm": 0.00046241938252933323,
      "learning_rate": 2.6482567108917e-05,
      "loss": 0.0,
      "step": 76220
    },
    {
      "epoch": 23.520518358531316,
      "grad_norm": 0.0014032069593667984,
      "learning_rate": 2.6479481641468684e-05,
      "loss": 0.0001,
      "step": 76230
    },
    {
      "epoch": 23.523603825979635,
      "grad_norm": 0.16806507110595703,
      "learning_rate": 2.647639617402037e-05,
      "loss": 0.0001,
      "step": 76240
    },
    {
      "epoch": 23.526689293427953,
      "grad_norm": 4.22196026192978e-05,
      "learning_rate": 2.6473310706572045e-05,
      "loss": 0.0001,
      "step": 76250
    },
    {
      "epoch": 23.529774760876272,
      "grad_norm": 1.4146930880087893e-05,
      "learning_rate": 2.647022523912373e-05,
      "loss": 0.0,
      "step": 76260
    },
    {
      "epoch": 23.53286022832459,
      "grad_norm": 0.0005851082387380302,
      "learning_rate": 2.646713977167541e-05,
      "loss": 0.0022,
      "step": 76270
    },
    {
      "epoch": 23.53594569577291,
      "grad_norm": 0.004892961122095585,
      "learning_rate": 2.6464054304227093e-05,
      "loss": 0.0,
      "step": 76280
    },
    {
      "epoch": 23.539031163221228,
      "grad_norm": 5.050208710599691e-05,
      "learning_rate": 2.6460968836778772e-05,
      "loss": 0.0001,
      "step": 76290
    },
    {
      "epoch": 23.542116630669547,
      "grad_norm": 0.0011664136545732617,
      "learning_rate": 2.6457883369330454e-05,
      "loss": 0.0,
      "step": 76300
    },
    {
      "epoch": 23.545202098117866,
      "grad_norm": 1.6703710571164265e-05,
      "learning_rate": 2.645479790188214e-05,
      "loss": 0.0,
      "step": 76310
    },
    {
      "epoch": 23.548287565566184,
      "grad_norm": 7.1426952672482e-06,
      "learning_rate": 2.6451712434433816e-05,
      "loss": 0.0001,
      "step": 76320
    },
    {
      "epoch": 23.551373033014503,
      "grad_norm": 0.003483722684904933,
      "learning_rate": 2.6448626966985502e-05,
      "loss": 0.0001,
      "step": 76330
    },
    {
      "epoch": 23.55445850046282,
      "grad_norm": 1.6862867369127343e-07,
      "learning_rate": 2.644554149953718e-05,
      "loss": 0.0,
      "step": 76340
    },
    {
      "epoch": 23.557543967911137,
      "grad_norm": 4.508969868766144e-05,
      "learning_rate": 2.6442456032088863e-05,
      "loss": 0.0,
      "step": 76350
    },
    {
      "epoch": 23.560629435359456,
      "grad_norm": 0.00012869143392890692,
      "learning_rate": 2.6439370564640542e-05,
      "loss": 0.0003,
      "step": 76360
    },
    {
      "epoch": 23.563714902807774,
      "grad_norm": 3.032124595847563e-07,
      "learning_rate": 2.6436285097192225e-05,
      "loss": 0.0,
      "step": 76370
    },
    {
      "epoch": 23.566800370256093,
      "grad_norm": 0.005283576436340809,
      "learning_rate": 2.643319962974391e-05,
      "loss": 0.0,
      "step": 76380
    },
    {
      "epoch": 23.569885837704412,
      "grad_norm": 0.3191341757774353,
      "learning_rate": 2.643011416229559e-05,
      "loss": 0.0002,
      "step": 76390
    },
    {
      "epoch": 23.57297130515273,
      "grad_norm": 0.00011252251715632156,
      "learning_rate": 2.6427028694847272e-05,
      "loss": 0.0001,
      "step": 76400
    },
    {
      "epoch": 23.57605677260105,
      "grad_norm": 0.00951565895229578,
      "learning_rate": 2.642394322739895e-05,
      "loss": 0.0,
      "step": 76410
    },
    {
      "epoch": 23.579142240049368,
      "grad_norm": 0.0002869231684599072,
      "learning_rate": 2.6420857759950634e-05,
      "loss": 0.0021,
      "step": 76420
    },
    {
      "epoch": 23.582227707497687,
      "grad_norm": 0.0010391799733042717,
      "learning_rate": 2.6417772292502313e-05,
      "loss": 0.0,
      "step": 76430
    },
    {
      "epoch": 23.585313174946005,
      "grad_norm": 0.13009865581989288,
      "learning_rate": 2.6414686825053995e-05,
      "loss": 0.0001,
      "step": 76440
    },
    {
      "epoch": 23.588398642394324,
      "grad_norm": 2.2888359580974793e-06,
      "learning_rate": 2.641160135760568e-05,
      "loss": 0.0,
      "step": 76450
    },
    {
      "epoch": 23.591484109842643,
      "grad_norm": 2.4103076457977295,
      "learning_rate": 2.640851589015736e-05,
      "loss": 0.0056,
      "step": 76460
    },
    {
      "epoch": 23.594569577290958,
      "grad_norm": 0.00013826902431901544,
      "learning_rate": 2.6405430422709043e-05,
      "loss": 0.0,
      "step": 76470
    },
    {
      "epoch": 23.597655044739277,
      "grad_norm": 0.00010233715875074267,
      "learning_rate": 2.6402344955260722e-05,
      "loss": 0.0069,
      "step": 76480
    },
    {
      "epoch": 23.600740512187595,
      "grad_norm": 1.6559873984078877e-05,
      "learning_rate": 2.6399259487812404e-05,
      "loss": 0.0008,
      "step": 76490
    },
    {
      "epoch": 23.603825979635914,
      "grad_norm": 0.0005423700204119086,
      "learning_rate": 2.6396174020364084e-05,
      "loss": 0.0001,
      "step": 76500
    },
    {
      "epoch": 23.606911447084233,
      "grad_norm": 0.0014085773145779967,
      "learning_rate": 2.639308855291577e-05,
      "loss": 0.0004,
      "step": 76510
    },
    {
      "epoch": 23.60999691453255,
      "grad_norm": 0.41467535495758057,
      "learning_rate": 2.6390003085467452e-05,
      "loss": 0.0003,
      "step": 76520
    },
    {
      "epoch": 23.61308238198087,
      "grad_norm": 1.0670262575149536,
      "learning_rate": 2.638691761801913e-05,
      "loss": 0.0005,
      "step": 76530
    },
    {
      "epoch": 23.61616784942919,
      "grad_norm": 2.5486199319857405e-06,
      "learning_rate": 2.6383832150570813e-05,
      "loss": 0.0,
      "step": 76540
    },
    {
      "epoch": 23.619253316877508,
      "grad_norm": 0.0001245187595486641,
      "learning_rate": 2.6380746683122493e-05,
      "loss": 0.0002,
      "step": 76550
    },
    {
      "epoch": 23.622338784325827,
      "grad_norm": 0.08542231470346451,
      "learning_rate": 2.6377661215674175e-05,
      "loss": 0.0002,
      "step": 76560
    },
    {
      "epoch": 23.625424251774145,
      "grad_norm": 0.00019535605679266155,
      "learning_rate": 2.6374575748225854e-05,
      "loss": 0.0052,
      "step": 76570
    },
    {
      "epoch": 23.628509719222464,
      "grad_norm": 0.002014332450926304,
      "learning_rate": 2.637149028077754e-05,
      "loss": 0.0002,
      "step": 76580
    },
    {
      "epoch": 23.63159518667078,
      "grad_norm": 2.9562639610958286e-05,
      "learning_rate": 2.6368404813329222e-05,
      "loss": 0.001,
      "step": 76590
    },
    {
      "epoch": 23.634680654119098,
      "grad_norm": 0.001559844589792192,
      "learning_rate": 2.63653193458809e-05,
      "loss": 0.0,
      "step": 76600
    },
    {
      "epoch": 23.637766121567417,
      "grad_norm": 1.9606111436587526e-06,
      "learning_rate": 2.6362233878432584e-05,
      "loss": 0.0052,
      "step": 76610
    },
    {
      "epoch": 23.640851589015735,
      "grad_norm": 0.00013785723422188312,
      "learning_rate": 2.6359148410984263e-05,
      "loss": 0.0,
      "step": 76620
    },
    {
      "epoch": 23.643937056464054,
      "grad_norm": 1.661865462665446e-05,
      "learning_rate": 2.635606294353595e-05,
      "loss": 0.0001,
      "step": 76630
    },
    {
      "epoch": 23.647022523912373,
      "grad_norm": 1.4043269157409668,
      "learning_rate": 2.6352977476087625e-05,
      "loss": 0.0124,
      "step": 76640
    },
    {
      "epoch": 23.65010799136069,
      "grad_norm": 0.0004125071282032877,
      "learning_rate": 2.634989200863931e-05,
      "loss": 0.0,
      "step": 76650
    },
    {
      "epoch": 23.65319345880901,
      "grad_norm": 9.93382345768623e-05,
      "learning_rate": 2.6346806541190993e-05,
      "loss": 0.0,
      "step": 76660
    },
    {
      "epoch": 23.65627892625733,
      "grad_norm": 0.0007394002750515938,
      "learning_rate": 2.6343721073742672e-05,
      "loss": 0.0001,
      "step": 76670
    },
    {
      "epoch": 23.659364393705648,
      "grad_norm": 0.00016117053746711463,
      "learning_rate": 2.6340635606294355e-05,
      "loss": 0.0,
      "step": 76680
    },
    {
      "epoch": 23.662449861153966,
      "grad_norm": 0.0001428618998033926,
      "learning_rate": 2.6337550138846034e-05,
      "loss": 0.0015,
      "step": 76690
    },
    {
      "epoch": 23.66553532860228,
      "grad_norm": 0.17308127880096436,
      "learning_rate": 2.633446467139772e-05,
      "loss": 0.0001,
      "step": 76700
    },
    {
      "epoch": 23.6686207960506,
      "grad_norm": 7.46136447560275e-06,
      "learning_rate": 2.6331379203949402e-05,
      "loss": 0.0014,
      "step": 76710
    },
    {
      "epoch": 23.67170626349892,
      "grad_norm": 0.22364215552806854,
      "learning_rate": 2.632829373650108e-05,
      "loss": 0.0002,
      "step": 76720
    },
    {
      "epoch": 23.674791730947238,
      "grad_norm": 0.004277524538338184,
      "learning_rate": 2.6325208269052764e-05,
      "loss": 0.0009,
      "step": 76730
    },
    {
      "epoch": 23.677877198395556,
      "grad_norm": 4.906875983579084e-05,
      "learning_rate": 2.6322122801604443e-05,
      "loss": 0.0001,
      "step": 76740
    },
    {
      "epoch": 23.680962665843875,
      "grad_norm": 0.49889570474624634,
      "learning_rate": 2.631903733415613e-05,
      "loss": 0.0003,
      "step": 76750
    },
    {
      "epoch": 23.684048133292194,
      "grad_norm": 0.010321145877242088,
      "learning_rate": 2.6315951866707804e-05,
      "loss": 0.0002,
      "step": 76760
    },
    {
      "epoch": 23.687133600740513,
      "grad_norm": 0.050583768635988235,
      "learning_rate": 2.631286639925949e-05,
      "loss": 0.0014,
      "step": 76770
    },
    {
      "epoch": 23.69021906818883,
      "grad_norm": 0.046538010239601135,
      "learning_rate": 2.6309780931811173e-05,
      "loss": 0.0006,
      "step": 76780
    },
    {
      "epoch": 23.69330453563715,
      "grad_norm": 0.00028867353103123605,
      "learning_rate": 2.630669546436285e-05,
      "loss": 0.0108,
      "step": 76790
    },
    {
      "epoch": 23.69639000308547,
      "grad_norm": 0.0018808835884556174,
      "learning_rate": 2.6303609996914534e-05,
      "loss": 0.0022,
      "step": 76800
    },
    {
      "epoch": 23.699475470533788,
      "grad_norm": 0.0017460864037275314,
      "learning_rate": 2.6300524529466213e-05,
      "loss": 0.0008,
      "step": 76810
    },
    {
      "epoch": 23.702560937982103,
      "grad_norm": 0.0018383112037554383,
      "learning_rate": 2.62974390620179e-05,
      "loss": 0.0005,
      "step": 76820
    },
    {
      "epoch": 23.70564640543042,
      "grad_norm": 1.932344675064087,
      "learning_rate": 2.6294353594569575e-05,
      "loss": 0.0027,
      "step": 76830
    },
    {
      "epoch": 23.70873187287874,
      "grad_norm": 0.0008400894002988935,
      "learning_rate": 2.629126812712126e-05,
      "loss": 0.0,
      "step": 76840
    },
    {
      "epoch": 23.71181734032706,
      "grad_norm": 0.040311798453330994,
      "learning_rate": 2.6288182659672943e-05,
      "loss": 0.0001,
      "step": 76850
    },
    {
      "epoch": 23.714902807775378,
      "grad_norm": 0.022154610604047775,
      "learning_rate": 2.6285097192224622e-05,
      "loss": 0.0,
      "step": 76860
    },
    {
      "epoch": 23.717988275223696,
      "grad_norm": 0.0004907906986773014,
      "learning_rate": 2.6282011724776308e-05,
      "loss": 0.0001,
      "step": 76870
    },
    {
      "epoch": 23.721073742672015,
      "grad_norm": 0.000578265986405313,
      "learning_rate": 2.6278926257327984e-05,
      "loss": 0.0001,
      "step": 76880
    },
    {
      "epoch": 23.724159210120334,
      "grad_norm": 0.0010541791561990976,
      "learning_rate": 2.627584078987967e-05,
      "loss": 0.0006,
      "step": 76890
    },
    {
      "epoch": 23.727244677568653,
      "grad_norm": 0.028938880190253258,
      "learning_rate": 2.627275532243135e-05,
      "loss": 0.0008,
      "step": 76900
    },
    {
      "epoch": 23.73033014501697,
      "grad_norm": 0.028317615389823914,
      "learning_rate": 2.626966985498303e-05,
      "loss": 0.0001,
      "step": 76910
    },
    {
      "epoch": 23.73341561246529,
      "grad_norm": 0.05601641908288002,
      "learning_rate": 2.6266584387534714e-05,
      "loss": 0.0022,
      "step": 76920
    },
    {
      "epoch": 23.73650107991361,
      "grad_norm": 2.4182666038541356e-06,
      "learning_rate": 2.6263498920086393e-05,
      "loss": 0.0002,
      "step": 76930
    },
    {
      "epoch": 23.739586547361924,
      "grad_norm": 0.004672624636441469,
      "learning_rate": 2.626041345263808e-05,
      "loss": 0.0,
      "step": 76940
    },
    {
      "epoch": 23.742672014810243,
      "grad_norm": 0.00014224706683307886,
      "learning_rate": 2.6257327985189754e-05,
      "loss": 0.0003,
      "step": 76950
    },
    {
      "epoch": 23.74575748225856,
      "grad_norm": 0.05850480496883392,
      "learning_rate": 2.625424251774144e-05,
      "loss": 0.0004,
      "step": 76960
    },
    {
      "epoch": 23.74884294970688,
      "grad_norm": 0.0010069325799122453,
      "learning_rate": 2.625115705029312e-05,
      "loss": 0.0001,
      "step": 76970
    },
    {
      "epoch": 23.7519284171552,
      "grad_norm": 0.018750518560409546,
      "learning_rate": 2.6248071582844802e-05,
      "loss": 0.0083,
      "step": 76980
    },
    {
      "epoch": 23.755013884603517,
      "grad_norm": 0.006987093016505241,
      "learning_rate": 2.6244986115396488e-05,
      "loss": 0.0001,
      "step": 76990
    },
    {
      "epoch": 23.758099352051836,
      "grad_norm": 0.06986752152442932,
      "learning_rate": 2.6241900647948163e-05,
      "loss": 0.0005,
      "step": 77000
    },
    {
      "epoch": 23.761184819500155,
      "grad_norm": 2.420585951767862e-05,
      "learning_rate": 2.623881518049985e-05,
      "loss": 0.0,
      "step": 77010
    },
    {
      "epoch": 23.764270286948474,
      "grad_norm": 1.6200902462005615,
      "learning_rate": 2.623572971305153e-05,
      "loss": 0.0012,
      "step": 77020
    },
    {
      "epoch": 23.767355754396792,
      "grad_norm": 0.5163652300834656,
      "learning_rate": 2.623264424560321e-05,
      "loss": 0.0003,
      "step": 77030
    },
    {
      "epoch": 23.77044122184511,
      "grad_norm": 3.6321176594356075e-05,
      "learning_rate": 2.622955877815489e-05,
      "loss": 0.0003,
      "step": 77040
    },
    {
      "epoch": 23.773526689293426,
      "grad_norm": 0.010426543653011322,
      "learning_rate": 2.6226473310706572e-05,
      "loss": 0.0013,
      "step": 77050
    },
    {
      "epoch": 23.776612156741745,
      "grad_norm": 0.005752675700932741,
      "learning_rate": 2.6223387843258258e-05,
      "loss": 0.0062,
      "step": 77060
    },
    {
      "epoch": 23.779697624190064,
      "grad_norm": 3.199763523298316e-05,
      "learning_rate": 2.6220302375809934e-05,
      "loss": 0.0068,
      "step": 77070
    },
    {
      "epoch": 23.782783091638382,
      "grad_norm": 0.00031990071875043213,
      "learning_rate": 2.621721690836162e-05,
      "loss": 0.0006,
      "step": 77080
    },
    {
      "epoch": 23.7858685590867,
      "grad_norm": 1.5656534742447548e-05,
      "learning_rate": 2.62141314409133e-05,
      "loss": 0.0,
      "step": 77090
    },
    {
      "epoch": 23.78895402653502,
      "grad_norm": 0.0009852383518591523,
      "learning_rate": 2.621104597346498e-05,
      "loss": 0.0003,
      "step": 77100
    },
    {
      "epoch": 23.79203949398334,
      "grad_norm": 0.012640687637031078,
      "learning_rate": 2.6207960506016667e-05,
      "loss": 0.0015,
      "step": 77110
    },
    {
      "epoch": 23.795124961431657,
      "grad_norm": 0.0017351923743262887,
      "learning_rate": 2.6204875038568343e-05,
      "loss": 0.0003,
      "step": 77120
    },
    {
      "epoch": 23.798210428879976,
      "grad_norm": 0.0005895749200135469,
      "learning_rate": 2.620178957112003e-05,
      "loss": 0.0002,
      "step": 77130
    },
    {
      "epoch": 23.801295896328295,
      "grad_norm": 0.005490988027304411,
      "learning_rate": 2.6198704103671708e-05,
      "loss": 0.0001,
      "step": 77140
    },
    {
      "epoch": 23.804381363776614,
      "grad_norm": 0.5042452812194824,
      "learning_rate": 2.619561863622339e-05,
      "loss": 0.0009,
      "step": 77150
    },
    {
      "epoch": 23.807466831224932,
      "grad_norm": 2.3739922046661377,
      "learning_rate": 2.619253316877507e-05,
      "loss": 0.0065,
      "step": 77160
    },
    {
      "epoch": 23.810552298673247,
      "grad_norm": 0.002267849864438176,
      "learning_rate": 2.6189447701326752e-05,
      "loss": 0.0,
      "step": 77170
    },
    {
      "epoch": 23.813637766121566,
      "grad_norm": 1.6377083738916554e-05,
      "learning_rate": 2.6186362233878438e-05,
      "loss": 0.0014,
      "step": 77180
    },
    {
      "epoch": 23.816723233569885,
      "grad_norm": 0.00197233515791595,
      "learning_rate": 2.6183276766430113e-05,
      "loss": 0.001,
      "step": 77190
    },
    {
      "epoch": 23.819808701018204,
      "grad_norm": 0.11786095798015594,
      "learning_rate": 2.61801912989818e-05,
      "loss": 0.0004,
      "step": 77200
    },
    {
      "epoch": 23.822894168466522,
      "grad_norm": 0.009075942449271679,
      "learning_rate": 2.617710583153348e-05,
      "loss": 0.0002,
      "step": 77210
    },
    {
      "epoch": 23.82597963591484,
      "grad_norm": 0.00362244900316,
      "learning_rate": 2.617402036408516e-05,
      "loss": 0.0005,
      "step": 77220
    },
    {
      "epoch": 23.82906510336316,
      "grad_norm": 3.5766028304351494e-05,
      "learning_rate": 2.617093489663684e-05,
      "loss": 0.0,
      "step": 77230
    },
    {
      "epoch": 23.83215057081148,
      "grad_norm": 7.785019261064008e-05,
      "learning_rate": 2.6167849429188522e-05,
      "loss": 0.0001,
      "step": 77240
    },
    {
      "epoch": 23.835236038259797,
      "grad_norm": 5.899813550058752e-05,
      "learning_rate": 2.616476396174021e-05,
      "loss": 0.0,
      "step": 77250
    },
    {
      "epoch": 23.838321505708116,
      "grad_norm": 0.09020046144723892,
      "learning_rate": 2.6161678494291887e-05,
      "loss": 0.0014,
      "step": 77260
    },
    {
      "epoch": 23.841406973156435,
      "grad_norm": 0.34356990456581116,
      "learning_rate": 2.615859302684357e-05,
      "loss": 0.0001,
      "step": 77270
    },
    {
      "epoch": 23.844492440604753,
      "grad_norm": 0.004293530248105526,
      "learning_rate": 2.615550755939525e-05,
      "loss": 0.0063,
      "step": 77280
    },
    {
      "epoch": 23.84757790805307,
      "grad_norm": 1.1509478099469561e-05,
      "learning_rate": 2.615242209194693e-05,
      "loss": 0.0115,
      "step": 77290
    },
    {
      "epoch": 23.850663375501387,
      "grad_norm": 1.8016764443018474e-05,
      "learning_rate": 2.614933662449861e-05,
      "loss": 0.0002,
      "step": 77300
    },
    {
      "epoch": 23.853748842949706,
      "grad_norm": 0.0005160134169273078,
      "learning_rate": 2.6146251157050293e-05,
      "loss": 0.0,
      "step": 77310
    },
    {
      "epoch": 23.856834310398025,
      "grad_norm": 0.07867391407489777,
      "learning_rate": 2.614316568960198e-05,
      "loss": 0.0056,
      "step": 77320
    },
    {
      "epoch": 23.859919777846343,
      "grad_norm": 0.003423030022531748,
      "learning_rate": 2.6140080222153658e-05,
      "loss": 0.0,
      "step": 77330
    },
    {
      "epoch": 23.863005245294662,
      "grad_norm": 0.08315970748662949,
      "learning_rate": 2.613699475470534e-05,
      "loss": 0.0,
      "step": 77340
    },
    {
      "epoch": 23.86609071274298,
      "grad_norm": 4.3796873796964064e-05,
      "learning_rate": 2.613390928725702e-05,
      "loss": 0.0028,
      "step": 77350
    },
    {
      "epoch": 23.8691761801913,
      "grad_norm": 0.000771582534071058,
      "learning_rate": 2.6130823819808702e-05,
      "loss": 0.0,
      "step": 77360
    },
    {
      "epoch": 23.87226164763962,
      "grad_norm": 9.895955008687451e-05,
      "learning_rate": 2.612773835236038e-05,
      "loss": 0.0008,
      "step": 77370
    },
    {
      "epoch": 23.875347115087937,
      "grad_norm": 0.01010371558368206,
      "learning_rate": 2.6124652884912067e-05,
      "loss": 0.0002,
      "step": 77380
    },
    {
      "epoch": 23.878432582536256,
      "grad_norm": 0.0002577979175839573,
      "learning_rate": 2.612156741746375e-05,
      "loss": 0.0012,
      "step": 77390
    },
    {
      "epoch": 23.88151804998457,
      "grad_norm": 0.11723596602678299,
      "learning_rate": 2.611848195001543e-05,
      "loss": 0.0001,
      "step": 77400
    },
    {
      "epoch": 23.88460351743289,
      "grad_norm": 0.005925777833908796,
      "learning_rate": 2.611539648256711e-05,
      "loss": 0.0013,
      "step": 77410
    },
    {
      "epoch": 23.88768898488121,
      "grad_norm": 0.0005905003054067492,
      "learning_rate": 2.611231101511879e-05,
      "loss": 0.0011,
      "step": 77420
    },
    {
      "epoch": 23.890774452329527,
      "grad_norm": 1.573684811592102,
      "learning_rate": 2.6109225547670473e-05,
      "loss": 0.0044,
      "step": 77430
    },
    {
      "epoch": 23.893859919777846,
      "grad_norm": 0.025154294446110725,
      "learning_rate": 2.610614008022215e-05,
      "loss": 0.0,
      "step": 77440
    },
    {
      "epoch": 23.896945387226165,
      "grad_norm": 0.0013171522878110409,
      "learning_rate": 2.6103054612773838e-05,
      "loss": 0.0002,
      "step": 77450
    },
    {
      "epoch": 23.900030854674483,
      "grad_norm": 0.38604485988616943,
      "learning_rate": 2.609996914532552e-05,
      "loss": 0.0003,
      "step": 77460
    },
    {
      "epoch": 23.903116322122802,
      "grad_norm": 0.05149327963590622,
      "learning_rate": 2.60968836778772e-05,
      "loss": 0.0018,
      "step": 77470
    },
    {
      "epoch": 23.90620178957112,
      "grad_norm": 0.0001414870348526165,
      "learning_rate": 2.609379821042888e-05,
      "loss": 0.0001,
      "step": 77480
    },
    {
      "epoch": 23.90928725701944,
      "grad_norm": 0.00035665641189552844,
      "learning_rate": 2.609071274298056e-05,
      "loss": 0.0009,
      "step": 77490
    },
    {
      "epoch": 23.912372724467758,
      "grad_norm": 0.024251606315374374,
      "learning_rate": 2.6087627275532243e-05,
      "loss": 0.002,
      "step": 77500
    },
    {
      "epoch": 23.915458191916077,
      "grad_norm": 0.0001702323934296146,
      "learning_rate": 2.6084541808083922e-05,
      "loss": 0.0048,
      "step": 77510
    },
    {
      "epoch": 23.918543659364392,
      "grad_norm": 3.5626060962677,
      "learning_rate": 2.6081456340635608e-05,
      "loss": 0.0057,
      "step": 77520
    },
    {
      "epoch": 23.92162912681271,
      "grad_norm": 0.00037153527955524623,
      "learning_rate": 2.607837087318729e-05,
      "loss": 0.0003,
      "step": 77530
    },
    {
      "epoch": 23.92471459426103,
      "grad_norm": 0.0007095992332324386,
      "learning_rate": 2.607528540573897e-05,
      "loss": 0.0,
      "step": 77540
    },
    {
      "epoch": 23.92780006170935,
      "grad_norm": 2.4573569297790527,
      "learning_rate": 2.6072199938290652e-05,
      "loss": 0.0022,
      "step": 77550
    },
    {
      "epoch": 23.930885529157667,
      "grad_norm": 0.0029903275426477194,
      "learning_rate": 2.606911447084233e-05,
      "loss": 0.0007,
      "step": 77560
    },
    {
      "epoch": 23.933970996605986,
      "grad_norm": 0.00021088661742396653,
      "learning_rate": 2.6066029003394017e-05,
      "loss": 0.0024,
      "step": 77570
    },
    {
      "epoch": 23.937056464054304,
      "grad_norm": 4.581307075568475e-05,
      "learning_rate": 2.60629435359457e-05,
      "loss": 0.001,
      "step": 77580
    },
    {
      "epoch": 23.940141931502623,
      "grad_norm": 0.00023271242389455438,
      "learning_rate": 2.605985806849738e-05,
      "loss": 0.0014,
      "step": 77590
    },
    {
      "epoch": 23.943227398950942,
      "grad_norm": 0.010358349420130253,
      "learning_rate": 2.605677260104906e-05,
      "loss": 0.0001,
      "step": 77600
    },
    {
      "epoch": 23.94631286639926,
      "grad_norm": 7.381367595371557e-06,
      "learning_rate": 2.605368713360074e-05,
      "loss": 0.0001,
      "step": 77610
    },
    {
      "epoch": 23.94939833384758,
      "grad_norm": 0.12793157994747162,
      "learning_rate": 2.6050601666152423e-05,
      "loss": 0.0027,
      "step": 77620
    },
    {
      "epoch": 23.952483801295898,
      "grad_norm": 0.001252953428775072,
      "learning_rate": 2.6047516198704102e-05,
      "loss": 0.0019,
      "step": 77630
    },
    {
      "epoch": 23.955569268744213,
      "grad_norm": 1.865470290184021,
      "learning_rate": 2.6044430731255788e-05,
      "loss": 0.0013,
      "step": 77640
    },
    {
      "epoch": 23.958654736192532,
      "grad_norm": 0.061856724321842194,
      "learning_rate": 2.604134526380747e-05,
      "loss": 0.0059,
      "step": 77650
    },
    {
      "epoch": 23.96174020364085,
      "grad_norm": 2.1250908374786377,
      "learning_rate": 2.603825979635915e-05,
      "loss": 0.007,
      "step": 77660
    },
    {
      "epoch": 23.96482567108917,
      "grad_norm": 0.0008789952844381332,
      "learning_rate": 2.6035174328910832e-05,
      "loss": 0.0,
      "step": 77670
    },
    {
      "epoch": 23.967911138537488,
      "grad_norm": 0.0011641274904832244,
      "learning_rate": 2.603208886146251e-05,
      "loss": 0.0049,
      "step": 77680
    },
    {
      "epoch": 23.970996605985807,
      "grad_norm": 0.0004667618195526302,
      "learning_rate": 2.6029003394014197e-05,
      "loss": 0.0001,
      "step": 77690
    },
    {
      "epoch": 23.974082073434126,
      "grad_norm": 0.0022430920507758856,
      "learning_rate": 2.6025917926565872e-05,
      "loss": 0.0,
      "step": 77700
    },
    {
      "epoch": 23.977167540882444,
      "grad_norm": 0.028347348794341087,
      "learning_rate": 2.6022832459117558e-05,
      "loss": 0.0067,
      "step": 77710
    },
    {
      "epoch": 23.980253008330763,
      "grad_norm": 0.26573753356933594,
      "learning_rate": 2.601974699166924e-05,
      "loss": 0.0065,
      "step": 77720
    },
    {
      "epoch": 23.98333847577908,
      "grad_norm": 9.102735930355266e-05,
      "learning_rate": 2.601666152422092e-05,
      "loss": 0.0001,
      "step": 77730
    },
    {
      "epoch": 23.9864239432274,
      "grad_norm": 0.0011614508694037795,
      "learning_rate": 2.6013576056772602e-05,
      "loss": 0.0037,
      "step": 77740
    },
    {
      "epoch": 23.989509410675716,
      "grad_norm": 0.0026007930282503366,
      "learning_rate": 2.601049058932428e-05,
      "loss": 0.0009,
      "step": 77750
    },
    {
      "epoch": 23.992594878124034,
      "grad_norm": 0.0001005051308311522,
      "learning_rate": 2.6007405121875967e-05,
      "loss": 0.0,
      "step": 77760
    },
    {
      "epoch": 23.995680345572353,
      "grad_norm": 4.880548294750042e-05,
      "learning_rate": 2.6004319654427643e-05,
      "loss": 0.0007,
      "step": 77770
    },
    {
      "epoch": 23.998765813020672,
      "grad_norm": 2.010432481765747,
      "learning_rate": 2.600123418697933e-05,
      "loss": 0.0163,
      "step": 77780
    },
    {
      "epoch": 24.0,
      "eval_accuracy_branch1": 0.9999035521734517,
      "eval_accuracy_branch2": 0.45269716346942124,
      "eval_f1_branch1": 0.9999062317824244,
      "eval_f1_branch2": 0.4522671857777057,
      "eval_loss": 0.00012116045400034636,
      "eval_precision_branch1": 0.9999026200753091,
      "eval_precision_branch2": 0.5207358113843523,
      "eval_recall_branch1": 0.9999098567676797,
      "eval_recall_branch2": 0.5197910940076965,
      "eval_runtime": 240.5078,
      "eval_samples_per_second": 431.1,
      "eval_steps_per_second": 53.89,
      "step": 77784
    },
    {
      "epoch": 24.00185128046899,
      "grad_norm": 5.066627636551857e-05,
      "learning_rate": 2.599814871953101e-05,
      "loss": 0.0001,
      "step": 77790
    },
    {
      "epoch": 24.00493674791731,
      "grad_norm": 0.0026311140973120928,
      "learning_rate": 2.599506325208269e-05,
      "loss": 0.0009,
      "step": 77800
    },
    {
      "epoch": 24.008022215365628,
      "grad_norm": 3.977473170380108e-06,
      "learning_rate": 2.5991977784634376e-05,
      "loss": 0.002,
      "step": 77810
    },
    {
      "epoch": 24.011107682813947,
      "grad_norm": 0.05064830183982849,
      "learning_rate": 2.5988892317186052e-05,
      "loss": 0.0019,
      "step": 77820
    },
    {
      "epoch": 24.014193150262265,
      "grad_norm": 0.004328712355345488,
      "learning_rate": 2.5985806849737738e-05,
      "loss": 0.0001,
      "step": 77830
    },
    {
      "epoch": 24.017278617710584,
      "grad_norm": 0.0005568339256569743,
      "learning_rate": 2.5982721382289417e-05,
      "loss": 0.0097,
      "step": 77840
    },
    {
      "epoch": 24.020364085158903,
      "grad_norm": 2.389821767807007,
      "learning_rate": 2.59796359148411e-05,
      "loss": 0.0119,
      "step": 77850
    },
    {
      "epoch": 24.02344955260722,
      "grad_norm": 0.0022769703064113855,
      "learning_rate": 2.5976550447392782e-05,
      "loss": 0.0012,
      "step": 77860
    },
    {
      "epoch": 24.026535020055537,
      "grad_norm": 0.0002680884499568492,
      "learning_rate": 2.597346497994446e-05,
      "loss": 0.0004,
      "step": 77870
    },
    {
      "epoch": 24.029620487503855,
      "grad_norm": 0.33611053228378296,
      "learning_rate": 2.5970379512496147e-05,
      "loss": 0.0015,
      "step": 77880
    },
    {
      "epoch": 24.032705954952174,
      "grad_norm": 7.320500299101695e-05,
      "learning_rate": 2.5967294045047822e-05,
      "loss": 0.0069,
      "step": 77890
    },
    {
      "epoch": 24.035791422400493,
      "grad_norm": 0.0003497750440146774,
      "learning_rate": 2.596420857759951e-05,
      "loss": 0.002,
      "step": 77900
    },
    {
      "epoch": 24.03887688984881,
      "grad_norm": 0.0007357713766396046,
      "learning_rate": 2.5961123110151187e-05,
      "loss": 0.0006,
      "step": 77910
    },
    {
      "epoch": 24.04196235729713,
      "grad_norm": 0.08216535300016403,
      "learning_rate": 2.595803764270287e-05,
      "loss": 0.003,
      "step": 77920
    },
    {
      "epoch": 24.04504782474545,
      "grad_norm": 0.00017142939032055438,
      "learning_rate": 2.5954952175254556e-05,
      "loss": 0.0021,
      "step": 77930
    },
    {
      "epoch": 24.048133292193768,
      "grad_norm": 0.0003025554760824889,
      "learning_rate": 2.595186670780623e-05,
      "loss": 0.0009,
      "step": 77940
    },
    {
      "epoch": 24.051218759642087,
      "grad_norm": 6.752726676495513e-06,
      "learning_rate": 2.5948781240357917e-05,
      "loss": 0.0008,
      "step": 77950
    },
    {
      "epoch": 24.054304227090405,
      "grad_norm": 2.4115390260703862e-05,
      "learning_rate": 2.5945695772909596e-05,
      "loss": 0.0,
      "step": 77960
    },
    {
      "epoch": 24.057389694538724,
      "grad_norm": 0.008954811841249466,
      "learning_rate": 2.594261030546128e-05,
      "loss": 0.0009,
      "step": 77970
    },
    {
      "epoch": 24.060475161987043,
      "grad_norm": 5.9873815189348534e-05,
      "learning_rate": 2.593952483801296e-05,
      "loss": 0.0001,
      "step": 77980
    },
    {
      "epoch": 24.063560629435358,
      "grad_norm": 0.0018927307100966573,
      "learning_rate": 2.593643937056464e-05,
      "loss": 0.0033,
      "step": 77990
    },
    {
      "epoch": 24.066646096883677,
      "grad_norm": 0.0023708203807473183,
      "learning_rate": 2.5933353903116326e-05,
      "loss": 0.001,
      "step": 78000
    },
    {
      "epoch": 24.069731564331995,
      "grad_norm": 0.016429154202342033,
      "learning_rate": 2.5930268435668002e-05,
      "loss": 0.0012,
      "step": 78010
    },
    {
      "epoch": 24.072817031780314,
      "grad_norm": 0.0004942462546750903,
      "learning_rate": 2.5927182968219688e-05,
      "loss": 0.0034,
      "step": 78020
    },
    {
      "epoch": 24.075902499228633,
      "grad_norm": 0.0002706649247556925,
      "learning_rate": 2.5924097500771367e-05,
      "loss": 0.0002,
      "step": 78030
    },
    {
      "epoch": 24.07898796667695,
      "grad_norm": 0.014947004616260529,
      "learning_rate": 2.592101203332305e-05,
      "loss": 0.0009,
      "step": 78040
    },
    {
      "epoch": 24.08207343412527,
      "grad_norm": 0.0001337292487733066,
      "learning_rate": 2.5917926565874735e-05,
      "loss": 0.0008,
      "step": 78050
    },
    {
      "epoch": 24.08515890157359,
      "grad_norm": 0.0017914075870066881,
      "learning_rate": 2.591484109842641e-05,
      "loss": 0.0031,
      "step": 78060
    },
    {
      "epoch": 24.088244369021908,
      "grad_norm": 0.00532201211899519,
      "learning_rate": 2.5911755630978097e-05,
      "loss": 0.0001,
      "step": 78070
    },
    {
      "epoch": 24.091329836470226,
      "grad_norm": 0.00013150362065061927,
      "learning_rate": 2.5908670163529776e-05,
      "loss": 0.0,
      "step": 78080
    },
    {
      "epoch": 24.094415303918545,
      "grad_norm": 0.1479370892047882,
      "learning_rate": 2.590558469608146e-05,
      "loss": 0.0003,
      "step": 78090
    },
    {
      "epoch": 24.09750077136686,
      "grad_norm": 0.0289003923535347,
      "learning_rate": 2.5902499228633138e-05,
      "loss": 0.0001,
      "step": 78100
    },
    {
      "epoch": 24.10058623881518,
      "grad_norm": 3.2418979571957607e-06,
      "learning_rate": 2.589941376118482e-05,
      "loss": 0.0,
      "step": 78110
    },
    {
      "epoch": 24.103671706263498,
      "grad_norm": 0.0006030117510817945,
      "learning_rate": 2.5896328293736506e-05,
      "loss": 0.0051,
      "step": 78120
    },
    {
      "epoch": 24.106757173711816,
      "grad_norm": 0.005998286884278059,
      "learning_rate": 2.589324282628818e-05,
      "loss": 0.0001,
      "step": 78130
    },
    {
      "epoch": 24.109842641160135,
      "grad_norm": 0.0015813707141205668,
      "learning_rate": 2.5890157358839867e-05,
      "loss": 0.0001,
      "step": 78140
    },
    {
      "epoch": 24.112928108608454,
      "grad_norm": 6.776715054002125e-06,
      "learning_rate": 2.5887071891391547e-05,
      "loss": 0.0039,
      "step": 78150
    },
    {
      "epoch": 24.116013576056773,
      "grad_norm": 1.95895516872406,
      "learning_rate": 2.588398642394323e-05,
      "loss": 0.0087,
      "step": 78160
    },
    {
      "epoch": 24.11909904350509,
      "grad_norm": 0.0005755274905823171,
      "learning_rate": 2.5880900956494908e-05,
      "loss": 0.0117,
      "step": 78170
    },
    {
      "epoch": 24.12218451095341,
      "grad_norm": 0.01819656789302826,
      "learning_rate": 2.587781548904659e-05,
      "loss": 0.0015,
      "step": 78180
    },
    {
      "epoch": 24.12526997840173,
      "grad_norm": 0.00013760055298916996,
      "learning_rate": 2.5874730021598276e-05,
      "loss": 0.0004,
      "step": 78190
    },
    {
      "epoch": 24.128355445850048,
      "grad_norm": 0.0012110014213249087,
      "learning_rate": 2.5871644554149956e-05,
      "loss": 0.0001,
      "step": 78200
    },
    {
      "epoch": 24.131440913298366,
      "grad_norm": 0.005026179365813732,
      "learning_rate": 2.5868559086701638e-05,
      "loss": 0.0001,
      "step": 78210
    },
    {
      "epoch": 24.13452638074668,
      "grad_norm": 0.011088806204497814,
      "learning_rate": 2.5865473619253317e-05,
      "loss": 0.0002,
      "step": 78220
    },
    {
      "epoch": 24.137611848195,
      "grad_norm": 4.689317211159505e-05,
      "learning_rate": 2.5862388151805e-05,
      "loss": 0.0003,
      "step": 78230
    },
    {
      "epoch": 24.14069731564332,
      "grad_norm": 0.007001756224781275,
      "learning_rate": 2.585930268435668e-05,
      "loss": 0.0001,
      "step": 78240
    },
    {
      "epoch": 24.143782783091638,
      "grad_norm": 0.0010399166494607925,
      "learning_rate": 2.585621721690836e-05,
      "loss": 0.0004,
      "step": 78250
    },
    {
      "epoch": 24.146868250539956,
      "grad_norm": 4.3241096136625856e-05,
      "learning_rate": 2.5853131749460047e-05,
      "loss": 0.0004,
      "step": 78260
    },
    {
      "epoch": 24.149953717988275,
      "grad_norm": 0.0020099482499063015,
      "learning_rate": 2.5850046282011726e-05,
      "loss": 0.0004,
      "step": 78270
    },
    {
      "epoch": 24.153039185436594,
      "grad_norm": 3.1686038710176945e-05,
      "learning_rate": 2.584696081456341e-05,
      "loss": 0.0022,
      "step": 78280
    },
    {
      "epoch": 24.156124652884913,
      "grad_norm": 0.00017416657647117972,
      "learning_rate": 2.5843875347115088e-05,
      "loss": 0.0,
      "step": 78290
    },
    {
      "epoch": 24.15921012033323,
      "grad_norm": 1.5027180779725313e-05,
      "learning_rate": 2.584078987966677e-05,
      "loss": 0.0003,
      "step": 78300
    },
    {
      "epoch": 24.16229558778155,
      "grad_norm": 2.6778816391015425e-06,
      "learning_rate": 2.583770441221845e-05,
      "loss": 0.0,
      "step": 78310
    },
    {
      "epoch": 24.16538105522987,
      "grad_norm": 1.4949129763408564e-05,
      "learning_rate": 2.5834618944770135e-05,
      "loss": 0.0008,
      "step": 78320
    },
    {
      "epoch": 24.168466522678187,
      "grad_norm": 7.396761066047475e-05,
      "learning_rate": 2.5831533477321818e-05,
      "loss": 0.0004,
      "step": 78330
    },
    {
      "epoch": 24.171551990126503,
      "grad_norm": 0.0007087287958711386,
      "learning_rate": 2.5828448009873497e-05,
      "loss": 0.0,
      "step": 78340
    },
    {
      "epoch": 24.17463745757482,
      "grad_norm": 0.0015616407617926598,
      "learning_rate": 2.582536254242518e-05,
      "loss": 0.0001,
      "step": 78350
    },
    {
      "epoch": 24.17772292502314,
      "grad_norm": 0.005420474335551262,
      "learning_rate": 2.5822277074976858e-05,
      "loss": 0.0016,
      "step": 78360
    },
    {
      "epoch": 24.18080839247146,
      "grad_norm": 0.014204981736838818,
      "learning_rate": 2.581919160752854e-05,
      "loss": 0.0001,
      "step": 78370
    },
    {
      "epoch": 24.183893859919777,
      "grad_norm": 0.13536180555820465,
      "learning_rate": 2.581610614008022e-05,
      "loss": 0.0003,
      "step": 78380
    },
    {
      "epoch": 24.186979327368096,
      "grad_norm": 6.366398883983493e-05,
      "learning_rate": 2.5813020672631906e-05,
      "loss": 0.0001,
      "step": 78390
    },
    {
      "epoch": 24.190064794816415,
      "grad_norm": 0.00011553320655366406,
      "learning_rate": 2.5809935205183588e-05,
      "loss": 0.0,
      "step": 78400
    },
    {
      "epoch": 24.193150262264734,
      "grad_norm": 0.00011257542064413428,
      "learning_rate": 2.5806849737735267e-05,
      "loss": 0.0007,
      "step": 78410
    },
    {
      "epoch": 24.196235729713052,
      "grad_norm": 0.0011184306349605322,
      "learning_rate": 2.580376427028695e-05,
      "loss": 0.0,
      "step": 78420
    },
    {
      "epoch": 24.19932119716137,
      "grad_norm": 0.0024761799722909927,
      "learning_rate": 2.580067880283863e-05,
      "loss": 0.0003,
      "step": 78430
    },
    {
      "epoch": 24.20240666460969,
      "grad_norm": 0.0006859804852865636,
      "learning_rate": 2.5797593335390315e-05,
      "loss": 0.0001,
      "step": 78440
    },
    {
      "epoch": 24.20549213205801,
      "grad_norm": 0.27064090967178345,
      "learning_rate": 2.5794507867941997e-05,
      "loss": 0.0001,
      "step": 78450
    },
    {
      "epoch": 24.208577599506324,
      "grad_norm": 0.26709291338920593,
      "learning_rate": 2.5791422400493676e-05,
      "loss": 0.0038,
      "step": 78460
    },
    {
      "epoch": 24.211663066954642,
      "grad_norm": 0.0006437141564674675,
      "learning_rate": 2.578833693304536e-05,
      "loss": 0.0,
      "step": 78470
    },
    {
      "epoch": 24.21474853440296,
      "grad_norm": 0.005114779341965914,
      "learning_rate": 2.5785251465597038e-05,
      "loss": 0.0,
      "step": 78480
    },
    {
      "epoch": 24.21783400185128,
      "grad_norm": 0.0011123251169919968,
      "learning_rate": 2.578216599814872e-05,
      "loss": 0.0002,
      "step": 78490
    },
    {
      "epoch": 24.2209194692996,
      "grad_norm": 0.00028223852859809995,
      "learning_rate": 2.57790805307004e-05,
      "loss": 0.0005,
      "step": 78500
    },
    {
      "epoch": 24.224004936747917,
      "grad_norm": 0.02446642331779003,
      "learning_rate": 2.5775995063252085e-05,
      "loss": 0.0001,
      "step": 78510
    },
    {
      "epoch": 24.227090404196236,
      "grad_norm": 0.00013553792086895555,
      "learning_rate": 2.5772909595803768e-05,
      "loss": 0.0001,
      "step": 78520
    },
    {
      "epoch": 24.230175871644555,
      "grad_norm": 0.0018592511769384146,
      "learning_rate": 2.5769824128355447e-05,
      "loss": 0.0,
      "step": 78530
    },
    {
      "epoch": 24.233261339092873,
      "grad_norm": 4.429744876688346e-06,
      "learning_rate": 2.576673866090713e-05,
      "loss": 0.0024,
      "step": 78540
    },
    {
      "epoch": 24.236346806541192,
      "grad_norm": 0.0006733008776791394,
      "learning_rate": 2.576365319345881e-05,
      "loss": 0.0001,
      "step": 78550
    },
    {
      "epoch": 24.23943227398951,
      "grad_norm": 0.0006319545791484416,
      "learning_rate": 2.5760567726010494e-05,
      "loss": 0.0,
      "step": 78560
    },
    {
      "epoch": 24.242517741437826,
      "grad_norm": 0.2675611078739166,
      "learning_rate": 2.575748225856217e-05,
      "loss": 0.0003,
      "step": 78570
    },
    {
      "epoch": 24.245603208886145,
      "grad_norm": 5.119991783431033e-06,
      "learning_rate": 2.5754396791113856e-05,
      "loss": 0.0001,
      "step": 78580
    },
    {
      "epoch": 24.248688676334464,
      "grad_norm": 0.00015742519462946802,
      "learning_rate": 2.5751311323665538e-05,
      "loss": 0.0008,
      "step": 78590
    },
    {
      "epoch": 24.251774143782782,
      "grad_norm": 0.0003332819906063378,
      "learning_rate": 2.5748225856217217e-05,
      "loss": 0.0,
      "step": 78600
    },
    {
      "epoch": 24.2548596112311,
      "grad_norm": 8.943170541897416e-06,
      "learning_rate": 2.57451403887689e-05,
      "loss": 0.0,
      "step": 78610
    },
    {
      "epoch": 24.25794507867942,
      "grad_norm": 0.002745137084275484,
      "learning_rate": 2.574205492132058e-05,
      "loss": 0.0003,
      "step": 78620
    },
    {
      "epoch": 24.26103054612774,
      "grad_norm": 0.000702489516697824,
      "learning_rate": 2.5738969453872265e-05,
      "loss": 0.0001,
      "step": 78630
    },
    {
      "epoch": 24.264116013576057,
      "grad_norm": 0.0008979924605228007,
      "learning_rate": 2.573588398642394e-05,
      "loss": 0.0,
      "step": 78640
    },
    {
      "epoch": 24.267201481024376,
      "grad_norm": 0.00010437534365337342,
      "learning_rate": 2.5732798518975626e-05,
      "loss": 0.0001,
      "step": 78650
    },
    {
      "epoch": 24.270286948472695,
      "grad_norm": 0.0001824478094931692,
      "learning_rate": 2.572971305152731e-05,
      "loss": 0.0001,
      "step": 78660
    },
    {
      "epoch": 24.273372415921013,
      "grad_norm": 0.048162464052438736,
      "learning_rate": 2.5726627584078988e-05,
      "loss": 0.0001,
      "step": 78670
    },
    {
      "epoch": 24.276457883369332,
      "grad_norm": 0.03241054341197014,
      "learning_rate": 2.5723542116630674e-05,
      "loss": 0.0,
      "step": 78680
    },
    {
      "epoch": 24.279543350817647,
      "grad_norm": 0.0013288728659972548,
      "learning_rate": 2.572045664918235e-05,
      "loss": 0.0002,
      "step": 78690
    },
    {
      "epoch": 24.282628818265966,
      "grad_norm": 0.00019802605675067753,
      "learning_rate": 2.5717371181734035e-05,
      "loss": 0.0012,
      "step": 78700
    },
    {
      "epoch": 24.285714285714285,
      "grad_norm": 0.3115522861480713,
      "learning_rate": 2.5714285714285714e-05,
      "loss": 0.0003,
      "step": 78710
    },
    {
      "epoch": 24.288799753162603,
      "grad_norm": 9.418190529686399e-06,
      "learning_rate": 2.5711200246837397e-05,
      "loss": 0.0,
      "step": 78720
    },
    {
      "epoch": 24.291885220610922,
      "grad_norm": 0.00012229134154040366,
      "learning_rate": 2.570811477938908e-05,
      "loss": 0.0,
      "step": 78730
    },
    {
      "epoch": 24.29497068805924,
      "grad_norm": 5.943251744611189e-05,
      "learning_rate": 2.570502931194076e-05,
      "loss": 0.0,
      "step": 78740
    },
    {
      "epoch": 24.29805615550756,
      "grad_norm": 0.00027755944756790996,
      "learning_rate": 2.5701943844492444e-05,
      "loss": 0.0,
      "step": 78750
    },
    {
      "epoch": 24.30114162295588,
      "grad_norm": 4.042733053211123e-05,
      "learning_rate": 2.569885837704412e-05,
      "loss": 0.0001,
      "step": 78760
    },
    {
      "epoch": 24.304227090404197,
      "grad_norm": 0.0008160198922269046,
      "learning_rate": 2.5695772909595806e-05,
      "loss": 0.0024,
      "step": 78770
    },
    {
      "epoch": 24.307312557852516,
      "grad_norm": 0.2296980619430542,
      "learning_rate": 2.5692687442147485e-05,
      "loss": 0.0008,
      "step": 78780
    },
    {
      "epoch": 24.310398025300834,
      "grad_norm": 4.3098566493426915e-08,
      "learning_rate": 2.5689601974699167e-05,
      "loss": 0.0001,
      "step": 78790
    },
    {
      "epoch": 24.313483492749153,
      "grad_norm": 6.183416189742275e-06,
      "learning_rate": 2.5686516507250853e-05,
      "loss": 0.0,
      "step": 78800
    },
    {
      "epoch": 24.31656896019747,
      "grad_norm": 7.586512947455049e-05,
      "learning_rate": 2.568343103980253e-05,
      "loss": 0.0,
      "step": 78810
    },
    {
      "epoch": 24.319654427645787,
      "grad_norm": 0.0007840615580789745,
      "learning_rate": 2.5680345572354215e-05,
      "loss": 0.0002,
      "step": 78820
    },
    {
      "epoch": 24.322739895094106,
      "grad_norm": 0.004453153815120459,
      "learning_rate": 2.5677260104905894e-05,
      "loss": 0.0,
      "step": 78830
    },
    {
      "epoch": 24.325825362542425,
      "grad_norm": 4.82433897559531e-05,
      "learning_rate": 2.5674174637457576e-05,
      "loss": 0.0001,
      "step": 78840
    },
    {
      "epoch": 24.328910829990743,
      "grad_norm": 8.910885662771761e-05,
      "learning_rate": 2.567108917000926e-05,
      "loss": 0.0,
      "step": 78850
    },
    {
      "epoch": 24.331996297439062,
      "grad_norm": 0.0005264219362288713,
      "learning_rate": 2.5668003702560938e-05,
      "loss": 0.0001,
      "step": 78860
    },
    {
      "epoch": 24.33508176488738,
      "grad_norm": 1.004268506221706e-05,
      "learning_rate": 2.5664918235112624e-05,
      "loss": 0.001,
      "step": 78870
    },
    {
      "epoch": 24.3381672323357,
      "grad_norm": 3.89786578125495e-07,
      "learning_rate": 2.56618327676643e-05,
      "loss": 0.0,
      "step": 78880
    },
    {
      "epoch": 24.341252699784018,
      "grad_norm": 0.03413359075784683,
      "learning_rate": 2.5658747300215985e-05,
      "loss": 0.0007,
      "step": 78890
    },
    {
      "epoch": 24.344338167232337,
      "grad_norm": 3.3112341043306515e-05,
      "learning_rate": 2.5655661832767665e-05,
      "loss": 0.0,
      "step": 78900
    },
    {
      "epoch": 24.347423634680656,
      "grad_norm": 2.9448914574459195e-05,
      "learning_rate": 2.5652576365319347e-05,
      "loss": 0.0,
      "step": 78910
    },
    {
      "epoch": 24.35050910212897,
      "grad_norm": 0.008708024397492409,
      "learning_rate": 2.5649490897871033e-05,
      "loss": 0.0,
      "step": 78920
    },
    {
      "epoch": 24.35359456957729,
      "grad_norm": 0.041844770312309265,
      "learning_rate": 2.564640543042271e-05,
      "loss": 0.0,
      "step": 78930
    },
    {
      "epoch": 24.35668003702561,
      "grad_norm": 0.001260228338651359,
      "learning_rate": 2.5643319962974394e-05,
      "loss": 0.0004,
      "step": 78940
    },
    {
      "epoch": 24.359765504473927,
      "grad_norm": 0.0014516862574964762,
      "learning_rate": 2.5640234495526074e-05,
      "loss": 0.0001,
      "step": 78950
    },
    {
      "epoch": 24.362850971922246,
      "grad_norm": 0.0011191059602424502,
      "learning_rate": 2.5637149028077756e-05,
      "loss": 0.0,
      "step": 78960
    },
    {
      "epoch": 24.365936439370564,
      "grad_norm": 0.12429169565439224,
      "learning_rate": 2.5634063560629435e-05,
      "loss": 0.0001,
      "step": 78970
    },
    {
      "epoch": 24.369021906818883,
      "grad_norm": 0.0010881319176405668,
      "learning_rate": 2.5630978093181118e-05,
      "loss": 0.0003,
      "step": 78980
    },
    {
      "epoch": 24.372107374267202,
      "grad_norm": 0.004254819825291634,
      "learning_rate": 2.5627892625732803e-05,
      "loss": 0.0,
      "step": 78990
    },
    {
      "epoch": 24.37519284171552,
      "grad_norm": 9.88324245554395e-05,
      "learning_rate": 2.562480715828448e-05,
      "loss": 0.0,
      "step": 79000
    },
    {
      "epoch": 24.37827830916384,
      "grad_norm": 0.0005527884932234883,
      "learning_rate": 2.5621721690836165e-05,
      "loss": 0.0042,
      "step": 79010
    },
    {
      "epoch": 24.381363776612158,
      "grad_norm": 0.0001620378898223862,
      "learning_rate": 2.5618636223387844e-05,
      "loss": 0.0001,
      "step": 79020
    },
    {
      "epoch": 24.384449244060477,
      "grad_norm": 0.0009992439299821854,
      "learning_rate": 2.5615550755939527e-05,
      "loss": 0.0001,
      "step": 79030
    },
    {
      "epoch": 24.387534711508792,
      "grad_norm": 1.6162772226380184e-05,
      "learning_rate": 2.5612465288491206e-05,
      "loss": 0.0,
      "step": 79040
    },
    {
      "epoch": 24.39062017895711,
      "grad_norm": 2.0919749658787623e-05,
      "learning_rate": 2.5609379821042888e-05,
      "loss": 0.0,
      "step": 79050
    },
    {
      "epoch": 24.39370564640543,
      "grad_norm": 0.06638208031654358,
      "learning_rate": 2.5606294353594574e-05,
      "loss": 0.0,
      "step": 79060
    },
    {
      "epoch": 24.396791113853748,
      "grad_norm": 5.953378422418609e-05,
      "learning_rate": 2.5603208886146253e-05,
      "loss": 0.0,
      "step": 79070
    },
    {
      "epoch": 24.399876581302067,
      "grad_norm": 2.296081765962299e-05,
      "learning_rate": 2.5600123418697936e-05,
      "loss": 0.0007,
      "step": 79080
    },
    {
      "epoch": 24.402962048750386,
      "grad_norm": 0.0005393693572841585,
      "learning_rate": 2.5597037951249615e-05,
      "loss": 0.0,
      "step": 79090
    },
    {
      "epoch": 24.406047516198704,
      "grad_norm": 4.231751063343836e-06,
      "learning_rate": 2.5593952483801297e-05,
      "loss": 0.0,
      "step": 79100
    },
    {
      "epoch": 24.409132983647023,
      "grad_norm": 0.0028562811203300953,
      "learning_rate": 2.5590867016352976e-05,
      "loss": 0.0,
      "step": 79110
    },
    {
      "epoch": 24.41221845109534,
      "grad_norm": 2.931296421593288e-06,
      "learning_rate": 2.558778154890466e-05,
      "loss": 0.0023,
      "step": 79120
    },
    {
      "epoch": 24.41530391854366,
      "grad_norm": 0.0016484447987750173,
      "learning_rate": 2.5584696081456345e-05,
      "loss": 0.0094,
      "step": 79130
    },
    {
      "epoch": 24.41838938599198,
      "grad_norm": 0.001171564101241529,
      "learning_rate": 2.5581610614008024e-05,
      "loss": 0.0002,
      "step": 79140
    },
    {
      "epoch": 24.421474853440298,
      "grad_norm": 1.805723695724737e-05,
      "learning_rate": 2.5578525146559706e-05,
      "loss": 0.0,
      "step": 79150
    },
    {
      "epoch": 24.424560320888613,
      "grad_norm": 0.0059138452634215355,
      "learning_rate": 2.5575439679111385e-05,
      "loss": 0.0012,
      "step": 79160
    },
    {
      "epoch": 24.427645788336932,
      "grad_norm": 3.0975003028288484e-05,
      "learning_rate": 2.5572354211663068e-05,
      "loss": 0.0022,
      "step": 79170
    },
    {
      "epoch": 24.43073125578525,
      "grad_norm": 0.00018600789189804345,
      "learning_rate": 2.5569268744214747e-05,
      "loss": 0.0033,
      "step": 79180
    },
    {
      "epoch": 24.43381672323357,
      "grad_norm": 0.0010869137477129698,
      "learning_rate": 2.5566183276766433e-05,
      "loss": 0.0002,
      "step": 79190
    },
    {
      "epoch": 24.436902190681888,
      "grad_norm": 3.468839850029326e-06,
      "learning_rate": 2.5563097809318115e-05,
      "loss": 0.0075,
      "step": 79200
    },
    {
      "epoch": 24.439987658130207,
      "grad_norm": 0.00022551248548552394,
      "learning_rate": 2.5560012341869794e-05,
      "loss": 0.0007,
      "step": 79210
    },
    {
      "epoch": 24.443073125578525,
      "grad_norm": 0.04787546768784523,
      "learning_rate": 2.5556926874421477e-05,
      "loss": 0.0002,
      "step": 79220
    },
    {
      "epoch": 24.446158593026844,
      "grad_norm": 0.0001788936642697081,
      "learning_rate": 2.5553841406973156e-05,
      "loss": 0.0003,
      "step": 79230
    },
    {
      "epoch": 24.449244060475163,
      "grad_norm": 6.217097688931972e-05,
      "learning_rate": 2.5550755939524838e-05,
      "loss": 0.0025,
      "step": 79240
    },
    {
      "epoch": 24.45232952792348,
      "grad_norm": 1.5447927580680698e-05,
      "learning_rate": 2.5547670472076517e-05,
      "loss": 0.0,
      "step": 79250
    },
    {
      "epoch": 24.4554149953718,
      "grad_norm": 0.1528434157371521,
      "learning_rate": 2.5544585004628203e-05,
      "loss": 0.0001,
      "step": 79260
    },
    {
      "epoch": 24.45850046282012,
      "grad_norm": 0.0014934256905689836,
      "learning_rate": 2.5541499537179886e-05,
      "loss": 0.0001,
      "step": 79270
    },
    {
      "epoch": 24.461585930268434,
      "grad_norm": 0.0002354724274482578,
      "learning_rate": 2.5538414069731565e-05,
      "loss": 0.0,
      "step": 79280
    },
    {
      "epoch": 24.464671397716753,
      "grad_norm": 4.232194896758301e-06,
      "learning_rate": 2.5535328602283247e-05,
      "loss": 0.0,
      "step": 79290
    },
    {
      "epoch": 24.46775686516507,
      "grad_norm": 6.674323958577588e-05,
      "learning_rate": 2.5532243134834926e-05,
      "loss": 0.0,
      "step": 79300
    },
    {
      "epoch": 24.47084233261339,
      "grad_norm": 0.8316497802734375,
      "learning_rate": 2.5529157667386612e-05,
      "loss": 0.0005,
      "step": 79310
    },
    {
      "epoch": 24.47392780006171,
      "grad_norm": 0.0007404753705486655,
      "learning_rate": 2.5526072199938295e-05,
      "loss": 0.0005,
      "step": 79320
    },
    {
      "epoch": 24.477013267510028,
      "grad_norm": 0.000381410209229216,
      "learning_rate": 2.5522986732489974e-05,
      "loss": 0.0,
      "step": 79330
    },
    {
      "epoch": 24.480098734958347,
      "grad_norm": 0.00015197580796666443,
      "learning_rate": 2.5519901265041656e-05,
      "loss": 0.003,
      "step": 79340
    },
    {
      "epoch": 24.483184202406665,
      "grad_norm": 0.013851667754352093,
      "learning_rate": 2.5516815797593335e-05,
      "loss": 0.0001,
      "step": 79350
    },
    {
      "epoch": 24.486269669854984,
      "grad_norm": 3.121971303698956e-06,
      "learning_rate": 2.5513730330145018e-05,
      "loss": 0.0023,
      "step": 79360
    },
    {
      "epoch": 24.489355137303303,
      "grad_norm": 0.007163361646234989,
      "learning_rate": 2.5510644862696697e-05,
      "loss": 0.0001,
      "step": 79370
    },
    {
      "epoch": 24.49244060475162,
      "grad_norm": 3.242553066229448e-05,
      "learning_rate": 2.5507559395248383e-05,
      "loss": 0.0003,
      "step": 79380
    },
    {
      "epoch": 24.495526072199937,
      "grad_norm": 0.0043855393305420876,
      "learning_rate": 2.5504473927800065e-05,
      "loss": 0.0026,
      "step": 79390
    },
    {
      "epoch": 24.498611539648255,
      "grad_norm": 3.896485395671334e-06,
      "learning_rate": 2.5501388460351744e-05,
      "loss": 0.0002,
      "step": 79400
    },
    {
      "epoch": 24.501697007096574,
      "grad_norm": 1.6793512105941772,
      "learning_rate": 2.5498302992903427e-05,
      "loss": 0.0072,
      "step": 79410
    },
    {
      "epoch": 24.504782474544893,
      "grad_norm": 3.712766556418501e-05,
      "learning_rate": 2.5495217525455106e-05,
      "loss": 0.0,
      "step": 79420
    },
    {
      "epoch": 24.50786794199321,
      "grad_norm": 0.0002581971057225019,
      "learning_rate": 2.5492132058006792e-05,
      "loss": 0.0,
      "step": 79430
    },
    {
      "epoch": 24.51095340944153,
      "grad_norm": 4.5303902879823e-05,
      "learning_rate": 2.5489046590558468e-05,
      "loss": 0.0001,
      "step": 79440
    },
    {
      "epoch": 24.51403887688985,
      "grad_norm": 4.381683083920507e-06,
      "learning_rate": 2.5485961123110153e-05,
      "loss": 0.0,
      "step": 79450
    },
    {
      "epoch": 24.517124344338168,
      "grad_norm": 0.00018255658505950123,
      "learning_rate": 2.5482875655661836e-05,
      "loss": 0.002,
      "step": 79460
    },
    {
      "epoch": 24.520209811786486,
      "grad_norm": 2.3931961550260894e-05,
      "learning_rate": 2.5479790188213515e-05,
      "loss": 0.0005,
      "step": 79470
    },
    {
      "epoch": 24.523295279234805,
      "grad_norm": 0.0001324794429820031,
      "learning_rate": 2.5476704720765197e-05,
      "loss": 0.0,
      "step": 79480
    },
    {
      "epoch": 24.526380746683124,
      "grad_norm": 5.420963589131134e-06,
      "learning_rate": 2.5473619253316877e-05,
      "loss": 0.0001,
      "step": 79490
    },
    {
      "epoch": 24.529466214131443,
      "grad_norm": 0.0013363590696826577,
      "learning_rate": 2.5470533785868562e-05,
      "loss": 0.0,
      "step": 79500
    },
    {
      "epoch": 24.532551681579758,
      "grad_norm": 4.8081665227073245e-06,
      "learning_rate": 2.5467448318420238e-05,
      "loss": 0.0001,
      "step": 79510
    },
    {
      "epoch": 24.535637149028076,
      "grad_norm": 1.8810638721333817e-05,
      "learning_rate": 2.5464362850971924e-05,
      "loss": 0.005,
      "step": 79520
    },
    {
      "epoch": 24.538722616476395,
      "grad_norm": 0.11930321156978607,
      "learning_rate": 2.5461277383523606e-05,
      "loss": 0.0001,
      "step": 79530
    },
    {
      "epoch": 24.541808083924714,
      "grad_norm": 2.9987852485646727e-06,
      "learning_rate": 2.5458191916075286e-05,
      "loss": 0.0016,
      "step": 79540
    },
    {
      "epoch": 24.544893551373033,
      "grad_norm": 3.87718955607852e-06,
      "learning_rate": 2.545510644862697e-05,
      "loss": 0.0006,
      "step": 79550
    },
    {
      "epoch": 24.54797901882135,
      "grad_norm": 0.00023034456535242498,
      "learning_rate": 2.5452020981178647e-05,
      "loss": 0.0029,
      "step": 79560
    },
    {
      "epoch": 24.55106448626967,
      "grad_norm": 0.07795164734125137,
      "learning_rate": 2.5448935513730333e-05,
      "loss": 0.0018,
      "step": 79570
    },
    {
      "epoch": 24.55414995371799,
      "grad_norm": 0.000590714393183589,
      "learning_rate": 2.5445850046282012e-05,
      "loss": 0.0001,
      "step": 79580
    },
    {
      "epoch": 24.557235421166308,
      "grad_norm": 1.7615072920307284e-06,
      "learning_rate": 2.5442764578833695e-05,
      "loss": 0.0,
      "step": 79590
    },
    {
      "epoch": 24.560320888614626,
      "grad_norm": 9.287951252190396e-05,
      "learning_rate": 2.5439679111385377e-05,
      "loss": 0.0006,
      "step": 79600
    },
    {
      "epoch": 24.563406356062945,
      "grad_norm": 0.0005337707116268575,
      "learning_rate": 2.5436593643937056e-05,
      "loss": 0.0119,
      "step": 79610
    },
    {
      "epoch": 24.566491823511264,
      "grad_norm": 0.0009756570216268301,
      "learning_rate": 2.5433508176488742e-05,
      "loss": 0.001,
      "step": 79620
    },
    {
      "epoch": 24.56957729095958,
      "grad_norm": 0.000505296338815242,
      "learning_rate": 2.5430422709040418e-05,
      "loss": 0.0004,
      "step": 79630
    },
    {
      "epoch": 24.572662758407898,
      "grad_norm": 0.0005936417728662491,
      "learning_rate": 2.5427337241592103e-05,
      "loss": 0.0031,
      "step": 79640
    },
    {
      "epoch": 24.575748225856216,
      "grad_norm": 0.022568395361304283,
      "learning_rate": 2.5424251774143783e-05,
      "loss": 0.0001,
      "step": 79650
    },
    {
      "epoch": 24.578833693304535,
      "grad_norm": 0.00014750218542758375,
      "learning_rate": 2.5421166306695465e-05,
      "loss": 0.0,
      "step": 79660
    },
    {
      "epoch": 24.581919160752854,
      "grad_norm": 0.00010006738739321008,
      "learning_rate": 2.5418080839247148e-05,
      "loss": 0.0,
      "step": 79670
    },
    {
      "epoch": 24.585004628201172,
      "grad_norm": 0.0001908936828840524,
      "learning_rate": 2.5414995371798827e-05,
      "loss": 0.0,
      "step": 79680
    },
    {
      "epoch": 24.58809009564949,
      "grad_norm": 0.00019603531109169126,
      "learning_rate": 2.5411909904350512e-05,
      "loss": 0.0,
      "step": 79690
    },
    {
      "epoch": 24.59117556309781,
      "grad_norm": 0.0001355936547042802,
      "learning_rate": 2.540882443690219e-05,
      "loss": 0.0005,
      "step": 79700
    },
    {
      "epoch": 24.59426103054613,
      "grad_norm": 0.026507588103413582,
      "learning_rate": 2.5405738969453874e-05,
      "loss": 0.0003,
      "step": 79710
    },
    {
      "epoch": 24.597346497994447,
      "grad_norm": 0.0004556881613098085,
      "learning_rate": 2.5402653502005557e-05,
      "loss": 0.0,
      "step": 79720
    },
    {
      "epoch": 24.600431965442766,
      "grad_norm": 0.00023738689196761698,
      "learning_rate": 2.5399568034557236e-05,
      "loss": 0.0,
      "step": 79730
    },
    {
      "epoch": 24.60351743289108,
      "grad_norm": 1.455018536944408e-05,
      "learning_rate": 2.539648256710892e-05,
      "loss": 0.0001,
      "step": 79740
    },
    {
      "epoch": 24.6066029003394,
      "grad_norm": 0.002870083088055253,
      "learning_rate": 2.5393397099660597e-05,
      "loss": 0.0011,
      "step": 79750
    },
    {
      "epoch": 24.60968836778772,
      "grad_norm": 7.688137702643871e-05,
      "learning_rate": 2.5390311632212283e-05,
      "loss": 0.0001,
      "step": 79760
    },
    {
      "epoch": 24.612773835236037,
      "grad_norm": 0.08936475217342377,
      "learning_rate": 2.5387226164763962e-05,
      "loss": 0.0001,
      "step": 79770
    },
    {
      "epoch": 24.615859302684356,
      "grad_norm": 6.79672448313795e-05,
      "learning_rate": 2.5384140697315645e-05,
      "loss": 0.0014,
      "step": 79780
    },
    {
      "epoch": 24.618944770132675,
      "grad_norm": 0.1271173059940338,
      "learning_rate": 2.5381055229867327e-05,
      "loss": 0.0001,
      "step": 79790
    },
    {
      "epoch": 24.622030237580994,
      "grad_norm": 0.005737944506108761,
      "learning_rate": 2.5377969762419006e-05,
      "loss": 0.0008,
      "step": 79800
    },
    {
      "epoch": 24.625115705029312,
      "grad_norm": 0.00012828999024350196,
      "learning_rate": 2.5374884294970692e-05,
      "loss": 0.0011,
      "step": 79810
    },
    {
      "epoch": 24.62820117247763,
      "grad_norm": 0.0006943036569282413,
      "learning_rate": 2.537179882752237e-05,
      "loss": 0.0,
      "step": 79820
    },
    {
      "epoch": 24.63128663992595,
      "grad_norm": 0.036241646856069565,
      "learning_rate": 2.5368713360074054e-05,
      "loss": 0.0001,
      "step": 79830
    },
    {
      "epoch": 24.63437210737427,
      "grad_norm": 0.0019572617020457983,
      "learning_rate": 2.5365627892625733e-05,
      "loss": 0.0001,
      "step": 79840
    },
    {
      "epoch": 24.637457574822587,
      "grad_norm": 0.0038635486271232367,
      "learning_rate": 2.5362542425177415e-05,
      "loss": 0.0003,
      "step": 79850
    },
    {
      "epoch": 24.640543042270902,
      "grad_norm": 0.008055304177105427,
      "learning_rate": 2.53594569577291e-05,
      "loss": 0.0001,
      "step": 79860
    },
    {
      "epoch": 24.64362850971922,
      "grad_norm": 2.5410070065845503e-06,
      "learning_rate": 2.5356371490280777e-05,
      "loss": 0.0001,
      "step": 79870
    },
    {
      "epoch": 24.64671397716754,
      "grad_norm": 0.003939379006624222,
      "learning_rate": 2.5353286022832463e-05,
      "loss": 0.0,
      "step": 79880
    },
    {
      "epoch": 24.64979944461586,
      "grad_norm": 0.0007227198220789433,
      "learning_rate": 2.5350200555384142e-05,
      "loss": 0.0,
      "step": 79890
    },
    {
      "epoch": 24.652884912064177,
      "grad_norm": 0.015302566811442375,
      "learning_rate": 2.5347115087935824e-05,
      "loss": 0.0,
      "step": 79900
    },
    {
      "epoch": 24.655970379512496,
      "grad_norm": 0.0017010757001116872,
      "learning_rate": 2.5344029620487503e-05,
      "loss": 0.0,
      "step": 79910
    },
    {
      "epoch": 24.659055846960815,
      "grad_norm": 1.5656436517019756e-05,
      "learning_rate": 2.5340944153039186e-05,
      "loss": 0.0,
      "step": 79920
    },
    {
      "epoch": 24.662141314409133,
      "grad_norm": 0.6041070818901062,
      "learning_rate": 2.533785868559087e-05,
      "loss": 0.0002,
      "step": 79930
    },
    {
      "epoch": 24.665226781857452,
      "grad_norm": 0.0021984437480568886,
      "learning_rate": 2.5334773218142547e-05,
      "loss": 0.0,
      "step": 79940
    },
    {
      "epoch": 24.66831224930577,
      "grad_norm": 1.0631299018859863,
      "learning_rate": 2.5331687750694233e-05,
      "loss": 0.0007,
      "step": 79950
    },
    {
      "epoch": 24.67139771675409,
      "grad_norm": 2.2816284399596043e-05,
      "learning_rate": 2.5328602283245912e-05,
      "loss": 0.0,
      "step": 79960
    },
    {
      "epoch": 24.67448318420241,
      "grad_norm": 0.0005778138875029981,
      "learning_rate": 2.5325516815797595e-05,
      "loss": 0.0001,
      "step": 79970
    },
    {
      "epoch": 24.677568651650724,
      "grad_norm": 0.005545427091419697,
      "learning_rate": 2.5322431348349274e-05,
      "loss": 0.0003,
      "step": 79980
    },
    {
      "epoch": 24.680654119099042,
      "grad_norm": 3.1825136829866096e-05,
      "learning_rate": 2.5319345880900956e-05,
      "loss": 0.0,
      "step": 79990
    },
    {
      "epoch": 24.68373958654736,
      "grad_norm": 2.4710967409191653e-05,
      "learning_rate": 2.5316260413452642e-05,
      "loss": 0.0006,
      "step": 80000
    },
    {
      "epoch": 24.68682505399568,
      "grad_norm": 0.00039786359411664307,
      "learning_rate": 2.531317494600432e-05,
      "loss": 0.0,
      "step": 80010
    },
    {
      "epoch": 24.689910521444,
      "grad_norm": 0.00015624442312400788,
      "learning_rate": 2.5310089478556004e-05,
      "loss": 0.0002,
      "step": 80020
    },
    {
      "epoch": 24.692995988892317,
      "grad_norm": 0.0006996787269599736,
      "learning_rate": 2.5307004011107683e-05,
      "loss": 0.0,
      "step": 80030
    },
    {
      "epoch": 24.696081456340636,
      "grad_norm": 0.0003855302929878235,
      "learning_rate": 2.5303918543659365e-05,
      "loss": 0.0002,
      "step": 80040
    },
    {
      "epoch": 24.699166923788955,
      "grad_norm": 0.00013199934619478881,
      "learning_rate": 2.5300833076211044e-05,
      "loss": 0.0,
      "step": 80050
    },
    {
      "epoch": 24.702252391237273,
      "grad_norm": 0.6069956421852112,
      "learning_rate": 2.5297747608762727e-05,
      "loss": 0.0003,
      "step": 80060
    },
    {
      "epoch": 24.705337858685592,
      "grad_norm": 0.0025981534272432327,
      "learning_rate": 2.5294662141314413e-05,
      "loss": 0.0001,
      "step": 80070
    },
    {
      "epoch": 24.70842332613391,
      "grad_norm": 0.08356688916683197,
      "learning_rate": 2.5291576673866092e-05,
      "loss": 0.0001,
      "step": 80080
    },
    {
      "epoch": 24.711508793582226,
      "grad_norm": 0.008146646432578564,
      "learning_rate": 2.5288491206417774e-05,
      "loss": 0.0,
      "step": 80090
    },
    {
      "epoch": 24.714594261030545,
      "grad_norm": 0.0002057594247162342,
      "learning_rate": 2.5285405738969453e-05,
      "loss": 0.0,
      "step": 80100
    },
    {
      "epoch": 24.717679728478863,
      "grad_norm": 0.00665058009326458,
      "learning_rate": 2.5282320271521136e-05,
      "loss": 0.001,
      "step": 80110
    },
    {
      "epoch": 24.720765195927182,
      "grad_norm": 0.0001626250013941899,
      "learning_rate": 2.5279234804072815e-05,
      "loss": 0.0034,
      "step": 80120
    },
    {
      "epoch": 24.7238506633755,
      "grad_norm": 0.00028589984867721796,
      "learning_rate": 2.52761493366245e-05,
      "loss": 0.0,
      "step": 80130
    },
    {
      "epoch": 24.72693613082382,
      "grad_norm": 3.8734662666684017e-05,
      "learning_rate": 2.5273063869176183e-05,
      "loss": 0.004,
      "step": 80140
    },
    {
      "epoch": 24.73002159827214,
      "grad_norm": 0.0005209889495745301,
      "learning_rate": 2.5269978401727862e-05,
      "loss": 0.0,
      "step": 80150
    },
    {
      "epoch": 24.733107065720457,
      "grad_norm": 0.3686469793319702,
      "learning_rate": 2.5266892934279545e-05,
      "loss": 0.0007,
      "step": 80160
    },
    {
      "epoch": 24.736192533168776,
      "grad_norm": 0.005721920635551214,
      "learning_rate": 2.5263807466831224e-05,
      "loss": 0.0,
      "step": 80170
    },
    {
      "epoch": 24.739278000617094,
      "grad_norm": 0.0003964859643019736,
      "learning_rate": 2.5260721999382906e-05,
      "loss": 0.0016,
      "step": 80180
    },
    {
      "epoch": 24.742363468065413,
      "grad_norm": 0.18763883411884308,
      "learning_rate": 2.5257636531934592e-05,
      "loss": 0.0006,
      "step": 80190
    },
    {
      "epoch": 24.745448935513732,
      "grad_norm": 0.00024194068100769073,
      "learning_rate": 2.525455106448627e-05,
      "loss": 0.0001,
      "step": 80200
    },
    {
      "epoch": 24.748534402962047,
      "grad_norm": 0.00504321651533246,
      "learning_rate": 2.5251465597037954e-05,
      "loss": 0.0001,
      "step": 80210
    },
    {
      "epoch": 24.751619870410366,
      "grad_norm": 4.106704000150785e-05,
      "learning_rate": 2.5248380129589633e-05,
      "loss": 0.0002,
      "step": 80220
    },
    {
      "epoch": 24.754705337858685,
      "grad_norm": 7.901891876826994e-06,
      "learning_rate": 2.5245294662141315e-05,
      "loss": 0.0011,
      "step": 80230
    },
    {
      "epoch": 24.757790805307003,
      "grad_norm": 1.0314072824257892e-05,
      "learning_rate": 2.5242209194692995e-05,
      "loss": 0.0,
      "step": 80240
    },
    {
      "epoch": 24.760876272755322,
      "grad_norm": 0.010607929900288582,
      "learning_rate": 2.523912372724468e-05,
      "loss": 0.0069,
      "step": 80250
    },
    {
      "epoch": 24.76396174020364,
      "grad_norm": 0.0003251733724027872,
      "learning_rate": 2.5236038259796363e-05,
      "loss": 0.0002,
      "step": 80260
    },
    {
      "epoch": 24.76704720765196,
      "grad_norm": 2.211687205999624e-05,
      "learning_rate": 2.5232952792348042e-05,
      "loss": 0.0,
      "step": 80270
    },
    {
      "epoch": 24.770132675100278,
      "grad_norm": 1.8618439435958862,
      "learning_rate": 2.5229867324899724e-05,
      "loss": 0.0029,
      "step": 80280
    },
    {
      "epoch": 24.773218142548597,
      "grad_norm": 1.9946237443946302e-05,
      "learning_rate": 2.5226781857451404e-05,
      "loss": 0.0002,
      "step": 80290
    },
    {
      "epoch": 24.776303609996916,
      "grad_norm": 3.8740068703191355e-05,
      "learning_rate": 2.5223696390003086e-05,
      "loss": 0.0003,
      "step": 80300
    },
    {
      "epoch": 24.779389077445234,
      "grad_norm": 0.00019348901696503162,
      "learning_rate": 2.5220610922554765e-05,
      "loss": 0.0081,
      "step": 80310
    },
    {
      "epoch": 24.782474544893553,
      "grad_norm": 1.872591269602708e-06,
      "learning_rate": 2.521752545510645e-05,
      "loss": 0.0006,
      "step": 80320
    },
    {
      "epoch": 24.78556001234187,
      "grad_norm": 0.06440805643796921,
      "learning_rate": 2.5214439987658133e-05,
      "loss": 0.0002,
      "step": 80330
    },
    {
      "epoch": 24.788645479790187,
      "grad_norm": 0.0006499610608443618,
      "learning_rate": 2.5211354520209813e-05,
      "loss": 0.0002,
      "step": 80340
    },
    {
      "epoch": 24.791730947238506,
      "grad_norm": 2.676390067790635e-06,
      "learning_rate": 2.5208269052761495e-05,
      "loss": 0.0002,
      "step": 80350
    },
    {
      "epoch": 24.794816414686824,
      "grad_norm": 0.13017195463180542,
      "learning_rate": 2.5205183585313174e-05,
      "loss": 0.0022,
      "step": 80360
    },
    {
      "epoch": 24.797901882135143,
      "grad_norm": 2.329928793187719e-05,
      "learning_rate": 2.520209811786486e-05,
      "loss": 0.0,
      "step": 80370
    },
    {
      "epoch": 24.800987349583462,
      "grad_norm": 0.0006521901814267039,
      "learning_rate": 2.5199012650416536e-05,
      "loss": 0.0001,
      "step": 80380
    },
    {
      "epoch": 24.80407281703178,
      "grad_norm": 0.00015731056919321418,
      "learning_rate": 2.519592718296822e-05,
      "loss": 0.0,
      "step": 80390
    },
    {
      "epoch": 24.8071582844801,
      "grad_norm": 3.976216248702258e-05,
      "learning_rate": 2.5192841715519904e-05,
      "loss": 0.0001,
      "step": 80400
    },
    {
      "epoch": 24.810243751928418,
      "grad_norm": 0.0008855133200995624,
      "learning_rate": 2.5189756248071583e-05,
      "loss": 0.0,
      "step": 80410
    },
    {
      "epoch": 24.813329219376737,
      "grad_norm": 0.00020711508113890886,
      "learning_rate": 2.5186670780623266e-05,
      "loss": 0.0003,
      "step": 80420
    },
    {
      "epoch": 24.816414686825055,
      "grad_norm": 0.005150393582880497,
      "learning_rate": 2.5183585313174945e-05,
      "loss": 0.0044,
      "step": 80430
    },
    {
      "epoch": 24.81950015427337,
      "grad_norm": 3.165697489748709e-05,
      "learning_rate": 2.518049984572663e-05,
      "loss": 0.0098,
      "step": 80440
    },
    {
      "epoch": 24.82258562172169,
      "grad_norm": 2.48108199230046e-06,
      "learning_rate": 2.5177414378278306e-05,
      "loss": 0.0117,
      "step": 80450
    },
    {
      "epoch": 24.825671089170008,
      "grad_norm": 0.0217791348695755,
      "learning_rate": 2.5174328910829992e-05,
      "loss": 0.0,
      "step": 80460
    },
    {
      "epoch": 24.828756556618327,
      "grad_norm": 9.588415559846908e-05,
      "learning_rate": 2.5171243443381675e-05,
      "loss": 0.0001,
      "step": 80470
    },
    {
      "epoch": 24.831842024066646,
      "grad_norm": 2.69893741607666,
      "learning_rate": 2.5168157975933354e-05,
      "loss": 0.0047,
      "step": 80480
    },
    {
      "epoch": 24.834927491514964,
      "grad_norm": 1.5933033864712343e-05,
      "learning_rate": 2.516507250848504e-05,
      "loss": 0.0,
      "step": 80490
    },
    {
      "epoch": 24.838012958963283,
      "grad_norm": 6.211991603777278e-06,
      "learning_rate": 2.5161987041036715e-05,
      "loss": 0.0002,
      "step": 80500
    },
    {
      "epoch": 24.8410984264116,
      "grad_norm": 1.8492477465770207e-05,
      "learning_rate": 2.51589015735884e-05,
      "loss": 0.0001,
      "step": 80510
    },
    {
      "epoch": 24.84418389385992,
      "grad_norm": 0.1515556275844574,
      "learning_rate": 2.515581610614008e-05,
      "loss": 0.0045,
      "step": 80520
    },
    {
      "epoch": 24.84726936130824,
      "grad_norm": 9.212632721755654e-05,
      "learning_rate": 2.5152730638691763e-05,
      "loss": 0.0,
      "step": 80530
    },
    {
      "epoch": 24.850354828756558,
      "grad_norm": 9.377257083542645e-05,
      "learning_rate": 2.5149645171243445e-05,
      "loss": 0.0012,
      "step": 80540
    },
    {
      "epoch": 24.853440296204877,
      "grad_norm": 0.001319073373451829,
      "learning_rate": 2.5146559703795124e-05,
      "loss": 0.0002,
      "step": 80550
    },
    {
      "epoch": 24.85652576365319,
      "grad_norm": 0.00018714294128585607,
      "learning_rate": 2.514347423634681e-05,
      "loss": 0.0003,
      "step": 80560
    },
    {
      "epoch": 24.85961123110151,
      "grad_norm": 3.0773710477660643e-06,
      "learning_rate": 2.5140388768898486e-05,
      "loss": 0.0,
      "step": 80570
    },
    {
      "epoch": 24.86269669854983,
      "grad_norm": 0.029705161228775978,
      "learning_rate": 2.513730330145017e-05,
      "loss": 0.0,
      "step": 80580
    },
    {
      "epoch": 24.865782165998148,
      "grad_norm": 0.009393306449055672,
      "learning_rate": 2.5134217834001854e-05,
      "loss": 0.0,
      "step": 80590
    },
    {
      "epoch": 24.868867633446467,
      "grad_norm": 0.1332019418478012,
      "learning_rate": 2.5131132366553533e-05,
      "loss": 0.0001,
      "step": 80600
    },
    {
      "epoch": 24.871953100894785,
      "grad_norm": 5.790690192952752e-05,
      "learning_rate": 2.512804689910522e-05,
      "loss": 0.0002,
      "step": 80610
    },
    {
      "epoch": 24.875038568343104,
      "grad_norm": 0.01801045797765255,
      "learning_rate": 2.5124961431656895e-05,
      "loss": 0.0001,
      "step": 80620
    },
    {
      "epoch": 24.878124035791423,
      "grad_norm": 0.00011365201498847455,
      "learning_rate": 2.512187596420858e-05,
      "loss": 0.0,
      "step": 80630
    },
    {
      "epoch": 24.88120950323974,
      "grad_norm": 0.8953275680541992,
      "learning_rate": 2.511879049676026e-05,
      "loss": 0.0004,
      "step": 80640
    },
    {
      "epoch": 24.88429497068806,
      "grad_norm": 0.0009447881602682173,
      "learning_rate": 2.5115705029311942e-05,
      "loss": 0.0001,
      "step": 80650
    },
    {
      "epoch": 24.88738043813638,
      "grad_norm": 0.009032887406647205,
      "learning_rate": 2.5112619561863625e-05,
      "loss": 0.0002,
      "step": 80660
    },
    {
      "epoch": 24.890465905584698,
      "grad_norm": 8.714477007742971e-05,
      "learning_rate": 2.5109534094415304e-05,
      "loss": 0.0,
      "step": 80670
    },
    {
      "epoch": 24.893551373033013,
      "grad_norm": 0.8773432970046997,
      "learning_rate": 2.510644862696699e-05,
      "loss": 0.0013,
      "step": 80680
    },
    {
      "epoch": 24.89663684048133,
      "grad_norm": 6.337237573461607e-05,
      "learning_rate": 2.5103363159518665e-05,
      "loss": 0.0056,
      "step": 80690
    },
    {
      "epoch": 24.89972230792965,
      "grad_norm": 0.0013572094030678272,
      "learning_rate": 2.510027769207035e-05,
      "loss": 0.0001,
      "step": 80700
    },
    {
      "epoch": 24.90280777537797,
      "grad_norm": 0.0721406564116478,
      "learning_rate": 2.509719222462203e-05,
      "loss": 0.0004,
      "step": 80710
    },
    {
      "epoch": 24.905893242826288,
      "grad_norm": 0.03830842301249504,
      "learning_rate": 2.5094106757173713e-05,
      "loss": 0.0001,
      "step": 80720
    },
    {
      "epoch": 24.908978710274607,
      "grad_norm": 3.989782999269664e-05,
      "learning_rate": 2.50910212897254e-05,
      "loss": 0.0007,
      "step": 80730
    },
    {
      "epoch": 24.912064177722925,
      "grad_norm": 0.08033517003059387,
      "learning_rate": 2.5087935822277074e-05,
      "loss": 0.0,
      "step": 80740
    },
    {
      "epoch": 24.915149645171244,
      "grad_norm": 0.008928576484322548,
      "learning_rate": 2.508485035482876e-05,
      "loss": 0.0001,
      "step": 80750
    },
    {
      "epoch": 24.918235112619563,
      "grad_norm": 6.4014398958534e-05,
      "learning_rate": 2.508176488738044e-05,
      "loss": 0.0001,
      "step": 80760
    },
    {
      "epoch": 24.92132058006788,
      "grad_norm": 1.5563748092972673e-05,
      "learning_rate": 2.5078679419932122e-05,
      "loss": 0.0,
      "step": 80770
    },
    {
      "epoch": 24.9244060475162,
      "grad_norm": 0.010824226774275303,
      "learning_rate": 2.50755939524838e-05,
      "loss": 0.0,
      "step": 80780
    },
    {
      "epoch": 24.927491514964515,
      "grad_norm": 0.011135045439004898,
      "learning_rate": 2.5072508485035483e-05,
      "loss": 0.0001,
      "step": 80790
    },
    {
      "epoch": 24.930576982412834,
      "grad_norm": 0.08331095427274704,
      "learning_rate": 2.506942301758717e-05,
      "loss": 0.005,
      "step": 80800
    },
    {
      "epoch": 24.933662449861153,
      "grad_norm": 0.013079830445349216,
      "learning_rate": 2.5066337550138845e-05,
      "loss": 0.0072,
      "step": 80810
    },
    {
      "epoch": 24.93674791730947,
      "grad_norm": 0.010762653313577175,
      "learning_rate": 2.506325208269053e-05,
      "loss": 0.0003,
      "step": 80820
    },
    {
      "epoch": 24.93983338475779,
      "grad_norm": 0.06497951596975327,
      "learning_rate": 2.506016661524221e-05,
      "loss": 0.0001,
      "step": 80830
    },
    {
      "epoch": 24.94291885220611,
      "grad_norm": 0.0154871866106987,
      "learning_rate": 2.5057081147793892e-05,
      "loss": 0.0,
      "step": 80840
    },
    {
      "epoch": 24.946004319654428,
      "grad_norm": 1.851864180935081e-05,
      "learning_rate": 2.505399568034557e-05,
      "loss": 0.0001,
      "step": 80850
    },
    {
      "epoch": 24.949089787102746,
      "grad_norm": 0.0015674798050895333,
      "learning_rate": 2.5050910212897254e-05,
      "loss": 0.0003,
      "step": 80860
    },
    {
      "epoch": 24.952175254551065,
      "grad_norm": 0.00039831767207942903,
      "learning_rate": 2.504782474544894e-05,
      "loss": 0.0001,
      "step": 80870
    },
    {
      "epoch": 24.955260721999384,
      "grad_norm": 3.785612716455944e-05,
      "learning_rate": 2.504473927800062e-05,
      "loss": 0.0002,
      "step": 80880
    },
    {
      "epoch": 24.958346189447703,
      "grad_norm": 8.011225531845412e-07,
      "learning_rate": 2.50416538105523e-05,
      "loss": 0.0,
      "step": 80890
    },
    {
      "epoch": 24.96143165689602,
      "grad_norm": 5.255216092336923e-05,
      "learning_rate": 2.503856834310398e-05,
      "loss": 0.0,
      "step": 80900
    },
    {
      "epoch": 24.964517124344336,
      "grad_norm": 0.00022410380188375711,
      "learning_rate": 2.5035482875655663e-05,
      "loss": 0.0004,
      "step": 80910
    },
    {
      "epoch": 24.967602591792655,
      "grad_norm": 0.0002251854311907664,
      "learning_rate": 2.5032397408207342e-05,
      "loss": 0.0001,
      "step": 80920
    },
    {
      "epoch": 24.970688059240974,
      "grad_norm": 0.00010262479190714657,
      "learning_rate": 2.5029311940759024e-05,
      "loss": 0.0002,
      "step": 80930
    },
    {
      "epoch": 24.973773526689293,
      "grad_norm": 1.7659774584899424e-06,
      "learning_rate": 2.502622647331071e-05,
      "loss": 0.002,
      "step": 80940
    },
    {
      "epoch": 24.97685899413761,
      "grad_norm": 3.95197857869789e-05,
      "learning_rate": 2.502314100586239e-05,
      "loss": 0.0001,
      "step": 80950
    },
    {
      "epoch": 24.97994446158593,
      "grad_norm": 0.00338188954629004,
      "learning_rate": 2.5020055538414072e-05,
      "loss": 0.0023,
      "step": 80960
    },
    {
      "epoch": 24.98302992903425,
      "grad_norm": 1.8469011138222413e-06,
      "learning_rate": 2.501697007096575e-05,
      "loss": 0.0001,
      "step": 80970
    },
    {
      "epoch": 24.986115396482568,
      "grad_norm": 2.9614302547997795e-06,
      "learning_rate": 2.5013884603517433e-05,
      "loss": 0.0008,
      "step": 80980
    },
    {
      "epoch": 24.989200863930886,
      "grad_norm": 0.00010983439278788865,
      "learning_rate": 2.5010799136069113e-05,
      "loss": 0.0,
      "step": 80990
    },
    {
      "epoch": 24.992286331379205,
      "grad_norm": 0.0012985611101612449,
      "learning_rate": 2.50077136686208e-05,
      "loss": 0.0003,
      "step": 81000
    },
    {
      "epoch": 24.995371798827524,
      "grad_norm": 0.08388421684503555,
      "learning_rate": 2.500462820117248e-05,
      "loss": 0.0032,
      "step": 81010
    },
    {
      "epoch": 24.998457266275842,
      "grad_norm": 6.043054554538685e-07,
      "learning_rate": 2.500154273372416e-05,
      "loss": 0.0016,
      "step": 81020
    },
    {
      "epoch": 25.0,
      "eval_accuracy_branch1": 0.999893907390797,
      "eval_accuracy_branch2": 0.4542113943462284,
      "eval_f1_branch1": 0.9998713455678332,
      "eval_f1_branch2": 0.45418222202555325,
      "eval_loss": 9.150295227300376e-05,
      "eval_precision_branch1": 0.9998851860434474,
      "eval_precision_branch2": 0.5138849516155943,
      "eval_recall_branch1": 0.9998575659080184,
      "eval_recall_branch2": 0.5137293481091404,
      "eval_runtime": 242.4083,
      "eval_samples_per_second": 427.721,
      "eval_steps_per_second": 53.468,
      "step": 81025
    },
    {
      "epoch": 25.001542733724158,
      "grad_norm": 0.004150602966547012,
      "learning_rate": 2.4998457266275842e-05,
      "loss": 0.0098,
      "step": 81030
    },
    {
      "epoch": 25.004628201172476,
      "grad_norm": 0.09525153785943985,
      "learning_rate": 2.4995371798827525e-05,
      "loss": 0.0,
      "step": 81040
    },
    {
      "epoch": 25.007713668620795,
      "grad_norm": 0.00012698625505436212,
      "learning_rate": 2.4992286331379204e-05,
      "loss": 0.0,
      "step": 81050
    },
    {
      "epoch": 25.010799136069114,
      "grad_norm": 0.0005831303424201906,
      "learning_rate": 2.4989200863930886e-05,
      "loss": 0.0004,
      "step": 81060
    },
    {
      "epoch": 25.013884603517432,
      "grad_norm": 0.0006026968476362526,
      "learning_rate": 2.498611539648257e-05,
      "loss": 0.0003,
      "step": 81070
    },
    {
      "epoch": 25.01697007096575,
      "grad_norm": 0.00012205439270474017,
      "learning_rate": 2.4983029929034248e-05,
      "loss": 0.0005,
      "step": 81080
    },
    {
      "epoch": 25.02005553841407,
      "grad_norm": 0.00022340277791954577,
      "learning_rate": 2.497994446158593e-05,
      "loss": 0.0002,
      "step": 81090
    },
    {
      "epoch": 25.02314100586239,
      "grad_norm": 0.00016675936058163643,
      "learning_rate": 2.4976858994137613e-05,
      "loss": 0.0,
      "step": 81100
    },
    {
      "epoch": 25.026226473310707,
      "grad_norm": 0.19462080299854279,
      "learning_rate": 2.4973773526689295e-05,
      "loss": 0.0001,
      "step": 81110
    },
    {
      "epoch": 25.029311940759026,
      "grad_norm": 3.1285962904803455e-05,
      "learning_rate": 2.4970688059240978e-05,
      "loss": 0.0048,
      "step": 81120
    },
    {
      "epoch": 25.032397408207345,
      "grad_norm": 0.00025120200007222593,
      "learning_rate": 2.4967602591792657e-05,
      "loss": 0.0012,
      "step": 81130
    },
    {
      "epoch": 25.035482875655664,
      "grad_norm": 5.303410580381751e-05,
      "learning_rate": 2.496451712434434e-05,
      "loss": 0.0002,
      "step": 81140
    },
    {
      "epoch": 25.03856834310398,
      "grad_norm": 2.2352005544235e-05,
      "learning_rate": 2.496143165689602e-05,
      "loss": 0.0001,
      "step": 81150
    },
    {
      "epoch": 25.041653810552297,
      "grad_norm": 1.9660534235299565e-05,
      "learning_rate": 2.4958346189447704e-05,
      "loss": 0.0001,
      "step": 81160
    },
    {
      "epoch": 25.044739278000616,
      "grad_norm": 1.6814123000585823e-06,
      "learning_rate": 2.4955260721999384e-05,
      "loss": 0.0002,
      "step": 81170
    },
    {
      "epoch": 25.047824745448935,
      "grad_norm": 3.3011001505656168e-06,
      "learning_rate": 2.4952175254551066e-05,
      "loss": 0.0003,
      "step": 81180
    },
    {
      "epoch": 25.050910212897254,
      "grad_norm": 9.980313916457817e-05,
      "learning_rate": 2.494908978710275e-05,
      "loss": 0.0005,
      "step": 81190
    },
    {
      "epoch": 25.053995680345572,
      "grad_norm": 1.4419415492739063e-06,
      "learning_rate": 2.4946004319654428e-05,
      "loss": 0.0,
      "step": 81200
    },
    {
      "epoch": 25.05708114779389,
      "grad_norm": 0.0006370285409502685,
      "learning_rate": 2.494291885220611e-05,
      "loss": 0.0,
      "step": 81210
    },
    {
      "epoch": 25.06016661524221,
      "grad_norm": 2.9214199912530603e-06,
      "learning_rate": 2.493983338475779e-05,
      "loss": 0.0015,
      "step": 81220
    },
    {
      "epoch": 25.06325208269053,
      "grad_norm": 0.8854407072067261,
      "learning_rate": 2.4936747917309475e-05,
      "loss": 0.001,
      "step": 81230
    },
    {
      "epoch": 25.066337550138847,
      "grad_norm": 0.000767790072131902,
      "learning_rate": 2.4933662449861158e-05,
      "loss": 0.001,
      "step": 81240
    },
    {
      "epoch": 25.069423017587166,
      "grad_norm": 0.0007107315468601882,
      "learning_rate": 2.4930576982412837e-05,
      "loss": 0.0003,
      "step": 81250
    },
    {
      "epoch": 25.07250848503548,
      "grad_norm": 0.10471060127019882,
      "learning_rate": 2.492749151496452e-05,
      "loss": 0.0123,
      "step": 81260
    },
    {
      "epoch": 25.0755939524838,
      "grad_norm": 0.0001300465373788029,
      "learning_rate": 2.4924406047516198e-05,
      "loss": 0.0,
      "step": 81270
    },
    {
      "epoch": 25.07867941993212,
      "grad_norm": 0.0016210784669965506,
      "learning_rate": 2.492132058006788e-05,
      "loss": 0.0001,
      "step": 81280
    },
    {
      "epoch": 25.081764887380437,
      "grad_norm": 4.823812923859805e-05,
      "learning_rate": 2.4918235112619563e-05,
      "loss": 0.0001,
      "step": 81290
    },
    {
      "epoch": 25.084850354828756,
      "grad_norm": 0.0012490871595218778,
      "learning_rate": 2.4915149645171246e-05,
      "loss": 0.0008,
      "step": 81300
    },
    {
      "epoch": 25.087935822277075,
      "grad_norm": 1.2513944056991022e-05,
      "learning_rate": 2.4912064177722928e-05,
      "loss": 0.0062,
      "step": 81310
    },
    {
      "epoch": 25.091021289725393,
      "grad_norm": 0.009545574896037579,
      "learning_rate": 2.4908978710274607e-05,
      "loss": 0.0002,
      "step": 81320
    },
    {
      "epoch": 25.094106757173712,
      "grad_norm": 0.0001753751712385565,
      "learning_rate": 2.490589324282629e-05,
      "loss": 0.0,
      "step": 81330
    },
    {
      "epoch": 25.09719222462203,
      "grad_norm": 0.00347870122641325,
      "learning_rate": 2.490280777537797e-05,
      "loss": 0.0005,
      "step": 81340
    },
    {
      "epoch": 25.10027769207035,
      "grad_norm": 0.0004941950319334865,
      "learning_rate": 2.489972230792965e-05,
      "loss": 0.0,
      "step": 81350
    },
    {
      "epoch": 25.10336315951867,
      "grad_norm": 0.001431359676644206,
      "learning_rate": 2.4896636840481337e-05,
      "loss": 0.0009,
      "step": 81360
    },
    {
      "epoch": 25.106448626966987,
      "grad_norm": 0.008724017068743706,
      "learning_rate": 2.4893551373033016e-05,
      "loss": 0.0007,
      "step": 81370
    },
    {
      "epoch": 25.109534094415302,
      "grad_norm": 1.8874823581427336e-05,
      "learning_rate": 2.48904659055847e-05,
      "loss": 0.0,
      "step": 81380
    },
    {
      "epoch": 25.11261956186362,
      "grad_norm": 0.0011615804396569729,
      "learning_rate": 2.4887380438136378e-05,
      "loss": 0.0,
      "step": 81390
    },
    {
      "epoch": 25.11570502931194,
      "grad_norm": 0.001370318466797471,
      "learning_rate": 2.488429497068806e-05,
      "loss": 0.0006,
      "step": 81400
    },
    {
      "epoch": 25.11879049676026,
      "grad_norm": 0.192198246717453,
      "learning_rate": 2.4881209503239743e-05,
      "loss": 0.0001,
      "step": 81410
    },
    {
      "epoch": 25.121875964208577,
      "grad_norm": 7.564581028418615e-05,
      "learning_rate": 2.4878124035791422e-05,
      "loss": 0.0,
      "step": 81420
    },
    {
      "epoch": 25.124961431656896,
      "grad_norm": 0.04157393425703049,
      "learning_rate": 2.4875038568343108e-05,
      "loss": 0.001,
      "step": 81430
    },
    {
      "epoch": 25.128046899105215,
      "grad_norm": 0.0001092132952180691,
      "learning_rate": 2.4871953100894787e-05,
      "loss": 0.0,
      "step": 81440
    },
    {
      "epoch": 25.131132366553533,
      "grad_norm": 1.9214967323932797e-06,
      "learning_rate": 2.486886763344647e-05,
      "loss": 0.0004,
      "step": 81450
    },
    {
      "epoch": 25.134217834001852,
      "grad_norm": 0.0006906578200869262,
      "learning_rate": 2.4865782165998148e-05,
      "loss": 0.0,
      "step": 81460
    },
    {
      "epoch": 25.13730330145017,
      "grad_norm": 0.0001341688766842708,
      "learning_rate": 2.486269669854983e-05,
      "loss": 0.0046,
      "step": 81470
    },
    {
      "epoch": 25.14038876889849,
      "grad_norm": 0.003767074318602681,
      "learning_rate": 2.4859611231101513e-05,
      "loss": 0.002,
      "step": 81480
    },
    {
      "epoch": 25.14347423634681,
      "grad_norm": 0.0005735913873650134,
      "learning_rate": 2.4856525763653192e-05,
      "loss": 0.0001,
      "step": 81490
    },
    {
      "epoch": 25.146559703795123,
      "grad_norm": 0.0006671302253380418,
      "learning_rate": 2.4853440296204878e-05,
      "loss": 0.0,
      "step": 81500
    },
    {
      "epoch": 25.149645171243442,
      "grad_norm": 1.0064940397569444e-05,
      "learning_rate": 2.4850354828756557e-05,
      "loss": 0.0,
      "step": 81510
    },
    {
      "epoch": 25.15273063869176,
      "grad_norm": 0.014033257029950619,
      "learning_rate": 2.484726936130824e-05,
      "loss": 0.0,
      "step": 81520
    },
    {
      "epoch": 25.15581610614008,
      "grad_norm": 0.0011568040354177356,
      "learning_rate": 2.4844183893859922e-05,
      "loss": 0.0002,
      "step": 81530
    },
    {
      "epoch": 25.1589015735884,
      "grad_norm": 0.005135711282491684,
      "learning_rate": 2.48410984264116e-05,
      "loss": 0.0,
      "step": 81540
    },
    {
      "epoch": 25.161987041036717,
      "grad_norm": 2.6590819288685452e-06,
      "learning_rate": 2.4838012958963284e-05,
      "loss": 0.0,
      "step": 81550
    },
    {
      "epoch": 25.165072508485036,
      "grad_norm": 0.24487560987472534,
      "learning_rate": 2.4834927491514963e-05,
      "loss": 0.0004,
      "step": 81560
    },
    {
      "epoch": 25.168157975933354,
      "grad_norm": 1.593481421470642,
      "learning_rate": 2.483184202406665e-05,
      "loss": 0.007,
      "step": 81570
    },
    {
      "epoch": 25.171243443381673,
      "grad_norm": 4.071266062055656e-07,
      "learning_rate": 2.4828756556618328e-05,
      "loss": 0.0001,
      "step": 81580
    },
    {
      "epoch": 25.174328910829992,
      "grad_norm": 0.00039203499909490347,
      "learning_rate": 2.482567108917001e-05,
      "loss": 0.0,
      "step": 81590
    },
    {
      "epoch": 25.17741437827831,
      "grad_norm": 0.03774354234337807,
      "learning_rate": 2.4822585621721693e-05,
      "loss": 0.0,
      "step": 81600
    },
    {
      "epoch": 25.18049984572663,
      "grad_norm": 0.49049270153045654,
      "learning_rate": 2.4819500154273372e-05,
      "loss": 0.0002,
      "step": 81610
    },
    {
      "epoch": 25.183585313174945,
      "grad_norm": 7.165073475334793e-05,
      "learning_rate": 2.4816414686825054e-05,
      "loss": 0.0001,
      "step": 81620
    },
    {
      "epoch": 25.186670780623263,
      "grad_norm": 0.07173603773117065,
      "learning_rate": 2.4813329219376737e-05,
      "loss": 0.0005,
      "step": 81630
    },
    {
      "epoch": 25.189756248071582,
      "grad_norm": 0.008620698936283588,
      "learning_rate": 2.481024375192842e-05,
      "loss": 0.0002,
      "step": 81640
    },
    {
      "epoch": 25.1928417155199,
      "grad_norm": 4.0125431155502156e-07,
      "learning_rate": 2.4807158284480102e-05,
      "loss": 0.0006,
      "step": 81650
    },
    {
      "epoch": 25.19592718296822,
      "grad_norm": 0.0003325895231682807,
      "learning_rate": 2.480407281703178e-05,
      "loss": 0.0011,
      "step": 81660
    },
    {
      "epoch": 25.199012650416538,
      "grad_norm": 0.051315099000930786,
      "learning_rate": 2.4800987349583463e-05,
      "loss": 0.0061,
      "step": 81670
    },
    {
      "epoch": 25.202098117864857,
      "grad_norm": 3.798607940552756e-05,
      "learning_rate": 2.4797901882135142e-05,
      "loss": 0.0022,
      "step": 81680
    },
    {
      "epoch": 25.205183585313176,
      "grad_norm": 0.11300729960203171,
      "learning_rate": 2.4794816414686825e-05,
      "loss": 0.0001,
      "step": 81690
    },
    {
      "epoch": 25.208269052761494,
      "grad_norm": 4.7931174776749685e-05,
      "learning_rate": 2.4791730947238507e-05,
      "loss": 0.0016,
      "step": 81700
    },
    {
      "epoch": 25.211354520209813,
      "grad_norm": 5.760589829151286e-06,
      "learning_rate": 2.478864547979019e-05,
      "loss": 0.0002,
      "step": 81710
    },
    {
      "epoch": 25.21443998765813,
      "grad_norm": 3.212117371731438e-05,
      "learning_rate": 2.4785560012341872e-05,
      "loss": 0.0003,
      "step": 81720
    },
    {
      "epoch": 25.217525455106447,
      "grad_norm": 0.004047716967761517,
      "learning_rate": 2.478247454489355e-05,
      "loss": 0.0,
      "step": 81730
    },
    {
      "epoch": 25.220610922554766,
      "grad_norm": 0.00011800651554949582,
      "learning_rate": 2.4779389077445234e-05,
      "loss": 0.0004,
      "step": 81740
    },
    {
      "epoch": 25.223696390003084,
      "grad_norm": 1.1035535335540771,
      "learning_rate": 2.4776303609996916e-05,
      "loss": 0.0018,
      "step": 81750
    },
    {
      "epoch": 25.226781857451403,
      "grad_norm": 0.0012440806021913886,
      "learning_rate": 2.4773218142548595e-05,
      "loss": 0.0,
      "step": 81760
    },
    {
      "epoch": 25.229867324899722,
      "grad_norm": 0.0001899368071462959,
      "learning_rate": 2.477013267510028e-05,
      "loss": 0.0075,
      "step": 81770
    },
    {
      "epoch": 25.23295279234804,
      "grad_norm": 0.00022544720559380949,
      "learning_rate": 2.476704720765196e-05,
      "loss": 0.0002,
      "step": 81780
    },
    {
      "epoch": 25.23603825979636,
      "grad_norm": 2.580146428954322e-05,
      "learning_rate": 2.4763961740203643e-05,
      "loss": 0.0052,
      "step": 81790
    },
    {
      "epoch": 25.239123727244678,
      "grad_norm": 0.02166423760354519,
      "learning_rate": 2.4760876272755322e-05,
      "loss": 0.0,
      "step": 81800
    },
    {
      "epoch": 25.242209194692997,
      "grad_norm": 6.9377914769575e-05,
      "learning_rate": 2.4757790805307004e-05,
      "loss": 0.0021,
      "step": 81810
    },
    {
      "epoch": 25.245294662141315,
      "grad_norm": 0.03204217180609703,
      "learning_rate": 2.4754705337858687e-05,
      "loss": 0.0001,
      "step": 81820
    },
    {
      "epoch": 25.248380129589634,
      "grad_norm": 0.01722746342420578,
      "learning_rate": 2.475161987041037e-05,
      "loss": 0.0007,
      "step": 81830
    },
    {
      "epoch": 25.251465597037953,
      "grad_norm": 0.0001268245978280902,
      "learning_rate": 2.4748534402962052e-05,
      "loss": 0.0089,
      "step": 81840
    },
    {
      "epoch": 25.254551064486268,
      "grad_norm": 0.519961416721344,
      "learning_rate": 2.474544893551373e-05,
      "loss": 0.0008,
      "step": 81850
    },
    {
      "epoch": 25.257636531934587,
      "grad_norm": 5.651983883581124e-05,
      "learning_rate": 2.4742363468065413e-05,
      "loss": 0.0,
      "step": 81860
    },
    {
      "epoch": 25.260721999382906,
      "grad_norm": 0.005663922987878323,
      "learning_rate": 2.4739278000617096e-05,
      "loss": 0.0022,
      "step": 81870
    },
    {
      "epoch": 25.263807466831224,
      "grad_norm": 0.021770205348730087,
      "learning_rate": 2.4736192533168775e-05,
      "loss": 0.0008,
      "step": 81880
    },
    {
      "epoch": 25.266892934279543,
      "grad_norm": 2.513234676371212e-06,
      "learning_rate": 2.4733107065720458e-05,
      "loss": 0.0002,
      "step": 81890
    },
    {
      "epoch": 25.26997840172786,
      "grad_norm": 3.989008109783754e-05,
      "learning_rate": 2.473002159827214e-05,
      "loss": 0.003,
      "step": 81900
    },
    {
      "epoch": 25.27306386917618,
      "grad_norm": 0.004673303570598364,
      "learning_rate": 2.4726936130823822e-05,
      "loss": 0.0,
      "step": 81910
    },
    {
      "epoch": 25.2761493366245,
      "grad_norm": 0.03504706919193268,
      "learning_rate": 2.47238506633755e-05,
      "loss": 0.0002,
      "step": 81920
    },
    {
      "epoch": 25.279234804072818,
      "grad_norm": 0.09870345145463943,
      "learning_rate": 2.4720765195927184e-05,
      "loss": 0.0001,
      "step": 81930
    },
    {
      "epoch": 25.282320271521137,
      "grad_norm": 1.5903538951533847e-05,
      "learning_rate": 2.4717679728478867e-05,
      "loss": 0.0,
      "step": 81940
    },
    {
      "epoch": 25.285405738969455,
      "grad_norm": 0.0002775767061393708,
      "learning_rate": 2.4714594261030546e-05,
      "loss": 0.0,
      "step": 81950
    },
    {
      "epoch": 25.288491206417774,
      "grad_norm": 0.007180565968155861,
      "learning_rate": 2.4711508793582228e-05,
      "loss": 0.0,
      "step": 81960
    },
    {
      "epoch": 25.29157667386609,
      "grad_norm": 6.072794349165633e-05,
      "learning_rate": 2.470842332613391e-05,
      "loss": 0.0009,
      "step": 81970
    },
    {
      "epoch": 25.294662141314408,
      "grad_norm": 8.223616168834269e-05,
      "learning_rate": 2.4705337858685593e-05,
      "loss": 0.0006,
      "step": 81980
    },
    {
      "epoch": 25.297747608762727,
      "grad_norm": 6.502766154881101e-06,
      "learning_rate": 2.4702252391237276e-05,
      "loss": 0.0001,
      "step": 81990
    },
    {
      "epoch": 25.300833076211045,
      "grad_norm": 4.999316729481507e-07,
      "learning_rate": 2.4699166923788955e-05,
      "loss": 0.0001,
      "step": 82000
    },
    {
      "epoch": 25.303918543659364,
      "grad_norm": 6.907714578119339e-07,
      "learning_rate": 2.4696081456340637e-05,
      "loss": 0.0,
      "step": 82010
    },
    {
      "epoch": 25.307004011107683,
      "grad_norm": 9.745369425218087e-06,
      "learning_rate": 2.4692995988892316e-05,
      "loss": 0.0,
      "step": 82020
    },
    {
      "epoch": 25.310089478556,
      "grad_norm": 7.162358815548941e-05,
      "learning_rate": 2.4689910521444002e-05,
      "loss": 0.0,
      "step": 82030
    },
    {
      "epoch": 25.31317494600432,
      "grad_norm": 1.7021016901708208e-05,
      "learning_rate": 2.468682505399568e-05,
      "loss": 0.0001,
      "step": 82040
    },
    {
      "epoch": 25.31626041345264,
      "grad_norm": 0.0001491474686190486,
      "learning_rate": 2.4683739586547364e-05,
      "loss": 0.0,
      "step": 82050
    },
    {
      "epoch": 25.319345880900958,
      "grad_norm": 0.000445163605036214,
      "learning_rate": 2.4680654119099046e-05,
      "loss": 0.0003,
      "step": 82060
    },
    {
      "epoch": 25.322431348349276,
      "grad_norm": 2.62861846067608e-07,
      "learning_rate": 2.4677568651650725e-05,
      "loss": 0.0,
      "step": 82070
    },
    {
      "epoch": 25.32551681579759,
      "grad_norm": 3.227279376005754e-05,
      "learning_rate": 2.4674483184202408e-05,
      "loss": 0.001,
      "step": 82080
    },
    {
      "epoch": 25.32860228324591,
      "grad_norm": 0.003029261715710163,
      "learning_rate": 2.4671397716754087e-05,
      "loss": 0.0,
      "step": 82090
    },
    {
      "epoch": 25.33168775069423,
      "grad_norm": 7.371975698333699e-06,
      "learning_rate": 2.4668312249305773e-05,
      "loss": 0.0036,
      "step": 82100
    },
    {
      "epoch": 25.334773218142548,
      "grad_norm": 8.751200766710099e-06,
      "learning_rate": 2.4665226781857455e-05,
      "loss": 0.0021,
      "step": 82110
    },
    {
      "epoch": 25.337858685590867,
      "grad_norm": 0.00010120414663106203,
      "learning_rate": 2.4662141314409134e-05,
      "loss": 0.0,
      "step": 82120
    },
    {
      "epoch": 25.340944153039185,
      "grad_norm": 4.2616698920028284e-05,
      "learning_rate": 2.4659055846960817e-05,
      "loss": 0.0008,
      "step": 82130
    },
    {
      "epoch": 25.344029620487504,
      "grad_norm": 0.00024645074154250324,
      "learning_rate": 2.4655970379512496e-05,
      "loss": 0.0,
      "step": 82140
    },
    {
      "epoch": 25.347115087935823,
      "grad_norm": 3.0193396014510654e-05,
      "learning_rate": 2.4652884912064178e-05,
      "loss": 0.0001,
      "step": 82150
    },
    {
      "epoch": 25.35020055538414,
      "grad_norm": 0.021034367382526398,
      "learning_rate": 2.464979944461586e-05,
      "loss": 0.0,
      "step": 82160
    },
    {
      "epoch": 25.35328602283246,
      "grad_norm": 0.00023046243586577475,
      "learning_rate": 2.4646713977167543e-05,
      "loss": 0.0,
      "step": 82170
    },
    {
      "epoch": 25.35637149028078,
      "grad_norm": 0.019229453057050705,
      "learning_rate": 2.4643628509719226e-05,
      "loss": 0.0,
      "step": 82180
    },
    {
      "epoch": 25.359456957729098,
      "grad_norm": 0.00013731321087107062,
      "learning_rate": 2.4640543042270905e-05,
      "loss": 0.0,
      "step": 82190
    },
    {
      "epoch": 25.362542425177413,
      "grad_norm": 0.0010128087596967816,
      "learning_rate": 2.4637457574822587e-05,
      "loss": 0.0,
      "step": 82200
    },
    {
      "epoch": 25.36562789262573,
      "grad_norm": 0.00014672412362415344,
      "learning_rate": 2.4634372107374266e-05,
      "loss": 0.0,
      "step": 82210
    },
    {
      "epoch": 25.36871336007405,
      "grad_norm": 3.304753408883698e-05,
      "learning_rate": 2.463128663992595e-05,
      "loss": 0.0,
      "step": 82220
    },
    {
      "epoch": 25.37179882752237,
      "grad_norm": 0.00017735686560627073,
      "learning_rate": 2.462820117247763e-05,
      "loss": 0.0,
      "step": 82230
    },
    {
      "epoch": 25.374884294970688,
      "grad_norm": 0.00022112602891866118,
      "learning_rate": 2.4625115705029314e-05,
      "loss": 0.0,
      "step": 82240
    },
    {
      "epoch": 25.377969762419006,
      "grad_norm": 0.0010498350020498037,
      "learning_rate": 2.4622030237580996e-05,
      "loss": 0.0,
      "step": 82250
    },
    {
      "epoch": 25.381055229867325,
      "grad_norm": 0.000392092508263886,
      "learning_rate": 2.4618944770132675e-05,
      "loss": 0.0009,
      "step": 82260
    },
    {
      "epoch": 25.384140697315644,
      "grad_norm": 0.023998521268367767,
      "learning_rate": 2.4615859302684358e-05,
      "loss": 0.0002,
      "step": 82270
    },
    {
      "epoch": 25.387226164763963,
      "grad_norm": 4.1811930714175105e-05,
      "learning_rate": 2.461277383523604e-05,
      "loss": 0.0015,
      "step": 82280
    },
    {
      "epoch": 25.39031163221228,
      "grad_norm": 0.0005819104262627661,
      "learning_rate": 2.460968836778772e-05,
      "loss": 0.0,
      "step": 82290
    },
    {
      "epoch": 25.3933970996606,
      "grad_norm": 0.0010707544861361384,
      "learning_rate": 2.4606602900339405e-05,
      "loss": 0.0,
      "step": 82300
    },
    {
      "epoch": 25.39648256710892,
      "grad_norm": 2.0745661458931863e-05,
      "learning_rate": 2.4603517432891084e-05,
      "loss": 0.0001,
      "step": 82310
    },
    {
      "epoch": 25.399568034557234,
      "grad_norm": 0.0020131960045546293,
      "learning_rate": 2.4600431965442767e-05,
      "loss": 0.0,
      "step": 82320
    },
    {
      "epoch": 25.402653502005553,
      "grad_norm": 0.0006854542880319059,
      "learning_rate": 2.4597346497994446e-05,
      "loss": 0.0002,
      "step": 82330
    },
    {
      "epoch": 25.40573896945387,
      "grad_norm": 0.00015923941100481898,
      "learning_rate": 2.459426103054613e-05,
      "loss": 0.0044,
      "step": 82340
    },
    {
      "epoch": 25.40882443690219,
      "grad_norm": 0.0011356669710949063,
      "learning_rate": 2.459117556309781e-05,
      "loss": 0.0023,
      "step": 82350
    },
    {
      "epoch": 25.41190990435051,
      "grad_norm": 2.510501326469239e-05,
      "learning_rate": 2.458809009564949e-05,
      "loss": 0.0,
      "step": 82360
    },
    {
      "epoch": 25.414995371798828,
      "grad_norm": 0.0011609018547460437,
      "learning_rate": 2.4585004628201176e-05,
      "loss": 0.0002,
      "step": 82370
    },
    {
      "epoch": 25.418080839247146,
      "grad_norm": 0.0018749851733446121,
      "learning_rate": 2.4581919160752855e-05,
      "loss": 0.0004,
      "step": 82380
    },
    {
      "epoch": 25.421166306695465,
      "grad_norm": 1.2507931614891277e-06,
      "learning_rate": 2.4578833693304537e-05,
      "loss": 0.0029,
      "step": 82390
    },
    {
      "epoch": 25.424251774143784,
      "grad_norm": 0.00010426225344417617,
      "learning_rate": 2.457574822585622e-05,
      "loss": 0.0,
      "step": 82400
    },
    {
      "epoch": 25.427337241592102,
      "grad_norm": 0.34949418902397156,
      "learning_rate": 2.45726627584079e-05,
      "loss": 0.0001,
      "step": 82410
    },
    {
      "epoch": 25.43042270904042,
      "grad_norm": 0.000683627265971154,
      "learning_rate": 2.456957729095958e-05,
      "loss": 0.0,
      "step": 82420
    },
    {
      "epoch": 25.433508176488736,
      "grad_norm": 6.079654485802166e-05,
      "learning_rate": 2.456649182351126e-05,
      "loss": 0.0002,
      "step": 82430
    },
    {
      "epoch": 25.436593643937055,
      "grad_norm": 1.6807283827802166e-05,
      "learning_rate": 2.4563406356062946e-05,
      "loss": 0.0,
      "step": 82440
    },
    {
      "epoch": 25.439679111385374,
      "grad_norm": 4.182904243469238,
      "learning_rate": 2.4560320888614625e-05,
      "loss": 0.0213,
      "step": 82450
    },
    {
      "epoch": 25.442764578833692,
      "grad_norm": 0.0019239529501646757,
      "learning_rate": 2.4557235421166308e-05,
      "loss": 0.0005,
      "step": 82460
    },
    {
      "epoch": 25.44585004628201,
      "grad_norm": 3.2455129257868975e-05,
      "learning_rate": 2.455414995371799e-05,
      "loss": 0.0003,
      "step": 82470
    },
    {
      "epoch": 25.44893551373033,
      "grad_norm": 0.20785988867282867,
      "learning_rate": 2.455106448626967e-05,
      "loss": 0.0073,
      "step": 82480
    },
    {
      "epoch": 25.45202098117865,
      "grad_norm": 0.1576923280954361,
      "learning_rate": 2.4547979018821352e-05,
      "loss": 0.0032,
      "step": 82490
    },
    {
      "epoch": 25.455106448626967,
      "grad_norm": 0.006858913227915764,
      "learning_rate": 2.4544893551373034e-05,
      "loss": 0.0001,
      "step": 82500
    },
    {
      "epoch": 25.458191916075286,
      "grad_norm": 0.0002554406237322837,
      "learning_rate": 2.4541808083924717e-05,
      "loss": 0.0,
      "step": 82510
    },
    {
      "epoch": 25.461277383523605,
      "grad_norm": 0.00012372920173220336,
      "learning_rate": 2.45387226164764e-05,
      "loss": 0.0005,
      "step": 82520
    },
    {
      "epoch": 25.464362850971924,
      "grad_norm": 0.0002551074721850455,
      "learning_rate": 2.453563714902808e-05,
      "loss": 0.0002,
      "step": 82530
    },
    {
      "epoch": 25.467448318420242,
      "grad_norm": 0.00030565145425498486,
      "learning_rate": 2.453255168157976e-05,
      "loss": 0.0,
      "step": 82540
    },
    {
      "epoch": 25.470533785868557,
      "grad_norm": 0.003562409896403551,
      "learning_rate": 2.452946621413144e-05,
      "loss": 0.0,
      "step": 82550
    },
    {
      "epoch": 25.473619253316876,
      "grad_norm": 0.00045722778304480016,
      "learning_rate": 2.4526380746683123e-05,
      "loss": 0.0002,
      "step": 82560
    },
    {
      "epoch": 25.476704720765195,
      "grad_norm": 0.0002470800536684692,
      "learning_rate": 2.4523295279234805e-05,
      "loss": 0.0,
      "step": 82570
    },
    {
      "epoch": 25.479790188213514,
      "grad_norm": 4.294564496376552e-05,
      "learning_rate": 2.4520209811786487e-05,
      "loss": 0.0001,
      "step": 82580
    },
    {
      "epoch": 25.482875655661832,
      "grad_norm": 0.00010383939661551267,
      "learning_rate": 2.451712434433817e-05,
      "loss": 0.0,
      "step": 82590
    },
    {
      "epoch": 25.48596112311015,
      "grad_norm": 0.0011865051928907633,
      "learning_rate": 2.451403887688985e-05,
      "loss": 0.0002,
      "step": 82600
    },
    {
      "epoch": 25.48904659055847,
      "grad_norm": 0.0002907022717408836,
      "learning_rate": 2.451095340944153e-05,
      "loss": 0.0002,
      "step": 82610
    },
    {
      "epoch": 25.49213205800679,
      "grad_norm": 0.002769573824480176,
      "learning_rate": 2.450786794199321e-05,
      "loss": 0.0,
      "step": 82620
    },
    {
      "epoch": 25.495217525455107,
      "grad_norm": 6.176837814564351e-06,
      "learning_rate": 2.4504782474544893e-05,
      "loss": 0.0,
      "step": 82630
    },
    {
      "epoch": 25.498302992903426,
      "grad_norm": 0.0004392238042782992,
      "learning_rate": 2.450169700709658e-05,
      "loss": 0.0001,
      "step": 82640
    },
    {
      "epoch": 25.501388460351745,
      "grad_norm": 8.074940183178114e-08,
      "learning_rate": 2.4498611539648258e-05,
      "loss": 0.0001,
      "step": 82650
    },
    {
      "epoch": 25.504473927800063,
      "grad_norm": 6.0084225879109e-06,
      "learning_rate": 2.449552607219994e-05,
      "loss": 0.0002,
      "step": 82660
    },
    {
      "epoch": 25.50755939524838,
      "grad_norm": 1.5286985217244364e-05,
      "learning_rate": 2.449244060475162e-05,
      "loss": 0.0,
      "step": 82670
    },
    {
      "epoch": 25.510644862696697,
      "grad_norm": 1.8055030750474543e-06,
      "learning_rate": 2.4489355137303302e-05,
      "loss": 0.0001,
      "step": 82680
    },
    {
      "epoch": 25.513730330145016,
      "grad_norm": 9.965401113731787e-05,
      "learning_rate": 2.4486269669854985e-05,
      "loss": 0.0,
      "step": 82690
    },
    {
      "epoch": 25.516815797593335,
      "grad_norm": 0.000375992531189695,
      "learning_rate": 2.4483184202406667e-05,
      "loss": 0.0021,
      "step": 82700
    },
    {
      "epoch": 25.519901265041653,
      "grad_norm": 4.108960638404824e-06,
      "learning_rate": 2.448009873495835e-05,
      "loss": 0.0,
      "step": 82710
    },
    {
      "epoch": 25.522986732489972,
      "grad_norm": 0.02033352665603161,
      "learning_rate": 2.447701326751003e-05,
      "loss": 0.0,
      "step": 82720
    },
    {
      "epoch": 25.52607219993829,
      "grad_norm": 6.496041896753013e-05,
      "learning_rate": 2.447392780006171e-05,
      "loss": 0.007,
      "step": 82730
    },
    {
      "epoch": 25.52915766738661,
      "grad_norm": 0.024151476100087166,
      "learning_rate": 2.447084233261339e-05,
      "loss": 0.0004,
      "step": 82740
    },
    {
      "epoch": 25.53224313483493,
      "grad_norm": 1.44135356094921e-05,
      "learning_rate": 2.4467756865165073e-05,
      "loss": 0.0,
      "step": 82750
    },
    {
      "epoch": 25.535328602283247,
      "grad_norm": 0.2497768998146057,
      "learning_rate": 2.4464671397716755e-05,
      "loss": 0.0042,
      "step": 82760
    },
    {
      "epoch": 25.538414069731566,
      "grad_norm": 0.006118327844887972,
      "learning_rate": 2.4461585930268438e-05,
      "loss": 0.0002,
      "step": 82770
    },
    {
      "epoch": 25.54149953717988,
      "grad_norm": 0.009412220679223537,
      "learning_rate": 2.445850046282012e-05,
      "loss": 0.0007,
      "step": 82780
    },
    {
      "epoch": 25.5445850046282,
      "grad_norm": 0.0005762266810052097,
      "learning_rate": 2.44554149953718e-05,
      "loss": 0.0,
      "step": 82790
    },
    {
      "epoch": 25.54767047207652,
      "grad_norm": 1.950731873512268,
      "learning_rate": 2.445232952792348e-05,
      "loss": 0.0024,
      "step": 82800
    },
    {
      "epoch": 25.550755939524837,
      "grad_norm": 8.401215745834634e-05,
      "learning_rate": 2.4449244060475164e-05,
      "loss": 0.0,
      "step": 82810
    },
    {
      "epoch": 25.553841406973156,
      "grad_norm": 2.129320455424022e-05,
      "learning_rate": 2.4446158593026843e-05,
      "loss": 0.0,
      "step": 82820
    },
    {
      "epoch": 25.556926874421475,
      "grad_norm": 0.0006712297326885164,
      "learning_rate": 2.4443073125578526e-05,
      "loss": 0.0002,
      "step": 82830
    },
    {
      "epoch": 25.560012341869793,
      "grad_norm": 2.542078436817974e-05,
      "learning_rate": 2.4439987658130208e-05,
      "loss": 0.006,
      "step": 82840
    },
    {
      "epoch": 25.563097809318112,
      "grad_norm": 0.9355887174606323,
      "learning_rate": 2.443690219068189e-05,
      "loss": 0.0004,
      "step": 82850
    },
    {
      "epoch": 25.56618327676643,
      "grad_norm": 0.013470252975821495,
      "learning_rate": 2.443381672323357e-05,
      "loss": 0.0049,
      "step": 82860
    },
    {
      "epoch": 25.56926874421475,
      "grad_norm": 0.0006555532454513013,
      "learning_rate": 2.4430731255785252e-05,
      "loss": 0.0002,
      "step": 82870
    },
    {
      "epoch": 25.572354211663068,
      "grad_norm": 0.39642924070358276,
      "learning_rate": 2.4427645788336935e-05,
      "loss": 0.0003,
      "step": 82880
    },
    {
      "epoch": 25.575439679111387,
      "grad_norm": 0.0005815298645757139,
      "learning_rate": 2.4424560320888614e-05,
      "loss": 0.0,
      "step": 82890
    },
    {
      "epoch": 25.578525146559702,
      "grad_norm": 0.16732540726661682,
      "learning_rate": 2.44214748534403e-05,
      "loss": 0.0003,
      "step": 82900
    },
    {
      "epoch": 25.58161061400802,
      "grad_norm": 0.7933803200721741,
      "learning_rate": 2.441838938599198e-05,
      "loss": 0.0005,
      "step": 82910
    },
    {
      "epoch": 25.58469608145634,
      "grad_norm": 0.00018096498388331383,
      "learning_rate": 2.441530391854366e-05,
      "loss": 0.0,
      "step": 82920
    },
    {
      "epoch": 25.58778154890466,
      "grad_norm": 1.1043059657822596e-06,
      "learning_rate": 2.4412218451095344e-05,
      "loss": 0.0006,
      "step": 82930
    },
    {
      "epoch": 25.590867016352977,
      "grad_norm": 0.0020264654885977507,
      "learning_rate": 2.4409132983647023e-05,
      "loss": 0.0002,
      "step": 82940
    },
    {
      "epoch": 25.593952483801296,
      "grad_norm": 4.589882155414671e-05,
      "learning_rate": 2.4406047516198705e-05,
      "loss": 0.0001,
      "step": 82950
    },
    {
      "epoch": 25.597037951249614,
      "grad_norm": 0.048248451203107834,
      "learning_rate": 2.4402962048750384e-05,
      "loss": 0.0002,
      "step": 82960
    },
    {
      "epoch": 25.600123418697933,
      "grad_norm": 0.0001243173610419035,
      "learning_rate": 2.439987658130207e-05,
      "loss": 0.0062,
      "step": 82970
    },
    {
      "epoch": 25.603208886146252,
      "grad_norm": 0.0006513310363516212,
      "learning_rate": 2.439679111385375e-05,
      "loss": 0.0001,
      "step": 82980
    },
    {
      "epoch": 25.60629435359457,
      "grad_norm": 0.0003455141850281507,
      "learning_rate": 2.4393705646405432e-05,
      "loss": 0.0,
      "step": 82990
    },
    {
      "epoch": 25.60937982104289,
      "grad_norm": 0.06273017823696136,
      "learning_rate": 2.4390620178957114e-05,
      "loss": 0.0009,
      "step": 83000
    },
    {
      "epoch": 25.612465288491208,
      "grad_norm": 5.755252914241282e-06,
      "learning_rate": 2.4387534711508793e-05,
      "loss": 0.0018,
      "step": 83010
    },
    {
      "epoch": 25.615550755939523,
      "grad_norm": 0.0025848462246358395,
      "learning_rate": 2.4384449244060476e-05,
      "loss": 0.0006,
      "step": 83020
    },
    {
      "epoch": 25.618636223387842,
      "grad_norm": 6.0276553995208815e-05,
      "learning_rate": 2.4381363776612158e-05,
      "loss": 0.0003,
      "step": 83030
    },
    {
      "epoch": 25.62172169083616,
      "grad_norm": 6.087124711484648e-05,
      "learning_rate": 2.437827830916384e-05,
      "loss": 0.0,
      "step": 83040
    },
    {
      "epoch": 25.62480715828448,
      "grad_norm": 0.0012482407037168741,
      "learning_rate": 2.4375192841715523e-05,
      "loss": 0.0,
      "step": 83050
    },
    {
      "epoch": 25.627892625732798,
      "grad_norm": 2.541112184524536,
      "learning_rate": 2.4372107374267202e-05,
      "loss": 0.0067,
      "step": 83060
    },
    {
      "epoch": 25.630978093181117,
      "grad_norm": 2.320819658052642e-05,
      "learning_rate": 2.4369021906818885e-05,
      "loss": 0.0,
      "step": 83070
    },
    {
      "epoch": 25.634063560629436,
      "grad_norm": 0.004500401206314564,
      "learning_rate": 2.4365936439370564e-05,
      "loss": 0.0,
      "step": 83080
    },
    {
      "epoch": 25.637149028077754,
      "grad_norm": 6.832369399489835e-05,
      "learning_rate": 2.4362850971922246e-05,
      "loss": 0.0001,
      "step": 83090
    },
    {
      "epoch": 25.640234495526073,
      "grad_norm": 3.0923001759219915e-05,
      "learning_rate": 2.435976550447393e-05,
      "loss": 0.0003,
      "step": 83100
    },
    {
      "epoch": 25.64331996297439,
      "grad_norm": 0.010683998465538025,
      "learning_rate": 2.435668003702561e-05,
      "loss": 0.0001,
      "step": 83110
    },
    {
      "epoch": 25.64640543042271,
      "grad_norm": 0.004647380672395229,
      "learning_rate": 2.4353594569577294e-05,
      "loss": 0.0,
      "step": 83120
    },
    {
      "epoch": 25.649490897871026,
      "grad_norm": 0.0009383107535541058,
      "learning_rate": 2.4350509102128973e-05,
      "loss": 0.0001,
      "step": 83130
    },
    {
      "epoch": 25.652576365319344,
      "grad_norm": 0.0004044526722282171,
      "learning_rate": 2.4347423634680655e-05,
      "loss": 0.0001,
      "step": 83140
    },
    {
      "epoch": 25.655661832767663,
      "grad_norm": 0.0066537619568407536,
      "learning_rate": 2.4344338167232338e-05,
      "loss": 0.0001,
      "step": 83150
    },
    {
      "epoch": 25.658747300215982,
      "grad_norm": 0.0001942255621543154,
      "learning_rate": 2.4341252699784017e-05,
      "loss": 0.0002,
      "step": 83160
    },
    {
      "epoch": 25.6618327676643,
      "grad_norm": 0.0005844996776431799,
      "learning_rate": 2.4338167232335703e-05,
      "loss": 0.0002,
      "step": 83170
    },
    {
      "epoch": 25.66491823511262,
      "grad_norm": 0.13246652483940125,
      "learning_rate": 2.4335081764887382e-05,
      "loss": 0.0001,
      "step": 83180
    },
    {
      "epoch": 25.668003702560938,
      "grad_norm": 0.00011851552699226886,
      "learning_rate": 2.4331996297439064e-05,
      "loss": 0.0,
      "step": 83190
    },
    {
      "epoch": 25.671089170009257,
      "grad_norm": 0.00011608278146013618,
      "learning_rate": 2.4328910829990743e-05,
      "loss": 0.0006,
      "step": 83200
    },
    {
      "epoch": 25.674174637457575,
      "grad_norm": 2.117887925123796e-05,
      "learning_rate": 2.4325825362542426e-05,
      "loss": 0.0026,
      "step": 83210
    },
    {
      "epoch": 25.677260104905894,
      "grad_norm": 0.012750133872032166,
      "learning_rate": 2.432273989509411e-05,
      "loss": 0.0,
      "step": 83220
    },
    {
      "epoch": 25.680345572354213,
      "grad_norm": 0.0014531610067933798,
      "learning_rate": 2.4319654427645787e-05,
      "loss": 0.0,
      "step": 83230
    },
    {
      "epoch": 25.68343103980253,
      "grad_norm": 0.00015864129818510264,
      "learning_rate": 2.4316568960197473e-05,
      "loss": 0.0001,
      "step": 83240
    },
    {
      "epoch": 25.686516507250847,
      "grad_norm": 0.00011715582513716072,
      "learning_rate": 2.4313483492749152e-05,
      "loss": 0.0001,
      "step": 83250
    },
    {
      "epoch": 25.689601974699166,
      "grad_norm": 2.4191340344259515e-05,
      "learning_rate": 2.4310398025300835e-05,
      "loss": 0.0023,
      "step": 83260
    },
    {
      "epoch": 25.692687442147484,
      "grad_norm": 2.1507873952941736e-06,
      "learning_rate": 2.4307312557852517e-05,
      "loss": 0.0,
      "step": 83270
    },
    {
      "epoch": 25.695772909595803,
      "grad_norm": 1.051012623065617e-05,
      "learning_rate": 2.4304227090404196e-05,
      "loss": 0.0001,
      "step": 83280
    },
    {
      "epoch": 25.69885837704412,
      "grad_norm": 0.0006560464389622211,
      "learning_rate": 2.430114162295588e-05,
      "loss": 0.0006,
      "step": 83290
    },
    {
      "epoch": 25.70194384449244,
      "grad_norm": 0.00031705384026281536,
      "learning_rate": 2.4298056155507558e-05,
      "loss": 0.0006,
      "step": 83300
    },
    {
      "epoch": 25.70502931194076,
      "grad_norm": 4.8752841394161806e-05,
      "learning_rate": 2.4294970688059244e-05,
      "loss": 0.0045,
      "step": 83310
    },
    {
      "epoch": 25.708114779389078,
      "grad_norm": 0.0002843734109774232,
      "learning_rate": 2.4291885220610923e-05,
      "loss": 0.0,
      "step": 83320
    },
    {
      "epoch": 25.711200246837397,
      "grad_norm": 1.2323791906965198e-06,
      "learning_rate": 2.4288799753162605e-05,
      "loss": 0.0002,
      "step": 83330
    },
    {
      "epoch": 25.714285714285715,
      "grad_norm": 0.13095837831497192,
      "learning_rate": 2.4285714285714288e-05,
      "loss": 0.0003,
      "step": 83340
    },
    {
      "epoch": 25.717371181734034,
      "grad_norm": 8.977566903922707e-05,
      "learning_rate": 2.4282628818265967e-05,
      "loss": 0.0,
      "step": 83350
    },
    {
      "epoch": 25.720456649182353,
      "grad_norm": 0.0003268927684985101,
      "learning_rate": 2.427954335081765e-05,
      "loss": 0.0,
      "step": 83360
    },
    {
      "epoch": 25.723542116630668,
      "grad_norm": 2.430695056915283,
      "learning_rate": 2.4276457883369332e-05,
      "loss": 0.0013,
      "step": 83370
    },
    {
      "epoch": 25.726627584078987,
      "grad_norm": 0.0291749257594347,
      "learning_rate": 2.4273372415921014e-05,
      "loss": 0.0,
      "step": 83380
    },
    {
      "epoch": 25.729713051527305,
      "grad_norm": 2.1881012798985466e-05,
      "learning_rate": 2.4270286948472694e-05,
      "loss": 0.0008,
      "step": 83390
    },
    {
      "epoch": 25.732798518975624,
      "grad_norm": 0.0006692562601529062,
      "learning_rate": 2.4267201481024376e-05,
      "loss": 0.0006,
      "step": 83400
    },
    {
      "epoch": 25.735883986423943,
      "grad_norm": 0.03418538346886635,
      "learning_rate": 2.426411601357606e-05,
      "loss": 0.0101,
      "step": 83410
    },
    {
      "epoch": 25.73896945387226,
      "grad_norm": 1.0180893696087878e-05,
      "learning_rate": 2.4261030546127738e-05,
      "loss": 0.0006,
      "step": 83420
    },
    {
      "epoch": 25.74205492132058,
      "grad_norm": 8.584974420955405e-05,
      "learning_rate": 2.425794507867942e-05,
      "loss": 0.0007,
      "step": 83430
    },
    {
      "epoch": 25.7451403887689,
      "grad_norm": 0.00010429491521790624,
      "learning_rate": 2.4254859611231103e-05,
      "loss": 0.0001,
      "step": 83440
    },
    {
      "epoch": 25.748225856217218,
      "grad_norm": 0.00621508015319705,
      "learning_rate": 2.4251774143782785e-05,
      "loss": 0.0013,
      "step": 83450
    },
    {
      "epoch": 25.751311323665536,
      "grad_norm": 0.006825800519436598,
      "learning_rate": 2.4248688676334468e-05,
      "loss": 0.008,
      "step": 83460
    },
    {
      "epoch": 25.754396791113855,
      "grad_norm": 0.0011690459214150906,
      "learning_rate": 2.4245603208886147e-05,
      "loss": 0.0002,
      "step": 83470
    },
    {
      "epoch": 25.757482258562174,
      "grad_norm": 0.000307286623865366,
      "learning_rate": 2.424251774143783e-05,
      "loss": 0.0006,
      "step": 83480
    },
    {
      "epoch": 25.76056772601049,
      "grad_norm": 0.00011162299779243767,
      "learning_rate": 2.4239432273989508e-05,
      "loss": 0.0001,
      "step": 83490
    },
    {
      "epoch": 25.763653193458808,
      "grad_norm": 0.00025967619149014354,
      "learning_rate": 2.423634680654119e-05,
      "loss": 0.0,
      "step": 83500
    },
    {
      "epoch": 25.766738660907127,
      "grad_norm": 8.490648610859353e-07,
      "learning_rate": 2.4233261339092873e-05,
      "loss": 0.001,
      "step": 83510
    },
    {
      "epoch": 25.769824128355445,
      "grad_norm": 0.001402876921929419,
      "learning_rate": 2.4230175871644556e-05,
      "loss": 0.0006,
      "step": 83520
    },
    {
      "epoch": 25.772909595803764,
      "grad_norm": 6.068646143830847e-06,
      "learning_rate": 2.4227090404196238e-05,
      "loss": 0.0001,
      "step": 83530
    },
    {
      "epoch": 25.775995063252083,
      "grad_norm": 4.455138878256548e-06,
      "learning_rate": 2.4224004936747917e-05,
      "loss": 0.0,
      "step": 83540
    },
    {
      "epoch": 25.7790805307004,
      "grad_norm": 9.274303010897711e-05,
      "learning_rate": 2.42209194692996e-05,
      "loss": 0.0001,
      "step": 83550
    },
    {
      "epoch": 25.78216599814872,
      "grad_norm": 0.0008866935968399048,
      "learning_rate": 2.4217834001851282e-05,
      "loss": 0.0025,
      "step": 83560
    },
    {
      "epoch": 25.78525146559704,
      "grad_norm": 4.0384926251135767e-05,
      "learning_rate": 2.4214748534402965e-05,
      "loss": 0.0001,
      "step": 83570
    },
    {
      "epoch": 25.788336933045358,
      "grad_norm": 0.0007900474593043327,
      "learning_rate": 2.4211663066954647e-05,
      "loss": 0.0,
      "step": 83580
    },
    {
      "epoch": 25.791422400493676,
      "grad_norm": 0.00133277359418571,
      "learning_rate": 2.4208577599506326e-05,
      "loss": 0.0001,
      "step": 83590
    },
    {
      "epoch": 25.794507867941995,
      "grad_norm": 0.11664251983165741,
      "learning_rate": 2.420549213205801e-05,
      "loss": 0.0001,
      "step": 83600
    },
    {
      "epoch": 25.79759333539031,
      "grad_norm": 0.01771547831594944,
      "learning_rate": 2.4202406664609688e-05,
      "loss": 0.0002,
      "step": 83610
    },
    {
      "epoch": 25.80067880283863,
      "grad_norm": 0.0002120109274983406,
      "learning_rate": 2.419932119716137e-05,
      "loss": 0.0002,
      "step": 83620
    },
    {
      "epoch": 25.803764270286948,
      "grad_norm": 0.10973818600177765,
      "learning_rate": 2.4196235729713053e-05,
      "loss": 0.0002,
      "step": 83630
    },
    {
      "epoch": 25.806849737735266,
      "grad_norm": 1.3444096111925319e-05,
      "learning_rate": 2.4193150262264735e-05,
      "loss": 0.0001,
      "step": 83640
    },
    {
      "epoch": 25.809935205183585,
      "grad_norm": 2.0388681321037438e-07,
      "learning_rate": 2.4190064794816418e-05,
      "loss": 0.0,
      "step": 83650
    },
    {
      "epoch": 25.813020672631904,
      "grad_norm": 3.4388722269795835e-05,
      "learning_rate": 2.4186979327368097e-05,
      "loss": 0.0001,
      "step": 83660
    },
    {
      "epoch": 25.816106140080223,
      "grad_norm": 1.9520215573720634e-05,
      "learning_rate": 2.418389385991978e-05,
      "loss": 0.0,
      "step": 83670
    },
    {
      "epoch": 25.81919160752854,
      "grad_norm": 3.6869287214358337e-06,
      "learning_rate": 2.418080839247146e-05,
      "loss": 0.0001,
      "step": 83680
    },
    {
      "epoch": 25.82227707497686,
      "grad_norm": 7.399869900837075e-06,
      "learning_rate": 2.417772292502314e-05,
      "loss": 0.0,
      "step": 83690
    },
    {
      "epoch": 25.82536254242518,
      "grad_norm": 0.03109998069703579,
      "learning_rate": 2.4174637457574823e-05,
      "loss": 0.0001,
      "step": 83700
    },
    {
      "epoch": 25.828448009873497,
      "grad_norm": 0.013263004831969738,
      "learning_rate": 2.4171551990126506e-05,
      "loss": 0.0,
      "step": 83710
    },
    {
      "epoch": 25.831533477321813,
      "grad_norm": 5.739220341638429e-06,
      "learning_rate": 2.4168466522678188e-05,
      "loss": 0.0,
      "step": 83720
    },
    {
      "epoch": 25.83461894477013,
      "grad_norm": 2.61455679719802e-05,
      "learning_rate": 2.4165381055229867e-05,
      "loss": 0.0001,
      "step": 83730
    },
    {
      "epoch": 25.83770441221845,
      "grad_norm": 0.0008226257050409913,
      "learning_rate": 2.416229558778155e-05,
      "loss": 0.0,
      "step": 83740
    },
    {
      "epoch": 25.84078987966677,
      "grad_norm": 0.00010305908654117957,
      "learning_rate": 2.4159210120333232e-05,
      "loss": 0.0,
      "step": 83750
    },
    {
      "epoch": 25.843875347115087,
      "grad_norm": 2.1576977360382443e-06,
      "learning_rate": 2.415612465288491e-05,
      "loss": 0.0001,
      "step": 83760
    },
    {
      "epoch": 25.846960814563406,
      "grad_norm": 0.002354341559112072,
      "learning_rate": 2.4153039185436597e-05,
      "loss": 0.0,
      "step": 83770
    },
    {
      "epoch": 25.850046282011725,
      "grad_norm": 2.6257202989654616e-05,
      "learning_rate": 2.4149953717988276e-05,
      "loss": 0.0003,
      "step": 83780
    },
    {
      "epoch": 25.853131749460044,
      "grad_norm": 1.313588745688321e-05,
      "learning_rate": 2.414686825053996e-05,
      "loss": 0.0001,
      "step": 83790
    },
    {
      "epoch": 25.856217216908362,
      "grad_norm": 0.02933405712246895,
      "learning_rate": 2.414378278309164e-05,
      "loss": 0.0035,
      "step": 83800
    },
    {
      "epoch": 25.85930268435668,
      "grad_norm": 2.3894643163657747e-05,
      "learning_rate": 2.414069731564332e-05,
      "loss": 0.0,
      "step": 83810
    },
    {
      "epoch": 25.862388151805,
      "grad_norm": 0.00019316984980832785,
      "learning_rate": 2.4137611848195003e-05,
      "loss": 0.0,
      "step": 83820
    },
    {
      "epoch": 25.86547361925332,
      "grad_norm": 0.0015407610917463899,
      "learning_rate": 2.4134526380746682e-05,
      "loss": 0.0018,
      "step": 83830
    },
    {
      "epoch": 25.868559086701634,
      "grad_norm": 3.87564568882226e-06,
      "learning_rate": 2.4131440913298368e-05,
      "loss": 0.0,
      "step": 83840
    },
    {
      "epoch": 25.871644554149952,
      "grad_norm": 0.0007397611043415964,
      "learning_rate": 2.4128355445850047e-05,
      "loss": 0.0005,
      "step": 83850
    },
    {
      "epoch": 25.87473002159827,
      "grad_norm": 0.0023088857997208834,
      "learning_rate": 2.412526997840173e-05,
      "loss": 0.0004,
      "step": 83860
    },
    {
      "epoch": 25.87781548904659,
      "grad_norm": 0.00037012394750490785,
      "learning_rate": 2.4122184510953412e-05,
      "loss": 0.0001,
      "step": 83870
    },
    {
      "epoch": 25.88090095649491,
      "grad_norm": 2.545088052749634,
      "learning_rate": 2.411909904350509e-05,
      "loss": 0.0031,
      "step": 83880
    },
    {
      "epoch": 25.883986423943227,
      "grad_norm": 5.873750342288986e-05,
      "learning_rate": 2.4116013576056773e-05,
      "loss": 0.0001,
      "step": 83890
    },
    {
      "epoch": 25.887071891391546,
      "grad_norm": 0.025383785367012024,
      "learning_rate": 2.4112928108608452e-05,
      "loss": 0.0,
      "step": 83900
    },
    {
      "epoch": 25.890157358839865,
      "grad_norm": 0.003948742989450693,
      "learning_rate": 2.410984264116014e-05,
      "loss": 0.0,
      "step": 83910
    },
    {
      "epoch": 25.893242826288184,
      "grad_norm": 2.071851304208394e-05,
      "learning_rate": 2.410675717371182e-05,
      "loss": 0.0035,
      "step": 83920
    },
    {
      "epoch": 25.896328293736502,
      "grad_norm": 1.0596097707748413,
      "learning_rate": 2.41036717062635e-05,
      "loss": 0.0007,
      "step": 83930
    },
    {
      "epoch": 25.89941376118482,
      "grad_norm": 0.0012999497121199965,
      "learning_rate": 2.4100586238815182e-05,
      "loss": 0.0037,
      "step": 83940
    },
    {
      "epoch": 25.90249922863314,
      "grad_norm": 0.01616698130965233,
      "learning_rate": 2.409750077136686e-05,
      "loss": 0.0002,
      "step": 83950
    },
    {
      "epoch": 25.905584696081455,
      "grad_norm": 0.0003909434308297932,
      "learning_rate": 2.4094415303918544e-05,
      "loss": 0.0007,
      "step": 83960
    },
    {
      "epoch": 25.908670163529774,
      "grad_norm": 0.006931417156010866,
      "learning_rate": 2.4091329836470226e-05,
      "loss": 0.0003,
      "step": 83970
    },
    {
      "epoch": 25.911755630978092,
      "grad_norm": 0.00023309423704631627,
      "learning_rate": 2.408824436902191e-05,
      "loss": 0.0,
      "step": 83980
    },
    {
      "epoch": 25.91484109842641,
      "grad_norm": 2.5138031560345553e-05,
      "learning_rate": 2.408515890157359e-05,
      "loss": 0.0,
      "step": 83990
    },
    {
      "epoch": 25.91792656587473,
      "grad_norm": 6.631204996665474e-06,
      "learning_rate": 2.408207343412527e-05,
      "loss": 0.001,
      "step": 84000
    },
    {
      "epoch": 25.92101203332305,
      "grad_norm": 0.3106052875518799,
      "learning_rate": 2.4078987966676953e-05,
      "loss": 0.0001,
      "step": 84010
    },
    {
      "epoch": 25.924097500771367,
      "grad_norm": 0.0005240285536274314,
      "learning_rate": 2.4075902499228632e-05,
      "loss": 0.0011,
      "step": 84020
    },
    {
      "epoch": 25.927182968219686,
      "grad_norm": 0.00025618806830607355,
      "learning_rate": 2.4072817031780314e-05,
      "loss": 0.0009,
      "step": 84030
    },
    {
      "epoch": 25.930268435668005,
      "grad_norm": 0.0010925575625151396,
      "learning_rate": 2.4069731564332e-05,
      "loss": 0.0001,
      "step": 84040
    },
    {
      "epoch": 25.933353903116323,
      "grad_norm": 2.778680936899036e-05,
      "learning_rate": 2.406664609688368e-05,
      "loss": 0.0001,
      "step": 84050
    },
    {
      "epoch": 25.936439370564642,
      "grad_norm": 0.8928217887878418,
      "learning_rate": 2.4063560629435362e-05,
      "loss": 0.0005,
      "step": 84060
    },
    {
      "epoch": 25.939524838012957,
      "grad_norm": 5.7426703278906643e-05,
      "learning_rate": 2.406047516198704e-05,
      "loss": 0.0,
      "step": 84070
    },
    {
      "epoch": 25.942610305461276,
      "grad_norm": 0.00022221663675736636,
      "learning_rate": 2.4057389694538723e-05,
      "loss": 0.0005,
      "step": 84080
    },
    {
      "epoch": 25.945695772909595,
      "grad_norm": 0.00055530114332214,
      "learning_rate": 2.4054304227090406e-05,
      "loss": 0.0,
      "step": 84090
    },
    {
      "epoch": 25.948781240357913,
      "grad_norm": 0.002885407069697976,
      "learning_rate": 2.4051218759642085e-05,
      "loss": 0.0,
      "step": 84100
    },
    {
      "epoch": 25.951866707806232,
      "grad_norm": 5.059258910478093e-05,
      "learning_rate": 2.404813329219377e-05,
      "loss": 0.0,
      "step": 84110
    },
    {
      "epoch": 25.95495217525455,
      "grad_norm": 0.0006156766903586686,
      "learning_rate": 2.404504782474545e-05,
      "loss": 0.0,
      "step": 84120
    },
    {
      "epoch": 25.95803764270287,
      "grad_norm": 4.355687451607082e-06,
      "learning_rate": 2.4041962357297132e-05,
      "loss": 0.0004,
      "step": 84130
    },
    {
      "epoch": 25.96112311015119,
      "grad_norm": 0.02254980430006981,
      "learning_rate": 2.403887688984881e-05,
      "loss": 0.0001,
      "step": 84140
    },
    {
      "epoch": 25.964208577599507,
      "grad_norm": 0.003329928731545806,
      "learning_rate": 2.4035791422400494e-05,
      "loss": 0.0001,
      "step": 84150
    },
    {
      "epoch": 25.967294045047826,
      "grad_norm": 0.0001378352753818035,
      "learning_rate": 2.4032705954952177e-05,
      "loss": 0.0052,
      "step": 84160
    },
    {
      "epoch": 25.970379512496145,
      "grad_norm": 0.21603965759277344,
      "learning_rate": 2.4029620487503856e-05,
      "loss": 0.0001,
      "step": 84170
    },
    {
      "epoch": 25.973464979944463,
      "grad_norm": 2.650301218032837,
      "learning_rate": 2.402653502005554e-05,
      "loss": 0.0022,
      "step": 84180
    },
    {
      "epoch": 25.97655044739278,
      "grad_norm": 0.003348009428009391,
      "learning_rate": 2.402344955260722e-05,
      "loss": 0.0,
      "step": 84190
    },
    {
      "epoch": 25.979635914841097,
      "grad_norm": 4.053587872476783e-06,
      "learning_rate": 2.4020364085158903e-05,
      "loss": 0.0,
      "step": 84200
    },
    {
      "epoch": 25.982721382289416,
      "grad_norm": 1.7564842700958252,
      "learning_rate": 2.4017278617710586e-05,
      "loss": 0.0018,
      "step": 84210
    },
    {
      "epoch": 25.985806849737735,
      "grad_norm": 0.00012049084762111306,
      "learning_rate": 2.4014193150262265e-05,
      "loss": 0.0,
      "step": 84220
    },
    {
      "epoch": 25.988892317186053,
      "grad_norm": 0.0002351351286051795,
      "learning_rate": 2.4011107682813947e-05,
      "loss": 0.0,
      "step": 84230
    },
    {
      "epoch": 25.991977784634372,
      "grad_norm": 0.6078478693962097,
      "learning_rate": 2.400802221536563e-05,
      "loss": 0.0007,
      "step": 84240
    },
    {
      "epoch": 25.99506325208269,
      "grad_norm": 0.22970224916934967,
      "learning_rate": 2.4004936747917312e-05,
      "loss": 0.0004,
      "step": 84250
    },
    {
      "epoch": 25.99814871953101,
      "grad_norm": 0.0351719968020916,
      "learning_rate": 2.400185128046899e-05,
      "loss": 0.0001,
      "step": 84260
    },
    {
      "epoch": 26.0,
      "eval_accuracy_branch1": 0.9991609039090305,
      "eval_accuracy_branch2": 0.45051744258943127,
      "eval_f1_branch1": 0.9991774105847807,
      "eval_f1_branch2": 0.44985605046239,
      "eval_loss": 0.00020082936680410057,
      "eval_precision_branch1": 0.9992521297079157,
      "eval_precision_branch2": 0.5210427595160944,
      "eval_recall_branch1": 0.999105533530151,
      "eval_recall_branch2": 0.5198344955296432,
      "eval_runtime": 242.5757,
      "eval_samples_per_second": 427.425,
      "eval_steps_per_second": 53.431,
      "step": 84266
    },
    {
      "epoch": 26.001234186979328,
      "grad_norm": 0.012640462256968021,
      "learning_rate": 2.3998765813020674e-05,
      "loss": 0.0015,
      "step": 84270
    },
    {
      "epoch": 26.004319654427647,
      "grad_norm": 7.984491821844131e-05,
      "learning_rate": 2.3995680345572356e-05,
      "loss": 0.0003,
      "step": 84280
    },
    {
      "epoch": 26.007405121875966,
      "grad_norm": 0.0011652385583147407,
      "learning_rate": 2.3992594878124035e-05,
      "loss": 0.0,
      "step": 84290
    },
    {
      "epoch": 26.010490589324284,
      "grad_norm": 2.0740941181429662e-05,
      "learning_rate": 2.3989509410675718e-05,
      "loss": 0.0003,
      "step": 84300
    },
    {
      "epoch": 26.0135760567726,
      "grad_norm": 0.023639759048819542,
      "learning_rate": 2.39864239432274e-05,
      "loss": 0.0,
      "step": 84310
    },
    {
      "epoch": 26.01666152422092,
      "grad_norm": 2.586780071258545,
      "learning_rate": 2.3983338475779083e-05,
      "loss": 0.0013,
      "step": 84320
    },
    {
      "epoch": 26.019746991669237,
      "grad_norm": 0.04726777225732803,
      "learning_rate": 2.3980253008330765e-05,
      "loss": 0.0017,
      "step": 84330
    },
    {
      "epoch": 26.022832459117556,
      "grad_norm": 2.811658487189561e-05,
      "learning_rate": 2.3977167540882444e-05,
      "loss": 0.001,
      "step": 84340
    },
    {
      "epoch": 26.025917926565874,
      "grad_norm": 4.2013536585727707e-05,
      "learning_rate": 2.3974082073434127e-05,
      "loss": 0.0035,
      "step": 84350
    },
    {
      "epoch": 26.029003394014193,
      "grad_norm": 1.2539735507743899e-05,
      "learning_rate": 2.3970996605985806e-05,
      "loss": 0.0,
      "step": 84360
    },
    {
      "epoch": 26.032088861462512,
      "grad_norm": 0.06333964318037033,
      "learning_rate": 2.3967911138537488e-05,
      "loss": 0.0023,
      "step": 84370
    },
    {
      "epoch": 26.03517432891083,
      "grad_norm": 2.119343844242394e-05,
      "learning_rate": 2.396482567108917e-05,
      "loss": 0.0,
      "step": 84380
    },
    {
      "epoch": 26.03825979635915,
      "grad_norm": 2.848961958079599e-05,
      "learning_rate": 2.3961740203640853e-05,
      "loss": 0.0002,
      "step": 84390
    },
    {
      "epoch": 26.041345263807468,
      "grad_norm": 0.004977772943675518,
      "learning_rate": 2.3958654736192536e-05,
      "loss": 0.0021,
      "step": 84400
    },
    {
      "epoch": 26.044430731255787,
      "grad_norm": 0.0006084439810365438,
      "learning_rate": 2.3955569268744215e-05,
      "loss": 0.0001,
      "step": 84410
    },
    {
      "epoch": 26.047516198704102,
      "grad_norm": 5.0962447858182713e-05,
      "learning_rate": 2.3952483801295897e-05,
      "loss": 0.0005,
      "step": 84420
    },
    {
      "epoch": 26.05060166615242,
      "grad_norm": 0.0010645881993696094,
      "learning_rate": 2.394939833384758e-05,
      "loss": 0.0003,
      "step": 84430
    },
    {
      "epoch": 26.05368713360074,
      "grad_norm": 6.401305796543966e-08,
      "learning_rate": 2.3946312866399262e-05,
      "loss": 0.0,
      "step": 84440
    },
    {
      "epoch": 26.056772601049058,
      "grad_norm": 0.0001100973822758533,
      "learning_rate": 2.3943227398950945e-05,
      "loss": 0.0008,
      "step": 84450
    },
    {
      "epoch": 26.059858068497377,
      "grad_norm": 0.005506338085979223,
      "learning_rate": 2.3940141931502624e-05,
      "loss": 0.0,
      "step": 84460
    },
    {
      "epoch": 26.062943535945696,
      "grad_norm": 8.307990356115624e-05,
      "learning_rate": 2.3937056464054306e-05,
      "loss": 0.0001,
      "step": 84470
    },
    {
      "epoch": 26.066029003394014,
      "grad_norm": 1.381212587148184e-05,
      "learning_rate": 2.3933970996605985e-05,
      "loss": 0.0002,
      "step": 84480
    },
    {
      "epoch": 26.069114470842333,
      "grad_norm": 0.0002335177268832922,
      "learning_rate": 2.3930885529157668e-05,
      "loss": 0.0,
      "step": 84490
    },
    {
      "epoch": 26.07219993829065,
      "grad_norm": 0.003163699060678482,
      "learning_rate": 2.392780006170935e-05,
      "loss": 0.0002,
      "step": 84500
    },
    {
      "epoch": 26.07528540573897,
      "grad_norm": 0.0008493087952956557,
      "learning_rate": 2.3924714594261033e-05,
      "loss": 0.0001,
      "step": 84510
    },
    {
      "epoch": 26.07837087318729,
      "grad_norm": 0.0001578701048856601,
      "learning_rate": 2.3921629126812715e-05,
      "loss": 0.0,
      "step": 84520
    },
    {
      "epoch": 26.081456340635608,
      "grad_norm": 4.689603883889504e-05,
      "learning_rate": 2.3918543659364394e-05,
      "loss": 0.0001,
      "step": 84530
    },
    {
      "epoch": 26.084541808083923,
      "grad_norm": 2.1593630663119256e-05,
      "learning_rate": 2.3915458191916077e-05,
      "loss": 0.0003,
      "step": 84540
    },
    {
      "epoch": 26.087627275532242,
      "grad_norm": 0.0003513921983540058,
      "learning_rate": 2.391237272446776e-05,
      "loss": 0.0,
      "step": 84550
    },
    {
      "epoch": 26.09071274298056,
      "grad_norm": 0.6754403710365295,
      "learning_rate": 2.390928725701944e-05,
      "loss": 0.0054,
      "step": 84560
    },
    {
      "epoch": 26.09379821042888,
      "grad_norm": 9.829172631725669e-05,
      "learning_rate": 2.390620178957112e-05,
      "loss": 0.0004,
      "step": 84570
    },
    {
      "epoch": 26.096883677877198,
      "grad_norm": 6.443003803724423e-05,
      "learning_rate": 2.3903116322122803e-05,
      "loss": 0.0,
      "step": 84580
    },
    {
      "epoch": 26.099969145325517,
      "grad_norm": 0.0867869108915329,
      "learning_rate": 2.3900030854674486e-05,
      "loss": 0.0,
      "step": 84590
    },
    {
      "epoch": 26.103054612773835,
      "grad_norm": 0.0026595122180879116,
      "learning_rate": 2.3896945387226165e-05,
      "loss": 0.0,
      "step": 84600
    },
    {
      "epoch": 26.106140080222154,
      "grad_norm": 4.245889067533426e-05,
      "learning_rate": 2.3893859919777847e-05,
      "loss": 0.0008,
      "step": 84610
    },
    {
      "epoch": 26.109225547670473,
      "grad_norm": 0.0004442557692527771,
      "learning_rate": 2.389077445232953e-05,
      "loss": 0.0,
      "step": 84620
    },
    {
      "epoch": 26.11231101511879,
      "grad_norm": 0.00028173273312859237,
      "learning_rate": 2.388768898488121e-05,
      "loss": 0.0006,
      "step": 84630
    },
    {
      "epoch": 26.11539648256711,
      "grad_norm": 0.0001763643667800352,
      "learning_rate": 2.3884603517432895e-05,
      "loss": 0.0001,
      "step": 84640
    },
    {
      "epoch": 26.11848195001543,
      "grad_norm": 0.00011993250518571585,
      "learning_rate": 2.3881518049984574e-05,
      "loss": 0.0004,
      "step": 84650
    },
    {
      "epoch": 26.121567417463744,
      "grad_norm": 0.0045667956583201885,
      "learning_rate": 2.3878432582536256e-05,
      "loss": 0.0001,
      "step": 84660
    },
    {
      "epoch": 26.124652884912063,
      "grad_norm": 6.47241176920943e-05,
      "learning_rate": 2.3875347115087935e-05,
      "loss": 0.0025,
      "step": 84670
    },
    {
      "epoch": 26.12773835236038,
      "grad_norm": 4.786018962477101e-06,
      "learning_rate": 2.3872261647639618e-05,
      "loss": 0.0002,
      "step": 84680
    },
    {
      "epoch": 26.1308238198087,
      "grad_norm": 0.0840611606836319,
      "learning_rate": 2.38691761801913e-05,
      "loss": 0.0006,
      "step": 84690
    },
    {
      "epoch": 26.13390928725702,
      "grad_norm": 1.8276324453836423e-06,
      "learning_rate": 2.386609071274298e-05,
      "loss": 0.0,
      "step": 84700
    },
    {
      "epoch": 26.136994754705338,
      "grad_norm": 0.03388979285955429,
      "learning_rate": 2.3863005245294665e-05,
      "loss": 0.0038,
      "step": 84710
    },
    {
      "epoch": 26.140080222153657,
      "grad_norm": 6.849128840258345e-05,
      "learning_rate": 2.3859919777846344e-05,
      "loss": 0.0004,
      "step": 84720
    },
    {
      "epoch": 26.143165689601975,
      "grad_norm": 0.00033170051756314933,
      "learning_rate": 2.3856834310398027e-05,
      "loss": 0.0,
      "step": 84730
    },
    {
      "epoch": 26.146251157050294,
      "grad_norm": 0.035798873752355576,
      "learning_rate": 2.385374884294971e-05,
      "loss": 0.0001,
      "step": 84740
    },
    {
      "epoch": 26.149336624498613,
      "grad_norm": 2.6062512915814295e-05,
      "learning_rate": 2.385066337550139e-05,
      "loss": 0.0002,
      "step": 84750
    },
    {
      "epoch": 26.15242209194693,
      "grad_norm": 1.746045563777443e-05,
      "learning_rate": 2.384757790805307e-05,
      "loss": 0.0,
      "step": 84760
    },
    {
      "epoch": 26.155507559395247,
      "grad_norm": 1.0443143764859997e-05,
      "learning_rate": 2.384449244060475e-05,
      "loss": 0.0,
      "step": 84770
    },
    {
      "epoch": 26.158593026843565,
      "grad_norm": 2.2696471205563284e-05,
      "learning_rate": 2.3841406973156436e-05,
      "loss": 0.0,
      "step": 84780
    },
    {
      "epoch": 26.161678494291884,
      "grad_norm": 0.00033853345667012036,
      "learning_rate": 2.3838321505708115e-05,
      "loss": 0.0,
      "step": 84790
    },
    {
      "epoch": 26.164763961740203,
      "grad_norm": 0.0001088743083528243,
      "learning_rate": 2.3835236038259797e-05,
      "loss": 0.0014,
      "step": 84800
    },
    {
      "epoch": 26.16784942918852,
      "grad_norm": 3.185815558026661e-06,
      "learning_rate": 2.383215057081148e-05,
      "loss": 0.0,
      "step": 84810
    },
    {
      "epoch": 26.17093489663684,
      "grad_norm": 0.0011423320975154638,
      "learning_rate": 2.382906510336316e-05,
      "loss": 0.0,
      "step": 84820
    },
    {
      "epoch": 26.17402036408516,
      "grad_norm": 0.0239399541169405,
      "learning_rate": 2.382597963591484e-05,
      "loss": 0.0002,
      "step": 84830
    },
    {
      "epoch": 26.177105831533478,
      "grad_norm": 0.01649990864098072,
      "learning_rate": 2.3822894168466524e-05,
      "loss": 0.0,
      "step": 84840
    },
    {
      "epoch": 26.180191298981796,
      "grad_norm": 2.5288902179454453e-05,
      "learning_rate": 2.3819808701018206e-05,
      "loss": 0.0,
      "step": 84850
    },
    {
      "epoch": 26.183276766430115,
      "grad_norm": 7.27421547708218e-06,
      "learning_rate": 2.381672323356989e-05,
      "loss": 0.0001,
      "step": 84860
    },
    {
      "epoch": 26.186362233878434,
      "grad_norm": 0.000605371780693531,
      "learning_rate": 2.3813637766121568e-05,
      "loss": 0.0002,
      "step": 84870
    },
    {
      "epoch": 26.189447701326753,
      "grad_norm": 0.0011852430179715157,
      "learning_rate": 2.381055229867325e-05,
      "loss": 0.0008,
      "step": 84880
    },
    {
      "epoch": 26.192533168775068,
      "grad_norm": 0.0003211354196537286,
      "learning_rate": 2.380746683122493e-05,
      "loss": 0.0003,
      "step": 84890
    },
    {
      "epoch": 26.195618636223386,
      "grad_norm": 0.03211541473865509,
      "learning_rate": 2.3804381363776612e-05,
      "loss": 0.0006,
      "step": 84900
    },
    {
      "epoch": 26.198704103671705,
      "grad_norm": 1.8420912965666503e-05,
      "learning_rate": 2.3801295896328295e-05,
      "loss": 0.0001,
      "step": 84910
    },
    {
      "epoch": 26.201789571120024,
      "grad_norm": 0.0010615807259455323,
      "learning_rate": 2.3798210428879977e-05,
      "loss": 0.0003,
      "step": 84920
    },
    {
      "epoch": 26.204875038568343,
      "grad_norm": 9.77494983089855e-06,
      "learning_rate": 2.379512496143166e-05,
      "loss": 0.0,
      "step": 84930
    },
    {
      "epoch": 26.20796050601666,
      "grad_norm": 0.005291630048304796,
      "learning_rate": 2.379203949398334e-05,
      "loss": 0.0,
      "step": 84940
    },
    {
      "epoch": 26.21104597346498,
      "grad_norm": 0.0024067023769021034,
      "learning_rate": 2.378895402653502e-05,
      "loss": 0.0,
      "step": 84950
    },
    {
      "epoch": 26.2141314409133,
      "grad_norm": 2.6964527933159843e-05,
      "learning_rate": 2.3785868559086704e-05,
      "loss": 0.0,
      "step": 84960
    },
    {
      "epoch": 26.217216908361618,
      "grad_norm": 8.514913497492671e-05,
      "learning_rate": 2.3782783091638383e-05,
      "loss": 0.0039,
      "step": 84970
    },
    {
      "epoch": 26.220302375809936,
      "grad_norm": 0.0004138744552619755,
      "learning_rate": 2.377969762419007e-05,
      "loss": 0.0001,
      "step": 84980
    },
    {
      "epoch": 26.223387843258255,
      "grad_norm": 1.1358907840985921e-06,
      "learning_rate": 2.3776612156741748e-05,
      "loss": 0.0002,
      "step": 84990
    },
    {
      "epoch": 26.226473310706574,
      "grad_norm": 4.734751200885512e-06,
      "learning_rate": 2.377352668929343e-05,
      "loss": 0.0005,
      "step": 85000
    },
    {
      "epoch": 26.22955877815489,
      "grad_norm": 6.113491690484807e-05,
      "learning_rate": 2.377044122184511e-05,
      "loss": 0.0001,
      "step": 85010
    },
    {
      "epoch": 26.232644245603208,
      "grad_norm": 4.630222974810749e-05,
      "learning_rate": 2.376735575439679e-05,
      "loss": 0.0008,
      "step": 85020
    },
    {
      "epoch": 26.235729713051526,
      "grad_norm": 0.00015965527563821524,
      "learning_rate": 2.3764270286948474e-05,
      "loss": 0.0001,
      "step": 85030
    },
    {
      "epoch": 26.238815180499845,
      "grad_norm": 0.24754972755908966,
      "learning_rate": 2.3761184819500153e-05,
      "loss": 0.0024,
      "step": 85040
    },
    {
      "epoch": 26.241900647948164,
      "grad_norm": 0.0001625131699256599,
      "learning_rate": 2.375809935205184e-05,
      "loss": 0.0005,
      "step": 85050
    },
    {
      "epoch": 26.244986115396483,
      "grad_norm": 0.00012921296001877636,
      "learning_rate": 2.3755013884603518e-05,
      "loss": 0.0007,
      "step": 85060
    },
    {
      "epoch": 26.2480715828448,
      "grad_norm": 0.0004938417696394026,
      "learning_rate": 2.37519284171552e-05,
      "loss": 0.0018,
      "step": 85070
    },
    {
      "epoch": 26.25115705029312,
      "grad_norm": 0.035424038767814636,
      "learning_rate": 2.3748842949706883e-05,
      "loss": 0.0001,
      "step": 85080
    },
    {
      "epoch": 26.25424251774144,
      "grad_norm": 0.012992724776268005,
      "learning_rate": 2.3745757482258562e-05,
      "loss": 0.0,
      "step": 85090
    },
    {
      "epoch": 26.257327985189757,
      "grad_norm": 0.00024335722264368087,
      "learning_rate": 2.3742672014810245e-05,
      "loss": 0.0015,
      "step": 85100
    },
    {
      "epoch": 26.260413452638076,
      "grad_norm": 0.00023486527788918465,
      "learning_rate": 2.3739586547361927e-05,
      "loss": 0.0001,
      "step": 85110
    },
    {
      "epoch": 26.26349892008639,
      "grad_norm": 0.0019210866885259748,
      "learning_rate": 2.373650107991361e-05,
      "loss": 0.0,
      "step": 85120
    },
    {
      "epoch": 26.26658438753471,
      "grad_norm": 0.0006539062596857548,
      "learning_rate": 2.373341561246529e-05,
      "loss": 0.0035,
      "step": 85130
    },
    {
      "epoch": 26.26966985498303,
      "grad_norm": 8.353334123967215e-06,
      "learning_rate": 2.373033014501697e-05,
      "loss": 0.0023,
      "step": 85140
    },
    {
      "epoch": 26.272755322431347,
      "grad_norm": 0.0015539738815277815,
      "learning_rate": 2.3727244677568654e-05,
      "loss": 0.0001,
      "step": 85150
    },
    {
      "epoch": 26.275840789879666,
      "grad_norm": 0.0003555592556949705,
      "learning_rate": 2.3724159210120333e-05,
      "loss": 0.0001,
      "step": 85160
    },
    {
      "epoch": 26.278926257327985,
      "grad_norm": 8.052153788185024e-08,
      "learning_rate": 2.3721073742672015e-05,
      "loss": 0.0004,
      "step": 85170
    },
    {
      "epoch": 26.282011724776304,
      "grad_norm": 6.036419790689251e-07,
      "learning_rate": 2.3717988275223698e-05,
      "loss": 0.0,
      "step": 85180
    },
    {
      "epoch": 26.285097192224622,
      "grad_norm": 0.13814677298069,
      "learning_rate": 2.371490280777538e-05,
      "loss": 0.0001,
      "step": 85190
    },
    {
      "epoch": 26.28818265967294,
      "grad_norm": 0.00032899039797484875,
      "learning_rate": 2.3711817340327063e-05,
      "loss": 0.001,
      "step": 85200
    },
    {
      "epoch": 26.29126812712126,
      "grad_norm": 3.8902358937775716e-05,
      "learning_rate": 2.3708731872878742e-05,
      "loss": 0.0001,
      "step": 85210
    },
    {
      "epoch": 26.29435359456958,
      "grad_norm": 1.019023602566449e-05,
      "learning_rate": 2.3705646405430424e-05,
      "loss": 0.0001,
      "step": 85220
    },
    {
      "epoch": 26.297439062017897,
      "grad_norm": 0.0028626665007323027,
      "learning_rate": 2.3702560937982103e-05,
      "loss": 0.0038,
      "step": 85230
    },
    {
      "epoch": 26.300524529466212,
      "grad_norm": 0.0028956029564142227,
      "learning_rate": 2.3699475470533786e-05,
      "loss": 0.0,
      "step": 85240
    },
    {
      "epoch": 26.30360999691453,
      "grad_norm": 0.00011252389231231064,
      "learning_rate": 2.3696390003085468e-05,
      "loss": 0.0,
      "step": 85250
    },
    {
      "epoch": 26.30669546436285,
      "grad_norm": 9.709491678222548e-06,
      "learning_rate": 2.369330453563715e-05,
      "loss": 0.0,
      "step": 85260
    },
    {
      "epoch": 26.30978093181117,
      "grad_norm": 0.00023506084107793868,
      "learning_rate": 2.3690219068188833e-05,
      "loss": 0.0,
      "step": 85270
    },
    {
      "epoch": 26.312866399259487,
      "grad_norm": 0.0019270492484793067,
      "learning_rate": 2.3687133600740512e-05,
      "loss": 0.0001,
      "step": 85280
    },
    {
      "epoch": 26.315951866707806,
      "grad_norm": 5.6864057114580646e-05,
      "learning_rate": 2.3684048133292195e-05,
      "loss": 0.0,
      "step": 85290
    },
    {
      "epoch": 26.319037334156125,
      "grad_norm": 0.0006123575149103999,
      "learning_rate": 2.3680962665843874e-05,
      "loss": 0.0007,
      "step": 85300
    },
    {
      "epoch": 26.322122801604444,
      "grad_norm": 1.4827044010162354,
      "learning_rate": 2.367787719839556e-05,
      "loss": 0.0014,
      "step": 85310
    },
    {
      "epoch": 26.325208269052762,
      "grad_norm": 3.1059938919497654e-05,
      "learning_rate": 2.3674791730947242e-05,
      "loss": 0.0016,
      "step": 85320
    },
    {
      "epoch": 26.32829373650108,
      "grad_norm": 0.4551279544830322,
      "learning_rate": 2.367170626349892e-05,
      "loss": 0.0002,
      "step": 85330
    },
    {
      "epoch": 26.3313792039494,
      "grad_norm": 0.00010609137098072097,
      "learning_rate": 2.3668620796050604e-05,
      "loss": 0.0,
      "step": 85340
    },
    {
      "epoch": 26.33446467139772,
      "grad_norm": 0.012213810347020626,
      "learning_rate": 2.3665535328602283e-05,
      "loss": 0.0001,
      "step": 85350
    },
    {
      "epoch": 26.337550138846034,
      "grad_norm": 0.0010663644643500447,
      "learning_rate": 2.3662449861153965e-05,
      "loss": 0.0001,
      "step": 85360
    },
    {
      "epoch": 26.340635606294352,
      "grad_norm": 2.8603086320799775e-05,
      "learning_rate": 2.3659364393705648e-05,
      "loss": 0.0139,
      "step": 85370
    },
    {
      "epoch": 26.34372107374267,
      "grad_norm": 0.0004723863967228681,
      "learning_rate": 2.365627892625733e-05,
      "loss": 0.0,
      "step": 85380
    },
    {
      "epoch": 26.34680654119099,
      "grad_norm": 0.0002940908307209611,
      "learning_rate": 2.3653193458809013e-05,
      "loss": 0.0001,
      "step": 85390
    },
    {
      "epoch": 26.34989200863931,
      "grad_norm": 0.011146917939186096,
      "learning_rate": 2.3650107991360692e-05,
      "loss": 0.0008,
      "step": 85400
    },
    {
      "epoch": 26.352977476087627,
      "grad_norm": 1.8753037452697754,
      "learning_rate": 2.3647022523912374e-05,
      "loss": 0.0092,
      "step": 85410
    },
    {
      "epoch": 26.356062943535946,
      "grad_norm": 5.3633870265912265e-05,
      "learning_rate": 2.3643937056464053e-05,
      "loss": 0.0001,
      "step": 85420
    },
    {
      "epoch": 26.359148410984265,
      "grad_norm": 0.012599359266459942,
      "learning_rate": 2.3640851589015736e-05,
      "loss": 0.0003,
      "step": 85430
    },
    {
      "epoch": 26.362233878432583,
      "grad_norm": 0.07118544727563858,
      "learning_rate": 2.363776612156742e-05,
      "loss": 0.0134,
      "step": 85440
    },
    {
      "epoch": 26.365319345880902,
      "grad_norm": 9.355034126201645e-05,
      "learning_rate": 2.36346806541191e-05,
      "loss": 0.0,
      "step": 85450
    },
    {
      "epoch": 26.36840481332922,
      "grad_norm": 3.135107908747159e-05,
      "learning_rate": 2.3631595186670783e-05,
      "loss": 0.0013,
      "step": 85460
    },
    {
      "epoch": 26.37149028077754,
      "grad_norm": 0.010222512297332287,
      "learning_rate": 2.3628509719222462e-05,
      "loss": 0.0038,
      "step": 85470
    },
    {
      "epoch": 26.374575748225855,
      "grad_norm": 0.010814007371664047,
      "learning_rate": 2.3625424251774145e-05,
      "loss": 0.0,
      "step": 85480
    },
    {
      "epoch": 26.377661215674173,
      "grad_norm": 0.0030914167873561382,
      "learning_rate": 2.3622338784325827e-05,
      "loss": 0.0021,
      "step": 85490
    },
    {
      "epoch": 26.380746683122492,
      "grad_norm": 0.0020085882861167192,
      "learning_rate": 2.3619253316877506e-05,
      "loss": 0.0,
      "step": 85500
    },
    {
      "epoch": 26.38383215057081,
      "grad_norm": 5.3199306421447545e-05,
      "learning_rate": 2.3616167849429192e-05,
      "loss": 0.0,
      "step": 85510
    },
    {
      "epoch": 26.38691761801913,
      "grad_norm": 0.024911627173423767,
      "learning_rate": 2.361308238198087e-05,
      "loss": 0.0001,
      "step": 85520
    },
    {
      "epoch": 26.39000308546745,
      "grad_norm": 0.12941566109657288,
      "learning_rate": 2.3609996914532554e-05,
      "loss": 0.0001,
      "step": 85530
    },
    {
      "epoch": 26.393088552915767,
      "grad_norm": 0.0015241741202771664,
      "learning_rate": 2.3606911447084233e-05,
      "loss": 0.0002,
      "step": 85540
    },
    {
      "epoch": 26.396174020364086,
      "grad_norm": 0.0022417104337364435,
      "learning_rate": 2.3603825979635915e-05,
      "loss": 0.0102,
      "step": 85550
    },
    {
      "epoch": 26.399259487812405,
      "grad_norm": 0.0021360893733799458,
      "learning_rate": 2.3600740512187598e-05,
      "loss": 0.0012,
      "step": 85560
    },
    {
      "epoch": 26.402344955260723,
      "grad_norm": 0.0005136663094162941,
      "learning_rate": 2.3597655044739277e-05,
      "loss": 0.0005,
      "step": 85570
    },
    {
      "epoch": 26.405430422709042,
      "grad_norm": 3.4451517421985045e-05,
      "learning_rate": 2.3594569577290963e-05,
      "loss": 0.0001,
      "step": 85580
    },
    {
      "epoch": 26.408515890157357,
      "grad_norm": 0.009098952636122704,
      "learning_rate": 2.3591484109842642e-05,
      "loss": 0.0,
      "step": 85590
    },
    {
      "epoch": 26.411601357605676,
      "grad_norm": 0.0025541922077536583,
      "learning_rate": 2.3588398642394324e-05,
      "loss": 0.0,
      "step": 85600
    },
    {
      "epoch": 26.414686825053995,
      "grad_norm": 0.00012369085743557662,
      "learning_rate": 2.3585313174946007e-05,
      "loss": 0.0,
      "step": 85610
    },
    {
      "epoch": 26.417772292502313,
      "grad_norm": 3.278493386460468e-05,
      "learning_rate": 2.3582227707497686e-05,
      "loss": 0.0005,
      "step": 85620
    },
    {
      "epoch": 26.420857759950632,
      "grad_norm": 0.007763728033751249,
      "learning_rate": 2.357914224004937e-05,
      "loss": 0.0,
      "step": 85630
    },
    {
      "epoch": 26.42394322739895,
      "grad_norm": 0.3637787401676178,
      "learning_rate": 2.3576056772601048e-05,
      "loss": 0.0013,
      "step": 85640
    },
    {
      "epoch": 26.42702869484727,
      "grad_norm": 0.0009816056117415428,
      "learning_rate": 2.3572971305152733e-05,
      "loss": 0.0004,
      "step": 85650
    },
    {
      "epoch": 26.430114162295588,
      "grad_norm": 0.019462285563349724,
      "learning_rate": 2.3569885837704413e-05,
      "loss": 0.0,
      "step": 85660
    },
    {
      "epoch": 26.433199629743907,
      "grad_norm": 0.0002812255406752229,
      "learning_rate": 2.3566800370256095e-05,
      "loss": 0.0024,
      "step": 85670
    },
    {
      "epoch": 26.436285097192226,
      "grad_norm": 3.630815399446874e-06,
      "learning_rate": 2.3563714902807777e-05,
      "loss": 0.0005,
      "step": 85680
    },
    {
      "epoch": 26.439370564640544,
      "grad_norm": 2.7621904337138403e-06,
      "learning_rate": 2.3560629435359457e-05,
      "loss": 0.0,
      "step": 85690
    },
    {
      "epoch": 26.442456032088863,
      "grad_norm": 7.049777650536271e-06,
      "learning_rate": 2.355754396791114e-05,
      "loss": 0.0002,
      "step": 85700
    },
    {
      "epoch": 26.44554149953718,
      "grad_norm": 5.520322247321019e-06,
      "learning_rate": 2.355445850046282e-05,
      "loss": 0.0001,
      "step": 85710
    },
    {
      "epoch": 26.448626966985497,
      "grad_norm": 0.0011533800279721618,
      "learning_rate": 2.3551373033014504e-05,
      "loss": 0.0007,
      "step": 85720
    },
    {
      "epoch": 26.451712434433816,
      "grad_norm": 1.350432194158202e-05,
      "learning_rate": 2.3548287565566186e-05,
      "loss": 0.0,
      "step": 85730
    },
    {
      "epoch": 26.454797901882134,
      "grad_norm": 0.10601016879081726,
      "learning_rate": 2.3545202098117866e-05,
      "loss": 0.0001,
      "step": 85740
    },
    {
      "epoch": 26.457883369330453,
      "grad_norm": 0.0043540229089558125,
      "learning_rate": 2.3542116630669548e-05,
      "loss": 0.0,
      "step": 85750
    },
    {
      "epoch": 26.460968836778772,
      "grad_norm": 0.06782519817352295,
      "learning_rate": 2.3539031163221227e-05,
      "loss": 0.0007,
      "step": 85760
    },
    {
      "epoch": 26.46405430422709,
      "grad_norm": 0.02949584648013115,
      "learning_rate": 2.353594569577291e-05,
      "loss": 0.0,
      "step": 85770
    },
    {
      "epoch": 26.46713977167541,
      "grad_norm": 4.9892751121660694e-06,
      "learning_rate": 2.3532860228324592e-05,
      "loss": 0.0001,
      "step": 85780
    },
    {
      "epoch": 26.470225239123728,
      "grad_norm": 2.4665533260304073e-07,
      "learning_rate": 2.3529774760876275e-05,
      "loss": 0.0,
      "step": 85790
    },
    {
      "epoch": 26.473310706572047,
      "grad_norm": 6.674705218756571e-05,
      "learning_rate": 2.3526689293427957e-05,
      "loss": 0.0002,
      "step": 85800
    },
    {
      "epoch": 26.476396174020365,
      "grad_norm": 0.007513080723583698,
      "learning_rate": 2.3523603825979636e-05,
      "loss": 0.0,
      "step": 85810
    },
    {
      "epoch": 26.479481641468684,
      "grad_norm": 0.01971890777349472,
      "learning_rate": 2.352051835853132e-05,
      "loss": 0.0,
      "step": 85820
    },
    {
      "epoch": 26.482567108917,
      "grad_norm": 9.151852282229811e-05,
      "learning_rate": 2.3517432891083e-05,
      "loss": 0.0,
      "step": 85830
    },
    {
      "epoch": 26.485652576365318,
      "grad_norm": 0.0002494008804205805,
      "learning_rate": 2.351434742363468e-05,
      "loss": 0.0001,
      "step": 85840
    },
    {
      "epoch": 26.488738043813637,
      "grad_norm": 0.001817234675399959,
      "learning_rate": 2.3511261956186366e-05,
      "loss": 0.0,
      "step": 85850
    },
    {
      "epoch": 26.491823511261956,
      "grad_norm": 0.0015153138665482402,
      "learning_rate": 2.3508176488738045e-05,
      "loss": 0.0,
      "step": 85860
    },
    {
      "epoch": 26.494908978710274,
      "grad_norm": 0.0002556967665441334,
      "learning_rate": 2.3505091021289728e-05,
      "loss": 0.0,
      "step": 85870
    },
    {
      "epoch": 26.497994446158593,
      "grad_norm": 0.004367238376289606,
      "learning_rate": 2.3502005553841407e-05,
      "loss": 0.0007,
      "step": 85880
    },
    {
      "epoch": 26.50107991360691,
      "grad_norm": 0.12673716247081757,
      "learning_rate": 2.349892008639309e-05,
      "loss": 0.0007,
      "step": 85890
    },
    {
      "epoch": 26.50416538105523,
      "grad_norm": 8.753388101467863e-05,
      "learning_rate": 2.349583461894477e-05,
      "loss": 0.0007,
      "step": 85900
    },
    {
      "epoch": 26.50725084850355,
      "grad_norm": 3.604362063924782e-05,
      "learning_rate": 2.349274915149645e-05,
      "loss": 0.001,
      "step": 85910
    },
    {
      "epoch": 26.510336315951868,
      "grad_norm": 0.0033620030153542757,
      "learning_rate": 2.3489663684048137e-05,
      "loss": 0.0,
      "step": 85920
    },
    {
      "epoch": 26.513421783400187,
      "grad_norm": 1.2571923434734344e-05,
      "learning_rate": 2.3486578216599816e-05,
      "loss": 0.0003,
      "step": 85930
    },
    {
      "epoch": 26.516507250848505,
      "grad_norm": 0.00013724688324145973,
      "learning_rate": 2.3483492749151498e-05,
      "loss": 0.0001,
      "step": 85940
    },
    {
      "epoch": 26.51959271829682,
      "grad_norm": 0.00014018273213878274,
      "learning_rate": 2.3480407281703177e-05,
      "loss": 0.0,
      "step": 85950
    },
    {
      "epoch": 26.52267818574514,
      "grad_norm": 0.00011701403855113313,
      "learning_rate": 2.347732181425486e-05,
      "loss": 0.0,
      "step": 85960
    },
    {
      "epoch": 26.525763653193458,
      "grad_norm": 0.027910126373171806,
      "learning_rate": 2.3474236346806542e-05,
      "loss": 0.0015,
      "step": 85970
    },
    {
      "epoch": 26.528849120641777,
      "grad_norm": 0.1489545851945877,
      "learning_rate": 2.3471150879358225e-05,
      "loss": 0.0002,
      "step": 85980
    },
    {
      "epoch": 26.531934588090095,
      "grad_norm": 0.0017820633947849274,
      "learning_rate": 2.3468065411909907e-05,
      "loss": 0.0,
      "step": 85990
    },
    {
      "epoch": 26.535020055538414,
      "grad_norm": 0.006751172710210085,
      "learning_rate": 2.3464979944461586e-05,
      "loss": 0.0,
      "step": 86000
    },
    {
      "epoch": 26.538105522986733,
      "grad_norm": 4.855465886066668e-05,
      "learning_rate": 2.346189447701327e-05,
      "loss": 0.0,
      "step": 86010
    },
    {
      "epoch": 26.54119099043505,
      "grad_norm": 7.569487934233621e-05,
      "learning_rate": 2.345880900956495e-05,
      "loss": 0.0,
      "step": 86020
    },
    {
      "epoch": 26.54427645788337,
      "grad_norm": 1.0695995092391968,
      "learning_rate": 2.345572354211663e-05,
      "loss": 0.0006,
      "step": 86030
    },
    {
      "epoch": 26.54736192533169,
      "grad_norm": 5.2732320909854025e-05,
      "learning_rate": 2.3452638074668313e-05,
      "loss": 0.0,
      "step": 86040
    },
    {
      "epoch": 26.550447392780008,
      "grad_norm": 0.00010963030945276842,
      "learning_rate": 2.3449552607219995e-05,
      "loss": 0.0002,
      "step": 86050
    },
    {
      "epoch": 26.553532860228323,
      "grad_norm": 0.00010563755495240912,
      "learning_rate": 2.3446467139771678e-05,
      "loss": 0.0012,
      "step": 86060
    },
    {
      "epoch": 26.55661832767664,
      "grad_norm": 0.002141401404514909,
      "learning_rate": 2.3443381672323357e-05,
      "loss": 0.0028,
      "step": 86070
    },
    {
      "epoch": 26.55970379512496,
      "grad_norm": 4.550280664261663e-06,
      "learning_rate": 2.344029620487504e-05,
      "loss": 0.0,
      "step": 86080
    },
    {
      "epoch": 26.56278926257328,
      "grad_norm": 0.0014164616586640477,
      "learning_rate": 2.3437210737426722e-05,
      "loss": 0.0,
      "step": 86090
    },
    {
      "epoch": 26.565874730021598,
      "grad_norm": 2.8136766559327953e-05,
      "learning_rate": 2.34341252699784e-05,
      "loss": 0.0001,
      "step": 86100
    },
    {
      "epoch": 26.568960197469917,
      "grad_norm": 6.279200169956312e-05,
      "learning_rate": 2.3431039802530083e-05,
      "loss": 0.0,
      "step": 86110
    },
    {
      "epoch": 26.572045664918235,
      "grad_norm": 0.0001795909192878753,
      "learning_rate": 2.3427954335081766e-05,
      "loss": 0.0,
      "step": 86120
    },
    {
      "epoch": 26.575131132366554,
      "grad_norm": 5.258013334241696e-05,
      "learning_rate": 2.3424868867633448e-05,
      "loss": 0.0004,
      "step": 86130
    },
    {
      "epoch": 26.578216599814873,
      "grad_norm": 1.764976514095906e-05,
      "learning_rate": 2.342178340018513e-05,
      "loss": 0.0001,
      "step": 86140
    },
    {
      "epoch": 26.58130206726319,
      "grad_norm": 1.5842460925341584e-05,
      "learning_rate": 2.341869793273681e-05,
      "loss": 0.0,
      "step": 86150
    },
    {
      "epoch": 26.58438753471151,
      "grad_norm": 0.02256634645164013,
      "learning_rate": 2.3415612465288492e-05,
      "loss": 0.0,
      "step": 86160
    },
    {
      "epoch": 26.58747300215983,
      "grad_norm": 1.842958590714261e-05,
      "learning_rate": 2.341252699784017e-05,
      "loss": 0.0,
      "step": 86170
    },
    {
      "epoch": 26.590558469608144,
      "grad_norm": 6.032027158653364e-06,
      "learning_rate": 2.3409441530391857e-05,
      "loss": 0.0,
      "step": 86180
    },
    {
      "epoch": 26.593643937056463,
      "grad_norm": 0.002693801885470748,
      "learning_rate": 2.3406356062943536e-05,
      "loss": 0.0,
      "step": 86190
    },
    {
      "epoch": 26.59672940450478,
      "grad_norm": 5.9557773056440055e-05,
      "learning_rate": 2.340327059549522e-05,
      "loss": 0.0,
      "step": 86200
    },
    {
      "epoch": 26.5998148719531,
      "grad_norm": 0.041258227080106735,
      "learning_rate": 2.34001851280469e-05,
      "loss": 0.0,
      "step": 86210
    },
    {
      "epoch": 26.60290033940142,
      "grad_norm": 0.0029117760714143515,
      "learning_rate": 2.339709966059858e-05,
      "loss": 0.0,
      "step": 86220
    },
    {
      "epoch": 26.605985806849738,
      "grad_norm": 0.001732224365696311,
      "learning_rate": 2.3394014193150263e-05,
      "loss": 0.0,
      "step": 86230
    },
    {
      "epoch": 26.609071274298056,
      "grad_norm": 2.8336298782960512e-05,
      "learning_rate": 2.3390928725701945e-05,
      "loss": 0.0,
      "step": 86240
    },
    {
      "epoch": 26.612156741746375,
      "grad_norm": 0.0003845257160719484,
      "learning_rate": 2.3387843258253628e-05,
      "loss": 0.0012,
      "step": 86250
    },
    {
      "epoch": 26.615242209194694,
      "grad_norm": 0.0010524356039240956,
      "learning_rate": 2.338475779080531e-05,
      "loss": 0.0,
      "step": 86260
    },
    {
      "epoch": 26.618327676643013,
      "grad_norm": 1.3152168321539648e-05,
      "learning_rate": 2.338167232335699e-05,
      "loss": 0.0001,
      "step": 86270
    },
    {
      "epoch": 26.62141314409133,
      "grad_norm": 0.0011478016385808587,
      "learning_rate": 2.3378586855908672e-05,
      "loss": 0.0,
      "step": 86280
    },
    {
      "epoch": 26.62449861153965,
      "grad_norm": 0.0014557227259501815,
      "learning_rate": 2.337550138846035e-05,
      "loss": 0.0001,
      "step": 86290
    },
    {
      "epoch": 26.627584078987965,
      "grad_norm": 6.439904041144473e-07,
      "learning_rate": 2.3372415921012033e-05,
      "loss": 0.0001,
      "step": 86300
    },
    {
      "epoch": 26.630669546436284,
      "grad_norm": 1.2383045032038353e-05,
      "learning_rate": 2.3369330453563716e-05,
      "loss": 0.0001,
      "step": 86310
    },
    {
      "epoch": 26.633755013884603,
      "grad_norm": 0.0012680931249633431,
      "learning_rate": 2.33662449861154e-05,
      "loss": 0.0,
      "step": 86320
    },
    {
      "epoch": 26.63684048133292,
      "grad_norm": 0.00022428156808018684,
      "learning_rate": 2.336315951866708e-05,
      "loss": 0.0,
      "step": 86330
    },
    {
      "epoch": 26.63992594878124,
      "grad_norm": 0.0008173116366378963,
      "learning_rate": 2.336007405121876e-05,
      "loss": 0.0,
      "step": 86340
    },
    {
      "epoch": 26.64301141622956,
      "grad_norm": 0.002406031358987093,
      "learning_rate": 2.3356988583770442e-05,
      "loss": 0.0004,
      "step": 86350
    },
    {
      "epoch": 26.646096883677878,
      "grad_norm": 0.00016745955508667976,
      "learning_rate": 2.3353903116322125e-05,
      "loss": 0.0002,
      "step": 86360
    },
    {
      "epoch": 26.649182351126196,
      "grad_norm": 0.001323993201367557,
      "learning_rate": 2.3350817648873804e-05,
      "loss": 0.0007,
      "step": 86370
    },
    {
      "epoch": 26.652267818574515,
      "grad_norm": 0.0004968182183802128,
      "learning_rate": 2.334773218142549e-05,
      "loss": 0.0002,
      "step": 86380
    },
    {
      "epoch": 26.655353286022834,
      "grad_norm": 0.00010236033267574385,
      "learning_rate": 2.334464671397717e-05,
      "loss": 0.0,
      "step": 86390
    },
    {
      "epoch": 26.658438753471152,
      "grad_norm": 0.0038866568356752396,
      "learning_rate": 2.334156124652885e-05,
      "loss": 0.0055,
      "step": 86400
    },
    {
      "epoch": 26.661524220919468,
      "grad_norm": 0.10824094712734222,
      "learning_rate": 2.333847577908053e-05,
      "loss": 0.0001,
      "step": 86410
    },
    {
      "epoch": 26.664609688367786,
      "grad_norm": 0.08199046552181244,
      "learning_rate": 2.3335390311632213e-05,
      "loss": 0.0001,
      "step": 86420
    },
    {
      "epoch": 26.667695155816105,
      "grad_norm": 7.156024366850033e-05,
      "learning_rate": 2.3332304844183896e-05,
      "loss": 0.0001,
      "step": 86430
    },
    {
      "epoch": 26.670780623264424,
      "grad_norm": 8.107005669444334e-06,
      "learning_rate": 2.3329219376735575e-05,
      "loss": 0.0017,
      "step": 86440
    },
    {
      "epoch": 26.673866090712743,
      "grad_norm": 1.979759931564331,
      "learning_rate": 2.332613390928726e-05,
      "loss": 0.0014,
      "step": 86450
    },
    {
      "epoch": 26.67695155816106,
      "grad_norm": 0.001575354253873229,
      "learning_rate": 2.332304844183894e-05,
      "loss": 0.0,
      "step": 86460
    },
    {
      "epoch": 26.68003702560938,
      "grad_norm": 0.0012425018940120935,
      "learning_rate": 2.3319962974390622e-05,
      "loss": 0.0,
      "step": 86470
    },
    {
      "epoch": 26.6831224930577,
      "grad_norm": 0.008842899464070797,
      "learning_rate": 2.3316877506942304e-05,
      "loss": 0.0,
      "step": 86480
    },
    {
      "epoch": 26.686207960506017,
      "grad_norm": 0.0011063413694500923,
      "learning_rate": 2.3313792039493984e-05,
      "loss": 0.0001,
      "step": 86490
    },
    {
      "epoch": 26.689293427954336,
      "grad_norm": 4.9393725021218415e-06,
      "learning_rate": 2.3310706572045666e-05,
      "loss": 0.0021,
      "step": 86500
    },
    {
      "epoch": 26.692378895402655,
      "grad_norm": 0.0009464864269830287,
      "learning_rate": 2.3307621104597345e-05,
      "loss": 0.0,
      "step": 86510
    },
    {
      "epoch": 26.695464362850974,
      "grad_norm": 6.833145562268328e-06,
      "learning_rate": 2.330453563714903e-05,
      "loss": 0.0017,
      "step": 86520
    },
    {
      "epoch": 26.69854983029929,
      "grad_norm": 0.00037235577474348247,
      "learning_rate": 2.330145016970071e-05,
      "loss": 0.0029,
      "step": 86530
    },
    {
      "epoch": 26.701635297747607,
      "grad_norm": 0.0001040122879203409,
      "learning_rate": 2.3298364702252393e-05,
      "loss": 0.0001,
      "step": 86540
    },
    {
      "epoch": 26.704720765195926,
      "grad_norm": 0.11915965378284454,
      "learning_rate": 2.3295279234804075e-05,
      "loss": 0.0002,
      "step": 86550
    },
    {
      "epoch": 26.707806232644245,
      "grad_norm": 0.00013120063522364944,
      "learning_rate": 2.3292193767355754e-05,
      "loss": 0.0044,
      "step": 86560
    },
    {
      "epoch": 26.710891700092564,
      "grad_norm": 0.09263774752616882,
      "learning_rate": 2.3289108299907437e-05,
      "loss": 0.0002,
      "step": 86570
    },
    {
      "epoch": 26.713977167540882,
      "grad_norm": 0.0002654173003975302,
      "learning_rate": 2.3286022832459116e-05,
      "loss": 0.0012,
      "step": 86580
    },
    {
      "epoch": 26.7170626349892,
      "grad_norm": 9.575978765496984e-06,
      "learning_rate": 2.32829373650108e-05,
      "loss": 0.0,
      "step": 86590
    },
    {
      "epoch": 26.72014810243752,
      "grad_norm": 0.00396577175706625,
      "learning_rate": 2.3279851897562484e-05,
      "loss": 0.0,
      "step": 86600
    },
    {
      "epoch": 26.72323356988584,
      "grad_norm": 0.00034900635364465415,
      "learning_rate": 2.3276766430114163e-05,
      "loss": 0.0004,
      "step": 86610
    },
    {
      "epoch": 26.726319037334157,
      "grad_norm": 0.6426530480384827,
      "learning_rate": 2.3273680962665846e-05,
      "loss": 0.0005,
      "step": 86620
    },
    {
      "epoch": 26.729404504782476,
      "grad_norm": 5.573703560912691e-07,
      "learning_rate": 2.3270595495217525e-05,
      "loss": 0.0002,
      "step": 86630
    },
    {
      "epoch": 26.732489972230795,
      "grad_norm": 0.016807017847895622,
      "learning_rate": 2.3267510027769207e-05,
      "loss": 0.0,
      "step": 86640
    },
    {
      "epoch": 26.73557543967911,
      "grad_norm": 0.0012098924489691854,
      "learning_rate": 2.326442456032089e-05,
      "loss": 0.0,
      "step": 86650
    },
    {
      "epoch": 26.73866090712743,
      "grad_norm": 0.0010860281763598323,
      "learning_rate": 2.3261339092872572e-05,
      "loss": 0.0,
      "step": 86660
    },
    {
      "epoch": 26.741746374575747,
      "grad_norm": 0.0004310317162889987,
      "learning_rate": 2.3258253625424255e-05,
      "loss": 0.0,
      "step": 86670
    },
    {
      "epoch": 26.744831842024066,
      "grad_norm": 0.0008204248151741922,
      "learning_rate": 2.3255168157975934e-05,
      "loss": 0.0059,
      "step": 86680
    },
    {
      "epoch": 26.747917309472385,
      "grad_norm": 0.0002972407091874629,
      "learning_rate": 2.3252082690527616e-05,
      "loss": 0.0001,
      "step": 86690
    },
    {
      "epoch": 26.751002776920703,
      "grad_norm": 4.850452569371555e-06,
      "learning_rate": 2.3248997223079295e-05,
      "loss": 0.0001,
      "step": 86700
    },
    {
      "epoch": 26.754088244369022,
      "grad_norm": 1.9824805349344388e-05,
      "learning_rate": 2.3245911755630978e-05,
      "loss": 0.0002,
      "step": 86710
    },
    {
      "epoch": 26.75717371181734,
      "grad_norm": 1.6178504665731452e-05,
      "learning_rate": 2.3242826288182664e-05,
      "loss": 0.002,
      "step": 86720
    },
    {
      "epoch": 26.76025917926566,
      "grad_norm": 0.008845912292599678,
      "learning_rate": 2.3239740820734343e-05,
      "loss": 0.0,
      "step": 86730
    },
    {
      "epoch": 26.76334464671398,
      "grad_norm": 7.106751581886783e-05,
      "learning_rate": 2.3236655353286025e-05,
      "loss": 0.0002,
      "step": 86740
    },
    {
      "epoch": 26.766430114162297,
      "grad_norm": 5.366915502236225e-05,
      "learning_rate": 2.3233569885837704e-05,
      "loss": 0.0,
      "step": 86750
    },
    {
      "epoch": 26.769515581610612,
      "grad_norm": 0.015058583579957485,
      "learning_rate": 2.3230484418389387e-05,
      "loss": 0.0,
      "step": 86760
    },
    {
      "epoch": 26.77260104905893,
      "grad_norm": 0.003405333496630192,
      "learning_rate": 2.322739895094107e-05,
      "loss": 0.0014,
      "step": 86770
    },
    {
      "epoch": 26.77568651650725,
      "grad_norm": 0.004181541036814451,
      "learning_rate": 2.322431348349275e-05,
      "loss": 0.0,
      "step": 86780
    },
    {
      "epoch": 26.77877198395557,
      "grad_norm": 0.012085755355656147,
      "learning_rate": 2.3221228016044434e-05,
      "loss": 0.0053,
      "step": 86790
    },
    {
      "epoch": 26.781857451403887,
      "grad_norm": 0.010622341185808182,
      "learning_rate": 2.3218142548596113e-05,
      "loss": 0.0,
      "step": 86800
    },
    {
      "epoch": 26.784942918852206,
      "grad_norm": 4.513495150604285e-05,
      "learning_rate": 2.3215057081147796e-05,
      "loss": 0.002,
      "step": 86810
    },
    {
      "epoch": 26.788028386300525,
      "grad_norm": 9.208630217472091e-05,
      "learning_rate": 2.3211971613699475e-05,
      "loss": 0.0058,
      "step": 86820
    },
    {
      "epoch": 26.791113853748843,
      "grad_norm": 0.10948214679956436,
      "learning_rate": 2.3208886146251157e-05,
      "loss": 0.0003,
      "step": 86830
    },
    {
      "epoch": 26.794199321197162,
      "grad_norm": 3.1800596714019775,
      "learning_rate": 2.320580067880284e-05,
      "loss": 0.0066,
      "step": 86840
    },
    {
      "epoch": 26.79728478864548,
      "grad_norm": 2.28971093747532e-05,
      "learning_rate": 2.3202715211354522e-05,
      "loss": 0.0005,
      "step": 86850
    },
    {
      "epoch": 26.8003702560938,
      "grad_norm": 0.5612611770629883,
      "learning_rate": 2.3199629743906205e-05,
      "loss": 0.0039,
      "step": 86860
    },
    {
      "epoch": 26.80345572354212,
      "grad_norm": 1.2001490592956543,
      "learning_rate": 2.3196544276457884e-05,
      "loss": 0.0017,
      "step": 86870
    },
    {
      "epoch": 26.806541190990433,
      "grad_norm": 0.006319540552794933,
      "learning_rate": 2.3193458809009566e-05,
      "loss": 0.0025,
      "step": 86880
    },
    {
      "epoch": 26.809626658438752,
      "grad_norm": 0.009078655391931534,
      "learning_rate": 2.319037334156125e-05,
      "loss": 0.0,
      "step": 86890
    },
    {
      "epoch": 26.81271212588707,
      "grad_norm": 0.0015017874538898468,
      "learning_rate": 2.3187287874112928e-05,
      "loss": 0.0096,
      "step": 86900
    },
    {
      "epoch": 26.81579759333539,
      "grad_norm": 3.531900644302368,
      "learning_rate": 2.318420240666461e-05,
      "loss": 0.0107,
      "step": 86910
    },
    {
      "epoch": 26.81888306078371,
      "grad_norm": 0.00027178102754987776,
      "learning_rate": 2.3181116939216293e-05,
      "loss": 0.0,
      "step": 86920
    },
    {
      "epoch": 26.821968528232027,
      "grad_norm": 0.00014126652968116105,
      "learning_rate": 2.3178031471767975e-05,
      "loss": 0.0002,
      "step": 86930
    },
    {
      "epoch": 26.825053995680346,
      "grad_norm": 5.796549320220947,
      "learning_rate": 2.3174946004319654e-05,
      "loss": 0.0074,
      "step": 86940
    },
    {
      "epoch": 26.828139463128664,
      "grad_norm": 0.42266690731048584,
      "learning_rate": 2.3171860536871337e-05,
      "loss": 0.0012,
      "step": 86950
    },
    {
      "epoch": 26.831224930576983,
      "grad_norm": 0.12217363715171814,
      "learning_rate": 2.316877506942302e-05,
      "loss": 0.0001,
      "step": 86960
    },
    {
      "epoch": 26.834310398025302,
      "grad_norm": 0.0006307486910372972,
      "learning_rate": 2.31656896019747e-05,
      "loss": 0.0026,
      "step": 86970
    },
    {
      "epoch": 26.83739586547362,
      "grad_norm": 0.00920988991856575,
      "learning_rate": 2.316260413452638e-05,
      "loss": 0.0004,
      "step": 86980
    },
    {
      "epoch": 26.84048133292194,
      "grad_norm": 0.0001314359251409769,
      "learning_rate": 2.3159518667078063e-05,
      "loss": 0.0005,
      "step": 86990
    },
    {
      "epoch": 26.843566800370255,
      "grad_norm": 2.858479547285242e-06,
      "learning_rate": 2.3156433199629746e-05,
      "loss": 0.0001,
      "step": 87000
    },
    {
      "epoch": 26.846652267818573,
      "grad_norm": 8.382458327105269e-05,
      "learning_rate": 2.315334773218143e-05,
      "loss": 0.0,
      "step": 87010
    },
    {
      "epoch": 26.849737735266892,
      "grad_norm": 0.006888167466968298,
      "learning_rate": 2.3150262264733107e-05,
      "loss": 0.0006,
      "step": 87020
    },
    {
      "epoch": 26.85282320271521,
      "grad_norm": 4.33113973485888e-06,
      "learning_rate": 2.314717679728479e-05,
      "loss": 0.0,
      "step": 87030
    },
    {
      "epoch": 26.85590867016353,
      "grad_norm": 0.1415053755044937,
      "learning_rate": 2.314409132983647e-05,
      "loss": 0.0001,
      "step": 87040
    },
    {
      "epoch": 26.858994137611848,
      "grad_norm": 8.355689828931645e-07,
      "learning_rate": 2.3141005862388155e-05,
      "loss": 0.0,
      "step": 87050
    },
    {
      "epoch": 26.862079605060167,
      "grad_norm": 0.027438722550868988,
      "learning_rate": 2.3137920394939834e-05,
      "loss": 0.0,
      "step": 87060
    },
    {
      "epoch": 26.865165072508486,
      "grad_norm": 0.009613597765564919,
      "learning_rate": 2.3134834927491516e-05,
      "loss": 0.0,
      "step": 87070
    },
    {
      "epoch": 26.868250539956804,
      "grad_norm": 0.12644967436790466,
      "learning_rate": 2.31317494600432e-05,
      "loss": 0.0003,
      "step": 87080
    },
    {
      "epoch": 26.871336007405123,
      "grad_norm": 1.7200499087266508e-06,
      "learning_rate": 2.3128663992594878e-05,
      "loss": 0.0001,
      "step": 87090
    },
    {
      "epoch": 26.874421474853442,
      "grad_norm": 0.0001537357020424679,
      "learning_rate": 2.312557852514656e-05,
      "loss": 0.0,
      "step": 87100
    },
    {
      "epoch": 26.877506942301757,
      "grad_norm": 2.2485473039068893e-07,
      "learning_rate": 2.312249305769824e-05,
      "loss": 0.0023,
      "step": 87110
    },
    {
      "epoch": 26.880592409750076,
      "grad_norm": 4.815181455342099e-06,
      "learning_rate": 2.3119407590249925e-05,
      "loss": 0.0,
      "step": 87120
    },
    {
      "epoch": 26.883677877198394,
      "grad_norm": 2.3577860702062026e-05,
      "learning_rate": 2.3116322122801608e-05,
      "loss": 0.0044,
      "step": 87130
    },
    {
      "epoch": 26.886763344646713,
      "grad_norm": 0.0005040013347752392,
      "learning_rate": 2.3113236655353287e-05,
      "loss": 0.0,
      "step": 87140
    },
    {
      "epoch": 26.889848812095032,
      "grad_norm": 0.00025141521473415196,
      "learning_rate": 2.311015118790497e-05,
      "loss": 0.0001,
      "step": 87150
    },
    {
      "epoch": 26.89293427954335,
      "grad_norm": 1.787599285307806e-05,
      "learning_rate": 2.310706572045665e-05,
      "loss": 0.0015,
      "step": 87160
    },
    {
      "epoch": 26.89601974699167,
      "grad_norm": 2.679390433968365e-07,
      "learning_rate": 2.310398025300833e-05,
      "loss": 0.0008,
      "step": 87170
    },
    {
      "epoch": 26.899105214439988,
      "grad_norm": 0.02093767561018467,
      "learning_rate": 2.3100894785560014e-05,
      "loss": 0.0001,
      "step": 87180
    },
    {
      "epoch": 26.902190681888307,
      "grad_norm": 0.00017198889690916985,
      "learning_rate": 2.3097809318111696e-05,
      "loss": 0.0,
      "step": 87190
    },
    {
      "epoch": 26.905276149336625,
      "grad_norm": 2.732324537646491e-05,
      "learning_rate": 2.309472385066338e-05,
      "loss": 0.0022,
      "step": 87200
    },
    {
      "epoch": 26.908361616784944,
      "grad_norm": 0.005349566228687763,
      "learning_rate": 2.3091638383215058e-05,
      "loss": 0.0,
      "step": 87210
    },
    {
      "epoch": 26.911447084233263,
      "grad_norm": 3.070886668865569e-05,
      "learning_rate": 2.308855291576674e-05,
      "loss": 0.0001,
      "step": 87220
    },
    {
      "epoch": 26.914532551681578,
      "grad_norm": 0.1578701138496399,
      "learning_rate": 2.308546744831842e-05,
      "loss": 0.0001,
      "step": 87230
    },
    {
      "epoch": 26.917618019129897,
      "grad_norm": 0.008777569979429245,
      "learning_rate": 2.30823819808701e-05,
      "loss": 0.0044,
      "step": 87240
    },
    {
      "epoch": 26.920703486578216,
      "grad_norm": 0.00018553424160927534,
      "learning_rate": 2.3079296513421787e-05,
      "loss": 0.0,
      "step": 87250
    },
    {
      "epoch": 26.923788954026534,
      "grad_norm": 0.11687473952770233,
      "learning_rate": 2.3076211045973467e-05,
      "loss": 0.0001,
      "step": 87260
    },
    {
      "epoch": 26.926874421474853,
      "grad_norm": 0.02329077012836933,
      "learning_rate": 2.307312557852515e-05,
      "loss": 0.0002,
      "step": 87270
    },
    {
      "epoch": 26.92995988892317,
      "grad_norm": 4.9756978114601225e-05,
      "learning_rate": 2.3070040111076828e-05,
      "loss": 0.0004,
      "step": 87280
    },
    {
      "epoch": 26.93304535637149,
      "grad_norm": 0.0001363643677905202,
      "learning_rate": 2.306695464362851e-05,
      "loss": 0.0001,
      "step": 87290
    },
    {
      "epoch": 26.93613082381981,
      "grad_norm": 0.00122083502355963,
      "learning_rate": 2.3063869176180193e-05,
      "loss": 0.0006,
      "step": 87300
    },
    {
      "epoch": 26.939216291268128,
      "grad_norm": 1.7341212696919683e-06,
      "learning_rate": 2.3060783708731872e-05,
      "loss": 0.0004,
      "step": 87310
    },
    {
      "epoch": 26.942301758716447,
      "grad_norm": 0.026659460738301277,
      "learning_rate": 2.3057698241283558e-05,
      "loss": 0.0004,
      "step": 87320
    },
    {
      "epoch": 26.945387226164765,
      "grad_norm": 0.006652116775512695,
      "learning_rate": 2.3054612773835237e-05,
      "loss": 0.0032,
      "step": 87330
    },
    {
      "epoch": 26.948472693613084,
      "grad_norm": 1.0338774700358044e-05,
      "learning_rate": 2.305152730638692e-05,
      "loss": 0.0002,
      "step": 87340
    },
    {
      "epoch": 26.9515581610614,
      "grad_norm": 0.07433280348777771,
      "learning_rate": 2.30484418389386e-05,
      "loss": 0.0001,
      "step": 87350
    },
    {
      "epoch": 26.954643628509718,
      "grad_norm": 0.005095366388559341,
      "learning_rate": 2.304535637149028e-05,
      "loss": 0.0004,
      "step": 87360
    },
    {
      "epoch": 26.957729095958037,
      "grad_norm": 0.007592670153826475,
      "learning_rate": 2.3042270904041964e-05,
      "loss": 0.0029,
      "step": 87370
    },
    {
      "epoch": 26.960814563406355,
      "grad_norm": 5.511327344720485e-06,
      "learning_rate": 2.3039185436593643e-05,
      "loss": 0.0002,
      "step": 87380
    },
    {
      "epoch": 26.963900030854674,
      "grad_norm": 1.2132787560403813e-05,
      "learning_rate": 2.303609996914533e-05,
      "loss": 0.0002,
      "step": 87390
    },
    {
      "epoch": 26.966985498302993,
      "grad_norm": 5.0447986723156646e-05,
      "learning_rate": 2.3033014501697008e-05,
      "loss": 0.0001,
      "step": 87400
    },
    {
      "epoch": 26.97007096575131,
      "grad_norm": 0.003914366941899061,
      "learning_rate": 2.302992903424869e-05,
      "loss": 0.0007,
      "step": 87410
    },
    {
      "epoch": 26.97315643319963,
      "grad_norm": 0.0025759730488061905,
      "learning_rate": 2.3026843566800373e-05,
      "loss": 0.0004,
      "step": 87420
    },
    {
      "epoch": 26.97624190064795,
      "grad_norm": 0.0026516783982515335,
      "learning_rate": 2.3023758099352052e-05,
      "loss": 0.0,
      "step": 87430
    },
    {
      "epoch": 26.979327368096268,
      "grad_norm": 3.910317536792718e-05,
      "learning_rate": 2.3020672631903734e-05,
      "loss": 0.0001,
      "step": 87440
    },
    {
      "epoch": 26.982412835544586,
      "grad_norm": 1.5948489817674272e-05,
      "learning_rate": 2.3017587164455413e-05,
      "loss": 0.0,
      "step": 87450
    },
    {
      "epoch": 26.9854983029929,
      "grad_norm": 1.2581510543823242,
      "learning_rate": 2.30145016970071e-05,
      "loss": 0.0007,
      "step": 87460
    },
    {
      "epoch": 26.98858377044122,
      "grad_norm": 1.1964009900111705e-05,
      "learning_rate": 2.3011416229558778e-05,
      "loss": 0.0001,
      "step": 87470
    },
    {
      "epoch": 26.99166923788954,
      "grad_norm": 0.0005152876256033778,
      "learning_rate": 2.300833076211046e-05,
      "loss": 0.0023,
      "step": 87480
    },
    {
      "epoch": 26.994754705337858,
      "grad_norm": 0.002230186015367508,
      "learning_rate": 2.3005245294662143e-05,
      "loss": 0.0,
      "step": 87490
    },
    {
      "epoch": 26.997840172786177,
      "grad_norm": 0.0007407912635244429,
      "learning_rate": 2.3002159827213822e-05,
      "loss": 0.0004,
      "step": 87500
    },
    {
      "epoch": 27.0,
      "eval_accuracy_branch1": 0.9999228417387614,
      "eval_accuracy_branch2": 0.4871965510257226,
      "eval_f1_branch1": 0.9999019816899793,
      "eval_f1_branch2": 0.4865140598401331,
      "eval_loss": 6.153794674901292e-05,
      "eval_precision_branch1": 0.9999032593613297,
      "eval_precision_branch2": 0.5328258628017235,
      "eval_recall_branch1": 0.999900735983811,
      "eval_recall_branch2": 0.5344246404907266,
      "eval_runtime": 238.783,
      "eval_samples_per_second": 434.214,
      "eval_steps_per_second": 54.279,
      "step": 87507
    },
    {
      "epoch": 27.000925640234495,
      "grad_norm": 1.3502279216481838e-05,
      "learning_rate": 2.2999074359765505e-05,
      "loss": 0.0,
      "step": 87510
    },
    {
      "epoch": 27.004011107682814,
      "grad_norm": 1.1786380127887242e-05,
      "learning_rate": 2.2995988892317187e-05,
      "loss": 0.0,
      "step": 87520
    },
    {
      "epoch": 27.007096575131133,
      "grad_norm": 0.003966900520026684,
      "learning_rate": 2.299290342486887e-05,
      "loss": 0.0011,
      "step": 87530
    },
    {
      "epoch": 27.01018204257945,
      "grad_norm": 0.001258965814486146,
      "learning_rate": 2.2989817957420552e-05,
      "loss": 0.0,
      "step": 87540
    },
    {
      "epoch": 27.01326751002777,
      "grad_norm": 0.005605694837868214,
      "learning_rate": 2.298673248997223e-05,
      "loss": 0.0,
      "step": 87550
    },
    {
      "epoch": 27.01635297747609,
      "grad_norm": 1.2141892511863261e-05,
      "learning_rate": 2.2983647022523914e-05,
      "loss": 0.0071,
      "step": 87560
    },
    {
      "epoch": 27.019438444924408,
      "grad_norm": 2.228781522717327e-05,
      "learning_rate": 2.2980561555075593e-05,
      "loss": 0.0,
      "step": 87570
    },
    {
      "epoch": 27.022523912372723,
      "grad_norm": 7.2433876994182356e-06,
      "learning_rate": 2.2977476087627275e-05,
      "loss": 0.0,
      "step": 87580
    },
    {
      "epoch": 27.02560937982104,
      "grad_norm": 3.0469114790321328e-05,
      "learning_rate": 2.2974390620178958e-05,
      "loss": 0.0001,
      "step": 87590
    },
    {
      "epoch": 27.02869484726936,
      "grad_norm": 7.888898835517466e-05,
      "learning_rate": 2.297130515273064e-05,
      "loss": 0.0001,
      "step": 87600
    },
    {
      "epoch": 27.03178031471768,
      "grad_norm": 3.837407803075621e-06,
      "learning_rate": 2.2968219685282323e-05,
      "loss": 0.0,
      "step": 87610
    },
    {
      "epoch": 27.034865782165998,
      "grad_norm": 9.31853264773963e-06,
      "learning_rate": 2.2965134217834002e-05,
      "loss": 0.0,
      "step": 87620
    },
    {
      "epoch": 27.037951249614316,
      "grad_norm": 0.005754618439823389,
      "learning_rate": 2.2962048750385684e-05,
      "loss": 0.0,
      "step": 87630
    },
    {
      "epoch": 27.041036717062635,
      "grad_norm": 0.0008303043432533741,
      "learning_rate": 2.2958963282937367e-05,
      "loss": 0.0003,
      "step": 87640
    },
    {
      "epoch": 27.044122184510954,
      "grad_norm": 2.441266224195715e-05,
      "learning_rate": 2.2955877815489046e-05,
      "loss": 0.0,
      "step": 87650
    },
    {
      "epoch": 27.047207651959273,
      "grad_norm": 0.23030565679073334,
      "learning_rate": 2.2952792348040732e-05,
      "loss": 0.0003,
      "step": 87660
    },
    {
      "epoch": 27.05029311940759,
      "grad_norm": 5.6948170822579414e-05,
      "learning_rate": 2.294970688059241e-05,
      "loss": 0.0,
      "step": 87670
    },
    {
      "epoch": 27.05337858685591,
      "grad_norm": 0.00015702631208114326,
      "learning_rate": 2.2946621413144093e-05,
      "loss": 0.0,
      "step": 87680
    },
    {
      "epoch": 27.05646405430423,
      "grad_norm": 2.632684845593758e-05,
      "learning_rate": 2.2943535945695772e-05,
      "loss": 0.0,
      "step": 87690
    },
    {
      "epoch": 27.059549521752544,
      "grad_norm": 0.00024306995328515768,
      "learning_rate": 2.2940450478247455e-05,
      "loss": 0.0017,
      "step": 87700
    },
    {
      "epoch": 27.062634989200863,
      "grad_norm": 3.181576175848022e-05,
      "learning_rate": 2.2937365010799137e-05,
      "loss": 0.0,
      "step": 87710
    },
    {
      "epoch": 27.06572045664918,
      "grad_norm": 0.0008449285523965955,
      "learning_rate": 2.293427954335082e-05,
      "loss": 0.0,
      "step": 87720
    },
    {
      "epoch": 27.0688059240975,
      "grad_norm": 7.776339043630287e-05,
      "learning_rate": 2.2931194075902502e-05,
      "loss": 0.0001,
      "step": 87730
    },
    {
      "epoch": 27.07189139154582,
      "grad_norm": 3.3456325354563887e-07,
      "learning_rate": 2.292810860845418e-05,
      "loss": 0.0002,
      "step": 87740
    },
    {
      "epoch": 27.074976858994138,
      "grad_norm": 0.0007309019565582275,
      "learning_rate": 2.2925023141005864e-05,
      "loss": 0.0,
      "step": 87750
    },
    {
      "epoch": 27.078062326442456,
      "grad_norm": 0.007445801980793476,
      "learning_rate": 2.2921937673557546e-05,
      "loss": 0.0002,
      "step": 87760
    },
    {
      "epoch": 27.081147793890775,
      "grad_norm": 3.8716501876479015e-05,
      "learning_rate": 2.2918852206109225e-05,
      "loss": 0.0,
      "step": 87770
    },
    {
      "epoch": 27.084233261339094,
      "grad_norm": 6.69712244416587e-05,
      "learning_rate": 2.2915766738660908e-05,
      "loss": 0.0001,
      "step": 87780
    },
    {
      "epoch": 27.087318728787412,
      "grad_norm": 0.0037131309509277344,
      "learning_rate": 2.291268127121259e-05,
      "loss": 0.0,
      "step": 87790
    },
    {
      "epoch": 27.09040419623573,
      "grad_norm": 0.025028003379702568,
      "learning_rate": 2.2909595803764273e-05,
      "loss": 0.0002,
      "step": 87800
    },
    {
      "epoch": 27.09348966368405,
      "grad_norm": 0.037704773247241974,
      "learning_rate": 2.2906510336315952e-05,
      "loss": 0.0007,
      "step": 87810
    },
    {
      "epoch": 27.096575131132365,
      "grad_norm": 0.00368521292693913,
      "learning_rate": 2.2903424868867634e-05,
      "loss": 0.0,
      "step": 87820
    },
    {
      "epoch": 27.099660598580684,
      "grad_norm": 2.8058276176452637,
      "learning_rate": 2.2900339401419317e-05,
      "loss": 0.0041,
      "step": 87830
    },
    {
      "epoch": 27.102746066029002,
      "grad_norm": 0.0007336258422583342,
      "learning_rate": 2.2897253933970996e-05,
      "loss": 0.0004,
      "step": 87840
    },
    {
      "epoch": 27.10583153347732,
      "grad_norm": 0.00014009000733494759,
      "learning_rate": 2.289416846652268e-05,
      "loss": 0.0001,
      "step": 87850
    },
    {
      "epoch": 27.10891700092564,
      "grad_norm": 5.784644599771127e-05,
      "learning_rate": 2.289108299907436e-05,
      "loss": 0.0057,
      "step": 87860
    },
    {
      "epoch": 27.11200246837396,
      "grad_norm": 1.434944260836346e-05,
      "learning_rate": 2.2887997531626043e-05,
      "loss": 0.0,
      "step": 87870
    },
    {
      "epoch": 27.115087935822277,
      "grad_norm": 0.08930179476737976,
      "learning_rate": 2.2884912064177726e-05,
      "loss": 0.0,
      "step": 87880
    },
    {
      "epoch": 27.118173403270596,
      "grad_norm": 4.1799921746132895e-06,
      "learning_rate": 2.2881826596729405e-05,
      "loss": 0.0001,
      "step": 87890
    },
    {
      "epoch": 27.121258870718915,
      "grad_norm": 0.7655737996101379,
      "learning_rate": 2.2878741129281087e-05,
      "loss": 0.0003,
      "step": 87900
    },
    {
      "epoch": 27.124344338167234,
      "grad_norm": 0.0015541936736553907,
      "learning_rate": 2.2875655661832767e-05,
      "loss": 0.0,
      "step": 87910
    },
    {
      "epoch": 27.127429805615552,
      "grad_norm": 0.010085675865411758,
      "learning_rate": 2.2872570194384452e-05,
      "loss": 0.0001,
      "step": 87920
    },
    {
      "epoch": 27.130515273063867,
      "grad_norm": 0.00033464431180618703,
      "learning_rate": 2.286948472693613e-05,
      "loss": 0.0,
      "step": 87930
    },
    {
      "epoch": 27.133600740512186,
      "grad_norm": 7.99385361460736e-06,
      "learning_rate": 2.2866399259487814e-05,
      "loss": 0.0,
      "step": 87940
    },
    {
      "epoch": 27.136686207960505,
      "grad_norm": 0.02775709703564644,
      "learning_rate": 2.2863313792039496e-05,
      "loss": 0.0067,
      "step": 87950
    },
    {
      "epoch": 27.139771675408824,
      "grad_norm": 0.1243448406457901,
      "learning_rate": 2.2860228324591176e-05,
      "loss": 0.0001,
      "step": 87960
    },
    {
      "epoch": 27.142857142857142,
      "grad_norm": 0.5654648542404175,
      "learning_rate": 2.2857142857142858e-05,
      "loss": 0.0003,
      "step": 87970
    },
    {
      "epoch": 27.14594261030546,
      "grad_norm": 0.0012821154668927193,
      "learning_rate": 2.2854057389694537e-05,
      "loss": 0.0187,
      "step": 87980
    },
    {
      "epoch": 27.14902807775378,
      "grad_norm": 4.830563284485834e-06,
      "learning_rate": 2.2850971922246223e-05,
      "loss": 0.001,
      "step": 87990
    },
    {
      "epoch": 27.1521135452021,
      "grad_norm": 0.0009652168955653906,
      "learning_rate": 2.2847886454797905e-05,
      "loss": 0.0009,
      "step": 88000
    },
    {
      "epoch": 27.155199012650417,
      "grad_norm": 0.00028309912886470556,
      "learning_rate": 2.2844800987349585e-05,
      "loss": 0.0004,
      "step": 88010
    },
    {
      "epoch": 27.158284480098736,
      "grad_norm": 0.0023648282513022423,
      "learning_rate": 2.2841715519901267e-05,
      "loss": 0.0,
      "step": 88020
    },
    {
      "epoch": 27.161369947547055,
      "grad_norm": 0.00028870414826087654,
      "learning_rate": 2.2838630052452946e-05,
      "loss": 0.0,
      "step": 88030
    },
    {
      "epoch": 27.164455414995373,
      "grad_norm": 2.231126927654259e-06,
      "learning_rate": 2.283554458500463e-05,
      "loss": 0.0002,
      "step": 88040
    },
    {
      "epoch": 27.16754088244369,
      "grad_norm": 0.006644736044108868,
      "learning_rate": 2.283245911755631e-05,
      "loss": 0.0,
      "step": 88050
    },
    {
      "epoch": 27.170626349892007,
      "grad_norm": 0.00580272451043129,
      "learning_rate": 2.2829373650107994e-05,
      "loss": 0.0004,
      "step": 88060
    },
    {
      "epoch": 27.173711817340326,
      "grad_norm": 4.461193748284131e-05,
      "learning_rate": 2.2826288182659676e-05,
      "loss": 0.0001,
      "step": 88070
    },
    {
      "epoch": 27.176797284788645,
      "grad_norm": 0.005986281204968691,
      "learning_rate": 2.2823202715211355e-05,
      "loss": 0.0,
      "step": 88080
    },
    {
      "epoch": 27.179882752236963,
      "grad_norm": 1.86277484317543e-05,
      "learning_rate": 2.2820117247763038e-05,
      "loss": 0.0,
      "step": 88090
    },
    {
      "epoch": 27.182968219685282,
      "grad_norm": 4.098039596556191e-07,
      "learning_rate": 2.2817031780314717e-05,
      "loss": 0.0,
      "step": 88100
    },
    {
      "epoch": 27.1860536871336,
      "grad_norm": 0.0021261058282107115,
      "learning_rate": 2.28139463128664e-05,
      "loss": 0.0001,
      "step": 88110
    },
    {
      "epoch": 27.18913915458192,
      "grad_norm": 0.0052496506832540035,
      "learning_rate": 2.281086084541808e-05,
      "loss": 0.0001,
      "step": 88120
    },
    {
      "epoch": 27.19222462203024,
      "grad_norm": 2.379707439104095e-06,
      "learning_rate": 2.2807775377969764e-05,
      "loss": 0.0,
      "step": 88130
    },
    {
      "epoch": 27.195310089478557,
      "grad_norm": 2.121755869666231e-06,
      "learning_rate": 2.2804689910521447e-05,
      "loss": 0.0,
      "step": 88140
    },
    {
      "epoch": 27.198395556926876,
      "grad_norm": 2.48962314799428e-05,
      "learning_rate": 2.2801604443073126e-05,
      "loss": 0.0013,
      "step": 88150
    },
    {
      "epoch": 27.201481024375195,
      "grad_norm": 0.0003602264914661646,
      "learning_rate": 2.2798518975624808e-05,
      "loss": 0.0,
      "step": 88160
    },
    {
      "epoch": 27.20456649182351,
      "grad_norm": 0.04361342266201973,
      "learning_rate": 2.279543350817649e-05,
      "loss": 0.0001,
      "step": 88170
    },
    {
      "epoch": 27.20765195927183,
      "grad_norm": 0.008817320689558983,
      "learning_rate": 2.279234804072817e-05,
      "loss": 0.0,
      "step": 88180
    },
    {
      "epoch": 27.210737426720147,
      "grad_norm": 0.0014366963878273964,
      "learning_rate": 2.2789262573279856e-05,
      "loss": 0.005,
      "step": 88190
    },
    {
      "epoch": 27.213822894168466,
      "grad_norm": 0.00028306018793955445,
      "learning_rate": 2.2786177105831535e-05,
      "loss": 0.0,
      "step": 88200
    },
    {
      "epoch": 27.216908361616785,
      "grad_norm": 3.4888205846073106e-05,
      "learning_rate": 2.2783091638383217e-05,
      "loss": 0.0,
      "step": 88210
    },
    {
      "epoch": 27.219993829065103,
      "grad_norm": 4.413925125845708e-05,
      "learning_rate": 2.2780006170934896e-05,
      "loss": 0.0,
      "step": 88220
    },
    {
      "epoch": 27.223079296513422,
      "grad_norm": 1.1567520232347306e-05,
      "learning_rate": 2.277692070348658e-05,
      "loss": 0.0,
      "step": 88230
    },
    {
      "epoch": 27.22616476396174,
      "grad_norm": 0.0006033165846019983,
      "learning_rate": 2.277383523603826e-05,
      "loss": 0.0027,
      "step": 88240
    },
    {
      "epoch": 27.22925023141006,
      "grad_norm": 0.0026807570829987526,
      "learning_rate": 2.277074976858994e-05,
      "loss": 0.0,
      "step": 88250
    },
    {
      "epoch": 27.23233569885838,
      "grad_norm": 0.0033199801109731197,
      "learning_rate": 2.2767664301141626e-05,
      "loss": 0.0,
      "step": 88260
    },
    {
      "epoch": 27.235421166306697,
      "grad_norm": 0.0026802781503647566,
      "learning_rate": 2.2764578833693305e-05,
      "loss": 0.0002,
      "step": 88270
    },
    {
      "epoch": 27.238506633755012,
      "grad_norm": 0.004195283632725477,
      "learning_rate": 2.2761493366244988e-05,
      "loss": 0.0,
      "step": 88280
    },
    {
      "epoch": 27.24159210120333,
      "grad_norm": 5.233775937085738e-06,
      "learning_rate": 2.275840789879667e-05,
      "loss": 0.0,
      "step": 88290
    },
    {
      "epoch": 27.24467756865165,
      "grad_norm": 0.00038893966120667756,
      "learning_rate": 2.275532243134835e-05,
      "loss": 0.0002,
      "step": 88300
    },
    {
      "epoch": 27.24776303609997,
      "grad_norm": 3.3007424917741446e-06,
      "learning_rate": 2.2752236963900032e-05,
      "loss": 0.0,
      "step": 88310
    },
    {
      "epoch": 27.250848503548287,
      "grad_norm": 3.963090421166271e-06,
      "learning_rate": 2.274915149645171e-05,
      "loss": 0.0,
      "step": 88320
    },
    {
      "epoch": 27.253933970996606,
      "grad_norm": 0.0004379989695735276,
      "learning_rate": 2.2746066029003397e-05,
      "loss": 0.0,
      "step": 88330
    },
    {
      "epoch": 27.257019438444924,
      "grad_norm": 0.0006768074235878885,
      "learning_rate": 2.2742980561555076e-05,
      "loss": 0.0,
      "step": 88340
    },
    {
      "epoch": 27.260104905893243,
      "grad_norm": 4.6633602323709056e-05,
      "learning_rate": 2.2739895094106758e-05,
      "loss": 0.0012,
      "step": 88350
    },
    {
      "epoch": 27.263190373341562,
      "grad_norm": 1.334249373030616e-05,
      "learning_rate": 2.273680962665844e-05,
      "loss": 0.0,
      "step": 88360
    },
    {
      "epoch": 27.26627584078988,
      "grad_norm": 0.7728402614593506,
      "learning_rate": 2.273372415921012e-05,
      "loss": 0.0004,
      "step": 88370
    },
    {
      "epoch": 27.2693613082382,
      "grad_norm": 0.0423656702041626,
      "learning_rate": 2.2730638691761802e-05,
      "loss": 0.0002,
      "step": 88380
    },
    {
      "epoch": 27.272446775686518,
      "grad_norm": 0.0014104725560173392,
      "learning_rate": 2.2727553224313485e-05,
      "loss": 0.0022,
      "step": 88390
    },
    {
      "epoch": 27.275532243134833,
      "grad_norm": 0.0003185379900969565,
      "learning_rate": 2.2724467756865167e-05,
      "loss": 0.0,
      "step": 88400
    },
    {
      "epoch": 27.278617710583152,
      "grad_norm": 1.1088885912613478e-05,
      "learning_rate": 2.272138228941685e-05,
      "loss": 0.0001,
      "step": 88410
    },
    {
      "epoch": 27.28170317803147,
      "grad_norm": 6.524749187519774e-05,
      "learning_rate": 2.271829682196853e-05,
      "loss": 0.0,
      "step": 88420
    },
    {
      "epoch": 27.28478864547979,
      "grad_norm": 1.360487544843636e-06,
      "learning_rate": 2.271521135452021e-05,
      "loss": 0.0,
      "step": 88430
    },
    {
      "epoch": 27.287874112928108,
      "grad_norm": 0.0006802293355576694,
      "learning_rate": 2.271212588707189e-05,
      "loss": 0.0003,
      "step": 88440
    },
    {
      "epoch": 27.290959580376427,
      "grad_norm": 0.6340572237968445,
      "learning_rate": 2.2709040419623573e-05,
      "loss": 0.0003,
      "step": 88450
    },
    {
      "epoch": 27.294045047824746,
      "grad_norm": 0.11937057971954346,
      "learning_rate": 2.2705954952175255e-05,
      "loss": 0.0001,
      "step": 88460
    },
    {
      "epoch": 27.297130515273064,
      "grad_norm": 1.7868156646727584e-05,
      "learning_rate": 2.2702869484726938e-05,
      "loss": 0.0001,
      "step": 88470
    },
    {
      "epoch": 27.300215982721383,
      "grad_norm": 1.3183652072257246e-06,
      "learning_rate": 2.269978401727862e-05,
      "loss": 0.0,
      "step": 88480
    },
    {
      "epoch": 27.303301450169702,
      "grad_norm": 7.11293159838533e-06,
      "learning_rate": 2.26966985498303e-05,
      "loss": 0.0,
      "step": 88490
    },
    {
      "epoch": 27.30638691761802,
      "grad_norm": 0.18818745017051697,
      "learning_rate": 2.2693613082381982e-05,
      "loss": 0.0001,
      "step": 88500
    },
    {
      "epoch": 27.30947238506634,
      "grad_norm": 8.27347412268864e-06,
      "learning_rate": 2.269052761493366e-05,
      "loss": 0.0,
      "step": 88510
    },
    {
      "epoch": 27.312557852514654,
      "grad_norm": 8.823897951515391e-05,
      "learning_rate": 2.2687442147485343e-05,
      "loss": 0.0023,
      "step": 88520
    },
    {
      "epoch": 27.315643319962973,
      "grad_norm": 5.572143891185988e-06,
      "learning_rate": 2.268435668003703e-05,
      "loss": 0.0,
      "step": 88530
    },
    {
      "epoch": 27.318728787411292,
      "grad_norm": 1.785994572855998e-05,
      "learning_rate": 2.268127121258871e-05,
      "loss": 0.0001,
      "step": 88540
    },
    {
      "epoch": 27.32181425485961,
      "grad_norm": 0.0005237985169515014,
      "learning_rate": 2.267818574514039e-05,
      "loss": 0.0037,
      "step": 88550
    },
    {
      "epoch": 27.32489972230793,
      "grad_norm": 7.836792406124005e-07,
      "learning_rate": 2.267510027769207e-05,
      "loss": 0.0002,
      "step": 88560
    },
    {
      "epoch": 27.327985189756248,
      "grad_norm": 7.963530151755549e-06,
      "learning_rate": 2.2672014810243752e-05,
      "loss": 0.0,
      "step": 88570
    },
    {
      "epoch": 27.331070657204567,
      "grad_norm": 0.0001366663200315088,
      "learning_rate": 2.2668929342795435e-05,
      "loss": 0.0,
      "step": 88580
    },
    {
      "epoch": 27.334156124652885,
      "grad_norm": 3.695310115814209,
      "learning_rate": 2.2665843875347117e-05,
      "loss": 0.0025,
      "step": 88590
    },
    {
      "epoch": 27.337241592101204,
      "grad_norm": 0.00022386801720131189,
      "learning_rate": 2.26627584078988e-05,
      "loss": 0.0,
      "step": 88600
    },
    {
      "epoch": 27.340327059549523,
      "grad_norm": 0.0003409149940125644,
      "learning_rate": 2.265967294045048e-05,
      "loss": 0.0001,
      "step": 88610
    },
    {
      "epoch": 27.34341252699784,
      "grad_norm": 0.00045442930422723293,
      "learning_rate": 2.265658747300216e-05,
      "loss": 0.0065,
      "step": 88620
    },
    {
      "epoch": 27.34649799444616,
      "grad_norm": 0.008778264746069908,
      "learning_rate": 2.265350200555384e-05,
      "loss": 0.0,
      "step": 88630
    },
    {
      "epoch": 27.349583461894476,
      "grad_norm": 1.0282991524945828e-06,
      "learning_rate": 2.2650416538105523e-05,
      "loss": 0.0004,
      "step": 88640
    },
    {
      "epoch": 27.352668929342794,
      "grad_norm": 1.4232854482543189e-05,
      "learning_rate": 2.2647331070657205e-05,
      "loss": 0.0,
      "step": 88650
    },
    {
      "epoch": 27.355754396791113,
      "grad_norm": 0.10024624317884445,
      "learning_rate": 2.2644245603208888e-05,
      "loss": 0.0001,
      "step": 88660
    },
    {
      "epoch": 27.35883986423943,
      "grad_norm": 1.3266574144363403,
      "learning_rate": 2.264116013576057e-05,
      "loss": 0.0013,
      "step": 88670
    },
    {
      "epoch": 27.36192533168775,
      "grad_norm": 0.021588150411844254,
      "learning_rate": 2.263807466831225e-05,
      "loss": 0.0007,
      "step": 88680
    },
    {
      "epoch": 27.36501079913607,
      "grad_norm": 0.0009095360292121768,
      "learning_rate": 2.2634989200863932e-05,
      "loss": 0.0019,
      "step": 88690
    },
    {
      "epoch": 27.368096266584388,
      "grad_norm": 1.5817377629900875e-07,
      "learning_rate": 2.2631903733415614e-05,
      "loss": 0.0,
      "step": 88700
    },
    {
      "epoch": 27.371181734032707,
      "grad_norm": 1.2803102436009794e-06,
      "learning_rate": 2.2628818265967294e-05,
      "loss": 0.001,
      "step": 88710
    },
    {
      "epoch": 27.374267201481025,
      "grad_norm": 0.013634596019983292,
      "learning_rate": 2.2625732798518976e-05,
      "loss": 0.0,
      "step": 88720
    },
    {
      "epoch": 27.377352668929344,
      "grad_norm": 1.7561918866704218e-05,
      "learning_rate": 2.262264733107066e-05,
      "loss": 0.0004,
      "step": 88730
    },
    {
      "epoch": 27.380438136377663,
      "grad_norm": 0.0002361022779950872,
      "learning_rate": 2.261956186362234e-05,
      "loss": 0.0006,
      "step": 88740
    },
    {
      "epoch": 27.383523603825978,
      "grad_norm": 2.351337570871692e-05,
      "learning_rate": 2.261647639617402e-05,
      "loss": 0.0025,
      "step": 88750
    },
    {
      "epoch": 27.386609071274297,
      "grad_norm": 3.678705616039224e-05,
      "learning_rate": 2.2613390928725703e-05,
      "loss": 0.0004,
      "step": 88760
    },
    {
      "epoch": 27.389694538722615,
      "grad_norm": 2.1326219211914577e-05,
      "learning_rate": 2.2610305461277385e-05,
      "loss": 0.0,
      "step": 88770
    },
    {
      "epoch": 27.392780006170934,
      "grad_norm": 5.778073682449758e-05,
      "learning_rate": 2.2607219993829064e-05,
      "loss": 0.0001,
      "step": 88780
    },
    {
      "epoch": 27.395865473619253,
      "grad_norm": 1.4363077878952026,
      "learning_rate": 2.260413452638075e-05,
      "loss": 0.0007,
      "step": 88790
    },
    {
      "epoch": 27.39895094106757,
      "grad_norm": 0.012662744149565697,
      "learning_rate": 2.260104905893243e-05,
      "loss": 0.0,
      "step": 88800
    },
    {
      "epoch": 27.40203640851589,
      "grad_norm": 0.002110586501657963,
      "learning_rate": 2.259796359148411e-05,
      "loss": 0.0002,
      "step": 88810
    },
    {
      "epoch": 27.40512187596421,
      "grad_norm": 0.1270955204963684,
      "learning_rate": 2.2594878124035794e-05,
      "loss": 0.0077,
      "step": 88820
    },
    {
      "epoch": 27.408207343412528,
      "grad_norm": 0.005468879360705614,
      "learning_rate": 2.2591792656587473e-05,
      "loss": 0.0001,
      "step": 88830
    },
    {
      "epoch": 27.411292810860846,
      "grad_norm": 1.318510840064846e-05,
      "learning_rate": 2.2588707189139156e-05,
      "loss": 0.0004,
      "step": 88840
    },
    {
      "epoch": 27.414378278309165,
      "grad_norm": 4.432029163581319e-05,
      "learning_rate": 2.2585621721690835e-05,
      "loss": 0.0113,
      "step": 88850
    },
    {
      "epoch": 27.417463745757484,
      "grad_norm": 0.09710467606782913,
      "learning_rate": 2.258253625424252e-05,
      "loss": 0.0,
      "step": 88860
    },
    {
      "epoch": 27.4205492132058,
      "grad_norm": 0.0025490077678114176,
      "learning_rate": 2.25794507867942e-05,
      "loss": 0.0002,
      "step": 88870
    },
    {
      "epoch": 27.423634680654118,
      "grad_norm": 0.04032617062330246,
      "learning_rate": 2.2576365319345882e-05,
      "loss": 0.0,
      "step": 88880
    },
    {
      "epoch": 27.426720148102437,
      "grad_norm": 0.0013325402978807688,
      "learning_rate": 2.2573279851897565e-05,
      "loss": 0.0111,
      "step": 88890
    },
    {
      "epoch": 27.429805615550755,
      "grad_norm": 0.02451617643237114,
      "learning_rate": 2.2570194384449244e-05,
      "loss": 0.0001,
      "step": 88900
    },
    {
      "epoch": 27.432891082999074,
      "grad_norm": 0.00035943652619607747,
      "learning_rate": 2.2567108917000926e-05,
      "loss": 0.0001,
      "step": 88910
    },
    {
      "epoch": 27.435976550447393,
      "grad_norm": 1.4275232160798623e-06,
      "learning_rate": 2.256402344955261e-05,
      "loss": 0.0,
      "step": 88920
    },
    {
      "epoch": 27.43906201789571,
      "grad_norm": 0.04004446044564247,
      "learning_rate": 2.256093798210429e-05,
      "loss": 0.0067,
      "step": 88930
    },
    {
      "epoch": 27.44214748534403,
      "grad_norm": 4.231349885230884e-05,
      "learning_rate": 2.2557852514655974e-05,
      "loss": 0.0,
      "step": 88940
    },
    {
      "epoch": 27.44523295279235,
      "grad_norm": 2.6932390028377995e-05,
      "learning_rate": 2.2554767047207653e-05,
      "loss": 0.0,
      "step": 88950
    },
    {
      "epoch": 27.448318420240668,
      "grad_norm": 2.4034217858570628e-05,
      "learning_rate": 2.2551681579759335e-05,
      "loss": 0.0005,
      "step": 88960
    },
    {
      "epoch": 27.451403887688986,
      "grad_norm": 0.0009302817634306848,
      "learning_rate": 2.2548596112311014e-05,
      "loss": 0.0001,
      "step": 88970
    },
    {
      "epoch": 27.454489355137305,
      "grad_norm": 0.0001033089793054387,
      "learning_rate": 2.2545510644862697e-05,
      "loss": 0.0001,
      "step": 88980
    },
    {
      "epoch": 27.45757482258562,
      "grad_norm": 5.146674766365322e-07,
      "learning_rate": 2.254242517741438e-05,
      "loss": 0.0052,
      "step": 88990
    },
    {
      "epoch": 27.46066029003394,
      "grad_norm": 1.4041941165924072,
      "learning_rate": 2.253933970996606e-05,
      "loss": 0.0007,
      "step": 89000
    },
    {
      "epoch": 27.463745757482258,
      "grad_norm": 0.0020442029926925898,
      "learning_rate": 2.2536254242517744e-05,
      "loss": 0.0002,
      "step": 89010
    },
    {
      "epoch": 27.466831224930576,
      "grad_norm": 4.575357888825238e-05,
      "learning_rate": 2.2533168775069423e-05,
      "loss": 0.0,
      "step": 89020
    },
    {
      "epoch": 27.469916692378895,
      "grad_norm": 5.765743480878882e-05,
      "learning_rate": 2.2530083307621106e-05,
      "loss": 0.0004,
      "step": 89030
    },
    {
      "epoch": 27.473002159827214,
      "grad_norm": 0.04482852667570114,
      "learning_rate": 2.2526997840172788e-05,
      "loss": 0.0058,
      "step": 89040
    },
    {
      "epoch": 27.476087627275533,
      "grad_norm": 5.1260536565678194e-05,
      "learning_rate": 2.2523912372724467e-05,
      "loss": 0.0,
      "step": 89050
    },
    {
      "epoch": 27.47917309472385,
      "grad_norm": 0.0012223704252392054,
      "learning_rate": 2.2520826905276153e-05,
      "loss": 0.0,
      "step": 89060
    },
    {
      "epoch": 27.48225856217217,
      "grad_norm": 1.866947059170343e-05,
      "learning_rate": 2.2517741437827832e-05,
      "loss": 0.0,
      "step": 89070
    },
    {
      "epoch": 27.48534402962049,
      "grad_norm": 0.0013687233440577984,
      "learning_rate": 2.2514655970379515e-05,
      "loss": 0.0,
      "step": 89080
    },
    {
      "epoch": 27.488429497068807,
      "grad_norm": 0.0003299481177236885,
      "learning_rate": 2.2511570502931194e-05,
      "loss": 0.0013,
      "step": 89090
    },
    {
      "epoch": 27.491514964517123,
      "grad_norm": 1.3555647910834523e-06,
      "learning_rate": 2.2508485035482876e-05,
      "loss": 0.0,
      "step": 89100
    },
    {
      "epoch": 27.49460043196544,
      "grad_norm": 6.42652012174949e-05,
      "learning_rate": 2.250539956803456e-05,
      "loss": 0.0,
      "step": 89110
    },
    {
      "epoch": 27.49768589941376,
      "grad_norm": 0.012056252919137478,
      "learning_rate": 2.2502314100586238e-05,
      "loss": 0.0,
      "step": 89120
    },
    {
      "epoch": 27.50077136686208,
      "grad_norm": 4.27996383223217e-06,
      "learning_rate": 2.2499228633137924e-05,
      "loss": 0.0,
      "step": 89130
    },
    {
      "epoch": 27.503856834310398,
      "grad_norm": 0.00020571475033648312,
      "learning_rate": 2.2496143165689603e-05,
      "loss": 0.0016,
      "step": 89140
    },
    {
      "epoch": 27.506942301758716,
      "grad_norm": 0.00010462892532814294,
      "learning_rate": 2.2493057698241285e-05,
      "loss": 0.0001,
      "step": 89150
    },
    {
      "epoch": 27.510027769207035,
      "grad_norm": 0.0006026915507391095,
      "learning_rate": 2.2489972230792968e-05,
      "loss": 0.0,
      "step": 89160
    },
    {
      "epoch": 27.513113236655354,
      "grad_norm": 1.843418002128601,
      "learning_rate": 2.2486886763344647e-05,
      "loss": 0.0021,
      "step": 89170
    },
    {
      "epoch": 27.516198704103672,
      "grad_norm": 3.552786438376643e-05,
      "learning_rate": 2.248380129589633e-05,
      "loss": 0.0,
      "step": 89180
    },
    {
      "epoch": 27.51928417155199,
      "grad_norm": 0.002612276002764702,
      "learning_rate": 2.248071582844801e-05,
      "loss": 0.0005,
      "step": 89190
    },
    {
      "epoch": 27.52236963900031,
      "grad_norm": 0.010080316103994846,
      "learning_rate": 2.2477630360999694e-05,
      "loss": 0.0004,
      "step": 89200
    },
    {
      "epoch": 27.52545510644863,
      "grad_norm": 3.488296351861209e-05,
      "learning_rate": 2.2474544893551373e-05,
      "loss": 0.0002,
      "step": 89210
    },
    {
      "epoch": 27.528540573896944,
      "grad_norm": 1.1370916581654456e-05,
      "learning_rate": 2.2471459426103056e-05,
      "loss": 0.0,
      "step": 89220
    },
    {
      "epoch": 27.531626041345262,
      "grad_norm": 1.5042750419524964e-05,
      "learning_rate": 2.246837395865474e-05,
      "loss": 0.0,
      "step": 89230
    },
    {
      "epoch": 27.53471150879358,
      "grad_norm": 0.008104401640594006,
      "learning_rate": 2.2465288491206417e-05,
      "loss": 0.0,
      "step": 89240
    },
    {
      "epoch": 27.5377969762419,
      "grad_norm": 2.1605832444038242e-05,
      "learning_rate": 2.24622030237581e-05,
      "loss": 0.0,
      "step": 89250
    },
    {
      "epoch": 27.54088244369022,
      "grad_norm": 0.007778157014399767,
      "learning_rate": 2.2459117556309782e-05,
      "loss": 0.0045,
      "step": 89260
    },
    {
      "epoch": 27.543967911138537,
      "grad_norm": 0.0001785396452760324,
      "learning_rate": 2.2456032088861465e-05,
      "loss": 0.0001,
      "step": 89270
    },
    {
      "epoch": 27.547053378586856,
      "grad_norm": 0.0006393344374373555,
      "learning_rate": 2.2452946621413147e-05,
      "loss": 0.0001,
      "step": 89280
    },
    {
      "epoch": 27.550138846035175,
      "grad_norm": 0.024419071152806282,
      "learning_rate": 2.2449861153964826e-05,
      "loss": 0.0001,
      "step": 89290
    },
    {
      "epoch": 27.553224313483494,
      "grad_norm": 7.109887519618496e-06,
      "learning_rate": 2.244677568651651e-05,
      "loss": 0.0,
      "step": 89300
    },
    {
      "epoch": 27.556309780931812,
      "grad_norm": 2.6626673843566095e-06,
      "learning_rate": 2.2443690219068188e-05,
      "loss": 0.0,
      "step": 89310
    },
    {
      "epoch": 27.55939524838013,
      "grad_norm": 2.5986892069340684e-05,
      "learning_rate": 2.244060475161987e-05,
      "loss": 0.0,
      "step": 89320
    },
    {
      "epoch": 27.56248071582845,
      "grad_norm": 5.979913112241775e-05,
      "learning_rate": 2.2437519284171553e-05,
      "loss": 0.0,
      "step": 89330
    },
    {
      "epoch": 27.565566183276765,
      "grad_norm": 4.294874452170916e-05,
      "learning_rate": 2.2434433816723235e-05,
      "loss": 0.0,
      "step": 89340
    },
    {
      "epoch": 27.568651650725084,
      "grad_norm": 3.071587562561035,
      "learning_rate": 2.2431348349274918e-05,
      "loss": 0.001,
      "step": 89350
    },
    {
      "epoch": 27.571737118173402,
      "grad_norm": 0.0009103844640776515,
      "learning_rate": 2.2428262881826597e-05,
      "loss": 0.0,
      "step": 89360
    },
    {
      "epoch": 27.57482258562172,
      "grad_norm": 1.3525408576242626e-05,
      "learning_rate": 2.242517741437828e-05,
      "loss": 0.002,
      "step": 89370
    },
    {
      "epoch": 27.57790805307004,
      "grad_norm": 0.024100612848997116,
      "learning_rate": 2.242209194692996e-05,
      "loss": 0.0,
      "step": 89380
    },
    {
      "epoch": 27.58099352051836,
      "grad_norm": 0.007307650055736303,
      "learning_rate": 2.241900647948164e-05,
      "loss": 0.0063,
      "step": 89390
    },
    {
      "epoch": 27.584078987966677,
      "grad_norm": 9.522410095996747e-07,
      "learning_rate": 2.2415921012033324e-05,
      "loss": 0.0,
      "step": 89400
    },
    {
      "epoch": 27.587164455414996,
      "grad_norm": 4.8317415348719805e-05,
      "learning_rate": 2.2412835544585006e-05,
      "loss": 0.0022,
      "step": 89410
    },
    {
      "epoch": 27.590249922863315,
      "grad_norm": 0.007444951683282852,
      "learning_rate": 2.240975007713669e-05,
      "loss": 0.0,
      "step": 89420
    },
    {
      "epoch": 27.593335390311633,
      "grad_norm": 0.0013021023478358984,
      "learning_rate": 2.2406664609688368e-05,
      "loss": 0.0,
      "step": 89430
    },
    {
      "epoch": 27.596420857759952,
      "grad_norm": 1.2363825590000488e-05,
      "learning_rate": 2.240357914224005e-05,
      "loss": 0.0001,
      "step": 89440
    },
    {
      "epoch": 27.599506325208267,
      "grad_norm": 0.0006549609825015068,
      "learning_rate": 2.2400493674791733e-05,
      "loss": 0.0,
      "step": 89450
    },
    {
      "epoch": 27.602591792656586,
      "grad_norm": 7.585915113850206e-07,
      "learning_rate": 2.2397408207343415e-05,
      "loss": 0.0,
      "step": 89460
    },
    {
      "epoch": 27.605677260104905,
      "grad_norm": 1.8807415926858084e-06,
      "learning_rate": 2.2394322739895097e-05,
      "loss": 0.0001,
      "step": 89470
    },
    {
      "epoch": 27.608762727553223,
      "grad_norm": 0.00011362443910911679,
      "learning_rate": 2.2391237272446777e-05,
      "loss": 0.0001,
      "step": 89480
    },
    {
      "epoch": 27.611848195001542,
      "grad_norm": 6.396938988473266e-05,
      "learning_rate": 2.238815180499846e-05,
      "loss": 0.0001,
      "step": 89490
    },
    {
      "epoch": 27.61493366244986,
      "grad_norm": 0.0015946730272844434,
      "learning_rate": 2.2385066337550138e-05,
      "loss": 0.0008,
      "step": 89500
    },
    {
      "epoch": 27.61801912989818,
      "grad_norm": 4.6570498852815945e-06,
      "learning_rate": 2.238198087010182e-05,
      "loss": 0.0001,
      "step": 89510
    },
    {
      "epoch": 27.6211045973465,
      "grad_norm": 0.0014051753096282482,
      "learning_rate": 2.2378895402653503e-05,
      "loss": 0.0,
      "step": 89520
    },
    {
      "epoch": 27.624190064794817,
      "grad_norm": 0.00010917626059381291,
      "learning_rate": 2.2375809935205186e-05,
      "loss": 0.0062,
      "step": 89530
    },
    {
      "epoch": 27.627275532243136,
      "grad_norm": 1.7224558177986182e-05,
      "learning_rate": 2.2372724467756868e-05,
      "loss": 0.0,
      "step": 89540
    },
    {
      "epoch": 27.630360999691455,
      "grad_norm": 6.191826855683757e-07,
      "learning_rate": 2.2369639000308547e-05,
      "loss": 0.0023,
      "step": 89550
    },
    {
      "epoch": 27.633446467139773,
      "grad_norm": 0.0006039980798959732,
      "learning_rate": 2.236655353286023e-05,
      "loss": 0.0002,
      "step": 89560
    },
    {
      "epoch": 27.63653193458809,
      "grad_norm": 5.275444345897995e-05,
      "learning_rate": 2.2363468065411912e-05,
      "loss": 0.0,
      "step": 89570
    },
    {
      "epoch": 27.639617402036407,
      "grad_norm": 0.0004545242991298437,
      "learning_rate": 2.236038259796359e-05,
      "loss": 0.0022,
      "step": 89580
    },
    {
      "epoch": 27.642702869484726,
      "grad_norm": 5.1359955250518396e-05,
      "learning_rate": 2.2357297130515274e-05,
      "loss": 0.0001,
      "step": 89590
    },
    {
      "epoch": 27.645788336933045,
      "grad_norm": 3.760681011044653e-06,
      "learning_rate": 2.2354211663066956e-05,
      "loss": 0.0,
      "step": 89600
    },
    {
      "epoch": 27.648873804381363,
      "grad_norm": 0.00015966102364473045,
      "learning_rate": 2.235112619561864e-05,
      "loss": 0.0002,
      "step": 89610
    },
    {
      "epoch": 27.651959271829682,
      "grad_norm": 0.0002797572815325111,
      "learning_rate": 2.2348040728170318e-05,
      "loss": 0.0035,
      "step": 89620
    },
    {
      "epoch": 27.655044739278,
      "grad_norm": 3.0064113616390387e-06,
      "learning_rate": 2.2344955260722e-05,
      "loss": 0.0049,
      "step": 89630
    },
    {
      "epoch": 27.65813020672632,
      "grad_norm": 4.167103907093406e-05,
      "learning_rate": 2.2341869793273683e-05,
      "loss": 0.0002,
      "step": 89640
    },
    {
      "epoch": 27.66121567417464,
      "grad_norm": 0.11833012849092484,
      "learning_rate": 2.2338784325825362e-05,
      "loss": 0.0003,
      "step": 89650
    },
    {
      "epoch": 27.664301141622957,
      "grad_norm": 1.4577583074569702,
      "learning_rate": 2.2335698858377048e-05,
      "loss": 0.0007,
      "step": 89660
    },
    {
      "epoch": 27.667386609071276,
      "grad_norm": 0.0002970215864479542,
      "learning_rate": 2.2332613390928727e-05,
      "loss": 0.0001,
      "step": 89670
    },
    {
      "epoch": 27.670472076519594,
      "grad_norm": 2.459993993397802e-06,
      "learning_rate": 2.232952792348041e-05,
      "loss": 0.0,
      "step": 89680
    },
    {
      "epoch": 27.67355754396791,
      "grad_norm": 5.2265109843574464e-05,
      "learning_rate": 2.232644245603209e-05,
      "loss": 0.0,
      "step": 89690
    },
    {
      "epoch": 27.67664301141623,
      "grad_norm": 1.2962704204255715e-05,
      "learning_rate": 2.232335698858377e-05,
      "loss": 0.0017,
      "step": 89700
    },
    {
      "epoch": 27.679728478864547,
      "grad_norm": 8.579986752010882e-05,
      "learning_rate": 2.2320271521135453e-05,
      "loss": 0.0,
      "step": 89710
    },
    {
      "epoch": 27.682813946312866,
      "grad_norm": 0.001801560283638537,
      "learning_rate": 2.2317186053687132e-05,
      "loss": 0.0,
      "step": 89720
    },
    {
      "epoch": 27.685899413761184,
      "grad_norm": 0.0010080195497721434,
      "learning_rate": 2.2314100586238818e-05,
      "loss": 0.0001,
      "step": 89730
    },
    {
      "epoch": 27.688984881209503,
      "grad_norm": 0.016749262809753418,
      "learning_rate": 2.2311015118790497e-05,
      "loss": 0.0,
      "step": 89740
    },
    {
      "epoch": 27.692070348657822,
      "grad_norm": 3.3551116302987793e-06,
      "learning_rate": 2.230792965134218e-05,
      "loss": 0.0009,
      "step": 89750
    },
    {
      "epoch": 27.69515581610614,
      "grad_norm": 8.686364162713289e-05,
      "learning_rate": 2.2304844183893862e-05,
      "loss": 0.0,
      "step": 89760
    },
    {
      "epoch": 27.69824128355446,
      "grad_norm": 0.000748933176510036,
      "learning_rate": 2.230175871644554e-05,
      "loss": 0.0,
      "step": 89770
    },
    {
      "epoch": 27.701326751002778,
      "grad_norm": 0.00039673465653322637,
      "learning_rate": 2.2298673248997224e-05,
      "loss": 0.0023,
      "step": 89780
    },
    {
      "epoch": 27.704412218451097,
      "grad_norm": 1.0499493328097742e-06,
      "learning_rate": 2.2295587781548903e-05,
      "loss": 0.0,
      "step": 89790
    },
    {
      "epoch": 27.707497685899412,
      "grad_norm": 7.112535968190059e-05,
      "learning_rate": 2.229250231410059e-05,
      "loss": 0.0,
      "step": 89800
    },
    {
      "epoch": 27.71058315334773,
      "grad_norm": 6.0894984926562756e-05,
      "learning_rate": 2.228941684665227e-05,
      "loss": 0.0014,
      "step": 89810
    },
    {
      "epoch": 27.71366862079605,
      "grad_norm": 0.0007261340506374836,
      "learning_rate": 2.228633137920395e-05,
      "loss": 0.0003,
      "step": 89820
    },
    {
      "epoch": 27.716754088244368,
      "grad_norm": 0.0009461430017836392,
      "learning_rate": 2.2283245911755633e-05,
      "loss": 0.0,
      "step": 89830
    },
    {
      "epoch": 27.719839555692687,
      "grad_norm": 4.0836301195668057e-05,
      "learning_rate": 2.2280160444307312e-05,
      "loss": 0.0001,
      "step": 89840
    },
    {
      "epoch": 27.722925023141006,
      "grad_norm": 1.7322390704066493e-05,
      "learning_rate": 2.2277074976858994e-05,
      "loss": 0.0,
      "step": 89850
    },
    {
      "epoch": 27.726010490589324,
      "grad_norm": 0.0004152929177507758,
      "learning_rate": 2.2273989509410677e-05,
      "loss": 0.0,
      "step": 89860
    },
    {
      "epoch": 27.729095958037643,
      "grad_norm": 0.0005775277386419475,
      "learning_rate": 2.227090404196236e-05,
      "loss": 0.0001,
      "step": 89870
    },
    {
      "epoch": 27.73218142548596,
      "grad_norm": 0.00025692061171866953,
      "learning_rate": 2.2267818574514042e-05,
      "loss": 0.0001,
      "step": 89880
    },
    {
      "epoch": 27.73526689293428,
      "grad_norm": 0.018774064257740974,
      "learning_rate": 2.226473310706572e-05,
      "loss": 0.0,
      "step": 89890
    },
    {
      "epoch": 27.7383523603826,
      "grad_norm": 0.00030412373598665,
      "learning_rate": 2.2261647639617403e-05,
      "loss": 0.0,
      "step": 89900
    },
    {
      "epoch": 27.741437827830918,
      "grad_norm": 1.1775285005569458,
      "learning_rate": 2.2258562172169082e-05,
      "loss": 0.0013,
      "step": 89910
    },
    {
      "epoch": 27.744523295279233,
      "grad_norm": 0.00011768218973884359,
      "learning_rate": 2.2255476704720765e-05,
      "loss": 0.0,
      "step": 89920
    },
    {
      "epoch": 27.747608762727552,
      "grad_norm": 8.119085396174341e-05,
      "learning_rate": 2.225239123727245e-05,
      "loss": 0.0,
      "step": 89930
    },
    {
      "epoch": 27.75069423017587,
      "grad_norm": 0.0002964790619444102,
      "learning_rate": 2.224930576982413e-05,
      "loss": 0.0,
      "step": 89940
    },
    {
      "epoch": 27.75377969762419,
      "grad_norm": 3.734920024871826,
      "learning_rate": 2.2246220302375812e-05,
      "loss": 0.0055,
      "step": 89950
    },
    {
      "epoch": 27.756865165072508,
      "grad_norm": 0.0002368145069340244,
      "learning_rate": 2.224313483492749e-05,
      "loss": 0.0,
      "step": 89960
    },
    {
      "epoch": 27.759950632520827,
      "grad_norm": 1.85373610293027e-05,
      "learning_rate": 2.2240049367479174e-05,
      "loss": 0.0039,
      "step": 89970
    },
    {
      "epoch": 27.763036099969145,
      "grad_norm": 0.005807000212371349,
      "learning_rate": 2.2236963900030856e-05,
      "loss": 0.0,
      "step": 89980
    },
    {
      "epoch": 27.766121567417464,
      "grad_norm": 1.170098221336957e-05,
      "learning_rate": 2.2233878432582535e-05,
      "loss": 0.0,
      "step": 89990
    },
    {
      "epoch": 27.769207034865783,
      "grad_norm": 0.0006823304574936628,
      "learning_rate": 2.223079296513422e-05,
      "loss": 0.0,
      "step": 90000
    },
    {
      "epoch": 27.7722925023141,
      "grad_norm": 0.0001898779592011124,
      "learning_rate": 2.22277074976859e-05,
      "loss": 0.0017,
      "step": 90010
    },
    {
      "epoch": 27.77537796976242,
      "grad_norm": 5.4998516134219244e-05,
      "learning_rate": 2.2224622030237583e-05,
      "loss": 0.0,
      "step": 90020
    },
    {
      "epoch": 27.77846343721074,
      "grad_norm": 6.505850615212694e-05,
      "learning_rate": 2.2221536562789262e-05,
      "loss": 0.0031,
      "step": 90030
    },
    {
      "epoch": 27.781548904659054,
      "grad_norm": 2.059439339063829e-06,
      "learning_rate": 2.2218451095340944e-05,
      "loss": 0.0003,
      "step": 90040
    },
    {
      "epoch": 27.784634372107373,
      "grad_norm": 0.0003893609391525388,
      "learning_rate": 2.2215365627892627e-05,
      "loss": 0.0001,
      "step": 90050
    },
    {
      "epoch": 27.78771983955569,
      "grad_norm": 0.0933409184217453,
      "learning_rate": 2.2212280160444306e-05,
      "loss": 0.0038,
      "step": 90060
    },
    {
      "epoch": 27.79080530700401,
      "grad_norm": 4.329806688474491e-05,
      "learning_rate": 2.2209194692995992e-05,
      "loss": 0.004,
      "step": 90070
    },
    {
      "epoch": 27.79389077445233,
      "grad_norm": 0.007034376263618469,
      "learning_rate": 2.220610922554767e-05,
      "loss": 0.0024,
      "step": 90080
    },
    {
      "epoch": 27.796976241900648,
      "grad_norm": 0.0001996414503082633,
      "learning_rate": 2.2203023758099353e-05,
      "loss": 0.0029,
      "step": 90090
    },
    {
      "epoch": 27.800061709348967,
      "grad_norm": 0.000977526418864727,
      "learning_rate": 2.2199938290651036e-05,
      "loss": 0.0013,
      "step": 90100
    },
    {
      "epoch": 27.803147176797285,
      "grad_norm": 1.9408260413911194e-05,
      "learning_rate": 2.2196852823202715e-05,
      "loss": 0.0002,
      "step": 90110
    },
    {
      "epoch": 27.806232644245604,
      "grad_norm": 0.00024372030748054385,
      "learning_rate": 2.2193767355754397e-05,
      "loss": 0.0,
      "step": 90120
    },
    {
      "epoch": 27.809318111693923,
      "grad_norm": 0.6035043001174927,
      "learning_rate": 2.219068188830608e-05,
      "loss": 0.0021,
      "step": 90130
    },
    {
      "epoch": 27.81240357914224,
      "grad_norm": 0.09084995836019516,
      "learning_rate": 2.2187596420857762e-05,
      "loss": 0.0013,
      "step": 90140
    },
    {
      "epoch": 27.815489046590557,
      "grad_norm": 8.96454366738908e-05,
      "learning_rate": 2.218451095340944e-05,
      "loss": 0.0,
      "step": 90150
    },
    {
      "epoch": 27.818574514038875,
      "grad_norm": 0.0003695409104693681,
      "learning_rate": 2.2181425485961124e-05,
      "loss": 0.0,
      "step": 90160
    },
    {
      "epoch": 27.821659981487194,
      "grad_norm": 0.0025828792713582516,
      "learning_rate": 2.2178340018512806e-05,
      "loss": 0.001,
      "step": 90170
    },
    {
      "epoch": 27.824745448935513,
      "grad_norm": 0.02146243117749691,
      "learning_rate": 2.2175254551064486e-05,
      "loss": 0.0001,
      "step": 90180
    },
    {
      "epoch": 27.82783091638383,
      "grad_norm": 0.0002511543279979378,
      "learning_rate": 2.2172169083616168e-05,
      "loss": 0.0006,
      "step": 90190
    },
    {
      "epoch": 27.83091638383215,
      "grad_norm": 1.2618543223652523e-05,
      "learning_rate": 2.216908361616785e-05,
      "loss": 0.0,
      "step": 90200
    },
    {
      "epoch": 27.83400185128047,
      "grad_norm": 4.886621354671661e-06,
      "learning_rate": 2.2165998148719533e-05,
      "loss": 0.0,
      "step": 90210
    },
    {
      "epoch": 27.837087318728788,
      "grad_norm": 0.00023533574130851775,
      "learning_rate": 2.2162912681271215e-05,
      "loss": 0.0001,
      "step": 90220
    },
    {
      "epoch": 27.840172786177106,
      "grad_norm": 0.01573157124221325,
      "learning_rate": 2.2159827213822895e-05,
      "loss": 0.0,
      "step": 90230
    },
    {
      "epoch": 27.843258253625425,
      "grad_norm": 0.12793470919132233,
      "learning_rate": 2.2156741746374577e-05,
      "loss": 0.0015,
      "step": 90240
    },
    {
      "epoch": 27.846343721073744,
      "grad_norm": 3.9156529965111986e-05,
      "learning_rate": 2.2153656278926256e-05,
      "loss": 0.0003,
      "step": 90250
    },
    {
      "epoch": 27.849429188522063,
      "grad_norm": 2.6452247766428627e-05,
      "learning_rate": 2.215057081147794e-05,
      "loss": 0.0001,
      "step": 90260
    },
    {
      "epoch": 27.85251465597038,
      "grad_norm": 2.795333102767472e-06,
      "learning_rate": 2.214748534402962e-05,
      "loss": 0.0,
      "step": 90270
    },
    {
      "epoch": 27.855600123418697,
      "grad_norm": 0.00016980170039460063,
      "learning_rate": 2.2144399876581304e-05,
      "loss": 0.0003,
      "step": 90280
    },
    {
      "epoch": 27.858685590867015,
      "grad_norm": 0.0017377182375639677,
      "learning_rate": 2.2141314409132986e-05,
      "loss": 0.0001,
      "step": 90290
    },
    {
      "epoch": 27.861771058315334,
      "grad_norm": 7.190476026153192e-05,
      "learning_rate": 2.2138228941684665e-05,
      "loss": 0.0,
      "step": 90300
    },
    {
      "epoch": 27.864856525763653,
      "grad_norm": 8.90328738023527e-05,
      "learning_rate": 2.2135143474236348e-05,
      "loss": 0.0,
      "step": 90310
    },
    {
      "epoch": 27.86794199321197,
      "grad_norm": 5.246654836810194e-06,
      "learning_rate": 2.213205800678803e-05,
      "loss": 0.0008,
      "step": 90320
    },
    {
      "epoch": 27.87102746066029,
      "grad_norm": 0.0043852985836565495,
      "learning_rate": 2.2128972539339713e-05,
      "loss": 0.0,
      "step": 90330
    },
    {
      "epoch": 27.87411292810861,
      "grad_norm": 6.201110863912618e-06,
      "learning_rate": 2.2125887071891395e-05,
      "loss": 0.0034,
      "step": 90340
    },
    {
      "epoch": 27.877198395556928,
      "grad_norm": 9.134331776294857e-06,
      "learning_rate": 2.2122801604443074e-05,
      "loss": 0.0002,
      "step": 90350
    },
    {
      "epoch": 27.880283863005246,
      "grad_norm": 5.185040663491236e-06,
      "learning_rate": 2.2119716136994757e-05,
      "loss": 0.0,
      "step": 90360
    },
    {
      "epoch": 27.883369330453565,
      "grad_norm": 7.124374678824097e-05,
      "learning_rate": 2.2116630669546436e-05,
      "loss": 0.0001,
      "step": 90370
    },
    {
      "epoch": 27.886454797901884,
      "grad_norm": 1.2543913499030168e-06,
      "learning_rate": 2.2113545202098118e-05,
      "loss": 0.0,
      "step": 90380
    },
    {
      "epoch": 27.8895402653502,
      "grad_norm": 0.0023399272467941046,
      "learning_rate": 2.21104597346498e-05,
      "loss": 0.0,
      "step": 90390
    },
    {
      "epoch": 27.892625732798518,
      "grad_norm": 0.000532511796336621,
      "learning_rate": 2.2107374267201483e-05,
      "loss": 0.0001,
      "step": 90400
    },
    {
      "epoch": 27.895711200246836,
      "grad_norm": 0.006830998230725527,
      "learning_rate": 2.2104288799753166e-05,
      "loss": 0.0021,
      "step": 90410
    },
    {
      "epoch": 27.898796667695155,
      "grad_norm": 0.00017400238721165806,
      "learning_rate": 2.2101203332304845e-05,
      "loss": 0.0,
      "step": 90420
    },
    {
      "epoch": 27.901882135143474,
      "grad_norm": 0.027782881632447243,
      "learning_rate": 2.2098117864856527e-05,
      "loss": 0.0015,
      "step": 90430
    },
    {
      "epoch": 27.904967602591793,
      "grad_norm": 0.00046701726387254894,
      "learning_rate": 2.209503239740821e-05,
      "loss": 0.0002,
      "step": 90440
    },
    {
      "epoch": 27.90805307004011,
      "grad_norm": 0.026601480320096016,
      "learning_rate": 2.209194692995989e-05,
      "loss": 0.0004,
      "step": 90450
    },
    {
      "epoch": 27.91113853748843,
      "grad_norm": 0.002687826519832015,
      "learning_rate": 2.208886146251157e-05,
      "loss": 0.0,
      "step": 90460
    },
    {
      "epoch": 27.91422400493675,
      "grad_norm": 0.002917667618021369,
      "learning_rate": 2.2085775995063254e-05,
      "loss": 0.0,
      "step": 90470
    },
    {
      "epoch": 27.917309472385067,
      "grad_norm": 1.3007746701987344e-06,
      "learning_rate": 2.2082690527614936e-05,
      "loss": 0.0009,
      "step": 90480
    },
    {
      "epoch": 27.920394939833386,
      "grad_norm": 2.4392863906541606e-07,
      "learning_rate": 2.2079605060166615e-05,
      "loss": 0.0,
      "step": 90490
    },
    {
      "epoch": 27.923480407281705,
      "grad_norm": 2.365702675888315e-05,
      "learning_rate": 2.2076519592718298e-05,
      "loss": 0.0,
      "step": 90500
    },
    {
      "epoch": 27.92656587473002,
      "grad_norm": 0.0033408869057893753,
      "learning_rate": 2.207343412526998e-05,
      "loss": 0.0085,
      "step": 90510
    },
    {
      "epoch": 27.92965134217834,
      "grad_norm": 0.0003328859165776521,
      "learning_rate": 2.207034865782166e-05,
      "loss": 0.0014,
      "step": 90520
    },
    {
      "epoch": 27.932736809626658,
      "grad_norm": 1.2768476153723896e-05,
      "learning_rate": 2.2067263190373345e-05,
      "loss": 0.0001,
      "step": 90530
    },
    {
      "epoch": 27.935822277074976,
      "grad_norm": 0.0002624128828756511,
      "learning_rate": 2.2064177722925024e-05,
      "loss": 0.0012,
      "step": 90540
    },
    {
      "epoch": 27.938907744523295,
      "grad_norm": 0.0031178866047412157,
      "learning_rate": 2.2061092255476707e-05,
      "loss": 0.003,
      "step": 90550
    },
    {
      "epoch": 27.941993211971614,
      "grad_norm": 1.0204535101365764e-05,
      "learning_rate": 2.2058006788028386e-05,
      "loss": 0.0,
      "step": 90560
    },
    {
      "epoch": 27.945078679419932,
      "grad_norm": 7.534618362114998e-06,
      "learning_rate": 2.2054921320580068e-05,
      "loss": 0.0002,
      "step": 90570
    },
    {
      "epoch": 27.94816414686825,
      "grad_norm": 8.139157216646709e-06,
      "learning_rate": 2.205183585313175e-05,
      "loss": 0.0002,
      "step": 90580
    },
    {
      "epoch": 27.95124961431657,
      "grad_norm": 0.06289657950401306,
      "learning_rate": 2.204875038568343e-05,
      "loss": 0.0002,
      "step": 90590
    },
    {
      "epoch": 27.95433508176489,
      "grad_norm": 0.006086430512368679,
      "learning_rate": 2.2045664918235116e-05,
      "loss": 0.0001,
      "step": 90600
    },
    {
      "epoch": 27.957420549213207,
      "grad_norm": 1.2868666090071201e-05,
      "learning_rate": 2.2042579450786795e-05,
      "loss": 0.0,
      "step": 90610
    },
    {
      "epoch": 27.960506016661526,
      "grad_norm": 0.010016068816184998,
      "learning_rate": 2.2039493983338477e-05,
      "loss": 0.0,
      "step": 90620
    },
    {
      "epoch": 27.96359148410984,
      "grad_norm": 0.005812274292111397,
      "learning_rate": 2.203640851589016e-05,
      "loss": 0.0,
      "step": 90630
    },
    {
      "epoch": 27.96667695155816,
      "grad_norm": 1.0031813383102417,
      "learning_rate": 2.203332304844184e-05,
      "loss": 0.0015,
      "step": 90640
    },
    {
      "epoch": 27.96976241900648,
      "grad_norm": 1.4806097745895386,
      "learning_rate": 2.203023758099352e-05,
      "loss": 0.0029,
      "step": 90650
    },
    {
      "epoch": 27.972847886454797,
      "grad_norm": 0.0002922393032349646,
      "learning_rate": 2.20271521135452e-05,
      "loss": 0.001,
      "step": 90660
    },
    {
      "epoch": 27.975933353903116,
      "grad_norm": 5.045147554483265e-05,
      "learning_rate": 2.2024066646096886e-05,
      "loss": 0.0042,
      "step": 90670
    },
    {
      "epoch": 27.979018821351435,
      "grad_norm": 3.7002298540755874e-06,
      "learning_rate": 2.2020981178648565e-05,
      "loss": 0.0,
      "step": 90680
    },
    {
      "epoch": 27.982104288799754,
      "grad_norm": 0.00016449733811896294,
      "learning_rate": 2.2017895711200248e-05,
      "loss": 0.0,
      "step": 90690
    },
    {
      "epoch": 27.985189756248072,
      "grad_norm": 2.889970528485719e-05,
      "learning_rate": 2.201481024375193e-05,
      "loss": 0.0,
      "step": 90700
    },
    {
      "epoch": 27.98827522369639,
      "grad_norm": 0.0998900756239891,
      "learning_rate": 2.201172477630361e-05,
      "loss": 0.0,
      "step": 90710
    },
    {
      "epoch": 27.99136069114471,
      "grad_norm": 4.962906132277567e-06,
      "learning_rate": 2.2008639308855292e-05,
      "loss": 0.0001,
      "step": 90720
    },
    {
      "epoch": 27.99444615859303,
      "grad_norm": 2.3464166588382795e-05,
      "learning_rate": 2.2005553841406974e-05,
      "loss": 0.0,
      "step": 90730
    },
    {
      "epoch": 27.997531626041344,
      "grad_norm": 3.426908051551436e-06,
      "learning_rate": 2.2002468373958657e-05,
      "loss": 0.0,
      "step": 90740
    },
    {
      "epoch": 28.0,
      "eval_accuracy_branch1": 0.9999131969561066,
      "eval_accuracy_branch2": 0.4617439695996451,
      "eval_f1_branch1": 0.99986500928348,
      "eval_f1_branch2": 0.4615610573768791,
      "eval_loss": 2.686005063878838e-05,
      "eval_precision_branch1": 0.9998576458877835,
      "eval_precision_branch2": 0.527166245811725,
      "eval_recall_branch1": 0.9998723891677505,
      "eval_recall_branch2": 0.5263736581696131,
      "eval_runtime": 241.0402,
      "eval_samples_per_second": 430.148,
      "eval_steps_per_second": 53.771,
      "step": 90748
    },
    {
      "epoch": 28.000617093489662,
      "grad_norm": 0.0010297783883288503,
      "learning_rate": 2.199938290651034e-05,
      "loss": 0.0029,
      "step": 90750
    },
    {
      "epoch": 28.00370256093798,
      "grad_norm": 2.3011301891529e-05,
      "learning_rate": 2.199629743906202e-05,
      "loss": 0.0001,
      "step": 90760
    },
    {
      "epoch": 28.0067880283863,
      "grad_norm": 9.612293797545135e-05,
      "learning_rate": 2.19932119716137e-05,
      "loss": 0.0,
      "step": 90770
    },
    {
      "epoch": 28.00987349583462,
      "grad_norm": 0.00030479879933409393,
      "learning_rate": 2.199012650416538e-05,
      "loss": 0.0002,
      "step": 90780
    },
    {
      "epoch": 28.012958963282937,
      "grad_norm": 0.034924447536468506,
      "learning_rate": 2.1987041036717062e-05,
      "loss": 0.0,
      "step": 90790
    },
    {
      "epoch": 28.016044430731256,
      "grad_norm": 0.0006972417468205094,
      "learning_rate": 2.1983955569268745e-05,
      "loss": 0.0,
      "step": 90800
    },
    {
      "epoch": 28.019129898179575,
      "grad_norm": 5.039235111325979e-05,
      "learning_rate": 2.1980870101820427e-05,
      "loss": 0.0002,
      "step": 90810
    },
    {
      "epoch": 28.022215365627893,
      "grad_norm": 3.5111017382405407e-07,
      "learning_rate": 2.197778463437211e-05,
      "loss": 0.0,
      "step": 90820
    },
    {
      "epoch": 28.025300833076212,
      "grad_norm": 0.006512320134788752,
      "learning_rate": 2.197469916692379e-05,
      "loss": 0.0,
      "step": 90830
    },
    {
      "epoch": 28.02838630052453,
      "grad_norm": 1.5056402844493277e-06,
      "learning_rate": 2.197161369947547e-05,
      "loss": 0.0,
      "step": 90840
    },
    {
      "epoch": 28.03147176797285,
      "grad_norm": 5.1341030484763905e-06,
      "learning_rate": 2.1968528232027154e-05,
      "loss": 0.0,
      "step": 90850
    },
    {
      "epoch": 28.034557235421165,
      "grad_norm": 1.6461241102661006e-05,
      "learning_rate": 2.1965442764578833e-05,
      "loss": 0.0,
      "step": 90860
    },
    {
      "epoch": 28.037642702869483,
      "grad_norm": 2.6802968022821005e-07,
      "learning_rate": 2.196235729713052e-05,
      "loss": 0.0003,
      "step": 90870
    },
    {
      "epoch": 28.040728170317802,
      "grad_norm": 0.0012139716418460011,
      "learning_rate": 2.1959271829682198e-05,
      "loss": 0.0,
      "step": 90880
    },
    {
      "epoch": 28.04381363776612,
      "grad_norm": 0.00018634571461007,
      "learning_rate": 2.195618636223388e-05,
      "loss": 0.0,
      "step": 90890
    },
    {
      "epoch": 28.04689910521444,
      "grad_norm": 0.018807120621204376,
      "learning_rate": 2.195310089478556e-05,
      "loss": 0.0001,
      "step": 90900
    },
    {
      "epoch": 28.04998457266276,
      "grad_norm": 5.441120811155997e-05,
      "learning_rate": 2.1950015427337242e-05,
      "loss": 0.0002,
      "step": 90910
    },
    {
      "epoch": 28.053070040111077,
      "grad_norm": 3.0273838547145715e-07,
      "learning_rate": 2.1946929959888924e-05,
      "loss": 0.0007,
      "step": 90920
    },
    {
      "epoch": 28.056155507559396,
      "grad_norm": 2.0855144612141885e-05,
      "learning_rate": 2.1943844492440604e-05,
      "loss": 0.0,
      "step": 90930
    },
    {
      "epoch": 28.059240975007715,
      "grad_norm": 0.2644791603088379,
      "learning_rate": 2.194075902499229e-05,
      "loss": 0.0002,
      "step": 90940
    },
    {
      "epoch": 28.062326442456033,
      "grad_norm": 0.00010176339856116101,
      "learning_rate": 2.193767355754397e-05,
      "loss": 0.0006,
      "step": 90950
    },
    {
      "epoch": 28.065411909904352,
      "grad_norm": 3.7218908346403623e-06,
      "learning_rate": 2.193458809009565e-05,
      "loss": 0.0,
      "step": 90960
    },
    {
      "epoch": 28.06849737735267,
      "grad_norm": 0.032109297811985016,
      "learning_rate": 2.1931502622647333e-05,
      "loss": 0.0002,
      "step": 90970
    },
    {
      "epoch": 28.071582844800986,
      "grad_norm": 0.00011187803465873003,
      "learning_rate": 2.1928417155199013e-05,
      "loss": 0.0,
      "step": 90980
    },
    {
      "epoch": 28.074668312249305,
      "grad_norm": 0.0024152465630322695,
      "learning_rate": 2.1925331687750695e-05,
      "loss": 0.0,
      "step": 90990
    },
    {
      "epoch": 28.077753779697623,
      "grad_norm": 6.440382549044443e-06,
      "learning_rate": 2.1922246220302378e-05,
      "loss": 0.0,
      "step": 91000
    },
    {
      "epoch": 28.080839247145942,
      "grad_norm": 0.00034949317341670394,
      "learning_rate": 2.191916075285406e-05,
      "loss": 0.0005,
      "step": 91010
    },
    {
      "epoch": 28.08392471459426,
      "grad_norm": 2.8349863896437455e-06,
      "learning_rate": 2.191607528540574e-05,
      "loss": 0.0,
      "step": 91020
    },
    {
      "epoch": 28.08701018204258,
      "grad_norm": 1.953124865394784e-06,
      "learning_rate": 2.191298981795742e-05,
      "loss": 0.0003,
      "step": 91030
    },
    {
      "epoch": 28.090095649490898,
      "grad_norm": 0.00034206832060590386,
      "learning_rate": 2.1909904350509104e-05,
      "loss": 0.001,
      "step": 91040
    },
    {
      "epoch": 28.093181116939217,
      "grad_norm": 0.007178809028118849,
      "learning_rate": 2.1906818883060783e-05,
      "loss": 0.0002,
      "step": 91050
    },
    {
      "epoch": 28.096266584387536,
      "grad_norm": 0.0026608332991600037,
      "learning_rate": 2.1903733415612466e-05,
      "loss": 0.0,
      "step": 91060
    },
    {
      "epoch": 28.099352051835854,
      "grad_norm": 3.4232085454277694e-05,
      "learning_rate": 2.1900647948164148e-05,
      "loss": 0.0076,
      "step": 91070
    },
    {
      "epoch": 28.102437519284173,
      "grad_norm": 5.298862788549741e-07,
      "learning_rate": 2.189756248071583e-05,
      "loss": 0.0016,
      "step": 91080
    },
    {
      "epoch": 28.10552298673249,
      "grad_norm": 0.00034094578586518764,
      "learning_rate": 2.1894477013267513e-05,
      "loss": 0.0,
      "step": 91090
    },
    {
      "epoch": 28.108608454180807,
      "grad_norm": 0.004538619425147772,
      "learning_rate": 2.1891391545819192e-05,
      "loss": 0.0,
      "step": 91100
    },
    {
      "epoch": 28.111693921629126,
      "grad_norm": 0.035762690007686615,
      "learning_rate": 2.1888306078370875e-05,
      "loss": 0.0002,
      "step": 91110
    },
    {
      "epoch": 28.114779389077444,
      "grad_norm": 3.2351674690289656e-06,
      "learning_rate": 2.1885220610922554e-05,
      "loss": 0.0003,
      "step": 91120
    },
    {
      "epoch": 28.117864856525763,
      "grad_norm": 9.735169896885054e-07,
      "learning_rate": 2.1882135143474236e-05,
      "loss": 0.005,
      "step": 91130
    },
    {
      "epoch": 28.120950323974082,
      "grad_norm": 2.1360439859563485e-05,
      "learning_rate": 2.187904967602592e-05,
      "loss": 0.0001,
      "step": 91140
    },
    {
      "epoch": 28.1240357914224,
      "grad_norm": 2.997598357978859e-06,
      "learning_rate": 2.18759642085776e-05,
      "loss": 0.0,
      "step": 91150
    },
    {
      "epoch": 28.12712125887072,
      "grad_norm": 8.507819438818842e-05,
      "learning_rate": 2.1872878741129284e-05,
      "loss": 0.0,
      "step": 91160
    },
    {
      "epoch": 28.130206726319038,
      "grad_norm": 0.006352700758725405,
      "learning_rate": 2.1869793273680963e-05,
      "loss": 0.0,
      "step": 91170
    },
    {
      "epoch": 28.133292193767357,
      "grad_norm": 1.4777723663428333e-05,
      "learning_rate": 2.1866707806232645e-05,
      "loss": 0.0023,
      "step": 91180
    },
    {
      "epoch": 28.136377661215676,
      "grad_norm": 0.0005852090544067323,
      "learning_rate": 2.1863622338784324e-05,
      "loss": 0.0,
      "step": 91190
    },
    {
      "epoch": 28.139463128663994,
      "grad_norm": 4.311239536036737e-06,
      "learning_rate": 2.186053687133601e-05,
      "loss": 0.0,
      "step": 91200
    },
    {
      "epoch": 28.14254859611231,
      "grad_norm": 2.9878257919335738e-05,
      "learning_rate": 2.1857451403887693e-05,
      "loss": 0.0,
      "step": 91210
    },
    {
      "epoch": 28.145634063560628,
      "grad_norm": 5.180042080610292e-06,
      "learning_rate": 2.185436593643937e-05,
      "loss": 0.0001,
      "step": 91220
    },
    {
      "epoch": 28.148719531008947,
      "grad_norm": 1.0737436241470277e-05,
      "learning_rate": 2.1851280468991054e-05,
      "loss": 0.0,
      "step": 91230
    },
    {
      "epoch": 28.151804998457266,
      "grad_norm": 5.609885192825459e-05,
      "learning_rate": 2.1848195001542733e-05,
      "loss": 0.0007,
      "step": 91240
    },
    {
      "epoch": 28.154890465905584,
      "grad_norm": 9.908054607876693e-07,
      "learning_rate": 2.1845109534094416e-05,
      "loss": 0.0,
      "step": 91250
    },
    {
      "epoch": 28.157975933353903,
      "grad_norm": 0.00040449787047691643,
      "learning_rate": 2.1842024066646098e-05,
      "loss": 0.0082,
      "step": 91260
    },
    {
      "epoch": 28.16106140080222,
      "grad_norm": 7.410945272567915e-06,
      "learning_rate": 2.183893859919778e-05,
      "loss": 0.0,
      "step": 91270
    },
    {
      "epoch": 28.16414686825054,
      "grad_norm": 0.016717126592993736,
      "learning_rate": 2.1835853131749463e-05,
      "loss": 0.0,
      "step": 91280
    },
    {
      "epoch": 28.16723233569886,
      "grad_norm": 0.0010790522210299969,
      "learning_rate": 2.1832767664301142e-05,
      "loss": 0.0,
      "step": 91290
    },
    {
      "epoch": 28.170317803147178,
      "grad_norm": 1.4589036254619714e-05,
      "learning_rate": 2.1829682196852825e-05,
      "loss": 0.0,
      "step": 91300
    },
    {
      "epoch": 28.173403270595497,
      "grad_norm": 0.015268070623278618,
      "learning_rate": 2.1826596729404504e-05,
      "loss": 0.0041,
      "step": 91310
    },
    {
      "epoch": 28.176488738043815,
      "grad_norm": 0.0002875081554520875,
      "learning_rate": 2.1823511261956186e-05,
      "loss": 0.0,
      "step": 91320
    },
    {
      "epoch": 28.17957420549213,
      "grad_norm": 1.3504298124189518e-07,
      "learning_rate": 2.182042579450787e-05,
      "loss": 0.002,
      "step": 91330
    },
    {
      "epoch": 28.18265967294045,
      "grad_norm": 2.3005857467651367,
      "learning_rate": 2.181734032705955e-05,
      "loss": 0.0021,
      "step": 91340
    },
    {
      "epoch": 28.185745140388768,
      "grad_norm": 0.00012472920934669673,
      "learning_rate": 2.1814254859611234e-05,
      "loss": 0.0003,
      "step": 91350
    },
    {
      "epoch": 28.188830607837087,
      "grad_norm": 0.14464586973190308,
      "learning_rate": 2.1811169392162913e-05,
      "loss": 0.0001,
      "step": 91360
    },
    {
      "epoch": 28.191916075285405,
      "grad_norm": 0.0033772613387554884,
      "learning_rate": 2.1808083924714595e-05,
      "loss": 0.0001,
      "step": 91370
    },
    {
      "epoch": 28.195001542733724,
      "grad_norm": 0.004763137083500624,
      "learning_rate": 2.1804998457266278e-05,
      "loss": 0.0001,
      "step": 91380
    },
    {
      "epoch": 28.198087010182043,
      "grad_norm": 0.5126885771751404,
      "learning_rate": 2.1801912989817957e-05,
      "loss": 0.0003,
      "step": 91390
    },
    {
      "epoch": 28.20117247763036,
      "grad_norm": 3.568385727703571e-05,
      "learning_rate": 2.1798827522369643e-05,
      "loss": 0.0,
      "step": 91400
    },
    {
      "epoch": 28.20425794507868,
      "grad_norm": 5.515396878763568e-06,
      "learning_rate": 2.1795742054921322e-05,
      "loss": 0.0001,
      "step": 91410
    },
    {
      "epoch": 28.207343412527,
      "grad_norm": 4.044870365760289e-06,
      "learning_rate": 2.1792656587473004e-05,
      "loss": 0.0,
      "step": 91420
    },
    {
      "epoch": 28.210428879975318,
      "grad_norm": 0.00031680057873018086,
      "learning_rate": 2.1789571120024683e-05,
      "loss": 0.0,
      "step": 91430
    },
    {
      "epoch": 28.213514347423633,
      "grad_norm": 2.0870693333563395e-05,
      "learning_rate": 2.1786485652576366e-05,
      "loss": 0.0001,
      "step": 91440
    },
    {
      "epoch": 28.21659981487195,
      "grad_norm": 4.123172038816847e-05,
      "learning_rate": 2.178340018512805e-05,
      "loss": 0.0,
      "step": 91450
    },
    {
      "epoch": 28.21968528232027,
      "grad_norm": 0.0005590140353888273,
      "learning_rate": 2.1780314717679727e-05,
      "loss": 0.0002,
      "step": 91460
    },
    {
      "epoch": 28.22277074976859,
      "grad_norm": 0.0018801772966980934,
      "learning_rate": 2.1777229250231413e-05,
      "loss": 0.0029,
      "step": 91470
    },
    {
      "epoch": 28.225856217216908,
      "grad_norm": 4.178213828254229e-07,
      "learning_rate": 2.1774143782783092e-05,
      "loss": 0.0002,
      "step": 91480
    },
    {
      "epoch": 28.228941684665227,
      "grad_norm": 0.00010082210064865649,
      "learning_rate": 2.1771058315334775e-05,
      "loss": 0.0006,
      "step": 91490
    },
    {
      "epoch": 28.232027152113545,
      "grad_norm": 1.670335404924117e-05,
      "learning_rate": 2.1767972847886457e-05,
      "loss": 0.0,
      "step": 91500
    },
    {
      "epoch": 28.235112619561864,
      "grad_norm": 9.899925316858571e-06,
      "learning_rate": 2.1764887380438136e-05,
      "loss": 0.0002,
      "step": 91510
    },
    {
      "epoch": 28.238198087010183,
      "grad_norm": 0.007446088828146458,
      "learning_rate": 2.176180191298982e-05,
      "loss": 0.0,
      "step": 91520
    },
    {
      "epoch": 28.2412835544585,
      "grad_norm": 3.484680064502754e-07,
      "learning_rate": 2.1758716445541498e-05,
      "loss": 0.0,
      "step": 91530
    },
    {
      "epoch": 28.24436902190682,
      "grad_norm": 0.0002378293575020507,
      "learning_rate": 2.1755630978093184e-05,
      "loss": 0.0003,
      "step": 91540
    },
    {
      "epoch": 28.24745448935514,
      "grad_norm": 0.004064997658133507,
      "learning_rate": 2.1752545510644863e-05,
      "loss": 0.0002,
      "step": 91550
    },
    {
      "epoch": 28.250539956803454,
      "grad_norm": 0.02598762884736061,
      "learning_rate": 2.1749460043196545e-05,
      "loss": 0.0001,
      "step": 91560
    },
    {
      "epoch": 28.253625424251773,
      "grad_norm": 2.075284101010766e-06,
      "learning_rate": 2.1746374575748228e-05,
      "loss": 0.0,
      "step": 91570
    },
    {
      "epoch": 28.25671089170009,
      "grad_norm": 0.006226902827620506,
      "learning_rate": 2.1743289108299907e-05,
      "loss": 0.0001,
      "step": 91580
    },
    {
      "epoch": 28.25979635914841,
      "grad_norm": 0.003556549549102783,
      "learning_rate": 2.174020364085159e-05,
      "loss": 0.0001,
      "step": 91590
    },
    {
      "epoch": 28.26288182659673,
      "grad_norm": 2.1699968044686102e-07,
      "learning_rate": 2.1737118173403272e-05,
      "loss": 0.0001,
      "step": 91600
    },
    {
      "epoch": 28.265967294045048,
      "grad_norm": 4.315156184020452e-05,
      "learning_rate": 2.1734032705954954e-05,
      "loss": 0.0,
      "step": 91610
    },
    {
      "epoch": 28.269052761493366,
      "grad_norm": 0.0001229663466801867,
      "learning_rate": 2.1730947238506637e-05,
      "loss": 0.0,
      "step": 91620
    },
    {
      "epoch": 28.272138228941685,
      "grad_norm": 0.0004304160247556865,
      "learning_rate": 2.1727861771058316e-05,
      "loss": 0.0006,
      "step": 91630
    },
    {
      "epoch": 28.275223696390004,
      "grad_norm": 7.95625674072653e-05,
      "learning_rate": 2.172477630361e-05,
      "loss": 0.0,
      "step": 91640
    },
    {
      "epoch": 28.278309163838323,
      "grad_norm": 0.0006023532478138804,
      "learning_rate": 2.1721690836161678e-05,
      "loss": 0.0002,
      "step": 91650
    },
    {
      "epoch": 28.28139463128664,
      "grad_norm": 4.73145664727781e-05,
      "learning_rate": 2.171860536871336e-05,
      "loss": 0.0005,
      "step": 91660
    },
    {
      "epoch": 28.28448009873496,
      "grad_norm": 0.00018590806575957686,
      "learning_rate": 2.1715519901265042e-05,
      "loss": 0.0002,
      "step": 91670
    },
    {
      "epoch": 28.287565566183275,
      "grad_norm": 0.0016392015386372805,
      "learning_rate": 2.1712434433816725e-05,
      "loss": 0.0001,
      "step": 91680
    },
    {
      "epoch": 28.290651033631594,
      "grad_norm": 1.4987178474257234e-05,
      "learning_rate": 2.1709348966368407e-05,
      "loss": 0.0017,
      "step": 91690
    },
    {
      "epoch": 28.293736501079913,
      "grad_norm": 3.2667758205207065e-05,
      "learning_rate": 2.1706263498920087e-05,
      "loss": 0.0021,
      "step": 91700
    },
    {
      "epoch": 28.29682196852823,
      "grad_norm": 0.00726722925901413,
      "learning_rate": 2.170317803147177e-05,
      "loss": 0.0,
      "step": 91710
    },
    {
      "epoch": 28.29990743597655,
      "grad_norm": 3.4628581488505006e-05,
      "learning_rate": 2.170009256402345e-05,
      "loss": 0.0,
      "step": 91720
    },
    {
      "epoch": 28.30299290342487,
      "grad_norm": 0.0032539661042392254,
      "learning_rate": 2.169700709657513e-05,
      "loss": 0.0001,
      "step": 91730
    },
    {
      "epoch": 28.306078370873188,
      "grad_norm": 1.925612449645996,
      "learning_rate": 2.1693921629126816e-05,
      "loss": 0.0018,
      "step": 91740
    },
    {
      "epoch": 28.309163838321506,
      "grad_norm": 0.0002674539282452315,
      "learning_rate": 2.1690836161678496e-05,
      "loss": 0.0016,
      "step": 91750
    },
    {
      "epoch": 28.312249305769825,
      "grad_norm": 1.2861552932008635e-05,
      "learning_rate": 2.1687750694230178e-05,
      "loss": 0.0,
      "step": 91760
    },
    {
      "epoch": 28.315334773218144,
      "grad_norm": 0.00010421340266475454,
      "learning_rate": 2.1684665226781857e-05,
      "loss": 0.0031,
      "step": 91770
    },
    {
      "epoch": 28.318420240666462,
      "grad_norm": 0.010248699225485325,
      "learning_rate": 2.168157975933354e-05,
      "loss": 0.0002,
      "step": 91780
    },
    {
      "epoch": 28.321505708114778,
      "grad_norm": 0.08956071734428406,
      "learning_rate": 2.1678494291885222e-05,
      "loss": 0.0008,
      "step": 91790
    },
    {
      "epoch": 28.324591175563096,
      "grad_norm": 0.0028437308501452208,
      "learning_rate": 2.16754088244369e-05,
      "loss": 0.0001,
      "step": 91800
    },
    {
      "epoch": 28.327676643011415,
      "grad_norm": 0.00310742505826056,
      "learning_rate": 2.1672323356988587e-05,
      "loss": 0.0003,
      "step": 91810
    },
    {
      "epoch": 28.330762110459734,
      "grad_norm": 8.1718506407924e-05,
      "learning_rate": 2.1669237889540266e-05,
      "loss": 0.0,
      "step": 91820
    },
    {
      "epoch": 28.333847577908053,
      "grad_norm": 0.17877815663814545,
      "learning_rate": 2.166615242209195e-05,
      "loss": 0.0001,
      "step": 91830
    },
    {
      "epoch": 28.33693304535637,
      "grad_norm": 0.009244217537343502,
      "learning_rate": 2.1663066954643628e-05,
      "loss": 0.0001,
      "step": 91840
    },
    {
      "epoch": 28.34001851280469,
      "grad_norm": 0.00018272289889864624,
      "learning_rate": 2.165998148719531e-05,
      "loss": 0.0002,
      "step": 91850
    },
    {
      "epoch": 28.34310398025301,
      "grad_norm": 1.3369709253311157,
      "learning_rate": 2.1656896019746993e-05,
      "loss": 0.0033,
      "step": 91860
    },
    {
      "epoch": 28.346189447701327,
      "grad_norm": 6.12096255281358e-06,
      "learning_rate": 2.1653810552298675e-05,
      "loss": 0.0,
      "step": 91870
    },
    {
      "epoch": 28.349274915149646,
      "grad_norm": 0.006776456721127033,
      "learning_rate": 2.1650725084850358e-05,
      "loss": 0.0,
      "step": 91880
    },
    {
      "epoch": 28.352360382597965,
      "grad_norm": 3.234342575073242,
      "learning_rate": 2.1647639617402037e-05,
      "loss": 0.0034,
      "step": 91890
    },
    {
      "epoch": 28.355445850046284,
      "grad_norm": 0.00050111033488065,
      "learning_rate": 2.164455414995372e-05,
      "loss": 0.0002,
      "step": 91900
    },
    {
      "epoch": 28.3585313174946,
      "grad_norm": 7.74103682488203e-06,
      "learning_rate": 2.16414686825054e-05,
      "loss": 0.0,
      "step": 91910
    },
    {
      "epoch": 28.361616784942917,
      "grad_norm": 0.0011327421525493264,
      "learning_rate": 2.163838321505708e-05,
      "loss": 0.0002,
      "step": 91920
    },
    {
      "epoch": 28.364702252391236,
      "grad_norm": 0.17555831372737885,
      "learning_rate": 2.1635297747608763e-05,
      "loss": 0.0002,
      "step": 91930
    },
    {
      "epoch": 28.367787719839555,
      "grad_norm": 2.439363561279606e-05,
      "learning_rate": 2.1632212280160446e-05,
      "loss": 0.0012,
      "step": 91940
    },
    {
      "epoch": 28.370873187287874,
      "grad_norm": 0.001052928389981389,
      "learning_rate": 2.1629126812712128e-05,
      "loss": 0.0,
      "step": 91950
    },
    {
      "epoch": 28.373958654736192,
      "grad_norm": 0.010305029340088367,
      "learning_rate": 2.1626041345263807e-05,
      "loss": 0.0004,
      "step": 91960
    },
    {
      "epoch": 28.37704412218451,
      "grad_norm": 4.187106696917908e-06,
      "learning_rate": 2.162295587781549e-05,
      "loss": 0.0,
      "step": 91970
    },
    {
      "epoch": 28.38012958963283,
      "grad_norm": 6.348925580823561e-06,
      "learning_rate": 2.1619870410367172e-05,
      "loss": 0.0,
      "step": 91980
    },
    {
      "epoch": 28.38321505708115,
      "grad_norm": 4.167401493759826e-05,
      "learning_rate": 2.161678494291885e-05,
      "loss": 0.0,
      "step": 91990
    },
    {
      "epoch": 28.386300524529467,
      "grad_norm": 0.00019313505617901683,
      "learning_rate": 2.1613699475470534e-05,
      "loss": 0.0048,
      "step": 92000
    },
    {
      "epoch": 28.389385991977786,
      "grad_norm": 1.3267434951558243e-05,
      "learning_rate": 2.1610614008022216e-05,
      "loss": 0.0,
      "step": 92010
    },
    {
      "epoch": 28.392471459426105,
      "grad_norm": 4.232858191244304e-05,
      "learning_rate": 2.16075285405739e-05,
      "loss": 0.0,
      "step": 92020
    },
    {
      "epoch": 28.39555692687442,
      "grad_norm": 8.351948963536415e-06,
      "learning_rate": 2.160444307312558e-05,
      "loss": 0.0001,
      "step": 92030
    },
    {
      "epoch": 28.39864239432274,
      "grad_norm": 0.0008462392725050449,
      "learning_rate": 2.160135760567726e-05,
      "loss": 0.0029,
      "step": 92040
    },
    {
      "epoch": 28.401727861771057,
      "grad_norm": 0.0002675751456990838,
      "learning_rate": 2.1598272138228943e-05,
      "loss": 0.0002,
      "step": 92050
    },
    {
      "epoch": 28.404813329219376,
      "grad_norm": 7.389420352410525e-05,
      "learning_rate": 2.1595186670780622e-05,
      "loss": 0.0,
      "step": 92060
    },
    {
      "epoch": 28.407898796667695,
      "grad_norm": 0.033469077199697495,
      "learning_rate": 2.1592101203332308e-05,
      "loss": 0.0017,
      "step": 92070
    },
    {
      "epoch": 28.410984264116014,
      "grad_norm": 0.00457047438248992,
      "learning_rate": 2.1589015735883987e-05,
      "loss": 0.0,
      "step": 92080
    },
    {
      "epoch": 28.414069731564332,
      "grad_norm": 0.00028859786107204854,
      "learning_rate": 2.158593026843567e-05,
      "loss": 0.0,
      "step": 92090
    },
    {
      "epoch": 28.41715519901265,
      "grad_norm": 0.2205916792154312,
      "learning_rate": 2.1582844800987352e-05,
      "loss": 0.0003,
      "step": 92100
    },
    {
      "epoch": 28.42024066646097,
      "grad_norm": 0.00032522788387723267,
      "learning_rate": 2.157975933353903e-05,
      "loss": 0.0,
      "step": 92110
    },
    {
      "epoch": 28.42332613390929,
      "grad_norm": 0.0030977411661297083,
      "learning_rate": 2.1576673866090713e-05,
      "loss": 0.0001,
      "step": 92120
    },
    {
      "epoch": 28.426411601357607,
      "grad_norm": 3.62831269740127e-05,
      "learning_rate": 2.1573588398642396e-05,
      "loss": 0.0001,
      "step": 92130
    },
    {
      "epoch": 28.429497068805922,
      "grad_norm": 0.0029892846941947937,
      "learning_rate": 2.1570502931194078e-05,
      "loss": 0.0007,
      "step": 92140
    },
    {
      "epoch": 28.43258253625424,
      "grad_norm": 0.0020852372981607914,
      "learning_rate": 2.156741746374576e-05,
      "loss": 0.0,
      "step": 92150
    },
    {
      "epoch": 28.43566800370256,
      "grad_norm": 3.1072460842551664e-05,
      "learning_rate": 2.156433199629744e-05,
      "loss": 0.0,
      "step": 92160
    },
    {
      "epoch": 28.43875347115088,
      "grad_norm": 0.00011408891441533342,
      "learning_rate": 2.1561246528849122e-05,
      "loss": 0.0,
      "step": 92170
    },
    {
      "epoch": 28.441838938599197,
      "grad_norm": 0.00026717668515630066,
      "learning_rate": 2.15581610614008e-05,
      "loss": 0.0007,
      "step": 92180
    },
    {
      "epoch": 28.444924406047516,
      "grad_norm": 0.001036732573993504,
      "learning_rate": 2.1555075593952484e-05,
      "loss": 0.0002,
      "step": 92190
    },
    {
      "epoch": 28.448009873495835,
      "grad_norm": 0.03571034222841263,
      "learning_rate": 2.1551990126504166e-05,
      "loss": 0.0001,
      "step": 92200
    },
    {
      "epoch": 28.451095340944153,
      "grad_norm": 2.9344890208449215e-05,
      "learning_rate": 2.154890465905585e-05,
      "loss": 0.0001,
      "step": 92210
    },
    {
      "epoch": 28.454180808392472,
      "grad_norm": 1.3999721204527305e-06,
      "learning_rate": 2.154581919160753e-05,
      "loss": 0.0,
      "step": 92220
    },
    {
      "epoch": 28.45726627584079,
      "grad_norm": 0.32773181796073914,
      "learning_rate": 2.154273372415921e-05,
      "loss": 0.0002,
      "step": 92230
    },
    {
      "epoch": 28.46035174328911,
      "grad_norm": 0.00011293053830740973,
      "learning_rate": 2.1539648256710893e-05,
      "loss": 0.0,
      "step": 92240
    },
    {
      "epoch": 28.46343721073743,
      "grad_norm": 0.13311637938022614,
      "learning_rate": 2.1536562789262575e-05,
      "loss": 0.0029,
      "step": 92250
    },
    {
      "epoch": 28.466522678185743,
      "grad_norm": 0.000993698020465672,
      "learning_rate": 2.1533477321814254e-05,
      "loss": 0.0001,
      "step": 92260
    },
    {
      "epoch": 28.469608145634062,
      "grad_norm": 4.111307134735398e-06,
      "learning_rate": 2.1530391854365937e-05,
      "loss": 0.0005,
      "step": 92270
    },
    {
      "epoch": 28.47269361308238,
      "grad_norm": 1.4711800133682118e-07,
      "learning_rate": 2.152730638691762e-05,
      "loss": 0.0001,
      "step": 92280
    },
    {
      "epoch": 28.4757790805307,
      "grad_norm": 2.039898572547827e-05,
      "learning_rate": 2.1524220919469302e-05,
      "loss": 0.0041,
      "step": 92290
    },
    {
      "epoch": 28.47886454797902,
      "grad_norm": 0.0004900864441879094,
      "learning_rate": 2.152113545202098e-05,
      "loss": 0.001,
      "step": 92300
    },
    {
      "epoch": 28.481950015427337,
      "grad_norm": 8.362092194147408e-05,
      "learning_rate": 2.1518049984572663e-05,
      "loss": 0.0,
      "step": 92310
    },
    {
      "epoch": 28.485035482875656,
      "grad_norm": 1.1787936955443001e-06,
      "learning_rate": 2.1514964517124346e-05,
      "loss": 0.0002,
      "step": 92320
    },
    {
      "epoch": 28.488120950323975,
      "grad_norm": 4.0115985029842705e-05,
      "learning_rate": 2.1511879049676025e-05,
      "loss": 0.0001,
      "step": 92330
    },
    {
      "epoch": 28.491206417772293,
      "grad_norm": 0.0006405369495041668,
      "learning_rate": 2.150879358222771e-05,
      "loss": 0.0,
      "step": 92340
    },
    {
      "epoch": 28.494291885220612,
      "grad_norm": 1.9074047803878784,
      "learning_rate": 2.150570811477939e-05,
      "loss": 0.0004,
      "step": 92350
    },
    {
      "epoch": 28.49737735266893,
      "grad_norm": 0.027438707649707794,
      "learning_rate": 2.1502622647331072e-05,
      "loss": 0.0005,
      "step": 92360
    },
    {
      "epoch": 28.50046282011725,
      "grad_norm": 1.693602598606958e-06,
      "learning_rate": 2.1499537179882755e-05,
      "loss": 0.0,
      "step": 92370
    },
    {
      "epoch": 28.503548287565565,
      "grad_norm": 7.081918056428549e-07,
      "learning_rate": 2.1496451712434434e-05,
      "loss": 0.0,
      "step": 92380
    },
    {
      "epoch": 28.506633755013883,
      "grad_norm": 2.8451855541788973e-05,
      "learning_rate": 2.1493366244986116e-05,
      "loss": 0.0,
      "step": 92390
    },
    {
      "epoch": 28.509719222462202,
      "grad_norm": 8.239040653279517e-06,
      "learning_rate": 2.1490280777537796e-05,
      "loss": 0.0001,
      "step": 92400
    },
    {
      "epoch": 28.51280468991052,
      "grad_norm": 1.8323831682209857e-05,
      "learning_rate": 2.148719531008948e-05,
      "loss": 0.0,
      "step": 92410
    },
    {
      "epoch": 28.51589015735884,
      "grad_norm": 0.00025889044627547264,
      "learning_rate": 2.148410984264116e-05,
      "loss": 0.0001,
      "step": 92420
    },
    {
      "epoch": 28.518975624807158,
      "grad_norm": 0.0008819566573947668,
      "learning_rate": 2.1481024375192843e-05,
      "loss": 0.0002,
      "step": 92430
    },
    {
      "epoch": 28.522061092255477,
      "grad_norm": 4.969914243702078e-06,
      "learning_rate": 2.1477938907744525e-05,
      "loss": 0.0,
      "step": 92440
    },
    {
      "epoch": 28.525146559703796,
      "grad_norm": 9.274945114157163e-06,
      "learning_rate": 2.1474853440296205e-05,
      "loss": 0.0,
      "step": 92450
    },
    {
      "epoch": 28.528232027152114,
      "grad_norm": 1.3971833141113166e-05,
      "learning_rate": 2.1471767972847887e-05,
      "loss": 0.0,
      "step": 92460
    },
    {
      "epoch": 28.531317494600433,
      "grad_norm": 0.008108730427920818,
      "learning_rate": 2.1468682505399566e-05,
      "loss": 0.0,
      "step": 92470
    },
    {
      "epoch": 28.534402962048752,
      "grad_norm": 2.3472714019590057e-05,
      "learning_rate": 2.1465597037951252e-05,
      "loss": 0.0012,
      "step": 92480
    },
    {
      "epoch": 28.537488429497067,
      "grad_norm": 0.04151123762130737,
      "learning_rate": 2.1462511570502934e-05,
      "loss": 0.0001,
      "step": 92490
    },
    {
      "epoch": 28.540573896945386,
      "grad_norm": 0.00303292041644454,
      "learning_rate": 2.1459426103054614e-05,
      "loss": 0.0001,
      "step": 92500
    },
    {
      "epoch": 28.543659364393704,
      "grad_norm": 0.0010262668365612626,
      "learning_rate": 2.1456340635606296e-05,
      "loss": 0.0001,
      "step": 92510
    },
    {
      "epoch": 28.546744831842023,
      "grad_norm": 1.4153978554531932e-05,
      "learning_rate": 2.1453255168157975e-05,
      "loss": 0.0,
      "step": 92520
    },
    {
      "epoch": 28.549830299290342,
      "grad_norm": 0.00015359489771071821,
      "learning_rate": 2.1450169700709658e-05,
      "loss": 0.0,
      "step": 92530
    },
    {
      "epoch": 28.55291576673866,
      "grad_norm": 3.104036331176758,
      "learning_rate": 2.144708423326134e-05,
      "loss": 0.0013,
      "step": 92540
    },
    {
      "epoch": 28.55600123418698,
      "grad_norm": 0.002476185094565153,
      "learning_rate": 2.1443998765813023e-05,
      "loss": 0.0,
      "step": 92550
    },
    {
      "epoch": 28.559086701635298,
      "grad_norm": 0.0696282908320427,
      "learning_rate": 2.1440913298364705e-05,
      "loss": 0.0002,
      "step": 92560
    },
    {
      "epoch": 28.562172169083617,
      "grad_norm": 5.750048876507208e-05,
      "learning_rate": 2.1437827830916384e-05,
      "loss": 0.0,
      "step": 92570
    },
    {
      "epoch": 28.565257636531936,
      "grad_norm": 3.3254793379455805e-05,
      "learning_rate": 2.1434742363468067e-05,
      "loss": 0.0017,
      "step": 92580
    },
    {
      "epoch": 28.568343103980254,
      "grad_norm": 0.0013748275814577937,
      "learning_rate": 2.1431656896019746e-05,
      "loss": 0.0,
      "step": 92590
    },
    {
      "epoch": 28.571428571428573,
      "grad_norm": 0.009269850328564644,
      "learning_rate": 2.1428571428571428e-05,
      "loss": 0.0,
      "step": 92600
    },
    {
      "epoch": 28.57451403887689,
      "grad_norm": 0.00023010313452687114,
      "learning_rate": 2.1425485961123114e-05,
      "loss": 0.0,
      "step": 92610
    },
    {
      "epoch": 28.577599506325207,
      "grad_norm": 0.002924273954704404,
      "learning_rate": 2.1422400493674793e-05,
      "loss": 0.0,
      "step": 92620
    },
    {
      "epoch": 28.580684973773526,
      "grad_norm": 0.0015601074555888772,
      "learning_rate": 2.1419315026226476e-05,
      "loss": 0.0,
      "step": 92630
    },
    {
      "epoch": 28.583770441221844,
      "grad_norm": 0.005353537853807211,
      "learning_rate": 2.1416229558778155e-05,
      "loss": 0.0002,
      "step": 92640
    },
    {
      "epoch": 28.586855908670163,
      "grad_norm": 0.003215707140043378,
      "learning_rate": 2.1413144091329837e-05,
      "loss": 0.0,
      "step": 92650
    },
    {
      "epoch": 28.58994137611848,
      "grad_norm": 1.0373343684477732e-05,
      "learning_rate": 2.141005862388152e-05,
      "loss": 0.0,
      "step": 92660
    },
    {
      "epoch": 28.5930268435668,
      "grad_norm": 8.32448567962274e-05,
      "learning_rate": 2.14069731564332e-05,
      "loss": 0.0,
      "step": 92670
    },
    {
      "epoch": 28.59611231101512,
      "grad_norm": 9.593747563485522e-06,
      "learning_rate": 2.1403887688984885e-05,
      "loss": 0.0,
      "step": 92680
    },
    {
      "epoch": 28.599197778463438,
      "grad_norm": 2.3976294869498815e-06,
      "learning_rate": 2.1400802221536564e-05,
      "loss": 0.0007,
      "step": 92690
    },
    {
      "epoch": 28.602283245911757,
      "grad_norm": 2.681897512957221e-07,
      "learning_rate": 2.1397716754088246e-05,
      "loss": 0.0002,
      "step": 92700
    },
    {
      "epoch": 28.605368713360075,
      "grad_norm": 0.00018558559531811625,
      "learning_rate": 2.1394631286639925e-05,
      "loss": 0.0002,
      "step": 92710
    },
    {
      "epoch": 28.608454180808394,
      "grad_norm": 5.32118122009706e-07,
      "learning_rate": 2.1391545819191608e-05,
      "loss": 0.0057,
      "step": 92720
    },
    {
      "epoch": 28.61153964825671,
      "grad_norm": 3.5724085591937182e-06,
      "learning_rate": 2.138846035174329e-05,
      "loss": 0.0,
      "step": 92730
    },
    {
      "epoch": 28.614625115705028,
      "grad_norm": 0.002630207920446992,
      "learning_rate": 2.1385374884294973e-05,
      "loss": 0.0005,
      "step": 92740
    },
    {
      "epoch": 28.617710583153347,
      "grad_norm": 3.580089469323866e-05,
      "learning_rate": 2.1382289416846655e-05,
      "loss": 0.0,
      "step": 92750
    },
    {
      "epoch": 28.620796050601665,
      "grad_norm": 7.768524028506363e-07,
      "learning_rate": 2.1379203949398334e-05,
      "loss": 0.0001,
      "step": 92760
    },
    {
      "epoch": 28.623881518049984,
      "grad_norm": 0.0030528861097991467,
      "learning_rate": 2.1376118481950017e-05,
      "loss": 0.0005,
      "step": 92770
    },
    {
      "epoch": 28.626966985498303,
      "grad_norm": 0.0018430034397169948,
      "learning_rate": 2.13730330145017e-05,
      "loss": 0.0,
      "step": 92780
    },
    {
      "epoch": 28.63005245294662,
      "grad_norm": 0.24823033809661865,
      "learning_rate": 2.1369947547053378e-05,
      "loss": 0.0001,
      "step": 92790
    },
    {
      "epoch": 28.63313792039494,
      "grad_norm": 1.63170102496224e-06,
      "learning_rate": 2.136686207960506e-05,
      "loss": 0.0007,
      "step": 92800
    },
    {
      "epoch": 28.63622338784326,
      "grad_norm": 3.2620389447401976e-06,
      "learning_rate": 2.1363776612156743e-05,
      "loss": 0.0,
      "step": 92810
    },
    {
      "epoch": 28.639308855291578,
      "grad_norm": 0.00017127534374594688,
      "learning_rate": 2.1360691144708426e-05,
      "loss": 0.0187,
      "step": 92820
    },
    {
      "epoch": 28.642394322739896,
      "grad_norm": 2.660548830135667e-07,
      "learning_rate": 2.1357605677260105e-05,
      "loss": 0.0008,
      "step": 92830
    },
    {
      "epoch": 28.645479790188215,
      "grad_norm": 8.622761379228905e-05,
      "learning_rate": 2.1354520209811787e-05,
      "loss": 0.0007,
      "step": 92840
    },
    {
      "epoch": 28.64856525763653,
      "grad_norm": 0.0002507394819986075,
      "learning_rate": 2.135143474236347e-05,
      "loss": 0.002,
      "step": 92850
    },
    {
      "epoch": 28.65165072508485,
      "grad_norm": 0.0008702971390448511,
      "learning_rate": 2.134834927491515e-05,
      "loss": 0.0,
      "step": 92860
    },
    {
      "epoch": 28.654736192533168,
      "grad_norm": 3.2275525882141665e-05,
      "learning_rate": 2.134526380746683e-05,
      "loss": 0.0057,
      "step": 92870
    },
    {
      "epoch": 28.657821659981487,
      "grad_norm": 0.0004020043124910444,
      "learning_rate": 2.1342178340018514e-05,
      "loss": 0.0001,
      "step": 92880
    },
    {
      "epoch": 28.660907127429805,
      "grad_norm": 0.8539883494377136,
      "learning_rate": 2.1339092872570196e-05,
      "loss": 0.0009,
      "step": 92890
    },
    {
      "epoch": 28.663992594878124,
      "grad_norm": 1.7687368654151214e-06,
      "learning_rate": 2.133600740512188e-05,
      "loss": 0.0066,
      "step": 92900
    },
    {
      "epoch": 28.667078062326443,
      "grad_norm": 0.000288427370833233,
      "learning_rate": 2.1332921937673558e-05,
      "loss": 0.0016,
      "step": 92910
    },
    {
      "epoch": 28.67016352977476,
      "grad_norm": 1.435180902481079,
      "learning_rate": 2.132983647022524e-05,
      "loss": 0.0008,
      "step": 92920
    },
    {
      "epoch": 28.67324899722308,
      "grad_norm": 9.158989996649325e-05,
      "learning_rate": 2.132675100277692e-05,
      "loss": 0.0,
      "step": 92930
    },
    {
      "epoch": 28.6763344646714,
      "grad_norm": 9.93514640867943e-06,
      "learning_rate": 2.1323665535328605e-05,
      "loss": 0.0,
      "step": 92940
    },
    {
      "epoch": 28.679419932119718,
      "grad_norm": 1.1911463843716774e-05,
      "learning_rate": 2.1320580067880284e-05,
      "loss": 0.0003,
      "step": 92950
    },
    {
      "epoch": 28.682505399568036,
      "grad_norm": 0.0004922716179862618,
      "learning_rate": 2.1317494600431967e-05,
      "loss": 0.0,
      "step": 92960
    },
    {
      "epoch": 28.68559086701635,
      "grad_norm": 0.0004723372694570571,
      "learning_rate": 2.131440913298365e-05,
      "loss": 0.0003,
      "step": 92970
    },
    {
      "epoch": 28.68867633446467,
      "grad_norm": 0.00031568470876663923,
      "learning_rate": 2.131132366553533e-05,
      "loss": 0.0023,
      "step": 92980
    },
    {
      "epoch": 28.69176180191299,
      "grad_norm": 1.7862370782495418e-07,
      "learning_rate": 2.130823819808701e-05,
      "loss": 0.0003,
      "step": 92990
    },
    {
      "epoch": 28.694847269361308,
      "grad_norm": 7.78605171944946e-05,
      "learning_rate": 2.1305152730638693e-05,
      "loss": 0.0,
      "step": 93000
    },
    {
      "epoch": 28.697932736809626,
      "grad_norm": 0.0003199967904947698,
      "learning_rate": 2.1302067263190376e-05,
      "loss": 0.0003,
      "step": 93010
    },
    {
      "epoch": 28.701018204257945,
      "grad_norm": 7.495526369893923e-05,
      "learning_rate": 2.1298981795742058e-05,
      "loss": 0.0007,
      "step": 93020
    },
    {
      "epoch": 28.704103671706264,
      "grad_norm": 2.0268129446776584e-05,
      "learning_rate": 2.1295896328293737e-05,
      "loss": 0.0,
      "step": 93030
    },
    {
      "epoch": 28.707189139154583,
      "grad_norm": 0.003871067427098751,
      "learning_rate": 2.129281086084542e-05,
      "loss": 0.0005,
      "step": 93040
    },
    {
      "epoch": 28.7102746066029,
      "grad_norm": 0.3666856288909912,
      "learning_rate": 2.12897253933971e-05,
      "loss": 0.0006,
      "step": 93050
    },
    {
      "epoch": 28.71336007405122,
      "grad_norm": 0.013509915210306644,
      "learning_rate": 2.128663992594878e-05,
      "loss": 0.0,
      "step": 93060
    },
    {
      "epoch": 28.71644554149954,
      "grad_norm": 2.128482719854219e-06,
      "learning_rate": 2.1283554458500464e-05,
      "loss": 0.0,
      "step": 93070
    },
    {
      "epoch": 28.719531008947854,
      "grad_norm": 0.0008268804522231221,
      "learning_rate": 2.1280468991052146e-05,
      "loss": 0.0002,
      "step": 93080
    },
    {
      "epoch": 28.722616476396173,
      "grad_norm": 1.294854337174911e-05,
      "learning_rate": 2.127738352360383e-05,
      "loss": 0.0,
      "step": 93090
    },
    {
      "epoch": 28.72570194384449,
      "grad_norm": 0.00031880370806902647,
      "learning_rate": 2.1274298056155508e-05,
      "loss": 0.0,
      "step": 93100
    },
    {
      "epoch": 28.72878741129281,
      "grad_norm": 0.0280553437769413,
      "learning_rate": 2.127121258870719e-05,
      "loss": 0.0,
      "step": 93110
    },
    {
      "epoch": 28.73187287874113,
      "grad_norm": 0.07089103013277054,
      "learning_rate": 2.126812712125887e-05,
      "loss": 0.0045,
      "step": 93120
    },
    {
      "epoch": 28.734958346189448,
      "grad_norm": 0.00018888966587837785,
      "learning_rate": 2.1265041653810552e-05,
      "loss": 0.0,
      "step": 93130
    },
    {
      "epoch": 28.738043813637766,
      "grad_norm": 3.7524745266637183e-07,
      "learning_rate": 2.1261956186362234e-05,
      "loss": 0.0002,
      "step": 93140
    },
    {
      "epoch": 28.741129281086085,
      "grad_norm": 0.00022001056640874594,
      "learning_rate": 2.1258870718913917e-05,
      "loss": 0.0001,
      "step": 93150
    },
    {
      "epoch": 28.744214748534404,
      "grad_norm": 0.0005492522614076734,
      "learning_rate": 2.12557852514656e-05,
      "loss": 0.0003,
      "step": 93160
    },
    {
      "epoch": 28.747300215982722,
      "grad_norm": 0.0004933665040880442,
      "learning_rate": 2.125269978401728e-05,
      "loss": 0.0058,
      "step": 93170
    },
    {
      "epoch": 28.75038568343104,
      "grad_norm": 9.612651774659753e-05,
      "learning_rate": 2.124961431656896e-05,
      "loss": 0.0,
      "step": 93180
    },
    {
      "epoch": 28.75347115087936,
      "grad_norm": 5.478516686707735e-05,
      "learning_rate": 2.1246528849120643e-05,
      "loss": 0.0,
      "step": 93190
    },
    {
      "epoch": 28.756556618327675,
      "grad_norm": 0.00024965766351670027,
      "learning_rate": 2.1243443381672323e-05,
      "loss": 0.0,
      "step": 93200
    },
    {
      "epoch": 28.759642085775994,
      "grad_norm": 0.00018820336845237762,
      "learning_rate": 2.124035791422401e-05,
      "loss": 0.0013,
      "step": 93210
    },
    {
      "epoch": 28.762727553224313,
      "grad_norm": 0.08470093458890915,
      "learning_rate": 2.1237272446775688e-05,
      "loss": 0.0004,
      "step": 93220
    },
    {
      "epoch": 28.76581302067263,
      "grad_norm": 0.005263306200504303,
      "learning_rate": 2.123418697932737e-05,
      "loss": 0.0084,
      "step": 93230
    },
    {
      "epoch": 28.76889848812095,
      "grad_norm": 0.00019484669610392302,
      "learning_rate": 2.123110151187905e-05,
      "loss": 0.0005,
      "step": 93240
    },
    {
      "epoch": 28.77198395556927,
      "grad_norm": 1.3617999684356619e-05,
      "learning_rate": 2.122801604443073e-05,
      "loss": 0.0009,
      "step": 93250
    },
    {
      "epoch": 28.775069423017587,
      "grad_norm": 1.1161491784150712e-05,
      "learning_rate": 2.1224930576982414e-05,
      "loss": 0.0079,
      "step": 93260
    },
    {
      "epoch": 28.778154890465906,
      "grad_norm": 0.0026476464699953794,
      "learning_rate": 2.1221845109534093e-05,
      "loss": 0.0001,
      "step": 93270
    },
    {
      "epoch": 28.781240357914225,
      "grad_norm": 2.2905622245161794e-05,
      "learning_rate": 2.121875964208578e-05,
      "loss": 0.0,
      "step": 93280
    },
    {
      "epoch": 28.784325825362544,
      "grad_norm": 0.0377073660492897,
      "learning_rate": 2.1215674174637458e-05,
      "loss": 0.0,
      "step": 93290
    },
    {
      "epoch": 28.787411292810862,
      "grad_norm": 0.001141443382948637,
      "learning_rate": 2.121258870718914e-05,
      "loss": 0.0001,
      "step": 93300
    },
    {
      "epoch": 28.79049676025918,
      "grad_norm": 3.7099516703165136e-06,
      "learning_rate": 2.1209503239740823e-05,
      "loss": 0.0,
      "step": 93310
    },
    {
      "epoch": 28.793582227707496,
      "grad_norm": 2.781381845474243,
      "learning_rate": 2.1206417772292502e-05,
      "loss": 0.005,
      "step": 93320
    },
    {
      "epoch": 28.796667695155815,
      "grad_norm": 0.0015130918473005295,
      "learning_rate": 2.1203332304844185e-05,
      "loss": 0.0,
      "step": 93330
    },
    {
      "epoch": 28.799753162604134,
      "grad_norm": 0.0006476083653979003,
      "learning_rate": 2.1200246837395864e-05,
      "loss": 0.0001,
      "step": 93340
    },
    {
      "epoch": 28.802838630052452,
      "grad_norm": 1.139307005360024e-05,
      "learning_rate": 2.119716136994755e-05,
      "loss": 0.0,
      "step": 93350
    },
    {
      "epoch": 28.80592409750077,
      "grad_norm": 0.0009521030588075519,
      "learning_rate": 2.119407590249923e-05,
      "loss": 0.0,
      "step": 93360
    },
    {
      "epoch": 28.80900956494909,
      "grad_norm": 0.0017669693334028125,
      "learning_rate": 2.119099043505091e-05,
      "loss": 0.0001,
      "step": 93370
    },
    {
      "epoch": 28.81209503239741,
      "grad_norm": 5.324985977495089e-06,
      "learning_rate": 2.1187904967602594e-05,
      "loss": 0.0009,
      "step": 93380
    },
    {
      "epoch": 28.815180499845727,
      "grad_norm": 0.04517350345849991,
      "learning_rate": 2.1184819500154273e-05,
      "loss": 0.0001,
      "step": 93390
    },
    {
      "epoch": 28.818265967294046,
      "grad_norm": 1.9729591608047485,
      "learning_rate": 2.1181734032705955e-05,
      "loss": 0.0011,
      "step": 93400
    },
    {
      "epoch": 28.821351434742365,
      "grad_norm": 7.938999146972492e-07,
      "learning_rate": 2.1178648565257638e-05,
      "loss": 0.0,
      "step": 93410
    },
    {
      "epoch": 28.824436902190683,
      "grad_norm": 0.0007559631485491991,
      "learning_rate": 2.117556309780932e-05,
      "loss": 0.0,
      "step": 93420
    },
    {
      "epoch": 28.827522369639,
      "grad_norm": 0.04119903966784477,
      "learning_rate": 2.1172477630361003e-05,
      "loss": 0.0,
      "step": 93430
    },
    {
      "epoch": 28.830607837087317,
      "grad_norm": 0.01084141805768013,
      "learning_rate": 2.116939216291268e-05,
      "loss": 0.0,
      "step": 93440
    },
    {
      "epoch": 28.833693304535636,
      "grad_norm": 9.08442962099798e-06,
      "learning_rate": 2.1166306695464364e-05,
      "loss": 0.0,
      "step": 93450
    },
    {
      "epoch": 28.836778771983955,
      "grad_norm": 0.008488399907946587,
      "learning_rate": 2.1163221228016043e-05,
      "loss": 0.0001,
      "step": 93460
    },
    {
      "epoch": 28.839864239432274,
      "grad_norm": 0.009178279899060726,
      "learning_rate": 2.1160135760567726e-05,
      "loss": 0.0,
      "step": 93470
    },
    {
      "epoch": 28.842949706880592,
      "grad_norm": 0.004560060333460569,
      "learning_rate": 2.1157050293119408e-05,
      "loss": 0.0,
      "step": 93480
    },
    {
      "epoch": 28.84603517432891,
      "grad_norm": 0.00010840460890904069,
      "learning_rate": 2.115396482567109e-05,
      "loss": 0.0001,
      "step": 93490
    },
    {
      "epoch": 28.84912064177723,
      "grad_norm": 1.2371398210525513,
      "learning_rate": 2.1150879358222773e-05,
      "loss": 0.0005,
      "step": 93500
    },
    {
      "epoch": 28.85220610922555,
      "grad_norm": 8.808556231088005e-06,
      "learning_rate": 2.1147793890774452e-05,
      "loss": 0.0001,
      "step": 93510
    },
    {
      "epoch": 28.855291576673867,
      "grad_norm": 0.0004203735152259469,
      "learning_rate": 2.1144708423326135e-05,
      "loss": 0.0001,
      "step": 93520
    },
    {
      "epoch": 28.858377044122186,
      "grad_norm": 9.490809134149458e-07,
      "learning_rate": 2.1141622955877817e-05,
      "loss": 0.0,
      "step": 93530
    },
    {
      "epoch": 28.861462511570505,
      "grad_norm": 3.5192051939247904e-08,
      "learning_rate": 2.1138537488429496e-05,
      "loss": 0.0001,
      "step": 93540
    },
    {
      "epoch": 28.86454797901882,
      "grad_norm": 0.00629027234390378,
      "learning_rate": 2.1135452020981182e-05,
      "loss": 0.0001,
      "step": 93550
    },
    {
      "epoch": 28.86763344646714,
      "grad_norm": 0.00044415713637135923,
      "learning_rate": 2.113236655353286e-05,
      "loss": 0.0001,
      "step": 93560
    },
    {
      "epoch": 28.870718913915457,
      "grad_norm": 0.00019889220129698515,
      "learning_rate": 2.1129281086084544e-05,
      "loss": 0.0002,
      "step": 93570
    },
    {
      "epoch": 28.873804381363776,
      "grad_norm": 7.634943176526576e-05,
      "learning_rate": 2.1126195618636223e-05,
      "loss": 0.0,
      "step": 93580
    },
    {
      "epoch": 28.876889848812095,
      "grad_norm": 7.159054803196341e-05,
      "learning_rate": 2.1123110151187905e-05,
      "loss": 0.0,
      "step": 93590
    },
    {
      "epoch": 28.879975316260413,
      "grad_norm": 0.0009248313144780695,
      "learning_rate": 2.1120024683739588e-05,
      "loss": 0.0,
      "step": 93600
    },
    {
      "epoch": 28.883060783708732,
      "grad_norm": 4.146963692619465e-05,
      "learning_rate": 2.111693921629127e-05,
      "loss": 0.0059,
      "step": 93610
    },
    {
      "epoch": 28.88614625115705,
      "grad_norm": 5.257533848634921e-05,
      "learning_rate": 2.1113853748842953e-05,
      "loss": 0.0,
      "step": 93620
    },
    {
      "epoch": 28.88923171860537,
      "grad_norm": 4.758524937642505e-06,
      "learning_rate": 2.1110768281394632e-05,
      "loss": 0.0003,
      "step": 93630
    },
    {
      "epoch": 28.89231718605369,
      "grad_norm": 0.00015299681399483234,
      "learning_rate": 2.1107682813946314e-05,
      "loss": 0.0,
      "step": 93640
    },
    {
      "epoch": 28.895402653502007,
      "grad_norm": 2.518836481613107e-05,
      "learning_rate": 2.1104597346497997e-05,
      "loss": 0.0,
      "step": 93650
    },
    {
      "epoch": 28.898488120950326,
      "grad_norm": 0.001048462581820786,
      "learning_rate": 2.1101511879049676e-05,
      "loss": 0.0019,
      "step": 93660
    },
    {
      "epoch": 28.90157358839864,
      "grad_norm": 0.025090500712394714,
      "learning_rate": 2.109842641160136e-05,
      "loss": 0.0,
      "step": 93670
    },
    {
      "epoch": 28.90465905584696,
      "grad_norm": 0.0005259924801066518,
      "learning_rate": 2.109534094415304e-05,
      "loss": 0.0,
      "step": 93680
    },
    {
      "epoch": 28.90774452329528,
      "grad_norm": 0.0019156201742589474,
      "learning_rate": 2.1092255476704723e-05,
      "loss": 0.0,
      "step": 93690
    },
    {
      "epoch": 28.910829990743597,
      "grad_norm": 0.0006866864277981222,
      "learning_rate": 2.1089170009256402e-05,
      "loss": 0.0,
      "step": 93700
    },
    {
      "epoch": 28.913915458191916,
      "grad_norm": 0.00017682902398519218,
      "learning_rate": 2.1086084541808085e-05,
      "loss": 0.0003,
      "step": 93710
    },
    {
      "epoch": 28.917000925640234,
      "grad_norm": 0.00024070424842648208,
      "learning_rate": 2.1082999074359767e-05,
      "loss": 0.0,
      "step": 93720
    },
    {
      "epoch": 28.920086393088553,
      "grad_norm": 9.85538208624348e-05,
      "learning_rate": 2.1079913606911446e-05,
      "loss": 0.0003,
      "step": 93730
    },
    {
      "epoch": 28.923171860536872,
      "grad_norm": 4.1687217162689194e-05,
      "learning_rate": 2.107682813946313e-05,
      "loss": 0.0,
      "step": 93740
    },
    {
      "epoch": 28.92625732798519,
      "grad_norm": 7.019452823442407e-07,
      "learning_rate": 2.107374267201481e-05,
      "loss": 0.0004,
      "step": 93750
    },
    {
      "epoch": 28.92934279543351,
      "grad_norm": 0.00020891833992209285,
      "learning_rate": 2.1070657204566494e-05,
      "loss": 0.0101,
      "step": 93760
    },
    {
      "epoch": 28.932428262881828,
      "grad_norm": 0.035534754395484924,
      "learning_rate": 2.1067571737118176e-05,
      "loss": 0.0001,
      "step": 93770
    },
    {
      "epoch": 28.935513730330143,
      "grad_norm": 0.003544855397194624,
      "learning_rate": 2.1064486269669855e-05,
      "loss": 0.0001,
      "step": 93780
    },
    {
      "epoch": 28.938599197778462,
      "grad_norm": 3.0169551337166922e-06,
      "learning_rate": 2.1061400802221538e-05,
      "loss": 0.0,
      "step": 93790
    },
    {
      "epoch": 28.94168466522678,
      "grad_norm": 3.062844916712493e-05,
      "learning_rate": 2.1058315334773217e-05,
      "loss": 0.0,
      "step": 93800
    },
    {
      "epoch": 28.9447701326751,
      "grad_norm": 2.2527026885654777e-05,
      "learning_rate": 2.1055229867324903e-05,
      "loss": 0.0,
      "step": 93810
    },
    {
      "epoch": 28.947855600123418,
      "grad_norm": 7.840847683837637e-05,
      "learning_rate": 2.1052144399876582e-05,
      "loss": 0.0001,
      "step": 93820
    },
    {
      "epoch": 28.950941067571737,
      "grad_norm": 0.0015784624265506864,
      "learning_rate": 2.1049058932428264e-05,
      "loss": 0.0,
      "step": 93830
    },
    {
      "epoch": 28.954026535020056,
      "grad_norm": 2.156591108359862e-06,
      "learning_rate": 2.1045973464979947e-05,
      "loss": 0.0002,
      "step": 93840
    },
    {
      "epoch": 28.957112002468374,
      "grad_norm": 8.909319859640163e-08,
      "learning_rate": 2.1042887997531626e-05,
      "loss": 0.0,
      "step": 93850
    },
    {
      "epoch": 28.960197469916693,
      "grad_norm": 0.04170318692922592,
      "learning_rate": 2.103980253008331e-05,
      "loss": 0.0001,
      "step": 93860
    },
    {
      "epoch": 28.963282937365012,
      "grad_norm": 0.003118765540421009,
      "learning_rate": 2.1036717062634988e-05,
      "loss": 0.0,
      "step": 93870
    },
    {
      "epoch": 28.96636840481333,
      "grad_norm": 0.4163918197154999,
      "learning_rate": 2.1033631595186673e-05,
      "loss": 0.0001,
      "step": 93880
    },
    {
      "epoch": 28.96945387226165,
      "grad_norm": 0.00033264592639170587,
      "learning_rate": 2.1030546127738356e-05,
      "loss": 0.0,
      "step": 93890
    },
    {
      "epoch": 28.972539339709964,
      "grad_norm": 0.0007025449303910136,
      "learning_rate": 2.1027460660290035e-05,
      "loss": 0.0,
      "step": 93900
    },
    {
      "epoch": 28.975624807158283,
      "grad_norm": 4.204673587082652e-06,
      "learning_rate": 2.1024375192841717e-05,
      "loss": 0.0002,
      "step": 93910
    },
    {
      "epoch": 28.978710274606602,
      "grad_norm": 0.0010227488819509745,
      "learning_rate": 2.1021289725393397e-05,
      "loss": 0.0001,
      "step": 93920
    },
    {
      "epoch": 28.98179574205492,
      "grad_norm": 1.8128025303099093e-08,
      "learning_rate": 2.101820425794508e-05,
      "loss": 0.0,
      "step": 93930
    },
    {
      "epoch": 28.98488120950324,
      "grad_norm": 0.048601675778627396,
      "learning_rate": 2.101511879049676e-05,
      "loss": 0.0,
      "step": 93940
    },
    {
      "epoch": 28.987966676951558,
      "grad_norm": 0.0005439869128167629,
      "learning_rate": 2.1012033323048444e-05,
      "loss": 0.0,
      "step": 93950
    },
    {
      "epoch": 28.991052144399877,
      "grad_norm": 3.125974762951955e-05,
      "learning_rate": 2.1008947855600126e-05,
      "loss": 0.0,
      "step": 93960
    },
    {
      "epoch": 28.994137611848195,
      "grad_norm": 0.0002455230278428644,
      "learning_rate": 2.1005862388151806e-05,
      "loss": 0.0001,
      "step": 93970
    },
    {
      "epoch": 28.997223079296514,
      "grad_norm": 4.272132173355203e-06,
      "learning_rate": 2.1002776920703488e-05,
      "loss": 0.0,
      "step": 93980
    },
    {
      "epoch": 29.0,
      "eval_accuracy_branch1": 0.9999614208693807,
      "eval_accuracy_branch2": 0.4026503862735453,
      "eval_f1_branch1": 0.999932435354904,
      "eval_f1_branch2": 0.3896394561746185,
      "eval_loss": 7.322417513933033e-05,
      "eval_precision_branch1": 0.9999394849743747,
      "eval_precision_branch2": 0.5112874605279474,
      "eval_recall_branch1": 0.9999254138239881,
      "eval_recall_branch2": 0.5077327044935043,
      "eval_runtime": 239.9491,
      "eval_samples_per_second": 432.104,
      "eval_steps_per_second": 54.016,
      "step": 93989
    },
    {
      "epoch": 29.000308546744833,
      "grad_norm": 6.442357971536694e-06,
      "learning_rate": 2.0999691453255167e-05,
      "loss": 0.0001,
      "step": 93990
    },
    {
      "epoch": 29.00339401419315,
      "grad_norm": 2.3978638637345284e-05,
      "learning_rate": 2.099660598580685e-05,
      "loss": 0.0,
      "step": 94000
    },
    {
      "epoch": 29.00647948164147,
      "grad_norm": 6.414773815777153e-05,
      "learning_rate": 2.0993520518358532e-05,
      "loss": 0.0,
      "step": 94010
    },
    {
      "epoch": 29.009564949089786,
      "grad_norm": 1.2853215594077483e-05,
      "learning_rate": 2.0990435050910215e-05,
      "loss": 0.0,
      "step": 94020
    },
    {
      "epoch": 29.012650416538104,
      "grad_norm": 1.8478096990293125e-06,
      "learning_rate": 2.0987349583461897e-05,
      "loss": 0.0008,
      "step": 94030
    },
    {
      "epoch": 29.015735883986423,
      "grad_norm": 0.00038383028004318476,
      "learning_rate": 2.0984264116013576e-05,
      "loss": 0.0004,
      "step": 94040
    },
    {
      "epoch": 29.01882135143474,
      "grad_norm": 0.00015710067236796021,
      "learning_rate": 2.098117864856526e-05,
      "loss": 0.0,
      "step": 94050
    },
    {
      "epoch": 29.02190681888306,
      "grad_norm": 0.00013572080933954567,
      "learning_rate": 2.097809318111694e-05,
      "loss": 0.0,
      "step": 94060
    },
    {
      "epoch": 29.02499228633138,
      "grad_norm": 1.976261019706726,
      "learning_rate": 2.097500771366862e-05,
      "loss": 0.0027,
      "step": 94070
    },
    {
      "epoch": 29.028077753779698,
      "grad_norm": 0.00022695200459565967,
      "learning_rate": 2.0971922246220306e-05,
      "loss": 0.0,
      "step": 94080
    },
    {
      "epoch": 29.031163221228017,
      "grad_norm": 0.008882860653102398,
      "learning_rate": 2.0968836778771985e-05,
      "loss": 0.0001,
      "step": 94090
    },
    {
      "epoch": 29.034248688676335,
      "grad_norm": 0.00010254054359393194,
      "learning_rate": 2.0965751311323668e-05,
      "loss": 0.003,
      "step": 94100
    },
    {
      "epoch": 29.037334156124654,
      "grad_norm": 0.0031313146464526653,
      "learning_rate": 2.0962665843875347e-05,
      "loss": 0.001,
      "step": 94110
    },
    {
      "epoch": 29.040419623572973,
      "grad_norm": 1.376167893409729,
      "learning_rate": 2.095958037642703e-05,
      "loss": 0.0006,
      "step": 94120
    },
    {
      "epoch": 29.043505091021288,
      "grad_norm": 0.00017189742357004434,
      "learning_rate": 2.095649490897871e-05,
      "loss": 0.0,
      "step": 94130
    },
    {
      "epoch": 29.046590558469607,
      "grad_norm": 8.30310964374803e-05,
      "learning_rate": 2.095340944153039e-05,
      "loss": 0.0,
      "step": 94140
    },
    {
      "epoch": 29.049676025917925,
      "grad_norm": 3.322964039398357e-05,
      "learning_rate": 2.0950323974082077e-05,
      "loss": 0.0,
      "step": 94150
    },
    {
      "epoch": 29.052761493366244,
      "grad_norm": 3.3310011531284545e-06,
      "learning_rate": 2.0947238506633756e-05,
      "loss": 0.0087,
      "step": 94160
    },
    {
      "epoch": 29.055846960814563,
      "grad_norm": 0.0001311483356403187,
      "learning_rate": 2.0944153039185438e-05,
      "loss": 0.0,
      "step": 94170
    },
    {
      "epoch": 29.05893242826288,
      "grad_norm": 9.193920959660318e-06,
      "learning_rate": 2.094106757173712e-05,
      "loss": 0.0,
      "step": 94180
    },
    {
      "epoch": 29.0620178957112,
      "grad_norm": 0.01051898580044508,
      "learning_rate": 2.09379821042888e-05,
      "loss": 0.0001,
      "step": 94190
    },
    {
      "epoch": 29.06510336315952,
      "grad_norm": 1.964569128176663e-05,
      "learning_rate": 2.0934896636840482e-05,
      "loss": 0.0,
      "step": 94200
    },
    {
      "epoch": 29.068188830607838,
      "grad_norm": 3.550880137481727e-05,
      "learning_rate": 2.093181116939216e-05,
      "loss": 0.0,
      "step": 94210
    },
    {
      "epoch": 29.071274298056156,
      "grad_norm": 3.50504365087545e-06,
      "learning_rate": 2.0928725701943847e-05,
      "loss": 0.0,
      "step": 94220
    },
    {
      "epoch": 29.074359765504475,
      "grad_norm": 9.98821560642682e-05,
      "learning_rate": 2.0925640234495526e-05,
      "loss": 0.0,
      "step": 94230
    },
    {
      "epoch": 29.077445232952794,
      "grad_norm": 0.0005475140060298145,
      "learning_rate": 2.092255476704721e-05,
      "loss": 0.0008,
      "step": 94240
    },
    {
      "epoch": 29.08053070040111,
      "grad_norm": 0.0020023463293910027,
      "learning_rate": 2.091946929959889e-05,
      "loss": 0.0,
      "step": 94250
    },
    {
      "epoch": 29.083616167849428,
      "grad_norm": 0.0001609230093890801,
      "learning_rate": 2.091638383215057e-05,
      "loss": 0.0025,
      "step": 94260
    },
    {
      "epoch": 29.086701635297747,
      "grad_norm": 0.14698472619056702,
      "learning_rate": 2.0913298364702253e-05,
      "loss": 0.0041,
      "step": 94270
    },
    {
      "epoch": 29.089787102746065,
      "grad_norm": 0.43827036023139954,
      "learning_rate": 2.0910212897253935e-05,
      "loss": 0.0002,
      "step": 94280
    },
    {
      "epoch": 29.092872570194384,
      "grad_norm": 0.006520270835608244,
      "learning_rate": 2.0907127429805618e-05,
      "loss": 0.0004,
      "step": 94290
    },
    {
      "epoch": 29.095958037642703,
      "grad_norm": 0.00011439269292168319,
      "learning_rate": 2.09040419623573e-05,
      "loss": 0.0,
      "step": 94300
    },
    {
      "epoch": 29.09904350509102,
      "grad_norm": 2.2667718440061435e-06,
      "learning_rate": 2.090095649490898e-05,
      "loss": 0.0,
      "step": 94310
    },
    {
      "epoch": 29.10212897253934,
      "grad_norm": 0.002730362582951784,
      "learning_rate": 2.0897871027460662e-05,
      "loss": 0.0002,
      "step": 94320
    },
    {
      "epoch": 29.10521443998766,
      "grad_norm": 0.556094765663147,
      "learning_rate": 2.089478556001234e-05,
      "loss": 0.0014,
      "step": 94330
    },
    {
      "epoch": 29.108299907435978,
      "grad_norm": 0.006385429762303829,
      "learning_rate": 2.0891700092564023e-05,
      "loss": 0.0001,
      "step": 94340
    },
    {
      "epoch": 29.111385374884296,
      "grad_norm": 0.025075290352106094,
      "learning_rate": 2.0888614625115706e-05,
      "loss": 0.0059,
      "step": 94350
    },
    {
      "epoch": 29.114470842332615,
      "grad_norm": 3.116942082215246e-07,
      "learning_rate": 2.0885529157667388e-05,
      "loss": 0.0011,
      "step": 94360
    },
    {
      "epoch": 29.11755630978093,
      "grad_norm": 5.510025584953837e-05,
      "learning_rate": 2.088244369021907e-05,
      "loss": 0.0007,
      "step": 94370
    },
    {
      "epoch": 29.12064177722925,
      "grad_norm": 3.561643825378269e-05,
      "learning_rate": 2.087935822277075e-05,
      "loss": 0.0011,
      "step": 94380
    },
    {
      "epoch": 29.123727244677568,
      "grad_norm": 2.5267968339903746e-06,
      "learning_rate": 2.0876272755322432e-05,
      "loss": 0.0,
      "step": 94390
    },
    {
      "epoch": 29.126812712125886,
      "grad_norm": 0.0036849146708846092,
      "learning_rate": 2.087318728787411e-05,
      "loss": 0.0004,
      "step": 94400
    },
    {
      "epoch": 29.129898179574205,
      "grad_norm": 0.004404284060001373,
      "learning_rate": 2.0870101820425794e-05,
      "loss": 0.0005,
      "step": 94410
    },
    {
      "epoch": 29.132983647022524,
      "grad_norm": 0.0005096539971418679,
      "learning_rate": 2.086701635297748e-05,
      "loss": 0.0035,
      "step": 94420
    },
    {
      "epoch": 29.136069114470843,
      "grad_norm": 0.05314948037266731,
      "learning_rate": 2.086393088552916e-05,
      "loss": 0.0045,
      "step": 94430
    },
    {
      "epoch": 29.13915458191916,
      "grad_norm": 0.00016114705067593604,
      "learning_rate": 2.086084541808084e-05,
      "loss": 0.0001,
      "step": 94440
    },
    {
      "epoch": 29.14224004936748,
      "grad_norm": 0.034699417650699615,
      "learning_rate": 2.085775995063252e-05,
      "loss": 0.0001,
      "step": 94450
    },
    {
      "epoch": 29.1453255168158,
      "grad_norm": 2.4819798909447854e-06,
      "learning_rate": 2.0854674483184203e-05,
      "loss": 0.0,
      "step": 94460
    },
    {
      "epoch": 29.148410984264117,
      "grad_norm": 0.00011678199371090159,
      "learning_rate": 2.0851589015735885e-05,
      "loss": 0.0,
      "step": 94470
    },
    {
      "epoch": 29.151496451712433,
      "grad_norm": 4.598118903231807e-05,
      "learning_rate": 2.0848503548287568e-05,
      "loss": 0.0035,
      "step": 94480
    },
    {
      "epoch": 29.15458191916075,
      "grad_norm": 0.0009800979169085622,
      "learning_rate": 2.084541808083925e-05,
      "loss": 0.0003,
      "step": 94490
    },
    {
      "epoch": 29.15766738660907,
      "grad_norm": 0.0016237045638263226,
      "learning_rate": 2.084233261339093e-05,
      "loss": 0.0,
      "step": 94500
    },
    {
      "epoch": 29.16075285405739,
      "grad_norm": 3.345486766193062e-05,
      "learning_rate": 2.0839247145942612e-05,
      "loss": 0.0,
      "step": 94510
    },
    {
      "epoch": 29.163838321505708,
      "grad_norm": 0.0009807936148718,
      "learning_rate": 2.083616167849429e-05,
      "loss": 0.0002,
      "step": 94520
    },
    {
      "epoch": 29.166923788954026,
      "grad_norm": 4.707358584710164e-06,
      "learning_rate": 2.0833076211045973e-05,
      "loss": 0.0001,
      "step": 94530
    },
    {
      "epoch": 29.170009256402345,
      "grad_norm": 0.019283873960375786,
      "learning_rate": 2.0829990743597656e-05,
      "loss": 0.0,
      "step": 94540
    },
    {
      "epoch": 29.173094723850664,
      "grad_norm": 6.950679380679503e-05,
      "learning_rate": 2.082690527614934e-05,
      "loss": 0.0,
      "step": 94550
    },
    {
      "epoch": 29.176180191298982,
      "grad_norm": 0.0006001335568726063,
      "learning_rate": 2.082381980870102e-05,
      "loss": 0.0001,
      "step": 94560
    },
    {
      "epoch": 29.1792656587473,
      "grad_norm": 3.3807040722422244e-08,
      "learning_rate": 2.08207343412527e-05,
      "loss": 0.0001,
      "step": 94570
    },
    {
      "epoch": 29.18235112619562,
      "grad_norm": 0.0012670247815549374,
      "learning_rate": 2.0817648873804382e-05,
      "loss": 0.001,
      "step": 94580
    },
    {
      "epoch": 29.18543659364394,
      "grad_norm": 1.2914160834043287e-06,
      "learning_rate": 2.0814563406356065e-05,
      "loss": 0.0001,
      "step": 94590
    },
    {
      "epoch": 29.188522061092254,
      "grad_norm": 0.019819196313619614,
      "learning_rate": 2.0811477938907744e-05,
      "loss": 0.0,
      "step": 94600
    },
    {
      "epoch": 29.191607528540573,
      "grad_norm": 0.0004873740836046636,
      "learning_rate": 2.0808392471459426e-05,
      "loss": 0.0,
      "step": 94610
    },
    {
      "epoch": 29.19469299598889,
      "grad_norm": 1.835763396229595e-05,
      "learning_rate": 2.080530700401111e-05,
      "loss": 0.0,
      "step": 94620
    },
    {
      "epoch": 29.19777846343721,
      "grad_norm": 0.0005228758091107011,
      "learning_rate": 2.080222153656279e-05,
      "loss": 0.0,
      "step": 94630
    },
    {
      "epoch": 29.20086393088553,
      "grad_norm": 0.12703432142734528,
      "learning_rate": 2.079913606911447e-05,
      "loss": 0.0001,
      "step": 94640
    },
    {
      "epoch": 29.203949398333847,
      "grad_norm": 0.0011870410526171327,
      "learning_rate": 2.0796050601666153e-05,
      "loss": 0.0008,
      "step": 94650
    },
    {
      "epoch": 29.207034865782166,
      "grad_norm": 0.0004236434760969132,
      "learning_rate": 2.0792965134217835e-05,
      "loss": 0.0002,
      "step": 94660
    },
    {
      "epoch": 29.210120333230485,
      "grad_norm": 0.006638491991907358,
      "learning_rate": 2.0789879666769515e-05,
      "loss": 0.0006,
      "step": 94670
    },
    {
      "epoch": 29.213205800678804,
      "grad_norm": 0.0005529065965674818,
      "learning_rate": 2.07867941993212e-05,
      "loss": 0.0,
      "step": 94680
    },
    {
      "epoch": 29.216291268127122,
      "grad_norm": 0.22163471579551697,
      "learning_rate": 2.078370873187288e-05,
      "loss": 0.0013,
      "step": 94690
    },
    {
      "epoch": 29.21937673557544,
      "grad_norm": 0.49010658264160156,
      "learning_rate": 2.0780623264424562e-05,
      "loss": 0.0005,
      "step": 94700
    },
    {
      "epoch": 29.22246220302376,
      "grad_norm": 0.010255352593958378,
      "learning_rate": 2.0777537796976244e-05,
      "loss": 0.0,
      "step": 94710
    },
    {
      "epoch": 29.225547670472075,
      "grad_norm": 0.000490708916913718,
      "learning_rate": 2.0774452329527924e-05,
      "loss": 0.0007,
      "step": 94720
    },
    {
      "epoch": 29.228633137920394,
      "grad_norm": 0.0002150803484255448,
      "learning_rate": 2.0771366862079606e-05,
      "loss": 0.0,
      "step": 94730
    },
    {
      "epoch": 29.231718605368712,
      "grad_norm": 0.00020191300427541137,
      "learning_rate": 2.0768281394631285e-05,
      "loss": 0.0,
      "step": 94740
    },
    {
      "epoch": 29.23480407281703,
      "grad_norm": 0.00028072684654034674,
      "learning_rate": 2.076519592718297e-05,
      "loss": 0.0,
      "step": 94750
    },
    {
      "epoch": 29.23788954026535,
      "grad_norm": 1.2982588941667927e-06,
      "learning_rate": 2.076211045973465e-05,
      "loss": 0.0,
      "step": 94760
    },
    {
      "epoch": 29.24097500771367,
      "grad_norm": 0.00020182730804663152,
      "learning_rate": 2.0759024992286333e-05,
      "loss": 0.0,
      "step": 94770
    },
    {
      "epoch": 29.244060475161987,
      "grad_norm": 4.356499994173646e-05,
      "learning_rate": 2.0755939524838015e-05,
      "loss": 0.0,
      "step": 94780
    },
    {
      "epoch": 29.247145942610306,
      "grad_norm": 0.21505706012248993,
      "learning_rate": 2.0752854057389694e-05,
      "loss": 0.0001,
      "step": 94790
    },
    {
      "epoch": 29.250231410058625,
      "grad_norm": 3.4433542168699205e-05,
      "learning_rate": 2.0749768589941377e-05,
      "loss": 0.0,
      "step": 94800
    },
    {
      "epoch": 29.253316877506943,
      "grad_norm": 3.3413918572477996e-05,
      "learning_rate": 2.074668312249306e-05,
      "loss": 0.0005,
      "step": 94810
    },
    {
      "epoch": 29.256402344955262,
      "grad_norm": 0.01839173585176468,
      "learning_rate": 2.074359765504474e-05,
      "loss": 0.0022,
      "step": 94820
    },
    {
      "epoch": 29.25948781240358,
      "grad_norm": 0.0022181638050824404,
      "learning_rate": 2.0740512187596424e-05,
      "loss": 0.0,
      "step": 94830
    },
    {
      "epoch": 29.262573279851896,
      "grad_norm": 2.355429614908644e-06,
      "learning_rate": 2.0737426720148103e-05,
      "loss": 0.0001,
      "step": 94840
    },
    {
      "epoch": 29.265658747300215,
      "grad_norm": 3.1952486096997745e-06,
      "learning_rate": 2.0734341252699786e-05,
      "loss": 0.0,
      "step": 94850
    },
    {
      "epoch": 29.268744214748533,
      "grad_norm": 1.4130977433524095e-05,
      "learning_rate": 2.0731255785251465e-05,
      "loss": 0.0,
      "step": 94860
    },
    {
      "epoch": 29.271829682196852,
      "grad_norm": 0.0002940213307738304,
      "learning_rate": 2.0728170317803147e-05,
      "loss": 0.0,
      "step": 94870
    },
    {
      "epoch": 29.27491514964517,
      "grad_norm": 9.859200508799404e-05,
      "learning_rate": 2.072508485035483e-05,
      "loss": 0.0,
      "step": 94880
    },
    {
      "epoch": 29.27800061709349,
      "grad_norm": 1.384801748827158e-06,
      "learning_rate": 2.0721999382906512e-05,
      "loss": 0.0,
      "step": 94890
    },
    {
      "epoch": 29.28108608454181,
      "grad_norm": 0.009832140058279037,
      "learning_rate": 2.0718913915458195e-05,
      "loss": 0.0001,
      "step": 94900
    },
    {
      "epoch": 29.284171551990127,
      "grad_norm": 0.001058276742696762,
      "learning_rate": 2.0715828448009874e-05,
      "loss": 0.0002,
      "step": 94910
    },
    {
      "epoch": 29.287257019438446,
      "grad_norm": 9.735876119520981e-06,
      "learning_rate": 2.0712742980561556e-05,
      "loss": 0.0,
      "step": 94920
    },
    {
      "epoch": 29.290342486886765,
      "grad_norm": 0.001366291893646121,
      "learning_rate": 2.070965751311324e-05,
      "loss": 0.0,
      "step": 94930
    },
    {
      "epoch": 29.293427954335083,
      "grad_norm": 6.128670793259516e-05,
      "learning_rate": 2.0706572045664918e-05,
      "loss": 0.0001,
      "step": 94940
    },
    {
      "epoch": 29.2965134217834,
      "grad_norm": 0.019808705896139145,
      "learning_rate": 2.0703486578216604e-05,
      "loss": 0.0004,
      "step": 94950
    },
    {
      "epoch": 29.299598889231717,
      "grad_norm": 2.8740620109601878e-05,
      "learning_rate": 2.0700401110768283e-05,
      "loss": 0.0,
      "step": 94960
    },
    {
      "epoch": 29.302684356680036,
      "grad_norm": 0.00039634667336940765,
      "learning_rate": 2.0697315643319965e-05,
      "loss": 0.0002,
      "step": 94970
    },
    {
      "epoch": 29.305769824128355,
      "grad_norm": 5.831099770148285e-06,
      "learning_rate": 2.0694230175871644e-05,
      "loss": 0.0,
      "step": 94980
    },
    {
      "epoch": 29.308855291576673,
      "grad_norm": 1.873906330729369e-05,
      "learning_rate": 2.0691144708423327e-05,
      "loss": 0.0122,
      "step": 94990
    },
    {
      "epoch": 29.311940759024992,
      "grad_norm": 0.0046928380616009235,
      "learning_rate": 2.068805924097501e-05,
      "loss": 0.0001,
      "step": 95000
    },
    {
      "epoch": 29.31502622647331,
      "grad_norm": 1.5782994523760863e-05,
      "learning_rate": 2.0684973773526688e-05,
      "loss": 0.0014,
      "step": 95010
    },
    {
      "epoch": 29.31811169392163,
      "grad_norm": 0.00010240155825158581,
      "learning_rate": 2.0681888306078374e-05,
      "loss": 0.0,
      "step": 95020
    },
    {
      "epoch": 29.32119716136995,
      "grad_norm": 0.005751952063292265,
      "learning_rate": 2.0678802838630053e-05,
      "loss": 0.0063,
      "step": 95030
    },
    {
      "epoch": 29.324282628818267,
      "grad_norm": 0.04380814731121063,
      "learning_rate": 2.0675717371181736e-05,
      "loss": 0.0,
      "step": 95040
    },
    {
      "epoch": 29.327368096266586,
      "grad_norm": 0.0013652712805196643,
      "learning_rate": 2.0672631903733418e-05,
      "loss": 0.0029,
      "step": 95050
    },
    {
      "epoch": 29.330453563714904,
      "grad_norm": 0.0005486116278916597,
      "learning_rate": 2.0669546436285097e-05,
      "loss": 0.0001,
      "step": 95060
    },
    {
      "epoch": 29.33353903116322,
      "grad_norm": 1.6899401089176536e-05,
      "learning_rate": 2.066646096883678e-05,
      "loss": 0.0,
      "step": 95070
    },
    {
      "epoch": 29.33662449861154,
      "grad_norm": 0.010470564477145672,
      "learning_rate": 2.066337550138846e-05,
      "loss": 0.0005,
      "step": 95080
    },
    {
      "epoch": 29.339709966059857,
      "grad_norm": 8.08035911177285e-05,
      "learning_rate": 2.0660290033940145e-05,
      "loss": 0.0009,
      "step": 95090
    },
    {
      "epoch": 29.342795433508176,
      "grad_norm": 0.07770373672246933,
      "learning_rate": 2.0657204566491824e-05,
      "loss": 0.0,
      "step": 95100
    },
    {
      "epoch": 29.345880900956494,
      "grad_norm": 0.0019919394981116056,
      "learning_rate": 2.0654119099043506e-05,
      "loss": 0.0001,
      "step": 95110
    },
    {
      "epoch": 29.348966368404813,
      "grad_norm": 2.30617279157741e-05,
      "learning_rate": 2.065103363159519e-05,
      "loss": 0.0,
      "step": 95120
    },
    {
      "epoch": 29.352051835853132,
      "grad_norm": 3.649023028629017e-06,
      "learning_rate": 2.0647948164146868e-05,
      "loss": 0.0,
      "step": 95130
    },
    {
      "epoch": 29.35513730330145,
      "grad_norm": 5.274028353596805e-06,
      "learning_rate": 2.064486269669855e-05,
      "loss": 0.0,
      "step": 95140
    },
    {
      "epoch": 29.35822277074977,
      "grad_norm": 0.0017186303157359362,
      "learning_rate": 2.0641777229250233e-05,
      "loss": 0.0,
      "step": 95150
    },
    {
      "epoch": 29.361308238198088,
      "grad_norm": 0.001499597798101604,
      "learning_rate": 2.0638691761801915e-05,
      "loss": 0.0,
      "step": 95160
    },
    {
      "epoch": 29.364393705646407,
      "grad_norm": 8.93124524736777e-06,
      "learning_rate": 2.0635606294353598e-05,
      "loss": 0.0,
      "step": 95170
    },
    {
      "epoch": 29.367479173094726,
      "grad_norm": 0.00256156618706882,
      "learning_rate": 2.0632520826905277e-05,
      "loss": 0.0,
      "step": 95180
    },
    {
      "epoch": 29.37056464054304,
      "grad_norm": 0.010860622860491276,
      "learning_rate": 2.062943535945696e-05,
      "loss": 0.0035,
      "step": 95190
    },
    {
      "epoch": 29.37365010799136,
      "grad_norm": 0.15725074708461761,
      "learning_rate": 2.062634989200864e-05,
      "loss": 0.0001,
      "step": 95200
    },
    {
      "epoch": 29.376735575439678,
      "grad_norm": 2.5341691070934758e-05,
      "learning_rate": 2.062326442456032e-05,
      "loss": 0.0003,
      "step": 95210
    },
    {
      "epoch": 29.379821042887997,
      "grad_norm": 0.06170012056827545,
      "learning_rate": 2.0620178957112003e-05,
      "loss": 0.0,
      "step": 95220
    },
    {
      "epoch": 29.382906510336316,
      "grad_norm": 8.744228580326308e-06,
      "learning_rate": 2.0617093489663686e-05,
      "loss": 0.0,
      "step": 95230
    },
    {
      "epoch": 29.385991977784634,
      "grad_norm": 0.003945658914744854,
      "learning_rate": 2.0614008022215368e-05,
      "loss": 0.0,
      "step": 95240
    },
    {
      "epoch": 29.389077445232953,
      "grad_norm": 1.6705626249313354,
      "learning_rate": 2.0610922554767047e-05,
      "loss": 0.0024,
      "step": 95250
    },
    {
      "epoch": 29.392162912681272,
      "grad_norm": 0.008338849060237408,
      "learning_rate": 2.060783708731873e-05,
      "loss": 0.0001,
      "step": 95260
    },
    {
      "epoch": 29.39524838012959,
      "grad_norm": 0.00466184364631772,
      "learning_rate": 2.060475161987041e-05,
      "loss": 0.0,
      "step": 95270
    },
    {
      "epoch": 29.39833384757791,
      "grad_norm": 0.0015831870259717107,
      "learning_rate": 2.060166615242209e-05,
      "loss": 0.0,
      "step": 95280
    },
    {
      "epoch": 29.401419315026228,
      "grad_norm": 0.08914539963006973,
      "learning_rate": 2.0598580684973774e-05,
      "loss": 0.0005,
      "step": 95290
    },
    {
      "epoch": 29.404504782474547,
      "grad_norm": 0.000529340235516429,
      "learning_rate": 2.0595495217525456e-05,
      "loss": 0.0009,
      "step": 95300
    },
    {
      "epoch": 29.407590249922862,
      "grad_norm": 9.902362216962501e-05,
      "learning_rate": 2.059240975007714e-05,
      "loss": 0.0,
      "step": 95310
    },
    {
      "epoch": 29.41067571737118,
      "grad_norm": 0.0001823076599976048,
      "learning_rate": 2.0589324282628818e-05,
      "loss": 0.0,
      "step": 95320
    },
    {
      "epoch": 29.4137611848195,
      "grad_norm": 1.0359040061302949e-06,
      "learning_rate": 2.05862388151805e-05,
      "loss": 0.0,
      "step": 95330
    },
    {
      "epoch": 29.416846652267818,
      "grad_norm": 0.00022992753656581044,
      "learning_rate": 2.0583153347732183e-05,
      "loss": 0.0,
      "step": 95340
    },
    {
      "epoch": 29.419932119716137,
      "grad_norm": 1.3499932720151264e-05,
      "learning_rate": 2.0580067880283865e-05,
      "loss": 0.0,
      "step": 95350
    },
    {
      "epoch": 29.423017587164455,
      "grad_norm": 0.0003064636548515409,
      "learning_rate": 2.0576982412835548e-05,
      "loss": 0.0001,
      "step": 95360
    },
    {
      "epoch": 29.426103054612774,
      "grad_norm": 6.5051443698394e-07,
      "learning_rate": 2.0573896945387227e-05,
      "loss": 0.0,
      "step": 95370
    },
    {
      "epoch": 29.429188522061093,
      "grad_norm": 1.0250274499412626e-05,
      "learning_rate": 2.057081147793891e-05,
      "loss": 0.0,
      "step": 95380
    },
    {
      "epoch": 29.43227398950941,
      "grad_norm": 0.0003057770663872361,
      "learning_rate": 2.056772601049059e-05,
      "loss": 0.0001,
      "step": 95390
    },
    {
      "epoch": 29.43535945695773,
      "grad_norm": 6.125777872512117e-06,
      "learning_rate": 2.056464054304227e-05,
      "loss": 0.0,
      "step": 95400
    },
    {
      "epoch": 29.43844492440605,
      "grad_norm": 0.0016195917269214988,
      "learning_rate": 2.0561555075593953e-05,
      "loss": 0.0,
      "step": 95410
    },
    {
      "epoch": 29.441530391854364,
      "grad_norm": 0.2801109254360199,
      "learning_rate": 2.0558469608145636e-05,
      "loss": 0.001,
      "step": 95420
    },
    {
      "epoch": 29.444615859302683,
      "grad_norm": 4.187762533547357e-05,
      "learning_rate": 2.055538414069732e-05,
      "loss": 0.0001,
      "step": 95430
    },
    {
      "epoch": 29.447701326751,
      "grad_norm": 2.3961216356838122e-05,
      "learning_rate": 2.0552298673248997e-05,
      "loss": 0.0,
      "step": 95440
    },
    {
      "epoch": 29.45078679419932,
      "grad_norm": 4.0261838876176625e-05,
      "learning_rate": 2.054921320580068e-05,
      "loss": 0.0,
      "step": 95450
    },
    {
      "epoch": 29.45387226164764,
      "grad_norm": 0.00016560310905333608,
      "learning_rate": 2.0546127738352362e-05,
      "loss": 0.0,
      "step": 95460
    },
    {
      "epoch": 29.456957729095958,
      "grad_norm": 1.9718567273230292e-05,
      "learning_rate": 2.054304227090404e-05,
      "loss": 0.0,
      "step": 95470
    },
    {
      "epoch": 29.460043196544277,
      "grad_norm": 5.013540430809371e-05,
      "learning_rate": 2.0539956803455724e-05,
      "loss": 0.0,
      "step": 95480
    },
    {
      "epoch": 29.463128663992595,
      "grad_norm": 0.002375091891735792,
      "learning_rate": 2.0536871336007406e-05,
      "loss": 0.0,
      "step": 95490
    },
    {
      "epoch": 29.466214131440914,
      "grad_norm": 4.861084744334221e-05,
      "learning_rate": 2.053378586855909e-05,
      "loss": 0.0,
      "step": 95500
    },
    {
      "epoch": 29.469299598889233,
      "grad_norm": 0.001363673945888877,
      "learning_rate": 2.0530700401110768e-05,
      "loss": 0.0016,
      "step": 95510
    },
    {
      "epoch": 29.47238506633755,
      "grad_norm": 1.281588652091159e-06,
      "learning_rate": 2.052761493366245e-05,
      "loss": 0.0028,
      "step": 95520
    },
    {
      "epoch": 29.47547053378587,
      "grad_norm": 4.725464168586768e-05,
      "learning_rate": 2.0524529466214133e-05,
      "loss": 0.0,
      "step": 95530
    },
    {
      "epoch": 29.478556001234185,
      "grad_norm": 0.013253683224320412,
      "learning_rate": 2.0521443998765812e-05,
      "loss": 0.0004,
      "step": 95540
    },
    {
      "epoch": 29.481641468682504,
      "grad_norm": 0.0122883515432477,
      "learning_rate": 2.0518358531317498e-05,
      "loss": 0.0001,
      "step": 95550
    },
    {
      "epoch": 29.484726936130823,
      "grad_norm": 5.010806489735842e-07,
      "learning_rate": 2.0515273063869177e-05,
      "loss": 0.0,
      "step": 95560
    },
    {
      "epoch": 29.48781240357914,
      "grad_norm": 0.005563995335251093,
      "learning_rate": 2.051218759642086e-05,
      "loss": 0.0,
      "step": 95570
    },
    {
      "epoch": 29.49089787102746,
      "grad_norm": 3.6607034417102113e-06,
      "learning_rate": 2.0509102128972542e-05,
      "loss": 0.0002,
      "step": 95580
    },
    {
      "epoch": 29.49398333847578,
      "grad_norm": 0.13722160458564758,
      "learning_rate": 2.050601666152422e-05,
      "loss": 0.0001,
      "step": 95590
    },
    {
      "epoch": 29.497068805924098,
      "grad_norm": 0.031531527638435364,
      "learning_rate": 2.0502931194075904e-05,
      "loss": 0.0024,
      "step": 95600
    },
    {
      "epoch": 29.500154273372416,
      "grad_norm": 1.7793133793020388e-06,
      "learning_rate": 2.0499845726627583e-05,
      "loss": 0.0004,
      "step": 95610
    },
    {
      "epoch": 29.503239740820735,
      "grad_norm": 0.00028963061049580574,
      "learning_rate": 2.049676025917927e-05,
      "loss": 0.0,
      "step": 95620
    },
    {
      "epoch": 29.506325208269054,
      "grad_norm": 4.523575626080856e-06,
      "learning_rate": 2.0493674791730948e-05,
      "loss": 0.0002,
      "step": 95630
    },
    {
      "epoch": 29.509410675717373,
      "grad_norm": 0.0002511054335627705,
      "learning_rate": 2.049058932428263e-05,
      "loss": 0.0,
      "step": 95640
    },
    {
      "epoch": 29.51249614316569,
      "grad_norm": 0.20684118568897247,
      "learning_rate": 2.0487503856834313e-05,
      "loss": 0.0001,
      "step": 95650
    },
    {
      "epoch": 29.515581610614007,
      "grad_norm": 4.172170520178042e-06,
      "learning_rate": 2.048441838938599e-05,
      "loss": 0.0,
      "step": 95660
    },
    {
      "epoch": 29.518667078062325,
      "grad_norm": 1.728715687931981e-05,
      "learning_rate": 2.0481332921937674e-05,
      "loss": 0.0,
      "step": 95670
    },
    {
      "epoch": 29.521752545510644,
      "grad_norm": 0.0001986651332117617,
      "learning_rate": 2.0478247454489353e-05,
      "loss": 0.0001,
      "step": 95680
    },
    {
      "epoch": 29.524838012958963,
      "grad_norm": 9.806852858673665e-07,
      "learning_rate": 2.047516198704104e-05,
      "loss": 0.0,
      "step": 95690
    },
    {
      "epoch": 29.52792348040728,
      "grad_norm": 3.6843935049546417e-06,
      "learning_rate": 2.047207651959272e-05,
      "loss": 0.0009,
      "step": 95700
    },
    {
      "epoch": 29.5310089478556,
      "grad_norm": 0.909927487373352,
      "learning_rate": 2.04689910521444e-05,
      "loss": 0.0052,
      "step": 95710
    },
    {
      "epoch": 29.53409441530392,
      "grad_norm": 7.665009434276726e-06,
      "learning_rate": 2.0465905584696083e-05,
      "loss": 0.0001,
      "step": 95720
    },
    {
      "epoch": 29.537179882752238,
      "grad_norm": 0.0001730102812871337,
      "learning_rate": 2.0462820117247762e-05,
      "loss": 0.0052,
      "step": 95730
    },
    {
      "epoch": 29.540265350200556,
      "grad_norm": 0.4707816541194916,
      "learning_rate": 2.0459734649799445e-05,
      "loss": 0.0006,
      "step": 95740
    },
    {
      "epoch": 29.543350817648875,
      "grad_norm": 0.00033038665424101055,
      "learning_rate": 2.0456649182351127e-05,
      "loss": 0.0027,
      "step": 95750
    },
    {
      "epoch": 29.546436285097194,
      "grad_norm": 0.08660443872213364,
      "learning_rate": 2.045356371490281e-05,
      "loss": 0.0017,
      "step": 95760
    },
    {
      "epoch": 29.54952175254551,
      "grad_norm": 0.00046254650806076825,
      "learning_rate": 2.0450478247454492e-05,
      "loss": 0.0,
      "step": 95770
    },
    {
      "epoch": 29.552607219993828,
      "grad_norm": 1.8489854483050294e-05,
      "learning_rate": 2.044739278000617e-05,
      "loss": 0.0005,
      "step": 95780
    },
    {
      "epoch": 29.555692687442146,
      "grad_norm": 0.00017932808259502053,
      "learning_rate": 2.0444307312557854e-05,
      "loss": 0.0,
      "step": 95790
    },
    {
      "epoch": 29.558778154890465,
      "grad_norm": 0.2026737481355667,
      "learning_rate": 2.0441221845109533e-05,
      "loss": 0.0001,
      "step": 95800
    },
    {
      "epoch": 29.561863622338784,
      "grad_norm": 9.578370736562647e-06,
      "learning_rate": 2.0438136377661215e-05,
      "loss": 0.0,
      "step": 95810
    },
    {
      "epoch": 29.564949089787103,
      "grad_norm": 6.729274900862947e-06,
      "learning_rate": 2.04350509102129e-05,
      "loss": 0.0,
      "step": 95820
    },
    {
      "epoch": 29.56803455723542,
      "grad_norm": 0.5043988823890686,
      "learning_rate": 2.043196544276458e-05,
      "loss": 0.0002,
      "step": 95830
    },
    {
      "epoch": 29.57112002468374,
      "grad_norm": 3.96370051021222e-05,
      "learning_rate": 2.0428879975316263e-05,
      "loss": 0.0,
      "step": 95840
    },
    {
      "epoch": 29.57420549213206,
      "grad_norm": 0.002770386403426528,
      "learning_rate": 2.0425794507867942e-05,
      "loss": 0.0002,
      "step": 95850
    },
    {
      "epoch": 29.577290959580377,
      "grad_norm": 1.751096533553209e-05,
      "learning_rate": 2.0422709040419624e-05,
      "loss": 0.0,
      "step": 95860
    },
    {
      "epoch": 29.580376427028696,
      "grad_norm": 0.03156663104891777,
      "learning_rate": 2.0419623572971307e-05,
      "loss": 0.0,
      "step": 95870
    },
    {
      "epoch": 29.583461894477015,
      "grad_norm": 0.00012077161227352917,
      "learning_rate": 2.0416538105522986e-05,
      "loss": 0.0,
      "step": 95880
    },
    {
      "epoch": 29.58654736192533,
      "grad_norm": 0.00015871439245529473,
      "learning_rate": 2.041345263807467e-05,
      "loss": 0.0,
      "step": 95890
    },
    {
      "epoch": 29.58963282937365,
      "grad_norm": 0.012008694000542164,
      "learning_rate": 2.041036717062635e-05,
      "loss": 0.0001,
      "step": 95900
    },
    {
      "epoch": 29.592718296821968,
      "grad_norm": 0.00015115152928046882,
      "learning_rate": 2.0407281703178033e-05,
      "loss": 0.0003,
      "step": 95910
    },
    {
      "epoch": 29.595803764270286,
      "grad_norm": 1.2604380572156515e-05,
      "learning_rate": 2.0404196235729712e-05,
      "loss": 0.0,
      "step": 95920
    },
    {
      "epoch": 29.598889231718605,
      "grad_norm": 3.125074726995081e-05,
      "learning_rate": 2.0401110768281395e-05,
      "loss": 0.0014,
      "step": 95930
    },
    {
      "epoch": 29.601974699166924,
      "grad_norm": 0.0019435971044003963,
      "learning_rate": 2.0398025300833077e-05,
      "loss": 0.0,
      "step": 95940
    },
    {
      "epoch": 29.605060166615242,
      "grad_norm": 2.553589411036228e-06,
      "learning_rate": 2.0394939833384756e-05,
      "loss": 0.0,
      "step": 95950
    },
    {
      "epoch": 29.60814563406356,
      "grad_norm": 0.0024073109962046146,
      "learning_rate": 2.0391854365936442e-05,
      "loss": 0.0002,
      "step": 95960
    },
    {
      "epoch": 29.61123110151188,
      "grad_norm": 0.0002808496356010437,
      "learning_rate": 2.038876889848812e-05,
      "loss": 0.0001,
      "step": 95970
    },
    {
      "epoch": 29.6143165689602,
      "grad_norm": 0.0006587763782590628,
      "learning_rate": 2.0385683431039804e-05,
      "loss": 0.0,
      "step": 95980
    },
    {
      "epoch": 29.617402036408517,
      "grad_norm": 4.5301720092538744e-05,
      "learning_rate": 2.0382597963591486e-05,
      "loss": 0.0,
      "step": 95990
    },
    {
      "epoch": 29.620487503856836,
      "grad_norm": 2.960123310913332e-07,
      "learning_rate": 2.0379512496143165e-05,
      "loss": 0.0001,
      "step": 96000
    },
    {
      "epoch": 29.62357297130515,
      "grad_norm": 8.223943268603762e-07,
      "learning_rate": 2.0376427028694848e-05,
      "loss": 0.0,
      "step": 96010
    },
    {
      "epoch": 29.62665843875347,
      "grad_norm": 1.4237211871659383e-05,
      "learning_rate": 2.037334156124653e-05,
      "loss": 0.0,
      "step": 96020
    },
    {
      "epoch": 29.62974390620179,
      "grad_norm": 2.1348332666093484e-05,
      "learning_rate": 2.0370256093798213e-05,
      "loss": 0.0,
      "step": 96030
    },
    {
      "epoch": 29.632829373650107,
      "grad_norm": 1.877550130302552e-05,
      "learning_rate": 2.0367170626349892e-05,
      "loss": 0.0,
      "step": 96040
    },
    {
      "epoch": 29.635914841098426,
      "grad_norm": 0.0022129334975034,
      "learning_rate": 2.0364085158901574e-05,
      "loss": 0.0047,
      "step": 96050
    },
    {
      "epoch": 29.639000308546745,
      "grad_norm": 1.6539934222237207e-05,
      "learning_rate": 2.0360999691453257e-05,
      "loss": 0.0001,
      "step": 96060
    },
    {
      "epoch": 29.642085775995064,
      "grad_norm": 0.00653474684804678,
      "learning_rate": 2.0357914224004936e-05,
      "loss": 0.0001,
      "step": 96070
    },
    {
      "epoch": 29.645171243443382,
      "grad_norm": 0.8267828226089478,
      "learning_rate": 2.035482875655662e-05,
      "loss": 0.0004,
      "step": 96080
    },
    {
      "epoch": 29.6482567108917,
      "grad_norm": 7.287275820999639e-06,
      "learning_rate": 2.03517432891083e-05,
      "loss": 0.0,
      "step": 96090
    },
    {
      "epoch": 29.65134217834002,
      "grad_norm": 1.7772582623365452e-06,
      "learning_rate": 2.0348657821659983e-05,
      "loss": 0.0001,
      "step": 96100
    },
    {
      "epoch": 29.65442764578834,
      "grad_norm": 3.1272393243853003e-06,
      "learning_rate": 2.0345572354211666e-05,
      "loss": 0.0,
      "step": 96110
    },
    {
      "epoch": 29.657513113236654,
      "grad_norm": 0.1919584721326828,
      "learning_rate": 2.0342486886763345e-05,
      "loss": 0.001,
      "step": 96120
    },
    {
      "epoch": 29.660598580684972,
      "grad_norm": 5.31403929926455e-06,
      "learning_rate": 2.0339401419315027e-05,
      "loss": 0.0001,
      "step": 96130
    },
    {
      "epoch": 29.66368404813329,
      "grad_norm": 1.9991521185147576e-05,
      "learning_rate": 2.0336315951866707e-05,
      "loss": 0.0001,
      "step": 96140
    },
    {
      "epoch": 29.66676951558161,
      "grad_norm": 0.00019522817456163466,
      "learning_rate": 2.033323048441839e-05,
      "loss": 0.0,
      "step": 96150
    },
    {
      "epoch": 29.66985498302993,
      "grad_norm": 0.00017315954028163105,
      "learning_rate": 2.033014501697007e-05,
      "loss": 0.0,
      "step": 96160
    },
    {
      "epoch": 29.672940450478247,
      "grad_norm": 1.0040904641073212e-07,
      "learning_rate": 2.0327059549521754e-05,
      "loss": 0.0007,
      "step": 96170
    },
    {
      "epoch": 29.676025917926566,
      "grad_norm": 1.3205324648879468e-05,
      "learning_rate": 2.0323974082073436e-05,
      "loss": 0.0001,
      "step": 96180
    },
    {
      "epoch": 29.679111385374885,
      "grad_norm": 0.37400224804878235,
      "learning_rate": 2.0320888614625116e-05,
      "loss": 0.0001,
      "step": 96190
    },
    {
      "epoch": 29.682196852823203,
      "grad_norm": 1.481929484725697e-05,
      "learning_rate": 2.0317803147176798e-05,
      "loss": 0.0,
      "step": 96200
    },
    {
      "epoch": 29.685282320271522,
      "grad_norm": 1.944318228197517e-06,
      "learning_rate": 2.031471767972848e-05,
      "loss": 0.0,
      "step": 96210
    },
    {
      "epoch": 29.68836778771984,
      "grad_norm": 0.13061606884002686,
      "learning_rate": 2.0311632212280163e-05,
      "loss": 0.0017,
      "step": 96220
    },
    {
      "epoch": 29.69145325516816,
      "grad_norm": 1.6045705080032349,
      "learning_rate": 2.0308546744831845e-05,
      "loss": 0.0007,
      "step": 96230
    },
    {
      "epoch": 29.694538722616475,
      "grad_norm": 9.956621215678751e-05,
      "learning_rate": 2.0305461277383525e-05,
      "loss": 0.0,
      "step": 96240
    },
    {
      "epoch": 29.697624190064793,
      "grad_norm": 0.00013975295587442815,
      "learning_rate": 2.0302375809935207e-05,
      "loss": 0.0004,
      "step": 96250
    },
    {
      "epoch": 29.700709657513112,
      "grad_norm": 3.26570463180542,
      "learning_rate": 2.0299290342486886e-05,
      "loss": 0.0025,
      "step": 96260
    },
    {
      "epoch": 29.70379512496143,
      "grad_norm": 7.824313797755167e-05,
      "learning_rate": 2.029620487503857e-05,
      "loss": 0.0015,
      "step": 96270
    },
    {
      "epoch": 29.70688059240975,
      "grad_norm": 0.003557277610525489,
      "learning_rate": 2.029311940759025e-05,
      "loss": 0.0,
      "step": 96280
    },
    {
      "epoch": 29.70996605985807,
      "grad_norm": 0.003981471061706543,
      "learning_rate": 2.0290033940141934e-05,
      "loss": 0.008,
      "step": 96290
    },
    {
      "epoch": 29.713051527306387,
      "grad_norm": 3.010784348589368e-05,
      "learning_rate": 2.0286948472693616e-05,
      "loss": 0.0001,
      "step": 96300
    },
    {
      "epoch": 29.716136994754706,
      "grad_norm": 0.00023490088642574847,
      "learning_rate": 2.0283863005245295e-05,
      "loss": 0.0002,
      "step": 96310
    },
    {
      "epoch": 29.719222462203025,
      "grad_norm": 0.005026579834520817,
      "learning_rate": 2.0280777537796978e-05,
      "loss": 0.0008,
      "step": 96320
    },
    {
      "epoch": 29.722307929651343,
      "grad_norm": 0.002731342799961567,
      "learning_rate": 2.027769207034866e-05,
      "loss": 0.0008,
      "step": 96330
    },
    {
      "epoch": 29.725393397099662,
      "grad_norm": 1.1897781405423302e-05,
      "learning_rate": 2.027460660290034e-05,
      "loss": 0.0003,
      "step": 96340
    },
    {
      "epoch": 29.72847886454798,
      "grad_norm": 0.004174935631453991,
      "learning_rate": 2.027152113545202e-05,
      "loss": 0.0002,
      "step": 96350
    },
    {
      "epoch": 29.731564331996296,
      "grad_norm": 0.38992956280708313,
      "learning_rate": 2.0268435668003704e-05,
      "loss": 0.0003,
      "step": 96360
    },
    {
      "epoch": 29.734649799444615,
      "grad_norm": 0.002350709866732359,
      "learning_rate": 2.0265350200555387e-05,
      "loss": 0.0035,
      "step": 96370
    },
    {
      "epoch": 29.737735266892933,
      "grad_norm": 0.002667632419615984,
      "learning_rate": 2.0262264733107066e-05,
      "loss": 0.0005,
      "step": 96380
    },
    {
      "epoch": 29.740820734341252,
      "grad_norm": 0.02615467831492424,
      "learning_rate": 2.0259179265658748e-05,
      "loss": 0.0002,
      "step": 96390
    },
    {
      "epoch": 29.74390620178957,
      "grad_norm": 2.0688043150585145e-05,
      "learning_rate": 2.025609379821043e-05,
      "loss": 0.0035,
      "step": 96400
    },
    {
      "epoch": 29.74699166923789,
      "grad_norm": 4.1381194023415446e-05,
      "learning_rate": 2.025300833076211e-05,
      "loss": 0.0001,
      "step": 96410
    },
    {
      "epoch": 29.75007713668621,
      "grad_norm": 0.006007154006510973,
      "learning_rate": 2.0249922863313792e-05,
      "loss": 0.0,
      "step": 96420
    },
    {
      "epoch": 29.753162604134527,
      "grad_norm": 0.00017484539421275258,
      "learning_rate": 2.0246837395865475e-05,
      "loss": 0.0,
      "step": 96430
    },
    {
      "epoch": 29.756248071582846,
      "grad_norm": 0.014576034620404243,
      "learning_rate": 2.0243751928417157e-05,
      "loss": 0.0,
      "step": 96440
    },
    {
      "epoch": 29.759333539031164,
      "grad_norm": 0.06573770940303802,
      "learning_rate": 2.024066646096884e-05,
      "loss": 0.0003,
      "step": 96450
    },
    {
      "epoch": 29.762419006479483,
      "grad_norm": 7.331094093387946e-05,
      "learning_rate": 2.023758099352052e-05,
      "loss": 0.0,
      "step": 96460
    },
    {
      "epoch": 29.7655044739278,
      "grad_norm": 3.853255066132988e-07,
      "learning_rate": 2.02344955260722e-05,
      "loss": 0.0018,
      "step": 96470
    },
    {
      "epoch": 29.768589941376117,
      "grad_norm": 0.00026674853870645165,
      "learning_rate": 2.023141005862388e-05,
      "loss": 0.0001,
      "step": 96480
    },
    {
      "epoch": 29.771675408824436,
      "grad_norm": 0.007968034595251083,
      "learning_rate": 2.0228324591175566e-05,
      "loss": 0.0,
      "step": 96490
    },
    {
      "epoch": 29.774760876272754,
      "grad_norm": 5.762555247201817e-06,
      "learning_rate": 2.0225239123727245e-05,
      "loss": 0.0,
      "step": 96500
    },
    {
      "epoch": 29.777846343721073,
      "grad_norm": 0.8027390837669373,
      "learning_rate": 2.0222153656278928e-05,
      "loss": 0.0011,
      "step": 96510
    },
    {
      "epoch": 29.780931811169392,
      "grad_norm": 2.1216869754425716e-06,
      "learning_rate": 2.021906818883061e-05,
      "loss": 0.0,
      "step": 96520
    },
    {
      "epoch": 29.78401727861771,
      "grad_norm": 1.0217341696261428e-05,
      "learning_rate": 2.021598272138229e-05,
      "loss": 0.0,
      "step": 96530
    },
    {
      "epoch": 29.78710274606603,
      "grad_norm": 8.350026473635808e-05,
      "learning_rate": 2.0212897253933972e-05,
      "loss": 0.0001,
      "step": 96540
    },
    {
      "epoch": 29.790188213514348,
      "grad_norm": 2.8537388061522506e-05,
      "learning_rate": 2.020981178648565e-05,
      "loss": 0.0001,
      "step": 96550
    },
    {
      "epoch": 29.793273680962667,
      "grad_norm": 5.373865405999823e-07,
      "learning_rate": 2.0206726319037337e-05,
      "loss": 0.0,
      "step": 96560
    },
    {
      "epoch": 29.796359148410986,
      "grad_norm": 0.00014357073814608157,
      "learning_rate": 2.0203640851589016e-05,
      "loss": 0.0,
      "step": 96570
    },
    {
      "epoch": 29.799444615859304,
      "grad_norm": 0.0016512408619746566,
      "learning_rate": 2.0200555384140698e-05,
      "loss": 0.0,
      "step": 96580
    },
    {
      "epoch": 29.80253008330762,
      "grad_norm": 7.677569442421373e-07,
      "learning_rate": 2.019746991669238e-05,
      "loss": 0.0,
      "step": 96590
    },
    {
      "epoch": 29.805615550755938,
      "grad_norm": 1.3890461559640244e-05,
      "learning_rate": 2.019438444924406e-05,
      "loss": 0.0001,
      "step": 96600
    },
    {
      "epoch": 29.808701018204257,
      "grad_norm": 6.042229870217852e-06,
      "learning_rate": 2.0191298981795742e-05,
      "loss": 0.0,
      "step": 96610
    },
    {
      "epoch": 29.811786485652576,
      "grad_norm": 0.0033701590728014708,
      "learning_rate": 2.0188213514347425e-05,
      "loss": 0.0003,
      "step": 96620
    },
    {
      "epoch": 29.814871953100894,
      "grad_norm": 0.0019071606220677495,
      "learning_rate": 2.0185128046899107e-05,
      "loss": 0.0004,
      "step": 96630
    },
    {
      "epoch": 29.817957420549213,
      "grad_norm": 0.004092375282198191,
      "learning_rate": 2.018204257945079e-05,
      "loss": 0.0001,
      "step": 96640
    },
    {
      "epoch": 29.821042887997532,
      "grad_norm": 0.000364105828339234,
      "learning_rate": 2.017895711200247e-05,
      "loss": 0.0,
      "step": 96650
    },
    {
      "epoch": 29.82412835544585,
      "grad_norm": 3.1360807497549104e-06,
      "learning_rate": 2.017587164455415e-05,
      "loss": 0.0,
      "step": 96660
    },
    {
      "epoch": 29.82721382289417,
      "grad_norm": 0.12892374396324158,
      "learning_rate": 2.017278617710583e-05,
      "loss": 0.0001,
      "step": 96670
    },
    {
      "epoch": 29.830299290342488,
      "grad_norm": 8.897131192497909e-05,
      "learning_rate": 2.0169700709657513e-05,
      "loss": 0.0002,
      "step": 96680
    },
    {
      "epoch": 29.833384757790807,
      "grad_norm": 0.00020072550978511572,
      "learning_rate": 2.0166615242209195e-05,
      "loss": 0.0,
      "step": 96690
    },
    {
      "epoch": 29.836470225239125,
      "grad_norm": 0.0010193617781624198,
      "learning_rate": 2.0163529774760878e-05,
      "loss": 0.0,
      "step": 96700
    },
    {
      "epoch": 29.83955569268744,
      "grad_norm": 1.4718637466430664,
      "learning_rate": 2.016044430731256e-05,
      "loss": 0.0008,
      "step": 96710
    },
    {
      "epoch": 29.84264116013576,
      "grad_norm": 8.544867887394503e-05,
      "learning_rate": 2.015735883986424e-05,
      "loss": 0.0,
      "step": 96720
    },
    {
      "epoch": 29.845726627584078,
      "grad_norm": 0.002384848427027464,
      "learning_rate": 2.0154273372415922e-05,
      "loss": 0.0,
      "step": 96730
    },
    {
      "epoch": 29.848812095032397,
      "grad_norm": 4.222540883347392e-05,
      "learning_rate": 2.0151187904967604e-05,
      "loss": 0.0001,
      "step": 96740
    },
    {
      "epoch": 29.851897562480715,
      "grad_norm": 0.02449190802872181,
      "learning_rate": 2.0148102437519283e-05,
      "loss": 0.0004,
      "step": 96750
    },
    {
      "epoch": 29.854983029929034,
      "grad_norm": 3.0990890991233755e-06,
      "learning_rate": 2.014501697007097e-05,
      "loss": 0.0,
      "step": 96760
    },
    {
      "epoch": 29.858068497377353,
      "grad_norm": 5.750925265601836e-05,
      "learning_rate": 2.014193150262265e-05,
      "loss": 0.0001,
      "step": 96770
    },
    {
      "epoch": 29.86115396482567,
      "grad_norm": 0.23773780465126038,
      "learning_rate": 2.013884603517433e-05,
      "loss": 0.0018,
      "step": 96780
    },
    {
      "epoch": 29.86423943227399,
      "grad_norm": 9.91748947853921e-07,
      "learning_rate": 2.013576056772601e-05,
      "loss": 0.0,
      "step": 96790
    },
    {
      "epoch": 29.86732489972231,
      "grad_norm": 1.2412835985742277e-06,
      "learning_rate": 2.0132675100277692e-05,
      "loss": 0.0,
      "step": 96800
    },
    {
      "epoch": 29.870410367170628,
      "grad_norm": 0.02169831283390522,
      "learning_rate": 2.0129589632829375e-05,
      "loss": 0.0,
      "step": 96810
    },
    {
      "epoch": 29.873495834618943,
      "grad_norm": 0.02262818068265915,
      "learning_rate": 2.0126504165381054e-05,
      "loss": 0.0,
      "step": 96820
    },
    {
      "epoch": 29.87658130206726,
      "grad_norm": 6.577948806807399e-05,
      "learning_rate": 2.012341869793274e-05,
      "loss": 0.0011,
      "step": 96830
    },
    {
      "epoch": 29.87966676951558,
      "grad_norm": 0.0004392650444060564,
      "learning_rate": 2.012033323048442e-05,
      "loss": 0.0,
      "step": 96840
    },
    {
      "epoch": 29.8827522369639,
      "grad_norm": 3.440767386564403e-06,
      "learning_rate": 2.01172477630361e-05,
      "loss": 0.0,
      "step": 96850
    },
    {
      "epoch": 29.885837704412218,
      "grad_norm": 0.0033144408371299505,
      "learning_rate": 2.0114162295587784e-05,
      "loss": 0.0,
      "step": 96860
    },
    {
      "epoch": 29.888923171860537,
      "grad_norm": 0.0001879626652225852,
      "learning_rate": 2.0111076828139463e-05,
      "loss": 0.0,
      "step": 96870
    },
    {
      "epoch": 29.892008639308855,
      "grad_norm": 2.837733461547032e-07,
      "learning_rate": 2.0107991360691145e-05,
      "loss": 0.0041,
      "step": 96880
    },
    {
      "epoch": 29.895094106757174,
      "grad_norm": 0.0017315208679065108,
      "learning_rate": 2.0104905893242828e-05,
      "loss": 0.0,
      "step": 96890
    },
    {
      "epoch": 29.898179574205493,
      "grad_norm": 0.0002929092152044177,
      "learning_rate": 2.010182042579451e-05,
      "loss": 0.0013,
      "step": 96900
    },
    {
      "epoch": 29.90126504165381,
      "grad_norm": 0.001728771603666246,
      "learning_rate": 2.009873495834619e-05,
      "loss": 0.0,
      "step": 96910
    },
    {
      "epoch": 29.90435050910213,
      "grad_norm": 0.1939799189567566,
      "learning_rate": 2.0095649490897872e-05,
      "loss": 0.0001,
      "step": 96920
    },
    {
      "epoch": 29.90743597655045,
      "grad_norm": 0.0001361680479021743,
      "learning_rate": 2.0092564023449554e-05,
      "loss": 0.0126,
      "step": 96930
    },
    {
      "epoch": 29.910521443998764,
      "grad_norm": 0.00044810192775912583,
      "learning_rate": 2.0089478556001234e-05,
      "loss": 0.0008,
      "step": 96940
    },
    {
      "epoch": 29.913606911447083,
      "grad_norm": 0.000229150231461972,
      "learning_rate": 2.0086393088552916e-05,
      "loss": 0.0002,
      "step": 96950
    },
    {
      "epoch": 29.9166923788954,
      "grad_norm": 5.751863909608801e-07,
      "learning_rate": 2.00833076211046e-05,
      "loss": 0.0009,
      "step": 96960
    },
    {
      "epoch": 29.91977784634372,
      "grad_norm": 0.020540259778499603,
      "learning_rate": 2.008022215365628e-05,
      "loss": 0.0,
      "step": 96970
    },
    {
      "epoch": 29.92286331379204,
      "grad_norm": 0.00029987975722178817,
      "learning_rate": 2.0077136686207963e-05,
      "loss": 0.0,
      "step": 96980
    },
    {
      "epoch": 29.925948781240358,
      "grad_norm": 4.4420470658224076e-05,
      "learning_rate": 2.0074051218759643e-05,
      "loss": 0.0009,
      "step": 96990
    },
    {
      "epoch": 29.929034248688676,
      "grad_norm": 0.006025299429893494,
      "learning_rate": 2.0070965751311325e-05,
      "loss": 0.0001,
      "step": 97000
    },
    {
      "epoch": 29.932119716136995,
      "grad_norm": 5.057274847786175e-07,
      "learning_rate": 2.0067880283863004e-05,
      "loss": 0.0003,
      "step": 97010
    },
    {
      "epoch": 29.935205183585314,
      "grad_norm": 4.377333425509278e-06,
      "learning_rate": 2.0064794816414687e-05,
      "loss": 0.0002,
      "step": 97020
    },
    {
      "epoch": 29.938290651033633,
      "grad_norm": 5.088170382805401e-07,
      "learning_rate": 2.006170934896637e-05,
      "loss": 0.0001,
      "step": 97030
    },
    {
      "epoch": 29.94137611848195,
      "grad_norm": 8.192835593945347e-06,
      "learning_rate": 2.005862388151805e-05,
      "loss": 0.0,
      "step": 97040
    },
    {
      "epoch": 29.94446158593027,
      "grad_norm": 3.8315774872899055e-05,
      "learning_rate": 2.0055538414069734e-05,
      "loss": 0.0001,
      "step": 97050
    },
    {
      "epoch": 29.947547053378585,
      "grad_norm": 0.0024481085129082203,
      "learning_rate": 2.0052452946621413e-05,
      "loss": 0.0001,
      "step": 97060
    },
    {
      "epoch": 29.950632520826904,
      "grad_norm": 2.0220888472977094e-05,
      "learning_rate": 2.0049367479173096e-05,
      "loss": 0.0,
      "step": 97070
    },
    {
      "epoch": 29.953717988275223,
      "grad_norm": 0.000563866167794913,
      "learning_rate": 2.0046282011724775e-05,
      "loss": 0.0,
      "step": 97080
    },
    {
      "epoch": 29.95680345572354,
      "grad_norm": 3.8518846849910915e-05,
      "learning_rate": 2.004319654427646e-05,
      "loss": 0.0,
      "step": 97090
    },
    {
      "epoch": 29.95988892317186,
      "grad_norm": 0.0007948878919705749,
      "learning_rate": 2.0040111076828143e-05,
      "loss": 0.0,
      "step": 97100
    },
    {
      "epoch": 29.96297439062018,
      "grad_norm": 2.0191739622532623e-06,
      "learning_rate": 2.0037025609379822e-05,
      "loss": 0.0,
      "step": 97110
    },
    {
      "epoch": 29.966059858068498,
      "grad_norm": 7.105405529728159e-06,
      "learning_rate": 2.0033940141931505e-05,
      "loss": 0.0063,
      "step": 97120
    },
    {
      "epoch": 29.969145325516816,
      "grad_norm": 1.1925018952751998e-05,
      "learning_rate": 2.0030854674483184e-05,
      "loss": 0.0,
      "step": 97130
    },
    {
      "epoch": 29.972230792965135,
      "grad_norm": 0.0016934244194999337,
      "learning_rate": 2.0027769207034866e-05,
      "loss": 0.0,
      "step": 97140
    },
    {
      "epoch": 29.975316260413454,
      "grad_norm": 1.2996675650356337e-05,
      "learning_rate": 2.002468373958655e-05,
      "loss": 0.0,
      "step": 97150
    },
    {
      "epoch": 29.978401727861772,
      "grad_norm": 0.0307245422154665,
      "learning_rate": 2.002159827213823e-05,
      "loss": 0.0005,
      "step": 97160
    },
    {
      "epoch": 29.981487195310088,
      "grad_norm": 8.677641744725406e-06,
      "learning_rate": 2.0018512804689914e-05,
      "loss": 0.0,
      "step": 97170
    },
    {
      "epoch": 29.984572662758406,
      "grad_norm": 2.0221059457981028e-06,
      "learning_rate": 2.0015427337241593e-05,
      "loss": 0.0,
      "step": 97180
    },
    {
      "epoch": 29.987658130206725,
      "grad_norm": 2.124055072272313e-06,
      "learning_rate": 2.0012341869793275e-05,
      "loss": 0.0001,
      "step": 97190
    },
    {
      "epoch": 29.990743597655044,
      "grad_norm": 0.09706080704927444,
      "learning_rate": 2.0009256402344954e-05,
      "loss": 0.0004,
      "step": 97200
    },
    {
      "epoch": 29.993829065103363,
      "grad_norm": 0.013248967006802559,
      "learning_rate": 2.0006170934896637e-05,
      "loss": 0.0001,
      "step": 97210
    },
    {
      "epoch": 29.99691453255168,
      "grad_norm": 0.0003628623380791396,
      "learning_rate": 2.000308546744832e-05,
      "loss": 0.0007,
      "step": 97220
    },
    {
      "epoch": 30.0,
      "grad_norm": 49.88221740722656,
      "learning_rate": 2e-05,
      "loss": 0.3534,
      "step": 97230
    },
    {
      "epoch": 30.0,
      "eval_accuracy_branch1": 0.9998071043469036,
      "eval_accuracy_branch2": 0.3976254545103826,
      "eval_f1_branch1": 0.9996664441078174,
      "eval_f1_branch2": 0.38171771687454437,
      "eval_loss": 0.00010562023817328736,
      "eval_precision_branch1": 0.9996712424954901,
      "eval_precision_branch2": 0.5116210998073437,
      "eval_recall_branch1": 0.9996624264936355,
      "eval_recall_branch2": 0.5074795289488151,
      "eval_runtime": 241.1842,
      "eval_samples_per_second": 429.891,
      "eval_steps_per_second": 53.739,
      "step": 97230
    },
    {
      "epoch": 30.00308546744832,
      "grad_norm": 0.07831593602895737,
      "learning_rate": 1.9996914532551684e-05,
      "loss": 0.0,
      "step": 97240
    },
    {
      "epoch": 30.006170934896637,
      "grad_norm": 0.00010573528561508283,
      "learning_rate": 1.9993829065103363e-05,
      "loss": 0.0049,
      "step": 97250
    },
    {
      "epoch": 30.009256402344956,
      "grad_norm": 0.0010929516283795238,
      "learning_rate": 1.9990743597655046e-05,
      "loss": 0.002,
      "step": 97260
    },
    {
      "epoch": 30.012341869793275,
      "grad_norm": 0.0059136394411325455,
      "learning_rate": 1.9987658130206728e-05,
      "loss": 0.0001,
      "step": 97270
    },
    {
      "epoch": 30.015427337241594,
      "grad_norm": 0.00018007360631600022,
      "learning_rate": 1.9984572662758407e-05,
      "loss": 0.0001,
      "step": 97280
    },
    {
      "epoch": 30.01851280468991,
      "grad_norm": 0.00047148828161880374,
      "learning_rate": 1.998148719531009e-05,
      "loss": 0.0002,
      "step": 97290
    },
    {
      "epoch": 30.021598272138228,
      "grad_norm": 7.676528912270442e-05,
      "learning_rate": 1.9978401727861772e-05,
      "loss": 0.0,
      "step": 97300
    },
    {
      "epoch": 30.024683739586546,
      "grad_norm": 0.00046410333015955985,
      "learning_rate": 1.9975316260413455e-05,
      "loss": 0.0,
      "step": 97310
    },
    {
      "epoch": 30.027769207034865,
      "grad_norm": 0.0002818486245814711,
      "learning_rate": 1.9972230792965134e-05,
      "loss": 0.003,
      "step": 97320
    },
    {
      "epoch": 30.030854674483184,
      "grad_norm": 1.1906950021511875e-05,
      "learning_rate": 1.9969145325516816e-05,
      "loss": 0.0,
      "step": 97330
    },
    {
      "epoch": 30.033940141931502,
      "grad_norm": 0.0030537669081240892,
      "learning_rate": 1.99660598580685e-05,
      "loss": 0.0,
      "step": 97340
    },
    {
      "epoch": 30.03702560937982,
      "grad_norm": 0.00012907671043649316,
      "learning_rate": 1.9962974390620178e-05,
      "loss": 0.0,
      "step": 97350
    },
    {
      "epoch": 30.04011107682814,
      "grad_norm": 0.031634747982025146,
      "learning_rate": 1.9959888923171864e-05,
      "loss": 0.0011,
      "step": 97360
    },
    {
      "epoch": 30.04319654427646,
      "grad_norm": 0.00023501343093812466,
      "learning_rate": 1.9956803455723543e-05,
      "loss": 0.0,
      "step": 97370
    },
    {
      "epoch": 30.046282011724777,
      "grad_norm": 0.02223127894103527,
      "learning_rate": 1.9953717988275225e-05,
      "loss": 0.0003,
      "step": 97380
    },
    {
      "epoch": 30.049367479173096,
      "grad_norm": 1.940977745107375e-05,
      "learning_rate": 1.9950632520826908e-05,
      "loss": 0.0106,
      "step": 97390
    },
    {
      "epoch": 30.052452946621415,
      "grad_norm": 0.0012063131434842944,
      "learning_rate": 1.9947547053378587e-05,
      "loss": 0.0,
      "step": 97400
    },
    {
      "epoch": 30.05553841406973,
      "grad_norm": 0.12421700358390808,
      "learning_rate": 1.994446158593027e-05,
      "loss": 0.0002,
      "step": 97410
    },
    {
      "epoch": 30.05862388151805,
      "grad_norm": 6.972786195547087e-06,
      "learning_rate": 1.994137611848195e-05,
      "loss": 0.0032,
      "step": 97420
    },
    {
      "epoch": 30.061709348966367,
      "grad_norm": 1.5144989902182715e-06,
      "learning_rate": 1.9938290651033634e-05,
      "loss": 0.0,
      "step": 97430
    },
    {
      "epoch": 30.064794816414686,
      "grad_norm": 0.03658377006649971,
      "learning_rate": 1.9935205183585313e-05,
      "loss": 0.0022,
      "step": 97440
    },
    {
      "epoch": 30.067880283863005,
      "grad_norm": 9.410213351657148e-06,
      "learning_rate": 1.9932119716136996e-05,
      "loss": 0.0003,
      "step": 97450
    },
    {
      "epoch": 30.070965751311324,
      "grad_norm": 0.0008850472513586283,
      "learning_rate": 1.9929034248688678e-05,
      "loss": 0.0,
      "step": 97460
    },
    {
      "epoch": 30.074051218759642,
      "grad_norm": 1.3683913493878208e-05,
      "learning_rate": 1.9925948781240357e-05,
      "loss": 0.0001,
      "step": 97470
    },
    {
      "epoch": 30.07713668620796,
      "grad_norm": 4.973804607288912e-05,
      "learning_rate": 1.992286331379204e-05,
      "loss": 0.0,
      "step": 97480
    },
    {
      "epoch": 30.08022215365628,
      "grad_norm": 1.8405998945236206,
      "learning_rate": 1.9919777846343722e-05,
      "loss": 0.0011,
      "step": 97490
    },
    {
      "epoch": 30.0833076211046,
      "grad_norm": 0.031169472262263298,
      "learning_rate": 1.9916692378895405e-05,
      "loss": 0.0,
      "step": 97500
    },
    {
      "epoch": 30.086393088552917,
      "grad_norm": 0.00016394919657614082,
      "learning_rate": 1.9913606911447087e-05,
      "loss": 0.0017,
      "step": 97510
    },
    {
      "epoch": 30.089478556001236,
      "grad_norm": 5.363829041016288e-05,
      "learning_rate": 1.9910521443998766e-05,
      "loss": 0.0002,
      "step": 97520
    },
    {
      "epoch": 30.09256402344955,
      "grad_norm": 0.00016934623999986798,
      "learning_rate": 1.990743597655045e-05,
      "loss": 0.0,
      "step": 97530
    },
    {
      "epoch": 30.09564949089787,
      "grad_norm": 4.042531145387329e-06,
      "learning_rate": 1.9904350509102128e-05,
      "loss": 0.0003,
      "step": 97540
    },
    {
      "epoch": 30.09873495834619,
      "grad_norm": 0.1546282023191452,
      "learning_rate": 1.990126504165381e-05,
      "loss": 0.001,
      "step": 97550
    },
    {
      "epoch": 30.101820425794507,
      "grad_norm": 9.89233285508817e-06,
      "learning_rate": 1.9898179574205493e-05,
      "loss": 0.0005,
      "step": 97560
    },
    {
      "epoch": 30.104905893242826,
      "grad_norm": 0.00017555299564264715,
      "learning_rate": 1.9895094106757175e-05,
      "loss": 0.0,
      "step": 97570
    },
    {
      "epoch": 30.107991360691145,
      "grad_norm": 2.416198492050171,
      "learning_rate": 1.9892008639308858e-05,
      "loss": 0.0022,
      "step": 97580
    },
    {
      "epoch": 30.111076828139463,
      "grad_norm": 1.9648216039058752e-05,
      "learning_rate": 1.9888923171860537e-05,
      "loss": 0.0003,
      "step": 97590
    },
    {
      "epoch": 30.114162295587782,
      "grad_norm": 4.751049345941283e-05,
      "learning_rate": 1.988583770441222e-05,
      "loss": 0.0004,
      "step": 97600
    },
    {
      "epoch": 30.1172477630361,
      "grad_norm": 0.0005276432493701577,
      "learning_rate": 1.9882752236963902e-05,
      "loss": 0.0002,
      "step": 97610
    },
    {
      "epoch": 30.12033323048442,
      "grad_norm": 0.3345196545124054,
      "learning_rate": 1.987966676951558e-05,
      "loss": 0.0002,
      "step": 97620
    },
    {
      "epoch": 30.12341869793274,
      "grad_norm": 0.00025094393640756607,
      "learning_rate": 1.9876581302067267e-05,
      "loss": 0.0001,
      "step": 97630
    },
    {
      "epoch": 30.126504165381053,
      "grad_norm": 1.4089232536207419e-05,
      "learning_rate": 1.9873495834618946e-05,
      "loss": 0.0,
      "step": 97640
    },
    {
      "epoch": 30.129589632829372,
      "grad_norm": 0.002450614469125867,
      "learning_rate": 1.987041036717063e-05,
      "loss": 0.0028,
      "step": 97650
    },
    {
      "epoch": 30.13267510027769,
      "grad_norm": 2.702658321140916e-06,
      "learning_rate": 1.9867324899722307e-05,
      "loss": 0.0003,
      "step": 97660
    },
    {
      "epoch": 30.13576056772601,
      "grad_norm": 5.3639534598914906e-05,
      "learning_rate": 1.986423943227399e-05,
      "loss": 0.0,
      "step": 97670
    },
    {
      "epoch": 30.13884603517433,
      "grad_norm": 0.004155449569225311,
      "learning_rate": 1.9861153964825672e-05,
      "loss": 0.0,
      "step": 97680
    },
    {
      "epoch": 30.141931502622647,
      "grad_norm": 2.2163145331433043e-05,
      "learning_rate": 1.985806849737735e-05,
      "loss": 0.0006,
      "step": 97690
    },
    {
      "epoch": 30.145016970070966,
      "grad_norm": 0.006922414526343346,
      "learning_rate": 1.9854983029929037e-05,
      "loss": 0.0,
      "step": 97700
    },
    {
      "epoch": 30.148102437519285,
      "grad_norm": 0.001150259980931878,
      "learning_rate": 1.9851897562480716e-05,
      "loss": 0.0,
      "step": 97710
    },
    {
      "epoch": 30.151187904967603,
      "grad_norm": 0.00016145527479238808,
      "learning_rate": 1.98488120950324e-05,
      "loss": 0.0072,
      "step": 97720
    },
    {
      "epoch": 30.154273372415922,
      "grad_norm": 0.0004061942745465785,
      "learning_rate": 1.9845726627584078e-05,
      "loss": 0.0,
      "step": 97730
    },
    {
      "epoch": 30.15735883986424,
      "grad_norm": 5.198279268370243e-06,
      "learning_rate": 1.984264116013576e-05,
      "loss": 0.0022,
      "step": 97740
    },
    {
      "epoch": 30.16044430731256,
      "grad_norm": 6.808885518694296e-05,
      "learning_rate": 1.9839555692687443e-05,
      "loss": 0.0068,
      "step": 97750
    },
    {
      "epoch": 30.163529774760875,
      "grad_norm": 3.5787928936770186e-05,
      "learning_rate": 1.9836470225239125e-05,
      "loss": 0.0001,
      "step": 97760
    },
    {
      "epoch": 30.166615242209193,
      "grad_norm": 0.0007713237428106368,
      "learning_rate": 1.9833384757790808e-05,
      "loss": 0.0004,
      "step": 97770
    },
    {
      "epoch": 30.169700709657512,
      "grad_norm": 0.00039157053106464446,
      "learning_rate": 1.9830299290342487e-05,
      "loss": 0.0003,
      "step": 97780
    },
    {
      "epoch": 30.17278617710583,
      "grad_norm": 3.0158067602314986e-05,
      "learning_rate": 1.982721382289417e-05,
      "loss": 0.0,
      "step": 97790
    },
    {
      "epoch": 30.17587164455415,
      "grad_norm": 0.0002685401705093682,
      "learning_rate": 1.9824128355445852e-05,
      "loss": 0.0,
      "step": 97800
    },
    {
      "epoch": 30.178957112002468,
      "grad_norm": 1.3155976375855971e-05,
      "learning_rate": 1.982104288799753e-05,
      "loss": 0.0013,
      "step": 97810
    },
    {
      "epoch": 30.182042579450787,
      "grad_norm": 0.0003184954111929983,
      "learning_rate": 1.9817957420549214e-05,
      "loss": 0.0,
      "step": 97820
    },
    {
      "epoch": 30.185128046899106,
      "grad_norm": 5.464531568577513e-05,
      "learning_rate": 1.9814871953100896e-05,
      "loss": 0.0063,
      "step": 97830
    },
    {
      "epoch": 30.188213514347424,
      "grad_norm": 2.9048762826278107e-06,
      "learning_rate": 1.981178648565258e-05,
      "loss": 0.0,
      "step": 97840
    },
    {
      "epoch": 30.191298981795743,
      "grad_norm": 3.1102588309295243e-06,
      "learning_rate": 1.9808701018204258e-05,
      "loss": 0.0,
      "step": 97850
    },
    {
      "epoch": 30.194384449244062,
      "grad_norm": 0.0003003692254424095,
      "learning_rate": 1.980561555075594e-05,
      "loss": 0.0,
      "step": 97860
    },
    {
      "epoch": 30.19746991669238,
      "grad_norm": 9.137776942225173e-06,
      "learning_rate": 1.9802530083307623e-05,
      "loss": 0.0002,
      "step": 97870
    },
    {
      "epoch": 30.200555384140696,
      "grad_norm": 2.91331457447086e-06,
      "learning_rate": 1.97994446158593e-05,
      "loss": 0.0002,
      "step": 97880
    },
    {
      "epoch": 30.203640851589014,
      "grad_norm": 2.1502393792616203e-05,
      "learning_rate": 1.9796359148410984e-05,
      "loss": 0.0,
      "step": 97890
    },
    {
      "epoch": 30.206726319037333,
      "grad_norm": 0.00856587290763855,
      "learning_rate": 1.9793273680962667e-05,
      "loss": 0.0004,
      "step": 97900
    },
    {
      "epoch": 30.209811786485652,
      "grad_norm": 4.021036602352979e-06,
      "learning_rate": 1.979018821351435e-05,
      "loss": 0.0,
      "step": 97910
    },
    {
      "epoch": 30.21289725393397,
      "grad_norm": 0.06759415566921234,
      "learning_rate": 1.978710274606603e-05,
      "loss": 0.0,
      "step": 97920
    },
    {
      "epoch": 30.21598272138229,
      "grad_norm": 0.08997035026550293,
      "learning_rate": 1.978401727861771e-05,
      "loss": 0.0004,
      "step": 97930
    },
    {
      "epoch": 30.219068188830608,
      "grad_norm": 2.13012481253827e-05,
      "learning_rate": 1.9780931811169393e-05,
      "loss": 0.0005,
      "step": 97940
    },
    {
      "epoch": 30.222153656278927,
      "grad_norm": 1.6189569578273222e-05,
      "learning_rate": 1.9777846343721072e-05,
      "loss": 0.0001,
      "step": 97950
    },
    {
      "epoch": 30.225239123727246,
      "grad_norm": 6.1015711253276095e-05,
      "learning_rate": 1.9774760876272758e-05,
      "loss": 0.0001,
      "step": 97960
    },
    {
      "epoch": 30.228324591175564,
      "grad_norm": 0.0215933658182621,
      "learning_rate": 1.9771675408824437e-05,
      "loss": 0.0017,
      "step": 97970
    },
    {
      "epoch": 30.231410058623883,
      "grad_norm": 0.00017879508959595114,
      "learning_rate": 1.976858994137612e-05,
      "loss": 0.0,
      "step": 97980
    },
    {
      "epoch": 30.2344955260722,
      "grad_norm": 7.897865725681186e-05,
      "learning_rate": 1.9765504473927802e-05,
      "loss": 0.0,
      "step": 97990
    },
    {
      "epoch": 30.237580993520517,
      "grad_norm": 8.317617243847053e-07,
      "learning_rate": 1.976241900647948e-05,
      "loss": 0.0,
      "step": 98000
    },
    {
      "epoch": 30.240666460968836,
      "grad_norm": 1.8334423657506704e-05,
      "learning_rate": 1.9759333539031164e-05,
      "loss": 0.0001,
      "step": 98010
    },
    {
      "epoch": 30.243751928417154,
      "grad_norm": 3.4932614653371274e-05,
      "learning_rate": 1.9756248071582846e-05,
      "loss": 0.0,
      "step": 98020
    },
    {
      "epoch": 30.246837395865473,
      "grad_norm": 0.009215653873980045,
      "learning_rate": 1.975316260413453e-05,
      "loss": 0.0,
      "step": 98030
    },
    {
      "epoch": 30.24992286331379,
      "grad_norm": 0.008254071697592735,
      "learning_rate": 1.975007713668621e-05,
      "loss": 0.0001,
      "step": 98040
    },
    {
      "epoch": 30.25300833076211,
      "grad_norm": 0.12917983531951904,
      "learning_rate": 1.974699166923789e-05,
      "loss": 0.0001,
      "step": 98050
    },
    {
      "epoch": 30.25609379821043,
      "grad_norm": 1.5712321328464895e-05,
      "learning_rate": 1.9743906201789573e-05,
      "loss": 0.0,
      "step": 98060
    },
    {
      "epoch": 30.259179265658748,
      "grad_norm": 8.874147169990465e-06,
      "learning_rate": 1.9740820734341252e-05,
      "loss": 0.0001,
      "step": 98070
    },
    {
      "epoch": 30.262264733107067,
      "grad_norm": 9.490906194287163e-08,
      "learning_rate": 1.9737735266892934e-05,
      "loss": 0.0,
      "step": 98080
    },
    {
      "epoch": 30.265350200555385,
      "grad_norm": 1.5459814903806546e-06,
      "learning_rate": 1.9734649799444617e-05,
      "loss": 0.0,
      "step": 98090
    },
    {
      "epoch": 30.268435668003704,
      "grad_norm": 1.0503997316391178e-07,
      "learning_rate": 1.97315643319963e-05,
      "loss": 0.0,
      "step": 98100
    },
    {
      "epoch": 30.27152113545202,
      "grad_norm": 1.4740558981429785e-05,
      "learning_rate": 1.972847886454798e-05,
      "loss": 0.0,
      "step": 98110
    },
    {
      "epoch": 30.274606602900338,
      "grad_norm": 0.00011070259643020108,
      "learning_rate": 1.972539339709966e-05,
      "loss": 0.0003,
      "step": 98120
    },
    {
      "epoch": 30.277692070348657,
      "grad_norm": 8.366455972463882e-07,
      "learning_rate": 1.9722307929651343e-05,
      "loss": 0.0002,
      "step": 98130
    },
    {
      "epoch": 30.280777537796975,
      "grad_norm": 1.422048717358848e-05,
      "learning_rate": 1.9719222462203026e-05,
      "loss": 0.0,
      "step": 98140
    },
    {
      "epoch": 30.283863005245294,
      "grad_norm": 6.023893092788057e-06,
      "learning_rate": 1.9716136994754705e-05,
      "loss": 0.0,
      "step": 98150
    },
    {
      "epoch": 30.286948472693613,
      "grad_norm": 7.121672297216719e-06,
      "learning_rate": 1.9713051527306387e-05,
      "loss": 0.0034,
      "step": 98160
    },
    {
      "epoch": 30.29003394014193,
      "grad_norm": 6.335973921522964e-06,
      "learning_rate": 1.970996605985807e-05,
      "loss": 0.0,
      "step": 98170
    },
    {
      "epoch": 30.29311940759025,
      "grad_norm": 3.424222086323425e-05,
      "learning_rate": 1.9706880592409752e-05,
      "loss": 0.0,
      "step": 98180
    },
    {
      "epoch": 30.29620487503857,
      "grad_norm": 0.02892737090587616,
      "learning_rate": 1.970379512496143e-05,
      "loss": 0.0,
      "step": 98190
    },
    {
      "epoch": 30.299290342486888,
      "grad_norm": 0.004449310712516308,
      "learning_rate": 1.9700709657513114e-05,
      "loss": 0.0,
      "step": 98200
    },
    {
      "epoch": 30.302375809935207,
      "grad_norm": 2.6128476747544482e-05,
      "learning_rate": 1.9697624190064796e-05,
      "loss": 0.0,
      "step": 98210
    },
    {
      "epoch": 30.305461277383525,
      "grad_norm": 4.745730166177964e-06,
      "learning_rate": 1.9694538722616475e-05,
      "loss": 0.0,
      "step": 98220
    },
    {
      "epoch": 30.30854674483184,
      "grad_norm": 3.1053723432705738e-06,
      "learning_rate": 1.969145325516816e-05,
      "loss": 0.0,
      "step": 98230
    },
    {
      "epoch": 30.31163221228016,
      "grad_norm": 0.06333564966917038,
      "learning_rate": 1.968836778771984e-05,
      "loss": 0.0001,
      "step": 98240
    },
    {
      "epoch": 30.314717679728478,
      "grad_norm": 1.475090414260194e-07,
      "learning_rate": 1.9685282320271523e-05,
      "loss": 0.0,
      "step": 98250
    },
    {
      "epoch": 30.317803147176797,
      "grad_norm": 0.005498322192579508,
      "learning_rate": 1.9682196852823205e-05,
      "loss": 0.0,
      "step": 98260
    },
    {
      "epoch": 30.320888614625115,
      "grad_norm": 2.0398363631102256e-05,
      "learning_rate": 1.9679111385374884e-05,
      "loss": 0.0,
      "step": 98270
    },
    {
      "epoch": 30.323974082073434,
      "grad_norm": 0.4722747504711151,
      "learning_rate": 1.9676025917926567e-05,
      "loss": 0.0003,
      "step": 98280
    },
    {
      "epoch": 30.327059549521753,
      "grad_norm": 0.003868371481075883,
      "learning_rate": 1.9672940450478246e-05,
      "loss": 0.0003,
      "step": 98290
    },
    {
      "epoch": 30.33014501697007,
      "grad_norm": 8.9803128503263e-05,
      "learning_rate": 1.9669854983029932e-05,
      "loss": 0.0,
      "step": 98300
    },
    {
      "epoch": 30.33323048441839,
      "grad_norm": 0.0013665672158822417,
      "learning_rate": 1.966676951558161e-05,
      "loss": 0.0,
      "step": 98310
    },
    {
      "epoch": 30.33631595186671,
      "grad_norm": 4.871893452218501e-06,
      "learning_rate": 1.9663684048133293e-05,
      "loss": 0.0,
      "step": 98320
    },
    {
      "epoch": 30.339401419315028,
      "grad_norm": 8.758642593420518e-07,
      "learning_rate": 1.9660598580684976e-05,
      "loss": 0.0001,
      "step": 98330
    },
    {
      "epoch": 30.342486886763346,
      "grad_norm": 0.002231332240626216,
      "learning_rate": 1.9657513113236655e-05,
      "loss": 0.0001,
      "step": 98340
    },
    {
      "epoch": 30.34557235421166,
      "grad_norm": 8.615897399977257e-07,
      "learning_rate": 1.9654427645788337e-05,
      "loss": 0.0,
      "step": 98350
    },
    {
      "epoch": 30.34865782165998,
      "grad_norm": 4.527618102656561e-07,
      "learning_rate": 1.9651342178340017e-05,
      "loss": 0.0004,
      "step": 98360
    },
    {
      "epoch": 30.3517432891083,
      "grad_norm": 0.007849933579564095,
      "learning_rate": 1.9648256710891702e-05,
      "loss": 0.0,
      "step": 98370
    },
    {
      "epoch": 30.354828756556618,
      "grad_norm": 2.1243196897557937e-05,
      "learning_rate": 1.9645171243443385e-05,
      "loss": 0.0003,
      "step": 98380
    },
    {
      "epoch": 30.357914224004936,
      "grad_norm": 0.004799106623977423,
      "learning_rate": 1.9642085775995064e-05,
      "loss": 0.0,
      "step": 98390
    },
    {
      "epoch": 30.360999691453255,
      "grad_norm": 0.001032697269693017,
      "learning_rate": 1.9639000308546746e-05,
      "loss": 0.0,
      "step": 98400
    },
    {
      "epoch": 30.364085158901574,
      "grad_norm": 5.0691308928207945e-08,
      "learning_rate": 1.9635914841098425e-05,
      "loss": 0.0,
      "step": 98410
    },
    {
      "epoch": 30.367170626349893,
      "grad_norm": 7.176205599535024e-06,
      "learning_rate": 1.9632829373650108e-05,
      "loss": 0.0001,
      "step": 98420
    },
    {
      "epoch": 30.37025609379821,
      "grad_norm": 1.1015413292625453e-05,
      "learning_rate": 1.962974390620179e-05,
      "loss": 0.0001,
      "step": 98430
    },
    {
      "epoch": 30.37334156124653,
      "grad_norm": 6.0917350310774054e-06,
      "learning_rate": 1.9626658438753473e-05,
      "loss": 0.0,
      "step": 98440
    },
    {
      "epoch": 30.37642702869485,
      "grad_norm": 2.912908257712843e-06,
      "learning_rate": 1.9623572971305155e-05,
      "loss": 0.0,
      "step": 98450
    },
    {
      "epoch": 30.379512496143164,
      "grad_norm": 0.0008614165126346052,
      "learning_rate": 1.9620487503856834e-05,
      "loss": 0.0,
      "step": 98460
    },
    {
      "epoch": 30.382597963591483,
      "grad_norm": 1.2327433296377421e-06,
      "learning_rate": 1.9617402036408517e-05,
      "loss": 0.0,
      "step": 98470
    },
    {
      "epoch": 30.3856834310398,
      "grad_norm": 0.0001370899990433827,
      "learning_rate": 1.9614316568960196e-05,
      "loss": 0.0042,
      "step": 98480
    },
    {
      "epoch": 30.38876889848812,
      "grad_norm": 1.5977515204212978e-06,
      "learning_rate": 1.961123110151188e-05,
      "loss": 0.0,
      "step": 98490
    },
    {
      "epoch": 30.39185436593644,
      "grad_norm": 0.00012013642844976857,
      "learning_rate": 1.9608145634063564e-05,
      "loss": 0.0012,
      "step": 98500
    },
    {
      "epoch": 30.394939833384758,
      "grad_norm": 0.00014509882021229714,
      "learning_rate": 1.9605060166615243e-05,
      "loss": 0.0,
      "step": 98510
    },
    {
      "epoch": 30.398025300833076,
      "grad_norm": 8.754649752518162e-05,
      "learning_rate": 1.9601974699166926e-05,
      "loss": 0.0001,
      "step": 98520
    },
    {
      "epoch": 30.401110768281395,
      "grad_norm": 1.307281536355731e-06,
      "learning_rate": 1.9598889231718605e-05,
      "loss": 0.0,
      "step": 98530
    },
    {
      "epoch": 30.404196235729714,
      "grad_norm": 4.606655420502648e-05,
      "learning_rate": 1.9595803764270288e-05,
      "loss": 0.0,
      "step": 98540
    },
    {
      "epoch": 30.407281703178032,
      "grad_norm": 8.850511790114979e-07,
      "learning_rate": 1.959271829682197e-05,
      "loss": 0.0,
      "step": 98550
    },
    {
      "epoch": 30.41036717062635,
      "grad_norm": 6.664898683084175e-05,
      "learning_rate": 1.958963282937365e-05,
      "loss": 0.001,
      "step": 98560
    },
    {
      "epoch": 30.41345263807467,
      "grad_norm": 0.004346560221165419,
      "learning_rate": 1.9586547361925335e-05,
      "loss": 0.0001,
      "step": 98570
    },
    {
      "epoch": 30.416538105522985,
      "grad_norm": 5.24922797922045e-05,
      "learning_rate": 1.9583461894477014e-05,
      "loss": 0.0029,
      "step": 98580
    },
    {
      "epoch": 30.419623572971304,
      "grad_norm": 0.02800901047885418,
      "learning_rate": 1.9580376427028697e-05,
      "loss": 0.0002,
      "step": 98590
    },
    {
      "epoch": 30.422709040419623,
      "grad_norm": 0.9706300497055054,
      "learning_rate": 1.9577290959580376e-05,
      "loss": 0.0003,
      "step": 98600
    },
    {
      "epoch": 30.42579450786794,
      "grad_norm": 3.535657242537127e-06,
      "learning_rate": 1.9574205492132058e-05,
      "loss": 0.0003,
      "step": 98610
    },
    {
      "epoch": 30.42887997531626,
      "grad_norm": 5.372801751946099e-05,
      "learning_rate": 1.957112002468374e-05,
      "loss": 0.0001,
      "step": 98620
    },
    {
      "epoch": 30.43196544276458,
      "grad_norm": 0.0001324625191045925,
      "learning_rate": 1.9568034557235423e-05,
      "loss": 0.0044,
      "step": 98630
    },
    {
      "epoch": 30.435050910212897,
      "grad_norm": 0.010567447170615196,
      "learning_rate": 1.9564949089787106e-05,
      "loss": 0.0,
      "step": 98640
    },
    {
      "epoch": 30.438136377661216,
      "grad_norm": 2.277388334274292,
      "learning_rate": 1.9561863622338785e-05,
      "loss": 0.005,
      "step": 98650
    },
    {
      "epoch": 30.441221845109535,
      "grad_norm": 6.283778930082917e-05,
      "learning_rate": 1.9558778154890467e-05,
      "loss": 0.0,
      "step": 98660
    },
    {
      "epoch": 30.444307312557854,
      "grad_norm": 1.2119910934416112e-05,
      "learning_rate": 1.955569268744215e-05,
      "loss": 0.0004,
      "step": 98670
    },
    {
      "epoch": 30.447392780006172,
      "grad_norm": 0.00034822081215679646,
      "learning_rate": 1.955260721999383e-05,
      "loss": 0.0,
      "step": 98680
    },
    {
      "epoch": 30.45047824745449,
      "grad_norm": 1.4583220945496578e-05,
      "learning_rate": 1.954952175254551e-05,
      "loss": 0.0002,
      "step": 98690
    },
    {
      "epoch": 30.453563714902806,
      "grad_norm": 0.00043248312431387603,
      "learning_rate": 1.9546436285097194e-05,
      "loss": 0.0005,
      "step": 98700
    },
    {
      "epoch": 30.456649182351125,
      "grad_norm": 0.007375875022262335,
      "learning_rate": 1.9543350817648876e-05,
      "loss": 0.0007,
      "step": 98710
    },
    {
      "epoch": 30.459734649799444,
      "grad_norm": 0.001797216827981174,
      "learning_rate": 1.9540265350200555e-05,
      "loss": 0.0,
      "step": 98720
    },
    {
      "epoch": 30.462820117247762,
      "grad_norm": 0.0028596564661711454,
      "learning_rate": 1.9537179882752238e-05,
      "loss": 0.0034,
      "step": 98730
    },
    {
      "epoch": 30.46590558469608,
      "grad_norm": 8.164245809894055e-05,
      "learning_rate": 1.953409441530392e-05,
      "loss": 0.0,
      "step": 98740
    },
    {
      "epoch": 30.4689910521444,
      "grad_norm": 0.00026726810028776526,
      "learning_rate": 1.95310089478556e-05,
      "loss": 0.0,
      "step": 98750
    },
    {
      "epoch": 30.47207651959272,
      "grad_norm": 1.7721323786190624e-07,
      "learning_rate": 1.9527923480407282e-05,
      "loss": 0.0,
      "step": 98760
    },
    {
      "epoch": 30.475161987041037,
      "grad_norm": 4.919817229165346e-07,
      "learning_rate": 1.9524838012958964e-05,
      "loss": 0.0,
      "step": 98770
    },
    {
      "epoch": 30.478247454489356,
      "grad_norm": 3.5319312701176386e-06,
      "learning_rate": 1.9521752545510647e-05,
      "loss": 0.0002,
      "step": 98780
    },
    {
      "epoch": 30.481332921937675,
      "grad_norm": 0.0005867573781870306,
      "learning_rate": 1.951866707806233e-05,
      "loss": 0.0024,
      "step": 98790
    },
    {
      "epoch": 30.484418389385993,
      "grad_norm": 9.932175453286618e-05,
      "learning_rate": 1.9515581610614008e-05,
      "loss": 0.0016,
      "step": 98800
    },
    {
      "epoch": 30.48750385683431,
      "grad_norm": 0.0002570051292423159,
      "learning_rate": 1.951249614316569e-05,
      "loss": 0.0,
      "step": 98810
    },
    {
      "epoch": 30.490589324282627,
      "grad_norm": 0.0008555622189305723,
      "learning_rate": 1.950941067571737e-05,
      "loss": 0.0001,
      "step": 98820
    },
    {
      "epoch": 30.493674791730946,
      "grad_norm": 0.014767318964004517,
      "learning_rate": 1.9506325208269056e-05,
      "loss": 0.0,
      "step": 98830
    },
    {
      "epoch": 30.496760259179265,
      "grad_norm": 0.0007968655554577708,
      "learning_rate": 1.9503239740820735e-05,
      "loss": 0.0002,
      "step": 98840
    },
    {
      "epoch": 30.499845726627584,
      "grad_norm": 0.03693723678588867,
      "learning_rate": 1.9500154273372417e-05,
      "loss": 0.0,
      "step": 98850
    },
    {
      "epoch": 30.502931194075902,
      "grad_norm": 2.6498138904571533,
      "learning_rate": 1.94970688059241e-05,
      "loss": 0.0035,
      "step": 98860
    },
    {
      "epoch": 30.50601666152422,
      "grad_norm": 1.2392889402690344e-05,
      "learning_rate": 1.949398333847578e-05,
      "loss": 0.0001,
      "step": 98870
    },
    {
      "epoch": 30.50910212897254,
      "grad_norm": 2.1498382920981385e-05,
      "learning_rate": 1.949089787102746e-05,
      "loss": 0.0,
      "step": 98880
    },
    {
      "epoch": 30.51218759642086,
      "grad_norm": 8.286997399409302e-07,
      "learning_rate": 1.9487812403579144e-05,
      "loss": 0.0037,
      "step": 98890
    },
    {
      "epoch": 30.515273063869177,
      "grad_norm": 0.0014217942953109741,
      "learning_rate": 1.9484726936130826e-05,
      "loss": 0.0,
      "step": 98900
    },
    {
      "epoch": 30.518358531317496,
      "grad_norm": 0.0048151761293411255,
      "learning_rate": 1.948164146868251e-05,
      "loss": 0.0,
      "step": 98910
    },
    {
      "epoch": 30.521443998765815,
      "grad_norm": 0.006580210756510496,
      "learning_rate": 1.9478556001234188e-05,
      "loss": 0.0002,
      "step": 98920
    },
    {
      "epoch": 30.52452946621413,
      "grad_norm": 6.9676575549237896e-06,
      "learning_rate": 1.947547053378587e-05,
      "loss": 0.0044,
      "step": 98930
    },
    {
      "epoch": 30.52761493366245,
      "grad_norm": 5.456621238408843e-06,
      "learning_rate": 1.947238506633755e-05,
      "loss": 0.0001,
      "step": 98940
    },
    {
      "epoch": 30.530700401110767,
      "grad_norm": 5.387998680816963e-05,
      "learning_rate": 1.9469299598889232e-05,
      "loss": 0.0,
      "step": 98950
    },
    {
      "epoch": 30.533785868559086,
      "grad_norm": 9.127559314947575e-05,
      "learning_rate": 1.9466214131440914e-05,
      "loss": 0.0,
      "step": 98960
    },
    {
      "epoch": 30.536871336007405,
      "grad_norm": 5.339233757695183e-05,
      "learning_rate": 1.9463128663992597e-05,
      "loss": 0.0002,
      "step": 98970
    },
    {
      "epoch": 30.539956803455723,
      "grad_norm": 2.530796882638242e-05,
      "learning_rate": 1.946004319654428e-05,
      "loss": 0.0,
      "step": 98980
    },
    {
      "epoch": 30.543042270904042,
      "grad_norm": 6.726045830873773e-05,
      "learning_rate": 1.945695772909596e-05,
      "loss": 0.0,
      "step": 98990
    },
    {
      "epoch": 30.54612773835236,
      "grad_norm": 1.221768616233021e-05,
      "learning_rate": 1.945387226164764e-05,
      "loss": 0.0,
      "step": 99000
    },
    {
      "epoch": 30.54921320580068,
      "grad_norm": 0.00016426049114670604,
      "learning_rate": 1.945078679419932e-05,
      "loss": 0.0017,
      "step": 99010
    },
    {
      "epoch": 30.552298673249,
      "grad_norm": 2.4452740490232827e-06,
      "learning_rate": 1.9447701326751002e-05,
      "loss": 0.0,
      "step": 99020
    },
    {
      "epoch": 30.555384140697317,
      "grad_norm": 2.6824436645256355e-06,
      "learning_rate": 1.9444615859302685e-05,
      "loss": 0.0026,
      "step": 99030
    },
    {
      "epoch": 30.558469608145636,
      "grad_norm": 1.978085265363916e-06,
      "learning_rate": 1.9441530391854367e-05,
      "loss": 0.0,
      "step": 99040
    },
    {
      "epoch": 30.56155507559395,
      "grad_norm": 0.0003607448597904295,
      "learning_rate": 1.943844492440605e-05,
      "loss": 0.0005,
      "step": 99050
    },
    {
      "epoch": 30.56464054304227,
      "grad_norm": 0.0007769181975163519,
      "learning_rate": 1.943535945695773e-05,
      "loss": 0.0,
      "step": 99060
    },
    {
      "epoch": 30.56772601049059,
      "grad_norm": 2.691027879714966,
      "learning_rate": 1.943227398950941e-05,
      "loss": 0.0045,
      "step": 99070
    },
    {
      "epoch": 30.570811477938907,
      "grad_norm": 2.912801573984325e-05,
      "learning_rate": 1.9429188522061094e-05,
      "loss": 0.0,
      "step": 99080
    },
    {
      "epoch": 30.573896945387226,
      "grad_norm": 0.000657489406876266,
      "learning_rate": 1.9426103054612773e-05,
      "loss": 0.0031,
      "step": 99090
    },
    {
      "epoch": 30.576982412835545,
      "grad_norm": 0.0008739876793697476,
      "learning_rate": 1.942301758716446e-05,
      "loss": 0.0,
      "step": 99100
    },
    {
      "epoch": 30.580067880283863,
      "grad_norm": 5.1785613322863355e-05,
      "learning_rate": 1.9419932119716138e-05,
      "loss": 0.0007,
      "step": 99110
    },
    {
      "epoch": 30.583153347732182,
      "grad_norm": 9.59690660238266e-05,
      "learning_rate": 1.941684665226782e-05,
      "loss": 0.0,
      "step": 99120
    },
    {
      "epoch": 30.5862388151805,
      "grad_norm": 1.2750463611155283e-05,
      "learning_rate": 1.94137611848195e-05,
      "loss": 0.0005,
      "step": 99130
    },
    {
      "epoch": 30.58932428262882,
      "grad_norm": 0.00016214749484788626,
      "learning_rate": 1.9410675717371182e-05,
      "loss": 0.0,
      "step": 99140
    },
    {
      "epoch": 30.592409750077138,
      "grad_norm": 9.850678907241672e-05,
      "learning_rate": 1.9407590249922864e-05,
      "loss": 0.0008,
      "step": 99150
    },
    {
      "epoch": 30.595495217525453,
      "grad_norm": 0.0010837912559509277,
      "learning_rate": 1.9404504782474544e-05,
      "loss": 0.0017,
      "step": 99160
    },
    {
      "epoch": 30.598580684973772,
      "grad_norm": 0.004544436000287533,
      "learning_rate": 1.940141931502623e-05,
      "loss": 0.0,
      "step": 99170
    },
    {
      "epoch": 30.60166615242209,
      "grad_norm": 4.192874621367082e-05,
      "learning_rate": 1.939833384757791e-05,
      "loss": 0.0,
      "step": 99180
    },
    {
      "epoch": 30.60475161987041,
      "grad_norm": 2.8702846975647844e-05,
      "learning_rate": 1.939524838012959e-05,
      "loss": 0.0,
      "step": 99190
    },
    {
      "epoch": 30.607837087318728,
      "grad_norm": 2.1160674805287272e-05,
      "learning_rate": 1.9392162912681273e-05,
      "loss": 0.0013,
      "step": 99200
    },
    {
      "epoch": 30.610922554767047,
      "grad_norm": 0.004045439418405294,
      "learning_rate": 1.9389077445232953e-05,
      "loss": 0.0001,
      "step": 99210
    },
    {
      "epoch": 30.614008022215366,
      "grad_norm": 1.4672464203613345e-05,
      "learning_rate": 1.9385991977784635e-05,
      "loss": 0.0002,
      "step": 99220
    },
    {
      "epoch": 30.617093489663684,
      "grad_norm": 7.702379662077874e-05,
      "learning_rate": 1.9382906510336314e-05,
      "loss": 0.0,
      "step": 99230
    },
    {
      "epoch": 30.620178957112003,
      "grad_norm": 3.8416586903622374e-05,
      "learning_rate": 1.9379821042888e-05,
      "loss": 0.0014,
      "step": 99240
    },
    {
      "epoch": 30.623264424560322,
      "grad_norm": 1.8145889043807983,
      "learning_rate": 1.937673557543968e-05,
      "loss": 0.0013,
      "step": 99250
    },
    {
      "epoch": 30.62634989200864,
      "grad_norm": 0.0004649402981158346,
      "learning_rate": 1.937365010799136e-05,
      "loss": 0.0,
      "step": 99260
    },
    {
      "epoch": 30.62943535945696,
      "grad_norm": 9.576487354934216e-05,
      "learning_rate": 1.9370564640543044e-05,
      "loss": 0.0004,
      "step": 99270
    },
    {
      "epoch": 30.632520826905274,
      "grad_norm": 0.0003487391513772309,
      "learning_rate": 1.9367479173094723e-05,
      "loss": 0.0,
      "step": 99280
    },
    {
      "epoch": 30.635606294353593,
      "grad_norm": 0.00018893333617597818,
      "learning_rate": 1.9364393705646406e-05,
      "loss": 0.0,
      "step": 99290
    },
    {
      "epoch": 30.638691761801912,
      "grad_norm": 0.0003258816432207823,
      "learning_rate": 1.9361308238198088e-05,
      "loss": 0.0,
      "step": 99300
    },
    {
      "epoch": 30.64177722925023,
      "grad_norm": 0.013789975084364414,
      "learning_rate": 1.935822277074977e-05,
      "loss": 0.0,
      "step": 99310
    },
    {
      "epoch": 30.64486269669855,
      "grad_norm": 2.0103394490433857e-05,
      "learning_rate": 1.9355137303301453e-05,
      "loss": 0.0002,
      "step": 99320
    },
    {
      "epoch": 30.647948164146868,
      "grad_norm": 4.680034180637449e-05,
      "learning_rate": 1.9352051835853132e-05,
      "loss": 0.0001,
      "step": 99330
    },
    {
      "epoch": 30.651033631595187,
      "grad_norm": 0.02103743702173233,
      "learning_rate": 1.9348966368404815e-05,
      "loss": 0.0014,
      "step": 99340
    },
    {
      "epoch": 30.654119099043506,
      "grad_norm": 0.00014412305608857423,
      "learning_rate": 1.9345880900956494e-05,
      "loss": 0.0,
      "step": 99350
    },
    {
      "epoch": 30.657204566491824,
      "grad_norm": 0.3389447331428528,
      "learning_rate": 1.9342795433508176e-05,
      "loss": 0.0001,
      "step": 99360
    },
    {
      "epoch": 30.660290033940143,
      "grad_norm": 0.0022814625408500433,
      "learning_rate": 1.933970996605986e-05,
      "loss": 0.0026,
      "step": 99370
    },
    {
      "epoch": 30.66337550138846,
      "grad_norm": 0.00011579679267015308,
      "learning_rate": 1.933662449861154e-05,
      "loss": 0.0003,
      "step": 99380
    },
    {
      "epoch": 30.66646096883678,
      "grad_norm": 0.00016464160580653697,
      "learning_rate": 1.9333539031163224e-05,
      "loss": 0.001,
      "step": 99390
    },
    {
      "epoch": 30.669546436285096,
      "grad_norm": 0.0002592719974927604,
      "learning_rate": 1.9330453563714903e-05,
      "loss": 0.0,
      "step": 99400
    },
    {
      "epoch": 30.672631903733414,
      "grad_norm": 8.048944437177852e-06,
      "learning_rate": 1.9327368096266585e-05,
      "loss": 0.0,
      "step": 99410
    },
    {
      "epoch": 30.675717371181733,
      "grad_norm": 0.12801647186279297,
      "learning_rate": 1.9324282628818268e-05,
      "loss": 0.0002,
      "step": 99420
    },
    {
      "epoch": 30.67880283863005,
      "grad_norm": 6.598135223612189e-05,
      "learning_rate": 1.9321197161369947e-05,
      "loss": 0.0,
      "step": 99430
    },
    {
      "epoch": 30.68188830607837,
      "grad_norm": 7.462437497451901e-05,
      "learning_rate": 1.9318111693921633e-05,
      "loss": 0.0121,
      "step": 99440
    },
    {
      "epoch": 30.68497377352669,
      "grad_norm": 0.0013855709694325924,
      "learning_rate": 1.931502622647331e-05,
      "loss": 0.0,
      "step": 99450
    },
    {
      "epoch": 30.688059240975008,
      "grad_norm": 0.00010606626892695203,
      "learning_rate": 1.9311940759024994e-05,
      "loss": 0.0,
      "step": 99460
    },
    {
      "epoch": 30.691144708423327,
      "grad_norm": 1.2898378372483421e-05,
      "learning_rate": 1.9308855291576673e-05,
      "loss": 0.0014,
      "step": 99470
    },
    {
      "epoch": 30.694230175871645,
      "grad_norm": 5.489793238666607e-06,
      "learning_rate": 1.9305769824128356e-05,
      "loss": 0.0,
      "step": 99480
    },
    {
      "epoch": 30.697315643319964,
      "grad_norm": 0.0003510513051878661,
      "learning_rate": 1.9302684356680038e-05,
      "loss": 0.0001,
      "step": 99490
    },
    {
      "epoch": 30.700401110768283,
      "grad_norm": 0.0001755452249199152,
      "learning_rate": 1.929959888923172e-05,
      "loss": 0.0007,
      "step": 99500
    },
    {
      "epoch": 30.703486578216598,
      "grad_norm": 0.0018394383369013667,
      "learning_rate": 1.9296513421783403e-05,
      "loss": 0.0,
      "step": 99510
    },
    {
      "epoch": 30.706572045664917,
      "grad_norm": 1.617664565856103e-05,
      "learning_rate": 1.9293427954335082e-05,
      "loss": 0.0001,
      "step": 99520
    },
    {
      "epoch": 30.709657513113235,
      "grad_norm": 5.396098276833072e-05,
      "learning_rate": 1.9290342486886765e-05,
      "loss": 0.0,
      "step": 99530
    },
    {
      "epoch": 30.712742980561554,
      "grad_norm": 6.1201055359561e-05,
      "learning_rate": 1.9287257019438447e-05,
      "loss": 0.0002,
      "step": 99540
    },
    {
      "epoch": 30.715828448009873,
      "grad_norm": 0.0001086127376765944,
      "learning_rate": 1.9284171551990126e-05,
      "loss": 0.0,
      "step": 99550
    },
    {
      "epoch": 30.71891391545819,
      "grad_norm": 0.0001828085514716804,
      "learning_rate": 1.928108608454181e-05,
      "loss": 0.0003,
      "step": 99560
    },
    {
      "epoch": 30.72199938290651,
      "grad_norm": 2.588393908808939e-05,
      "learning_rate": 1.927800061709349e-05,
      "loss": 0.0,
      "step": 99570
    },
    {
      "epoch": 30.72508485035483,
      "grad_norm": 3.7258266729622846e-06,
      "learning_rate": 1.9274915149645174e-05,
      "loss": 0.0,
      "step": 99580
    },
    {
      "epoch": 30.728170317803148,
      "grad_norm": 2.956366188300308e-05,
      "learning_rate": 1.9271829682196853e-05,
      "loss": 0.0003,
      "step": 99590
    },
    {
      "epoch": 30.731255785251467,
      "grad_norm": 3.6791963793803006e-05,
      "learning_rate": 1.9268744214748535e-05,
      "loss": 0.0,
      "step": 99600
    },
    {
      "epoch": 30.734341252699785,
      "grad_norm": 0.002262540627270937,
      "learning_rate": 1.9265658747300218e-05,
      "loss": 0.0,
      "step": 99610
    },
    {
      "epoch": 30.737426720148104,
      "grad_norm": 2.4689218207640806e-06,
      "learning_rate": 1.9262573279851897e-05,
      "loss": 0.0,
      "step": 99620
    },
    {
      "epoch": 30.740512187596423,
      "grad_norm": 1.637719469727017e-05,
      "learning_rate": 1.925948781240358e-05,
      "loss": 0.0004,
      "step": 99630
    },
    {
      "epoch": 30.743597655044738,
      "grad_norm": 2.8918709631398087e-06,
      "learning_rate": 1.9256402344955262e-05,
      "loss": 0.0006,
      "step": 99640
    },
    {
      "epoch": 30.746683122493057,
      "grad_norm": 1.362974307994591e-05,
      "learning_rate": 1.9253316877506944e-05,
      "loss": 0.0,
      "step": 99650
    },
    {
      "epoch": 30.749768589941375,
      "grad_norm": 4.1120265450445e-06,
      "learning_rate": 1.9250231410058627e-05,
      "loss": 0.0,
      "step": 99660
    },
    {
      "epoch": 30.752854057389694,
      "grad_norm": 0.0009767982410266995,
      "learning_rate": 1.9247145942610306e-05,
      "loss": 0.0001,
      "step": 99670
    },
    {
      "epoch": 30.755939524838013,
      "grad_norm": 0.00020857954223174602,
      "learning_rate": 1.9244060475161988e-05,
      "loss": 0.0009,
      "step": 99680
    },
    {
      "epoch": 30.75902499228633,
      "grad_norm": 1.3776362720818724e-05,
      "learning_rate": 1.9240975007713667e-05,
      "loss": 0.0,
      "step": 99690
    },
    {
      "epoch": 30.76211045973465,
      "grad_norm": 0.000208062439924106,
      "learning_rate": 1.9237889540265353e-05,
      "loss": 0.0002,
      "step": 99700
    },
    {
      "epoch": 30.76519592718297,
      "grad_norm": 0.0005466428119689226,
      "learning_rate": 1.9234804072817032e-05,
      "loss": 0.0,
      "step": 99710
    },
    {
      "epoch": 30.768281394631288,
      "grad_norm": 0.00044213698129169643,
      "learning_rate": 1.9231718605368715e-05,
      "loss": 0.0008,
      "step": 99720
    },
    {
      "epoch": 30.771366862079606,
      "grad_norm": 5.51661378267454e-06,
      "learning_rate": 1.9228633137920397e-05,
      "loss": 0.0,
      "step": 99730
    },
    {
      "epoch": 30.774452329527925,
      "grad_norm": 0.1992574781179428,
      "learning_rate": 1.9225547670472076e-05,
      "loss": 0.0001,
      "step": 99740
    },
    {
      "epoch": 30.77753779697624,
      "grad_norm": 0.050529129803180695,
      "learning_rate": 1.922246220302376e-05,
      "loss": 0.0,
      "step": 99750
    },
    {
      "epoch": 30.78062326442456,
      "grad_norm": 2.115590359608177e-05,
      "learning_rate": 1.9219376735575438e-05,
      "loss": 0.0002,
      "step": 99760
    },
    {
      "epoch": 30.783708731872878,
      "grad_norm": 9.311783651355654e-05,
      "learning_rate": 1.9216291268127124e-05,
      "loss": 0.0,
      "step": 99770
    },
    {
      "epoch": 30.786794199321196,
      "grad_norm": 0.00109916424844414,
      "learning_rate": 1.9213205800678806e-05,
      "loss": 0.0079,
      "step": 99780
    },
    {
      "epoch": 30.789879666769515,
      "grad_norm": 0.014252855442464352,
      "learning_rate": 1.9210120333230485e-05,
      "loss": 0.0,
      "step": 99790
    },
    {
      "epoch": 30.792965134217834,
      "grad_norm": 2.369392177570262e-06,
      "learning_rate": 1.9207034865782168e-05,
      "loss": 0.0007,
      "step": 99800
    },
    {
      "epoch": 30.796050601666153,
      "grad_norm": 0.00810839794576168,
      "learning_rate": 1.9203949398333847e-05,
      "loss": 0.0,
      "step": 99810
    },
    {
      "epoch": 30.79913606911447,
      "grad_norm": 6.984579158597626e-06,
      "learning_rate": 1.920086393088553e-05,
      "loss": 0.0004,
      "step": 99820
    },
    {
      "epoch": 30.80222153656279,
      "grad_norm": 0.0021170275285840034,
      "learning_rate": 1.9197778463437212e-05,
      "loss": 0.0002,
      "step": 99830
    },
    {
      "epoch": 30.80530700401111,
      "grad_norm": 0.00010139818186871707,
      "learning_rate": 1.9194692995988894e-05,
      "loss": 0.0023,
      "step": 99840
    },
    {
      "epoch": 30.808392471459427,
      "grad_norm": 3.5485227272147313e-06,
      "learning_rate": 1.9191607528540577e-05,
      "loss": 0.0,
      "step": 99850
    },
    {
      "epoch": 30.811477938907746,
      "grad_norm": 0.00015933169925119728,
      "learning_rate": 1.9188522061092256e-05,
      "loss": 0.0006,
      "step": 99860
    },
    {
      "epoch": 30.81456340635606,
      "grad_norm": 9.039815267897211e-06,
      "learning_rate": 1.918543659364394e-05,
      "loss": 0.0,
      "step": 99870
    },
    {
      "epoch": 30.81764887380438,
      "grad_norm": 0.01594247855246067,
      "learning_rate": 1.9182351126195617e-05,
      "loss": 0.0,
      "step": 99880
    },
    {
      "epoch": 30.8207343412527,
      "grad_norm": 1.213131872646045e-05,
      "learning_rate": 1.91792656587473e-05,
      "loss": 0.0,
      "step": 99890
    },
    {
      "epoch": 30.823819808701018,
      "grad_norm": 7.71462237025844e-06,
      "learning_rate": 1.9176180191298982e-05,
      "loss": 0.0001,
      "step": 99900
    },
    {
      "epoch": 30.826905276149336,
      "grad_norm": 1.9832317775581032e-05,
      "learning_rate": 1.9173094723850665e-05,
      "loss": 0.0,
      "step": 99910
    },
    {
      "epoch": 30.829990743597655,
      "grad_norm": 8.376274490728974e-05,
      "learning_rate": 1.9170009256402347e-05,
      "loss": 0.0003,
      "step": 99920
    },
    {
      "epoch": 30.833076211045974,
      "grad_norm": 3.4997174225281924e-05,
      "learning_rate": 1.9166923788954026e-05,
      "loss": 0.0024,
      "step": 99930
    },
    {
      "epoch": 30.836161678494292,
      "grad_norm": 8.761429853620939e-06,
      "learning_rate": 1.916383832150571e-05,
      "loss": 0.0,
      "step": 99940
    },
    {
      "epoch": 30.83924714594261,
      "grad_norm": 0.00018857151735574007,
      "learning_rate": 1.916075285405739e-05,
      "loss": 0.0,
      "step": 99950
    },
    {
      "epoch": 30.84233261339093,
      "grad_norm": 0.0001873008586699143,
      "learning_rate": 1.915766738660907e-05,
      "loss": 0.0,
      "step": 99960
    },
    {
      "epoch": 30.84541808083925,
      "grad_norm": 0.13729345798492432,
      "learning_rate": 1.9154581919160756e-05,
      "loss": 0.0001,
      "step": 99970
    },
    {
      "epoch": 30.848503548287567,
      "grad_norm": 0.0016683033900335431,
      "learning_rate": 1.9151496451712435e-05,
      "loss": 0.0008,
      "step": 99980
    },
    {
      "epoch": 30.851589015735883,
      "grad_norm": 4.722939195289655e-07,
      "learning_rate": 1.9148410984264118e-05,
      "loss": 0.0,
      "step": 99990
    },
    {
      "epoch": 30.8546744831842,
      "grad_norm": 2.5760360585991293e-05,
      "learning_rate": 1.9145325516815797e-05,
      "loss": 0.0,
      "step": 100000
    },
    {
      "epoch": 30.85775995063252,
      "grad_norm": 4.174187779426575e-06,
      "learning_rate": 1.914224004936748e-05,
      "loss": 0.0001,
      "step": 100010
    },
    {
      "epoch": 30.86084541808084,
      "grad_norm": 0.00038277357816696167,
      "learning_rate": 1.9139154581919162e-05,
      "loss": 0.0002,
      "step": 100020
    },
    {
      "epoch": 30.863930885529157,
      "grad_norm": 5.026729922974482e-05,
      "learning_rate": 1.913606911447084e-05,
      "loss": 0.0,
      "step": 100030
    },
    {
      "epoch": 30.867016352977476,
      "grad_norm": 0.00010114273027284071,
      "learning_rate": 1.9132983647022527e-05,
      "loss": 0.0,
      "step": 100040
    },
    {
      "epoch": 30.870101820425795,
      "grad_norm": 5.368081588130735e-07,
      "learning_rate": 1.9129898179574206e-05,
      "loss": 0.0,
      "step": 100050
    },
    {
      "epoch": 30.873187287874114,
      "grad_norm": 1.2593038263730705e-05,
      "learning_rate": 1.912681271212589e-05,
      "loss": 0.0001,
      "step": 100060
    },
    {
      "epoch": 30.876272755322432,
      "grad_norm": 2.520890484447591e-05,
      "learning_rate": 1.912372724467757e-05,
      "loss": 0.0,
      "step": 100070
    },
    {
      "epoch": 30.87935822277075,
      "grad_norm": 1.1227110007894225e-05,
      "learning_rate": 1.912064177722925e-05,
      "loss": 0.0001,
      "step": 100080
    },
    {
      "epoch": 30.88244369021907,
      "grad_norm": 0.004378663841634989,
      "learning_rate": 1.9117556309780933e-05,
      "loss": 0.0,
      "step": 100090
    },
    {
      "epoch": 30.885529157667385,
      "grad_norm": 1.0939000276266597e-05,
      "learning_rate": 1.911447084233261e-05,
      "loss": 0.0,
      "step": 100100
    },
    {
      "epoch": 30.888614625115704,
      "grad_norm": 0.011057436466217041,
      "learning_rate": 1.9111385374884298e-05,
      "loss": 0.0054,
      "step": 100110
    },
    {
      "epoch": 30.891700092564022,
      "grad_norm": 0.0001569719024701044,
      "learning_rate": 1.9108299907435977e-05,
      "loss": 0.0,
      "step": 100120
    },
    {
      "epoch": 30.89478556001234,
      "grad_norm": 0.00023803970543667674,
      "learning_rate": 1.910521443998766e-05,
      "loss": 0.0,
      "step": 100130
    },
    {
      "epoch": 30.89787102746066,
      "grad_norm": 5.179505023988895e-06,
      "learning_rate": 1.910212897253934e-05,
      "loss": 0.0,
      "step": 100140
    },
    {
      "epoch": 30.90095649490898,
      "grad_norm": 0.00043251289753243327,
      "learning_rate": 1.909904350509102e-05,
      "loss": 0.0003,
      "step": 100150
    },
    {
      "epoch": 30.904041962357297,
      "grad_norm": 1.9961935322498903e-06,
      "learning_rate": 1.9095958037642703e-05,
      "loss": 0.0,
      "step": 100160
    },
    {
      "epoch": 30.907127429805616,
      "grad_norm": 1.0459019428310512e-08,
      "learning_rate": 1.9092872570194386e-05,
      "loss": 0.0038,
      "step": 100170
    },
    {
      "epoch": 30.910212897253935,
      "grad_norm": 9.423460141988471e-05,
      "learning_rate": 1.9089787102746068e-05,
      "loss": 0.0,
      "step": 100180
    },
    {
      "epoch": 30.913298364702253,
      "grad_norm": 9.220518404617906e-05,
      "learning_rate": 1.908670163529775e-05,
      "loss": 0.0004,
      "step": 100190
    },
    {
      "epoch": 30.916383832150572,
      "grad_norm": 0.0001922313094837591,
      "learning_rate": 1.908361616784943e-05,
      "loss": 0.0023,
      "step": 100200
    },
    {
      "epoch": 30.91946929959889,
      "grad_norm": 2.5742190700839274e-05,
      "learning_rate": 1.9080530700401112e-05,
      "loss": 0.0,
      "step": 100210
    },
    {
      "epoch": 30.922554767047206,
      "grad_norm": 7.192418252088828e-06,
      "learning_rate": 1.907744523295279e-05,
      "loss": 0.0,
      "step": 100220
    },
    {
      "epoch": 30.925640234495525,
      "grad_norm": 3.7332858937588753e-06,
      "learning_rate": 1.9074359765504474e-05,
      "loss": 0.0,
      "step": 100230
    },
    {
      "epoch": 30.928725701943844,
      "grad_norm": 0.0009126865188591182,
      "learning_rate": 1.9071274298056156e-05,
      "loss": 0.0003,
      "step": 100240
    },
    {
      "epoch": 30.931811169392162,
      "grad_norm": 0.3222329914569855,
      "learning_rate": 1.906818883060784e-05,
      "loss": 0.0012,
      "step": 100250
    },
    {
      "epoch": 30.93489663684048,
      "grad_norm": 9.862746082944795e-05,
      "learning_rate": 1.906510336315952e-05,
      "loss": 0.0,
      "step": 100260
    },
    {
      "epoch": 30.9379821042888,
      "grad_norm": 2.0242732716724277e-05,
      "learning_rate": 1.90620178957112e-05,
      "loss": 0.0,
      "step": 100270
    },
    {
      "epoch": 30.94106757173712,
      "grad_norm": 0.000321242434438318,
      "learning_rate": 1.9058932428262883e-05,
      "loss": 0.0,
      "step": 100280
    },
    {
      "epoch": 30.944153039185437,
      "grad_norm": 0.0002923903230112046,
      "learning_rate": 1.9055846960814562e-05,
      "loss": 0.0001,
      "step": 100290
    },
    {
      "epoch": 30.947238506633756,
      "grad_norm": 0.0015972403343766928,
      "learning_rate": 1.9052761493366244e-05,
      "loss": 0.0,
      "step": 100300
    },
    {
      "epoch": 30.950323974082075,
      "grad_norm": 3.478012104096706e-06,
      "learning_rate": 1.904967602591793e-05,
      "loss": 0.0,
      "step": 100310
    },
    {
      "epoch": 30.953409441530393,
      "grad_norm": 0.0050644357688724995,
      "learning_rate": 1.904659055846961e-05,
      "loss": 0.0,
      "step": 100320
    },
    {
      "epoch": 30.956494908978712,
      "grad_norm": 0.028656378388404846,
      "learning_rate": 1.904350509102129e-05,
      "loss": 0.0,
      "step": 100330
    },
    {
      "epoch": 30.959580376427027,
      "grad_norm": 0.027132172137498856,
      "learning_rate": 1.904041962357297e-05,
      "loss": 0.0,
      "step": 100340
    },
    {
      "epoch": 30.962665843875346,
      "grad_norm": 2.7017915726901265e-07,
      "learning_rate": 1.9037334156124653e-05,
      "loss": 0.0,
      "step": 100350
    },
    {
      "epoch": 30.965751311323665,
      "grad_norm": 2.8625987397390418e-05,
      "learning_rate": 1.9034248688676336e-05,
      "loss": 0.0001,
      "step": 100360
    },
    {
      "epoch": 30.968836778771983,
      "grad_norm": 0.0003033899702131748,
      "learning_rate": 1.9031163221228018e-05,
      "loss": 0.0,
      "step": 100370
    },
    {
      "epoch": 30.971922246220302,
      "grad_norm": 2.708234433157486e-06,
      "learning_rate": 1.90280777537797e-05,
      "loss": 0.0001,
      "step": 100380
    },
    {
      "epoch": 30.97500771366862,
      "grad_norm": 0.0008369726128876209,
      "learning_rate": 1.902499228633138e-05,
      "loss": 0.0049,
      "step": 100390
    },
    {
      "epoch": 30.97809318111694,
      "grad_norm": 0.005356959532946348,
      "learning_rate": 1.9021906818883062e-05,
      "loss": 0.0,
      "step": 100400
    },
    {
      "epoch": 30.98117864856526,
      "grad_norm": 2.038144657490193e-06,
      "learning_rate": 1.901882135143474e-05,
      "loss": 0.0,
      "step": 100410
    },
    {
      "epoch": 30.984264116013577,
      "grad_norm": 5.741097265854478e-05,
      "learning_rate": 1.9015735883986424e-05,
      "loss": 0.0,
      "step": 100420
    },
    {
      "epoch": 30.987349583461896,
      "grad_norm": 0.08650820702314377,
      "learning_rate": 1.9012650416538106e-05,
      "loss": 0.0022,
      "step": 100430
    },
    {
      "epoch": 30.990435050910214,
      "grad_norm": 6.643524841365434e-08,
      "learning_rate": 1.900956494908979e-05,
      "loss": 0.0011,
      "step": 100440
    },
    {
      "epoch": 30.99352051835853,
      "grad_norm": 0.015344811603426933,
      "learning_rate": 1.900647948164147e-05,
      "loss": 0.0,
      "step": 100450
    },
    {
      "epoch": 30.99660598580685,
      "grad_norm": 0.0024889977648854256,
      "learning_rate": 1.900339401419315e-05,
      "loss": 0.0,
      "step": 100460
    },
    {
      "epoch": 30.999691453255167,
      "grad_norm": 6.467587081715465e-05,
      "learning_rate": 1.9000308546744833e-05,
      "loss": 0.0,
      "step": 100470
    },
    {
      "epoch": 31.0,
      "eval_accuracy_branch1": 0.9999614208693807,
      "eval_accuracy_branch2": 0.3945777031914586,
      "eval_f1_branch1": 0.9999676805967603,
      "eval_f1_branch2": 0.38159128288723865,
      "eval_loss": 1.2561738913063891e-05,
      "eval_precision_branch1": 0.9999673960532,
      "eval_precision_branch2": 0.4974456035957783,
      "eval_recall_branch1": 0.999967965885144,
      "eval_recall_branch2": 0.49824223836115855,
      "eval_runtime": 233.1542,
      "eval_samples_per_second": 444.697,
      "eval_steps_per_second": 55.59,
      "step": 100471
    },
    {
      "epoch": 31.002776920703486,
      "grad_norm": 0.0006832292419858277,
      "learning_rate": 1.8997223079296515e-05,
      "loss": 0.0,
      "step": 100480
    },
    {
      "epoch": 31.005862388151805,
      "grad_norm": 0.0023220484144985676,
      "learning_rate": 1.8994137611848194e-05,
      "loss": 0.0,
      "step": 100490
    },
    {
      "epoch": 31.008947855600123,
      "grad_norm": 0.00022312493820209056,
      "learning_rate": 1.8991052144399877e-05,
      "loss": 0.0002,
      "step": 100500
    },
    {
      "epoch": 31.012033323048442,
      "grad_norm": 8.890940989658702e-06,
      "learning_rate": 1.898796667695156e-05,
      "loss": 0.0,
      "step": 100510
    },
    {
      "epoch": 31.01511879049676,
      "grad_norm": 0.00013610722089651972,
      "learning_rate": 1.8984881209503242e-05,
      "loss": 0.0,
      "step": 100520
    },
    {
      "epoch": 31.01820425794508,
      "grad_norm": 1.7451066014473327e-05,
      "learning_rate": 1.898179574205492e-05,
      "loss": 0.0001,
      "step": 100530
    },
    {
      "epoch": 31.021289725393398,
      "grad_norm": 0.006430861074477434,
      "learning_rate": 1.8978710274606603e-05,
      "loss": 0.0,
      "step": 100540
    },
    {
      "epoch": 31.024375192841717,
      "grad_norm": 0.00011254796845605597,
      "learning_rate": 1.8975624807158286e-05,
      "loss": 0.0013,
      "step": 100550
    },
    {
      "epoch": 31.027460660290036,
      "grad_norm": 0.00035021972144022584,
      "learning_rate": 1.8972539339709965e-05,
      "loss": 0.0002,
      "step": 100560
    },
    {
      "epoch": 31.03054612773835,
      "grad_norm": 0.00021580708562396467,
      "learning_rate": 1.8969453872261647e-05,
      "loss": 0.0,
      "step": 100570
    },
    {
      "epoch": 31.03363159518667,
      "grad_norm": 0.0008037643856368959,
      "learning_rate": 1.896636840481333e-05,
      "loss": 0.0,
      "step": 100580
    },
    {
      "epoch": 31.036717062634988,
      "grad_norm": 2.0687400592578342e-06,
      "learning_rate": 1.8963282937365012e-05,
      "loss": 0.0005,
      "step": 100590
    },
    {
      "epoch": 31.039802530083307,
      "grad_norm": 0.022725364193320274,
      "learning_rate": 1.8960197469916695e-05,
      "loss": 0.0,
      "step": 100600
    },
    {
      "epoch": 31.042887997531626,
      "grad_norm": 7.426402817145572e-07,
      "learning_rate": 1.8957112002468374e-05,
      "loss": 0.0,
      "step": 100610
    },
    {
      "epoch": 31.045973464979944,
      "grad_norm": 0.275009423494339,
      "learning_rate": 1.8954026535020056e-05,
      "loss": 0.0001,
      "step": 100620
    },
    {
      "epoch": 31.049058932428263,
      "grad_norm": 0.05737803503870964,
      "learning_rate": 1.8950941067571735e-05,
      "loss": 0.0001,
      "step": 100630
    },
    {
      "epoch": 31.052144399876582,
      "grad_norm": 0.00022085668751969934,
      "learning_rate": 1.894785560012342e-05,
      "loss": 0.0,
      "step": 100640
    },
    {
      "epoch": 31.0552298673249,
      "grad_norm": 2.1564668713836e-05,
      "learning_rate": 1.89447701326751e-05,
      "loss": 0.0001,
      "step": 100650
    },
    {
      "epoch": 31.05831533477322,
      "grad_norm": 8.078852715698304e-07,
      "learning_rate": 1.8941684665226783e-05,
      "loss": 0.0,
      "step": 100660
    },
    {
      "epoch": 31.061400802221538,
      "grad_norm": 3.725815986399539e-05,
      "learning_rate": 1.8938599197778465e-05,
      "loss": 0.0,
      "step": 100670
    },
    {
      "epoch": 31.064486269669857,
      "grad_norm": 3.6204954085405916e-05,
      "learning_rate": 1.8935513730330144e-05,
      "loss": 0.0,
      "step": 100680
    },
    {
      "epoch": 31.067571737118172,
      "grad_norm": 3.4260578104294837e-05,
      "learning_rate": 1.8932428262881827e-05,
      "loss": 0.0001,
      "step": 100690
    },
    {
      "epoch": 31.07065720456649,
      "grad_norm": 5.678978709511284e-07,
      "learning_rate": 1.892934279543351e-05,
      "loss": 0.0001,
      "step": 100700
    },
    {
      "epoch": 31.07374267201481,
      "grad_norm": 6.992635917413281e-06,
      "learning_rate": 1.8926257327985192e-05,
      "loss": 0.0,
      "step": 100710
    },
    {
      "epoch": 31.076828139463128,
      "grad_norm": 0.002307130955159664,
      "learning_rate": 1.8923171860536874e-05,
      "loss": 0.0,
      "step": 100720
    },
    {
      "epoch": 31.079913606911447,
      "grad_norm": 2.3534226784249768e-05,
      "learning_rate": 1.8920086393088553e-05,
      "loss": 0.0,
      "step": 100730
    },
    {
      "epoch": 31.082999074359766,
      "grad_norm": 6.724779086653143e-05,
      "learning_rate": 1.8917000925640236e-05,
      "loss": 0.0002,
      "step": 100740
    },
    {
      "epoch": 31.086084541808084,
      "grad_norm": 0.0003430881770327687,
      "learning_rate": 1.8913915458191915e-05,
      "loss": 0.0,
      "step": 100750
    },
    {
      "epoch": 31.089170009256403,
      "grad_norm": 3.745291905943304e-05,
      "learning_rate": 1.8910829990743598e-05,
      "loss": 0.0,
      "step": 100760
    },
    {
      "epoch": 31.09225547670472,
      "grad_norm": 0.0005464734858833253,
      "learning_rate": 1.890774452329528e-05,
      "loss": 0.0001,
      "step": 100770
    },
    {
      "epoch": 31.09534094415304,
      "grad_norm": 3.607607084177289e-07,
      "learning_rate": 1.8904659055846962e-05,
      "loss": 0.0,
      "step": 100780
    },
    {
      "epoch": 31.09842641160136,
      "grad_norm": 0.00011299547622911632,
      "learning_rate": 1.8901573588398645e-05,
      "loss": 0.0,
      "step": 100790
    },
    {
      "epoch": 31.101511879049674,
      "grad_norm": 2.783897980407346e-05,
      "learning_rate": 1.8898488120950324e-05,
      "loss": 0.0004,
      "step": 100800
    },
    {
      "epoch": 31.104597346497993,
      "grad_norm": 0.00010180167009821162,
      "learning_rate": 1.8895402653502007e-05,
      "loss": 0.0,
      "step": 100810
    },
    {
      "epoch": 31.10768281394631,
      "grad_norm": 0.02592102624475956,
      "learning_rate": 1.889231718605369e-05,
      "loss": 0.0004,
      "step": 100820
    },
    {
      "epoch": 31.11076828139463,
      "grad_norm": 2.234486601082608e-06,
      "learning_rate": 1.8889231718605368e-05,
      "loss": 0.0003,
      "step": 100830
    },
    {
      "epoch": 31.11385374884295,
      "grad_norm": 0.017971742898225784,
      "learning_rate": 1.8886146251157054e-05,
      "loss": 0.0,
      "step": 100840
    },
    {
      "epoch": 31.116939216291268,
      "grad_norm": 0.008802004158496857,
      "learning_rate": 1.8883060783708733e-05,
      "loss": 0.005,
      "step": 100850
    },
    {
      "epoch": 31.120024683739587,
      "grad_norm": 2.920488213931094e-06,
      "learning_rate": 1.8879975316260416e-05,
      "loss": 0.0,
      "step": 100860
    },
    {
      "epoch": 31.123110151187905,
      "grad_norm": 0.00014858346548862755,
      "learning_rate": 1.8876889848812095e-05,
      "loss": 0.0,
      "step": 100870
    },
    {
      "epoch": 31.126195618636224,
      "grad_norm": 1.5418318355386873e-07,
      "learning_rate": 1.8873804381363777e-05,
      "loss": 0.0006,
      "step": 100880
    },
    {
      "epoch": 31.129281086084543,
      "grad_norm": 1.0836115649226485e-07,
      "learning_rate": 1.887071891391546e-05,
      "loss": 0.0,
      "step": 100890
    },
    {
      "epoch": 31.13236655353286,
      "grad_norm": 4.710467328550294e-05,
      "learning_rate": 1.886763344646714e-05,
      "loss": 0.0,
      "step": 100900
    },
    {
      "epoch": 31.13545202098118,
      "grad_norm": 0.0005330527783371508,
      "learning_rate": 1.8864547979018825e-05,
      "loss": 0.0,
      "step": 100910
    },
    {
      "epoch": 31.138537488429495,
      "grad_norm": 0.0002454755885992199,
      "learning_rate": 1.8861462511570504e-05,
      "loss": 0.0,
      "step": 100920
    },
    {
      "epoch": 31.141622955877814,
      "grad_norm": 1.0059989108412992e-05,
      "learning_rate": 1.8858377044122186e-05,
      "loss": 0.0006,
      "step": 100930
    },
    {
      "epoch": 31.144708423326133,
      "grad_norm": 1.2313922525208909e-05,
      "learning_rate": 1.885529157667387e-05,
      "loss": 0.0001,
      "step": 100940
    },
    {
      "epoch": 31.14779389077445,
      "grad_norm": 4.7734201871207915e-06,
      "learning_rate": 1.8852206109225548e-05,
      "loss": 0.0005,
      "step": 100950
    },
    {
      "epoch": 31.15087935822277,
      "grad_norm": 5.7675924836075865e-06,
      "learning_rate": 1.884912064177723e-05,
      "loss": 0.0,
      "step": 100960
    },
    {
      "epoch": 31.15396482567109,
      "grad_norm": 2.7370867883291794e-07,
      "learning_rate": 1.884603517432891e-05,
      "loss": 0.0,
      "step": 100970
    },
    {
      "epoch": 31.157050293119408,
      "grad_norm": 9.903270438371692e-06,
      "learning_rate": 1.8842949706880595e-05,
      "loss": 0.0,
      "step": 100980
    },
    {
      "epoch": 31.160135760567726,
      "grad_norm": 0.0001318669819738716,
      "learning_rate": 1.8839864239432274e-05,
      "loss": 0.0,
      "step": 100990
    },
    {
      "epoch": 31.163221228016045,
      "grad_norm": 2.2944661282053858e-07,
      "learning_rate": 1.8836778771983957e-05,
      "loss": 0.0004,
      "step": 101000
    },
    {
      "epoch": 31.166306695464364,
      "grad_norm": 3.6631114198826253e-05,
      "learning_rate": 1.883369330453564e-05,
      "loss": 0.0,
      "step": 101010
    },
    {
      "epoch": 31.169392162912683,
      "grad_norm": 0.0001352260005660355,
      "learning_rate": 1.8830607837087318e-05,
      "loss": 0.0,
      "step": 101020
    },
    {
      "epoch": 31.172477630361,
      "grad_norm": 8.016906213015318e-05,
      "learning_rate": 1.8827522369639e-05,
      "loss": 0.0001,
      "step": 101030
    },
    {
      "epoch": 31.175563097809317,
      "grad_norm": 6.062145530449925e-06,
      "learning_rate": 1.8824436902190683e-05,
      "loss": 0.0,
      "step": 101040
    },
    {
      "epoch": 31.178648565257635,
      "grad_norm": 0.007289737928658724,
      "learning_rate": 1.8821351434742366e-05,
      "loss": 0.0,
      "step": 101050
    },
    {
      "epoch": 31.181734032705954,
      "grad_norm": 4.376062861410901e-05,
      "learning_rate": 1.8818265967294048e-05,
      "loss": 0.0,
      "step": 101060
    },
    {
      "epoch": 31.184819500154273,
      "grad_norm": 0.00045900995610281825,
      "learning_rate": 1.8815180499845727e-05,
      "loss": 0.0008,
      "step": 101070
    },
    {
      "epoch": 31.18790496760259,
      "grad_norm": 0.0027338513173162937,
      "learning_rate": 1.881209503239741e-05,
      "loss": 0.0026,
      "step": 101080
    },
    {
      "epoch": 31.19099043505091,
      "grad_norm": 0.006976320408284664,
      "learning_rate": 1.880900956494909e-05,
      "loss": 0.0001,
      "step": 101090
    },
    {
      "epoch": 31.19407590249923,
      "grad_norm": 5.547845489672909e-07,
      "learning_rate": 1.880592409750077e-05,
      "loss": 0.0,
      "step": 101100
    },
    {
      "epoch": 31.197161369947548,
      "grad_norm": 3.782741987379268e-05,
      "learning_rate": 1.8802838630052454e-05,
      "loss": 0.0,
      "step": 101110
    },
    {
      "epoch": 31.200246837395866,
      "grad_norm": 5.746676379203564e-07,
      "learning_rate": 1.8799753162604136e-05,
      "loss": 0.0,
      "step": 101120
    },
    {
      "epoch": 31.203332304844185,
      "grad_norm": 1.9739041817956604e-05,
      "learning_rate": 1.879666769515582e-05,
      "loss": 0.0,
      "step": 101130
    },
    {
      "epoch": 31.206417772292504,
      "grad_norm": 0.0007042681681923568,
      "learning_rate": 1.8793582227707498e-05,
      "loss": 0.002,
      "step": 101140
    },
    {
      "epoch": 31.20950323974082,
      "grad_norm": 4.10499342251569e-06,
      "learning_rate": 1.879049676025918e-05,
      "loss": 0.0006,
      "step": 101150
    },
    {
      "epoch": 31.212588707189138,
      "grad_norm": 0.00014365609968081117,
      "learning_rate": 1.878741129281086e-05,
      "loss": 0.001,
      "step": 101160
    },
    {
      "epoch": 31.215674174637456,
      "grad_norm": 0.044762514531612396,
      "learning_rate": 1.8784325825362542e-05,
      "loss": 0.0001,
      "step": 101170
    },
    {
      "epoch": 31.218759642085775,
      "grad_norm": 0.0006195729365572333,
      "learning_rate": 1.8781240357914224e-05,
      "loss": 0.0,
      "step": 101180
    },
    {
      "epoch": 31.221845109534094,
      "grad_norm": 0.0017213723622262478,
      "learning_rate": 1.8778154890465907e-05,
      "loss": 0.0,
      "step": 101190
    },
    {
      "epoch": 31.224930576982413,
      "grad_norm": 0.000301053689327091,
      "learning_rate": 1.877506942301759e-05,
      "loss": 0.0,
      "step": 101200
    },
    {
      "epoch": 31.22801604443073,
      "grad_norm": 3.9350008592009544e-05,
      "learning_rate": 1.877198395556927e-05,
      "loss": 0.0129,
      "step": 101210
    },
    {
      "epoch": 31.23110151187905,
      "grad_norm": 0.0001527694403193891,
      "learning_rate": 1.876889848812095e-05,
      "loss": 0.0001,
      "step": 101220
    },
    {
      "epoch": 31.23418697932737,
      "grad_norm": 2.2463995264843106e-05,
      "learning_rate": 1.8765813020672633e-05,
      "loss": 0.0056,
      "step": 101230
    },
    {
      "epoch": 31.237272446775687,
      "grad_norm": 3.2992393244057894e-05,
      "learning_rate": 1.8762727553224316e-05,
      "loss": 0.0001,
      "step": 101240
    },
    {
      "epoch": 31.240357914224006,
      "grad_norm": 0.0004885219968855381,
      "learning_rate": 1.8759642085775998e-05,
      "loss": 0.0,
      "step": 101250
    },
    {
      "epoch": 31.243443381672325,
      "grad_norm": 0.00041676234104670584,
      "learning_rate": 1.8756556618327677e-05,
      "loss": 0.0,
      "step": 101260
    },
    {
      "epoch": 31.24652884912064,
      "grad_norm": 5.047729246143717e-06,
      "learning_rate": 1.875347115087936e-05,
      "loss": 0.0018,
      "step": 101270
    },
    {
      "epoch": 31.24961431656896,
      "grad_norm": 0.3758052587509155,
      "learning_rate": 1.875038568343104e-05,
      "loss": 0.0002,
      "step": 101280
    },
    {
      "epoch": 31.252699784017278,
      "grad_norm": 0.00813212525099516,
      "learning_rate": 1.874730021598272e-05,
      "loss": 0.001,
      "step": 101290
    },
    {
      "epoch": 31.255785251465596,
      "grad_norm": 2.8124875825596973e-05,
      "learning_rate": 1.8744214748534404e-05,
      "loss": 0.0,
      "step": 101300
    },
    {
      "epoch": 31.258870718913915,
      "grad_norm": 0.00018989770615007728,
      "learning_rate": 1.8741129281086086e-05,
      "loss": 0.0,
      "step": 101310
    },
    {
      "epoch": 31.261956186362234,
      "grad_norm": 9.207057155435905e-05,
      "learning_rate": 1.873804381363777e-05,
      "loss": 0.0,
      "step": 101320
    },
    {
      "epoch": 31.265041653810552,
      "grad_norm": 0.000848958152346313,
      "learning_rate": 1.8734958346189448e-05,
      "loss": 0.0,
      "step": 101330
    },
    {
      "epoch": 31.26812712125887,
      "grad_norm": 2.1854722945136018e-05,
      "learning_rate": 1.873187287874113e-05,
      "loss": 0.0001,
      "step": 101340
    },
    {
      "epoch": 31.27121258870719,
      "grad_norm": 0.0008002257673069835,
      "learning_rate": 1.8728787411292813e-05,
      "loss": 0.0,
      "step": 101350
    },
    {
      "epoch": 31.27429805615551,
      "grad_norm": 0.0004488521080929786,
      "learning_rate": 1.8725701943844492e-05,
      "loss": 0.0,
      "step": 101360
    },
    {
      "epoch": 31.277383523603827,
      "grad_norm": 0.0017226898344233632,
      "learning_rate": 1.8722616476396174e-05,
      "loss": 0.0,
      "step": 101370
    },
    {
      "epoch": 31.280468991052146,
      "grad_norm": 0.00012921604502480477,
      "learning_rate": 1.8719531008947857e-05,
      "loss": 0.0002,
      "step": 101380
    },
    {
      "epoch": 31.28355445850046,
      "grad_norm": 1.462408931729442e-07,
      "learning_rate": 1.871644554149954e-05,
      "loss": 0.0,
      "step": 101390
    },
    {
      "epoch": 31.28663992594878,
      "grad_norm": 9.229173156199977e-05,
      "learning_rate": 1.871336007405122e-05,
      "loss": 0.0001,
      "step": 101400
    },
    {
      "epoch": 31.2897253933971,
      "grad_norm": 1.7880790892377263e-07,
      "learning_rate": 1.87102746066029e-05,
      "loss": 0.0,
      "step": 101410
    },
    {
      "epoch": 31.292810860845417,
      "grad_norm": 0.0010574246989563107,
      "learning_rate": 1.8707189139154583e-05,
      "loss": 0.0,
      "step": 101420
    },
    {
      "epoch": 31.295896328293736,
      "grad_norm": 0.000814586179330945,
      "learning_rate": 1.8704103671706262e-05,
      "loss": 0.0004,
      "step": 101430
    },
    {
      "epoch": 31.298981795742055,
      "grad_norm": 1.8083118220602046e-06,
      "learning_rate": 1.8701018204257945e-05,
      "loss": 0.0,
      "step": 101440
    },
    {
      "epoch": 31.302067263190374,
      "grad_norm": 1.3669578038388863e-06,
      "learning_rate": 1.8697932736809627e-05,
      "loss": 0.0,
      "step": 101450
    },
    {
      "epoch": 31.305152730638692,
      "grad_norm": 5.260417310637422e-06,
      "learning_rate": 1.869484726936131e-05,
      "loss": 0.0,
      "step": 101460
    },
    {
      "epoch": 31.30823819808701,
      "grad_norm": 3.5195789678255096e-05,
      "learning_rate": 1.8691761801912992e-05,
      "loss": 0.0,
      "step": 101470
    },
    {
      "epoch": 31.31132366553533,
      "grad_norm": 1.123722313423059e-06,
      "learning_rate": 1.868867633446467e-05,
      "loss": 0.0,
      "step": 101480
    },
    {
      "epoch": 31.31440913298365,
      "grad_norm": 0.00024197381571866572,
      "learning_rate": 1.8685590867016354e-05,
      "loss": 0.0,
      "step": 101490
    },
    {
      "epoch": 31.317494600431964,
      "grad_norm": 0.004492972977459431,
      "learning_rate": 1.8682505399568033e-05,
      "loss": 0.0,
      "step": 101500
    },
    {
      "epoch": 31.320580067880282,
      "grad_norm": 1.0661228770914022e-05,
      "learning_rate": 1.867941993211972e-05,
      "loss": 0.0,
      "step": 101510
    },
    {
      "epoch": 31.3236655353286,
      "grad_norm": 3.608838596846908e-05,
      "learning_rate": 1.8676334464671398e-05,
      "loss": 0.0001,
      "step": 101520
    },
    {
      "epoch": 31.32675100277692,
      "grad_norm": 6.282975664362311e-05,
      "learning_rate": 1.867324899722308e-05,
      "loss": 0.0,
      "step": 101530
    },
    {
      "epoch": 31.32983647022524,
      "grad_norm": 0.0012305928394198418,
      "learning_rate": 1.8670163529774763e-05,
      "loss": 0.0,
      "step": 101540
    },
    {
      "epoch": 31.332921937673557,
      "grad_norm": 0.000995623180642724,
      "learning_rate": 1.8667078062326442e-05,
      "loss": 0.0,
      "step": 101550
    },
    {
      "epoch": 31.336007405121876,
      "grad_norm": 0.0014505099970847368,
      "learning_rate": 1.8663992594878125e-05,
      "loss": 0.0,
      "step": 101560
    },
    {
      "epoch": 31.339092872570195,
      "grad_norm": 8.962572337622987e-07,
      "learning_rate": 1.8660907127429804e-05,
      "loss": 0.0,
      "step": 101570
    },
    {
      "epoch": 31.342178340018513,
      "grad_norm": 0.00030213684658519924,
      "learning_rate": 1.865782165998149e-05,
      "loss": 0.0,
      "step": 101580
    },
    {
      "epoch": 31.345263807466832,
      "grad_norm": 3.143043841191684e-06,
      "learning_rate": 1.8654736192533172e-05,
      "loss": 0.0,
      "step": 101590
    },
    {
      "epoch": 31.34834927491515,
      "grad_norm": 0.0006971376133151352,
      "learning_rate": 1.865165072508485e-05,
      "loss": 0.0,
      "step": 101600
    },
    {
      "epoch": 31.35143474236347,
      "grad_norm": 2.7090000003227033e-06,
      "learning_rate": 1.8648565257636534e-05,
      "loss": 0.0,
      "step": 101610
    },
    {
      "epoch": 31.354520209811785,
      "grad_norm": 2.220515170847648e-06,
      "learning_rate": 1.8645479790188213e-05,
      "loss": 0.0,
      "step": 101620
    },
    {
      "epoch": 31.357605677260104,
      "grad_norm": 0.0005786779220215976,
      "learning_rate": 1.8642394322739895e-05,
      "loss": 0.0001,
      "step": 101630
    },
    {
      "epoch": 31.360691144708422,
      "grad_norm": 0.003923468757420778,
      "learning_rate": 1.8639308855291578e-05,
      "loss": 0.0001,
      "step": 101640
    },
    {
      "epoch": 31.36377661215674,
      "grad_norm": 0.0009608390391804278,
      "learning_rate": 1.863622338784326e-05,
      "loss": 0.0,
      "step": 101650
    },
    {
      "epoch": 31.36686207960506,
      "grad_norm": 0.00011474628990981728,
      "learning_rate": 1.8633137920394943e-05,
      "loss": 0.0,
      "step": 101660
    },
    {
      "epoch": 31.36994754705338,
      "grad_norm": 0.00036514678504318,
      "learning_rate": 1.863005245294662e-05,
      "loss": 0.0,
      "step": 101670
    },
    {
      "epoch": 31.373033014501697,
      "grad_norm": 0.00103586760815233,
      "learning_rate": 1.8626966985498304e-05,
      "loss": 0.0,
      "step": 101680
    },
    {
      "epoch": 31.376118481950016,
      "grad_norm": 0.22653134167194366,
      "learning_rate": 1.8623881518049983e-05,
      "loss": 0.0001,
      "step": 101690
    },
    {
      "epoch": 31.379203949398335,
      "grad_norm": 7.77302648202749e-06,
      "learning_rate": 1.8620796050601666e-05,
      "loss": 0.0,
      "step": 101700
    },
    {
      "epoch": 31.382289416846653,
      "grad_norm": 2.955648051283788e-05,
      "learning_rate": 1.861771058315335e-05,
      "loss": 0.0001,
      "step": 101710
    },
    {
      "epoch": 31.385374884294972,
      "grad_norm": 7.566347630927339e-05,
      "learning_rate": 1.861462511570503e-05,
      "loss": 0.0,
      "step": 101720
    },
    {
      "epoch": 31.38846035174329,
      "grad_norm": 0.13655470311641693,
      "learning_rate": 1.8611539648256713e-05,
      "loss": 0.0001,
      "step": 101730
    },
    {
      "epoch": 31.391545819191606,
      "grad_norm": 0.0002879033563658595,
      "learning_rate": 1.8608454180808392e-05,
      "loss": 0.0,
      "step": 101740
    },
    {
      "epoch": 31.394631286639925,
      "grad_norm": 1.1538813851075247e-05,
      "learning_rate": 1.8605368713360075e-05,
      "loss": 0.0,
      "step": 101750
    },
    {
      "epoch": 31.397716754088243,
      "grad_norm": 2.5554481908329763e-05,
      "learning_rate": 1.8602283245911757e-05,
      "loss": 0.0,
      "step": 101760
    },
    {
      "epoch": 31.400802221536562,
      "grad_norm": 0.00030690684798173606,
      "learning_rate": 1.8599197778463436e-05,
      "loss": 0.0,
      "step": 101770
    },
    {
      "epoch": 31.40388768898488,
      "grad_norm": 0.0031516761519014835,
      "learning_rate": 1.8596112311015122e-05,
      "loss": 0.0,
      "step": 101780
    },
    {
      "epoch": 31.4069731564332,
      "grad_norm": 1.6402944993387791e-06,
      "learning_rate": 1.85930268435668e-05,
      "loss": 0.0001,
      "step": 101790
    },
    {
      "epoch": 31.41005862388152,
      "grad_norm": 0.00014445958368014544,
      "learning_rate": 1.8589941376118484e-05,
      "loss": 0.0,
      "step": 101800
    },
    {
      "epoch": 31.413144091329837,
      "grad_norm": 8.108241672744043e-06,
      "learning_rate": 1.8586855908670163e-05,
      "loss": 0.0,
      "step": 101810
    },
    {
      "epoch": 31.416229558778156,
      "grad_norm": 4.008613541373052e-05,
      "learning_rate": 1.8583770441221845e-05,
      "loss": 0.0,
      "step": 101820
    },
    {
      "epoch": 31.419315026226474,
      "grad_norm": 5.082666802991298e-07,
      "learning_rate": 1.8580684973773528e-05,
      "loss": 0.0,
      "step": 101830
    },
    {
      "epoch": 31.422400493674793,
      "grad_norm": 5.249495416137506e-07,
      "learning_rate": 1.8577599506325207e-05,
      "loss": 0.0,
      "step": 101840
    },
    {
      "epoch": 31.425485961123112,
      "grad_norm": 5.0434946388122626e-06,
      "learning_rate": 1.8574514038876893e-05,
      "loss": 0.0,
      "step": 101850
    },
    {
      "epoch": 31.428571428571427,
      "grad_norm": 4.848450771532953e-06,
      "learning_rate": 1.8571428571428572e-05,
      "loss": 0.0,
      "step": 101860
    },
    {
      "epoch": 31.431656896019746,
      "grad_norm": 0.0003753177297767252,
      "learning_rate": 1.8568343103980254e-05,
      "loss": 0.0,
      "step": 101870
    },
    {
      "epoch": 31.434742363468064,
      "grad_norm": 1.6521659063073457e-06,
      "learning_rate": 1.8565257636531937e-05,
      "loss": 0.0,
      "step": 101880
    },
    {
      "epoch": 31.437827830916383,
      "grad_norm": 7.78859066485893e-06,
      "learning_rate": 1.8562172169083616e-05,
      "loss": 0.0,
      "step": 101890
    },
    {
      "epoch": 31.440913298364702,
      "grad_norm": 0.004103335551917553,
      "learning_rate": 1.8559086701635298e-05,
      "loss": 0.0,
      "step": 101900
    },
    {
      "epoch": 31.44399876581302,
      "grad_norm": 0.00010858551104320213,
      "learning_rate": 1.855600123418698e-05,
      "loss": 0.0,
      "step": 101910
    },
    {
      "epoch": 31.44708423326134,
      "grad_norm": 3.593951623770408e-05,
      "learning_rate": 1.8552915766738663e-05,
      "loss": 0.0,
      "step": 101920
    },
    {
      "epoch": 31.450169700709658,
      "grad_norm": 0.0006913439137861133,
      "learning_rate": 1.8549830299290342e-05,
      "loss": 0.0,
      "step": 101930
    },
    {
      "epoch": 31.453255168157977,
      "grad_norm": 5.821164563712955e-07,
      "learning_rate": 1.8546744831842025e-05,
      "loss": 0.0,
      "step": 101940
    },
    {
      "epoch": 31.456340635606296,
      "grad_norm": 7.793702388880774e-05,
      "learning_rate": 1.8543659364393707e-05,
      "loss": 0.0,
      "step": 101950
    },
    {
      "epoch": 31.459426103054614,
      "grad_norm": 7.848383393138647e-05,
      "learning_rate": 1.8540573896945386e-05,
      "loss": 0.0,
      "step": 101960
    },
    {
      "epoch": 31.46251157050293,
      "grad_norm": 0.00029630240169353783,
      "learning_rate": 1.853748842949707e-05,
      "loss": 0.0,
      "step": 101970
    },
    {
      "epoch": 31.465597037951248,
      "grad_norm": 6.832543294876814e-05,
      "learning_rate": 1.853440296204875e-05,
      "loss": 0.0,
      "step": 101980
    },
    {
      "epoch": 31.468682505399567,
      "grad_norm": 0.001476667239330709,
      "learning_rate": 1.8531317494600434e-05,
      "loss": 0.0,
      "step": 101990
    },
    {
      "epoch": 31.471767972847886,
      "grad_norm": 5.3021421990706585e-06,
      "learning_rate": 1.8528232027152116e-05,
      "loss": 0.0,
      "step": 102000
    },
    {
      "epoch": 31.474853440296204,
      "grad_norm": 1.8943671875604196e-06,
      "learning_rate": 1.8525146559703795e-05,
      "loss": 0.0,
      "step": 102010
    },
    {
      "epoch": 31.477938907744523,
      "grad_norm": 0.0011048404267057776,
      "learning_rate": 1.8522061092255478e-05,
      "loss": 0.0,
      "step": 102020
    },
    {
      "epoch": 31.481024375192842,
      "grad_norm": 2.3192385469883448e-06,
      "learning_rate": 1.8518975624807157e-05,
      "loss": 0.0,
      "step": 102030
    },
    {
      "epoch": 31.48410984264116,
      "grad_norm": 3.8959376524871914e-07,
      "learning_rate": 1.851589015735884e-05,
      "loss": 0.0,
      "step": 102040
    },
    {
      "epoch": 31.48719531008948,
      "grad_norm": 0.0009430363425053656,
      "learning_rate": 1.8512804689910522e-05,
      "loss": 0.0,
      "step": 102050
    },
    {
      "epoch": 31.490280777537798,
      "grad_norm": 0.0002012458717217669,
      "learning_rate": 1.8509719222462204e-05,
      "loss": 0.0,
      "step": 102060
    },
    {
      "epoch": 31.493366244986117,
      "grad_norm": 9.303449769504368e-05,
      "learning_rate": 1.8506633755013887e-05,
      "loss": 0.0002,
      "step": 102070
    },
    {
      "epoch": 31.496451712434435,
      "grad_norm": 0.001789415837265551,
      "learning_rate": 1.8503548287565566e-05,
      "loss": 0.0,
      "step": 102080
    },
    {
      "epoch": 31.49953717988275,
      "grad_norm": 5.982585935271345e-05,
      "learning_rate": 1.850046282011725e-05,
      "loss": 0.0,
      "step": 102090
    },
    {
      "epoch": 31.50262264733107,
      "grad_norm": 1.1907369525943068e-06,
      "learning_rate": 1.849737735266893e-05,
      "loss": 0.0001,
      "step": 102100
    },
    {
      "epoch": 31.505708114779388,
      "grad_norm": 4.0277376683661714e-05,
      "learning_rate": 1.8494291885220613e-05,
      "loss": 0.0,
      "step": 102110
    },
    {
      "epoch": 31.508793582227707,
      "grad_norm": 3.6995825212216005e-05,
      "learning_rate": 1.8491206417772296e-05,
      "loss": 0.0,
      "step": 102120
    },
    {
      "epoch": 31.511879049676025,
      "grad_norm": 0.022383714094758034,
      "learning_rate": 1.8488120950323975e-05,
      "loss": 0.0001,
      "step": 102130
    },
    {
      "epoch": 31.514964517124344,
      "grad_norm": 3.969063527620165e-06,
      "learning_rate": 1.8485035482875657e-05,
      "loss": 0.0,
      "step": 102140
    },
    {
      "epoch": 31.518049984572663,
      "grad_norm": 0.0008173797396011651,
      "learning_rate": 1.8481950015427336e-05,
      "loss": 0.0,
      "step": 102150
    },
    {
      "epoch": 31.52113545202098,
      "grad_norm": 0.00192456622608006,
      "learning_rate": 1.847886454797902e-05,
      "loss": 0.0,
      "step": 102160
    },
    {
      "epoch": 31.5242209194693,
      "grad_norm": 1.5050459296617191e-06,
      "learning_rate": 1.84757790805307e-05,
      "loss": 0.0,
      "step": 102170
    },
    {
      "epoch": 31.52730638691762,
      "grad_norm": 0.00035574185312725604,
      "learning_rate": 1.8472693613082384e-05,
      "loss": 0.0,
      "step": 102180
    },
    {
      "epoch": 31.530391854365938,
      "grad_norm": 1.038467962644063e-05,
      "learning_rate": 1.8469608145634066e-05,
      "loss": 0.0,
      "step": 102190
    },
    {
      "epoch": 31.533477321814257,
      "grad_norm": 8.78541328575011e-08,
      "learning_rate": 1.8466522678185745e-05,
      "loss": 0.0,
      "step": 102200
    },
    {
      "epoch": 31.53656278926257,
      "grad_norm": 1.8660429645933618e-07,
      "learning_rate": 1.8463437210737428e-05,
      "loss": 0.0,
      "step": 102210
    },
    {
      "epoch": 31.53964825671089,
      "grad_norm": 1.0017203749157488e-05,
      "learning_rate": 1.846035174328911e-05,
      "loss": 0.0,
      "step": 102220
    },
    {
      "epoch": 31.54273372415921,
      "grad_norm": 9.387139289174229e-05,
      "learning_rate": 1.845726627584079e-05,
      "loss": 0.0057,
      "step": 102230
    },
    {
      "epoch": 31.545819191607528,
      "grad_norm": 1.2317968867137097e-06,
      "learning_rate": 1.8454180808392472e-05,
      "loss": 0.0,
      "step": 102240
    },
    {
      "epoch": 31.548904659055847,
      "grad_norm": 0.0002564239548519254,
      "learning_rate": 1.8451095340944154e-05,
      "loss": 0.0,
      "step": 102250
    },
    {
      "epoch": 31.551990126504165,
      "grad_norm": 0.0005378154455684125,
      "learning_rate": 1.8448009873495837e-05,
      "loss": 0.0007,
      "step": 102260
    },
    {
      "epoch": 31.555075593952484,
      "grad_norm": 2.3305015020014253e-06,
      "learning_rate": 1.8444924406047516e-05,
      "loss": 0.0,
      "step": 102270
    },
    {
      "epoch": 31.558161061400803,
      "grad_norm": 5.1291644922457635e-06,
      "learning_rate": 1.84418389385992e-05,
      "loss": 0.0,
      "step": 102280
    },
    {
      "epoch": 31.56124652884912,
      "grad_norm": 1.0270557403564453,
      "learning_rate": 1.843875347115088e-05,
      "loss": 0.0036,
      "step": 102290
    },
    {
      "epoch": 31.56433199629744,
      "grad_norm": 1.7251217365264893,
      "learning_rate": 1.843566800370256e-05,
      "loss": 0.001,
      "step": 102300
    },
    {
      "epoch": 31.56741746374576,
      "grad_norm": 0.00021628821559716016,
      "learning_rate": 1.8432582536254243e-05,
      "loss": 0.0,
      "step": 102310
    },
    {
      "epoch": 31.570502931194078,
      "grad_norm": 0.0005787567934021354,
      "learning_rate": 1.8429497068805925e-05,
      "loss": 0.0,
      "step": 102320
    },
    {
      "epoch": 31.573588398642393,
      "grad_norm": 2.5086512323468924e-05,
      "learning_rate": 1.8426411601357607e-05,
      "loss": 0.0,
      "step": 102330
    },
    {
      "epoch": 31.57667386609071,
      "grad_norm": 4.4320811866782606e-05,
      "learning_rate": 1.842332613390929e-05,
      "loss": 0.0018,
      "step": 102340
    },
    {
      "epoch": 31.57975933353903,
      "grad_norm": 0.00021706256666220725,
      "learning_rate": 1.842024066646097e-05,
      "loss": 0.0,
      "step": 102350
    },
    {
      "epoch": 31.58284480098735,
      "grad_norm": 0.001995330909267068,
      "learning_rate": 1.841715519901265e-05,
      "loss": 0.0001,
      "step": 102360
    },
    {
      "epoch": 31.585930268435668,
      "grad_norm": 3.2889292924664915e-05,
      "learning_rate": 1.841406973156433e-05,
      "loss": 0.0004,
      "step": 102370
    },
    {
      "epoch": 31.589015735883986,
      "grad_norm": 0.0006839994457550347,
      "learning_rate": 1.8410984264116016e-05,
      "loss": 0.0002,
      "step": 102380
    },
    {
      "epoch": 31.592101203332305,
      "grad_norm": 2.753641865638201e-06,
      "learning_rate": 1.8407898796667696e-05,
      "loss": 0.0,
      "step": 102390
    },
    {
      "epoch": 31.595186670780624,
      "grad_norm": 1.9411318135098554e-06,
      "learning_rate": 1.8404813329219378e-05,
      "loss": 0.0038,
      "step": 102400
    },
    {
      "epoch": 31.598272138228943,
      "grad_norm": 0.00222768378444016,
      "learning_rate": 1.840172786177106e-05,
      "loss": 0.0,
      "step": 102410
    },
    {
      "epoch": 31.60135760567726,
      "grad_norm": 1.5126913240237627e-05,
      "learning_rate": 1.839864239432274e-05,
      "loss": 0.0,
      "step": 102420
    },
    {
      "epoch": 31.60444307312558,
      "grad_norm": 0.00029955754871480167,
      "learning_rate": 1.8395556926874422e-05,
      "loss": 0.0,
      "step": 102430
    },
    {
      "epoch": 31.607528540573895,
      "grad_norm": 1.8043024283542763e-06,
      "learning_rate": 1.83924714594261e-05,
      "loss": 0.0,
      "step": 102440
    },
    {
      "epoch": 31.610614008022214,
      "grad_norm": 3.2038217341323616e-06,
      "learning_rate": 1.8389385991977787e-05,
      "loss": 0.0,
      "step": 102450
    },
    {
      "epoch": 31.613699475470533,
      "grad_norm": 0.012473583221435547,
      "learning_rate": 1.8386300524529466e-05,
      "loss": 0.0,
      "step": 102460
    },
    {
      "epoch": 31.61678494291885,
      "grad_norm": 0.0002201219176640734,
      "learning_rate": 1.838321505708115e-05,
      "loss": 0.0035,
      "step": 102470
    },
    {
      "epoch": 31.61987041036717,
      "grad_norm": 4.9808978275223126e-08,
      "learning_rate": 1.838012958963283e-05,
      "loss": 0.0079,
      "step": 102480
    },
    {
      "epoch": 31.62295587781549,
      "grad_norm": 0.00031728483736515045,
      "learning_rate": 1.837704412218451e-05,
      "loss": 0.0,
      "step": 102490
    },
    {
      "epoch": 31.626041345263808,
      "grad_norm": 0.00021510069200303406,
      "learning_rate": 1.8373958654736193e-05,
      "loss": 0.0,
      "step": 102500
    },
    {
      "epoch": 31.629126812712126,
      "grad_norm": 0.0015094827394932508,
      "learning_rate": 1.8370873187287875e-05,
      "loss": 0.0001,
      "step": 102510
    },
    {
      "epoch": 31.632212280160445,
      "grad_norm": 0.00015899054415058345,
      "learning_rate": 1.8367787719839558e-05,
      "loss": 0.002,
      "step": 102520
    },
    {
      "epoch": 31.635297747608764,
      "grad_norm": 3.301248943898827e-05,
      "learning_rate": 1.836470225239124e-05,
      "loss": 0.0,
      "step": 102530
    },
    {
      "epoch": 31.638383215057083,
      "grad_norm": 0.00019534473540261388,
      "learning_rate": 1.836161678494292e-05,
      "loss": 0.0,
      "step": 102540
    },
    {
      "epoch": 31.6414686825054,
      "grad_norm": 0.010577556677162647,
      "learning_rate": 1.83585313174946e-05,
      "loss": 0.0002,
      "step": 102550
    },
    {
      "epoch": 31.644554149953716,
      "grad_norm": 0.0010331274243071675,
      "learning_rate": 1.835544585004628e-05,
      "loss": 0.0,
      "step": 102560
    },
    {
      "epoch": 31.647639617402035,
      "grad_norm": 0.0001003623619908467,
      "learning_rate": 1.8352360382597963e-05,
      "loss": 0.0001,
      "step": 102570
    },
    {
      "epoch": 31.650725084850354,
      "grad_norm": 2.204483826062642e-05,
      "learning_rate": 1.8349274915149646e-05,
      "loss": 0.0006,
      "step": 102580
    },
    {
      "epoch": 31.653810552298673,
      "grad_norm": 0.00010087838745675981,
      "learning_rate": 1.8346189447701328e-05,
      "loss": 0.0,
      "step": 102590
    },
    {
      "epoch": 31.65689601974699,
      "grad_norm": 3.640765498857945e-06,
      "learning_rate": 1.834310398025301e-05,
      "loss": 0.0002,
      "step": 102600
    },
    {
      "epoch": 31.65998148719531,
      "grad_norm": 9.062867320608348e-06,
      "learning_rate": 1.834001851280469e-05,
      "loss": 0.0,
      "step": 102610
    },
    {
      "epoch": 31.66306695464363,
      "grad_norm": 4.038886254420504e-05,
      "learning_rate": 1.8336933045356372e-05,
      "loss": 0.0002,
      "step": 102620
    },
    {
      "epoch": 31.666152422091947,
      "grad_norm": 0.008170893415808678,
      "learning_rate": 1.8333847577908055e-05,
      "loss": 0.0002,
      "step": 102630
    },
    {
      "epoch": 31.669237889540266,
      "grad_norm": 0.0008769144769757986,
      "learning_rate": 1.8330762110459734e-05,
      "loss": 0.0,
      "step": 102640
    },
    {
      "epoch": 31.672323356988585,
      "grad_norm": 2.1242067305138335e-05,
      "learning_rate": 1.832767664301142e-05,
      "loss": 0.0,
      "step": 102650
    },
    {
      "epoch": 31.675408824436904,
      "grad_norm": 0.0001510507136117667,
      "learning_rate": 1.83245911755631e-05,
      "loss": 0.0,
      "step": 102660
    },
    {
      "epoch": 31.678494291885222,
      "grad_norm": 0.00016015712753869593,
      "learning_rate": 1.832150570811478e-05,
      "loss": 0.0,
      "step": 102670
    },
    {
      "epoch": 31.681579759333538,
      "grad_norm": 0.0022078263573348522,
      "learning_rate": 1.831842024066646e-05,
      "loss": 0.0,
      "step": 102680
    },
    {
      "epoch": 31.684665226781856,
      "grad_norm": 1.7405172911821865e-05,
      "learning_rate": 1.8315334773218143e-05,
      "loss": 0.0,
      "step": 102690
    },
    {
      "epoch": 31.687750694230175,
      "grad_norm": 1.038132040775963e-06,
      "learning_rate": 1.8312249305769825e-05,
      "loss": 0.0002,
      "step": 102700
    },
    {
      "epoch": 31.690836161678494,
      "grad_norm": 0.006603627931326628,
      "learning_rate": 1.8309163838321504e-05,
      "loss": 0.0002,
      "step": 102710
    },
    {
      "epoch": 31.693921629126812,
      "grad_norm": 0.0022251801565289497,
      "learning_rate": 1.830607837087319e-05,
      "loss": 0.0003,
      "step": 102720
    },
    {
      "epoch": 31.69700709657513,
      "grad_norm": 0.0037685446441173553,
      "learning_rate": 1.830299290342487e-05,
      "loss": 0.0001,
      "step": 102730
    },
    {
      "epoch": 31.70009256402345,
      "grad_norm": 1.4460742931987625e-05,
      "learning_rate": 1.8299907435976552e-05,
      "loss": 0.0,
      "step": 102740
    },
    {
      "epoch": 31.70317803147177,
      "grad_norm": 0.0002726747188717127,
      "learning_rate": 1.8296821968528234e-05,
      "loss": 0.0006,
      "step": 102750
    },
    {
      "epoch": 31.706263498920087,
      "grad_norm": 5.964491720078513e-05,
      "learning_rate": 1.8293736501079913e-05,
      "loss": 0.0032,
      "step": 102760
    },
    {
      "epoch": 31.709348966368406,
      "grad_norm": 0.0002803560928441584,
      "learning_rate": 1.8290651033631596e-05,
      "loss": 0.0,
      "step": 102770
    },
    {
      "epoch": 31.712434433816725,
      "grad_norm": 2.0024726836709306e-05,
      "learning_rate": 1.8287565566183278e-05,
      "loss": 0.0001,
      "step": 102780
    },
    {
      "epoch": 31.71551990126504,
      "grad_norm": 0.0036867696326225996,
      "learning_rate": 1.828448009873496e-05,
      "loss": 0.0,
      "step": 102790
    },
    {
      "epoch": 31.71860536871336,
      "grad_norm": 0.000400689197704196,
      "learning_rate": 1.828139463128664e-05,
      "loss": 0.0024,
      "step": 102800
    },
    {
      "epoch": 31.721690836161677,
      "grad_norm": 6.205023237271234e-05,
      "learning_rate": 1.8278309163838322e-05,
      "loss": 0.0,
      "step": 102810
    },
    {
      "epoch": 31.724776303609996,
      "grad_norm": 0.00020126919844187796,
      "learning_rate": 1.8275223696390005e-05,
      "loss": 0.0004,
      "step": 102820
    },
    {
      "epoch": 31.727861771058315,
      "grad_norm": 0.005798154976218939,
      "learning_rate": 1.8272138228941684e-05,
      "loss": 0.0,
      "step": 102830
    },
    {
      "epoch": 31.730947238506634,
      "grad_norm": 0.003579034935683012,
      "learning_rate": 1.8269052761493366e-05,
      "loss": 0.0001,
      "step": 102840
    },
    {
      "epoch": 31.734032705954952,
      "grad_norm": 0.00012593335122801363,
      "learning_rate": 1.826596729404505e-05,
      "loss": 0.0,
      "step": 102850
    },
    {
      "epoch": 31.73711817340327,
      "grad_norm": 0.0013288228074088693,
      "learning_rate": 1.826288182659673e-05,
      "loss": 0.0002,
      "step": 102860
    },
    {
      "epoch": 31.74020364085159,
      "grad_norm": 0.000517726584803313,
      "learning_rate": 1.8259796359148414e-05,
      "loss": 0.0002,
      "step": 102870
    },
    {
      "epoch": 31.74328910829991,
      "grad_norm": 4.894995981885586e-06,
      "learning_rate": 1.8256710891700093e-05,
      "loss": 0.0,
      "step": 102880
    },
    {
      "epoch": 31.746374575748227,
      "grad_norm": 0.01648266427218914,
      "learning_rate": 1.8253625424251775e-05,
      "loss": 0.0002,
      "step": 102890
    },
    {
      "epoch": 31.749460043196546,
      "grad_norm": 0.007840762846171856,
      "learning_rate": 1.8250539956803454e-05,
      "loss": 0.0,
      "step": 102900
    },
    {
      "epoch": 31.75254551064486,
      "grad_norm": 1.6308373233187012e-05,
      "learning_rate": 1.8247454489355137e-05,
      "loss": 0.0,
      "step": 102910
    },
    {
      "epoch": 31.75563097809318,
      "grad_norm": 0.08287183940410614,
      "learning_rate": 1.824436902190682e-05,
      "loss": 0.0001,
      "step": 102920
    },
    {
      "epoch": 31.7587164455415,
      "grad_norm": 3.5607683912530774e-06,
      "learning_rate": 1.8241283554458502e-05,
      "loss": 0.0001,
      "step": 102930
    },
    {
      "epoch": 31.761801912989817,
      "grad_norm": 6.931144525879063e-06,
      "learning_rate": 1.8238198087010184e-05,
      "loss": 0.0002,
      "step": 102940
    },
    {
      "epoch": 31.764887380438136,
      "grad_norm": 1.522842558188131e-05,
      "learning_rate": 1.8235112619561863e-05,
      "loss": 0.0002,
      "step": 102950
    },
    {
      "epoch": 31.767972847886455,
      "grad_norm": 5.548671197175281e-06,
      "learning_rate": 1.8232027152113546e-05,
      "loss": 0.0,
      "step": 102960
    },
    {
      "epoch": 31.771058315334773,
      "grad_norm": 2.883878778447979e-06,
      "learning_rate": 1.8228941684665225e-05,
      "loss": 0.0,
      "step": 102970
    },
    {
      "epoch": 31.774143782783092,
      "grad_norm": 2.4502924134139903e-05,
      "learning_rate": 1.822585621721691e-05,
      "loss": 0.0,
      "step": 102980
    },
    {
      "epoch": 31.77722925023141,
      "grad_norm": 0.0005678824381902814,
      "learning_rate": 1.8222770749768593e-05,
      "loss": 0.0,
      "step": 102990
    },
    {
      "epoch": 31.78031471767973,
      "grad_norm": 1.3616378055303358e-05,
      "learning_rate": 1.8219685282320272e-05,
      "loss": 0.0,
      "step": 103000
    },
    {
      "epoch": 31.78340018512805,
      "grad_norm": 0.00018057286797557026,
      "learning_rate": 1.8216599814871955e-05,
      "loss": 0.0,
      "step": 103010
    },
    {
      "epoch": 31.786485652576367,
      "grad_norm": 0.000278371648164466,
      "learning_rate": 1.8213514347423634e-05,
      "loss": 0.0,
      "step": 103020
    },
    {
      "epoch": 31.789571120024682,
      "grad_norm": 0.006035979837179184,
      "learning_rate": 1.8210428879975317e-05,
      "loss": 0.0,
      "step": 103030
    },
    {
      "epoch": 31.792656587473,
      "grad_norm": 0.009063711389899254,
      "learning_rate": 1.8207343412527e-05,
      "loss": 0.0001,
      "step": 103040
    },
    {
      "epoch": 31.79574205492132,
      "grad_norm": 0.005618079099804163,
      "learning_rate": 1.820425794507868e-05,
      "loss": 0.0013,
      "step": 103050
    },
    {
      "epoch": 31.79882752236964,
      "grad_norm": 9.236704499926418e-05,
      "learning_rate": 1.8201172477630364e-05,
      "loss": 0.0,
      "step": 103060
    },
    {
      "epoch": 31.801912989817957,
      "grad_norm": 0.0003402266011107713,
      "learning_rate": 1.8198087010182043e-05,
      "loss": 0.0,
      "step": 103070
    },
    {
      "epoch": 31.804998457266276,
      "grad_norm": 9.970113978852169e-07,
      "learning_rate": 1.8195001542733726e-05,
      "loss": 0.0,
      "step": 103080
    },
    {
      "epoch": 31.808083924714595,
      "grad_norm": 0.05723557248711586,
      "learning_rate": 1.8191916075285405e-05,
      "loss": 0.0005,
      "step": 103090
    },
    {
      "epoch": 31.811169392162913,
      "grad_norm": 2.516188942536246e-06,
      "learning_rate": 1.8188830607837087e-05,
      "loss": 0.0,
      "step": 103100
    },
    {
      "epoch": 31.814254859611232,
      "grad_norm": 2.8605754778254777e-05,
      "learning_rate": 1.818574514038877e-05,
      "loss": 0.0,
      "step": 103110
    },
    {
      "epoch": 31.81734032705955,
      "grad_norm": 7.909188570920378e-05,
      "learning_rate": 1.8182659672940452e-05,
      "loss": 0.0,
      "step": 103120
    },
    {
      "epoch": 31.82042579450787,
      "grad_norm": 0.009004770778119564,
      "learning_rate": 1.8179574205492135e-05,
      "loss": 0.0002,
      "step": 103130
    },
    {
      "epoch": 31.823511261956185,
      "grad_norm": 1.7878772268886678e-05,
      "learning_rate": 1.8176488738043814e-05,
      "loss": 0.0,
      "step": 103140
    },
    {
      "epoch": 31.826596729404503,
      "grad_norm": 0.12582746148109436,
      "learning_rate": 1.8173403270595496e-05,
      "loss": 0.0,
      "step": 103150
    },
    {
      "epoch": 31.829682196852822,
      "grad_norm": 0.014030017890036106,
      "learning_rate": 1.817031780314718e-05,
      "loss": 0.0,
      "step": 103160
    },
    {
      "epoch": 31.83276766430114,
      "grad_norm": 1.068479718924209e-06,
      "learning_rate": 1.8167232335698858e-05,
      "loss": 0.0,
      "step": 103170
    },
    {
      "epoch": 31.83585313174946,
      "grad_norm": 0.0009542696643620729,
      "learning_rate": 1.816414686825054e-05,
      "loss": 0.0,
      "step": 103180
    },
    {
      "epoch": 31.83893859919778,
      "grad_norm": 1.8092829350280226e-06,
      "learning_rate": 1.8161061400802223e-05,
      "loss": 0.0,
      "step": 103190
    },
    {
      "epoch": 31.842024066646097,
      "grad_norm": 0.15640798211097717,
      "learning_rate": 1.8157975933353905e-05,
      "loss": 0.0027,
      "step": 103200
    },
    {
      "epoch": 31.845109534094416,
      "grad_norm": 3.738547820830718e-05,
      "learning_rate": 1.8154890465905584e-05,
      "loss": 0.0,
      "step": 103210
    },
    {
      "epoch": 31.848195001542734,
      "grad_norm": 0.05071146786212921,
      "learning_rate": 1.8151804998457267e-05,
      "loss": 0.0008,
      "step": 103220
    },
    {
      "epoch": 31.851280468991053,
      "grad_norm": 2.1797697627334855e-05,
      "learning_rate": 1.814871953100895e-05,
      "loss": 0.001,
      "step": 103230
    },
    {
      "epoch": 31.854365936439372,
      "grad_norm": 0.17635102570056915,
      "learning_rate": 1.8145634063560628e-05,
      "loss": 0.0001,
      "step": 103240
    },
    {
      "epoch": 31.85745140388769,
      "grad_norm": 6.4599998950143345e-06,
      "learning_rate": 1.8142548596112314e-05,
      "loss": 0.0001,
      "step": 103250
    },
    {
      "epoch": 31.860536871336006,
      "grad_norm": 0.0008945036679506302,
      "learning_rate": 1.8139463128663993e-05,
      "loss": 0.0,
      "step": 103260
    },
    {
      "epoch": 31.863622338784324,
      "grad_norm": 3.349121698192903e-06,
      "learning_rate": 1.8136377661215676e-05,
      "loss": 0.0,
      "step": 103270
    },
    {
      "epoch": 31.866707806232643,
      "grad_norm": 3.345578443259001e-05,
      "learning_rate": 1.8133292193767358e-05,
      "loss": 0.0029,
      "step": 103280
    },
    {
      "epoch": 31.869793273680962,
      "grad_norm": 3.624845703598112e-05,
      "learning_rate": 1.8130206726319037e-05,
      "loss": 0.0,
      "step": 103290
    },
    {
      "epoch": 31.87287874112928,
      "grad_norm": 0.00022855319548398256,
      "learning_rate": 1.812712125887072e-05,
      "loss": 0.0,
      "step": 103300
    },
    {
      "epoch": 31.8759642085776,
      "grad_norm": 0.0014599098358303308,
      "learning_rate": 1.81240357914224e-05,
      "loss": 0.0047,
      "step": 103310
    },
    {
      "epoch": 31.879049676025918,
      "grad_norm": 3.303968333057128e-05,
      "learning_rate": 1.8120950323974085e-05,
      "loss": 0.0002,
      "step": 103320
    },
    {
      "epoch": 31.882135143474237,
      "grad_norm": 0.0009319453383795917,
      "learning_rate": 1.8117864856525764e-05,
      "loss": 0.0,
      "step": 103330
    },
    {
      "epoch": 31.885220610922556,
      "grad_norm": 9.778878848010208e-06,
      "learning_rate": 1.8114779389077446e-05,
      "loss": 0.0001,
      "step": 103340
    },
    {
      "epoch": 31.888306078370874,
      "grad_norm": 0.00015994382556527853,
      "learning_rate": 1.811169392162913e-05,
      "loss": 0.0,
      "step": 103350
    },
    {
      "epoch": 31.891391545819193,
      "grad_norm": 4.343022283137543e-06,
      "learning_rate": 1.8108608454180808e-05,
      "loss": 0.0001,
      "step": 103360
    },
    {
      "epoch": 31.89447701326751,
      "grad_norm": 0.7565467357635498,
      "learning_rate": 1.810552298673249e-05,
      "loss": 0.0003,
      "step": 103370
    },
    {
      "epoch": 31.897562480715827,
      "grad_norm": 9.768694144440815e-05,
      "learning_rate": 1.8102437519284173e-05,
      "loss": 0.0,
      "step": 103380
    },
    {
      "epoch": 31.900647948164146,
      "grad_norm": 8.087122296274174e-06,
      "learning_rate": 1.8099352051835855e-05,
      "loss": 0.002,
      "step": 103390
    },
    {
      "epoch": 31.903733415612464,
      "grad_norm": 0.12780572474002838,
      "learning_rate": 1.8096266584387538e-05,
      "loss": 0.0002,
      "step": 103400
    },
    {
      "epoch": 31.906818883060783,
      "grad_norm": 1.188600163004594e-05,
      "learning_rate": 1.8093181116939217e-05,
      "loss": 0.0001,
      "step": 103410
    },
    {
      "epoch": 31.909904350509102,
      "grad_norm": 2.7379039238439873e-05,
      "learning_rate": 1.80900956494909e-05,
      "loss": 0.0,
      "step": 103420
    },
    {
      "epoch": 31.91298981795742,
      "grad_norm": 0.00022828557121101767,
      "learning_rate": 1.808701018204258e-05,
      "loss": 0.0008,
      "step": 103430
    },
    {
      "epoch": 31.91607528540574,
      "grad_norm": 1.3049001693725586,
      "learning_rate": 1.808392471459426e-05,
      "loss": 0.0029,
      "step": 103440
    },
    {
      "epoch": 31.919160752854058,
      "grad_norm": 5.5970904213609174e-05,
      "learning_rate": 1.8080839247145943e-05,
      "loss": 0.002,
      "step": 103450
    },
    {
      "epoch": 31.922246220302377,
      "grad_norm": 0.05094717815518379,
      "learning_rate": 1.8077753779697626e-05,
      "loss": 0.0,
      "step": 103460
    },
    {
      "epoch": 31.925331687750695,
      "grad_norm": 0.00014086787996347994,
      "learning_rate": 1.8074668312249308e-05,
      "loss": 0.0,
      "step": 103470
    },
    {
      "epoch": 31.928417155199014,
      "grad_norm": 2.726466118474491e-05,
      "learning_rate": 1.8071582844800987e-05,
      "loss": 0.0001,
      "step": 103480
    },
    {
      "epoch": 31.93150262264733,
      "grad_norm": 0.006800654344260693,
      "learning_rate": 1.806849737735267e-05,
      "loss": 0.0044,
      "step": 103490
    },
    {
      "epoch": 31.934588090095648,
      "grad_norm": 2.9925051876489306e-06,
      "learning_rate": 1.8065411909904352e-05,
      "loss": 0.0002,
      "step": 103500
    },
    {
      "epoch": 31.937673557543967,
      "grad_norm": 5.348844752006698e-06,
      "learning_rate": 1.806232644245603e-05,
      "loss": 0.0001,
      "step": 103510
    },
    {
      "epoch": 31.940759024992285,
      "grad_norm": 1.2327463991823606e-05,
      "learning_rate": 1.8059240975007717e-05,
      "loss": 0.0001,
      "step": 103520
    },
    {
      "epoch": 31.943844492440604,
      "grad_norm": 0.00018251444271299988,
      "learning_rate": 1.8056155507559396e-05,
      "loss": 0.0,
      "step": 103530
    },
    {
      "epoch": 31.946929959888923,
      "grad_norm": 2.3152684661909007e-05,
      "learning_rate": 1.805307004011108e-05,
      "loss": 0.0084,
      "step": 103540
    },
    {
      "epoch": 31.95001542733724,
      "grad_norm": 4.5131197111913934e-05,
      "learning_rate": 1.8049984572662758e-05,
      "loss": 0.0003,
      "step": 103550
    },
    {
      "epoch": 31.95310089478556,
      "grad_norm": 7.517723588534864e-06,
      "learning_rate": 1.804689910521444e-05,
      "loss": 0.0,
      "step": 103560
    },
    {
      "epoch": 31.95618636223388,
      "grad_norm": 2.021662794504664e-06,
      "learning_rate": 1.8043813637766123e-05,
      "loss": 0.0006,
      "step": 103570
    },
    {
      "epoch": 31.959271829682198,
      "grad_norm": 7.468507101293653e-05,
      "learning_rate": 1.8040728170317802e-05,
      "loss": 0.0002,
      "step": 103580
    },
    {
      "epoch": 31.962357297130517,
      "grad_norm": 0.002515185624361038,
      "learning_rate": 1.8037642702869488e-05,
      "loss": 0.0,
      "step": 103590
    },
    {
      "epoch": 31.965442764578835,
      "grad_norm": 0.0033463446889072657,
      "learning_rate": 1.8034557235421167e-05,
      "loss": 0.0004,
      "step": 103600
    },
    {
      "epoch": 31.96852823202715,
      "grad_norm": 5.291338311508298e-06,
      "learning_rate": 1.803147176797285e-05,
      "loss": 0.0001,
      "step": 103610
    },
    {
      "epoch": 31.97161369947547,
      "grad_norm": 7.245841402436781e-07,
      "learning_rate": 1.8028386300524532e-05,
      "loss": 0.0002,
      "step": 103620
    },
    {
      "epoch": 31.974699166923788,
      "grad_norm": 3.820753136096755e-06,
      "learning_rate": 1.802530083307621e-05,
      "loss": 0.0068,
      "step": 103630
    },
    {
      "epoch": 31.977784634372107,
      "grad_norm": 0.0003633509622886777,
      "learning_rate": 1.8022215365627893e-05,
      "loss": 0.0,
      "step": 103640
    },
    {
      "epoch": 31.980870101820425,
      "grad_norm": 5.514903023140505e-05,
      "learning_rate": 1.8019129898179576e-05,
      "loss": 0.0012,
      "step": 103650
    },
    {
      "epoch": 31.983955569268744,
      "grad_norm": 3.0717001209268346e-06,
      "learning_rate": 1.801604443073126e-05,
      "loss": 0.0001,
      "step": 103660
    },
    {
      "epoch": 31.987041036717063,
      "grad_norm": 2.2737417221069336,
      "learning_rate": 1.8012958963282937e-05,
      "loss": 0.001,
      "step": 103670
    },
    {
      "epoch": 31.99012650416538,
      "grad_norm": 0.00015167951642069966,
      "learning_rate": 1.800987349583462e-05,
      "loss": 0.0,
      "step": 103680
    },
    {
      "epoch": 31.9932119716137,
      "grad_norm": 4.549034926526474e-08,
      "learning_rate": 1.8006788028386302e-05,
      "loss": 0.0,
      "step": 103690
    },
    {
      "epoch": 31.99629743906202,
      "grad_norm": 0.0012161869090050459,
      "learning_rate": 1.800370256093798e-05,
      "loss": 0.0,
      "step": 103700
    },
    {
      "epoch": 31.999382906510338,
      "grad_norm": 0.02931183949112892,
      "learning_rate": 1.8000617093489664e-05,
      "loss": 0.0001,
      "step": 103710
    },
    {
      "epoch": 32.0,
      "eval_accuracy_branch1": 0.9997878147815938,
      "eval_accuracy_branch2": 0.41418554632871346,
      "eval_f1_branch1": 0.9996870751039637,
      "eval_f1_branch2": 0.40421029178579765,
      "eval_loss": 0.0005671723047271371,
      "eval_precision_branch1": 0.9996839741072314,
      "eval_precision_branch2": 0.519822514620565,
      "eval_recall_branch1": 0.9996906469491399,
      "eval_recall_branch2": 0.5144816411562165,
      "eval_runtime": 237.3252,
      "eval_samples_per_second": 436.881,
      "eval_steps_per_second": 54.613,
      "step": 103712
    },
    {
      "epoch": 32.002468373958656,
      "grad_norm": 6.756872608093545e-05,
      "learning_rate": 1.7997531626041346e-05,
      "loss": 0.0059,
      "step": 103720
    },
    {
      "epoch": 32.00555384140697,
      "grad_norm": 0.010951733216643333,
      "learning_rate": 1.799444615859303e-05,
      "loss": 0.002,
      "step": 103730
    },
    {
      "epoch": 32.008639308855294,
      "grad_norm": 8.014861123228911e-06,
      "learning_rate": 1.7991360691144708e-05,
      "loss": 0.0,
      "step": 103740
    },
    {
      "epoch": 32.01172477630361,
      "grad_norm": 1.434474870620761e-05,
      "learning_rate": 1.798827522369639e-05,
      "loss": 0.0,
      "step": 103750
    },
    {
      "epoch": 32.01481024375193,
      "grad_norm": 0.0001379442837787792,
      "learning_rate": 1.7985189756248073e-05,
      "loss": 0.0003,
      "step": 103760
    },
    {
      "epoch": 32.01789571120025,
      "grad_norm": 0.0032559295650571585,
      "learning_rate": 1.7982104288799752e-05,
      "loss": 0.0003,
      "step": 103770
    },
    {
      "epoch": 32.02098117864857,
      "grad_norm": 3.4260494430782273e-05,
      "learning_rate": 1.7979018821351435e-05,
      "loss": 0.0024,
      "step": 103780
    },
    {
      "epoch": 32.024066646096884,
      "grad_norm": 0.8581592440605164,
      "learning_rate": 1.7975933353903117e-05,
      "loss": 0.007,
      "step": 103790
    },
    {
      "epoch": 32.0271521135452,
      "grad_norm": 0.00014502459089271724,
      "learning_rate": 1.79728478864548e-05,
      "loss": 0.0,
      "step": 103800
    },
    {
      "epoch": 32.03023758099352,
      "grad_norm": 2.1236080556263914e-06,
      "learning_rate": 1.7969762419006482e-05,
      "loss": 0.0007,
      "step": 103810
    },
    {
      "epoch": 32.03332304844184,
      "grad_norm": 0.0008246226352639496,
      "learning_rate": 1.796667695155816e-05,
      "loss": 0.0001,
      "step": 103820
    },
    {
      "epoch": 32.03640851589016,
      "grad_norm": 4.2597872379701585e-05,
      "learning_rate": 1.7963591484109844e-05,
      "loss": 0.0,
      "step": 103830
    },
    {
      "epoch": 32.039493983338474,
      "grad_norm": 3.6546713090501726e-05,
      "learning_rate": 1.7960506016661523e-05,
      "loss": 0.0001,
      "step": 103840
    },
    {
      "epoch": 32.042579450786796,
      "grad_norm": 7.447492407663958e-06,
      "learning_rate": 1.795742054921321e-05,
      "loss": 0.0007,
      "step": 103850
    },
    {
      "epoch": 32.04566491823511,
      "grad_norm": 2.6286781576345675e-05,
      "learning_rate": 1.7954335081764888e-05,
      "loss": 0.0,
      "step": 103860
    },
    {
      "epoch": 32.048750385683434,
      "grad_norm": 0.008725357241928577,
      "learning_rate": 1.795124961431657e-05,
      "loss": 0.0002,
      "step": 103870
    },
    {
      "epoch": 32.05183585313175,
      "grad_norm": 1.735429759719409e-05,
      "learning_rate": 1.7948164146868253e-05,
      "loss": 0.0006,
      "step": 103880
    },
    {
      "epoch": 32.05492132058007,
      "grad_norm": 3.1623799800872803,
      "learning_rate": 1.794507867941993e-05,
      "loss": 0.0038,
      "step": 103890
    },
    {
      "epoch": 32.058006788028386,
      "grad_norm": 1.3696775567950681e-05,
      "learning_rate": 1.7941993211971614e-05,
      "loss": 0.0,
      "step": 103900
    },
    {
      "epoch": 32.0610922554767,
      "grad_norm": 0.0006214659078978002,
      "learning_rate": 1.7938907744523297e-05,
      "loss": 0.0,
      "step": 103910
    },
    {
      "epoch": 32.064177722925024,
      "grad_norm": 0.00657467357814312,
      "learning_rate": 1.793582227707498e-05,
      "loss": 0.0028,
      "step": 103920
    },
    {
      "epoch": 32.06726319037334,
      "grad_norm": 1.4573219004887505e-06,
      "learning_rate": 1.793273680962666e-05,
      "loss": 0.0013,
      "step": 103930
    },
    {
      "epoch": 32.07034865782166,
      "grad_norm": 0.024648433551192284,
      "learning_rate": 1.792965134217834e-05,
      "loss": 0.0044,
      "step": 103940
    },
    {
      "epoch": 32.073434125269976,
      "grad_norm": 0.000266492017544806,
      "learning_rate": 1.7926565874730023e-05,
      "loss": 0.0018,
      "step": 103950
    },
    {
      "epoch": 32.0765195927183,
      "grad_norm": 1.433211309631588e-05,
      "learning_rate": 1.7923480407281702e-05,
      "loss": 0.0,
      "step": 103960
    },
    {
      "epoch": 32.079605060166614,
      "grad_norm": 0.0008253243286162615,
      "learning_rate": 1.7920394939833385e-05,
      "loss": 0.0001,
      "step": 103970
    },
    {
      "epoch": 32.082690527614936,
      "grad_norm": 6.843513347121188e-07,
      "learning_rate": 1.7917309472385067e-05,
      "loss": 0.0016,
      "step": 103980
    },
    {
      "epoch": 32.08577599506325,
      "grad_norm": 0.0665508359670639,
      "learning_rate": 1.791422400493675e-05,
      "loss": 0.0003,
      "step": 103990
    },
    {
      "epoch": 32.088861462511574,
      "grad_norm": 1.0567428944341373e-05,
      "learning_rate": 1.7911138537488432e-05,
      "loss": 0.0,
      "step": 104000
    },
    {
      "epoch": 32.09194692995989,
      "grad_norm": 0.006805587559938431,
      "learning_rate": 1.790805307004011e-05,
      "loss": 0.0001,
      "step": 104010
    },
    {
      "epoch": 32.095032397408204,
      "grad_norm": 0.0004328996001277119,
      "learning_rate": 1.7904967602591794e-05,
      "loss": 0.0,
      "step": 104020
    },
    {
      "epoch": 32.098117864856526,
      "grad_norm": 3.625150384323206e-06,
      "learning_rate": 1.7901882135143476e-05,
      "loss": 0.0008,
      "step": 104030
    },
    {
      "epoch": 32.10120333230484,
      "grad_norm": 1.881879688880872e-05,
      "learning_rate": 1.7898796667695155e-05,
      "loss": 0.0016,
      "step": 104040
    },
    {
      "epoch": 32.104288799753164,
      "grad_norm": 0.0541917122900486,
      "learning_rate": 1.7895711200246838e-05,
      "loss": 0.0,
      "step": 104050
    },
    {
      "epoch": 32.10737426720148,
      "grad_norm": 0.002638867124915123,
      "learning_rate": 1.789262573279852e-05,
      "loss": 0.0,
      "step": 104060
    },
    {
      "epoch": 32.1104597346498,
      "grad_norm": 3.641664079623297e-05,
      "learning_rate": 1.7889540265350203e-05,
      "loss": 0.0007,
      "step": 104070
    },
    {
      "epoch": 32.113545202098116,
      "grad_norm": 1.4223674952518195e-05,
      "learning_rate": 1.7886454797901882e-05,
      "loss": 0.0001,
      "step": 104080
    },
    {
      "epoch": 32.11663066954644,
      "grad_norm": 0.011383659206330776,
      "learning_rate": 1.7883369330453564e-05,
      "loss": 0.0003,
      "step": 104090
    },
    {
      "epoch": 32.119716136994754,
      "grad_norm": 0.00036736828042194247,
      "learning_rate": 1.7880283863005247e-05,
      "loss": 0.0001,
      "step": 104100
    },
    {
      "epoch": 32.122801604443076,
      "grad_norm": 1.81365612661466e-05,
      "learning_rate": 1.7877198395556926e-05,
      "loss": 0.0,
      "step": 104110
    },
    {
      "epoch": 32.12588707189139,
      "grad_norm": 4.553719463729067e-06,
      "learning_rate": 1.787411292810861e-05,
      "loss": 0.0,
      "step": 104120
    },
    {
      "epoch": 32.12897253933971,
      "grad_norm": 4.319385051727295,
      "learning_rate": 1.787102746066029e-05,
      "loss": 0.0112,
      "step": 104130
    },
    {
      "epoch": 32.13205800678803,
      "grad_norm": 3.207777626812458e-05,
      "learning_rate": 1.7867941993211973e-05,
      "loss": 0.0,
      "step": 104140
    },
    {
      "epoch": 32.135143474236344,
      "grad_norm": 6.57821601635078e-08,
      "learning_rate": 1.7864856525763656e-05,
      "loss": 0.0,
      "step": 104150
    },
    {
      "epoch": 32.138228941684666,
      "grad_norm": 4.849795914196875e-06,
      "learning_rate": 1.7861771058315335e-05,
      "loss": 0.0014,
      "step": 104160
    },
    {
      "epoch": 32.14131440913298,
      "grad_norm": 9.241489351552445e-06,
      "learning_rate": 1.7858685590867017e-05,
      "loss": 0.0011,
      "step": 104170
    },
    {
      "epoch": 32.1443998765813,
      "grad_norm": 0.00030693941516801715,
      "learning_rate": 1.7855600123418696e-05,
      "loss": 0.0,
      "step": 104180
    },
    {
      "epoch": 32.14748534402962,
      "grad_norm": 4.306920163799077e-05,
      "learning_rate": 1.7852514655970382e-05,
      "loss": 0.0,
      "step": 104190
    },
    {
      "epoch": 32.15057081147794,
      "grad_norm": 4.832375907426467e-06,
      "learning_rate": 1.784942918852206e-05,
      "loss": 0.0005,
      "step": 104200
    },
    {
      "epoch": 32.153656278926256,
      "grad_norm": 0.002317313803359866,
      "learning_rate": 1.7846343721073744e-05,
      "loss": 0.0,
      "step": 104210
    },
    {
      "epoch": 32.15674174637458,
      "grad_norm": 7.014810398686677e-05,
      "learning_rate": 1.7843258253625426e-05,
      "loss": 0.0,
      "step": 104220
    },
    {
      "epoch": 32.159827213822894,
      "grad_norm": 0.0106097012758255,
      "learning_rate": 1.7840172786177105e-05,
      "loss": 0.0,
      "step": 104230
    },
    {
      "epoch": 32.162912681271216,
      "grad_norm": 0.0015813620993867517,
      "learning_rate": 1.7837087318728788e-05,
      "loss": 0.0,
      "step": 104240
    },
    {
      "epoch": 32.16599814871953,
      "grad_norm": 0.0004620541585609317,
      "learning_rate": 1.7834001851280467e-05,
      "loss": 0.0,
      "step": 104250
    },
    {
      "epoch": 32.169083616167846,
      "grad_norm": 2.0981726265745237e-05,
      "learning_rate": 1.7830916383832153e-05,
      "loss": 0.0,
      "step": 104260
    },
    {
      "epoch": 32.17216908361617,
      "grad_norm": 2.260431574541144e-05,
      "learning_rate": 1.7827830916383835e-05,
      "loss": 0.0,
      "step": 104270
    },
    {
      "epoch": 32.175254551064484,
      "grad_norm": 0.00020214523829054087,
      "learning_rate": 1.7824745448935514e-05,
      "loss": 0.0,
      "step": 104280
    },
    {
      "epoch": 32.178340018512806,
      "grad_norm": 2.51726833084831e-05,
      "learning_rate": 1.7821659981487197e-05,
      "loss": 0.0,
      "step": 104290
    },
    {
      "epoch": 32.18142548596112,
      "grad_norm": 7.001050903454598e-07,
      "learning_rate": 1.7818574514038876e-05,
      "loss": 0.0,
      "step": 104300
    },
    {
      "epoch": 32.18451095340944,
      "grad_norm": 4.7492835619777907e-07,
      "learning_rate": 1.781548904659056e-05,
      "loss": 0.0001,
      "step": 104310
    },
    {
      "epoch": 32.18759642085776,
      "grad_norm": 0.00439405394718051,
      "learning_rate": 1.781240357914224e-05,
      "loss": 0.0,
      "step": 104320
    },
    {
      "epoch": 32.19068188830608,
      "grad_norm": 0.0014837937196716666,
      "learning_rate": 1.7809318111693923e-05,
      "loss": 0.0004,
      "step": 104330
    },
    {
      "epoch": 32.193767355754396,
      "grad_norm": 2.439119953123736e-06,
      "learning_rate": 1.7806232644245606e-05,
      "loss": 0.0,
      "step": 104340
    },
    {
      "epoch": 32.19685282320272,
      "grad_norm": 0.005741792730987072,
      "learning_rate": 1.7803147176797285e-05,
      "loss": 0.0,
      "step": 104350
    },
    {
      "epoch": 32.19993829065103,
      "grad_norm": 1.3874389878765214e-05,
      "learning_rate": 1.7800061709348967e-05,
      "loss": 0.0,
      "step": 104360
    },
    {
      "epoch": 32.20302375809935,
      "grad_norm": 0.053596992045640945,
      "learning_rate": 1.7796976241900646e-05,
      "loss": 0.0045,
      "step": 104370
    },
    {
      "epoch": 32.20610922554767,
      "grad_norm": 0.00016345952462870628,
      "learning_rate": 1.779389077445233e-05,
      "loss": 0.0,
      "step": 104380
    },
    {
      "epoch": 32.209194692995986,
      "grad_norm": 9.646987564337905e-07,
      "learning_rate": 1.7790805307004015e-05,
      "loss": 0.0001,
      "step": 104390
    },
    {
      "epoch": 32.21228016044431,
      "grad_norm": 0.007204269524663687,
      "learning_rate": 1.7787719839555694e-05,
      "loss": 0.0001,
      "step": 104400
    },
    {
      "epoch": 32.21536562789262,
      "grad_norm": 1.6258103414656944e-06,
      "learning_rate": 1.7784634372107376e-05,
      "loss": 0.0,
      "step": 104410
    },
    {
      "epoch": 32.218451095340946,
      "grad_norm": 1.0220265721727628e-05,
      "learning_rate": 1.7781548904659055e-05,
      "loss": 0.0,
      "step": 104420
    },
    {
      "epoch": 32.22153656278926,
      "grad_norm": 0.00025160907534882426,
      "learning_rate": 1.7778463437210738e-05,
      "loss": 0.0001,
      "step": 104430
    },
    {
      "epoch": 32.22462203023758,
      "grad_norm": 4.7579898819094524e-05,
      "learning_rate": 1.777537796976242e-05,
      "loss": 0.0,
      "step": 104440
    },
    {
      "epoch": 32.2277074976859,
      "grad_norm": 0.07011116296052933,
      "learning_rate": 1.77722925023141e-05,
      "loss": 0.0001,
      "step": 104450
    },
    {
      "epoch": 32.23079296513422,
      "grad_norm": 0.051090944558382034,
      "learning_rate": 1.7769207034865785e-05,
      "loss": 0.0011,
      "step": 104460
    },
    {
      "epoch": 32.233878432582536,
      "grad_norm": 0.03549228981137276,
      "learning_rate": 1.7766121567417464e-05,
      "loss": 0.0012,
      "step": 104470
    },
    {
      "epoch": 32.23696390003086,
      "grad_norm": 5.4836114031786565e-06,
      "learning_rate": 1.7763036099969147e-05,
      "loss": 0.0001,
      "step": 104480
    },
    {
      "epoch": 32.24004936747917,
      "grad_norm": 1.9128419808112085e-06,
      "learning_rate": 1.7759950632520826e-05,
      "loss": 0.0,
      "step": 104490
    },
    {
      "epoch": 32.24313483492749,
      "grad_norm": 0.0002221745962742716,
      "learning_rate": 1.775686516507251e-05,
      "loss": 0.0001,
      "step": 104500
    },
    {
      "epoch": 32.24622030237581,
      "grad_norm": 9.351775588584132e-06,
      "learning_rate": 1.775377969762419e-05,
      "loss": 0.0004,
      "step": 104510
    },
    {
      "epoch": 32.249305769824126,
      "grad_norm": 0.0008859536610543728,
      "learning_rate": 1.7750694230175873e-05,
      "loss": 0.0,
      "step": 104520
    },
    {
      "epoch": 32.25239123727245,
      "grad_norm": 8.417695062234998e-05,
      "learning_rate": 1.7747608762727556e-05,
      "loss": 0.0,
      "step": 104530
    },
    {
      "epoch": 32.25547670472076,
      "grad_norm": 0.0008581180009059608,
      "learning_rate": 1.7744523295279235e-05,
      "loss": 0.0,
      "step": 104540
    },
    {
      "epoch": 32.258562172169086,
      "grad_norm": 1.438825529476162e-05,
      "learning_rate": 1.7741437827830917e-05,
      "loss": 0.0,
      "step": 104550
    },
    {
      "epoch": 32.2616476396174,
      "grad_norm": 2.6570173758955207e-06,
      "learning_rate": 1.77383523603826e-05,
      "loss": 0.0008,
      "step": 104560
    },
    {
      "epoch": 32.26473310706572,
      "grad_norm": 0.00018269193242304027,
      "learning_rate": 1.773526689293428e-05,
      "loss": 0.0,
      "step": 104570
    },
    {
      "epoch": 32.26781857451404,
      "grad_norm": 0.004768237005919218,
      "learning_rate": 1.773218142548596e-05,
      "loss": 0.0001,
      "step": 104580
    },
    {
      "epoch": 32.27090404196236,
      "grad_norm": 1.2971569049113896e-05,
      "learning_rate": 1.7729095958037644e-05,
      "loss": 0.0,
      "step": 104590
    },
    {
      "epoch": 32.273989509410676,
      "grad_norm": 5.555010034186125e-07,
      "learning_rate": 1.7726010490589326e-05,
      "loss": 0.0,
      "step": 104600
    },
    {
      "epoch": 32.27707497685899,
      "grad_norm": 0.0007282394799403846,
      "learning_rate": 1.7722925023141006e-05,
      "loss": 0.0,
      "step": 104610
    },
    {
      "epoch": 32.28016044430731,
      "grad_norm": 3.102693199252826e-06,
      "learning_rate": 1.7719839555692688e-05,
      "loss": 0.0002,
      "step": 104620
    },
    {
      "epoch": 32.28324591175563,
      "grad_norm": 2.0619891074602492e-05,
      "learning_rate": 1.771675408824437e-05,
      "loss": 0.0,
      "step": 104630
    },
    {
      "epoch": 32.28633137920395,
      "grad_norm": 0.03279982507228851,
      "learning_rate": 1.771366862079605e-05,
      "loss": 0.0001,
      "step": 104640
    },
    {
      "epoch": 32.289416846652266,
      "grad_norm": 0.00015188213728833944,
      "learning_rate": 1.7710583153347732e-05,
      "loss": 0.0026,
      "step": 104650
    },
    {
      "epoch": 32.29250231410059,
      "grad_norm": 2.9082473702146672e-05,
      "learning_rate": 1.7707497685899415e-05,
      "loss": 0.0,
      "step": 104660
    },
    {
      "epoch": 32.2955877815489,
      "grad_norm": 1.3815903663635254,
      "learning_rate": 1.7704412218451097e-05,
      "loss": 0.0012,
      "step": 104670
    },
    {
      "epoch": 32.298673248997225,
      "grad_norm": 0.00013209442840889096,
      "learning_rate": 1.770132675100278e-05,
      "loss": 0.0,
      "step": 104680
    },
    {
      "epoch": 32.30175871644554,
      "grad_norm": 0.16278301179409027,
      "learning_rate": 1.769824128355446e-05,
      "loss": 0.0001,
      "step": 104690
    },
    {
      "epoch": 32.30484418389386,
      "grad_norm": 0.07786358147859573,
      "learning_rate": 1.769515581610614e-05,
      "loss": 0.0,
      "step": 104700
    },
    {
      "epoch": 32.30792965134218,
      "grad_norm": 0.2983594834804535,
      "learning_rate": 1.769207034865782e-05,
      "loss": 0.0003,
      "step": 104710
    },
    {
      "epoch": 32.31101511879049,
      "grad_norm": 0.0057687051594257355,
      "learning_rate": 1.7688984881209503e-05,
      "loss": 0.0051,
      "step": 104720
    },
    {
      "epoch": 32.314100586238816,
      "grad_norm": 0.0218327846378088,
      "learning_rate": 1.7685899413761185e-05,
      "loss": 0.0,
      "step": 104730
    },
    {
      "epoch": 32.31718605368713,
      "grad_norm": 4.7459197958232835e-06,
      "learning_rate": 1.7682813946312868e-05,
      "loss": 0.0,
      "step": 104740
    },
    {
      "epoch": 32.32027152113545,
      "grad_norm": 0.0014708638191223145,
      "learning_rate": 1.767972847886455e-05,
      "loss": 0.0,
      "step": 104750
    },
    {
      "epoch": 32.32335698858377,
      "grad_norm": 1.6729774870327674e-05,
      "learning_rate": 1.767664301141623e-05,
      "loss": 0.0014,
      "step": 104760
    },
    {
      "epoch": 32.32644245603209,
      "grad_norm": 0.0008455056813545525,
      "learning_rate": 1.767355754396791e-05,
      "loss": 0.0,
      "step": 104770
    },
    {
      "epoch": 32.329527923480406,
      "grad_norm": 0.9321722388267517,
      "learning_rate": 1.7670472076519594e-05,
      "loss": 0.0012,
      "step": 104780
    },
    {
      "epoch": 32.33261339092873,
      "grad_norm": 0.00022390867525245994,
      "learning_rate": 1.7667386609071277e-05,
      "loss": 0.0,
      "step": 104790
    },
    {
      "epoch": 32.33569885837704,
      "grad_norm": 7.926746911834925e-05,
      "learning_rate": 1.766430114162296e-05,
      "loss": 0.0,
      "step": 104800
    },
    {
      "epoch": 32.338784325825365,
      "grad_norm": 2.620244413265027e-05,
      "learning_rate": 1.7661215674174638e-05,
      "loss": 0.0,
      "step": 104810
    },
    {
      "epoch": 32.34186979327368,
      "grad_norm": 0.04661126434803009,
      "learning_rate": 1.765813020672632e-05,
      "loss": 0.0018,
      "step": 104820
    },
    {
      "epoch": 32.344955260722,
      "grad_norm": 2.7037538075092016e-06,
      "learning_rate": 1.7655044739278e-05,
      "loss": 0.0,
      "step": 104830
    },
    {
      "epoch": 32.34804072817032,
      "grad_norm": 0.003245610510930419,
      "learning_rate": 1.7651959271829682e-05,
      "loss": 0.0,
      "step": 104840
    },
    {
      "epoch": 32.35112619561863,
      "grad_norm": 1.2085013622709084e-05,
      "learning_rate": 1.7648873804381365e-05,
      "loss": 0.0,
      "step": 104850
    },
    {
      "epoch": 32.354211663066955,
      "grad_norm": 0.049446068704128265,
      "learning_rate": 1.7645788336933047e-05,
      "loss": 0.0,
      "step": 104860
    },
    {
      "epoch": 32.35729713051527,
      "grad_norm": 4.625324436347e-06,
      "learning_rate": 1.764270286948473e-05,
      "loss": 0.0,
      "step": 104870
    },
    {
      "epoch": 32.36038259796359,
      "grad_norm": 2.899703304137802e-07,
      "learning_rate": 1.763961740203641e-05,
      "loss": 0.0,
      "step": 104880
    },
    {
      "epoch": 32.36346806541191,
      "grad_norm": 0.00020222406601533294,
      "learning_rate": 1.763653193458809e-05,
      "loss": 0.0,
      "step": 104890
    },
    {
      "epoch": 32.36655353286023,
      "grad_norm": 0.0014800369972363114,
      "learning_rate": 1.7633446467139774e-05,
      "loss": 0.0002,
      "step": 104900
    },
    {
      "epoch": 32.369639000308545,
      "grad_norm": 8.266021609415475e-07,
      "learning_rate": 1.7630360999691453e-05,
      "loss": 0.0001,
      "step": 104910
    },
    {
      "epoch": 32.37272446775687,
      "grad_norm": 7.800629828125238e-05,
      "learning_rate": 1.7627275532243135e-05,
      "loss": 0.0017,
      "step": 104920
    },
    {
      "epoch": 32.37580993520518,
      "grad_norm": 0.0001493838499300182,
      "learning_rate": 1.7624190064794818e-05,
      "loss": 0.0,
      "step": 104930
    },
    {
      "epoch": 32.378895402653505,
      "grad_norm": 0.00014336005551740527,
      "learning_rate": 1.76211045973465e-05,
      "loss": 0.0,
      "step": 104940
    },
    {
      "epoch": 32.38198087010182,
      "grad_norm": 0.0014709082897752523,
      "learning_rate": 1.761801912989818e-05,
      "loss": 0.0012,
      "step": 104950
    },
    {
      "epoch": 32.385066337550136,
      "grad_norm": 8.760056516621262e-05,
      "learning_rate": 1.7614933662449862e-05,
      "loss": 0.0003,
      "step": 104960
    },
    {
      "epoch": 32.38815180499846,
      "grad_norm": 0.0015695920446887612,
      "learning_rate": 1.7611848195001544e-05,
      "loss": 0.0009,
      "step": 104970
    },
    {
      "epoch": 32.39123727244677,
      "grad_norm": 0.00022073311265558004,
      "learning_rate": 1.7608762727553223e-05,
      "loss": 0.0047,
      "step": 104980
    },
    {
      "epoch": 32.394322739895095,
      "grad_norm": 0.011732595972716808,
      "learning_rate": 1.760567726010491e-05,
      "loss": 0.0,
      "step": 104990
    },
    {
      "epoch": 32.39740820734341,
      "grad_norm": 0.0041521755047142506,
      "learning_rate": 1.7602591792656588e-05,
      "loss": 0.0047,
      "step": 105000
    },
    {
      "epoch": 32.40049367479173,
      "grad_norm": 1.445636712560372e-06,
      "learning_rate": 1.759950632520827e-05,
      "loss": 0.0001,
      "step": 105010
    },
    {
      "epoch": 32.40357914224005,
      "grad_norm": 0.05870267376303673,
      "learning_rate": 1.759642085775995e-05,
      "loss": 0.0001,
      "step": 105020
    },
    {
      "epoch": 32.40666460968837,
      "grad_norm": 2.3759739633533172e-05,
      "learning_rate": 1.7593335390311632e-05,
      "loss": 0.0,
      "step": 105030
    },
    {
      "epoch": 32.409750077136685,
      "grad_norm": 0.00014305859804153442,
      "learning_rate": 1.7590249922863315e-05,
      "loss": 0.0,
      "step": 105040
    },
    {
      "epoch": 32.41283554458501,
      "grad_norm": 0.00018109125085175037,
      "learning_rate": 1.7587164455414994e-05,
      "loss": 0.0,
      "step": 105050
    },
    {
      "epoch": 32.41592101203332,
      "grad_norm": 2.224342097179033e-06,
      "learning_rate": 1.758407898796668e-05,
      "loss": 0.0001,
      "step": 105060
    },
    {
      "epoch": 32.41900647948164,
      "grad_norm": 1.1804307177953888e-05,
      "learning_rate": 1.758099352051836e-05,
      "loss": 0.0,
      "step": 105070
    },
    {
      "epoch": 32.42209194692996,
      "grad_norm": 2.00082049559569e-05,
      "learning_rate": 1.757790805307004e-05,
      "loss": 0.0,
      "step": 105080
    },
    {
      "epoch": 32.425177414378275,
      "grad_norm": 4.028921466669999e-06,
      "learning_rate": 1.7574822585621724e-05,
      "loss": 0.0005,
      "step": 105090
    },
    {
      "epoch": 32.4282628818266,
      "grad_norm": 0.008653697557747364,
      "learning_rate": 1.7571737118173403e-05,
      "loss": 0.0,
      "step": 105100
    },
    {
      "epoch": 32.43134834927491,
      "grad_norm": 6.112099526944803e-06,
      "learning_rate": 1.7568651650725085e-05,
      "loss": 0.0005,
      "step": 105110
    },
    {
      "epoch": 32.434433816723235,
      "grad_norm": 1.984007212740835e-06,
      "learning_rate": 1.7565566183276764e-05,
      "loss": 0.0,
      "step": 105120
    },
    {
      "epoch": 32.43751928417155,
      "grad_norm": 0.0005309600965119898,
      "learning_rate": 1.756248071582845e-05,
      "loss": 0.0,
      "step": 105130
    },
    {
      "epoch": 32.44060475161987,
      "grad_norm": 0.22982722520828247,
      "learning_rate": 1.755939524838013e-05,
      "loss": 0.0001,
      "step": 105140
    },
    {
      "epoch": 32.44369021906819,
      "grad_norm": 0.0995728000998497,
      "learning_rate": 1.7556309780931812e-05,
      "loss": 0.0,
      "step": 105150
    },
    {
      "epoch": 32.44677568651651,
      "grad_norm": 0.0002290369593538344,
      "learning_rate": 1.7553224313483494e-05,
      "loss": 0.0,
      "step": 105160
    },
    {
      "epoch": 32.449861153964825,
      "grad_norm": 1.6607881434538285e-06,
      "learning_rate": 1.7550138846035173e-05,
      "loss": 0.0,
      "step": 105170
    },
    {
      "epoch": 32.45294662141315,
      "grad_norm": 5.111986411066027e-06,
      "learning_rate": 1.7547053378586856e-05,
      "loss": 0.0,
      "step": 105180
    },
    {
      "epoch": 32.45603208886146,
      "grad_norm": 0.001386575517244637,
      "learning_rate": 1.754396791113854e-05,
      "loss": 0.0,
      "step": 105190
    },
    {
      "epoch": 32.45911755630978,
      "grad_norm": 5.81786225666292e-05,
      "learning_rate": 1.754088244369022e-05,
      "loss": 0.0,
      "step": 105200
    },
    {
      "epoch": 32.4622030237581,
      "grad_norm": 0.001953868195414543,
      "learning_rate": 1.7537796976241903e-05,
      "loss": 0.0002,
      "step": 105210
    },
    {
      "epoch": 32.465288491206415,
      "grad_norm": 3.6210290090821218e-06,
      "learning_rate": 1.7534711508793582e-05,
      "loss": 0.0,
      "step": 105220
    },
    {
      "epoch": 32.46837395865474,
      "grad_norm": 8.609842188889161e-05,
      "learning_rate": 1.7531626041345265e-05,
      "loss": 0.0,
      "step": 105230
    },
    {
      "epoch": 32.47145942610305,
      "grad_norm": 6.0397902416298166e-05,
      "learning_rate": 1.7528540573896944e-05,
      "loss": 0.0,
      "step": 105240
    },
    {
      "epoch": 32.474544893551375,
      "grad_norm": 0.000817808962892741,
      "learning_rate": 1.7525455106448627e-05,
      "loss": 0.0,
      "step": 105250
    },
    {
      "epoch": 32.47763036099969,
      "grad_norm": 6.914047556705327e-09,
      "learning_rate": 1.752236963900031e-05,
      "loss": 0.0,
      "step": 105260
    },
    {
      "epoch": 32.48071582844801,
      "grad_norm": 2.9363316571107134e-05,
      "learning_rate": 1.751928417155199e-05,
      "loss": 0.0,
      "step": 105270
    },
    {
      "epoch": 32.48380129589633,
      "grad_norm": 0.0007516656187362969,
      "learning_rate": 1.7516198704103674e-05,
      "loss": 0.0001,
      "step": 105280
    },
    {
      "epoch": 32.48688676334465,
      "grad_norm": 0.0015097567811608315,
      "learning_rate": 1.7513113236655353e-05,
      "loss": 0.0,
      "step": 105290
    },
    {
      "epoch": 32.489972230792965,
      "grad_norm": 3.556249339453643e-06,
      "learning_rate": 1.7510027769207035e-05,
      "loss": 0.0,
      "step": 105300
    },
    {
      "epoch": 32.49305769824128,
      "grad_norm": 3.4815900562534807e-06,
      "learning_rate": 1.7506942301758718e-05,
      "loss": 0.0,
      "step": 105310
    },
    {
      "epoch": 32.4961431656896,
      "grad_norm": 0.0004728876519948244,
      "learning_rate": 1.7503856834310397e-05,
      "loss": 0.0007,
      "step": 105320
    },
    {
      "epoch": 32.49922863313792,
      "grad_norm": 8.947480637289118e-06,
      "learning_rate": 1.7500771366862083e-05,
      "loss": 0.0,
      "step": 105330
    },
    {
      "epoch": 32.50231410058624,
      "grad_norm": 6.993442366365343e-05,
      "learning_rate": 1.7497685899413762e-05,
      "loss": 0.0,
      "step": 105340
    },
    {
      "epoch": 32.505399568034555,
      "grad_norm": 3.863281108351657e-07,
      "learning_rate": 1.7494600431965444e-05,
      "loss": 0.0,
      "step": 105350
    },
    {
      "epoch": 32.50848503548288,
      "grad_norm": 0.00018093005928676575,
      "learning_rate": 1.7491514964517124e-05,
      "loss": 0.0005,
      "step": 105360
    },
    {
      "epoch": 32.51157050293119,
      "grad_norm": 2.0299698917369824e-06,
      "learning_rate": 1.7488429497068806e-05,
      "loss": 0.0,
      "step": 105370
    },
    {
      "epoch": 32.514655970379515,
      "grad_norm": 0.0007269272464327514,
      "learning_rate": 1.748534402962049e-05,
      "loss": 0.0,
      "step": 105380
    },
    {
      "epoch": 32.51774143782783,
      "grad_norm": 0.0016536375042051077,
      "learning_rate": 1.748225856217217e-05,
      "loss": 0.0001,
      "step": 105390
    },
    {
      "epoch": 32.52082690527615,
      "grad_norm": 1.3406604466581484e-06,
      "learning_rate": 1.7479173094723853e-05,
      "loss": 0.0,
      "step": 105400
    },
    {
      "epoch": 32.52391237272447,
      "grad_norm": 0.00022125276154838502,
      "learning_rate": 1.7476087627275533e-05,
      "loss": 0.0,
      "step": 105410
    },
    {
      "epoch": 32.52699784017278,
      "grad_norm": 0.00016481267812196165,
      "learning_rate": 1.7473002159827215e-05,
      "loss": 0.0,
      "step": 105420
    },
    {
      "epoch": 32.530083307621105,
      "grad_norm": 0.002222418552264571,
      "learning_rate": 1.7469916692378898e-05,
      "loss": 0.0,
      "step": 105430
    },
    {
      "epoch": 32.53316877506942,
      "grad_norm": 4.774272383656353e-05,
      "learning_rate": 1.7466831224930577e-05,
      "loss": 0.0001,
      "step": 105440
    },
    {
      "epoch": 32.53625424251774,
      "grad_norm": 1.4154881682770792e-05,
      "learning_rate": 1.746374575748226e-05,
      "loss": 0.0008,
      "step": 105450
    },
    {
      "epoch": 32.53933970996606,
      "grad_norm": 3.988499520346522e-05,
      "learning_rate": 1.746066029003394e-05,
      "loss": 0.0,
      "step": 105460
    },
    {
      "epoch": 32.54242517741438,
      "grad_norm": 1.7083712009480223e-05,
      "learning_rate": 1.7457574822585624e-05,
      "loss": 0.0001,
      "step": 105470
    },
    {
      "epoch": 32.545510644862695,
      "grad_norm": 0.00025962525978684425,
      "learning_rate": 1.7454489355137303e-05,
      "loss": 0.0,
      "step": 105480
    },
    {
      "epoch": 32.54859611231102,
      "grad_norm": 2.0940747162967455e-06,
      "learning_rate": 1.7451403887688986e-05,
      "loss": 0.0,
      "step": 105490
    },
    {
      "epoch": 32.55168157975933,
      "grad_norm": 0.00012426341709215194,
      "learning_rate": 1.7448318420240668e-05,
      "loss": 0.0,
      "step": 105500
    },
    {
      "epoch": 32.554767047207655,
      "grad_norm": 0.0026269368827342987,
      "learning_rate": 1.7445232952792347e-05,
      "loss": 0.0,
      "step": 105510
    },
    {
      "epoch": 32.55785251465597,
      "grad_norm": 0.002303829649463296,
      "learning_rate": 1.744214748534403e-05,
      "loss": 0.0001,
      "step": 105520
    },
    {
      "epoch": 32.56093798210429,
      "grad_norm": 3.466698217380326e-07,
      "learning_rate": 1.7439062017895712e-05,
      "loss": 0.0,
      "step": 105530
    },
    {
      "epoch": 32.56402344955261,
      "grad_norm": 3.358309913892299e-05,
      "learning_rate": 1.7435976550447395e-05,
      "loss": 0.0,
      "step": 105540
    },
    {
      "epoch": 32.56710891700092,
      "grad_norm": 2.289527416229248,
      "learning_rate": 1.7432891082999077e-05,
      "loss": 0.0017,
      "step": 105550
    },
    {
      "epoch": 32.570194384449245,
      "grad_norm": 2.074965050269384e-05,
      "learning_rate": 1.7429805615550756e-05,
      "loss": 0.0001,
      "step": 105560
    },
    {
      "epoch": 32.57327985189756,
      "grad_norm": 0.0005226471112109721,
      "learning_rate": 1.742672014810244e-05,
      "loss": 0.0,
      "step": 105570
    },
    {
      "epoch": 32.57636531934588,
      "grad_norm": 1.0333747013646644e-06,
      "learning_rate": 1.7423634680654118e-05,
      "loss": 0.0,
      "step": 105580
    },
    {
      "epoch": 32.5794507867942,
      "grad_norm": 4.93606821692083e-05,
      "learning_rate": 1.74205492132058e-05,
      "loss": 0.0,
      "step": 105590
    },
    {
      "epoch": 32.58253625424252,
      "grad_norm": 1.7833859601523727e-05,
      "learning_rate": 1.7417463745757483e-05,
      "loss": 0.0006,
      "step": 105600
    },
    {
      "epoch": 32.585621721690835,
      "grad_norm": 6.309372838586569e-05,
      "learning_rate": 1.7414378278309165e-05,
      "loss": 0.0001,
      "step": 105610
    },
    {
      "epoch": 32.58870718913916,
      "grad_norm": 6.0300644690869376e-05,
      "learning_rate": 1.7411292810860848e-05,
      "loss": 0.0002,
      "step": 105620
    },
    {
      "epoch": 32.59179265658747,
      "grad_norm": 2.8096230835217284e-06,
      "learning_rate": 1.7408207343412527e-05,
      "loss": 0.0001,
      "step": 105630
    },
    {
      "epoch": 32.594878124035795,
      "grad_norm": 2.7228010367252864e-05,
      "learning_rate": 1.740512187596421e-05,
      "loss": 0.0,
      "step": 105640
    },
    {
      "epoch": 32.59796359148411,
      "grad_norm": 2.316346399311442e-05,
      "learning_rate": 1.740203640851589e-05,
      "loss": 0.0,
      "step": 105650
    },
    {
      "epoch": 32.601049058932425,
      "grad_norm": 0.00010996037599397823,
      "learning_rate": 1.7398950941067574e-05,
      "loss": 0.0,
      "step": 105660
    },
    {
      "epoch": 32.60413452638075,
      "grad_norm": 0.06448962539434433,
      "learning_rate": 1.7395865473619257e-05,
      "loss": 0.0036,
      "step": 105670
    },
    {
      "epoch": 32.60721999382906,
      "grad_norm": 4.812403631149209e-07,
      "learning_rate": 1.7392780006170936e-05,
      "loss": 0.0034,
      "step": 105680
    },
    {
      "epoch": 32.610305461277385,
      "grad_norm": 3.619306880864315e-05,
      "learning_rate": 1.7389694538722618e-05,
      "loss": 0.0001,
      "step": 105690
    },
    {
      "epoch": 32.6133909287257,
      "grad_norm": 0.00010789804946398363,
      "learning_rate": 1.7386609071274297e-05,
      "loss": 0.0001,
      "step": 105700
    },
    {
      "epoch": 32.61647639617402,
      "grad_norm": 0.1033322885632515,
      "learning_rate": 1.738352360382598e-05,
      "loss": 0.0001,
      "step": 105710
    },
    {
      "epoch": 32.61956186362234,
      "grad_norm": 3.571664137780317e-06,
      "learning_rate": 1.7380438136377662e-05,
      "loss": 0.0,
      "step": 105720
    },
    {
      "epoch": 32.62264733107066,
      "grad_norm": 2.536635111027863e-05,
      "learning_rate": 1.7377352668929345e-05,
      "loss": 0.0027,
      "step": 105730
    },
    {
      "epoch": 32.625732798518975,
      "grad_norm": 7.397370893613697e-08,
      "learning_rate": 1.7374267201481027e-05,
      "loss": 0.0,
      "step": 105740
    },
    {
      "epoch": 32.6288182659673,
      "grad_norm": 0.002500552451238036,
      "learning_rate": 1.7371181734032706e-05,
      "loss": 0.0004,
      "step": 105750
    },
    {
      "epoch": 32.63190373341561,
      "grad_norm": 6.219915667315945e-05,
      "learning_rate": 1.736809626658439e-05,
      "loss": 0.0,
      "step": 105760
    },
    {
      "epoch": 32.63498920086393,
      "grad_norm": 9.952858817996457e-06,
      "learning_rate": 1.7365010799136068e-05,
      "loss": 0.0,
      "step": 105770
    },
    {
      "epoch": 32.63807466831225,
      "grad_norm": 0.0023348561953753233,
      "learning_rate": 1.736192533168775e-05,
      "loss": 0.0001,
      "step": 105780
    },
    {
      "epoch": 32.641160135760565,
      "grad_norm": 2.6051159238704713e-06,
      "learning_rate": 1.7358839864239433e-05,
      "loss": 0.0002,
      "step": 105790
    },
    {
      "epoch": 32.64424560320889,
      "grad_norm": 2.3478551156586036e-05,
      "learning_rate": 1.7355754396791115e-05,
      "loss": 0.0,
      "step": 105800
    },
    {
      "epoch": 32.6473310706572,
      "grad_norm": 2.371512692889155e-07,
      "learning_rate": 1.7352668929342798e-05,
      "loss": 0.0,
      "step": 105810
    },
    {
      "epoch": 32.650416538105524,
      "grad_norm": 0.003975373692810535,
      "learning_rate": 1.7349583461894477e-05,
      "loss": 0.0,
      "step": 105820
    },
    {
      "epoch": 32.65350200555384,
      "grad_norm": 8.194789188564755e-06,
      "learning_rate": 1.734649799444616e-05,
      "loss": 0.0,
      "step": 105830
    },
    {
      "epoch": 32.65658747300216,
      "grad_norm": 1.673760561970994e-05,
      "learning_rate": 1.7343412526997842e-05,
      "loss": 0.0,
      "step": 105840
    },
    {
      "epoch": 32.65967294045048,
      "grad_norm": 6.337571903713979e-06,
      "learning_rate": 1.734032705954952e-05,
      "loss": 0.0,
      "step": 105850
    },
    {
      "epoch": 32.6627584078988,
      "grad_norm": 1.6109598846014705e-06,
      "learning_rate": 1.7337241592101207e-05,
      "loss": 0.0,
      "step": 105860
    },
    {
      "epoch": 32.665843875347115,
      "grad_norm": 0.031334418803453445,
      "learning_rate": 1.7334156124652886e-05,
      "loss": 0.0004,
      "step": 105870
    },
    {
      "epoch": 32.66892934279544,
      "grad_norm": 0.0005047430167905986,
      "learning_rate": 1.733107065720457e-05,
      "loss": 0.0,
      "step": 105880
    },
    {
      "epoch": 32.67201481024375,
      "grad_norm": 2.6970545150106773e-05,
      "learning_rate": 1.7327985189756247e-05,
      "loss": 0.0001,
      "step": 105890
    },
    {
      "epoch": 32.67510027769207,
      "grad_norm": 3.6143965189694427e-06,
      "learning_rate": 1.732489972230793e-05,
      "loss": 0.0002,
      "step": 105900
    },
    {
      "epoch": 32.67818574514039,
      "grad_norm": 1.3621867083202233e-06,
      "learning_rate": 1.7321814254859612e-05,
      "loss": 0.0,
      "step": 105910
    },
    {
      "epoch": 32.681271212588705,
      "grad_norm": 8.29083361963967e-08,
      "learning_rate": 1.731872878741129e-05,
      "loss": 0.0,
      "step": 105920
    },
    {
      "epoch": 32.68435668003703,
      "grad_norm": 3.1914526061882498e-06,
      "learning_rate": 1.7315643319962977e-05,
      "loss": 0.0,
      "step": 105930
    },
    {
      "epoch": 32.68744214748534,
      "grad_norm": 0.01832561381161213,
      "learning_rate": 1.7312557852514656e-05,
      "loss": 0.0,
      "step": 105940
    },
    {
      "epoch": 32.690527614933664,
      "grad_norm": 2.572577795945108e-05,
      "learning_rate": 1.730947238506634e-05,
      "loss": 0.003,
      "step": 105950
    },
    {
      "epoch": 32.69361308238198,
      "grad_norm": 6.200862844707444e-05,
      "learning_rate": 1.730638691761802e-05,
      "loss": 0.0,
      "step": 105960
    },
    {
      "epoch": 32.6966985498303,
      "grad_norm": 9.42250517255161e-06,
      "learning_rate": 1.73033014501697e-05,
      "loss": 0.0,
      "step": 105970
    },
    {
      "epoch": 32.69978401727862,
      "grad_norm": 3.014536196133122e-05,
      "learning_rate": 1.7300215982721383e-05,
      "loss": 0.0,
      "step": 105980
    },
    {
      "epoch": 32.70286948472694,
      "grad_norm": 1.7887676222017035e-05,
      "learning_rate": 1.7297130515273062e-05,
      "loss": 0.0011,
      "step": 105990
    },
    {
      "epoch": 32.705954952175254,
      "grad_norm": 0.0007035446469672024,
      "learning_rate": 1.7294045047824748e-05,
      "loss": 0.0,
      "step": 106000
    },
    {
      "epoch": 32.70904041962357,
      "grad_norm": 5.195175162953092e-06,
      "learning_rate": 1.7290959580376427e-05,
      "loss": 0.0,
      "step": 106010
    },
    {
      "epoch": 32.71212588707189,
      "grad_norm": 0.007243888918310404,
      "learning_rate": 1.728787411292811e-05,
      "loss": 0.0001,
      "step": 106020
    },
    {
      "epoch": 32.71521135452021,
      "grad_norm": 2.4373219275730662e-05,
      "learning_rate": 1.7284788645479792e-05,
      "loss": 0.0001,
      "step": 106030
    },
    {
      "epoch": 32.71829682196853,
      "grad_norm": 0.0002264480572193861,
      "learning_rate": 1.728170317803147e-05,
      "loss": 0.0002,
      "step": 106040
    },
    {
      "epoch": 32.721382289416844,
      "grad_norm": 4.785983946931083e-06,
      "learning_rate": 1.7278617710583154e-05,
      "loss": 0.0,
      "step": 106050
    },
    {
      "epoch": 32.72446775686517,
      "grad_norm": 2.0513837739599694e-07,
      "learning_rate": 1.7275532243134836e-05,
      "loss": 0.0,
      "step": 106060
    },
    {
      "epoch": 32.72755322431348,
      "grad_norm": 0.0077202352695167065,
      "learning_rate": 1.727244677568652e-05,
      "loss": 0.0,
      "step": 106070
    },
    {
      "epoch": 32.730638691761804,
      "grad_norm": 1.6283403283523512e-06,
      "learning_rate": 1.72693613082382e-05,
      "loss": 0.0,
      "step": 106080
    },
    {
      "epoch": 32.73372415921012,
      "grad_norm": 1.565404272696469e-05,
      "learning_rate": 1.726627584078988e-05,
      "loss": 0.0,
      "step": 106090
    },
    {
      "epoch": 32.73680962665844,
      "grad_norm": 9.504472586741031e-07,
      "learning_rate": 1.7263190373341563e-05,
      "loss": 0.0,
      "step": 106100
    },
    {
      "epoch": 32.73989509410676,
      "grad_norm": 0.00031927810050547123,
      "learning_rate": 1.726010490589324e-05,
      "loss": 0.0,
      "step": 106110
    },
    {
      "epoch": 32.74298056155508,
      "grad_norm": 1.448887787525166e-09,
      "learning_rate": 1.7257019438444924e-05,
      "loss": 0.0,
      "step": 106120
    },
    {
      "epoch": 32.746066029003394,
      "grad_norm": 8.749289918341674e-06,
      "learning_rate": 1.7253933970996607e-05,
      "loss": 0.0001,
      "step": 106130
    },
    {
      "epoch": 32.74915149645171,
      "grad_norm": 1.1762783287849743e-05,
      "learning_rate": 1.725084850354829e-05,
      "loss": 0.0,
      "step": 106140
    },
    {
      "epoch": 32.75223696390003,
      "grad_norm": 1.1829321010736749e-05,
      "learning_rate": 1.724776303609997e-05,
      "loss": 0.0001,
      "step": 106150
    },
    {
      "epoch": 32.75532243134835,
      "grad_norm": 2.538755779823987e-06,
      "learning_rate": 1.724467756865165e-05,
      "loss": 0.0003,
      "step": 106160
    },
    {
      "epoch": 32.75840789879667,
      "grad_norm": 1.187195630336646e-05,
      "learning_rate": 1.7241592101203333e-05,
      "loss": 0.0001,
      "step": 106170
    },
    {
      "epoch": 32.761493366244984,
      "grad_norm": 0.01665056310594082,
      "learning_rate": 1.7238506633755012e-05,
      "loss": 0.0,
      "step": 106180
    },
    {
      "epoch": 32.76457883369331,
      "grad_norm": 2.72527540801093e-06,
      "learning_rate": 1.7235421166306695e-05,
      "loss": 0.0007,
      "step": 106190
    },
    {
      "epoch": 32.76766430114162,
      "grad_norm": 1.1528497267931925e-08,
      "learning_rate": 1.723233569885838e-05,
      "loss": 0.0,
      "step": 106200
    },
    {
      "epoch": 32.770749768589944,
      "grad_norm": 5.731577630285756e-07,
      "learning_rate": 1.722925023141006e-05,
      "loss": 0.0,
      "step": 106210
    },
    {
      "epoch": 32.77383523603826,
      "grad_norm": 0.000517091597430408,
      "learning_rate": 1.7226164763961742e-05,
      "loss": 0.0,
      "step": 106220
    },
    {
      "epoch": 32.77692070348658,
      "grad_norm": 0.0014675435377284884,
      "learning_rate": 1.722307929651342e-05,
      "loss": 0.0,
      "step": 106230
    },
    {
      "epoch": 32.7800061709349,
      "grad_norm": 0.0014147524489089847,
      "learning_rate": 1.7219993829065104e-05,
      "loss": 0.0,
      "step": 106240
    },
    {
      "epoch": 32.78309163838321,
      "grad_norm": 9.728677832754329e-05,
      "learning_rate": 1.7216908361616786e-05,
      "loss": 0.0,
      "step": 106250
    },
    {
      "epoch": 32.786177105831534,
      "grad_norm": 9.173969374387525e-06,
      "learning_rate": 1.721382289416847e-05,
      "loss": 0.0,
      "step": 106260
    },
    {
      "epoch": 32.78926257327985,
      "grad_norm": 5.4277094022836536e-05,
      "learning_rate": 1.721073742672015e-05,
      "loss": 0.0,
      "step": 106270
    },
    {
      "epoch": 32.79234804072817,
      "grad_norm": 2.0152510842308402e-05,
      "learning_rate": 1.720765195927183e-05,
      "loss": 0.0,
      "step": 106280
    },
    {
      "epoch": 32.79543350817649,
      "grad_norm": 3.620212009991519e-05,
      "learning_rate": 1.7204566491823513e-05,
      "loss": 0.0008,
      "step": 106290
    },
    {
      "epoch": 32.79851897562481,
      "grad_norm": 0.00020323731587268412,
      "learning_rate": 1.7201481024375192e-05,
      "loss": 0.0,
      "step": 106300
    },
    {
      "epoch": 32.801604443073124,
      "grad_norm": 2.4543194740545005e-05,
      "learning_rate": 1.7198395556926874e-05,
      "loss": 0.0,
      "step": 106310
    },
    {
      "epoch": 32.80468991052145,
      "grad_norm": 0.00012444867752492428,
      "learning_rate": 1.7195310089478557e-05,
      "loss": 0.0,
      "step": 106320
    },
    {
      "epoch": 32.80777537796976,
      "grad_norm": 4.688178523792885e-05,
      "learning_rate": 1.719222462203024e-05,
      "loss": 0.0,
      "step": 106330
    },
    {
      "epoch": 32.810860845418084,
      "grad_norm": 9.432722436031327e-05,
      "learning_rate": 1.718913915458192e-05,
      "loss": 0.0026,
      "step": 106340
    },
    {
      "epoch": 32.8139463128664,
      "grad_norm": 1.1844571190522402e-07,
      "learning_rate": 1.71860536871336e-05,
      "loss": 0.0,
      "step": 106350
    },
    {
      "epoch": 32.817031780314714,
      "grad_norm": 1.4634733247476106e-07,
      "learning_rate": 1.7182968219685283e-05,
      "loss": 0.0001,
      "step": 106360
    },
    {
      "epoch": 32.82011724776304,
      "grad_norm": 1.181167704089603e-06,
      "learning_rate": 1.7179882752236966e-05,
      "loss": 0.0,
      "step": 106370
    },
    {
      "epoch": 32.82320271521135,
      "grad_norm": 1.3106661072015413e-06,
      "learning_rate": 1.7176797284788645e-05,
      "loss": 0.0002,
      "step": 106380
    },
    {
      "epoch": 32.826288182659674,
      "grad_norm": 0.00014612605446018279,
      "learning_rate": 1.7173711817340327e-05,
      "loss": 0.0,
      "step": 106390
    },
    {
      "epoch": 32.82937365010799,
      "grad_norm": 1.1726324373739772e-06,
      "learning_rate": 1.717062634989201e-05,
      "loss": 0.0,
      "step": 106400
    },
    {
      "epoch": 32.83245911755631,
      "grad_norm": 7.598850515933009e-06,
      "learning_rate": 1.7167540882443692e-05,
      "loss": 0.0,
      "step": 106410
    },
    {
      "epoch": 32.83554458500463,
      "grad_norm": 6.572633992618648e-06,
      "learning_rate": 1.716445541499537e-05,
      "loss": 0.0,
      "step": 106420
    },
    {
      "epoch": 32.83863005245295,
      "grad_norm": 0.13902081549167633,
      "learning_rate": 1.7161369947547054e-05,
      "loss": 0.0001,
      "step": 106430
    },
    {
      "epoch": 32.841715519901264,
      "grad_norm": 2.198910124207032e-06,
      "learning_rate": 1.7158284480098736e-05,
      "loss": 0.0,
      "step": 106440
    },
    {
      "epoch": 32.844800987349586,
      "grad_norm": 5.7989147705939104e-08,
      "learning_rate": 1.7155199012650415e-05,
      "loss": 0.0,
      "step": 106450
    },
    {
      "epoch": 32.8478864547979,
      "grad_norm": 2.6960608010995202e-05,
      "learning_rate": 1.7152113545202098e-05,
      "loss": 0.0,
      "step": 106460
    },
    {
      "epoch": 32.850971922246224,
      "grad_norm": 7.223665647870803e-07,
      "learning_rate": 1.714902807775378e-05,
      "loss": 0.0,
      "step": 106470
    },
    {
      "epoch": 32.85405738969454,
      "grad_norm": 1.615982000657823e-05,
      "learning_rate": 1.7145942610305463e-05,
      "loss": 0.0,
      "step": 106480
    },
    {
      "epoch": 32.857142857142854,
      "grad_norm": 1.431252258043969e-06,
      "learning_rate": 1.7142857142857145e-05,
      "loss": 0.0,
      "step": 106490
    },
    {
      "epoch": 32.860228324591176,
      "grad_norm": 0.00045106877223588526,
      "learning_rate": 1.7139771675408824e-05,
      "loss": 0.0003,
      "step": 106500
    },
    {
      "epoch": 32.86331379203949,
      "grad_norm": 2.498799585737288e-05,
      "learning_rate": 1.7136686207960507e-05,
      "loss": 0.0,
      "step": 106510
    },
    {
      "epoch": 32.866399259487814,
      "grad_norm": 0.00010894974548136815,
      "learning_rate": 1.7133600740512186e-05,
      "loss": 0.0,
      "step": 106520
    },
    {
      "epoch": 32.86948472693613,
      "grad_norm": 1.1636931276370888e-06,
      "learning_rate": 1.7130515273063872e-05,
      "loss": 0.0,
      "step": 106530
    },
    {
      "epoch": 32.87257019438445,
      "grad_norm": 2.1011562978401344e-07,
      "learning_rate": 1.712742980561555e-05,
      "loss": 0.0002,
      "step": 106540
    },
    {
      "epoch": 32.875655661832766,
      "grad_norm": 1.5205206409518723e-06,
      "learning_rate": 1.7124344338167233e-05,
      "loss": 0.0,
      "step": 106550
    },
    {
      "epoch": 32.87874112928109,
      "grad_norm": 2.0199240680085495e-05,
      "learning_rate": 1.7121258870718916e-05,
      "loss": 0.0,
      "step": 106560
    },
    {
      "epoch": 32.881826596729404,
      "grad_norm": 1.0061923603643663e-05,
      "learning_rate": 1.7118173403270595e-05,
      "loss": 0.0001,
      "step": 106570
    },
    {
      "epoch": 32.884912064177726,
      "grad_norm": 2.7944677185587352e-06,
      "learning_rate": 1.7115087935822277e-05,
      "loss": 0.0,
      "step": 106580
    },
    {
      "epoch": 32.88799753162604,
      "grad_norm": 0.025554032996296883,
      "learning_rate": 1.711200246837396e-05,
      "loss": 0.0004,
      "step": 106590
    },
    {
      "epoch": 32.89108299907436,
      "grad_norm": 3.8366124499589205e-05,
      "learning_rate": 1.7108917000925642e-05,
      "loss": 0.0,
      "step": 106600
    },
    {
      "epoch": 32.89416846652268,
      "grad_norm": 6.203438260854455e-06,
      "learning_rate": 1.7105831533477325e-05,
      "loss": 0.0002,
      "step": 106610
    },
    {
      "epoch": 32.897253933970994,
      "grad_norm": 0.0008309865952469409,
      "learning_rate": 1.7102746066029004e-05,
      "loss": 0.0,
      "step": 106620
    },
    {
      "epoch": 32.900339401419316,
      "grad_norm": 2.6494988105696393e-06,
      "learning_rate": 1.7099660598580686e-05,
      "loss": 0.0,
      "step": 106630
    },
    {
      "epoch": 32.90342486886763,
      "grad_norm": 3.0804819743934786e-06,
      "learning_rate": 1.7096575131132365e-05,
      "loss": 0.0001,
      "step": 106640
    },
    {
      "epoch": 32.906510336315954,
      "grad_norm": 2.1722709789173678e-05,
      "learning_rate": 1.7093489663684048e-05,
      "loss": 0.0,
      "step": 106650
    },
    {
      "epoch": 32.90959580376427,
      "grad_norm": 0.00409195339307189,
      "learning_rate": 1.709040419623573e-05,
      "loss": 0.0,
      "step": 106660
    },
    {
      "epoch": 32.91268127121259,
      "grad_norm": 2.205764758400619e-06,
      "learning_rate": 1.7087318728787413e-05,
      "loss": 0.0,
      "step": 106670
    },
    {
      "epoch": 32.915766738660906,
      "grad_norm": 0.0001714178069960326,
      "learning_rate": 1.7084233261339095e-05,
      "loss": 0.0,
      "step": 106680
    },
    {
      "epoch": 32.91885220610923,
      "grad_norm": 1.8099517546943389e-06,
      "learning_rate": 1.7081147793890774e-05,
      "loss": 0.0017,
      "step": 106690
    },
    {
      "epoch": 32.921937673557544,
      "grad_norm": 0.00028655174537561834,
      "learning_rate": 1.7078062326442457e-05,
      "loss": 0.0,
      "step": 106700
    },
    {
      "epoch": 32.92502314100586,
      "grad_norm": 2.4122624381561764e-05,
      "learning_rate": 1.707497685899414e-05,
      "loss": 0.0002,
      "step": 106710
    },
    {
      "epoch": 32.92810860845418,
      "grad_norm": 0.0077948300167918205,
      "learning_rate": 1.707189139154582e-05,
      "loss": 0.0,
      "step": 106720
    },
    {
      "epoch": 32.931194075902496,
      "grad_norm": 0.0002631116658449173,
      "learning_rate": 1.7068805924097504e-05,
      "loss": 0.0,
      "step": 106730
    },
    {
      "epoch": 32.93427954335082,
      "grad_norm": 7.256071967276512e-06,
      "learning_rate": 1.7065720456649183e-05,
      "loss": 0.0,
      "step": 106740
    },
    {
      "epoch": 32.937365010799134,
      "grad_norm": 0.00010230542829958722,
      "learning_rate": 1.7062634989200866e-05,
      "loss": 0.0,
      "step": 106750
    },
    {
      "epoch": 32.940450478247456,
      "grad_norm": 1.3441612054521102e-06,
      "learning_rate": 1.7059549521752545e-05,
      "loss": 0.001,
      "step": 106760
    },
    {
      "epoch": 32.94353594569577,
      "grad_norm": 7.852080307202414e-05,
      "learning_rate": 1.7056464054304227e-05,
      "loss": 0.0,
      "step": 106770
    },
    {
      "epoch": 32.94662141314409,
      "grad_norm": 0.6518113017082214,
      "learning_rate": 1.705337858685591e-05,
      "loss": 0.0002,
      "step": 106780
    },
    {
      "epoch": 32.94970688059241,
      "grad_norm": 1.4619583453168161e-05,
      "learning_rate": 1.705029311940759e-05,
      "loss": 0.0,
      "step": 106790
    },
    {
      "epoch": 32.95279234804073,
      "grad_norm": 1.919014539453201e-05,
      "learning_rate": 1.7047207651959275e-05,
      "loss": 0.0007,
      "step": 106800
    },
    {
      "epoch": 32.955877815489046,
      "grad_norm": 7.414183346554637e-05,
      "learning_rate": 1.7044122184510954e-05,
      "loss": 0.0,
      "step": 106810
    },
    {
      "epoch": 32.95896328293737,
      "grad_norm": 1.1672491382341832e-05,
      "learning_rate": 1.7041036717062636e-05,
      "loss": 0.0,
      "step": 106820
    },
    {
      "epoch": 32.962048750385684,
      "grad_norm": 0.0007870100089348853,
      "learning_rate": 1.703795124961432e-05,
      "loss": 0.0004,
      "step": 106830
    },
    {
      "epoch": 32.965134217834,
      "grad_norm": 6.02881891609286e-06,
      "learning_rate": 1.7034865782165998e-05,
      "loss": 0.0,
      "step": 106840
    },
    {
      "epoch": 32.96821968528232,
      "grad_norm": 0.00036899434053339064,
      "learning_rate": 1.703178031471768e-05,
      "loss": 0.0,
      "step": 106850
    },
    {
      "epoch": 32.971305152730636,
      "grad_norm": 0.0011302699567750096,
      "learning_rate": 1.702869484726936e-05,
      "loss": 0.0,
      "step": 106860
    },
    {
      "epoch": 32.97439062017896,
      "grad_norm": 6.038901119609363e-06,
      "learning_rate": 1.7025609379821045e-05,
      "loss": 0.0,
      "step": 106870
    },
    {
      "epoch": 32.977476087627274,
      "grad_norm": 0.001803725608624518,
      "learning_rate": 1.7022523912372725e-05,
      "loss": 0.0,
      "step": 106880
    },
    {
      "epoch": 32.980561555075596,
      "grad_norm": 3.5171698982594535e-05,
      "learning_rate": 1.7019438444924407e-05,
      "loss": 0.0,
      "step": 106890
    },
    {
      "epoch": 32.98364702252391,
      "grad_norm": 6.67711574351415e-05,
      "learning_rate": 1.701635297747609e-05,
      "loss": 0.0,
      "step": 106900
    },
    {
      "epoch": 32.98673248997223,
      "grad_norm": 2.7184742634744907e-07,
      "learning_rate": 1.701326751002777e-05,
      "loss": 0.0,
      "step": 106910
    },
    {
      "epoch": 32.98981795742055,
      "grad_norm": 0.00041070824954658747,
      "learning_rate": 1.701018204257945e-05,
      "loss": 0.0,
      "step": 106920
    },
    {
      "epoch": 32.99290342486887,
      "grad_norm": 6.250583737710258e-06,
      "learning_rate": 1.7007096575131134e-05,
      "loss": 0.0,
      "step": 106930
    },
    {
      "epoch": 32.995988892317186,
      "grad_norm": 2.73127312766519e-07,
      "learning_rate": 1.7004011107682816e-05,
      "loss": 0.0001,
      "step": 106940
    },
    {
      "epoch": 32.9990743597655,
      "grad_norm": 3.0662624794786097e-06,
      "learning_rate": 1.70009256402345e-05,
      "loss": 0.0001,
      "step": 106950
    },
    {
      "epoch": 33.0,
      "eval_accuracy_branch1": 0.9999807104346904,
      "eval_accuracy_branch2": 0.3993615153882507,
      "eval_f1_branch1": 0.9999841289106349,
      "eval_f1_branch2": 0.3830140407517875,
      "eval_loss": 4.742165856441716e-06,
      "eval_precision_branch1": 0.9999835528276934,
      "eval_precision_branch2": 0.5162146048714857,
      "eval_recall_branch1": 0.999984707024828,
      "eval_recall_branch2": 0.5103223286363242,
      "eval_runtime": 239.201,
      "eval_samples_per_second": 433.455,
      "eval_steps_per_second": 54.185,
      "step": 106953
    },
    {
      "epoch": 33.00215982721382,
      "grad_norm": 1.2297638932068367e-05,
      "learning_rate": 1.6997840172786178e-05,
      "loss": 0.7339,
      "step": 106960
    },
    {
      "epoch": 33.00524529466214,
      "grad_norm": 1.325691209785873e-05,
      "learning_rate": 1.699475470533786e-05,
      "loss": 0.0,
      "step": 106970
    },
    {
      "epoch": 33.00833076211046,
      "grad_norm": 2.110344439643086e-06,
      "learning_rate": 1.699166923788954e-05,
      "loss": 0.0,
      "step": 106980
    },
    {
      "epoch": 33.011416229558776,
      "grad_norm": 2.5081315470742993e-05,
      "learning_rate": 1.698858377044122e-05,
      "loss": 0.0001,
      "step": 106990
    },
    {
      "epoch": 33.0145016970071,
      "grad_norm": 0.0002340567298233509,
      "learning_rate": 1.6985498302992904e-05,
      "loss": 0.0,
      "step": 107000
    },
    {
      "epoch": 33.01758716445541,
      "grad_norm": 0.0001555542112328112,
      "learning_rate": 1.6982412835544587e-05,
      "loss": 0.0,
      "step": 107010
    },
    {
      "epoch": 33.020672631903736,
      "grad_norm": 1.1751756574085448e-05,
      "learning_rate": 1.697932736809627e-05,
      "loss": 0.0,
      "step": 107020
    },
    {
      "epoch": 33.02375809935205,
      "grad_norm": 1.2735004929709248e-05,
      "learning_rate": 1.6976241900647948e-05,
      "loss": 0.0,
      "step": 107030
    },
    {
      "epoch": 33.02684356680037,
      "grad_norm": 6.219624992809258e-06,
      "learning_rate": 1.697315643319963e-05,
      "loss": 0.0,
      "step": 107040
    },
    {
      "epoch": 33.02992903424869,
      "grad_norm": 3.7545828490692656e-06,
      "learning_rate": 1.697007096575131e-05,
      "loss": 0.0,
      "step": 107050
    },
    {
      "epoch": 33.033014501697004,
      "grad_norm": 1.3685083786185714e-06,
      "learning_rate": 1.6966985498302992e-05,
      "loss": 0.0005,
      "step": 107060
    },
    {
      "epoch": 33.036099969145326,
      "grad_norm": 1.8387765521765687e-05,
      "learning_rate": 1.6963900030854678e-05,
      "loss": 0.0,
      "step": 107070
    },
    {
      "epoch": 33.03918543659364,
      "grad_norm": 0.0004043065709993243,
      "learning_rate": 1.6960814563406357e-05,
      "loss": 0.0,
      "step": 107080
    },
    {
      "epoch": 33.04227090404196,
      "grad_norm": 2.700956247281283e-05,
      "learning_rate": 1.695772909595804e-05,
      "loss": 0.0006,
      "step": 107090
    },
    {
      "epoch": 33.04535637149028,
      "grad_norm": 6.383581876434619e-06,
      "learning_rate": 1.695464362850972e-05,
      "loss": 0.0,
      "step": 107100
    },
    {
      "epoch": 33.0484418389386,
      "grad_norm": 0.03831551969051361,
      "learning_rate": 1.69515581610614e-05,
      "loss": 0.0001,
      "step": 107110
    },
    {
      "epoch": 33.051527306386916,
      "grad_norm": 9.853152732830495e-05,
      "learning_rate": 1.6948472693613084e-05,
      "loss": 0.0,
      "step": 107120
    },
    {
      "epoch": 33.05461277383524,
      "grad_norm": 0.0003152206481900066,
      "learning_rate": 1.6945387226164766e-05,
      "loss": 0.0002,
      "step": 107130
    },
    {
      "epoch": 33.05769824128355,
      "grad_norm": 0.0003578325267881155,
      "learning_rate": 1.694230175871645e-05,
      "loss": 0.0001,
      "step": 107140
    },
    {
      "epoch": 33.060783708731876,
      "grad_norm": 4.959023272022023e-07,
      "learning_rate": 1.6939216291268128e-05,
      "loss": 0.0008,
      "step": 107150
    },
    {
      "epoch": 33.06386917618019,
      "grad_norm": 0.009941591881215572,
      "learning_rate": 1.693613082381981e-05,
      "loss": 0.0019,
      "step": 107160
    },
    {
      "epoch": 33.06695464362851,
      "grad_norm": 7.476264727301896e-06,
      "learning_rate": 1.693304535637149e-05,
      "loss": 0.001,
      "step": 107170
    },
    {
      "epoch": 33.07004011107683,
      "grad_norm": 0.0017133394721895456,
      "learning_rate": 1.6929959888923172e-05,
      "loss": 0.0007,
      "step": 107180
    },
    {
      "epoch": 33.07312557852514,
      "grad_norm": 0.00015287360292859375,
      "learning_rate": 1.6926874421474854e-05,
      "loss": 0.0004,
      "step": 107190
    },
    {
      "epoch": 33.076211045973466,
      "grad_norm": 0.002924824133515358,
      "learning_rate": 1.6923788954026537e-05,
      "loss": 0.0,
      "step": 107200
    },
    {
      "epoch": 33.07929651342178,
      "grad_norm": 0.00012342627451289445,
      "learning_rate": 1.692070348657822e-05,
      "loss": 0.0001,
      "step": 107210
    },
    {
      "epoch": 33.0823819808701,
      "grad_norm": 2.2093355655670166,
      "learning_rate": 1.6917618019129898e-05,
      "loss": 0.0041,
      "step": 107220
    },
    {
      "epoch": 33.08546744831842,
      "grad_norm": 0.000915138574782759,
      "learning_rate": 1.691453255168158e-05,
      "loss": 0.0,
      "step": 107230
    },
    {
      "epoch": 33.08855291576674,
      "grad_norm": 6.837319688202115e-06,
      "learning_rate": 1.6911447084233263e-05,
      "loss": 0.0221,
      "step": 107240
    },
    {
      "epoch": 33.091638383215056,
      "grad_norm": 5.5515261919936165e-05,
      "learning_rate": 1.6908361616784942e-05,
      "loss": 0.0004,
      "step": 107250
    },
    {
      "epoch": 33.09472385066338,
      "grad_norm": 8.531846162895818e-08,
      "learning_rate": 1.6905276149336625e-05,
      "loss": 0.0001,
      "step": 107260
    },
    {
      "epoch": 33.09780931811169,
      "grad_norm": 0.00010969671711791307,
      "learning_rate": 1.6902190681888307e-05,
      "loss": 0.0001,
      "step": 107270
    },
    {
      "epoch": 33.100894785560016,
      "grad_norm": 3.813271121089201e-07,
      "learning_rate": 1.689910521443999e-05,
      "loss": 0.0,
      "step": 107280
    },
    {
      "epoch": 33.10398025300833,
      "grad_norm": 0.23932801187038422,
      "learning_rate": 1.689601974699167e-05,
      "loss": 0.0003,
      "step": 107290
    },
    {
      "epoch": 33.107065720456646,
      "grad_norm": 0.00016002351185306907,
      "learning_rate": 1.689293427954335e-05,
      "loss": 0.0001,
      "step": 107300
    },
    {
      "epoch": 33.11015118790497,
      "grad_norm": 5.4504122090293095e-05,
      "learning_rate": 1.6889848812095034e-05,
      "loss": 0.0,
      "step": 107310
    },
    {
      "epoch": 33.11323665535328,
      "grad_norm": 0.0006245311233215034,
      "learning_rate": 1.6886763344646713e-05,
      "loss": 0.0002,
      "step": 107320
    },
    {
      "epoch": 33.116322122801606,
      "grad_norm": 0.0001078377608791925,
      "learning_rate": 1.6883677877198395e-05,
      "loss": 0.0,
      "step": 107330
    },
    {
      "epoch": 33.11940759024992,
      "grad_norm": 0.00031753035727888346,
      "learning_rate": 1.6880592409750078e-05,
      "loss": 0.0005,
      "step": 107340
    },
    {
      "epoch": 33.12249305769824,
      "grad_norm": 4.418594016897259e-06,
      "learning_rate": 1.687750694230176e-05,
      "loss": 0.0,
      "step": 107350
    },
    {
      "epoch": 33.12557852514656,
      "grad_norm": 0.007261132355779409,
      "learning_rate": 1.6874421474853443e-05,
      "loss": 0.0008,
      "step": 107360
    },
    {
      "epoch": 33.12866399259488,
      "grad_norm": 0.0012514571426436305,
      "learning_rate": 1.6871336007405122e-05,
      "loss": 0.0096,
      "step": 107370
    },
    {
      "epoch": 33.131749460043196,
      "grad_norm": 2.304586587342783e-06,
      "learning_rate": 1.6868250539956804e-05,
      "loss": 0.0,
      "step": 107380
    },
    {
      "epoch": 33.13483492749152,
      "grad_norm": 0.0013049382250756025,
      "learning_rate": 1.6865165072508483e-05,
      "loss": 0.0,
      "step": 107390
    },
    {
      "epoch": 33.13792039493983,
      "grad_norm": 4.987330157746328e-06,
      "learning_rate": 1.686207960506017e-05,
      "loss": 0.003,
      "step": 107400
    },
    {
      "epoch": 33.14100586238815,
      "grad_norm": 7.129661389626563e-05,
      "learning_rate": 1.685899413761185e-05,
      "loss": 0.0,
      "step": 107410
    },
    {
      "epoch": 33.14409132983647,
      "grad_norm": 0.0008029666496440768,
      "learning_rate": 1.685590867016353e-05,
      "loss": 0.0008,
      "step": 107420
    },
    {
      "epoch": 33.147176797284786,
      "grad_norm": 0.0016499774064868689,
      "learning_rate": 1.6852823202715213e-05,
      "loss": 0.0,
      "step": 107430
    },
    {
      "epoch": 33.15026226473311,
      "grad_norm": 1.9002609406015836e-05,
      "learning_rate": 1.6849737735266892e-05,
      "loss": 0.0014,
      "step": 107440
    },
    {
      "epoch": 33.15334773218142,
      "grad_norm": 0.17561639845371246,
      "learning_rate": 1.6846652267818575e-05,
      "loss": 0.0001,
      "step": 107450
    },
    {
      "epoch": 33.156433199629745,
      "grad_norm": 1.9984385289717466e-05,
      "learning_rate": 1.6843566800370254e-05,
      "loss": 0.0003,
      "step": 107460
    },
    {
      "epoch": 33.15951866707806,
      "grad_norm": 0.001638642861507833,
      "learning_rate": 1.684048133292194e-05,
      "loss": 0.0002,
      "step": 107470
    },
    {
      "epoch": 33.16260413452638,
      "grad_norm": 1.1518058045112411e-06,
      "learning_rate": 1.6837395865473622e-05,
      "loss": 0.0,
      "step": 107480
    },
    {
      "epoch": 33.1656896019747,
      "grad_norm": 0.00034531077835708857,
      "learning_rate": 1.68343103980253e-05,
      "loss": 0.0,
      "step": 107490
    },
    {
      "epoch": 33.16877506942302,
      "grad_norm": 0.0013743123272433877,
      "learning_rate": 1.6831224930576984e-05,
      "loss": 0.001,
      "step": 107500
    },
    {
      "epoch": 33.171860536871336,
      "grad_norm": 0.0014912319602444768,
      "learning_rate": 1.6828139463128663e-05,
      "loss": 0.0,
      "step": 107510
    },
    {
      "epoch": 33.17494600431966,
      "grad_norm": 0.009287877008318901,
      "learning_rate": 1.6825053995680345e-05,
      "loss": 0.0,
      "step": 107520
    },
    {
      "epoch": 33.17803147176797,
      "grad_norm": 0.01037439052015543,
      "learning_rate": 1.6821968528232028e-05,
      "loss": 0.0003,
      "step": 107530
    },
    {
      "epoch": 33.18111693921629,
      "grad_norm": 0.00015244251699186862,
      "learning_rate": 1.681888306078371e-05,
      "loss": 0.0001,
      "step": 107540
    },
    {
      "epoch": 33.18420240666461,
      "grad_norm": 3.617810580180958e-05,
      "learning_rate": 1.6815797593335393e-05,
      "loss": 0.0012,
      "step": 107550
    },
    {
      "epoch": 33.187287874112926,
      "grad_norm": 0.0002653670671861619,
      "learning_rate": 1.6812712125887072e-05,
      "loss": 0.0,
      "step": 107560
    },
    {
      "epoch": 33.19037334156125,
      "grad_norm": 0.0006384516600519419,
      "learning_rate": 1.6809626658438754e-05,
      "loss": 0.001,
      "step": 107570
    },
    {
      "epoch": 33.19345880900956,
      "grad_norm": 8.8271754066227e-06,
      "learning_rate": 1.6806541190990434e-05,
      "loss": 0.0,
      "step": 107580
    },
    {
      "epoch": 33.196544276457885,
      "grad_norm": 7.174290658440441e-05,
      "learning_rate": 1.6803455723542116e-05,
      "loss": 0.0,
      "step": 107590
    },
    {
      "epoch": 33.1996297439062,
      "grad_norm": 0.0002991001238115132,
      "learning_rate": 1.6800370256093802e-05,
      "loss": 0.0006,
      "step": 107600
    },
    {
      "epoch": 33.20271521135452,
      "grad_norm": 8.344072557520121e-05,
      "learning_rate": 1.679728478864548e-05,
      "loss": 0.0,
      "step": 107610
    },
    {
      "epoch": 33.20580067880284,
      "grad_norm": 5.087975978312897e-07,
      "learning_rate": 1.6794199321197163e-05,
      "loss": 0.001,
      "step": 107620
    },
    {
      "epoch": 33.20888614625116,
      "grad_norm": 4.075970991834765e-06,
      "learning_rate": 1.6791113853748843e-05,
      "loss": 0.0,
      "step": 107630
    },
    {
      "epoch": 33.211971613699475,
      "grad_norm": 2.3682228800225857e-07,
      "learning_rate": 1.6788028386300525e-05,
      "loss": 0.0,
      "step": 107640
    },
    {
      "epoch": 33.21505708114779,
      "grad_norm": 0.0011799142230302095,
      "learning_rate": 1.6784942918852208e-05,
      "loss": 0.0,
      "step": 107650
    },
    {
      "epoch": 33.21814254859611,
      "grad_norm": 2.2221044559955772e-07,
      "learning_rate": 1.6781857451403887e-05,
      "loss": 0.0,
      "step": 107660
    },
    {
      "epoch": 33.22122801604443,
      "grad_norm": 0.0009486210183240473,
      "learning_rate": 1.6778771983955572e-05,
      "loss": 0.0,
      "step": 107670
    },
    {
      "epoch": 33.22431348349275,
      "grad_norm": 7.002308848313987e-06,
      "learning_rate": 1.677568651650725e-05,
      "loss": 0.0013,
      "step": 107680
    },
    {
      "epoch": 33.227398950941065,
      "grad_norm": 0.004689479246735573,
      "learning_rate": 1.6772601049058934e-05,
      "loss": 0.0,
      "step": 107690
    },
    {
      "epoch": 33.23048441838939,
      "grad_norm": 0.1354554295539856,
      "learning_rate": 1.6769515581610613e-05,
      "loss": 0.0001,
      "step": 107700
    },
    {
      "epoch": 33.2335698858377,
      "grad_norm": 0.00031969661358743906,
      "learning_rate": 1.6766430114162296e-05,
      "loss": 0.0,
      "step": 107710
    },
    {
      "epoch": 33.236655353286025,
      "grad_norm": 2.5917393031704705e-06,
      "learning_rate": 1.6763344646713978e-05,
      "loss": 0.0001,
      "step": 107720
    },
    {
      "epoch": 33.23974082073434,
      "grad_norm": 2.7441186034593557e-07,
      "learning_rate": 1.6760259179265657e-05,
      "loss": 0.0,
      "step": 107730
    },
    {
      "epoch": 33.24282628818266,
      "grad_norm": 0.0007980639929883182,
      "learning_rate": 1.6757173711817343e-05,
      "loss": 0.003,
      "step": 107740
    },
    {
      "epoch": 33.24591175563098,
      "grad_norm": 1.2728406773021561e-06,
      "learning_rate": 1.6754088244369022e-05,
      "loss": 0.0039,
      "step": 107750
    },
    {
      "epoch": 33.2489972230793,
      "grad_norm": 2.5764090878510615e-06,
      "learning_rate": 1.6751002776920705e-05,
      "loss": 0.0,
      "step": 107760
    },
    {
      "epoch": 33.252082690527615,
      "grad_norm": 0.05397779121994972,
      "learning_rate": 1.6747917309472387e-05,
      "loss": 0.0001,
      "step": 107770
    },
    {
      "epoch": 33.25516815797593,
      "grad_norm": 5.001616955269128e-05,
      "learning_rate": 1.6744831842024066e-05,
      "loss": 0.0,
      "step": 107780
    },
    {
      "epoch": 33.25825362542425,
      "grad_norm": 0.0007842942140996456,
      "learning_rate": 1.674174637457575e-05,
      "loss": 0.0,
      "step": 107790
    },
    {
      "epoch": 33.26133909287257,
      "grad_norm": 0.0001474344899179414,
      "learning_rate": 1.673866090712743e-05,
      "loss": 0.0001,
      "step": 107800
    },
    {
      "epoch": 33.26442456032089,
      "grad_norm": 1.418774809280876e-05,
      "learning_rate": 1.6735575439679114e-05,
      "loss": 0.0001,
      "step": 107810
    },
    {
      "epoch": 33.267510027769205,
      "grad_norm": 0.00027515855617821217,
      "learning_rate": 1.6732489972230793e-05,
      "loss": 0.0,
      "step": 107820
    },
    {
      "epoch": 33.27059549521753,
      "grad_norm": 1.5021760191302747e-05,
      "learning_rate": 1.6729404504782475e-05,
      "loss": 0.0001,
      "step": 107830
    },
    {
      "epoch": 33.27368096266584,
      "grad_norm": 0.011701064184308052,
      "learning_rate": 1.6726319037334158e-05,
      "loss": 0.0011,
      "step": 107840
    },
    {
      "epoch": 33.276766430114165,
      "grad_norm": 0.00045576051343232393,
      "learning_rate": 1.6723233569885837e-05,
      "loss": 0.0018,
      "step": 107850
    },
    {
      "epoch": 33.27985189756248,
      "grad_norm": 0.0042271395213902,
      "learning_rate": 1.672014810243752e-05,
      "loss": 0.0,
      "step": 107860
    },
    {
      "epoch": 33.2829373650108,
      "grad_norm": 7.330664175242418e-06,
      "learning_rate": 1.67170626349892e-05,
      "loss": 0.0,
      "step": 107870
    },
    {
      "epoch": 33.28602283245912,
      "grad_norm": 8.928825263865292e-05,
      "learning_rate": 1.6713977167540884e-05,
      "loss": 0.0003,
      "step": 107880
    },
    {
      "epoch": 33.28910829990743,
      "grad_norm": 0.00046632616431452334,
      "learning_rate": 1.6710891700092567e-05,
      "loss": 0.0002,
      "step": 107890
    },
    {
      "epoch": 33.292193767355755,
      "grad_norm": 0.00048803328536450863,
      "learning_rate": 1.6707806232644246e-05,
      "loss": 0.0,
      "step": 107900
    },
    {
      "epoch": 33.29527923480407,
      "grad_norm": 1.2368062698442372e-06,
      "learning_rate": 1.6704720765195928e-05,
      "loss": 0.0,
      "step": 107910
    },
    {
      "epoch": 33.29836470225239,
      "grad_norm": 5.9683712606783956e-05,
      "learning_rate": 1.6701635297747607e-05,
      "loss": 0.0,
      "step": 107920
    },
    {
      "epoch": 33.30145016970071,
      "grad_norm": 2.2625520159635926e-06,
      "learning_rate": 1.669854983029929e-05,
      "loss": 0.0,
      "step": 107930
    },
    {
      "epoch": 33.30453563714903,
      "grad_norm": 2.990630491694901e-05,
      "learning_rate": 1.6695464362850972e-05,
      "loss": 0.0,
      "step": 107940
    },
    {
      "epoch": 33.307621104597345,
      "grad_norm": 4.793206471731537e-07,
      "learning_rate": 1.6692378895402655e-05,
      "loss": 0.0,
      "step": 107950
    },
    {
      "epoch": 33.31070657204567,
      "grad_norm": 0.00011261733015999198,
      "learning_rate": 1.6689293427954337e-05,
      "loss": 0.0001,
      "step": 107960
    },
    {
      "epoch": 33.31379203949398,
      "grad_norm": 0.0017170998034998775,
      "learning_rate": 1.6686207960506016e-05,
      "loss": 0.0001,
      "step": 107970
    },
    {
      "epoch": 33.316877506942305,
      "grad_norm": 0.0007074457826092839,
      "learning_rate": 1.66831224930577e-05,
      "loss": 0.0,
      "step": 107980
    },
    {
      "epoch": 33.31996297439062,
      "grad_norm": 0.001123796682804823,
      "learning_rate": 1.668003702560938e-05,
      "loss": 0.008,
      "step": 107990
    },
    {
      "epoch": 33.323048441838935,
      "grad_norm": 1.0376888894825242e-05,
      "learning_rate": 1.6676951558161064e-05,
      "loss": 0.0,
      "step": 108000
    },
    {
      "epoch": 33.32613390928726,
      "grad_norm": 0.04716166481375694,
      "learning_rate": 1.6673866090712746e-05,
      "loss": 0.0,
      "step": 108010
    },
    {
      "epoch": 33.32921937673557,
      "grad_norm": 0.000649681780487299,
      "learning_rate": 1.6670780623264425e-05,
      "loss": 0.0,
      "step": 108020
    },
    {
      "epoch": 33.332304844183895,
      "grad_norm": 1.4917606705466824e-08,
      "learning_rate": 1.6667695155816108e-05,
      "loss": 0.0,
      "step": 108030
    },
    {
      "epoch": 33.33539031163221,
      "grad_norm": 0.009173897095024586,
      "learning_rate": 1.6664609688367787e-05,
      "loss": 0.0,
      "step": 108040
    },
    {
      "epoch": 33.33847577908053,
      "grad_norm": 0.0001994697522604838,
      "learning_rate": 1.666152422091947e-05,
      "loss": 0.0,
      "step": 108050
    },
    {
      "epoch": 33.34156124652885,
      "grad_norm": 2.23787907316364e-07,
      "learning_rate": 1.6658438753471152e-05,
      "loss": 0.0024,
      "step": 108060
    },
    {
      "epoch": 33.34464671397717,
      "grad_norm": 0.00024260363716166466,
      "learning_rate": 1.6655353286022834e-05,
      "loss": 0.0118,
      "step": 108070
    },
    {
      "epoch": 33.347732181425485,
      "grad_norm": 2.527240212657489e-05,
      "learning_rate": 1.6652267818574517e-05,
      "loss": 0.0,
      "step": 108080
    },
    {
      "epoch": 33.35081764887381,
      "grad_norm": 0.00018594480934552848,
      "learning_rate": 1.6649182351126196e-05,
      "loss": 0.0,
      "step": 108090
    },
    {
      "epoch": 33.35390311632212,
      "grad_norm": 8.739370969124138e-07,
      "learning_rate": 1.664609688367788e-05,
      "loss": 0.0,
      "step": 108100
    },
    {
      "epoch": 33.356988583770445,
      "grad_norm": 0.0014557117829099298,
      "learning_rate": 1.664301141622956e-05,
      "loss": 0.0,
      "step": 108110
    },
    {
      "epoch": 33.36007405121876,
      "grad_norm": 0.0028707508463412523,
      "learning_rate": 1.663992594878124e-05,
      "loss": 0.0,
      "step": 108120
    },
    {
      "epoch": 33.363159518667075,
      "grad_norm": 1.7221007908574393e-07,
      "learning_rate": 1.6636840481332922e-05,
      "loss": 0.0,
      "step": 108130
    },
    {
      "epoch": 33.3662449861154,
      "grad_norm": 5.3276675316737965e-05,
      "learning_rate": 1.6633755013884605e-05,
      "loss": 0.0031,
      "step": 108140
    },
    {
      "epoch": 33.36933045356371,
      "grad_norm": 0.017612671479582787,
      "learning_rate": 1.6630669546436287e-05,
      "loss": 0.0007,
      "step": 108150
    },
    {
      "epoch": 33.372415921012035,
      "grad_norm": 6.948338977963431e-06,
      "learning_rate": 1.6627584078987966e-05,
      "loss": 0.0,
      "step": 108160
    },
    {
      "epoch": 33.37550138846035,
      "grad_norm": 5.978191097710805e-07,
      "learning_rate": 1.662449861153965e-05,
      "loss": 0.0044,
      "step": 108170
    },
    {
      "epoch": 33.37858685590867,
      "grad_norm": 0.00010442810889799148,
      "learning_rate": 1.662141314409133e-05,
      "loss": 0.0,
      "step": 108180
    },
    {
      "epoch": 33.38167232335699,
      "grad_norm": 5.3054550335218664e-06,
      "learning_rate": 1.661832767664301e-05,
      "loss": 0.0,
      "step": 108190
    },
    {
      "epoch": 33.38475779080531,
      "grad_norm": 3.94360677091754e-06,
      "learning_rate": 1.6615242209194693e-05,
      "loss": 0.01,
      "step": 108200
    },
    {
      "epoch": 33.387843258253625,
      "grad_norm": 3.538649616530165e-05,
      "learning_rate": 1.6612156741746375e-05,
      "loss": 0.0002,
      "step": 108210
    },
    {
      "epoch": 33.39092872570195,
      "grad_norm": 8.096607416518964e-06,
      "learning_rate": 1.6609071274298058e-05,
      "loss": 0.0,
      "step": 108220
    },
    {
      "epoch": 33.39401419315026,
      "grad_norm": 2.8117501642555e-05,
      "learning_rate": 1.660598580684974e-05,
      "loss": 0.0001,
      "step": 108230
    },
    {
      "epoch": 33.39709966059858,
      "grad_norm": 2.746835889411159e-06,
      "learning_rate": 1.660290033940142e-05,
      "loss": 0.0,
      "step": 108240
    },
    {
      "epoch": 33.4001851280469,
      "grad_norm": 0.0019551636651158333,
      "learning_rate": 1.6599814871953102e-05,
      "loss": 0.0001,
      "step": 108250
    },
    {
      "epoch": 33.403270595495215,
      "grad_norm": 0.0004729596257675439,
      "learning_rate": 1.659672940450478e-05,
      "loss": 0.0,
      "step": 108260
    },
    {
      "epoch": 33.40635606294354,
      "grad_norm": 3.3159823942696676e-05,
      "learning_rate": 1.6593643937056467e-05,
      "loss": 0.0,
      "step": 108270
    },
    {
      "epoch": 33.40944153039185,
      "grad_norm": 8.31336437840946e-05,
      "learning_rate": 1.6590558469608146e-05,
      "loss": 0.0,
      "step": 108280
    },
    {
      "epoch": 33.412526997840175,
      "grad_norm": 3.4385909657430602e-06,
      "learning_rate": 1.658747300215983e-05,
      "loss": 0.0,
      "step": 108290
    },
    {
      "epoch": 33.41561246528849,
      "grad_norm": 1.3248036339064129e-05,
      "learning_rate": 1.658438753471151e-05,
      "loss": 0.0022,
      "step": 108300
    },
    {
      "epoch": 33.41869793273681,
      "grad_norm": 0.001690235803835094,
      "learning_rate": 1.658130206726319e-05,
      "loss": 0.0002,
      "step": 108310
    },
    {
      "epoch": 33.42178340018513,
      "grad_norm": 6.249067519092932e-05,
      "learning_rate": 1.6578216599814872e-05,
      "loss": 0.0007,
      "step": 108320
    },
    {
      "epoch": 33.42486886763345,
      "grad_norm": 2.571240429460886e-06,
      "learning_rate": 1.657513113236655e-05,
      "loss": 0.0008,
      "step": 108330
    },
    {
      "epoch": 33.427954335081765,
      "grad_norm": 2.016694452322554e-06,
      "learning_rate": 1.6572045664918237e-05,
      "loss": 0.0,
      "step": 108340
    },
    {
      "epoch": 33.43103980253008,
      "grad_norm": 0.1894313395023346,
      "learning_rate": 1.6568960197469917e-05,
      "loss": 0.0001,
      "step": 108350
    },
    {
      "epoch": 33.4341252699784,
      "grad_norm": 0.00010176507203141227,
      "learning_rate": 1.65658747300216e-05,
      "loss": 0.0003,
      "step": 108360
    },
    {
      "epoch": 33.43721073742672,
      "grad_norm": 0.00016666088777128607,
      "learning_rate": 1.656278926257328e-05,
      "loss": 0.0,
      "step": 108370
    },
    {
      "epoch": 33.44029620487504,
      "grad_norm": 6.169575954118045e-06,
      "learning_rate": 1.655970379512496e-05,
      "loss": 0.0001,
      "step": 108380
    },
    {
      "epoch": 33.443381672323355,
      "grad_norm": 0.014177757315337658,
      "learning_rate": 1.6556618327676643e-05,
      "loss": 0.0001,
      "step": 108390
    },
    {
      "epoch": 33.44646713977168,
      "grad_norm": 1.2017580270767212,
      "learning_rate": 1.6553532860228326e-05,
      "loss": 0.0005,
      "step": 108400
    },
    {
      "epoch": 33.44955260721999,
      "grad_norm": 0.06073623523116112,
      "learning_rate": 1.6550447392780008e-05,
      "loss": 0.0,
      "step": 108410
    },
    {
      "epoch": 33.452638074668315,
      "grad_norm": 2.9907490898040123e-05,
      "learning_rate": 1.654736192533169e-05,
      "loss": 0.0001,
      "step": 108420
    },
    {
      "epoch": 33.45572354211663,
      "grad_norm": 0.0009154469007626176,
      "learning_rate": 1.654427645788337e-05,
      "loss": 0.0,
      "step": 108430
    },
    {
      "epoch": 33.45880900956495,
      "grad_norm": 0.00029534855275414884,
      "learning_rate": 1.6541190990435052e-05,
      "loss": 0.0,
      "step": 108440
    },
    {
      "epoch": 33.46189447701327,
      "grad_norm": 0.12478610128164291,
      "learning_rate": 1.653810552298673e-05,
      "loss": 0.0001,
      "step": 108450
    },
    {
      "epoch": 33.46497994446159,
      "grad_norm": 0.0008176970295608044,
      "learning_rate": 1.6535020055538414e-05,
      "loss": 0.0,
      "step": 108460
    },
    {
      "epoch": 33.468065411909905,
      "grad_norm": 1.3078574738756288e-05,
      "learning_rate": 1.6531934588090096e-05,
      "loss": 0.0001,
      "step": 108470
    },
    {
      "epoch": 33.47115087935822,
      "grad_norm": 0.0003628408594522625,
      "learning_rate": 1.652884912064178e-05,
      "loss": 0.0,
      "step": 108480
    },
    {
      "epoch": 33.47423634680654,
      "grad_norm": 1.3292348057802883e-06,
      "learning_rate": 1.652576365319346e-05,
      "loss": 0.0,
      "step": 108490
    },
    {
      "epoch": 33.47732181425486,
      "grad_norm": 2.5868101147352718e-05,
      "learning_rate": 1.652267818574514e-05,
      "loss": 0.0,
      "step": 108500
    },
    {
      "epoch": 33.48040728170318,
      "grad_norm": 2.4553794446546817e-06,
      "learning_rate": 1.6519592718296823e-05,
      "loss": 0.0,
      "step": 108510
    },
    {
      "epoch": 33.483492749151495,
      "grad_norm": 2.456478432577569e-05,
      "learning_rate": 1.6516507250848505e-05,
      "loss": 0.0,
      "step": 108520
    },
    {
      "epoch": 33.48657821659982,
      "grad_norm": 1.1297515811747871e-06,
      "learning_rate": 1.6513421783400184e-05,
      "loss": 0.0,
      "step": 108530
    },
    {
      "epoch": 33.48966368404813,
      "grad_norm": 0.00016383346519432962,
      "learning_rate": 1.651033631595187e-05,
      "loss": 0.0,
      "step": 108540
    },
    {
      "epoch": 33.492749151496454,
      "grad_norm": 5.055953238297661e-07,
      "learning_rate": 1.650725084850355e-05,
      "loss": 0.0,
      "step": 108550
    },
    {
      "epoch": 33.49583461894477,
      "grad_norm": 4.828802775591612e-05,
      "learning_rate": 1.650416538105523e-05,
      "loss": 0.0001,
      "step": 108560
    },
    {
      "epoch": 33.49892008639309,
      "grad_norm": 3.568597821868025e-05,
      "learning_rate": 1.650107991360691e-05,
      "loss": 0.0001,
      "step": 108570
    },
    {
      "epoch": 33.50200555384141,
      "grad_norm": 7.065453246468678e-05,
      "learning_rate": 1.6497994446158593e-05,
      "loss": 0.0,
      "step": 108580
    },
    {
      "epoch": 33.50509102128972,
      "grad_norm": 0.00018172088311985135,
      "learning_rate": 1.6494908978710276e-05,
      "loss": 0.0,
      "step": 108590
    },
    {
      "epoch": 33.508176488738044,
      "grad_norm": 4.478848495637067e-06,
      "learning_rate": 1.6491823511261955e-05,
      "loss": 0.0,
      "step": 108600
    },
    {
      "epoch": 33.51126195618636,
      "grad_norm": 0.0006869799108244479,
      "learning_rate": 1.648873804381364e-05,
      "loss": 0.0,
      "step": 108610
    },
    {
      "epoch": 33.51434742363468,
      "grad_norm": 1.0522152479097713e-05,
      "learning_rate": 1.648565257636532e-05,
      "loss": 0.0,
      "step": 108620
    },
    {
      "epoch": 33.517432891083,
      "grad_norm": 1.4792864021728747e-05,
      "learning_rate": 1.6482567108917002e-05,
      "loss": 0.0,
      "step": 108630
    },
    {
      "epoch": 33.52051835853132,
      "grad_norm": 3.3529468055348843e-06,
      "learning_rate": 1.6479481641468685e-05,
      "loss": 0.0,
      "step": 108640
    },
    {
      "epoch": 33.523603825979635,
      "grad_norm": 6.381894309015479e-06,
      "learning_rate": 1.6476396174020364e-05,
      "loss": 0.0,
      "step": 108650
    },
    {
      "epoch": 33.52668929342796,
      "grad_norm": 1.9372171664144844e-05,
      "learning_rate": 1.6473310706572046e-05,
      "loss": 0.0001,
      "step": 108660
    },
    {
      "epoch": 33.52977476087627,
      "grad_norm": 0.00016763093299232423,
      "learning_rate": 1.647022523912373e-05,
      "loss": 0.0,
      "step": 108670
    },
    {
      "epoch": 33.532860228324594,
      "grad_norm": 5.7803372328635305e-06,
      "learning_rate": 1.646713977167541e-05,
      "loss": 0.0,
      "step": 108680
    },
    {
      "epoch": 33.53594569577291,
      "grad_norm": 0.0009363133576698601,
      "learning_rate": 1.646405430422709e-05,
      "loss": 0.0,
      "step": 108690
    },
    {
      "epoch": 33.539031163221225,
      "grad_norm": 0.0018224401865154505,
      "learning_rate": 1.6460968836778773e-05,
      "loss": 0.0,
      "step": 108700
    },
    {
      "epoch": 33.54211663066955,
      "grad_norm": 0.00013702845899388194,
      "learning_rate": 1.6457883369330455e-05,
      "loss": 0.0,
      "step": 108710
    },
    {
      "epoch": 33.54520209811786,
      "grad_norm": 1.706490365904756e-05,
      "learning_rate": 1.6454797901882134e-05,
      "loss": 0.0,
      "step": 108720
    },
    {
      "epoch": 33.548287565566184,
      "grad_norm": 3.8281887100310996e-05,
      "learning_rate": 1.6451712434433817e-05,
      "loss": 0.0,
      "step": 108730
    },
    {
      "epoch": 33.5513730330145,
      "grad_norm": 6.985691288718954e-05,
      "learning_rate": 1.64486269669855e-05,
      "loss": 0.0,
      "step": 108740
    },
    {
      "epoch": 33.55445850046282,
      "grad_norm": 0.07864594459533691,
      "learning_rate": 1.6445541499537182e-05,
      "loss": 0.0,
      "step": 108750
    },
    {
      "epoch": 33.55754396791114,
      "grad_norm": 3.743320485227741e-05,
      "learning_rate": 1.6442456032088864e-05,
      "loss": 0.0,
      "step": 108760
    },
    {
      "epoch": 33.56062943535946,
      "grad_norm": 0.00014252403343562037,
      "learning_rate": 1.6439370564640543e-05,
      "loss": 0.0,
      "step": 108770
    },
    {
      "epoch": 33.563714902807774,
      "grad_norm": 0.0001415588048985228,
      "learning_rate": 1.6436285097192226e-05,
      "loss": 0.0,
      "step": 108780
    },
    {
      "epoch": 33.5668003702561,
      "grad_norm": 0.0008243532502092421,
      "learning_rate": 1.6433199629743905e-05,
      "loss": 0.0,
      "step": 108790
    },
    {
      "epoch": 33.56988583770441,
      "grad_norm": 0.0007470636628568172,
      "learning_rate": 1.6430114162295587e-05,
      "loss": 0.0,
      "step": 108800
    },
    {
      "epoch": 33.572971305152734,
      "grad_norm": 2.7924128517042845e-05,
      "learning_rate": 1.642702869484727e-05,
      "loss": 0.0,
      "step": 108810
    },
    {
      "epoch": 33.57605677260105,
      "grad_norm": 3.4424600016791373e-05,
      "learning_rate": 1.6423943227398952e-05,
      "loss": 0.0,
      "step": 108820
    },
    {
      "epoch": 33.579142240049364,
      "grad_norm": 0.0016349961515516043,
      "learning_rate": 1.6420857759950635e-05,
      "loss": 0.0,
      "step": 108830
    },
    {
      "epoch": 33.58222770749769,
      "grad_norm": 1.5165927607085905e-06,
      "learning_rate": 1.6417772292502314e-05,
      "loss": 0.0001,
      "step": 108840
    },
    {
      "epoch": 33.585313174946,
      "grad_norm": 2.781028797471663e-06,
      "learning_rate": 1.6414686825053996e-05,
      "loss": 0.0001,
      "step": 108850
    },
    {
      "epoch": 33.588398642394324,
      "grad_norm": 0.00013058494369033724,
      "learning_rate": 1.6411601357605675e-05,
      "loss": 0.0001,
      "step": 108860
    },
    {
      "epoch": 33.59148410984264,
      "grad_norm": 0.0008719805045984685,
      "learning_rate": 1.6408515890157358e-05,
      "loss": 0.0001,
      "step": 108870
    },
    {
      "epoch": 33.59456957729096,
      "grad_norm": 3.256326090195216e-05,
      "learning_rate": 1.6405430422709044e-05,
      "loss": 0.0,
      "step": 108880
    },
    {
      "epoch": 33.59765504473928,
      "grad_norm": 0.00011706808436429128,
      "learning_rate": 1.6402344955260723e-05,
      "loss": 0.0,
      "step": 108890
    },
    {
      "epoch": 33.6007405121876,
      "grad_norm": 0.00021755549823865294,
      "learning_rate": 1.6399259487812405e-05,
      "loss": 0.0,
      "step": 108900
    },
    {
      "epoch": 33.603825979635914,
      "grad_norm": 8.667140718898736e-06,
      "learning_rate": 1.6396174020364084e-05,
      "loss": 0.0005,
      "step": 108910
    },
    {
      "epoch": 33.60691144708424,
      "grad_norm": 4.791436822415562e-06,
      "learning_rate": 1.6393088552915767e-05,
      "loss": 0.0,
      "step": 108920
    },
    {
      "epoch": 33.60999691453255,
      "grad_norm": 1.06413135654293e-05,
      "learning_rate": 1.639000308546745e-05,
      "loss": 0.0,
      "step": 108930
    },
    {
      "epoch": 33.61308238198087,
      "grad_norm": 0.0005658376612700522,
      "learning_rate": 1.6386917618019132e-05,
      "loss": 0.0,
      "step": 108940
    },
    {
      "epoch": 33.61616784942919,
      "grad_norm": 3.6954276083633886e-07,
      "learning_rate": 1.6383832150570814e-05,
      "loss": 0.0,
      "step": 108950
    },
    {
      "epoch": 33.619253316877504,
      "grad_norm": 6.398795903805876e-06,
      "learning_rate": 1.6380746683122493e-05,
      "loss": 0.0,
      "step": 108960
    },
    {
      "epoch": 33.62233878432583,
      "grad_norm": 3.1847830541664734e-05,
      "learning_rate": 1.6377661215674176e-05,
      "loss": 0.0,
      "step": 108970
    },
    {
      "epoch": 33.62542425177414,
      "grad_norm": 2.6907217034022324e-05,
      "learning_rate": 1.6374575748225855e-05,
      "loss": 0.0,
      "step": 108980
    },
    {
      "epoch": 33.628509719222464,
      "grad_norm": 2.95597487820487e-06,
      "learning_rate": 1.6371490280777537e-05,
      "loss": 0.0011,
      "step": 108990
    },
    {
      "epoch": 33.63159518667078,
      "grad_norm": 0.002968188375234604,
      "learning_rate": 1.636840481332922e-05,
      "loss": 0.0,
      "step": 109000
    },
    {
      "epoch": 33.6346806541191,
      "grad_norm": 8.086009984253906e-06,
      "learning_rate": 1.6365319345880902e-05,
      "loss": 0.0001,
      "step": 109010
    },
    {
      "epoch": 33.63776612156742,
      "grad_norm": 0.0005612321547232568,
      "learning_rate": 1.6362233878432585e-05,
      "loss": 0.0,
      "step": 109020
    },
    {
      "epoch": 33.64085158901574,
      "grad_norm": 1.143893086918979e-06,
      "learning_rate": 1.6359148410984264e-05,
      "loss": 0.0,
      "step": 109030
    },
    {
      "epoch": 33.643937056464054,
      "grad_norm": 4.071065632160753e-05,
      "learning_rate": 1.6356062943535946e-05,
      "loss": 0.0,
      "step": 109040
    },
    {
      "epoch": 33.64702252391237,
      "grad_norm": 5.053234417573549e-07,
      "learning_rate": 1.635297747608763e-05,
      "loss": 0.0,
      "step": 109050
    },
    {
      "epoch": 33.65010799136069,
      "grad_norm": 0.0003008745552506298,
      "learning_rate": 1.6349892008639308e-05,
      "loss": 0.0013,
      "step": 109060
    },
    {
      "epoch": 33.65319345880901,
      "grad_norm": 0.024794016033411026,
      "learning_rate": 1.634680654119099e-05,
      "loss": 0.0,
      "step": 109070
    },
    {
      "epoch": 33.65627892625733,
      "grad_norm": 2.953780267489492e-06,
      "learning_rate": 1.6343721073742673e-05,
      "loss": 0.0,
      "step": 109080
    },
    {
      "epoch": 33.659364393705644,
      "grad_norm": 6.622301953029819e-06,
      "learning_rate": 1.6340635606294355e-05,
      "loss": 0.0002,
      "step": 109090
    },
    {
      "epoch": 33.662449861153966,
      "grad_norm": 0.0003376544045750052,
      "learning_rate": 1.6337550138846035e-05,
      "loss": 0.0002,
      "step": 109100
    },
    {
      "epoch": 33.66553532860228,
      "grad_norm": 4.097522105439566e-05,
      "learning_rate": 1.6334464671397717e-05,
      "loss": 0.0005,
      "step": 109110
    },
    {
      "epoch": 33.668620796050604,
      "grad_norm": 0.00034238159423694015,
      "learning_rate": 1.63313792039494e-05,
      "loss": 0.0001,
      "step": 109120
    },
    {
      "epoch": 33.67170626349892,
      "grad_norm": 0.001681364024989307,
      "learning_rate": 1.632829373650108e-05,
      "loss": 0.0001,
      "step": 109130
    },
    {
      "epoch": 33.67479173094724,
      "grad_norm": 0.00010890976409427822,
      "learning_rate": 1.6325208269052764e-05,
      "loss": 0.0,
      "step": 109140
    },
    {
      "epoch": 33.67787719839556,
      "grad_norm": 4.1323903133161366e-05,
      "learning_rate": 1.6322122801604444e-05,
      "loss": 0.0,
      "step": 109150
    },
    {
      "epoch": 33.68096266584388,
      "grad_norm": 7.3029873419727664e-06,
      "learning_rate": 1.6319037334156126e-05,
      "loss": 0.0,
      "step": 109160
    },
    {
      "epoch": 33.684048133292194,
      "grad_norm": 8.556364628020674e-05,
      "learning_rate": 1.631595186670781e-05,
      "loss": 0.0,
      "step": 109170
    },
    {
      "epoch": 33.68713360074051,
      "grad_norm": 1.6692943972884677e-05,
      "learning_rate": 1.6312866399259488e-05,
      "loss": 0.0001,
      "step": 109180
    },
    {
      "epoch": 33.69021906818883,
      "grad_norm": 5.7184075558325276e-05,
      "learning_rate": 1.630978093181117e-05,
      "loss": 0.0,
      "step": 109190
    },
    {
      "epoch": 33.69330453563715,
      "grad_norm": 1.6910867088881787e-06,
      "learning_rate": 1.630669546436285e-05,
      "loss": 0.0,
      "step": 109200
    },
    {
      "epoch": 33.69639000308547,
      "grad_norm": 1.1084243851655629e-05,
      "learning_rate": 1.6303609996914535e-05,
      "loss": 0.0,
      "step": 109210
    },
    {
      "epoch": 33.699475470533784,
      "grad_norm": 2.1442619981826283e-06,
      "learning_rate": 1.6300524529466214e-05,
      "loss": 0.0,
      "step": 109220
    },
    {
      "epoch": 33.702560937982106,
      "grad_norm": 0.000346143584465608,
      "learning_rate": 1.6297439062017897e-05,
      "loss": 0.0,
      "step": 109230
    },
    {
      "epoch": 33.70564640543042,
      "grad_norm": 8.450804784843058e-07,
      "learning_rate": 1.629435359456958e-05,
      "loss": 0.0,
      "step": 109240
    },
    {
      "epoch": 33.708731872878744,
      "grad_norm": 0.005831709131598473,
      "learning_rate": 1.6291268127121258e-05,
      "loss": 0.0,
      "step": 109250
    },
    {
      "epoch": 33.71181734032706,
      "grad_norm": 1.5504534530919045e-05,
      "learning_rate": 1.628818265967294e-05,
      "loss": 0.0,
      "step": 109260
    },
    {
      "epoch": 33.71490280777538,
      "grad_norm": 0.00016150866576936096,
      "learning_rate": 1.6285097192224623e-05,
      "loss": 0.0002,
      "step": 109270
    },
    {
      "epoch": 33.717988275223696,
      "grad_norm": 7.958654350659344e-06,
      "learning_rate": 1.6282011724776306e-05,
      "loss": 0.0,
      "step": 109280
    },
    {
      "epoch": 33.72107374267201,
      "grad_norm": 0.006495136301964521,
      "learning_rate": 1.6278926257327988e-05,
      "loss": 0.0,
      "step": 109290
    },
    {
      "epoch": 33.724159210120334,
      "grad_norm": 3.2950061722658575e-05,
      "learning_rate": 1.6275840789879667e-05,
      "loss": 0.0,
      "step": 109300
    },
    {
      "epoch": 33.72724467756865,
      "grad_norm": 0.0014410397270694375,
      "learning_rate": 1.627275532243135e-05,
      "loss": 0.0,
      "step": 109310
    },
    {
      "epoch": 33.73033014501697,
      "grad_norm": 0.00015267457638401538,
      "learning_rate": 1.626966985498303e-05,
      "loss": 0.0,
      "step": 109320
    },
    {
      "epoch": 33.733415612465286,
      "grad_norm": 8.900103125597525e-07,
      "learning_rate": 1.626658438753471e-05,
      "loss": 0.0,
      "step": 109330
    },
    {
      "epoch": 33.73650107991361,
      "grad_norm": 6.542632036143914e-05,
      "learning_rate": 1.6263498920086394e-05,
      "loss": 0.0,
      "step": 109340
    },
    {
      "epoch": 33.739586547361924,
      "grad_norm": 0.00016301247524097562,
      "learning_rate": 1.6260413452638076e-05,
      "loss": 0.0,
      "step": 109350
    },
    {
      "epoch": 33.742672014810246,
      "grad_norm": 0.0003913087130058557,
      "learning_rate": 1.625732798518976e-05,
      "loss": 0.0,
      "step": 109360
    },
    {
      "epoch": 33.74575748225856,
      "grad_norm": 2.0110851437493693e-06,
      "learning_rate": 1.6254242517741438e-05,
      "loss": 0.0007,
      "step": 109370
    },
    {
      "epoch": 33.748842949706884,
      "grad_norm": 3.5083860439044656e-06,
      "learning_rate": 1.625115705029312e-05,
      "loss": 0.0,
      "step": 109380
    },
    {
      "epoch": 33.7519284171552,
      "grad_norm": 2.4821754777804017e-05,
      "learning_rate": 1.6248071582844803e-05,
      "loss": 0.0008,
      "step": 109390
    },
    {
      "epoch": 33.755013884603514,
      "grad_norm": 5.058007445768453e-05,
      "learning_rate": 1.6244986115396482e-05,
      "loss": 0.0,
      "step": 109400
    },
    {
      "epoch": 33.758099352051836,
      "grad_norm": 3.42489147442393e-05,
      "learning_rate": 1.6241900647948168e-05,
      "loss": 0.0018,
      "step": 109410
    },
    {
      "epoch": 33.76118481950015,
      "grad_norm": 0.0035358271561563015,
      "learning_rate": 1.6238815180499847e-05,
      "loss": 0.0003,
      "step": 109420
    },
    {
      "epoch": 33.764270286948474,
      "grad_norm": 2.0564361875585746e-06,
      "learning_rate": 1.623572971305153e-05,
      "loss": 0.0,
      "step": 109430
    },
    {
      "epoch": 33.76735575439679,
      "grad_norm": 1.3049262634012848e-05,
      "learning_rate": 1.6232644245603208e-05,
      "loss": 0.0,
      "step": 109440
    },
    {
      "epoch": 33.77044122184511,
      "grad_norm": 6.4647938415873796e-06,
      "learning_rate": 1.622955877815489e-05,
      "loss": 0.0,
      "step": 109450
    },
    {
      "epoch": 33.773526689293426,
      "grad_norm": 1.8821440335159423e-06,
      "learning_rate": 1.6226473310706573e-05,
      "loss": 0.0,
      "step": 109460
    },
    {
      "epoch": 33.77661215674175,
      "grad_norm": 1.212827737617772e-05,
      "learning_rate": 1.6223387843258252e-05,
      "loss": 0.0,
      "step": 109470
    },
    {
      "epoch": 33.779697624190064,
      "grad_norm": 6.912227399880067e-05,
      "learning_rate": 1.6220302375809938e-05,
      "loss": 0.0,
      "step": 109480
    },
    {
      "epoch": 33.782783091638386,
      "grad_norm": 0.0015201070345938206,
      "learning_rate": 1.6217216908361617e-05,
      "loss": 0.0,
      "step": 109490
    },
    {
      "epoch": 33.7858685590867,
      "grad_norm": 0.04462556540966034,
      "learning_rate": 1.62141314409133e-05,
      "loss": 0.0,
      "step": 109500
    },
    {
      "epoch": 33.78895402653502,
      "grad_norm": 0.4264671802520752,
      "learning_rate": 1.6211045973464982e-05,
      "loss": 0.002,
      "step": 109510
    },
    {
      "epoch": 33.79203949398334,
      "grad_norm": 0.000918712408747524,
      "learning_rate": 1.620796050601666e-05,
      "loss": 0.0,
      "step": 109520
    },
    {
      "epoch": 33.795124961431654,
      "grad_norm": 6.764822501281742e-06,
      "learning_rate": 1.6204875038568344e-05,
      "loss": 0.0,
      "step": 109530
    },
    {
      "epoch": 33.798210428879976,
      "grad_norm": 0.0003519073943607509,
      "learning_rate": 1.6201789571120026e-05,
      "loss": 0.0,
      "step": 109540
    },
    {
      "epoch": 33.80129589632829,
      "grad_norm": 0.00030421718838624656,
      "learning_rate": 1.619870410367171e-05,
      "loss": 0.0,
      "step": 109550
    },
    {
      "epoch": 33.80438136377661,
      "grad_norm": 5.8633246226236224e-05,
      "learning_rate": 1.6195618636223388e-05,
      "loss": 0.0,
      "step": 109560
    },
    {
      "epoch": 33.80746683122493,
      "grad_norm": 1.0115854820469394e-05,
      "learning_rate": 1.619253316877507e-05,
      "loss": 0.0003,
      "step": 109570
    },
    {
      "epoch": 33.81055229867325,
      "grad_norm": 9.566402150085196e-05,
      "learning_rate": 1.6189447701326753e-05,
      "loss": 0.0,
      "step": 109580
    },
    {
      "epoch": 33.813637766121566,
      "grad_norm": 5.772006943516317e-07,
      "learning_rate": 1.6186362233878432e-05,
      "loss": 0.0001,
      "step": 109590
    },
    {
      "epoch": 33.81672323356989,
      "grad_norm": 0.002576533704996109,
      "learning_rate": 1.6183276766430114e-05,
      "loss": 0.0,
      "step": 109600
    },
    {
      "epoch": 33.819808701018204,
      "grad_norm": 0.0006379417609423399,
      "learning_rate": 1.6180191298981797e-05,
      "loss": 0.0,
      "step": 109610
    },
    {
      "epoch": 33.822894168466526,
      "grad_norm": 2.438413503114134e-05,
      "learning_rate": 1.617710583153348e-05,
      "loss": 0.0,
      "step": 109620
    },
    {
      "epoch": 33.82597963591484,
      "grad_norm": 4.630259718396701e-05,
      "learning_rate": 1.617402036408516e-05,
      "loss": 0.0,
      "step": 109630
    },
    {
      "epoch": 33.829065103363156,
      "grad_norm": 0.0001481686340412125,
      "learning_rate": 1.617093489663684e-05,
      "loss": 0.0,
      "step": 109640
    },
    {
      "epoch": 33.83215057081148,
      "grad_norm": 2.5249758550671686e-07,
      "learning_rate": 1.6167849429188523e-05,
      "loss": 0.0,
      "step": 109650
    },
    {
      "epoch": 33.835236038259794,
      "grad_norm": 0.0005432032630778849,
      "learning_rate": 1.6164763961740202e-05,
      "loss": 0.0,
      "step": 109660
    },
    {
      "epoch": 33.838321505708116,
      "grad_norm": 2.3138444760206767e-07,
      "learning_rate": 1.6161678494291885e-05,
      "loss": 0.0,
      "step": 109670
    },
    {
      "epoch": 33.84140697315643,
      "grad_norm": 0.0001398479362251237,
      "learning_rate": 1.6158593026843567e-05,
      "loss": 0.0,
      "step": 109680
    },
    {
      "epoch": 33.84449244060475,
      "grad_norm": 2.8051192202838138e-05,
      "learning_rate": 1.615550755939525e-05,
      "loss": 0.0,
      "step": 109690
    },
    {
      "epoch": 33.84757790805307,
      "grad_norm": 5.3352065151557326e-05,
      "learning_rate": 1.6152422091946932e-05,
      "loss": 0.0,
      "step": 109700
    },
    {
      "epoch": 33.85066337550139,
      "grad_norm": 3.935741551686078e-05,
      "learning_rate": 1.614933662449861e-05,
      "loss": 0.0,
      "step": 109710
    },
    {
      "epoch": 33.853748842949706,
      "grad_norm": 0.0001340786984656006,
      "learning_rate": 1.6146251157050294e-05,
      "loss": 0.0,
      "step": 109720
    },
    {
      "epoch": 33.85683431039803,
      "grad_norm": 0.00023376070021186024,
      "learning_rate": 1.6143165689601973e-05,
      "loss": 0.0,
      "step": 109730
    },
    {
      "epoch": 33.85991977784634,
      "grad_norm": 1.647577664698474e-05,
      "learning_rate": 1.6140080222153655e-05,
      "loss": 0.0,
      "step": 109740
    },
    {
      "epoch": 33.86300524529466,
      "grad_norm": 2.1825040676048957e-05,
      "learning_rate": 1.6136994754705338e-05,
      "loss": 0.0,
      "step": 109750
    },
    {
      "epoch": 33.86609071274298,
      "grad_norm": 5.978718945698347e-06,
      "learning_rate": 1.613390928725702e-05,
      "loss": 0.0011,
      "step": 109760
    },
    {
      "epoch": 33.869176180191296,
      "grad_norm": 8.756070747040212e-05,
      "learning_rate": 1.6130823819808703e-05,
      "loss": 0.0,
      "step": 109770
    },
    {
      "epoch": 33.87226164763962,
      "grad_norm": 4.369733505882323e-05,
      "learning_rate": 1.6127738352360382e-05,
      "loss": 0.0,
      "step": 109780
    },
    {
      "epoch": 33.87534711508793,
      "grad_norm": 0.0002223370102001354,
      "learning_rate": 1.6124652884912064e-05,
      "loss": 0.0,
      "step": 109790
    },
    {
      "epoch": 33.878432582536256,
      "grad_norm": 0.03552337363362312,
      "learning_rate": 1.6121567417463747e-05,
      "loss": 0.0002,
      "step": 109800
    },
    {
      "epoch": 33.88151804998457,
      "grad_norm": 8.937303164202604e-07,
      "learning_rate": 1.611848195001543e-05,
      "loss": 0.0002,
      "step": 109810
    },
    {
      "epoch": 33.88460351743289,
      "grad_norm": 5.583509482676163e-05,
      "learning_rate": 1.6115396482567112e-05,
      "loss": 0.0,
      "step": 109820
    },
    {
      "epoch": 33.88768898488121,
      "grad_norm": 1.0904266673605889e-05,
      "learning_rate": 1.611231101511879e-05,
      "loss": 0.0001,
      "step": 109830
    },
    {
      "epoch": 33.89077445232953,
      "grad_norm": 2.937127646873705e-05,
      "learning_rate": 1.6109225547670473e-05,
      "loss": 0.0,
      "step": 109840
    },
    {
      "epoch": 33.893859919777846,
      "grad_norm": 0.0013228681636974216,
      "learning_rate": 1.6106140080222153e-05,
      "loss": 0.0,
      "step": 109850
    },
    {
      "epoch": 33.89694538722617,
      "grad_norm": 2.3721810066490434e-05,
      "learning_rate": 1.6103054612773835e-05,
      "loss": 0.0,
      "step": 109860
    },
    {
      "epoch": 33.90003085467448,
      "grad_norm": 0.00015910495130810887,
      "learning_rate": 1.6099969145325518e-05,
      "loss": 0.0,
      "step": 109870
    },
    {
      "epoch": 33.9031163221228,
      "grad_norm": 2.1084744730615057e-05,
      "learning_rate": 1.60968836778772e-05,
      "loss": 0.0,
      "step": 109880
    },
    {
      "epoch": 33.90620178957112,
      "grad_norm": 1.0504534202482319e-06,
      "learning_rate": 1.6093798210428882e-05,
      "loss": 0.0,
      "step": 109890
    },
    {
      "epoch": 33.909287257019436,
      "grad_norm": 3.7562099350907374e-06,
      "learning_rate": 1.609071274298056e-05,
      "loss": 0.0,
      "step": 109900
    },
    {
      "epoch": 33.91237272446776,
      "grad_norm": 3.5612285387287557e-07,
      "learning_rate": 1.6087627275532244e-05,
      "loss": 0.0009,
      "step": 109910
    },
    {
      "epoch": 33.91545819191607,
      "grad_norm": 1.990648570426856e-06,
      "learning_rate": 1.6084541808083927e-05,
      "loss": 0.0001,
      "step": 109920
    },
    {
      "epoch": 33.918543659364396,
      "grad_norm": 7.121256828668265e-08,
      "learning_rate": 1.6081456340635606e-05,
      "loss": 0.0,
      "step": 109930
    },
    {
      "epoch": 33.92162912681271,
      "grad_norm": 0.028682714328169823,
      "learning_rate": 1.6078370873187288e-05,
      "loss": 0.0,
      "step": 109940
    },
    {
      "epoch": 33.92471459426103,
      "grad_norm": 1.0411437187940464e-06,
      "learning_rate": 1.607528540573897e-05,
      "loss": 0.0,
      "step": 109950
    },
    {
      "epoch": 33.92780006170935,
      "grad_norm": 7.993215831447742e-07,
      "learning_rate": 1.6072199938290653e-05,
      "loss": 0.0,
      "step": 109960
    },
    {
      "epoch": 33.93088552915767,
      "grad_norm": 7.4973650043830276e-06,
      "learning_rate": 1.6069114470842332e-05,
      "loss": 0.0,
      "step": 109970
    },
    {
      "epoch": 33.933970996605986,
      "grad_norm": 0.00011807172268163413,
      "learning_rate": 1.6066029003394015e-05,
      "loss": 0.0,
      "step": 109980
    },
    {
      "epoch": 33.9370564640543,
      "grad_norm": 0.0009729210869409144,
      "learning_rate": 1.6062943535945697e-05,
      "loss": 0.0,
      "step": 109990
    },
    {
      "epoch": 33.94014193150262,
      "grad_norm": 0.0018855694215744734,
      "learning_rate": 1.6059858068497376e-05,
      "loss": 0.0,
      "step": 110000
    },
    {
      "epoch": 33.94322739895094,
      "grad_norm": 0.0068445042707026005,
      "learning_rate": 1.6056772601049062e-05,
      "loss": 0.0001,
      "step": 110010
    },
    {
      "epoch": 33.94631286639926,
      "grad_norm": 4.077645030520216e-07,
      "learning_rate": 1.605368713360074e-05,
      "loss": 0.0,
      "step": 110020
    },
    {
      "epoch": 33.949398333847576,
      "grad_norm": 2.1121895770193078e-05,
      "learning_rate": 1.6050601666152424e-05,
      "loss": 0.0,
      "step": 110030
    },
    {
      "epoch": 33.9524838012959,
      "grad_norm": 0.0001965721312444657,
      "learning_rate": 1.6047516198704106e-05,
      "loss": 0.0,
      "step": 110040
    },
    {
      "epoch": 33.95556926874421,
      "grad_norm": 0.023049402981996536,
      "learning_rate": 1.6044430731255785e-05,
      "loss": 0.0001,
      "step": 110050
    },
    {
      "epoch": 33.958654736192535,
      "grad_norm": 2.4099228994600708e-06,
      "learning_rate": 1.6041345263807468e-05,
      "loss": 0.0,
      "step": 110060
    },
    {
      "epoch": 33.96174020364085,
      "grad_norm": 2.296344428032171e-05,
      "learning_rate": 1.6038259796359147e-05,
      "loss": 0.0003,
      "step": 110070
    },
    {
      "epoch": 33.96482567108917,
      "grad_norm": 1.1367905244696885e-05,
      "learning_rate": 1.6035174328910833e-05,
      "loss": 0.0,
      "step": 110080
    },
    {
      "epoch": 33.96791113853749,
      "grad_norm": 2.7510742484082584e-07,
      "learning_rate": 1.603208886146251e-05,
      "loss": 0.0,
      "step": 110090
    },
    {
      "epoch": 33.9709966059858,
      "grad_norm": 0.00023799554037395865,
      "learning_rate": 1.6029003394014194e-05,
      "loss": 0.0002,
      "step": 110100
    },
    {
      "epoch": 33.974082073434126,
      "grad_norm": 7.76696288085077e-06,
      "learning_rate": 1.6025917926565877e-05,
      "loss": 0.0001,
      "step": 110110
    },
    {
      "epoch": 33.97716754088244,
      "grad_norm": 0.00018530288070905954,
      "learning_rate": 1.6022832459117556e-05,
      "loss": 0.0,
      "step": 110120
    },
    {
      "epoch": 33.98025300833076,
      "grad_norm": 1.6570874095123145e-06,
      "learning_rate": 1.6019746991669238e-05,
      "loss": 0.0,
      "step": 110130
    },
    {
      "epoch": 33.98333847577908,
      "grad_norm": 5.7890288189810235e-06,
      "learning_rate": 1.6016661524220917e-05,
      "loss": 0.0,
      "step": 110140
    },
    {
      "epoch": 33.9864239432274,
      "grad_norm": 0.0005012995679862797,
      "learning_rate": 1.6013576056772603e-05,
      "loss": 0.0,
      "step": 110150
    },
    {
      "epoch": 33.989509410675716,
      "grad_norm": 3.68212022294756e-05,
      "learning_rate": 1.6010490589324286e-05,
      "loss": 0.0,
      "step": 110160
    },
    {
      "epoch": 33.99259487812404,
      "grad_norm": 3.7630794395226985e-05,
      "learning_rate": 1.6007405121875965e-05,
      "loss": 0.0,
      "step": 110170
    },
    {
      "epoch": 33.99568034557235,
      "grad_norm": 4.151141183683649e-06,
      "learning_rate": 1.6004319654427647e-05,
      "loss": 0.0001,
      "step": 110180
    },
    {
      "epoch": 33.998765813020675,
      "grad_norm": 3.818210188910598e-06,
      "learning_rate": 1.6001234186979326e-05,
      "loss": 0.0,
      "step": 110190
    },
    {
      "epoch": 34.0,
      "eval_accuracy_branch1": 0.9999614208693807,
      "eval_accuracy_branch2": 0.4048204623708805,
      "eval_f1_branch1": 0.9999676879377873,
      "eval_f1_branch2": 0.3890639056815961,
      "eval_loss": 7.769003423163667e-05,
      "eval_precision_branch1": 0.9999668279139776,
      "eval_precision_branch2": 0.5243313741867949,
      "eval_recall_branch1": 0.9999685508404427,
      "eval_recall_branch2": 0.5156462486617864,
      "eval_runtime": 239.8717,
      "eval_samples_per_second": 432.244,
      "eval_steps_per_second": 54.033,
      "step": 110194
    },
    {
      "epoch": 34.00185128046899,
      "grad_norm": 5.220641128289571e-07,
      "learning_rate": 1.599814871953101e-05,
      "loss": 0.0,
      "step": 110200
    },
    {
      "epoch": 34.00493674791731,
      "grad_norm": 3.053944237763062e-05,
      "learning_rate": 1.599506325208269e-05,
      "loss": 0.0001,
      "step": 110210
    },
    {
      "epoch": 34.00802221536563,
      "grad_norm": 6.598077106900746e-06,
      "learning_rate": 1.5991977784634374e-05,
      "loss": 0.0,
      "step": 110220
    },
    {
      "epoch": 34.01110768281394,
      "grad_norm": 8.814011380309239e-06,
      "learning_rate": 1.5988892317186056e-05,
      "loss": 0.0,
      "step": 110230
    },
    {
      "epoch": 34.014193150262265,
      "grad_norm": 5.089833939564414e-05,
      "learning_rate": 1.5985806849737735e-05,
      "loss": 0.0,
      "step": 110240
    },
    {
      "epoch": 34.01727861771058,
      "grad_norm": 0.0006589916301891208,
      "learning_rate": 1.5982721382289418e-05,
      "loss": 0.0001,
      "step": 110250
    },
    {
      "epoch": 34.0203640851589,
      "grad_norm": 1.7802533420763211e-06,
      "learning_rate": 1.5979635914841097e-05,
      "loss": 0.0,
      "step": 110260
    },
    {
      "epoch": 34.02344955260722,
      "grad_norm": 9.216679609380662e-05,
      "learning_rate": 1.597655044739278e-05,
      "loss": 0.0084,
      "step": 110270
    },
    {
      "epoch": 34.02653502005554,
      "grad_norm": 0.13941973447799683,
      "learning_rate": 1.5973464979944465e-05,
      "loss": 0.0001,
      "step": 110280
    },
    {
      "epoch": 34.029620487503855,
      "grad_norm": 1.6828656725920155e-06,
      "learning_rate": 1.5970379512496144e-05,
      "loss": 0.0,
      "step": 110290
    },
    {
      "epoch": 34.03270595495218,
      "grad_norm": 4.6183827180357184e-06,
      "learning_rate": 1.5967294045047827e-05,
      "loss": 0.0,
      "step": 110300
    },
    {
      "epoch": 34.03579142240049,
      "grad_norm": 0.5597180128097534,
      "learning_rate": 1.5964208577599506e-05,
      "loss": 0.0002,
      "step": 110310
    },
    {
      "epoch": 34.038876889848815,
      "grad_norm": 0.000521646870765835,
      "learning_rate": 1.596112311015119e-05,
      "loss": 0.0,
      "step": 110320
    },
    {
      "epoch": 34.04196235729713,
      "grad_norm": 0.00013830822717864066,
      "learning_rate": 1.595803764270287e-05,
      "loss": 0.0,
      "step": 110330
    },
    {
      "epoch": 34.045047824745446,
      "grad_norm": 0.0035427433904260397,
      "learning_rate": 1.595495217525455e-05,
      "loss": 0.0,
      "step": 110340
    },
    {
      "epoch": 34.04813329219377,
      "grad_norm": 3.110590114374645e-05,
      "learning_rate": 1.5951866707806236e-05,
      "loss": 0.0004,
      "step": 110350
    },
    {
      "epoch": 34.05121875964208,
      "grad_norm": 1.1934001804547734e-06,
      "learning_rate": 1.5948781240357915e-05,
      "loss": 0.0,
      "step": 110360
    },
    {
      "epoch": 34.054304227090405,
      "grad_norm": 0.0002091571077471599,
      "learning_rate": 1.5945695772909597e-05,
      "loss": 0.0001,
      "step": 110370
    },
    {
      "epoch": 34.05738969453872,
      "grad_norm": 0.010044556111097336,
      "learning_rate": 1.5942610305461276e-05,
      "loss": 0.0,
      "step": 110380
    },
    {
      "epoch": 34.06047516198704,
      "grad_norm": 0.00022821093443781137,
      "learning_rate": 1.593952483801296e-05,
      "loss": 0.0001,
      "step": 110390
    },
    {
      "epoch": 34.06356062943536,
      "grad_norm": 4.984603378943575e-07,
      "learning_rate": 1.593643937056464e-05,
      "loss": 0.0001,
      "step": 110400
    },
    {
      "epoch": 34.06664609688368,
      "grad_norm": 4.228896841595997e-07,
      "learning_rate": 1.5933353903116324e-05,
      "loss": 0.0001,
      "step": 110410
    },
    {
      "epoch": 34.069731564331995,
      "grad_norm": 0.00048168739886023104,
      "learning_rate": 1.5930268435668006e-05,
      "loss": 0.0,
      "step": 110420
    },
    {
      "epoch": 34.07281703178032,
      "grad_norm": 1.0218228680969332e-06,
      "learning_rate": 1.5927182968219685e-05,
      "loss": 0.0,
      "step": 110430
    },
    {
      "epoch": 34.07590249922863,
      "grad_norm": 3.1767056043463526e-06,
      "learning_rate": 1.5924097500771368e-05,
      "loss": 0.0,
      "step": 110440
    },
    {
      "epoch": 34.078987966676955,
      "grad_norm": 5.842786413268186e-05,
      "learning_rate": 1.592101203332305e-05,
      "loss": 0.0001,
      "step": 110450
    },
    {
      "epoch": 34.08207343412527,
      "grad_norm": 1.0525734069233295e-05,
      "learning_rate": 1.591792656587473e-05,
      "loss": 0.0009,
      "step": 110460
    },
    {
      "epoch": 34.085158901573585,
      "grad_norm": 0.010636935941874981,
      "learning_rate": 1.5914841098426412e-05,
      "loss": 0.0,
      "step": 110470
    },
    {
      "epoch": 34.08824436902191,
      "grad_norm": 4.648325443267822,
      "learning_rate": 1.5911755630978094e-05,
      "loss": 0.009,
      "step": 110480
    },
    {
      "epoch": 34.09132983647022,
      "grad_norm": 0.0014884112169966102,
      "learning_rate": 1.5908670163529777e-05,
      "loss": 0.0,
      "step": 110490
    },
    {
      "epoch": 34.094415303918545,
      "grad_norm": 9.591655043550418e-07,
      "learning_rate": 1.5905584696081456e-05,
      "loss": 0.0,
      "step": 110500
    },
    {
      "epoch": 34.09750077136686,
      "grad_norm": 0.00019429448002483696,
      "learning_rate": 1.590249922863314e-05,
      "loss": 0.0,
      "step": 110510
    },
    {
      "epoch": 34.10058623881518,
      "grad_norm": 0.019397106021642685,
      "learning_rate": 1.589941376118482e-05,
      "loss": 0.0,
      "step": 110520
    },
    {
      "epoch": 34.1036717062635,
      "grad_norm": 8.995899406727403e-06,
      "learning_rate": 1.58963282937365e-05,
      "loss": 0.0017,
      "step": 110530
    },
    {
      "epoch": 34.10675717371182,
      "grad_norm": 4.9582187784835696e-05,
      "learning_rate": 1.5893242826288182e-05,
      "loss": 0.0,
      "step": 110540
    },
    {
      "epoch": 34.109842641160135,
      "grad_norm": 2.4083508833427913e-05,
      "learning_rate": 1.5890157358839865e-05,
      "loss": 0.0,
      "step": 110550
    },
    {
      "epoch": 34.11292810860846,
      "grad_norm": 0.007892786525189877,
      "learning_rate": 1.5887071891391547e-05,
      "loss": 0.0,
      "step": 110560
    },
    {
      "epoch": 34.11601357605677,
      "grad_norm": 2.3645529267923848e-07,
      "learning_rate": 1.588398642394323e-05,
      "loss": 0.0001,
      "step": 110570
    },
    {
      "epoch": 34.11909904350509,
      "grad_norm": 1.7715599536895752,
      "learning_rate": 1.588090095649491e-05,
      "loss": 0.0009,
      "step": 110580
    },
    {
      "epoch": 34.12218451095341,
      "grad_norm": 0.0001688034535618499,
      "learning_rate": 1.587781548904659e-05,
      "loss": 0.0,
      "step": 110590
    },
    {
      "epoch": 34.125269978401725,
      "grad_norm": 0.011361942626535892,
      "learning_rate": 1.587473002159827e-05,
      "loss": 0.0,
      "step": 110600
    },
    {
      "epoch": 34.12835544585005,
      "grad_norm": 3.0529547530022683e-06,
      "learning_rate": 1.5871644554149953e-05,
      "loss": 0.0,
      "step": 110610
    },
    {
      "epoch": 34.13144091329836,
      "grad_norm": 0.004578304477035999,
      "learning_rate": 1.5868559086701636e-05,
      "loss": 0.0005,
      "step": 110620
    },
    {
      "epoch": 34.134526380746685,
      "grad_norm": 0.00014443558757193387,
      "learning_rate": 1.5865473619253318e-05,
      "loss": 0.0,
      "step": 110630
    },
    {
      "epoch": 34.137611848195,
      "grad_norm": 8.535836968803778e-06,
      "learning_rate": 1.5862388151805e-05,
      "loss": 0.0,
      "step": 110640
    },
    {
      "epoch": 34.14069731564332,
      "grad_norm": 4.051576615893282e-05,
      "learning_rate": 1.585930268435668e-05,
      "loss": 0.0032,
      "step": 110650
    },
    {
      "epoch": 34.14378278309164,
      "grad_norm": 1.1940218200834352e-06,
      "learning_rate": 1.5856217216908362e-05,
      "loss": 0.0,
      "step": 110660
    },
    {
      "epoch": 34.14686825053996,
      "grad_norm": 1.059404621628346e-05,
      "learning_rate": 1.5853131749460045e-05,
      "loss": 0.0,
      "step": 110670
    },
    {
      "epoch": 34.149953717988275,
      "grad_norm": 0.0015801511472091079,
      "learning_rate": 1.5850046282011727e-05,
      "loss": 0.0,
      "step": 110680
    },
    {
      "epoch": 34.15303918543659,
      "grad_norm": 0.011123166419565678,
      "learning_rate": 1.584696081456341e-05,
      "loss": 0.0002,
      "step": 110690
    },
    {
      "epoch": 34.15612465288491,
      "grad_norm": 3.173316872562282e-05,
      "learning_rate": 1.584387534711509e-05,
      "loss": 0.0,
      "step": 110700
    },
    {
      "epoch": 34.15921012033323,
      "grad_norm": 6.831952487118542e-05,
      "learning_rate": 1.584078987966677e-05,
      "loss": 0.0,
      "step": 110710
    },
    {
      "epoch": 34.16229558778155,
      "grad_norm": 7.006281634858169e-07,
      "learning_rate": 1.583770441221845e-05,
      "loss": 0.0,
      "step": 110720
    },
    {
      "epoch": 34.165381055229865,
      "grad_norm": 0.00290766847319901,
      "learning_rate": 1.5834618944770133e-05,
      "loss": 0.0001,
      "step": 110730
    },
    {
      "epoch": 34.16846652267819,
      "grad_norm": 1.0159045814361889e-05,
      "learning_rate": 1.5831533477321815e-05,
      "loss": 0.0,
      "step": 110740
    },
    {
      "epoch": 34.1715519901265,
      "grad_norm": 0.0001614905777387321,
      "learning_rate": 1.5828448009873498e-05,
      "loss": 0.0,
      "step": 110750
    },
    {
      "epoch": 34.174637457574825,
      "grad_norm": 1.651851988526687e-07,
      "learning_rate": 1.582536254242518e-05,
      "loss": 0.0,
      "step": 110760
    },
    {
      "epoch": 34.17772292502314,
      "grad_norm": 5.186998350836802e-06,
      "learning_rate": 1.582227707497686e-05,
      "loss": 0.0,
      "step": 110770
    },
    {
      "epoch": 34.18080839247146,
      "grad_norm": 1.571138454892207e-05,
      "learning_rate": 1.581919160752854e-05,
      "loss": 0.0002,
      "step": 110780
    },
    {
      "epoch": 34.18389385991978,
      "grad_norm": 6.806417331972625e-06,
      "learning_rate": 1.5816106140080224e-05,
      "loss": 0.005,
      "step": 110790
    },
    {
      "epoch": 34.1869793273681,
      "grad_norm": 2.671677827835083,
      "learning_rate": 1.5813020672631903e-05,
      "loss": 0.001,
      "step": 110800
    },
    {
      "epoch": 34.190064794816415,
      "grad_norm": 1.5207565411401447e-06,
      "learning_rate": 1.5809935205183586e-05,
      "loss": 0.0,
      "step": 110810
    },
    {
      "epoch": 34.19315026226473,
      "grad_norm": 5.558880275202682e-06,
      "learning_rate": 1.5806849737735268e-05,
      "loss": 0.0,
      "step": 110820
    },
    {
      "epoch": 34.19623572971305,
      "grad_norm": 4.713262171662791e-07,
      "learning_rate": 1.580376427028695e-05,
      "loss": 0.0,
      "step": 110830
    },
    {
      "epoch": 34.19932119716137,
      "grad_norm": 0.10009688138961792,
      "learning_rate": 1.580067880283863e-05,
      "loss": 0.0001,
      "step": 110840
    },
    {
      "epoch": 34.20240666460969,
      "grad_norm": 3.9598649891559035e-05,
      "learning_rate": 1.5797593335390312e-05,
      "loss": 0.0,
      "step": 110850
    },
    {
      "epoch": 34.205492132058005,
      "grad_norm": 8.138596604112536e-05,
      "learning_rate": 1.5794507867941995e-05,
      "loss": 0.0001,
      "step": 110860
    },
    {
      "epoch": 34.20857759950633,
      "grad_norm": 0.004844806157052517,
      "learning_rate": 1.5791422400493674e-05,
      "loss": 0.0007,
      "step": 110870
    },
    {
      "epoch": 34.21166306695464,
      "grad_norm": 8.230144158005714e-05,
      "learning_rate": 1.578833693304536e-05,
      "loss": 0.0016,
      "step": 110880
    },
    {
      "epoch": 34.214748534402965,
      "grad_norm": 0.0010405690409243107,
      "learning_rate": 1.578525146559704e-05,
      "loss": 0.0,
      "step": 110890
    },
    {
      "epoch": 34.21783400185128,
      "grad_norm": 0.002514147898182273,
      "learning_rate": 1.578216599814872e-05,
      "loss": 0.0,
      "step": 110900
    },
    {
      "epoch": 34.2209194692996,
      "grad_norm": 0.15469907224178314,
      "learning_rate": 1.57790805307004e-05,
      "loss": 0.0001,
      "step": 110910
    },
    {
      "epoch": 34.22400493674792,
      "grad_norm": 0.001320047304034233,
      "learning_rate": 1.5775995063252083e-05,
      "loss": 0.0,
      "step": 110920
    },
    {
      "epoch": 34.22709040419623,
      "grad_norm": 0.00088664167560637,
      "learning_rate": 1.5772909595803765e-05,
      "loss": 0.0,
      "step": 110930
    },
    {
      "epoch": 34.230175871644555,
      "grad_norm": 4.628260739991674e-06,
      "learning_rate": 1.5769824128355444e-05,
      "loss": 0.0,
      "step": 110940
    },
    {
      "epoch": 34.23326133909287,
      "grad_norm": 2.782035934956184e-08,
      "learning_rate": 1.576673866090713e-05,
      "loss": 0.0,
      "step": 110950
    },
    {
      "epoch": 34.23634680654119,
      "grad_norm": 0.000189093392691575,
      "learning_rate": 1.576365319345881e-05,
      "loss": 0.0002,
      "step": 110960
    },
    {
      "epoch": 34.23943227398951,
      "grad_norm": 0.00028504320653155446,
      "learning_rate": 1.5760567726010492e-05,
      "loss": 0.0,
      "step": 110970
    },
    {
      "epoch": 34.24251774143783,
      "grad_norm": 4.541324138641357,
      "learning_rate": 1.5757482258562174e-05,
      "loss": 0.0087,
      "step": 110980
    },
    {
      "epoch": 34.245603208886145,
      "grad_norm": 0.0003226649423595518,
      "learning_rate": 1.5754396791113853e-05,
      "loss": 0.0003,
      "step": 110990
    },
    {
      "epoch": 34.24868867633447,
      "grad_norm": 2.8564903914229944e-05,
      "learning_rate": 1.5751311323665536e-05,
      "loss": 0.0003,
      "step": 111000
    },
    {
      "epoch": 34.25177414378278,
      "grad_norm": 0.020110350102186203,
      "learning_rate": 1.5748225856217215e-05,
      "loss": 0.0001,
      "step": 111010
    },
    {
      "epoch": 34.254859611231105,
      "grad_norm": 1.3930023214925313e-06,
      "learning_rate": 1.57451403887689e-05,
      "loss": 0.0,
      "step": 111020
    },
    {
      "epoch": 34.25794507867942,
      "grad_norm": 3.1728554859000724e-06,
      "learning_rate": 1.574205492132058e-05,
      "loss": 0.0001,
      "step": 111030
    },
    {
      "epoch": 34.261030546127735,
      "grad_norm": 2.2563111782073975,
      "learning_rate": 1.5738969453872262e-05,
      "loss": 0.0031,
      "step": 111040
    },
    {
      "epoch": 34.26411601357606,
      "grad_norm": 0.0008206142229028046,
      "learning_rate": 1.5735883986423945e-05,
      "loss": 0.0,
      "step": 111050
    },
    {
      "epoch": 34.26720148102437,
      "grad_norm": 0.0013698849361389875,
      "learning_rate": 1.5732798518975624e-05,
      "loss": 0.0001,
      "step": 111060
    },
    {
      "epoch": 34.270286948472695,
      "grad_norm": 1.2498367141233757e-06,
      "learning_rate": 1.5729713051527306e-05,
      "loss": 0.0011,
      "step": 111070
    },
    {
      "epoch": 34.27337241592101,
      "grad_norm": 0.0020781673956662416,
      "learning_rate": 1.572662758407899e-05,
      "loss": 0.0,
      "step": 111080
    },
    {
      "epoch": 34.27645788336933,
      "grad_norm": 8.362215453416866e-07,
      "learning_rate": 1.572354211663067e-05,
      "loss": 0.0,
      "step": 111090
    },
    {
      "epoch": 34.27954335081765,
      "grad_norm": 2.637031502672471e-05,
      "learning_rate": 1.5720456649182354e-05,
      "loss": 0.0071,
      "step": 111100
    },
    {
      "epoch": 34.28262881826597,
      "grad_norm": 0.020871203392744064,
      "learning_rate": 1.5717371181734033e-05,
      "loss": 0.0,
      "step": 111110
    },
    {
      "epoch": 34.285714285714285,
      "grad_norm": 4.93762513542606e-07,
      "learning_rate": 1.5714285714285715e-05,
      "loss": 0.0,
      "step": 111120
    },
    {
      "epoch": 34.28879975316261,
      "grad_norm": 1.0112563359143678e-05,
      "learning_rate": 1.5711200246837394e-05,
      "loss": 0.001,
      "step": 111130
    },
    {
      "epoch": 34.29188522061092,
      "grad_norm": 0.002525974065065384,
      "learning_rate": 1.5708114779389077e-05,
      "loss": 0.0003,
      "step": 111140
    },
    {
      "epoch": 34.294970688059244,
      "grad_norm": 0.042452938854694366,
      "learning_rate": 1.570502931194076e-05,
      "loss": 0.0065,
      "step": 111150
    },
    {
      "epoch": 34.29805615550756,
      "grad_norm": 0.000610118149779737,
      "learning_rate": 1.5701943844492442e-05,
      "loss": 0.0021,
      "step": 111160
    },
    {
      "epoch": 34.301141622955875,
      "grad_norm": 1.123998845287133e-05,
      "learning_rate": 1.5698858377044124e-05,
      "loss": 0.0019,
      "step": 111170
    },
    {
      "epoch": 34.3042270904042,
      "grad_norm": 1.1941455341002438e-05,
      "learning_rate": 1.5695772909595803e-05,
      "loss": 0.0,
      "step": 111180
    },
    {
      "epoch": 34.30731255785251,
      "grad_norm": 3.961452603107318e-05,
      "learning_rate": 1.5692687442147486e-05,
      "loss": 0.0,
      "step": 111190
    },
    {
      "epoch": 34.310398025300834,
      "grad_norm": 1.6384927192802934e-08,
      "learning_rate": 1.568960197469917e-05,
      "loss": 0.0006,
      "step": 111200
    },
    {
      "epoch": 34.31348349274915,
      "grad_norm": 0.000662356149405241,
      "learning_rate": 1.5686516507250847e-05,
      "loss": 0.0002,
      "step": 111210
    },
    {
      "epoch": 34.31656896019747,
      "grad_norm": 2.030694986387971e-06,
      "learning_rate": 1.5683431039802533e-05,
      "loss": 0.0,
      "step": 111220
    },
    {
      "epoch": 34.31965442764579,
      "grad_norm": 0.0002366342960158363,
      "learning_rate": 1.5680345572354212e-05,
      "loss": 0.0,
      "step": 111230
    },
    {
      "epoch": 34.32273989509411,
      "grad_norm": 1.2489972505136393e-06,
      "learning_rate": 1.5677260104905895e-05,
      "loss": 0.0,
      "step": 111240
    },
    {
      "epoch": 34.325825362542425,
      "grad_norm": 0.0011354396119713783,
      "learning_rate": 1.5674174637457574e-05,
      "loss": 0.0,
      "step": 111250
    },
    {
      "epoch": 34.32891082999075,
      "grad_norm": 4.90099353100959e-07,
      "learning_rate": 1.5671089170009256e-05,
      "loss": 0.0007,
      "step": 111260
    },
    {
      "epoch": 34.33199629743906,
      "grad_norm": 0.000280504347756505,
      "learning_rate": 1.566800370256094e-05,
      "loss": 0.0,
      "step": 111270
    },
    {
      "epoch": 34.33508176488738,
      "grad_norm": 0.9745780825614929,
      "learning_rate": 1.566491823511262e-05,
      "loss": 0.0011,
      "step": 111280
    },
    {
      "epoch": 34.3381672323357,
      "grad_norm": 0.00011347344843670726,
      "learning_rate": 1.5661832767664304e-05,
      "loss": 0.0001,
      "step": 111290
    },
    {
      "epoch": 34.341252699784015,
      "grad_norm": 0.06552395969629288,
      "learning_rate": 1.5658747300215983e-05,
      "loss": 0.0,
      "step": 111300
    },
    {
      "epoch": 34.34433816723234,
      "grad_norm": 7.88742327131331e-05,
      "learning_rate": 1.5655661832767665e-05,
      "loss": 0.0,
      "step": 111310
    },
    {
      "epoch": 34.34742363468065,
      "grad_norm": 1.908965487018577e-06,
      "learning_rate": 1.5652576365319348e-05,
      "loss": 0.0,
      "step": 111320
    },
    {
      "epoch": 34.350509102128974,
      "grad_norm": 5.0065299461721224e-08,
      "learning_rate": 1.5649490897871027e-05,
      "loss": 0.0003,
      "step": 111330
    },
    {
      "epoch": 34.35359456957729,
      "grad_norm": 0.00394988851621747,
      "learning_rate": 1.564640543042271e-05,
      "loss": 0.0,
      "step": 111340
    },
    {
      "epoch": 34.35668003702561,
      "grad_norm": 0.010431893169879913,
      "learning_rate": 1.5643319962974392e-05,
      "loss": 0.0,
      "step": 111350
    },
    {
      "epoch": 34.35976550447393,
      "grad_norm": 7.236826058942825e-05,
      "learning_rate": 1.5640234495526074e-05,
      "loss": 0.0,
      "step": 111360
    },
    {
      "epoch": 34.36285097192225,
      "grad_norm": 0.001756306504830718,
      "learning_rate": 1.5637149028077754e-05,
      "loss": 0.0,
      "step": 111370
    },
    {
      "epoch": 34.365936439370564,
      "grad_norm": 0.0001261508878087625,
      "learning_rate": 1.5634063560629436e-05,
      "loss": 0.0002,
      "step": 111380
    },
    {
      "epoch": 34.36902190681888,
      "grad_norm": 2.5839376576186623e-06,
      "learning_rate": 1.563097809318112e-05,
      "loss": 0.0033,
      "step": 111390
    },
    {
      "epoch": 34.3721073742672,
      "grad_norm": 0.0003008868370670825,
      "learning_rate": 1.5627892625732798e-05,
      "loss": 0.0,
      "step": 111400
    },
    {
      "epoch": 34.37519284171552,
      "grad_norm": 0.0028653270564973354,
      "learning_rate": 1.562480715828448e-05,
      "loss": 0.0,
      "step": 111410
    },
    {
      "epoch": 34.37827830916384,
      "grad_norm": 1.4193574315868318e-06,
      "learning_rate": 1.5621721690836163e-05,
      "loss": 0.0,
      "step": 111420
    },
    {
      "epoch": 34.381363776612154,
      "grad_norm": 8.522772986907512e-06,
      "learning_rate": 1.5618636223387845e-05,
      "loss": 0.0001,
      "step": 111430
    },
    {
      "epoch": 34.38444924406048,
      "grad_norm": 3.430297510931268e-05,
      "learning_rate": 1.5615550755939527e-05,
      "loss": 0.0,
      "step": 111440
    },
    {
      "epoch": 34.38753471150879,
      "grad_norm": 5.291823254083283e-05,
      "learning_rate": 1.5612465288491207e-05,
      "loss": 0.0,
      "step": 111450
    },
    {
      "epoch": 34.390620178957114,
      "grad_norm": 1.0080400443257531e-06,
      "learning_rate": 1.560937982104289e-05,
      "loss": 0.0,
      "step": 111460
    },
    {
      "epoch": 34.39370564640543,
      "grad_norm": 1.7093433370973798e-06,
      "learning_rate": 1.5606294353594568e-05,
      "loss": 0.0,
      "step": 111470
    },
    {
      "epoch": 34.39679111385375,
      "grad_norm": 0.00022360360890161246,
      "learning_rate": 1.560320888614625e-05,
      "loss": 0.0,
      "step": 111480
    },
    {
      "epoch": 34.39987658130207,
      "grad_norm": 3.92229703720659e-05,
      "learning_rate": 1.5600123418697933e-05,
      "loss": 0.0,
      "step": 111490
    },
    {
      "epoch": 34.40296204875039,
      "grad_norm": 1.2178582586841458e-08,
      "learning_rate": 1.5597037951249616e-05,
      "loss": 0.0,
      "step": 111500
    },
    {
      "epoch": 34.406047516198704,
      "grad_norm": 7.025228114798665e-07,
      "learning_rate": 1.5593952483801298e-05,
      "loss": 0.0,
      "step": 111510
    },
    {
      "epoch": 34.40913298364702,
      "grad_norm": 2.8463331545935944e-05,
      "learning_rate": 1.5590867016352977e-05,
      "loss": 0.0,
      "step": 111520
    },
    {
      "epoch": 34.41221845109534,
      "grad_norm": 6.604879308724776e-05,
      "learning_rate": 1.558778154890466e-05,
      "loss": 0.0,
      "step": 111530
    },
    {
      "epoch": 34.41530391854366,
      "grad_norm": 0.0009249615832231939,
      "learning_rate": 1.558469608145634e-05,
      "loss": 0.0,
      "step": 111540
    },
    {
      "epoch": 34.41838938599198,
      "grad_norm": 9.936494507201132e-07,
      "learning_rate": 1.5581610614008025e-05,
      "loss": 0.0017,
      "step": 111550
    },
    {
      "epoch": 34.421474853440294,
      "grad_norm": 1.0206203114648815e-05,
      "learning_rate": 1.5578525146559707e-05,
      "loss": 0.0,
      "step": 111560
    },
    {
      "epoch": 34.42456032088862,
      "grad_norm": 0.00015366767183877528,
      "learning_rate": 1.5575439679111386e-05,
      "loss": 0.0,
      "step": 111570
    },
    {
      "epoch": 34.42764578833693,
      "grad_norm": 4.312822511565173e-06,
      "learning_rate": 1.557235421166307e-05,
      "loss": 0.0,
      "step": 111580
    },
    {
      "epoch": 34.430731255785254,
      "grad_norm": 2.1087971617816947e-06,
      "learning_rate": 1.5569268744214748e-05,
      "loss": 0.0007,
      "step": 111590
    },
    {
      "epoch": 34.43381672323357,
      "grad_norm": 0.0001691975339781493,
      "learning_rate": 1.556618327676643e-05,
      "loss": 0.0001,
      "step": 111600
    },
    {
      "epoch": 34.43690219068189,
      "grad_norm": 0.00011313302093185484,
      "learning_rate": 1.5563097809318113e-05,
      "loss": 0.0001,
      "step": 111610
    },
    {
      "epoch": 34.43998765813021,
      "grad_norm": 0.0029381513595581055,
      "learning_rate": 1.5560012341869795e-05,
      "loss": 0.0002,
      "step": 111620
    },
    {
      "epoch": 34.44307312557852,
      "grad_norm": 4.644881119020283e-05,
      "learning_rate": 1.5556926874421478e-05,
      "loss": 0.0003,
      "step": 111630
    },
    {
      "epoch": 34.446158593026844,
      "grad_norm": 0.0004794617125298828,
      "learning_rate": 1.5553841406973157e-05,
      "loss": 0.0,
      "step": 111640
    },
    {
      "epoch": 34.44924406047516,
      "grad_norm": 1.8553450900071766e-06,
      "learning_rate": 1.555075593952484e-05,
      "loss": 0.0,
      "step": 111650
    },
    {
      "epoch": 34.45232952792348,
      "grad_norm": 2.2929614260647213e-06,
      "learning_rate": 1.5547670472076518e-05,
      "loss": 0.0,
      "step": 111660
    },
    {
      "epoch": 34.4554149953718,
      "grad_norm": 1.3438773748930544e-05,
      "learning_rate": 1.55445850046282e-05,
      "loss": 0.0,
      "step": 111670
    },
    {
      "epoch": 34.45850046282012,
      "grad_norm": 0.007983634248375893,
      "learning_rate": 1.5541499537179883e-05,
      "loss": 0.0001,
      "step": 111680
    },
    {
      "epoch": 34.461585930268434,
      "grad_norm": 1.0597326763672754e-05,
      "learning_rate": 1.5538414069731566e-05,
      "loss": 0.0001,
      "step": 111690
    },
    {
      "epoch": 34.46467139771676,
      "grad_norm": 0.0028143380768597126,
      "learning_rate": 1.5535328602283248e-05,
      "loss": 0.0,
      "step": 111700
    },
    {
      "epoch": 34.46775686516507,
      "grad_norm": 0.00040673636249266565,
      "learning_rate": 1.5532243134834927e-05,
      "loss": 0.0,
      "step": 111710
    },
    {
      "epoch": 34.470842332613394,
      "grad_norm": 5.124762083141832e-06,
      "learning_rate": 1.552915766738661e-05,
      "loss": 0.0,
      "step": 111720
    },
    {
      "epoch": 34.47392780006171,
      "grad_norm": 6.372145833211107e-08,
      "learning_rate": 1.5526072199938292e-05,
      "loss": 0.0,
      "step": 111730
    },
    {
      "epoch": 34.477013267510024,
      "grad_norm": 3.331664629513398e-05,
      "learning_rate": 1.552298673248997e-05,
      "loss": 0.0,
      "step": 111740
    },
    {
      "epoch": 34.48009873495835,
      "grad_norm": 2.228134690085426e-07,
      "learning_rate": 1.5519901265041657e-05,
      "loss": 0.0,
      "step": 111750
    },
    {
      "epoch": 34.48318420240666,
      "grad_norm": 6.914159911275419e-08,
      "learning_rate": 1.5516815797593336e-05,
      "loss": 0.0,
      "step": 111760
    },
    {
      "epoch": 34.486269669854984,
      "grad_norm": 4.558595537673682e-05,
      "learning_rate": 1.551373033014502e-05,
      "loss": 0.0,
      "step": 111770
    },
    {
      "epoch": 34.4893551373033,
      "grad_norm": 0.007617861032485962,
      "learning_rate": 1.5510644862696698e-05,
      "loss": 0.0,
      "step": 111780
    },
    {
      "epoch": 34.49244060475162,
      "grad_norm": 8.931084448704496e-05,
      "learning_rate": 1.550755939524838e-05,
      "loss": 0.0,
      "step": 111790
    },
    {
      "epoch": 34.49552607219994,
      "grad_norm": 0.00036827876465395093,
      "learning_rate": 1.5504473927800063e-05,
      "loss": 0.0005,
      "step": 111800
    },
    {
      "epoch": 34.49861153964826,
      "grad_norm": 0.0005170392105355859,
      "learning_rate": 1.5501388460351742e-05,
      "loss": 0.0,
      "step": 111810
    },
    {
      "epoch": 34.501697007096574,
      "grad_norm": 2.408996988378931e-05,
      "learning_rate": 1.5498302992903428e-05,
      "loss": 0.0,
      "step": 111820
    },
    {
      "epoch": 34.504782474544896,
      "grad_norm": 2.056870835076552e-05,
      "learning_rate": 1.5495217525455107e-05,
      "loss": 0.0,
      "step": 111830
    },
    {
      "epoch": 34.50786794199321,
      "grad_norm": 0.03144800662994385,
      "learning_rate": 1.549213205800679e-05,
      "loss": 0.0,
      "step": 111840
    },
    {
      "epoch": 34.510953409441534,
      "grad_norm": 0.011763432994484901,
      "learning_rate": 1.5489046590558472e-05,
      "loss": 0.0005,
      "step": 111850
    },
    {
      "epoch": 34.51403887688985,
      "grad_norm": 6.605988164665177e-05,
      "learning_rate": 1.548596112311015e-05,
      "loss": 0.0005,
      "step": 111860
    },
    {
      "epoch": 34.517124344338164,
      "grad_norm": 5.58552642360155e-07,
      "learning_rate": 1.5482875655661833e-05,
      "loss": 0.0,
      "step": 111870
    },
    {
      "epoch": 34.520209811786486,
      "grad_norm": 0.028491029515862465,
      "learning_rate": 1.5479790188213512e-05,
      "loss": 0.0,
      "step": 111880
    },
    {
      "epoch": 34.5232952792348,
      "grad_norm": 7.440721219609259e-06,
      "learning_rate": 1.5476704720765198e-05,
      "loss": 0.0,
      "step": 111890
    },
    {
      "epoch": 34.526380746683124,
      "grad_norm": 0.0006482079043053091,
      "learning_rate": 1.5473619253316877e-05,
      "loss": 0.0016,
      "step": 111900
    },
    {
      "epoch": 34.52946621413144,
      "grad_norm": 0.00018952203390654176,
      "learning_rate": 1.547053378586856e-05,
      "loss": 0.0,
      "step": 111910
    },
    {
      "epoch": 34.53255168157976,
      "grad_norm": 6.822085197200067e-06,
      "learning_rate": 1.5467448318420242e-05,
      "loss": 0.0,
      "step": 111920
    },
    {
      "epoch": 34.53563714902808,
      "grad_norm": 8.951711606641766e-06,
      "learning_rate": 1.546436285097192e-05,
      "loss": 0.0,
      "step": 111930
    },
    {
      "epoch": 34.5387226164764,
      "grad_norm": 0.0001246966712642461,
      "learning_rate": 1.5461277383523604e-05,
      "loss": 0.0002,
      "step": 111940
    },
    {
      "epoch": 34.541808083924714,
      "grad_norm": 0.009281313978135586,
      "learning_rate": 1.5458191916075286e-05,
      "loss": 0.0,
      "step": 111950
    },
    {
      "epoch": 34.544893551373036,
      "grad_norm": 2.060487747192383,
      "learning_rate": 1.545510644862697e-05,
      "loss": 0.0037,
      "step": 111960
    },
    {
      "epoch": 34.54797901882135,
      "grad_norm": 0.02553519234061241,
      "learning_rate": 1.545202098117865e-05,
      "loss": 0.0,
      "step": 111970
    },
    {
      "epoch": 34.55106448626967,
      "grad_norm": 3.6716978684125934e-06,
      "learning_rate": 1.544893551373033e-05,
      "loss": 0.0,
      "step": 111980
    },
    {
      "epoch": 34.55414995371799,
      "grad_norm": 0.0012431190116330981,
      "learning_rate": 1.5445850046282013e-05,
      "loss": 0.0,
      "step": 111990
    },
    {
      "epoch": 34.557235421166304,
      "grad_norm": 1.7346388631267473e-05,
      "learning_rate": 1.5442764578833692e-05,
      "loss": 0.0,
      "step": 112000
    },
    {
      "epoch": 34.560320888614626,
      "grad_norm": 3.163380370097002e-06,
      "learning_rate": 1.5439679111385374e-05,
      "loss": 0.0,
      "step": 112010
    },
    {
      "epoch": 34.56340635606294,
      "grad_norm": 6.58023709547706e-05,
      "learning_rate": 1.5436593643937057e-05,
      "loss": 0.0027,
      "step": 112020
    },
    {
      "epoch": 34.566491823511264,
      "grad_norm": 4.485871613724157e-06,
      "learning_rate": 1.543350817648874e-05,
      "loss": 0.0,
      "step": 112030
    },
    {
      "epoch": 34.56957729095958,
      "grad_norm": 5.606817012449028e-06,
      "learning_rate": 1.5430422709040422e-05,
      "loss": 0.0008,
      "step": 112040
    },
    {
      "epoch": 34.5726627584079,
      "grad_norm": 1.453438017051667e-06,
      "learning_rate": 1.54273372415921e-05,
      "loss": 0.0009,
      "step": 112050
    },
    {
      "epoch": 34.575748225856216,
      "grad_norm": 1.2045555195072666e-05,
      "learning_rate": 1.5424251774143783e-05,
      "loss": 0.0,
      "step": 112060
    },
    {
      "epoch": 34.57883369330454,
      "grad_norm": 1.3752505765296519e-05,
      "learning_rate": 1.5421166306695466e-05,
      "loss": 0.0,
      "step": 112070
    },
    {
      "epoch": 34.581919160752854,
      "grad_norm": 9.617334580980241e-05,
      "learning_rate": 1.5418080839247145e-05,
      "loss": 0.0,
      "step": 112080
    },
    {
      "epoch": 34.585004628201176,
      "grad_norm": 6.981685874052346e-05,
      "learning_rate": 1.541499537179883e-05,
      "loss": 0.0001,
      "step": 112090
    },
    {
      "epoch": 34.58809009564949,
      "grad_norm": 0.0009037451236508787,
      "learning_rate": 1.541190990435051e-05,
      "loss": 0.0001,
      "step": 112100
    },
    {
      "epoch": 34.591175563097806,
      "grad_norm": 0.1220448762178421,
      "learning_rate": 1.5408824436902192e-05,
      "loss": 0.0001,
      "step": 112110
    },
    {
      "epoch": 34.59426103054613,
      "grad_norm": 8.897139196051285e-05,
      "learning_rate": 1.540573896945387e-05,
      "loss": 0.0,
      "step": 112120
    },
    {
      "epoch": 34.597346497994444,
      "grad_norm": 0.00016312964726239443,
      "learning_rate": 1.5402653502005554e-05,
      "loss": 0.0,
      "step": 112130
    },
    {
      "epoch": 34.600431965442766,
      "grad_norm": 9.553612471790984e-05,
      "learning_rate": 1.5399568034557237e-05,
      "loss": 0.0,
      "step": 112140
    },
    {
      "epoch": 34.60351743289108,
      "grad_norm": 2.73560829100461e-07,
      "learning_rate": 1.539648256710892e-05,
      "loss": 0.0,
      "step": 112150
    },
    {
      "epoch": 34.606602900339404,
      "grad_norm": 2.3958028805282083e-07,
      "learning_rate": 1.53933970996606e-05,
      "loss": 0.0,
      "step": 112160
    },
    {
      "epoch": 34.60968836778772,
      "grad_norm": 0.01146184653043747,
      "learning_rate": 1.539031163221228e-05,
      "loss": 0.0001,
      "step": 112170
    },
    {
      "epoch": 34.61277383523604,
      "grad_norm": 2.2723885194864124e-05,
      "learning_rate": 1.5387226164763963e-05,
      "loss": 0.0,
      "step": 112180
    },
    {
      "epoch": 34.615859302684356,
      "grad_norm": 1.4258621376939118e-05,
      "learning_rate": 1.5384140697315642e-05,
      "loss": 0.0,
      "step": 112190
    },
    {
      "epoch": 34.61894477013268,
      "grad_norm": 9.38912489800714e-05,
      "learning_rate": 1.5381055229867325e-05,
      "loss": 0.0,
      "step": 112200
    },
    {
      "epoch": 34.622030237580994,
      "grad_norm": 0.0008619948639534414,
      "learning_rate": 1.5377969762419007e-05,
      "loss": 0.0,
      "step": 112210
    },
    {
      "epoch": 34.62511570502931,
      "grad_norm": 3.1334323011833476e-06,
      "learning_rate": 1.537488429497069e-05,
      "loss": 0.0,
      "step": 112220
    },
    {
      "epoch": 34.62820117247763,
      "grad_norm": 0.7632129192352295,
      "learning_rate": 1.5371798827522372e-05,
      "loss": 0.0002,
      "step": 112230
    },
    {
      "epoch": 34.631286639925946,
      "grad_norm": 2.736462789698635e-08,
      "learning_rate": 1.536871336007405e-05,
      "loss": 0.0016,
      "step": 112240
    },
    {
      "epoch": 34.63437210737427,
      "grad_norm": 2.1937585188425146e-06,
      "learning_rate": 1.5365627892625734e-05,
      "loss": 0.0,
      "step": 112250
    },
    {
      "epoch": 34.637457574822584,
      "grad_norm": 0.00011790867574745789,
      "learning_rate": 1.5362542425177416e-05,
      "loss": 0.0001,
      "step": 112260
    },
    {
      "epoch": 34.640543042270906,
      "grad_norm": 1.676700048847124e-05,
      "learning_rate": 1.5359456957729095e-05,
      "loss": 0.0,
      "step": 112270
    },
    {
      "epoch": 34.64362850971922,
      "grad_norm": 0.052341029047966,
      "learning_rate": 1.5356371490280778e-05,
      "loss": 0.0,
      "step": 112280
    },
    {
      "epoch": 34.64671397716754,
      "grad_norm": 8.063801942626014e-06,
      "learning_rate": 1.535328602283246e-05,
      "loss": 0.0,
      "step": 112290
    },
    {
      "epoch": 34.64979944461586,
      "grad_norm": 2.279495856782887e-05,
      "learning_rate": 1.5350200555384143e-05,
      "loss": 0.0,
      "step": 112300
    },
    {
      "epoch": 34.65288491206418,
      "grad_norm": 4.92071421831497e-06,
      "learning_rate": 1.534711508793582e-05,
      "loss": 0.0,
      "step": 112310
    },
    {
      "epoch": 34.655970379512496,
      "grad_norm": 4.059885395690799e-05,
      "learning_rate": 1.5344029620487504e-05,
      "loss": 0.0,
      "step": 112320
    },
    {
      "epoch": 34.65905584696081,
      "grad_norm": 9.701216185931116e-08,
      "learning_rate": 1.5340944153039187e-05,
      "loss": 0.0,
      "step": 112330
    },
    {
      "epoch": 34.66214131440913,
      "grad_norm": 8.045030881476123e-06,
      "learning_rate": 1.5337858685590866e-05,
      "loss": 0.0,
      "step": 112340
    },
    {
      "epoch": 34.66522678185745,
      "grad_norm": 3.583358250125457e-07,
      "learning_rate": 1.5334773218142548e-05,
      "loss": 0.0,
      "step": 112350
    },
    {
      "epoch": 34.66831224930577,
      "grad_norm": 0.0016883588396012783,
      "learning_rate": 1.533168775069423e-05,
      "loss": 0.0,
      "step": 112360
    },
    {
      "epoch": 34.671397716754086,
      "grad_norm": 3.209964415873401e-05,
      "learning_rate": 1.5328602283245913e-05,
      "loss": 0.0,
      "step": 112370
    },
    {
      "epoch": 34.67448318420241,
      "grad_norm": 8.055091029746109e-07,
      "learning_rate": 1.5325516815797596e-05,
      "loss": 0.0,
      "step": 112380
    },
    {
      "epoch": 34.67756865165072,
      "grad_norm": 0.01400650106370449,
      "learning_rate": 1.5322431348349275e-05,
      "loss": 0.0,
      "step": 112390
    },
    {
      "epoch": 34.680654119099046,
      "grad_norm": 8.733692880014132e-07,
      "learning_rate": 1.5319345880900957e-05,
      "loss": 0.0,
      "step": 112400
    },
    {
      "epoch": 34.68373958654736,
      "grad_norm": 2.4881317131075775e-06,
      "learning_rate": 1.5316260413452636e-05,
      "loss": 0.0,
      "step": 112410
    },
    {
      "epoch": 34.68682505399568,
      "grad_norm": 5.2779741963604465e-06,
      "learning_rate": 1.5313174946004322e-05,
      "loss": 0.0,
      "step": 112420
    },
    {
      "epoch": 34.689910521444,
      "grad_norm": 0.01911945827305317,
      "learning_rate": 1.5310089478556e-05,
      "loss": 0.0,
      "step": 112430
    },
    {
      "epoch": 34.69299598889232,
      "grad_norm": 5.578198852163041e-06,
      "learning_rate": 1.5307004011107684e-05,
      "loss": 0.0,
      "step": 112440
    },
    {
      "epoch": 34.696081456340636,
      "grad_norm": 2.1430348340345517e-07,
      "learning_rate": 1.5303918543659366e-05,
      "loss": 0.0,
      "step": 112450
    },
    {
      "epoch": 34.69916692378895,
      "grad_norm": 0.0023872985038906336,
      "learning_rate": 1.5300833076211045e-05,
      "loss": 0.0022,
      "step": 112460
    },
    {
      "epoch": 34.70225239123727,
      "grad_norm": 1.0761605153675191e-06,
      "learning_rate": 1.5297747608762728e-05,
      "loss": 0.0,
      "step": 112470
    },
    {
      "epoch": 34.70533785868559,
      "grad_norm": 0.00010930413554888219,
      "learning_rate": 1.529466214131441e-05,
      "loss": 0.0,
      "step": 112480
    },
    {
      "epoch": 34.70842332613391,
      "grad_norm": 2.7510843665368157e-06,
      "learning_rate": 1.5291576673866093e-05,
      "loss": 0.0,
      "step": 112490
    },
    {
      "epoch": 34.711508793582226,
      "grad_norm": 2.579533884272678e-06,
      "learning_rate": 1.5288491206417775e-05,
      "loss": 0.0,
      "step": 112500
    },
    {
      "epoch": 34.71459426103055,
      "grad_norm": 0.07282805442810059,
      "learning_rate": 1.5285405738969454e-05,
      "loss": 0.0,
      "step": 112510
    },
    {
      "epoch": 34.71767972847886,
      "grad_norm": 2.218429926870158e-06,
      "learning_rate": 1.5282320271521137e-05,
      "loss": 0.0001,
      "step": 112520
    },
    {
      "epoch": 34.720765195927186,
      "grad_norm": 0.001194175099954009,
      "learning_rate": 1.5279234804072816e-05,
      "loss": 0.0,
      "step": 112530
    },
    {
      "epoch": 34.7238506633755,
      "grad_norm": 5.26159851688135e-07,
      "learning_rate": 1.52761493366245e-05,
      "loss": 0.0,
      "step": 112540
    },
    {
      "epoch": 34.72693613082382,
      "grad_norm": 0.0010150098241865635,
      "learning_rate": 1.527306386917618e-05,
      "loss": 0.0005,
      "step": 112550
    },
    {
      "epoch": 34.73002159827214,
      "grad_norm": 6.6205689108755905e-06,
      "learning_rate": 1.5269978401727863e-05,
      "loss": 0.0018,
      "step": 112560
    },
    {
      "epoch": 34.73310706572045,
      "grad_norm": 0.0001603077253093943,
      "learning_rate": 1.5266892934279546e-05,
      "loss": 0.0,
      "step": 112570
    },
    {
      "epoch": 34.736192533168776,
      "grad_norm": 0.02556387521326542,
      "learning_rate": 1.5263807466831225e-05,
      "loss": 0.0,
      "step": 112580
    },
    {
      "epoch": 34.73927800061709,
      "grad_norm": 3.970691977883689e-06,
      "learning_rate": 1.5260721999382907e-05,
      "loss": 0.0,
      "step": 112590
    },
    {
      "epoch": 34.74236346806541,
      "grad_norm": 0.002029530005529523,
      "learning_rate": 1.5257636531934588e-05,
      "loss": 0.0002,
      "step": 112600
    },
    {
      "epoch": 34.74544893551373,
      "grad_norm": 0.001388123375363648,
      "learning_rate": 1.5254551064486269e-05,
      "loss": 0.0,
      "step": 112610
    },
    {
      "epoch": 34.74853440296205,
      "grad_norm": 1.4260722309700213e-06,
      "learning_rate": 1.5251465597037953e-05,
      "loss": 0.0,
      "step": 112620
    },
    {
      "epoch": 34.751619870410366,
      "grad_norm": 0.01979769393801689,
      "learning_rate": 1.5248380129589634e-05,
      "loss": 0.0007,
      "step": 112630
    },
    {
      "epoch": 34.75470533785869,
      "grad_norm": 0.00016491954738739878,
      "learning_rate": 1.5245294662141316e-05,
      "loss": 0.0,
      "step": 112640
    },
    {
      "epoch": 34.757790805307,
      "grad_norm": 0.003660121699795127,
      "learning_rate": 1.5242209194692997e-05,
      "loss": 0.0,
      "step": 112650
    },
    {
      "epoch": 34.760876272755326,
      "grad_norm": 9.047018829733133e-05,
      "learning_rate": 1.5239123727244678e-05,
      "loss": 0.0,
      "step": 112660
    },
    {
      "epoch": 34.76396174020364,
      "grad_norm": 0.00015856523532420397,
      "learning_rate": 1.5236038259796359e-05,
      "loss": 0.0,
      "step": 112670
    },
    {
      "epoch": 34.767047207651956,
      "grad_norm": 0.00046881730668246746,
      "learning_rate": 1.5232952792348041e-05,
      "loss": 0.0,
      "step": 112680
    },
    {
      "epoch": 34.77013267510028,
      "grad_norm": 0.00024367337755393237,
      "learning_rate": 1.5229867324899724e-05,
      "loss": 0.0,
      "step": 112690
    },
    {
      "epoch": 34.77321814254859,
      "grad_norm": 3.8382688671845244e-07,
      "learning_rate": 1.5226781857451406e-05,
      "loss": 0.0,
      "step": 112700
    },
    {
      "epoch": 34.776303609996916,
      "grad_norm": 0.00010749515058705583,
      "learning_rate": 1.5223696390003087e-05,
      "loss": 0.0,
      "step": 112710
    },
    {
      "epoch": 34.77938907744523,
      "grad_norm": 0.0015856169629842043,
      "learning_rate": 1.5220610922554768e-05,
      "loss": 0.0,
      "step": 112720
    },
    {
      "epoch": 34.78247454489355,
      "grad_norm": 5.3102365882296e-07,
      "learning_rate": 1.5217525455106448e-05,
      "loss": 0.0003,
      "step": 112730
    },
    {
      "epoch": 34.78556001234187,
      "grad_norm": 0.0015002248110249639,
      "learning_rate": 1.521443998765813e-05,
      "loss": 0.0,
      "step": 112740
    },
    {
      "epoch": 34.78864547979019,
      "grad_norm": 2.7985564884147607e-05,
      "learning_rate": 1.5211354520209812e-05,
      "loss": 0.0,
      "step": 112750
    },
    {
      "epoch": 34.791730947238506,
      "grad_norm": 8.334575977642089e-05,
      "learning_rate": 1.5208269052761496e-05,
      "loss": 0.0001,
      "step": 112760
    },
    {
      "epoch": 34.79481641468683,
      "grad_norm": 0.0001481411891290918,
      "learning_rate": 1.5205183585313177e-05,
      "loss": 0.0,
      "step": 112770
    },
    {
      "epoch": 34.79790188213514,
      "grad_norm": 2.8308439141255803e-05,
      "learning_rate": 1.5202098117864857e-05,
      "loss": 0.0,
      "step": 112780
    },
    {
      "epoch": 34.800987349583465,
      "grad_norm": 9.145257536147255e-06,
      "learning_rate": 1.5199012650416538e-05,
      "loss": 0.0002,
      "step": 112790
    },
    {
      "epoch": 34.80407281703178,
      "grad_norm": 2.52175436799007e-06,
      "learning_rate": 1.5195927182968219e-05,
      "loss": 0.0,
      "step": 112800
    },
    {
      "epoch": 34.807158284480096,
      "grad_norm": 0.0015899008139967918,
      "learning_rate": 1.5192841715519901e-05,
      "loss": 0.0,
      "step": 112810
    },
    {
      "epoch": 34.81024375192842,
      "grad_norm": 7.382888270512922e-06,
      "learning_rate": 1.5189756248071586e-05,
      "loss": 0.0,
      "step": 112820
    },
    {
      "epoch": 34.81332921937673,
      "grad_norm": 3.921159805031493e-05,
      "learning_rate": 1.5186670780623266e-05,
      "loss": 0.0,
      "step": 112830
    },
    {
      "epoch": 34.816414686825055,
      "grad_norm": 0.04757830500602722,
      "learning_rate": 1.5183585313174947e-05,
      "loss": 0.0001,
      "step": 112840
    },
    {
      "epoch": 34.81950015427337,
      "grad_norm": 0.0001528201246401295,
      "learning_rate": 1.5180499845726628e-05,
      "loss": 0.0,
      "step": 112850
    },
    {
      "epoch": 34.82258562172169,
      "grad_norm": 8.249125130532775e-06,
      "learning_rate": 1.5177414378278309e-05,
      "loss": 0.0,
      "step": 112860
    },
    {
      "epoch": 34.82567108917001,
      "grad_norm": 0.014277363196015358,
      "learning_rate": 1.5174328910829991e-05,
      "loss": 0.0,
      "step": 112870
    },
    {
      "epoch": 34.82875655661833,
      "grad_norm": 5.2632185543188825e-06,
      "learning_rate": 1.5171243443381672e-05,
      "loss": 0.0,
      "step": 112880
    },
    {
      "epoch": 34.831842024066646,
      "grad_norm": 0.005953083746135235,
      "learning_rate": 1.5168157975933356e-05,
      "loss": 0.0,
      "step": 112890
    },
    {
      "epoch": 34.83492749151497,
      "grad_norm": 0.00023936927027534693,
      "learning_rate": 1.5165072508485037e-05,
      "loss": 0.0,
      "step": 112900
    },
    {
      "epoch": 34.83801295896328,
      "grad_norm": 5.3238662076182663e-05,
      "learning_rate": 1.5161987041036718e-05,
      "loss": 0.0001,
      "step": 112910
    },
    {
      "epoch": 34.8410984264116,
      "grad_norm": 0.00011020294186891988,
      "learning_rate": 1.5158901573588399e-05,
      "loss": 0.0,
      "step": 112920
    },
    {
      "epoch": 34.84418389385992,
      "grad_norm": 0.00028048368403688073,
      "learning_rate": 1.5155816106140081e-05,
      "loss": 0.0004,
      "step": 112930
    },
    {
      "epoch": 34.847269361308236,
      "grad_norm": 3.7422714740387164e-06,
      "learning_rate": 1.5152730638691762e-05,
      "loss": 0.0,
      "step": 112940
    },
    {
      "epoch": 34.85035482875656,
      "grad_norm": 1.587543374625966e-05,
      "learning_rate": 1.5149645171243443e-05,
      "loss": 0.0001,
      "step": 112950
    },
    {
      "epoch": 34.85344029620487,
      "grad_norm": 2.424056447125622e-06,
      "learning_rate": 1.5146559703795127e-05,
      "loss": 0.0,
      "step": 112960
    },
    {
      "epoch": 34.856525763653195,
      "grad_norm": 2.4361206669709645e-06,
      "learning_rate": 1.5143474236346808e-05,
      "loss": 0.0002,
      "step": 112970
    },
    {
      "epoch": 34.85961123110151,
      "grad_norm": 1.3607623259304091e-06,
      "learning_rate": 1.5140388768898488e-05,
      "loss": 0.0,
      "step": 112980
    },
    {
      "epoch": 34.86269669854983,
      "grad_norm": 5.221640435593145e-07,
      "learning_rate": 1.513730330145017e-05,
      "loss": 0.0,
      "step": 112990
    },
    {
      "epoch": 34.86578216599815,
      "grad_norm": 2.0754096112796105e-06,
      "learning_rate": 1.5134217834001852e-05,
      "loss": 0.0,
      "step": 113000
    },
    {
      "epoch": 34.86886763344647,
      "grad_norm": 8.512425665685441e-06,
      "learning_rate": 1.5131132366553532e-05,
      "loss": 0.0,
      "step": 113010
    },
    {
      "epoch": 34.871953100894785,
      "grad_norm": 1.0175470244178086e-08,
      "learning_rate": 1.5128046899105213e-05,
      "loss": 0.0,
      "step": 113020
    },
    {
      "epoch": 34.8750385683431,
      "grad_norm": 2.734059989961679e-06,
      "learning_rate": 1.5124961431656897e-05,
      "loss": 0.0003,
      "step": 113030
    },
    {
      "epoch": 34.87812403579142,
      "grad_norm": 6.237583249912859e-08,
      "learning_rate": 1.5121875964208578e-05,
      "loss": 0.0,
      "step": 113040
    },
    {
      "epoch": 34.88120950323974,
      "grad_norm": 4.3818045014631934e-07,
      "learning_rate": 1.511879049676026e-05,
      "loss": 0.0,
      "step": 113050
    },
    {
      "epoch": 34.88429497068806,
      "grad_norm": 2.381417942842745e-07,
      "learning_rate": 1.5115705029311941e-05,
      "loss": 0.0,
      "step": 113060
    },
    {
      "epoch": 34.887380438136375,
      "grad_norm": 3.000867820901476e-08,
      "learning_rate": 1.5112619561863622e-05,
      "loss": 0.0,
      "step": 113070
    },
    {
      "epoch": 34.8904659055847,
      "grad_norm": 0.0003766481240745634,
      "learning_rate": 1.5109534094415303e-05,
      "loss": 0.0001,
      "step": 113080
    },
    {
      "epoch": 34.89355137303301,
      "grad_norm": 0.0006510429666377604,
      "learning_rate": 1.5106448626966987e-05,
      "loss": 0.0,
      "step": 113090
    },
    {
      "epoch": 34.896636840481335,
      "grad_norm": 4.99626480632287e-07,
      "learning_rate": 1.5103363159518668e-05,
      "loss": 0.0,
      "step": 113100
    },
    {
      "epoch": 34.89972230792965,
      "grad_norm": 4.406012885738164e-05,
      "learning_rate": 1.510027769207035e-05,
      "loss": 0.0,
      "step": 113110
    },
    {
      "epoch": 34.90280777537797,
      "grad_norm": 7.424711157000274e-07,
      "learning_rate": 1.5097192224622031e-05,
      "loss": 0.0,
      "step": 113120
    },
    {
      "epoch": 34.90589324282629,
      "grad_norm": 0.00010912734433077276,
      "learning_rate": 1.5094106757173712e-05,
      "loss": 0.0,
      "step": 113130
    },
    {
      "epoch": 34.90897871027461,
      "grad_norm": 1.804520252335351e-05,
      "learning_rate": 1.5091021289725393e-05,
      "loss": 0.0,
      "step": 113140
    },
    {
      "epoch": 34.912064177722925,
      "grad_norm": 0.0009714490151964128,
      "learning_rate": 1.5087935822277075e-05,
      "loss": 0.0,
      "step": 113150
    },
    {
      "epoch": 34.91514964517124,
      "grad_norm": 0.0006448430358432233,
      "learning_rate": 1.5084850354828758e-05,
      "loss": 0.0,
      "step": 113160
    },
    {
      "epoch": 34.91823511261956,
      "grad_norm": 2.44735542764829e-06,
      "learning_rate": 1.508176488738044e-05,
      "loss": 0.0,
      "step": 113170
    },
    {
      "epoch": 34.92132058006788,
      "grad_norm": 1.6191748954952345e-06,
      "learning_rate": 1.5078679419932121e-05,
      "loss": 0.0,
      "step": 113180
    },
    {
      "epoch": 34.9244060475162,
      "grad_norm": 1.7758856074578944e-06,
      "learning_rate": 1.5075593952483802e-05,
      "loss": 0.0,
      "step": 113190
    },
    {
      "epoch": 34.927491514964515,
      "grad_norm": 3.660934680738137e-06,
      "learning_rate": 1.5072508485035482e-05,
      "loss": 0.0001,
      "step": 113200
    },
    {
      "epoch": 34.93057698241284,
      "grad_norm": 1.86902445875603e-06,
      "learning_rate": 1.5069423017587165e-05,
      "loss": 0.0,
      "step": 113210
    },
    {
      "epoch": 34.93366244986115,
      "grad_norm": 4.666968379751779e-05,
      "learning_rate": 1.5066337550138846e-05,
      "loss": 0.0,
      "step": 113220
    },
    {
      "epoch": 34.936747917309475,
      "grad_norm": 2.1644025309797144e-06,
      "learning_rate": 1.506325208269053e-05,
      "loss": 0.0,
      "step": 113230
    },
    {
      "epoch": 34.93983338475779,
      "grad_norm": 3.9546410590673986e-08,
      "learning_rate": 1.506016661524221e-05,
      "loss": 0.0,
      "step": 113240
    },
    {
      "epoch": 34.94291885220611,
      "grad_norm": 0.002628564601764083,
      "learning_rate": 1.5057081147793891e-05,
      "loss": 0.0,
      "step": 113250
    },
    {
      "epoch": 34.94600431965443,
      "grad_norm": 3.7387169413705124e-06,
      "learning_rate": 1.5053995680345572e-05,
      "loss": 0.0031,
      "step": 113260
    },
    {
      "epoch": 34.94908978710274,
      "grad_norm": 4.185133548162412e-06,
      "learning_rate": 1.5050910212897255e-05,
      "loss": 0.0,
      "step": 113270
    },
    {
      "epoch": 34.952175254551065,
      "grad_norm": 6.60830153265124e-07,
      "learning_rate": 1.5047824745448936e-05,
      "loss": 0.0,
      "step": 113280
    },
    {
      "epoch": 34.95526072199938,
      "grad_norm": 1.1761644600483123e-06,
      "learning_rate": 1.504473927800062e-05,
      "loss": 0.0,
      "step": 113290
    },
    {
      "epoch": 34.9583461894477,
      "grad_norm": 0.016495320945978165,
      "learning_rate": 1.50416538105523e-05,
      "loss": 0.0,
      "step": 113300
    },
    {
      "epoch": 34.96143165689602,
      "grad_norm": 0.00011333188012940809,
      "learning_rate": 1.5038568343103981e-05,
      "loss": 0.0,
      "step": 113310
    },
    {
      "epoch": 34.96451712434434,
      "grad_norm": 0.0006155036389827728,
      "learning_rate": 1.5035482875655662e-05,
      "loss": 0.0,
      "step": 113320
    },
    {
      "epoch": 34.967602591792655,
      "grad_norm": 1.98257089323306e-06,
      "learning_rate": 1.5032397408207345e-05,
      "loss": 0.0,
      "step": 113330
    },
    {
      "epoch": 34.97068805924098,
      "grad_norm": 2.9683777658107147e-09,
      "learning_rate": 1.5029311940759025e-05,
      "loss": 0.0,
      "step": 113340
    },
    {
      "epoch": 34.97377352668929,
      "grad_norm": 1.3716839930566493e-06,
      "learning_rate": 1.5026226473310706e-05,
      "loss": 0.0,
      "step": 113350
    },
    {
      "epoch": 34.976858994137615,
      "grad_norm": 1.179635182779748e-05,
      "learning_rate": 1.502314100586239e-05,
      "loss": 0.0,
      "step": 113360
    },
    {
      "epoch": 34.97994446158593,
      "grad_norm": 3.290525455668103e-06,
      "learning_rate": 1.5020055538414071e-05,
      "loss": 0.0,
      "step": 113370
    },
    {
      "epoch": 34.983029929034245,
      "grad_norm": 5.066144240117865e-06,
      "learning_rate": 1.5016970070965752e-05,
      "loss": 0.0,
      "step": 113380
    },
    {
      "epoch": 34.98611539648257,
      "grad_norm": 0.06370597332715988,
      "learning_rate": 1.5013884603517434e-05,
      "loss": 0.0036,
      "step": 113390
    },
    {
      "epoch": 34.98920086393088,
      "grad_norm": 5.158344265510095e-06,
      "learning_rate": 1.5010799136069115e-05,
      "loss": 0.0,
      "step": 113400
    },
    {
      "epoch": 34.992286331379205,
      "grad_norm": 9.567047527525574e-06,
      "learning_rate": 1.5007713668620796e-05,
      "loss": 0.0,
      "step": 113410
    },
    {
      "epoch": 34.99537179882752,
      "grad_norm": 5.672244469678844e-07,
      "learning_rate": 1.5004628201172477e-05,
      "loss": 0.0,
      "step": 113420
    },
    {
      "epoch": 34.99845726627584,
      "grad_norm": 5.865022558282362e-06,
      "learning_rate": 1.500154273372416e-05,
      "loss": 0.0,
      "step": 113430
    },
    {
      "epoch": 35.0,
      "eval_accuracy_branch1": 0.9999421313040711,
      "eval_accuracy_branch2": 0.41705004677719587,
      "eval_f1_branch1": 0.9999389707946341,
      "eval_f1_branch2": 0.4100287432339199,
      "eval_loss": 1.5846550013520755e-05,
      "eval_precision_branch1": 0.9999385269842471,
      "eval_precision_branch2": 0.5128906046025885,
      "eval_recall_branch1": 0.999939436662805,
      "eval_recall_branch2": 0.5100908538526084,
      "eval_runtime": 240.9566,
      "eval_samples_per_second": 430.297,
      "eval_steps_per_second": 53.79,
      "step": 113435
    },
    {
      "epoch": 35.00154273372416,
      "grad_norm": 0.00021825019211973995,
      "learning_rate": 1.4998457266275842e-05,
      "loss": 0.0,
      "step": 113440
    },
    {
      "epoch": 35.00462820117248,
      "grad_norm": 4.1685852920636535e-06,
      "learning_rate": 1.4995371798827524e-05,
      "loss": 0.0,
      "step": 113450
    },
    {
      "epoch": 35.007713668620795,
      "grad_norm": 4.4080537918489426e-05,
      "learning_rate": 1.4992286331379205e-05,
      "loss": 0.0005,
      "step": 113460
    },
    {
      "epoch": 35.01079913606912,
      "grad_norm": 0.2647587060928345,
      "learning_rate": 1.4989200863930886e-05,
      "loss": 0.0006,
      "step": 113470
    },
    {
      "epoch": 35.01388460351743,
      "grad_norm": 0.0010072948643937707,
      "learning_rate": 1.4986115396482566e-05,
      "loss": 0.0,
      "step": 113480
    },
    {
      "epoch": 35.016970070965755,
      "grad_norm": 4.3526171111807344e-07,
      "learning_rate": 1.498302992903425e-05,
      "loss": 0.0001,
      "step": 113490
    },
    {
      "epoch": 35.02005553841407,
      "grad_norm": 4.2905864461317833e-07,
      "learning_rate": 1.4979944461585931e-05,
      "loss": 0.0,
      "step": 113500
    },
    {
      "epoch": 35.023141005862385,
      "grad_norm": 6.474204565165564e-05,
      "learning_rate": 1.4976858994137614e-05,
      "loss": 0.0,
      "step": 113510
    },
    {
      "epoch": 35.02622647331071,
      "grad_norm": 0.00032244069734588265,
      "learning_rate": 1.4973773526689295e-05,
      "loss": 0.0013,
      "step": 113520
    },
    {
      "epoch": 35.02931194075902,
      "grad_norm": 3.99995333282277e-05,
      "learning_rate": 1.4970688059240975e-05,
      "loss": 0.0,
      "step": 113530
    },
    {
      "epoch": 35.032397408207345,
      "grad_norm": 1.3100917385600042e-05,
      "learning_rate": 1.4967602591792656e-05,
      "loss": 0.0,
      "step": 113540
    },
    {
      "epoch": 35.03548287565566,
      "grad_norm": 0.0021099280565977097,
      "learning_rate": 1.4964517124344337e-05,
      "loss": 0.0037,
      "step": 113550
    },
    {
      "epoch": 35.03856834310398,
      "grad_norm": 0.00011536679812707007,
      "learning_rate": 1.4961431656896021e-05,
      "loss": 0.0001,
      "step": 113560
    },
    {
      "epoch": 35.0416538105523,
      "grad_norm": 0.0006358941900543869,
      "learning_rate": 1.4958346189447704e-05,
      "loss": 0.0,
      "step": 113570
    },
    {
      "epoch": 35.04473927800062,
      "grad_norm": 7.601083052577451e-05,
      "learning_rate": 1.4955260721999384e-05,
      "loss": 0.0,
      "step": 113580
    },
    {
      "epoch": 35.047824745448935,
      "grad_norm": 0.00010760330042103305,
      "learning_rate": 1.4952175254551065e-05,
      "loss": 0.0,
      "step": 113590
    },
    {
      "epoch": 35.05091021289726,
      "grad_norm": 6.919125894455647e-07,
      "learning_rate": 1.4949089787102746e-05,
      "loss": 0.0023,
      "step": 113600
    },
    {
      "epoch": 35.05399568034557,
      "grad_norm": 3.168145485688001e-05,
      "learning_rate": 1.4946004319654427e-05,
      "loss": 0.0,
      "step": 113610
    },
    {
      "epoch": 35.05708114779389,
      "grad_norm": 2.318540055057383e-06,
      "learning_rate": 1.494291885220611e-05,
      "loss": 0.0004,
      "step": 113620
    },
    {
      "epoch": 35.06016661524221,
      "grad_norm": 0.00011852797615574673,
      "learning_rate": 1.4939833384757793e-05,
      "loss": 0.0,
      "step": 113630
    },
    {
      "epoch": 35.063252082690525,
      "grad_norm": 6.797317553264293e-08,
      "learning_rate": 1.4936747917309474e-05,
      "loss": 0.0,
      "step": 113640
    },
    {
      "epoch": 35.06633755013885,
      "grad_norm": 0.00041506229899823666,
      "learning_rate": 1.4933662449861155e-05,
      "loss": 0.0,
      "step": 113650
    },
    {
      "epoch": 35.06942301758716,
      "grad_norm": 1.924142907228088e-06,
      "learning_rate": 1.4930576982412836e-05,
      "loss": 0.0002,
      "step": 113660
    },
    {
      "epoch": 35.072508485035485,
      "grad_norm": 0.0019493649015203118,
      "learning_rate": 1.4927491514964517e-05,
      "loss": 0.0,
      "step": 113670
    },
    {
      "epoch": 35.0755939524838,
      "grad_norm": 9.047344633472676e-07,
      "learning_rate": 1.4924406047516199e-05,
      "loss": 0.0,
      "step": 113680
    },
    {
      "epoch": 35.07867941993212,
      "grad_norm": 1.2448350389604457e-05,
      "learning_rate": 1.4921320580067882e-05,
      "loss": 0.0,
      "step": 113690
    },
    {
      "epoch": 35.08176488738044,
      "grad_norm": 0.0003635896719060838,
      "learning_rate": 1.4918235112619564e-05,
      "loss": 0.0011,
      "step": 113700
    },
    {
      "epoch": 35.08485035482876,
      "grad_norm": 2.6326183615310583e-06,
      "learning_rate": 1.4915149645171245e-05,
      "loss": 0.0001,
      "step": 113710
    },
    {
      "epoch": 35.087935822277075,
      "grad_norm": 1.1269772812738665e-06,
      "learning_rate": 1.4912064177722926e-05,
      "loss": 0.0001,
      "step": 113720
    },
    {
      "epoch": 35.09102128972539,
      "grad_norm": 0.0006829428020864725,
      "learning_rate": 1.4908978710274606e-05,
      "loss": 0.0,
      "step": 113730
    },
    {
      "epoch": 35.09410675717371,
      "grad_norm": 5.5521691137983e-06,
      "learning_rate": 1.4905893242826289e-05,
      "loss": 0.0,
      "step": 113740
    },
    {
      "epoch": 35.09719222462203,
      "grad_norm": 0.00010204250429524109,
      "learning_rate": 1.490280777537797e-05,
      "loss": 0.0002,
      "step": 113750
    },
    {
      "epoch": 35.10027769207035,
      "grad_norm": 0.0932709127664566,
      "learning_rate": 1.4899722307929654e-05,
      "loss": 0.0,
      "step": 113760
    },
    {
      "epoch": 35.103363159518665,
      "grad_norm": 0.0003318767121527344,
      "learning_rate": 1.4896636840481335e-05,
      "loss": 0.0,
      "step": 113770
    },
    {
      "epoch": 35.10644862696699,
      "grad_norm": 0.00027030700584873557,
      "learning_rate": 1.4893551373033015e-05,
      "loss": 0.0,
      "step": 113780
    },
    {
      "epoch": 35.1095340944153,
      "grad_norm": 2.8665215978662673e-08,
      "learning_rate": 1.4890465905584696e-05,
      "loss": 0.0,
      "step": 113790
    },
    {
      "epoch": 35.112619561863625,
      "grad_norm": 8.026028552876596e-08,
      "learning_rate": 1.4887380438136379e-05,
      "loss": 0.0,
      "step": 113800
    },
    {
      "epoch": 35.11570502931194,
      "grad_norm": 3.723411646205932e-05,
      "learning_rate": 1.488429497068806e-05,
      "loss": 0.0,
      "step": 113810
    },
    {
      "epoch": 35.11879049676026,
      "grad_norm": 1.761971361702308e-05,
      "learning_rate": 1.488120950323974e-05,
      "loss": 0.0,
      "step": 113820
    },
    {
      "epoch": 35.12187596420858,
      "grad_norm": 4.1000583905770327e-07,
      "learning_rate": 1.4878124035791424e-05,
      "loss": 0.0,
      "step": 113830
    },
    {
      "epoch": 35.1249614316569,
      "grad_norm": 3.122335556327016e-06,
      "learning_rate": 1.4875038568343105e-05,
      "loss": 0.0,
      "step": 113840
    },
    {
      "epoch": 35.128046899105215,
      "grad_norm": 1.829119128160528e-06,
      "learning_rate": 1.4871953100894786e-05,
      "loss": 0.0,
      "step": 113850
    },
    {
      "epoch": 35.13113236655353,
      "grad_norm": 8.801020157989115e-06,
      "learning_rate": 1.4868867633446468e-05,
      "loss": 0.0,
      "step": 113860
    },
    {
      "epoch": 35.13421783400185,
      "grad_norm": 0.0007610975881107152,
      "learning_rate": 1.486578216599815e-05,
      "loss": 0.0,
      "step": 113870
    },
    {
      "epoch": 35.13730330145017,
      "grad_norm": 2.1276741790643428e-06,
      "learning_rate": 1.486269669854983e-05,
      "loss": 0.0004,
      "step": 113880
    },
    {
      "epoch": 35.14038876889849,
      "grad_norm": 9.476504055783153e-05,
      "learning_rate": 1.485961123110151e-05,
      "loss": 0.0,
      "step": 113890
    },
    {
      "epoch": 35.143474236346805,
      "grad_norm": 0.0012707372661679983,
      "learning_rate": 1.4856525763653195e-05,
      "loss": 0.0,
      "step": 113900
    },
    {
      "epoch": 35.14655970379513,
      "grad_norm": 5.395452717493754e-06,
      "learning_rate": 1.4853440296204876e-05,
      "loss": 0.0,
      "step": 113910
    },
    {
      "epoch": 35.14964517124344,
      "grad_norm": 0.00016836247232276946,
      "learning_rate": 1.4850354828756558e-05,
      "loss": 0.0,
      "step": 113920
    },
    {
      "epoch": 35.152730638691764,
      "grad_norm": 0.0004364373453427106,
      "learning_rate": 1.4847269361308239e-05,
      "loss": 0.0001,
      "step": 113930
    },
    {
      "epoch": 35.15581610614008,
      "grad_norm": 4.217339665046893e-06,
      "learning_rate": 1.484418389385992e-05,
      "loss": 0.0,
      "step": 113940
    },
    {
      "epoch": 35.1589015735884,
      "grad_norm": 0.0004920854116789997,
      "learning_rate": 1.48410984264116e-05,
      "loss": 0.0,
      "step": 113950
    },
    {
      "epoch": 35.16198704103672,
      "grad_norm": 7.658453978365287e-05,
      "learning_rate": 1.4838012958963285e-05,
      "loss": 0.0,
      "step": 113960
    },
    {
      "epoch": 35.16507250848503,
      "grad_norm": 0.00012961977336090058,
      "learning_rate": 1.4834927491514965e-05,
      "loss": 0.0,
      "step": 113970
    },
    {
      "epoch": 35.168157975933354,
      "grad_norm": 2.8249598926777253e-07,
      "learning_rate": 1.4831842024066648e-05,
      "loss": 0.0,
      "step": 113980
    },
    {
      "epoch": 35.17124344338167,
      "grad_norm": 1.0628467634887784e-06,
      "learning_rate": 1.4828756556618329e-05,
      "loss": 0.0,
      "step": 113990
    },
    {
      "epoch": 35.17432891082999,
      "grad_norm": 0.0036452659405767918,
      "learning_rate": 1.482567108917001e-05,
      "loss": 0.0,
      "step": 114000
    },
    {
      "epoch": 35.17741437827831,
      "grad_norm": 1.0134033800568432e-05,
      "learning_rate": 1.482258562172169e-05,
      "loss": 0.0001,
      "step": 114010
    },
    {
      "epoch": 35.18049984572663,
      "grad_norm": 1.0140944368686178e-06,
      "learning_rate": 1.4819500154273371e-05,
      "loss": 0.0,
      "step": 114020
    },
    {
      "epoch": 35.183585313174945,
      "grad_norm": 4.4499665818875656e-05,
      "learning_rate": 1.4816414686825055e-05,
      "loss": 0.0,
      "step": 114030
    },
    {
      "epoch": 35.18667078062327,
      "grad_norm": 1.2477482414396945e-05,
      "learning_rate": 1.4813329219376738e-05,
      "loss": 0.0001,
      "step": 114040
    },
    {
      "epoch": 35.18975624807158,
      "grad_norm": 0.0007137984503060579,
      "learning_rate": 1.4810243751928419e-05,
      "loss": 0.0,
      "step": 114050
    },
    {
      "epoch": 35.192841715519904,
      "grad_norm": 4.937097060064843e-07,
      "learning_rate": 1.48071582844801e-05,
      "loss": 0.0,
      "step": 114060
    },
    {
      "epoch": 35.19592718296822,
      "grad_norm": 0.006183553021401167,
      "learning_rate": 1.480407281703178e-05,
      "loss": 0.0,
      "step": 114070
    },
    {
      "epoch": 35.199012650416535,
      "grad_norm": 0.003033348126336932,
      "learning_rate": 1.4800987349583461e-05,
      "loss": 0.0,
      "step": 114080
    },
    {
      "epoch": 35.20209811786486,
      "grad_norm": 1.2489075743360445e-05,
      "learning_rate": 1.4797901882135143e-05,
      "loss": 0.0002,
      "step": 114090
    },
    {
      "epoch": 35.20518358531317,
      "grad_norm": 2.711034312596894e-06,
      "learning_rate": 1.4794816414686828e-05,
      "loss": 0.0,
      "step": 114100
    },
    {
      "epoch": 35.208269052761494,
      "grad_norm": 3.1071929242898477e-06,
      "learning_rate": 1.4791730947238508e-05,
      "loss": 0.0001,
      "step": 114110
    },
    {
      "epoch": 35.21135452020981,
      "grad_norm": 1.0295049150954583e-06,
      "learning_rate": 1.4788645479790189e-05,
      "loss": 0.0,
      "step": 114120
    },
    {
      "epoch": 35.21443998765813,
      "grad_norm": 7.78587673266884e-06,
      "learning_rate": 1.478556001234187e-05,
      "loss": 0.0,
      "step": 114130
    },
    {
      "epoch": 35.21752545510645,
      "grad_norm": 4.554471615847433e-06,
      "learning_rate": 1.478247454489355e-05,
      "loss": 0.0,
      "step": 114140
    },
    {
      "epoch": 35.22061092255477,
      "grad_norm": 0.000107751831819769,
      "learning_rate": 1.4779389077445233e-05,
      "loss": 0.0,
      "step": 114150
    },
    {
      "epoch": 35.223696390003084,
      "grad_norm": 1.5246890825437731e-06,
      "learning_rate": 1.4776303609996917e-05,
      "loss": 0.0002,
      "step": 114160
    },
    {
      "epoch": 35.22678185745141,
      "grad_norm": 3.0126389901852235e-05,
      "learning_rate": 1.4773218142548598e-05,
      "loss": 0.0,
      "step": 114170
    },
    {
      "epoch": 35.22986732489972,
      "grad_norm": 0.00030493162921629846,
      "learning_rate": 1.4770132675100279e-05,
      "loss": 0.0,
      "step": 114180
    },
    {
      "epoch": 35.232952792348044,
      "grad_norm": 0.009162441827356815,
      "learning_rate": 1.476704720765196e-05,
      "loss": 0.0,
      "step": 114190
    },
    {
      "epoch": 35.23603825979636,
      "grad_norm": 0.00015690602594986558,
      "learning_rate": 1.476396174020364e-05,
      "loss": 0.0,
      "step": 114200
    },
    {
      "epoch": 35.239123727244674,
      "grad_norm": 0.00014085017028264701,
      "learning_rate": 1.4760876272755323e-05,
      "loss": 0.0,
      "step": 114210
    },
    {
      "epoch": 35.242209194693,
      "grad_norm": 6.357205165841151e-06,
      "learning_rate": 1.4757790805307004e-05,
      "loss": 0.0,
      "step": 114220
    },
    {
      "epoch": 35.24529466214131,
      "grad_norm": 7.212355558294803e-05,
      "learning_rate": 1.4754705337858688e-05,
      "loss": 0.0,
      "step": 114230
    },
    {
      "epoch": 35.248380129589634,
      "grad_norm": 4.948549758410081e-06,
      "learning_rate": 1.4751619870410369e-05,
      "loss": 0.0,
      "step": 114240
    },
    {
      "epoch": 35.25146559703795,
      "grad_norm": 0.0001444561203243211,
      "learning_rate": 1.474853440296205e-05,
      "loss": 0.0,
      "step": 114250
    },
    {
      "epoch": 35.25455106448627,
      "grad_norm": 0.0005374400061555207,
      "learning_rate": 1.474544893551373e-05,
      "loss": 0.0,
      "step": 114260
    },
    {
      "epoch": 35.25763653193459,
      "grad_norm": 4.31336779627145e-08,
      "learning_rate": 1.4742363468065413e-05,
      "loss": 0.0,
      "step": 114270
    },
    {
      "epoch": 35.26072199938291,
      "grad_norm": 0.0005842166137881577,
      "learning_rate": 1.4739278000617093e-05,
      "loss": 0.0,
      "step": 114280
    },
    {
      "epoch": 35.263807466831224,
      "grad_norm": 2.1641488601176206e-08,
      "learning_rate": 1.4736192533168774e-05,
      "loss": 0.0,
      "step": 114290
    },
    {
      "epoch": 35.26689293427955,
      "grad_norm": 0.0001721946318866685,
      "learning_rate": 1.4733107065720458e-05,
      "loss": 0.0,
      "step": 114300
    },
    {
      "epoch": 35.26997840172786,
      "grad_norm": 2.3200847863336094e-05,
      "learning_rate": 1.473002159827214e-05,
      "loss": 0.0,
      "step": 114310
    },
    {
      "epoch": 35.27306386917618,
      "grad_norm": 0.0029726417269557714,
      "learning_rate": 1.472693613082382e-05,
      "loss": 0.0,
      "step": 114320
    },
    {
      "epoch": 35.2761493366245,
      "grad_norm": 0.04777832701802254,
      "learning_rate": 1.4723850663375502e-05,
      "loss": 0.0,
      "step": 114330
    },
    {
      "epoch": 35.279234804072814,
      "grad_norm": 0.051055923104286194,
      "learning_rate": 1.4720765195927183e-05,
      "loss": 0.0,
      "step": 114340
    },
    {
      "epoch": 35.28232027152114,
      "grad_norm": 4.416872343426803e-06,
      "learning_rate": 1.4717679728478864e-05,
      "loss": 0.0,
      "step": 114350
    },
    {
      "epoch": 35.28540573896945,
      "grad_norm": 2.127418419206606e-08,
      "learning_rate": 1.4714594261030548e-05,
      "loss": 0.0,
      "step": 114360
    },
    {
      "epoch": 35.288491206417774,
      "grad_norm": 1.1615531548159197e-05,
      "learning_rate": 1.4711508793582229e-05,
      "loss": 0.0,
      "step": 114370
    },
    {
      "epoch": 35.29157667386609,
      "grad_norm": 5.170408456933728e-08,
      "learning_rate": 1.470842332613391e-05,
      "loss": 0.0,
      "step": 114380
    },
    {
      "epoch": 35.29466214131441,
      "grad_norm": 0.0021271321456879377,
      "learning_rate": 1.4705337858685592e-05,
      "loss": 0.0,
      "step": 114390
    },
    {
      "epoch": 35.29774760876273,
      "grad_norm": 2.2300657292362303e-05,
      "learning_rate": 1.4702252391237273e-05,
      "loss": 0.0,
      "step": 114400
    },
    {
      "epoch": 35.30083307621105,
      "grad_norm": 2.793379508148064e-06,
      "learning_rate": 1.4699166923788954e-05,
      "loss": 0.0001,
      "step": 114410
    },
    {
      "epoch": 35.303918543659364,
      "grad_norm": 0.0023434797767549753,
      "learning_rate": 1.4696081456340635e-05,
      "loss": 0.0,
      "step": 114420
    },
    {
      "epoch": 35.30700401110768,
      "grad_norm": 0.0014353793812915683,
      "learning_rate": 1.4692995988892319e-05,
      "loss": 0.0,
      "step": 114430
    },
    {
      "epoch": 35.310089478556,
      "grad_norm": 1.0867447599594016e-06,
      "learning_rate": 1.4689910521444e-05,
      "loss": 0.0,
      "step": 114440
    },
    {
      "epoch": 35.31317494600432,
      "grad_norm": 2.180137744289823e-05,
      "learning_rate": 1.4686825053995682e-05,
      "loss": 0.0,
      "step": 114450
    },
    {
      "epoch": 35.31626041345264,
      "grad_norm": 7.865278348617721e-06,
      "learning_rate": 1.4683739586547363e-05,
      "loss": 0.0,
      "step": 114460
    },
    {
      "epoch": 35.319345880900954,
      "grad_norm": 6.330465680548514e-07,
      "learning_rate": 1.4680654119099044e-05,
      "loss": 0.0002,
      "step": 114470
    },
    {
      "epoch": 35.32243134834928,
      "grad_norm": 1.599509459992987e-06,
      "learning_rate": 1.4677568651650724e-05,
      "loss": 0.0,
      "step": 114480
    },
    {
      "epoch": 35.32551681579759,
      "grad_norm": 0.0005429224693216383,
      "learning_rate": 1.4674483184202407e-05,
      "loss": 0.0,
      "step": 114490
    },
    {
      "epoch": 35.328602283245914,
      "grad_norm": 5.120193600305356e-05,
      "learning_rate": 1.467139771675409e-05,
      "loss": 0.0,
      "step": 114500
    },
    {
      "epoch": 35.33168775069423,
      "grad_norm": 4.065963366883807e-05,
      "learning_rate": 1.4668312249305772e-05,
      "loss": 0.0,
      "step": 114510
    },
    {
      "epoch": 35.33477321814255,
      "grad_norm": 2.415480821582605e-06,
      "learning_rate": 1.4665226781857453e-05,
      "loss": 0.0,
      "step": 114520
    },
    {
      "epoch": 35.33785868559087,
      "grad_norm": 8.101686432837596e-08,
      "learning_rate": 1.4662141314409133e-05,
      "loss": 0.0,
      "step": 114530
    },
    {
      "epoch": 35.34094415303919,
      "grad_norm": 2.1794210169900907e-06,
      "learning_rate": 1.4659055846960814e-05,
      "loss": 0.0002,
      "step": 114540
    },
    {
      "epoch": 35.344029620487504,
      "grad_norm": 0.0006867210031487048,
      "learning_rate": 1.4655970379512497e-05,
      "loss": 0.0004,
      "step": 114550
    },
    {
      "epoch": 35.34711508793582,
      "grad_norm": 0.000748653372284025,
      "learning_rate": 1.4652884912064179e-05,
      "loss": 0.0,
      "step": 114560
    },
    {
      "epoch": 35.35020055538414,
      "grad_norm": 3.292332849014201e-06,
      "learning_rate": 1.4649799444615862e-05,
      "loss": 0.0,
      "step": 114570
    },
    {
      "epoch": 35.35328602283246,
      "grad_norm": 4.453443762031384e-05,
      "learning_rate": 1.4646713977167542e-05,
      "loss": 0.0,
      "step": 114580
    },
    {
      "epoch": 35.35637149028078,
      "grad_norm": 1.964734838111326e-05,
      "learning_rate": 1.4643628509719223e-05,
      "loss": 0.0,
      "step": 114590
    },
    {
      "epoch": 35.359456957729094,
      "grad_norm": 4.485028512135614e-06,
      "learning_rate": 1.4640543042270904e-05,
      "loss": 0.0,
      "step": 114600
    },
    {
      "epoch": 35.362542425177416,
      "grad_norm": 9.570957445248496e-06,
      "learning_rate": 1.4637457574822586e-05,
      "loss": 0.0,
      "step": 114610
    },
    {
      "epoch": 35.36562789262573,
      "grad_norm": 0.0003655283653642982,
      "learning_rate": 1.4634372107374267e-05,
      "loss": 0.0001,
      "step": 114620
    },
    {
      "epoch": 35.368713360074054,
      "grad_norm": 1.818884447857272e-05,
      "learning_rate": 1.4631286639925951e-05,
      "loss": 0.0,
      "step": 114630
    },
    {
      "epoch": 35.37179882752237,
      "grad_norm": 4.0947718105144304e-08,
      "learning_rate": 1.4628201172477632e-05,
      "loss": 0.0,
      "step": 114640
    },
    {
      "epoch": 35.37488429497069,
      "grad_norm": 1.1538740182004403e-05,
      "learning_rate": 1.4625115705029313e-05,
      "loss": 0.0,
      "step": 114650
    },
    {
      "epoch": 35.377969762419006,
      "grad_norm": 1.12298926069343e-06,
      "learning_rate": 1.4622030237580994e-05,
      "loss": 0.0,
      "step": 114660
    },
    {
      "epoch": 35.38105522986732,
      "grad_norm": 0.0017114210641011596,
      "learning_rate": 1.4618944770132676e-05,
      "loss": 0.0,
      "step": 114670
    },
    {
      "epoch": 35.384140697315644,
      "grad_norm": 0.0014281711773946881,
      "learning_rate": 1.4615859302684357e-05,
      "loss": 0.0001,
      "step": 114680
    },
    {
      "epoch": 35.38722616476396,
      "grad_norm": 0.000952757487539202,
      "learning_rate": 1.4612773835236038e-05,
      "loss": 0.0001,
      "step": 114690
    },
    {
      "epoch": 35.39031163221228,
      "grad_norm": 2.467905233061174e-06,
      "learning_rate": 1.4609688367787722e-05,
      "loss": 0.0041,
      "step": 114700
    },
    {
      "epoch": 35.393397099660596,
      "grad_norm": 2.497637751730508e-06,
      "learning_rate": 1.4606602900339403e-05,
      "loss": 0.0,
      "step": 114710
    },
    {
      "epoch": 35.39648256710892,
      "grad_norm": 1.4772937220186577e-06,
      "learning_rate": 1.4603517432891083e-05,
      "loss": 0.0001,
      "step": 114720
    },
    {
      "epoch": 35.399568034557234,
      "grad_norm": 3.5688833577296464e-06,
      "learning_rate": 1.4600431965442766e-05,
      "loss": 0.0,
      "step": 114730
    },
    {
      "epoch": 35.402653502005556,
      "grad_norm": 1.410696626180652e-07,
      "learning_rate": 1.4597346497994447e-05,
      "loss": 0.0,
      "step": 114740
    },
    {
      "epoch": 35.40573896945387,
      "grad_norm": 2.796901753754355e-06,
      "learning_rate": 1.4594261030546128e-05,
      "loss": 0.0,
      "step": 114750
    },
    {
      "epoch": 35.408824436902194,
      "grad_norm": 0.022420469671487808,
      "learning_rate": 1.4591175563097808e-05,
      "loss": 0.0,
      "step": 114760
    },
    {
      "epoch": 35.41190990435051,
      "grad_norm": 2.1576743165496737e-06,
      "learning_rate": 1.4588090095649492e-05,
      "loss": 0.0,
      "step": 114770
    },
    {
      "epoch": 35.414995371798824,
      "grad_norm": 0.00018589211686048657,
      "learning_rate": 1.4585004628201173e-05,
      "loss": 0.0,
      "step": 114780
    },
    {
      "epoch": 35.418080839247146,
      "grad_norm": 9.847648470895365e-05,
      "learning_rate": 1.4581919160752856e-05,
      "loss": 0.0,
      "step": 114790
    },
    {
      "epoch": 35.42116630669546,
      "grad_norm": 3.768608803511597e-05,
      "learning_rate": 1.4578833693304537e-05,
      "loss": 0.0,
      "step": 114800
    },
    {
      "epoch": 35.424251774143784,
      "grad_norm": 9.1623633124982e-09,
      "learning_rate": 1.4575748225856217e-05,
      "loss": 0.0,
      "step": 114810
    },
    {
      "epoch": 35.4273372415921,
      "grad_norm": 8.089427865343168e-06,
      "learning_rate": 1.4572662758407898e-05,
      "loss": 0.0,
      "step": 114820
    },
    {
      "epoch": 35.43042270904042,
      "grad_norm": 7.431412996083964e-08,
      "learning_rate": 1.4569577290959582e-05,
      "loss": 0.0001,
      "step": 114830
    },
    {
      "epoch": 35.433508176488736,
      "grad_norm": 1.9038113805436296e-06,
      "learning_rate": 1.4566491823511263e-05,
      "loss": 0.0001,
      "step": 114840
    },
    {
      "epoch": 35.43659364393706,
      "grad_norm": 6.946464736756752e-08,
      "learning_rate": 1.4563406356062946e-05,
      "loss": 0.0003,
      "step": 114850
    },
    {
      "epoch": 35.439679111385374,
      "grad_norm": 0.00015287489804904908,
      "learning_rate": 1.4560320888614626e-05,
      "loss": 0.0,
      "step": 114860
    },
    {
      "epoch": 35.442764578833696,
      "grad_norm": 2.0647223209380172e-05,
      "learning_rate": 1.4557235421166307e-05,
      "loss": 0.0,
      "step": 114870
    },
    {
      "epoch": 35.44585004628201,
      "grad_norm": 1.256715194131175e-07,
      "learning_rate": 1.4554149953717988e-05,
      "loss": 0.0,
      "step": 114880
    },
    {
      "epoch": 35.44893551373033,
      "grad_norm": 2.771012759694713e-06,
      "learning_rate": 1.4551064486269669e-05,
      "loss": 0.0,
      "step": 114890
    },
    {
      "epoch": 35.45202098117865,
      "grad_norm": 5.201905878493562e-06,
      "learning_rate": 1.4547979018821353e-05,
      "loss": 0.0,
      "step": 114900
    },
    {
      "epoch": 35.455106448626964,
      "grad_norm": 0.0009269006550312042,
      "learning_rate": 1.4544893551373034e-05,
      "loss": 0.0,
      "step": 114910
    },
    {
      "epoch": 35.458191916075286,
      "grad_norm": 1.1393464092179784e-06,
      "learning_rate": 1.4541808083924716e-05,
      "loss": 0.0,
      "step": 114920
    },
    {
      "epoch": 35.4612773835236,
      "grad_norm": 0.003897184506058693,
      "learning_rate": 1.4538722616476397e-05,
      "loss": 0.0,
      "step": 114930
    },
    {
      "epoch": 35.46436285097192,
      "grad_norm": 1.914919948831084e-06,
      "learning_rate": 1.4535637149028078e-05,
      "loss": 0.0,
      "step": 114940
    },
    {
      "epoch": 35.46744831842024,
      "grad_norm": 8.631972741568461e-05,
      "learning_rate": 1.4532551681579758e-05,
      "loss": 0.0,
      "step": 114950
    },
    {
      "epoch": 35.47053378586856,
      "grad_norm": 3.830736022791825e-05,
      "learning_rate": 1.4529466214131441e-05,
      "loss": 0.0,
      "step": 114960
    },
    {
      "epoch": 35.473619253316876,
      "grad_norm": 0.0001419523759977892,
      "learning_rate": 1.4526380746683123e-05,
      "loss": 0.0,
      "step": 114970
    },
    {
      "epoch": 35.4767047207652,
      "grad_norm": 0.00027134738047607243,
      "learning_rate": 1.4523295279234806e-05,
      "loss": 0.0,
      "step": 114980
    },
    {
      "epoch": 35.479790188213514,
      "grad_norm": 0.04267551749944687,
      "learning_rate": 1.4520209811786487e-05,
      "loss": 0.0,
      "step": 114990
    },
    {
      "epoch": 35.482875655661836,
      "grad_norm": 7.249173359014094e-05,
      "learning_rate": 1.4517124344338167e-05,
      "loss": 0.0,
      "step": 115000
    },
    {
      "epoch": 35.48596112311015,
      "grad_norm": 9.379985385749023e-06,
      "learning_rate": 1.4514038876889848e-05,
      "loss": 0.0001,
      "step": 115010
    },
    {
      "epoch": 35.489046590558466,
      "grad_norm": 3.9123620808823034e-05,
      "learning_rate": 1.451095340944153e-05,
      "loss": 0.0,
      "step": 115020
    },
    {
      "epoch": 35.49213205800679,
      "grad_norm": 1.9782230083364993e-05,
      "learning_rate": 1.4507867941993213e-05,
      "loss": 0.0,
      "step": 115030
    },
    {
      "epoch": 35.495217525455104,
      "grad_norm": 6.315642622212181e-07,
      "learning_rate": 1.4504782474544896e-05,
      "loss": 0.0,
      "step": 115040
    },
    {
      "epoch": 35.498302992903426,
      "grad_norm": 1.8129238014807925e-05,
      "learning_rate": 1.4501697007096576e-05,
      "loss": 0.0,
      "step": 115050
    },
    {
      "epoch": 35.50138846035174,
      "grad_norm": 8.750458277972939e-07,
      "learning_rate": 1.4498611539648257e-05,
      "loss": 0.0,
      "step": 115060
    },
    {
      "epoch": 35.50447392780006,
      "grad_norm": 1.9618288206402212e-05,
      "learning_rate": 1.4495526072199938e-05,
      "loss": 0.0,
      "step": 115070
    },
    {
      "epoch": 35.50755939524838,
      "grad_norm": 0.0019857550505548716,
      "learning_rate": 1.449244060475162e-05,
      "loss": 0.0,
      "step": 115080
    },
    {
      "epoch": 35.5106448626967,
      "grad_norm": 0.34110164642333984,
      "learning_rate": 1.4489355137303301e-05,
      "loss": 0.0001,
      "step": 115090
    },
    {
      "epoch": 35.513730330145016,
      "grad_norm": 9.004164166981354e-05,
      "learning_rate": 1.4486269669854985e-05,
      "loss": 0.0,
      "step": 115100
    },
    {
      "epoch": 35.51681579759334,
      "grad_norm": 8.321359018736985e-06,
      "learning_rate": 1.4483184202406666e-05,
      "loss": 0.0,
      "step": 115110
    },
    {
      "epoch": 35.51990126504165,
      "grad_norm": 1.5771754988236353e-05,
      "learning_rate": 1.4480098734958347e-05,
      "loss": 0.0,
      "step": 115120
    },
    {
      "epoch": 35.52298673248997,
      "grad_norm": 3.45703227822014e-07,
      "learning_rate": 1.4477013267510028e-05,
      "loss": 0.0,
      "step": 115130
    },
    {
      "epoch": 35.52607219993829,
      "grad_norm": 6.14724776824005e-05,
      "learning_rate": 1.447392780006171e-05,
      "loss": 0.0,
      "step": 115140
    },
    {
      "epoch": 35.529157667386606,
      "grad_norm": 1.5028643608093262,
      "learning_rate": 1.4470842332613391e-05,
      "loss": 0.0006,
      "step": 115150
    },
    {
      "epoch": 35.53224313483493,
      "grad_norm": 5.937200057815062e-06,
      "learning_rate": 1.4467756865165072e-05,
      "loss": 0.0,
      "step": 115160
    },
    {
      "epoch": 35.53532860228324,
      "grad_norm": 3.0594196687161457e-07,
      "learning_rate": 1.4464671397716756e-05,
      "loss": 0.0005,
      "step": 115170
    },
    {
      "epoch": 35.538414069731566,
      "grad_norm": 0.0010072154691442847,
      "learning_rate": 1.4461585930268437e-05,
      "loss": 0.0,
      "step": 115180
    },
    {
      "epoch": 35.54149953717988,
      "grad_norm": 0.08997733891010284,
      "learning_rate": 1.4458500462820118e-05,
      "loss": 0.0074,
      "step": 115190
    },
    {
      "epoch": 35.5445850046282,
      "grad_norm": 8.175617836059246e-07,
      "learning_rate": 1.44554149953718e-05,
      "loss": 0.0,
      "step": 115200
    },
    {
      "epoch": 35.54767047207652,
      "grad_norm": 2.7997766665066592e-06,
      "learning_rate": 1.445232952792348e-05,
      "loss": 0.0,
      "step": 115210
    },
    {
      "epoch": 35.55075593952484,
      "grad_norm": 0.0007232332136482,
      "learning_rate": 1.4449244060475162e-05,
      "loss": 0.0,
      "step": 115220
    },
    {
      "epoch": 35.553841406973156,
      "grad_norm": 7.163410373323131e-06,
      "learning_rate": 1.4446158593026846e-05,
      "loss": 0.0,
      "step": 115230
    },
    {
      "epoch": 35.55692687442148,
      "grad_norm": 7.185416052379878e-06,
      "learning_rate": 1.4443073125578527e-05,
      "loss": 0.0,
      "step": 115240
    },
    {
      "epoch": 35.56001234186979,
      "grad_norm": 9.426492397324182e-06,
      "learning_rate": 1.4439987658130207e-05,
      "loss": 0.0,
      "step": 115250
    },
    {
      "epoch": 35.56309780931811,
      "grad_norm": 2.8543028747662902e-05,
      "learning_rate": 1.443690219068189e-05,
      "loss": 0.0,
      "step": 115260
    },
    {
      "epoch": 35.56618327676643,
      "grad_norm": 2.571074162460718e-07,
      "learning_rate": 1.443381672323357e-05,
      "loss": 0.0,
      "step": 115270
    },
    {
      "epoch": 35.569268744214746,
      "grad_norm": 0.00024109709192998707,
      "learning_rate": 1.4430731255785251e-05,
      "loss": 0.0,
      "step": 115280
    },
    {
      "epoch": 35.57235421166307,
      "grad_norm": 0.0056495158933103085,
      "learning_rate": 1.4427645788336932e-05,
      "loss": 0.0,
      "step": 115290
    },
    {
      "epoch": 35.57543967911138,
      "grad_norm": 0.05061310529708862,
      "learning_rate": 1.4424560320888616e-05,
      "loss": 0.0001,
      "step": 115300
    },
    {
      "epoch": 35.578525146559706,
      "grad_norm": 3.8882935768924654e-05,
      "learning_rate": 1.4421474853440297e-05,
      "loss": 0.0001,
      "step": 115310
    },
    {
      "epoch": 35.58161061400802,
      "grad_norm": 0.0028626099228858948,
      "learning_rate": 1.441838938599198e-05,
      "loss": 0.0,
      "step": 115320
    },
    {
      "epoch": 35.58469608145634,
      "grad_norm": 0.00010234113869955763,
      "learning_rate": 1.441530391854366e-05,
      "loss": 0.0,
      "step": 115330
    },
    {
      "epoch": 35.58778154890466,
      "grad_norm": 9.858943667495623e-05,
      "learning_rate": 1.4412218451095341e-05,
      "loss": 0.0,
      "step": 115340
    },
    {
      "epoch": 35.59086701635298,
      "grad_norm": 7.553357590950327e-06,
      "learning_rate": 1.4409132983647022e-05,
      "loss": 0.0,
      "step": 115350
    },
    {
      "epoch": 35.593952483801296,
      "grad_norm": 1.2520572454377543e-06,
      "learning_rate": 1.4406047516198703e-05,
      "loss": 0.0,
      "step": 115360
    },
    {
      "epoch": 35.59703795124961,
      "grad_norm": 0.00355044798925519,
      "learning_rate": 1.4402962048750387e-05,
      "loss": 0.0,
      "step": 115370
    },
    {
      "epoch": 35.60012341869793,
      "grad_norm": 0.00011283253115834668,
      "learning_rate": 1.439987658130207e-05,
      "loss": 0.0,
      "step": 115380
    },
    {
      "epoch": 35.60320888614625,
      "grad_norm": 0.00036327363341115415,
      "learning_rate": 1.439679111385375e-05,
      "loss": 0.0001,
      "step": 115390
    },
    {
      "epoch": 35.60629435359457,
      "grad_norm": 9.681875781097915e-06,
      "learning_rate": 1.4393705646405431e-05,
      "loss": 0.0,
      "step": 115400
    },
    {
      "epoch": 35.609379821042886,
      "grad_norm": 5.307784249453107e-06,
      "learning_rate": 1.4390620178957112e-05,
      "loss": 0.0,
      "step": 115410
    },
    {
      "epoch": 35.61246528849121,
      "grad_norm": 9.10933522391133e-06,
      "learning_rate": 1.4387534711508792e-05,
      "loss": 0.0,
      "step": 115420
    },
    {
      "epoch": 35.61555075593952,
      "grad_norm": 3.1071388093550922e-06,
      "learning_rate": 1.4384449244060477e-05,
      "loss": 0.0053,
      "step": 115430
    },
    {
      "epoch": 35.618636223387846,
      "grad_norm": 2.1584179421552108e-07,
      "learning_rate": 1.4381363776612159e-05,
      "loss": 0.0,
      "step": 115440
    },
    {
      "epoch": 35.62172169083616,
      "grad_norm": 2.8570078939083032e-05,
      "learning_rate": 1.437827830916384e-05,
      "loss": 0.0,
      "step": 115450
    },
    {
      "epoch": 35.62480715828448,
      "grad_norm": 4.0044196794042364e-05,
      "learning_rate": 1.437519284171552e-05,
      "loss": 0.0,
      "step": 115460
    },
    {
      "epoch": 35.6278926257328,
      "grad_norm": 5.595135917246807e-06,
      "learning_rate": 1.4372107374267201e-05,
      "loss": 0.0,
      "step": 115470
    },
    {
      "epoch": 35.63097809318112,
      "grad_norm": 2.300498636031989e-06,
      "learning_rate": 1.4369021906818882e-05,
      "loss": 0.0001,
      "step": 115480
    },
    {
      "epoch": 35.634063560629436,
      "grad_norm": 2.8834961995016783e-05,
      "learning_rate": 1.4365936439370565e-05,
      "loss": 0.001,
      "step": 115490
    },
    {
      "epoch": 35.63714902807775,
      "grad_norm": 1.4935930266801734e-05,
      "learning_rate": 1.4362850971922249e-05,
      "loss": 0.0,
      "step": 115500
    },
    {
      "epoch": 35.64023449552607,
      "grad_norm": 0.000579041603486985,
      "learning_rate": 1.435976550447393e-05,
      "loss": 0.0002,
      "step": 115510
    },
    {
      "epoch": 35.64331996297439,
      "grad_norm": 9.835039236349985e-07,
      "learning_rate": 1.435668003702561e-05,
      "loss": 0.0,
      "step": 115520
    },
    {
      "epoch": 35.64640543042271,
      "grad_norm": 0.00024630670668557286,
      "learning_rate": 1.4353594569577291e-05,
      "loss": 0.0001,
      "step": 115530
    },
    {
      "epoch": 35.649490897871026,
      "grad_norm": 7.53542481106706e-05,
      "learning_rate": 1.4350509102128972e-05,
      "loss": 0.0,
      "step": 115540
    },
    {
      "epoch": 35.65257636531935,
      "grad_norm": 4.1598985944801825e-07,
      "learning_rate": 1.4347423634680655e-05,
      "loss": 0.0,
      "step": 115550
    },
    {
      "epoch": 35.65566183276766,
      "grad_norm": 1.7431257219868712e-05,
      "learning_rate": 1.4344338167232335e-05,
      "loss": 0.0,
      "step": 115560
    },
    {
      "epoch": 35.658747300215985,
      "grad_norm": 8.864382834872231e-05,
      "learning_rate": 1.434125269978402e-05,
      "loss": 0.0,
      "step": 115570
    },
    {
      "epoch": 35.6618327676643,
      "grad_norm": 3.836649193544872e-05,
      "learning_rate": 1.43381672323357e-05,
      "loss": 0.0,
      "step": 115580
    },
    {
      "epoch": 35.66491823511262,
      "grad_norm": 2.889416464313399e-05,
      "learning_rate": 1.4335081764887381e-05,
      "loss": 0.0,
      "step": 115590
    },
    {
      "epoch": 35.66800370256094,
      "grad_norm": 5.415847112999472e-07,
      "learning_rate": 1.4331996297439062e-05,
      "loss": 0.0,
      "step": 115600
    },
    {
      "epoch": 35.67108917000925,
      "grad_norm": 0.00392546970397234,
      "learning_rate": 1.4328910829990744e-05,
      "loss": 0.0,
      "step": 115610
    },
    {
      "epoch": 35.674174637457575,
      "grad_norm": 5.501461782841943e-05,
      "learning_rate": 1.4325825362542425e-05,
      "loss": 0.0,
      "step": 115620
    },
    {
      "epoch": 35.67726010490589,
      "grad_norm": 2.9755943614873104e-05,
      "learning_rate": 1.4322739895094106e-05,
      "loss": 0.0,
      "step": 115630
    },
    {
      "epoch": 35.68034557235421,
      "grad_norm": 3.321182248328114e-06,
      "learning_rate": 1.431965442764579e-05,
      "loss": 0.0,
      "step": 115640
    },
    {
      "epoch": 35.68343103980253,
      "grad_norm": 5.965198397461791e-07,
      "learning_rate": 1.431656896019747e-05,
      "loss": 0.0001,
      "step": 115650
    },
    {
      "epoch": 35.68651650725085,
      "grad_norm": 8.687643457960803e-06,
      "learning_rate": 1.4313483492749152e-05,
      "loss": 0.0009,
      "step": 115660
    },
    {
      "epoch": 35.689601974699166,
      "grad_norm": 0.011723615229129791,
      "learning_rate": 1.4310398025300834e-05,
      "loss": 0.0111,
      "step": 115670
    },
    {
      "epoch": 35.69268744214749,
      "grad_norm": 0.00019654107745736837,
      "learning_rate": 1.4307312557852515e-05,
      "loss": 0.0,
      "step": 115680
    },
    {
      "epoch": 35.6957729095958,
      "grad_norm": 0.0001897171896416694,
      "learning_rate": 1.4304227090404196e-05,
      "loss": 0.0,
      "step": 115690
    },
    {
      "epoch": 35.698858377044125,
      "grad_norm": 0.00023397881886921823,
      "learning_rate": 1.430114162295588e-05,
      "loss": 0.0,
      "step": 115700
    },
    {
      "epoch": 35.70194384449244,
      "grad_norm": 1.994927742998698e-06,
      "learning_rate": 1.429805615550756e-05,
      "loss": 0.0,
      "step": 115710
    },
    {
      "epoch": 35.705029311940756,
      "grad_norm": 5.865568164153956e-05,
      "learning_rate": 1.4294970688059241e-05,
      "loss": 0.0003,
      "step": 115720
    },
    {
      "epoch": 35.70811477938908,
      "grad_norm": 9.381610288983211e-05,
      "learning_rate": 1.4291885220610924e-05,
      "loss": 0.0,
      "step": 115730
    },
    {
      "epoch": 35.71120024683739,
      "grad_norm": 9.445701465438106e-08,
      "learning_rate": 1.4288799753162605e-05,
      "loss": 0.0006,
      "step": 115740
    },
    {
      "epoch": 35.714285714285715,
      "grad_norm": 1.2079542102583218e-05,
      "learning_rate": 1.4285714285714285e-05,
      "loss": 0.0,
      "step": 115750
    },
    {
      "epoch": 35.71737118173403,
      "grad_norm": 0.000416764261899516,
      "learning_rate": 1.4282628818265966e-05,
      "loss": 0.0001,
      "step": 115760
    },
    {
      "epoch": 35.72045664918235,
      "grad_norm": 4.967571658198722e-05,
      "learning_rate": 1.427954335081765e-05,
      "loss": 0.0011,
      "step": 115770
    },
    {
      "epoch": 35.72354211663067,
      "grad_norm": 5.8943449232629064e-08,
      "learning_rate": 1.4276457883369331e-05,
      "loss": 0.0,
      "step": 115780
    },
    {
      "epoch": 35.72662758407899,
      "grad_norm": 2.7607120500761084e-05,
      "learning_rate": 1.4273372415921014e-05,
      "loss": 0.0,
      "step": 115790
    },
    {
      "epoch": 35.729713051527305,
      "grad_norm": 0.01279348973184824,
      "learning_rate": 1.4270286948472694e-05,
      "loss": 0.0067,
      "step": 115800
    },
    {
      "epoch": 35.73279851897563,
      "grad_norm": 0.00020889520237687975,
      "learning_rate": 1.4267201481024375e-05,
      "loss": 0.0,
      "step": 115810
    },
    {
      "epoch": 35.73588398642394,
      "grad_norm": 1.5498128050239757e-05,
      "learning_rate": 1.4264116013576056e-05,
      "loss": 0.0,
      "step": 115820
    },
    {
      "epoch": 35.738969453872265,
      "grad_norm": 0.23970545828342438,
      "learning_rate": 1.4261030546127738e-05,
      "loss": 0.0009,
      "step": 115830
    },
    {
      "epoch": 35.74205492132058,
      "grad_norm": 0.00035866047255694866,
      "learning_rate": 1.4257945078679421e-05,
      "loss": 0.0,
      "step": 115840
    },
    {
      "epoch": 35.745140388768895,
      "grad_norm": 0.0010422597406432033,
      "learning_rate": 1.4254859611231103e-05,
      "loss": 0.0,
      "step": 115850
    },
    {
      "epoch": 35.74822585621722,
      "grad_norm": 3.915327440040528e-08,
      "learning_rate": 1.4251774143782784e-05,
      "loss": 0.0,
      "step": 115860
    },
    {
      "epoch": 35.75131132366553,
      "grad_norm": 0.005389283411204815,
      "learning_rate": 1.4248688676334465e-05,
      "loss": 0.0,
      "step": 115870
    },
    {
      "epoch": 35.754396791113855,
      "grad_norm": 4.01323347887228e-07,
      "learning_rate": 1.4245603208886146e-05,
      "loss": 0.0001,
      "step": 115880
    },
    {
      "epoch": 35.75748225856217,
      "grad_norm": 1.5161097621785302e-07,
      "learning_rate": 1.4242517741437828e-05,
      "loss": 0.0001,
      "step": 115890
    },
    {
      "epoch": 35.76056772601049,
      "grad_norm": 0.003624951234087348,
      "learning_rate": 1.423943227398951e-05,
      "loss": 0.0,
      "step": 115900
    },
    {
      "epoch": 35.76365319345881,
      "grad_norm": 0.00026922320830635726,
      "learning_rate": 1.4236346806541193e-05,
      "loss": 0.0,
      "step": 115910
    },
    {
      "epoch": 35.76673866090713,
      "grad_norm": 9.439129826205317e-06,
      "learning_rate": 1.4233261339092874e-05,
      "loss": 0.0,
      "step": 115920
    },
    {
      "epoch": 35.769824128355445,
      "grad_norm": 5.889092335564783e-06,
      "learning_rate": 1.4230175871644555e-05,
      "loss": 0.0,
      "step": 115930
    },
    {
      "epoch": 35.77290959580377,
      "grad_norm": 6.033151294104755e-07,
      "learning_rate": 1.4227090404196236e-05,
      "loss": 0.0,
      "step": 115940
    },
    {
      "epoch": 35.77599506325208,
      "grad_norm": 7.494974397559417e-06,
      "learning_rate": 1.4224004936747918e-05,
      "loss": 0.0,
      "step": 115950
    },
    {
      "epoch": 35.7790805307004,
      "grad_norm": 0.0003275696071796119,
      "learning_rate": 1.4220919469299599e-05,
      "loss": 0.0002,
      "step": 115960
    },
    {
      "epoch": 35.78216599814872,
      "grad_norm": 8.201073796954006e-06,
      "learning_rate": 1.4217834001851283e-05,
      "loss": 0.0,
      "step": 115970
    },
    {
      "epoch": 35.785251465597035,
      "grad_norm": 3.115257277386263e-05,
      "learning_rate": 1.4214748534402964e-05,
      "loss": 0.0,
      "step": 115980
    },
    {
      "epoch": 35.78833693304536,
      "grad_norm": 0.00014278468734119087,
      "learning_rate": 1.4211663066954645e-05,
      "loss": 0.0,
      "step": 115990
    },
    {
      "epoch": 35.79142240049367,
      "grad_norm": 2.143222991435323e-05,
      "learning_rate": 1.4208577599506325e-05,
      "loss": 0.0,
      "step": 116000
    },
    {
      "epoch": 35.794507867941995,
      "grad_norm": 0.00013597436191048473,
      "learning_rate": 1.4205492132058008e-05,
      "loss": 0.0,
      "step": 116010
    },
    {
      "epoch": 35.79759333539031,
      "grad_norm": 0.0004439654585439712,
      "learning_rate": 1.4202406664609689e-05,
      "loss": 0.0001,
      "step": 116020
    },
    {
      "epoch": 35.80067880283863,
      "grad_norm": 3.0273968150140718e-05,
      "learning_rate": 1.419932119716137e-05,
      "loss": 0.0,
      "step": 116030
    },
    {
      "epoch": 35.80376427028695,
      "grad_norm": 1.6530574953321775e-07,
      "learning_rate": 1.4196235729713054e-05,
      "loss": 0.0,
      "step": 116040
    },
    {
      "epoch": 35.80684973773527,
      "grad_norm": 1.014418558042962e-06,
      "learning_rate": 1.4193150262264734e-05,
      "loss": 0.0,
      "step": 116050
    },
    {
      "epoch": 35.809935205183585,
      "grad_norm": 0.00012008897465420887,
      "learning_rate": 1.4190064794816415e-05,
      "loss": 0.0,
      "step": 116060
    },
    {
      "epoch": 35.8130206726319,
      "grad_norm": 0.00020135199883952737,
      "learning_rate": 1.4186979327368098e-05,
      "loss": 0.0,
      "step": 116070
    },
    {
      "epoch": 35.81610614008022,
      "grad_norm": 4.2311935288807945e-08,
      "learning_rate": 1.4183893859919778e-05,
      "loss": 0.0,
      "step": 116080
    },
    {
      "epoch": 35.81919160752854,
      "grad_norm": 4.314297257224098e-07,
      "learning_rate": 1.418080839247146e-05,
      "loss": 0.0,
      "step": 116090
    },
    {
      "epoch": 35.82227707497686,
      "grad_norm": 8.555376552976668e-06,
      "learning_rate": 1.4177722925023143e-05,
      "loss": 0.0,
      "step": 116100
    },
    {
      "epoch": 35.825362542425175,
      "grad_norm": 7.50391748738366e-08,
      "learning_rate": 1.4174637457574824e-05,
      "loss": 0.0,
      "step": 116110
    },
    {
      "epoch": 35.8284480098735,
      "grad_norm": 1.7838281564763747e-05,
      "learning_rate": 1.4171551990126505e-05,
      "loss": 0.0,
      "step": 116120
    },
    {
      "epoch": 35.83153347732181,
      "grad_norm": 0.0004620049730874598,
      "learning_rate": 1.4168466522678187e-05,
      "loss": 0.0,
      "step": 116130
    },
    {
      "epoch": 35.834618944770135,
      "grad_norm": 4.860588433075463e-06,
      "learning_rate": 1.4165381055229868e-05,
      "loss": 0.0001,
      "step": 116140
    },
    {
      "epoch": 35.83770441221845,
      "grad_norm": 6.774626672267914e-05,
      "learning_rate": 1.4162295587781549e-05,
      "loss": 0.0002,
      "step": 116150
    },
    {
      "epoch": 35.84078987966677,
      "grad_norm": 3.052671445402666e-06,
      "learning_rate": 1.415921012033323e-05,
      "loss": 0.0,
      "step": 116160
    },
    {
      "epoch": 35.84387534711509,
      "grad_norm": 0.007182298693805933,
      "learning_rate": 1.4156124652884914e-05,
      "loss": 0.0,
      "step": 116170
    },
    {
      "epoch": 35.84696081456341,
      "grad_norm": 6.007809588481905e-06,
      "learning_rate": 1.4153039185436595e-05,
      "loss": 0.0001,
      "step": 116180
    },
    {
      "epoch": 35.850046282011725,
      "grad_norm": 0.011231321841478348,
      "learning_rate": 1.4149953717988275e-05,
      "loss": 0.0069,
      "step": 116190
    },
    {
      "epoch": 35.85313174946004,
      "grad_norm": 4.4722846723743714e-06,
      "learning_rate": 1.4146868250539958e-05,
      "loss": 0.0048,
      "step": 116200
    },
    {
      "epoch": 35.85621721690836,
      "grad_norm": 5.125653387949569e-06,
      "learning_rate": 1.4143782783091639e-05,
      "loss": 0.0,
      "step": 116210
    },
    {
      "epoch": 35.85930268435668,
      "grad_norm": 8.322678581862419e-07,
      "learning_rate": 1.414069731564332e-05,
      "loss": 0.0001,
      "step": 116220
    },
    {
      "epoch": 35.862388151805,
      "grad_norm": 4.441118107934017e-06,
      "learning_rate": 1.4137611848195e-05,
      "loss": 0.0,
      "step": 116230
    },
    {
      "epoch": 35.865473619253315,
      "grad_norm": 0.01198637206107378,
      "learning_rate": 1.4134526380746684e-05,
      "loss": 0.0,
      "step": 116240
    },
    {
      "epoch": 35.86855908670164,
      "grad_norm": 1.576739009578887e-06,
      "learning_rate": 1.4131440913298365e-05,
      "loss": 0.0,
      "step": 116250
    },
    {
      "epoch": 35.87164455414995,
      "grad_norm": 1.1665815114974976,
      "learning_rate": 1.4128355445850048e-05,
      "loss": 0.0004,
      "step": 116260
    },
    {
      "epoch": 35.874730021598275,
      "grad_norm": 0.00026147792232222855,
      "learning_rate": 1.4125269978401728e-05,
      "loss": 0.0,
      "step": 116270
    },
    {
      "epoch": 35.87781548904659,
      "grad_norm": 5.993187427520752,
      "learning_rate": 1.412218451095341e-05,
      "loss": 0.0069,
      "step": 116280
    },
    {
      "epoch": 35.88090095649491,
      "grad_norm": 1.1552520845725667e-05,
      "learning_rate": 1.411909904350509e-05,
      "loss": 0.0004,
      "step": 116290
    },
    {
      "epoch": 35.88398642394323,
      "grad_norm": 0.00032037231721915305,
      "learning_rate": 1.4116013576056774e-05,
      "loss": 0.0,
      "step": 116300
    },
    {
      "epoch": 35.88707189139154,
      "grad_norm": 5.472246584758977e-07,
      "learning_rate": 1.4112928108608455e-05,
      "loss": 0.0001,
      "step": 116310
    },
    {
      "epoch": 35.890157358839865,
      "grad_norm": 5.6134056649170816e-05,
      "learning_rate": 1.4109842641160137e-05,
      "loss": 0.0,
      "step": 116320
    },
    {
      "epoch": 35.89324282628818,
      "grad_norm": 9.869665518635884e-06,
      "learning_rate": 1.4106757173711818e-05,
      "loss": 0.0,
      "step": 116330
    },
    {
      "epoch": 35.8963282937365,
      "grad_norm": 2.9851932481506083e-07,
      "learning_rate": 1.4103671706263499e-05,
      "loss": 0.0001,
      "step": 116340
    },
    {
      "epoch": 35.89941376118482,
      "grad_norm": 0.00010161233512917534,
      "learning_rate": 1.410058623881518e-05,
      "loss": 0.0,
      "step": 116350
    },
    {
      "epoch": 35.90249922863314,
      "grad_norm": 4.992390586266993e-06,
      "learning_rate": 1.4097500771366862e-05,
      "loss": 0.0,
      "step": 116360
    },
    {
      "epoch": 35.905584696081455,
      "grad_norm": 0.0087968148291111,
      "learning_rate": 1.4094415303918545e-05,
      "loss": 0.0001,
      "step": 116370
    },
    {
      "epoch": 35.90867016352978,
      "grad_norm": 0.0002447843726258725,
      "learning_rate": 1.4091329836470227e-05,
      "loss": 0.0,
      "step": 116380
    },
    {
      "epoch": 35.91175563097809,
      "grad_norm": 0.0013240956468507648,
      "learning_rate": 1.4088244369021908e-05,
      "loss": 0.0,
      "step": 116390
    },
    {
      "epoch": 35.914841098426415,
      "grad_norm": 4.226896876957653e-08,
      "learning_rate": 1.4085158901573589e-05,
      "loss": 0.0,
      "step": 116400
    },
    {
      "epoch": 35.91792656587473,
      "grad_norm": 4.793904008693062e-05,
      "learning_rate": 1.408207343412527e-05,
      "loss": 0.0,
      "step": 116410
    },
    {
      "epoch": 35.92101203332305,
      "grad_norm": 1.974453880393412e-06,
      "learning_rate": 1.4078987966676952e-05,
      "loss": 0.0001,
      "step": 116420
    },
    {
      "epoch": 35.92409750077137,
      "grad_norm": 9.669706196291372e-05,
      "learning_rate": 1.4075902499228633e-05,
      "loss": 0.0,
      "step": 116430
    },
    {
      "epoch": 35.92718296821968,
      "grad_norm": 1.4963893590902444e-06,
      "learning_rate": 1.4072817031780317e-05,
      "loss": 0.0,
      "step": 116440
    },
    {
      "epoch": 35.930268435668005,
      "grad_norm": 3.9874725189292803e-05,
      "learning_rate": 1.4069731564331998e-05,
      "loss": 0.0,
      "step": 116450
    },
    {
      "epoch": 35.93335390311632,
      "grad_norm": 0.00054391153389588,
      "learning_rate": 1.4066646096883679e-05,
      "loss": 0.0003,
      "step": 116460
    },
    {
      "epoch": 35.93643937056464,
      "grad_norm": 0.032112106680870056,
      "learning_rate": 1.406356062943536e-05,
      "loss": 0.0,
      "step": 116470
    },
    {
      "epoch": 35.93952483801296,
      "grad_norm": 0.0009746992727741599,
      "learning_rate": 1.4060475161987042e-05,
      "loss": 0.0,
      "step": 116480
    },
    {
      "epoch": 35.94261030546128,
      "grad_norm": 8.888333104550838e-05,
      "learning_rate": 1.4057389694538723e-05,
      "loss": 0.0,
      "step": 116490
    },
    {
      "epoch": 35.945695772909595,
      "grad_norm": 6.505094916064991e-06,
      "learning_rate": 1.4054304227090403e-05,
      "loss": 0.0,
      "step": 116500
    },
    {
      "epoch": 35.94878124035792,
      "grad_norm": 2.1465988538693637e-05,
      "learning_rate": 1.4051218759642088e-05,
      "loss": 0.0,
      "step": 116510
    },
    {
      "epoch": 35.95186670780623,
      "grad_norm": 5.326864993548952e-07,
      "learning_rate": 1.4048133292193768e-05,
      "loss": 0.0009,
      "step": 116520
    },
    {
      "epoch": 35.954952175254554,
      "grad_norm": 1.3316197509993799e-05,
      "learning_rate": 1.404504782474545e-05,
      "loss": 0.0,
      "step": 116530
    },
    {
      "epoch": 35.95803764270287,
      "grad_norm": 7.725814299419653e-08,
      "learning_rate": 1.4041962357297132e-05,
      "loss": 0.0001,
      "step": 116540
    },
    {
      "epoch": 35.961123110151185,
      "grad_norm": 0.0006061250460334122,
      "learning_rate": 1.4038876889848812e-05,
      "loss": 0.0,
      "step": 116550
    },
    {
      "epoch": 35.96420857759951,
      "grad_norm": 1.658083647271269e-06,
      "learning_rate": 1.4035791422400493e-05,
      "loss": 0.002,
      "step": 116560
    },
    {
      "epoch": 35.96729404504782,
      "grad_norm": 0.00032676098635420203,
      "learning_rate": 1.4032705954952177e-05,
      "loss": 0.0,
      "step": 116570
    },
    {
      "epoch": 35.970379512496145,
      "grad_norm": 6.22775178271695e-06,
      "learning_rate": 1.4029620487503858e-05,
      "loss": 0.0001,
      "step": 116580
    },
    {
      "epoch": 35.97346497994446,
      "grad_norm": 3.131711139303661e-07,
      "learning_rate": 1.4026535020055539e-05,
      "loss": 0.0,
      "step": 116590
    },
    {
      "epoch": 35.97655044739278,
      "grad_norm": 2.6888494630838977e-06,
      "learning_rate": 1.4023449552607221e-05,
      "loss": 0.0,
      "step": 116600
    },
    {
      "epoch": 35.9796359148411,
      "grad_norm": 1.0981534614984412e-06,
      "learning_rate": 1.4020364085158902e-05,
      "loss": 0.0,
      "step": 116610
    },
    {
      "epoch": 35.98272138228942,
      "grad_norm": 0.001233190530911088,
      "learning_rate": 1.4017278617710583e-05,
      "loss": 0.0,
      "step": 116620
    },
    {
      "epoch": 35.985806849737735,
      "grad_norm": 2.778587486318429e-06,
      "learning_rate": 1.4014193150262264e-05,
      "loss": 0.0012,
      "step": 116630
    },
    {
      "epoch": 35.98889231718606,
      "grad_norm": 2.1776384073746158e-06,
      "learning_rate": 1.4011107682813948e-05,
      "loss": 0.0,
      "step": 116640
    },
    {
      "epoch": 35.99197778463437,
      "grad_norm": 2.635740202094894e-05,
      "learning_rate": 1.4008022215365629e-05,
      "loss": 0.0039,
      "step": 116650
    },
    {
      "epoch": 35.99506325208269,
      "grad_norm": 0.00025054055731743574,
      "learning_rate": 1.4004936747917311e-05,
      "loss": 0.0,
      "step": 116660
    },
    {
      "epoch": 35.99814871953101,
      "grad_norm": 9.169091754301917e-06,
      "learning_rate": 1.4001851280468992e-05,
      "loss": 0.0064,
      "step": 116670
    },
    {
      "epoch": 36.0,
      "eval_accuracy_branch1": 0.9999131969561066,
      "eval_accuracy_branch2": 0.38399737661911787,
      "eval_f1_branch1": 0.9999222297139515,
      "eval_f1_branch2": 0.35899768028227536,
      "eval_loss": 7.320294389501214e-05,
      "eval_precision_branch1": 0.9999209187447241,
      "eval_precision_branch2": 0.5114611077509361,
      "eval_recall_branch1": 0.999923543017599,
      "eval_recall_branch2": 0.5060545123115651,
      "eval_runtime": 241.7231,
      "eval_samples_per_second": 428.933,
      "eval_steps_per_second": 53.619,
      "step": 116676
    },
    {
      "epoch": 36.001234186979325,
      "grad_norm": 1.4319849697130849e-06,
      "learning_rate": 1.3998765813020673e-05,
      "loss": 0.0,
      "step": 116680
    },
    {
      "epoch": 36.00431965442765,
      "grad_norm": 0.00013153038162272424,
      "learning_rate": 1.3995680345572354e-05,
      "loss": 0.0011,
      "step": 116690
    },
    {
      "epoch": 36.00740512187596,
      "grad_norm": 6.8594781623687595e-06,
      "learning_rate": 1.3992594878124034e-05,
      "loss": 0.005,
      "step": 116700
    },
    {
      "epoch": 36.010490589324284,
      "grad_norm": 9.377542301081121e-05,
      "learning_rate": 1.3989509410675719e-05,
      "loss": 0.0,
      "step": 116710
    },
    {
      "epoch": 36.0135760567726,
      "grad_norm": 5.9321155276848e-06,
      "learning_rate": 1.3986423943227401e-05,
      "loss": 0.0,
      "step": 116720
    },
    {
      "epoch": 36.01666152422092,
      "grad_norm": 0.00014937392552383244,
      "learning_rate": 1.3983338475779082e-05,
      "loss": 0.0002,
      "step": 116730
    },
    {
      "epoch": 36.01974699166924,
      "grad_norm": 0.009560633450746536,
      "learning_rate": 1.3980253008330763e-05,
      "loss": 0.0,
      "step": 116740
    },
    {
      "epoch": 36.02283245911756,
      "grad_norm": 5.803583007946145e-06,
      "learning_rate": 1.3977167540882443e-05,
      "loss": 0.0115,
      "step": 116750
    },
    {
      "epoch": 36.025917926565874,
      "grad_norm": 6.676561952190241e-07,
      "learning_rate": 1.3974082073434124e-05,
      "loss": 0.0,
      "step": 116760
    },
    {
      "epoch": 36.02900339401419,
      "grad_norm": 2.0115909137530252e-05,
      "learning_rate": 1.3970996605985808e-05,
      "loss": 0.0,
      "step": 116770
    },
    {
      "epoch": 36.03208886146251,
      "grad_norm": 1.5944760889397003e-06,
      "learning_rate": 1.396791113853749e-05,
      "loss": 0.0002,
      "step": 116780
    },
    {
      "epoch": 36.03517432891083,
      "grad_norm": 2.7076575861428864e-06,
      "learning_rate": 1.3964825671089172e-05,
      "loss": 0.0001,
      "step": 116790
    },
    {
      "epoch": 36.03825979635915,
      "grad_norm": 0.026320643723011017,
      "learning_rate": 1.3961740203640852e-05,
      "loss": 0.0,
      "step": 116800
    },
    {
      "epoch": 36.041345263807465,
      "grad_norm": 0.000630463007837534,
      "learning_rate": 1.3958654736192533e-05,
      "loss": 0.0,
      "step": 116810
    },
    {
      "epoch": 36.04443073125579,
      "grad_norm": 1.877910449366027e-08,
      "learning_rate": 1.3955569268744214e-05,
      "loss": 0.0001,
      "step": 116820
    },
    {
      "epoch": 36.0475161987041,
      "grad_norm": 1.5726607671240345e-05,
      "learning_rate": 1.3952483801295896e-05,
      "loss": 0.0,
      "step": 116830
    },
    {
      "epoch": 36.050601666152424,
      "grad_norm": 0.000693118607159704,
      "learning_rate": 1.394939833384758e-05,
      "loss": 0.0002,
      "step": 116840
    },
    {
      "epoch": 36.05368713360074,
      "grad_norm": 5.924364359088941e-07,
      "learning_rate": 1.3946312866399261e-05,
      "loss": 0.0,
      "step": 116850
    },
    {
      "epoch": 36.05677260104906,
      "grad_norm": 5.298255928209983e-06,
      "learning_rate": 1.3943227398950942e-05,
      "loss": 0.0,
      "step": 116860
    },
    {
      "epoch": 36.05985806849738,
      "grad_norm": 3.281896283624519e-07,
      "learning_rate": 1.3940141931502623e-05,
      "loss": 0.0001,
      "step": 116870
    },
    {
      "epoch": 36.0629435359457,
      "grad_norm": 1.0533621974673224e-08,
      "learning_rate": 1.3937056464054304e-05,
      "loss": 0.0039,
      "step": 116880
    },
    {
      "epoch": 36.066029003394014,
      "grad_norm": 6.236645276658237e-05,
      "learning_rate": 1.3933970996605986e-05,
      "loss": 0.0,
      "step": 116890
    },
    {
      "epoch": 36.06911447084233,
      "grad_norm": 2.3754164857336946e-08,
      "learning_rate": 1.3930885529157667e-05,
      "loss": 0.0,
      "step": 116900
    },
    {
      "epoch": 36.07219993829065,
      "grad_norm": 1.657310377822796e-08,
      "learning_rate": 1.3927800061709351e-05,
      "loss": 0.0,
      "step": 116910
    },
    {
      "epoch": 36.07528540573897,
      "grad_norm": 1.893357875815127e-05,
      "learning_rate": 1.3924714594261032e-05,
      "loss": 0.0,
      "step": 116920
    },
    {
      "epoch": 36.07837087318729,
      "grad_norm": 9.238738130079582e-06,
      "learning_rate": 1.3921629126812713e-05,
      "loss": 0.0,
      "step": 116930
    },
    {
      "epoch": 36.081456340635604,
      "grad_norm": 0.00012631609570235014,
      "learning_rate": 1.3918543659364393e-05,
      "loss": 0.0,
      "step": 116940
    },
    {
      "epoch": 36.08454180808393,
      "grad_norm": 2.4720575311221182e-05,
      "learning_rate": 1.3915458191916076e-05,
      "loss": 0.0,
      "step": 116950
    },
    {
      "epoch": 36.08762727553224,
      "grad_norm": 0.0005761434440501034,
      "learning_rate": 1.3912372724467757e-05,
      "loss": 0.0,
      "step": 116960
    },
    {
      "epoch": 36.090712742980564,
      "grad_norm": 0.0002863860863726586,
      "learning_rate": 1.3909287257019441e-05,
      "loss": 0.0,
      "step": 116970
    },
    {
      "epoch": 36.09379821042888,
      "grad_norm": 1.69298027685727e-06,
      "learning_rate": 1.3906201789571122e-05,
      "loss": 0.0,
      "step": 116980
    },
    {
      "epoch": 36.0968836778772,
      "grad_norm": 0.1379726231098175,
      "learning_rate": 1.3903116322122802e-05,
      "loss": 0.0,
      "step": 116990
    },
    {
      "epoch": 36.09996914532552,
      "grad_norm": 0.000998093979433179,
      "learning_rate": 1.3900030854674483e-05,
      "loss": 0.0,
      "step": 117000
    },
    {
      "epoch": 36.10305461277383,
      "grad_norm": 1.1199666005268227e-05,
      "learning_rate": 1.3896945387226166e-05,
      "loss": 0.0015,
      "step": 117010
    },
    {
      "epoch": 36.106140080222154,
      "grad_norm": 1.1751812053262256e-05,
      "learning_rate": 1.3893859919777847e-05,
      "loss": 0.0,
      "step": 117020
    },
    {
      "epoch": 36.10922554767047,
      "grad_norm": 3.191586017692316e-07,
      "learning_rate": 1.3890774452329527e-05,
      "loss": 0.0,
      "step": 117030
    },
    {
      "epoch": 36.11231101511879,
      "grad_norm": 6.492687680292875e-05,
      "learning_rate": 1.3887688984881211e-05,
      "loss": 0.0,
      "step": 117040
    },
    {
      "epoch": 36.11539648256711,
      "grad_norm": 1.0119634680449963e-05,
      "learning_rate": 1.3884603517432892e-05,
      "loss": 0.0001,
      "step": 117050
    },
    {
      "epoch": 36.11848195001543,
      "grad_norm": 0.0003440363216213882,
      "learning_rate": 1.3881518049984573e-05,
      "loss": 0.0,
      "step": 117060
    },
    {
      "epoch": 36.121567417463744,
      "grad_norm": 9.198646148433909e-05,
      "learning_rate": 1.3878432582536256e-05,
      "loss": 0.0,
      "step": 117070
    },
    {
      "epoch": 36.12465288491207,
      "grad_norm": 6.0992606449872255e-05,
      "learning_rate": 1.3875347115087936e-05,
      "loss": 0.0,
      "step": 117080
    },
    {
      "epoch": 36.12773835236038,
      "grad_norm": 5.076037996332161e-05,
      "learning_rate": 1.3872261647639617e-05,
      "loss": 0.0,
      "step": 117090
    },
    {
      "epoch": 36.130823819808704,
      "grad_norm": 1.7760481568984687e-05,
      "learning_rate": 1.3869176180191298e-05,
      "loss": 0.0,
      "step": 117100
    },
    {
      "epoch": 36.13390928725702,
      "grad_norm": 4.09478998335544e-05,
      "learning_rate": 1.3866090712742982e-05,
      "loss": 0.0,
      "step": 117110
    },
    {
      "epoch": 36.13699475470534,
      "grad_norm": 0.01616683416068554,
      "learning_rate": 1.3863005245294663e-05,
      "loss": 0.0,
      "step": 117120
    },
    {
      "epoch": 36.14008022215366,
      "grad_norm": 1.449222281735274e-06,
      "learning_rate": 1.3859919777846345e-05,
      "loss": 0.0,
      "step": 117130
    },
    {
      "epoch": 36.14316568960197,
      "grad_norm": 2.4683065930730663e-05,
      "learning_rate": 1.3856834310398026e-05,
      "loss": 0.0003,
      "step": 117140
    },
    {
      "epoch": 36.146251157050294,
      "grad_norm": 0.0005238698795437813,
      "learning_rate": 1.3853748842949707e-05,
      "loss": 0.0001,
      "step": 117150
    },
    {
      "epoch": 36.14933662449861,
      "grad_norm": 1.8453130905982107e-05,
      "learning_rate": 1.3850663375501388e-05,
      "loss": 0.0003,
      "step": 117160
    },
    {
      "epoch": 36.15242209194693,
      "grad_norm": 2.3314933628171275e-07,
      "learning_rate": 1.3847577908053072e-05,
      "loss": 0.0,
      "step": 117170
    },
    {
      "epoch": 36.15550755939525,
      "grad_norm": 0.011722586117684841,
      "learning_rate": 1.3844492440604753e-05,
      "loss": 0.0023,
      "step": 117180
    },
    {
      "epoch": 36.15859302684357,
      "grad_norm": 0.00019906696979887784,
      "learning_rate": 1.3841406973156435e-05,
      "loss": 0.0007,
      "step": 117190
    },
    {
      "epoch": 36.161678494291884,
      "grad_norm": 6.457835866058304e-07,
      "learning_rate": 1.3838321505708116e-05,
      "loss": 0.0,
      "step": 117200
    },
    {
      "epoch": 36.164763961740206,
      "grad_norm": 3.848625055979937e-06,
      "learning_rate": 1.3835236038259797e-05,
      "loss": 0.0,
      "step": 117210
    },
    {
      "epoch": 36.16784942918852,
      "grad_norm": 0.02987942099571228,
      "learning_rate": 1.3832150570811477e-05,
      "loss": 0.0,
      "step": 117220
    },
    {
      "epoch": 36.170934896636844,
      "grad_norm": 6.500130984932184e-05,
      "learning_rate": 1.382906510336316e-05,
      "loss": 0.0,
      "step": 117230
    },
    {
      "epoch": 36.17402036408516,
      "grad_norm": 0.0004901533247902989,
      "learning_rate": 1.3825979635914842e-05,
      "loss": 0.0,
      "step": 117240
    },
    {
      "epoch": 36.177105831533474,
      "grad_norm": 3.517879179071315e-07,
      "learning_rate": 1.3822894168466525e-05,
      "loss": 0.0,
      "step": 117250
    },
    {
      "epoch": 36.180191298981796,
      "grad_norm": 0.00154660374391824,
      "learning_rate": 1.3819808701018206e-05,
      "loss": 0.0,
      "step": 117260
    },
    {
      "epoch": 36.18327676643011,
      "grad_norm": 1.3665456208400428e-05,
      "learning_rate": 1.3816723233569886e-05,
      "loss": 0.0,
      "step": 117270
    },
    {
      "epoch": 36.186362233878434,
      "grad_norm": 1.8950247977045365e-05,
      "learning_rate": 1.3813637766121567e-05,
      "loss": 0.0,
      "step": 117280
    },
    {
      "epoch": 36.18944770132675,
      "grad_norm": 0.021742934361100197,
      "learning_rate": 1.381055229867325e-05,
      "loss": 0.0,
      "step": 117290
    },
    {
      "epoch": 36.19253316877507,
      "grad_norm": 2.003496774705127e-06,
      "learning_rate": 1.380746683122493e-05,
      "loss": 0.0001,
      "step": 117300
    },
    {
      "epoch": 36.19561863622339,
      "grad_norm": 2.5056133381440304e-06,
      "learning_rate": 1.3804381363776615e-05,
      "loss": 0.0,
      "step": 117310
    },
    {
      "epoch": 36.19870410367171,
      "grad_norm": 1.2553149417726672e-06,
      "learning_rate": 1.3801295896328295e-05,
      "loss": 0.0,
      "step": 117320
    },
    {
      "epoch": 36.201789571120024,
      "grad_norm": 5.51809023363603e-07,
      "learning_rate": 1.3798210428879976e-05,
      "loss": 0.0,
      "step": 117330
    },
    {
      "epoch": 36.204875038568346,
      "grad_norm": 8.170391083694994e-05,
      "learning_rate": 1.3795124961431657e-05,
      "loss": 0.0,
      "step": 117340
    },
    {
      "epoch": 36.20796050601666,
      "grad_norm": 6.334023794352106e-08,
      "learning_rate": 1.379203949398334e-05,
      "loss": 0.0,
      "step": 117350
    },
    {
      "epoch": 36.21104597346498,
      "grad_norm": 1.3244739420770202e-05,
      "learning_rate": 1.378895402653502e-05,
      "loss": 0.0031,
      "step": 117360
    },
    {
      "epoch": 36.2141314409133,
      "grad_norm": 0.001965997973456979,
      "learning_rate": 1.3785868559086701e-05,
      "loss": 0.0,
      "step": 117370
    },
    {
      "epoch": 36.217216908361614,
      "grad_norm": 1.5260313830367522e-06,
      "learning_rate": 1.3782783091638385e-05,
      "loss": 0.0002,
      "step": 117380
    },
    {
      "epoch": 36.220302375809936,
      "grad_norm": 4.024587383355538e-07,
      "learning_rate": 1.3779697624190066e-05,
      "loss": 0.0,
      "step": 117390
    },
    {
      "epoch": 36.22338784325825,
      "grad_norm": 8.086051821010187e-06,
      "learning_rate": 1.3776612156741747e-05,
      "loss": 0.0,
      "step": 117400
    },
    {
      "epoch": 36.226473310706574,
      "grad_norm": 0.00012063897156622261,
      "learning_rate": 1.3773526689293428e-05,
      "loss": 0.0,
      "step": 117410
    },
    {
      "epoch": 36.22955877815489,
      "grad_norm": 3.655071978414526e-08,
      "learning_rate": 1.377044122184511e-05,
      "loss": 0.0,
      "step": 117420
    },
    {
      "epoch": 36.23264424560321,
      "grad_norm": 2.407051908903668e-07,
      "learning_rate": 1.376735575439679e-05,
      "loss": 0.0,
      "step": 117430
    },
    {
      "epoch": 36.235729713051526,
      "grad_norm": 2.7376891011954285e-06,
      "learning_rate": 1.3764270286948475e-05,
      "loss": 0.0,
      "step": 117440
    },
    {
      "epoch": 36.23881518049985,
      "grad_norm": 1.9243672795710154e-05,
      "learning_rate": 1.3761184819500156e-05,
      "loss": 0.0,
      "step": 117450
    },
    {
      "epoch": 36.241900647948164,
      "grad_norm": 5.1084432925563306e-05,
      "learning_rate": 1.3758099352051837e-05,
      "loss": 0.0,
      "step": 117460
    },
    {
      "epoch": 36.244986115396486,
      "grad_norm": 4.003232731975004e-07,
      "learning_rate": 1.3755013884603517e-05,
      "loss": 0.0037,
      "step": 117470
    },
    {
      "epoch": 36.2480715828448,
      "grad_norm": 8.266489999186888e-07,
      "learning_rate": 1.37519284171552e-05,
      "loss": 0.0,
      "step": 117480
    },
    {
      "epoch": 36.251157050293116,
      "grad_norm": 5.0236962124472484e-05,
      "learning_rate": 1.374884294970688e-05,
      "loss": 0.0,
      "step": 117490
    },
    {
      "epoch": 36.25424251774144,
      "grad_norm": 7.120148893591249e-06,
      "learning_rate": 1.3745757482258561e-05,
      "loss": 0.0,
      "step": 117500
    },
    {
      "epoch": 36.257327985189754,
      "grad_norm": 0.0027567606884986162,
      "learning_rate": 1.3742672014810246e-05,
      "loss": 0.0,
      "step": 117510
    },
    {
      "epoch": 36.260413452638076,
      "grad_norm": 0.0027658450417220592,
      "learning_rate": 1.3739586547361926e-05,
      "loss": 0.0001,
      "step": 117520
    },
    {
      "epoch": 36.26349892008639,
      "grad_norm": 0.0007315051625482738,
      "learning_rate": 1.3736501079913607e-05,
      "loss": 0.0001,
      "step": 117530
    },
    {
      "epoch": 36.266584387534714,
      "grad_norm": 1.002933186100563e-05,
      "learning_rate": 1.373341561246529e-05,
      "loss": 0.0,
      "step": 117540
    },
    {
      "epoch": 36.26966985498303,
      "grad_norm": 4.4029566197423264e-05,
      "learning_rate": 1.373033014501697e-05,
      "loss": 0.0001,
      "step": 117550
    },
    {
      "epoch": 36.27275532243135,
      "grad_norm": 5.308621098265576e-07,
      "learning_rate": 1.3727244677568651e-05,
      "loss": 0.0,
      "step": 117560
    },
    {
      "epoch": 36.275840789879666,
      "grad_norm": 6.355916752909252e-07,
      "learning_rate": 1.3724159210120332e-05,
      "loss": 0.0,
      "step": 117570
    },
    {
      "epoch": 36.27892625732799,
      "grad_norm": 2.6473654202163743e-07,
      "learning_rate": 1.3721073742672016e-05,
      "loss": 0.0,
      "step": 117580
    },
    {
      "epoch": 36.282011724776304,
      "grad_norm": 2.1791327071696287e-06,
      "learning_rate": 1.3717988275223697e-05,
      "loss": 0.0,
      "step": 117590
    },
    {
      "epoch": 36.28509719222462,
      "grad_norm": 1.398677341057919e-06,
      "learning_rate": 1.371490280777538e-05,
      "loss": 0.0,
      "step": 117600
    },
    {
      "epoch": 36.28818265967294,
      "grad_norm": 4.710753637482412e-05,
      "learning_rate": 1.371181734032706e-05,
      "loss": 0.0,
      "step": 117610
    },
    {
      "epoch": 36.291268127121256,
      "grad_norm": 2.574507789177005e-06,
      "learning_rate": 1.3708731872878741e-05,
      "loss": 0.0,
      "step": 117620
    },
    {
      "epoch": 36.29435359456958,
      "grad_norm": 1.259419263988093e-06,
      "learning_rate": 1.3705646405430422e-05,
      "loss": 0.0,
      "step": 117630
    },
    {
      "epoch": 36.297439062017894,
      "grad_norm": 4.763904507854022e-05,
      "learning_rate": 1.3702560937982106e-05,
      "loss": 0.0,
      "step": 117640
    },
    {
      "epoch": 36.300524529466216,
      "grad_norm": 5.202973625273444e-05,
      "learning_rate": 1.3699475470533787e-05,
      "loss": 0.0,
      "step": 117650
    },
    {
      "epoch": 36.30360999691453,
      "grad_norm": 0.0033539014402776957,
      "learning_rate": 1.3696390003085469e-05,
      "loss": 0.0001,
      "step": 117660
    },
    {
      "epoch": 36.30669546436285,
      "grad_norm": 0.00027494144160300493,
      "learning_rate": 1.369330453563715e-05,
      "loss": 0.0,
      "step": 117670
    },
    {
      "epoch": 36.30978093181117,
      "grad_norm": 1.0612815231070272e-06,
      "learning_rate": 1.369021906818883e-05,
      "loss": 0.0,
      "step": 117680
    },
    {
      "epoch": 36.31286639925949,
      "grad_norm": 1.2287960089452099e-05,
      "learning_rate": 1.3687133600740511e-05,
      "loss": 0.0,
      "step": 117690
    },
    {
      "epoch": 36.315951866707806,
      "grad_norm": 5.996465915814042e-06,
      "learning_rate": 1.3684048133292194e-05,
      "loss": 0.0,
      "step": 117700
    },
    {
      "epoch": 36.31903733415612,
      "grad_norm": 0.0001987231516977772,
      "learning_rate": 1.3680962665843876e-05,
      "loss": 0.0,
      "step": 117710
    },
    {
      "epoch": 36.32212280160444,
      "grad_norm": 0.0001490489230491221,
      "learning_rate": 1.3677877198395559e-05,
      "loss": 0.0,
      "step": 117720
    },
    {
      "epoch": 36.32520826905276,
      "grad_norm": 0.0035427697002887726,
      "learning_rate": 1.367479173094724e-05,
      "loss": 0.0,
      "step": 117730
    },
    {
      "epoch": 36.32829373650108,
      "grad_norm": 2.8290349973758566e-07,
      "learning_rate": 1.367170626349892e-05,
      "loss": 0.0,
      "step": 117740
    },
    {
      "epoch": 36.331379203949396,
      "grad_norm": 2.1854402803000994e-05,
      "learning_rate": 1.3668620796050601e-05,
      "loss": 0.0,
      "step": 117750
    },
    {
      "epoch": 36.33446467139772,
      "grad_norm": 0.0009651889558881521,
      "learning_rate": 1.3665535328602284e-05,
      "loss": 0.0,
      "step": 117760
    },
    {
      "epoch": 36.337550138846034,
      "grad_norm": 5.580251672654413e-05,
      "learning_rate": 1.3662449861153965e-05,
      "loss": 0.0,
      "step": 117770
    },
    {
      "epoch": 36.340635606294356,
      "grad_norm": 0.0003992013807874173,
      "learning_rate": 1.3659364393705649e-05,
      "loss": 0.0,
      "step": 117780
    },
    {
      "epoch": 36.34372107374267,
      "grad_norm": 4.174571586190723e-06,
      "learning_rate": 1.365627892625733e-05,
      "loss": 0.0,
      "step": 117790
    },
    {
      "epoch": 36.34680654119099,
      "grad_norm": 8.398214959015604e-06,
      "learning_rate": 1.365319345880901e-05,
      "loss": 0.0,
      "step": 117800
    },
    {
      "epoch": 36.34989200863931,
      "grad_norm": 2.9565238946815953e-05,
      "learning_rate": 1.3650107991360691e-05,
      "loss": 0.0,
      "step": 117810
    },
    {
      "epoch": 36.35297747608763,
      "grad_norm": 2.35514539781434e-06,
      "learning_rate": 1.3647022523912374e-05,
      "loss": 0.0,
      "step": 117820
    },
    {
      "epoch": 36.356062943535946,
      "grad_norm": 6.380764534696937e-05,
      "learning_rate": 1.3643937056464054e-05,
      "loss": 0.0,
      "step": 117830
    },
    {
      "epoch": 36.35914841098426,
      "grad_norm": 8.389564953859008e-08,
      "learning_rate": 1.3640851589015738e-05,
      "loss": 0.0,
      "step": 117840
    },
    {
      "epoch": 36.36223387843258,
      "grad_norm": 0.00027947669150307775,
      "learning_rate": 1.363776612156742e-05,
      "loss": 0.0001,
      "step": 117850
    },
    {
      "epoch": 36.3653193458809,
      "grad_norm": 9.235174366040155e-05,
      "learning_rate": 1.36346806541191e-05,
      "loss": 0.001,
      "step": 117860
    },
    {
      "epoch": 36.36840481332922,
      "grad_norm": 1.1307432714602328e-06,
      "learning_rate": 1.363159518667078e-05,
      "loss": 0.0,
      "step": 117870
    },
    {
      "epoch": 36.371490280777536,
      "grad_norm": 1.1327183528919704e-05,
      "learning_rate": 1.3628509719222463e-05,
      "loss": 0.0,
      "step": 117880
    },
    {
      "epoch": 36.37457574822586,
      "grad_norm": 4.834715809920453e-07,
      "learning_rate": 1.3625424251774144e-05,
      "loss": 0.0,
      "step": 117890
    },
    {
      "epoch": 36.37766121567417,
      "grad_norm": 4.635360528482124e-05,
      "learning_rate": 1.3622338784325825e-05,
      "loss": 0.0,
      "step": 117900
    },
    {
      "epoch": 36.380746683122496,
      "grad_norm": 1.0999094683938893e-06,
      "learning_rate": 1.3619253316877509e-05,
      "loss": 0.0005,
      "step": 117910
    },
    {
      "epoch": 36.38383215057081,
      "grad_norm": 0.21506789326667786,
      "learning_rate": 1.361616784942919e-05,
      "loss": 0.0001,
      "step": 117920
    },
    {
      "epoch": 36.38691761801913,
      "grad_norm": 0.0005245141219347715,
      "learning_rate": 1.361308238198087e-05,
      "loss": 0.0,
      "step": 117930
    },
    {
      "epoch": 36.39000308546745,
      "grad_norm": 9.713164035929367e-05,
      "learning_rate": 1.3609996914532553e-05,
      "loss": 0.0,
      "step": 117940
    },
    {
      "epoch": 36.39308855291576,
      "grad_norm": 0.00017524880240671337,
      "learning_rate": 1.3606911447084234e-05,
      "loss": 0.0,
      "step": 117950
    },
    {
      "epoch": 36.396174020364086,
      "grad_norm": 3.5247852792963386e-05,
      "learning_rate": 1.3603825979635915e-05,
      "loss": 0.0,
      "step": 117960
    },
    {
      "epoch": 36.3992594878124,
      "grad_norm": 0.00010877691238420084,
      "learning_rate": 1.3600740512187595e-05,
      "loss": 0.0001,
      "step": 117970
    },
    {
      "epoch": 36.40234495526072,
      "grad_norm": 0.0005949397454969585,
      "learning_rate": 1.359765504473928e-05,
      "loss": 0.0,
      "step": 117980
    },
    {
      "epoch": 36.40543042270904,
      "grad_norm": 1.7096585480658177e-08,
      "learning_rate": 1.359456957729096e-05,
      "loss": 0.0,
      "step": 117990
    },
    {
      "epoch": 36.40851589015736,
      "grad_norm": 0.008239949122071266,
      "learning_rate": 1.3591484109842643e-05,
      "loss": 0.0,
      "step": 118000
    },
    {
      "epoch": 36.411601357605676,
      "grad_norm": 1.5190792623798188e-08,
      "learning_rate": 1.3588398642394324e-05,
      "loss": 0.0005,
      "step": 118010
    },
    {
      "epoch": 36.414686825054,
      "grad_norm": 2.2559373036301622e-08,
      "learning_rate": 1.3585313174946004e-05,
      "loss": 0.0023,
      "step": 118020
    },
    {
      "epoch": 36.41777229250231,
      "grad_norm": 3.4911367947643157e-06,
      "learning_rate": 1.3582227707497685e-05,
      "loss": 0.0,
      "step": 118030
    },
    {
      "epoch": 36.420857759950636,
      "grad_norm": 0.00012680020881816745,
      "learning_rate": 1.3579142240049366e-05,
      "loss": 0.0001,
      "step": 118040
    },
    {
      "epoch": 36.42394322739895,
      "grad_norm": 8.78372975421371e-06,
      "learning_rate": 1.357605677260105e-05,
      "loss": 0.0,
      "step": 118050
    },
    {
      "epoch": 36.427028694847266,
      "grad_norm": 8.002474351087585e-05,
      "learning_rate": 1.3572971305152733e-05,
      "loss": 0.0,
      "step": 118060
    },
    {
      "epoch": 36.43011416229559,
      "grad_norm": 0.022507911548018456,
      "learning_rate": 1.3569885837704413e-05,
      "loss": 0.0,
      "step": 118070
    },
    {
      "epoch": 36.4331996297439,
      "grad_norm": 1.497256185700735e-08,
      "learning_rate": 1.3566800370256094e-05,
      "loss": 0.0014,
      "step": 118080
    },
    {
      "epoch": 36.436285097192226,
      "grad_norm": 3.0997371140983887e-06,
      "learning_rate": 1.3563714902807775e-05,
      "loss": 0.0005,
      "step": 118090
    },
    {
      "epoch": 36.43937056464054,
      "grad_norm": 4.692373750003753e-06,
      "learning_rate": 1.3560629435359456e-05,
      "loss": 0.0,
      "step": 118100
    },
    {
      "epoch": 36.44245603208886,
      "grad_norm": 2.9840726710972376e-05,
      "learning_rate": 1.355754396791114e-05,
      "loss": 0.0,
      "step": 118110
    },
    {
      "epoch": 36.44554149953718,
      "grad_norm": 0.9974497556686401,
      "learning_rate": 1.3554458500462822e-05,
      "loss": 0.0004,
      "step": 118120
    },
    {
      "epoch": 36.4486269669855,
      "grad_norm": 4.800638271262869e-05,
      "learning_rate": 1.3551373033014503e-05,
      "loss": 0.0,
      "step": 118130
    },
    {
      "epoch": 36.451712434433816,
      "grad_norm": 9.524317283648998e-05,
      "learning_rate": 1.3548287565566184e-05,
      "loss": 0.0,
      "step": 118140
    },
    {
      "epoch": 36.45479790188214,
      "grad_norm": 3.843277909254539e-07,
      "learning_rate": 1.3545202098117865e-05,
      "loss": 0.0,
      "step": 118150
    },
    {
      "epoch": 36.45788336933045,
      "grad_norm": 1.9801679229658475e-07,
      "learning_rate": 1.3542116630669546e-05,
      "loss": 0.0,
      "step": 118160
    },
    {
      "epoch": 36.460968836778775,
      "grad_norm": 2.800094591748348e-07,
      "learning_rate": 1.3539031163221228e-05,
      "loss": 0.0,
      "step": 118170
    },
    {
      "epoch": 36.46405430422709,
      "grad_norm": 8.576898835599422e-05,
      "learning_rate": 1.3535945695772912e-05,
      "loss": 0.0,
      "step": 118180
    },
    {
      "epoch": 36.467139771675406,
      "grad_norm": 0.001559551921673119,
      "learning_rate": 1.3532860228324593e-05,
      "loss": 0.0,
      "step": 118190
    },
    {
      "epoch": 36.47022523912373,
      "grad_norm": 5.834795501868939e-06,
      "learning_rate": 1.3529774760876274e-05,
      "loss": 0.0003,
      "step": 118200
    },
    {
      "epoch": 36.47331070657204,
      "grad_norm": 0.0008207597420550883,
      "learning_rate": 1.3526689293427955e-05,
      "loss": 0.0,
      "step": 118210
    },
    {
      "epoch": 36.476396174020365,
      "grad_norm": 1.3483086149790324e-06,
      "learning_rate": 1.3523603825979635e-05,
      "loss": 0.0007,
      "step": 118220
    },
    {
      "epoch": 36.47948164146868,
      "grad_norm": 3.3974561119975988e-06,
      "learning_rate": 1.3520518358531318e-05,
      "loss": 0.0,
      "step": 118230
    },
    {
      "epoch": 36.482567108917,
      "grad_norm": 0.006715929135680199,
      "learning_rate": 1.3517432891082999e-05,
      "loss": 0.0006,
      "step": 118240
    },
    {
      "epoch": 36.48565257636532,
      "grad_norm": 1.772288203239441,
      "learning_rate": 1.3514347423634683e-05,
      "loss": 0.001,
      "step": 118250
    },
    {
      "epoch": 36.48873804381364,
      "grad_norm": 0.0007609386811964214,
      "learning_rate": 1.3511261956186364e-05,
      "loss": 0.0011,
      "step": 118260
    },
    {
      "epoch": 36.491823511261956,
      "grad_norm": 1.8998069890585612e-06,
      "learning_rate": 1.3508176488738044e-05,
      "loss": 0.0026,
      "step": 118270
    },
    {
      "epoch": 36.49490897871028,
      "grad_norm": 2.597810180304805e-07,
      "learning_rate": 1.3505091021289725e-05,
      "loss": 0.0,
      "step": 118280
    },
    {
      "epoch": 36.49799444615859,
      "grad_norm": 0.1486104428768158,
      "learning_rate": 1.3502005553841408e-05,
      "loss": 0.0002,
      "step": 118290
    },
    {
      "epoch": 36.50107991360691,
      "grad_norm": 0.07022655755281448,
      "learning_rate": 1.3498920086393088e-05,
      "loss": 0.0,
      "step": 118300
    },
    {
      "epoch": 36.50416538105523,
      "grad_norm": 3.980842393502826e-06,
      "learning_rate": 1.3495834618944773e-05,
      "loss": 0.0001,
      "step": 118310
    },
    {
      "epoch": 36.507250848503546,
      "grad_norm": 1.147204216067621e-06,
      "learning_rate": 1.3492749151496453e-05,
      "loss": 0.0,
      "step": 118320
    },
    {
      "epoch": 36.51033631595187,
      "grad_norm": 0.0033569184597581625,
      "learning_rate": 1.3489663684048134e-05,
      "loss": 0.0,
      "step": 118330
    },
    {
      "epoch": 36.51342178340018,
      "grad_norm": 1.676129068073351e-05,
      "learning_rate": 1.3486578216599815e-05,
      "loss": 0.0001,
      "step": 118340
    },
    {
      "epoch": 36.516507250848505,
      "grad_norm": 0.0011861699167639017,
      "learning_rate": 1.3483492749151497e-05,
      "loss": 0.0012,
      "step": 118350
    },
    {
      "epoch": 36.51959271829682,
      "grad_norm": 5.901320037082769e-07,
      "learning_rate": 1.3480407281703178e-05,
      "loss": 0.0,
      "step": 118360
    },
    {
      "epoch": 36.52267818574514,
      "grad_norm": 4.943031308357604e-05,
      "learning_rate": 1.3477321814254859e-05,
      "loss": 0.0,
      "step": 118370
    },
    {
      "epoch": 36.52576365319346,
      "grad_norm": 0.00046373673831112683,
      "learning_rate": 1.3474236346806543e-05,
      "loss": 0.0,
      "step": 118380
    },
    {
      "epoch": 36.52884912064178,
      "grad_norm": 0.344623863697052,
      "learning_rate": 1.3471150879358224e-05,
      "loss": 0.0001,
      "step": 118390
    },
    {
      "epoch": 36.531934588090095,
      "grad_norm": 0.0015373285859823227,
      "learning_rate": 1.3468065411909905e-05,
      "loss": 0.0,
      "step": 118400
    },
    {
      "epoch": 36.53502005553841,
      "grad_norm": 0.00011167734191985801,
      "learning_rate": 1.3464979944461587e-05,
      "loss": 0.0,
      "step": 118410
    },
    {
      "epoch": 36.53810552298673,
      "grad_norm": 0.0002931574999820441,
      "learning_rate": 1.3461894477013268e-05,
      "loss": 0.0008,
      "step": 118420
    },
    {
      "epoch": 36.54119099043505,
      "grad_norm": 0.00011749303666874766,
      "learning_rate": 1.3458809009564949e-05,
      "loss": 0.0,
      "step": 118430
    },
    {
      "epoch": 36.54427645788337,
      "grad_norm": 4.291831828595605e-06,
      "learning_rate": 1.345572354211663e-05,
      "loss": 0.0,
      "step": 118440
    },
    {
      "epoch": 36.547361925331685,
      "grad_norm": 1.56152145791566e-05,
      "learning_rate": 1.3452638074668314e-05,
      "loss": 0.0001,
      "step": 118450
    },
    {
      "epoch": 36.55044739278001,
      "grad_norm": 0.00017486164870206267,
      "learning_rate": 1.3449552607219994e-05,
      "loss": 0.0,
      "step": 118460
    },
    {
      "epoch": 36.55353286022832,
      "grad_norm": 0.008025013841688633,
      "learning_rate": 1.3446467139771677e-05,
      "loss": 0.0001,
      "step": 118470
    },
    {
      "epoch": 36.556618327676645,
      "grad_norm": 2.5243195977964206e-07,
      "learning_rate": 1.3443381672323358e-05,
      "loss": 0.0,
      "step": 118480
    },
    {
      "epoch": 36.55970379512496,
      "grad_norm": 6.332732027658494e-06,
      "learning_rate": 1.3440296204875038e-05,
      "loss": 0.0,
      "step": 118490
    },
    {
      "epoch": 36.56278926257328,
      "grad_norm": 3.535275709509733e-06,
      "learning_rate": 1.343721073742672e-05,
      "loss": 0.0,
      "step": 118500
    },
    {
      "epoch": 36.5658747300216,
      "grad_norm": 7.335602845159883e-07,
      "learning_rate": 1.3434125269978403e-05,
      "loss": 0.0,
      "step": 118510
    },
    {
      "epoch": 36.56896019746992,
      "grad_norm": 4.7480511966568884e-07,
      "learning_rate": 1.3431039802530084e-05,
      "loss": 0.0001,
      "step": 118520
    },
    {
      "epoch": 36.572045664918235,
      "grad_norm": 9.819254955800716e-07,
      "learning_rate": 1.3427954335081767e-05,
      "loss": 0.0,
      "step": 118530
    },
    {
      "epoch": 36.57513113236655,
      "grad_norm": 0.00014075209037400782,
      "learning_rate": 1.3424868867633447e-05,
      "loss": 0.0,
      "step": 118540
    },
    {
      "epoch": 36.57821659981487,
      "grad_norm": 7.183027150858834e-07,
      "learning_rate": 1.3421783400185128e-05,
      "loss": 0.0,
      "step": 118550
    },
    {
      "epoch": 36.58130206726319,
      "grad_norm": 0.0003718516672961414,
      "learning_rate": 1.3418697932736809e-05,
      "loss": 0.0001,
      "step": 118560
    },
    {
      "epoch": 36.58438753471151,
      "grad_norm": 5.058188435214106e-06,
      "learning_rate": 1.3415612465288492e-05,
      "loss": 0.0,
      "step": 118570
    },
    {
      "epoch": 36.587473002159825,
      "grad_norm": 0.00019402719044592232,
      "learning_rate": 1.3412526997840174e-05,
      "loss": 0.0001,
      "step": 118580
    },
    {
      "epoch": 36.59055846960815,
      "grad_norm": 0.00018986246141139418,
      "learning_rate": 1.3409441530391856e-05,
      "loss": 0.0001,
      "step": 118590
    },
    {
      "epoch": 36.59364393705646,
      "grad_norm": 2.876411599572748e-06,
      "learning_rate": 1.3406356062943537e-05,
      "loss": 0.0,
      "step": 118600
    },
    {
      "epoch": 36.596729404504785,
      "grad_norm": 1.6171940231402004e-08,
      "learning_rate": 1.3403270595495218e-05,
      "loss": 0.0,
      "step": 118610
    },
    {
      "epoch": 36.5998148719531,
      "grad_norm": 2.772252321243286,
      "learning_rate": 1.3400185128046899e-05,
      "loss": 0.0014,
      "step": 118620
    },
    {
      "epoch": 36.60290033940142,
      "grad_norm": 2.138134277629433e-06,
      "learning_rate": 1.3397099660598581e-05,
      "loss": 0.0,
      "step": 118630
    },
    {
      "epoch": 36.60598580684974,
      "grad_norm": 1.1230037344489574e-08,
      "learning_rate": 1.3394014193150262e-05,
      "loss": 0.0,
      "step": 118640
    },
    {
      "epoch": 36.60907127429805,
      "grad_norm": 9.689867511042394e-06,
      "learning_rate": 1.3390928725701946e-05,
      "loss": 0.0,
      "step": 118650
    },
    {
      "epoch": 36.612156741746375,
      "grad_norm": 4.4320998426883307e-07,
      "learning_rate": 1.3387843258253627e-05,
      "loss": 0.0,
      "step": 118660
    },
    {
      "epoch": 36.61524220919469,
      "grad_norm": 7.919637141640123e-07,
      "learning_rate": 1.3384757790805308e-05,
      "loss": 0.0,
      "step": 118670
    },
    {
      "epoch": 36.61832767664301,
      "grad_norm": 7.0077189775474835e-06,
      "learning_rate": 1.3381672323356989e-05,
      "loss": 0.0002,
      "step": 118680
    },
    {
      "epoch": 36.62141314409133,
      "grad_norm": 2.71359476755606e-05,
      "learning_rate": 1.337858685590867e-05,
      "loss": 0.0005,
      "step": 118690
    },
    {
      "epoch": 36.62449861153965,
      "grad_norm": 1.2330189314013751e-08,
      "learning_rate": 1.3375501388460352e-05,
      "loss": 0.0,
      "step": 118700
    },
    {
      "epoch": 36.627584078987965,
      "grad_norm": 4.238042361492944e-09,
      "learning_rate": 1.3372415921012036e-05,
      "loss": 0.0,
      "step": 118710
    },
    {
      "epoch": 36.63066954643629,
      "grad_norm": 1.6650035377097083e-06,
      "learning_rate": 1.3369330453563717e-05,
      "loss": 0.0,
      "step": 118720
    },
    {
      "epoch": 36.6337550138846,
      "grad_norm": 7.66242101235548e-06,
      "learning_rate": 1.3366244986115398e-05,
      "loss": 0.0,
      "step": 118730
    },
    {
      "epoch": 36.636840481332925,
      "grad_norm": 2.230598056485178e-06,
      "learning_rate": 1.3363159518667078e-05,
      "loss": 0.0,
      "step": 118740
    },
    {
      "epoch": 36.63992594878124,
      "grad_norm": 0.0009857469704002142,
      "learning_rate": 1.336007405121876e-05,
      "loss": 0.0,
      "step": 118750
    },
    {
      "epoch": 36.643011416229555,
      "grad_norm": 0.0037539878394454718,
      "learning_rate": 1.3356988583770442e-05,
      "loss": 0.0,
      "step": 118760
    },
    {
      "epoch": 36.64609688367788,
      "grad_norm": 5.6235930969705805e-06,
      "learning_rate": 1.3353903116322122e-05,
      "loss": 0.0,
      "step": 118770
    },
    {
      "epoch": 36.64918235112619,
      "grad_norm": 8.074212382780388e-05,
      "learning_rate": 1.3350817648873807e-05,
      "loss": 0.0,
      "step": 118780
    },
    {
      "epoch": 36.652267818574515,
      "grad_norm": 3.3139508559543174e-06,
      "learning_rate": 1.3347732181425487e-05,
      "loss": 0.0,
      "step": 118790
    },
    {
      "epoch": 36.65535328602283,
      "grad_norm": 0.0001997808867599815,
      "learning_rate": 1.3344646713977168e-05,
      "loss": 0.0,
      "step": 118800
    },
    {
      "epoch": 36.65843875347115,
      "grad_norm": 2.108913213305641e-05,
      "learning_rate": 1.3341561246528849e-05,
      "loss": 0.0,
      "step": 118810
    },
    {
      "epoch": 36.66152422091947,
      "grad_norm": 6.783198386983713e-06,
      "learning_rate": 1.3338475779080531e-05,
      "loss": 0.0,
      "step": 118820
    },
    {
      "epoch": 36.66460968836779,
      "grad_norm": 4.312464056965837e-07,
      "learning_rate": 1.3335390311632212e-05,
      "loss": 0.0,
      "step": 118830
    },
    {
      "epoch": 36.667695155816105,
      "grad_norm": 0.0009482289315201342,
      "learning_rate": 1.3332304844183893e-05,
      "loss": 0.0,
      "step": 118840
    },
    {
      "epoch": 36.67078062326443,
      "grad_norm": 0.8261896967887878,
      "learning_rate": 1.3329219376735577e-05,
      "loss": 0.0005,
      "step": 118850
    },
    {
      "epoch": 36.67386609071274,
      "grad_norm": 0.0023244719486683607,
      "learning_rate": 1.3326133909287258e-05,
      "loss": 0.0,
      "step": 118860
    },
    {
      "epoch": 36.676951558161065,
      "grad_norm": 5.569274890149245e-06,
      "learning_rate": 1.3323048441838939e-05,
      "loss": 0.0,
      "step": 118870
    },
    {
      "epoch": 36.68003702560938,
      "grad_norm": 2.2029556845382103e-08,
      "learning_rate": 1.3319962974390621e-05,
      "loss": 0.0,
      "step": 118880
    },
    {
      "epoch": 36.683122493057695,
      "grad_norm": 3.2687862585589755e-06,
      "learning_rate": 1.3316877506942302e-05,
      "loss": 0.0,
      "step": 118890
    },
    {
      "epoch": 36.68620796050602,
      "grad_norm": 0.002907188842073083,
      "learning_rate": 1.3313792039493983e-05,
      "loss": 0.0,
      "step": 118900
    },
    {
      "epoch": 36.68929342795433,
      "grad_norm": 3.486844798317179e-05,
      "learning_rate": 1.3310706572045664e-05,
      "loss": 0.0,
      "step": 118910
    },
    {
      "epoch": 36.692378895402655,
      "grad_norm": 6.243693860596977e-06,
      "learning_rate": 1.3307621104597348e-05,
      "loss": 0.0,
      "step": 118920
    },
    {
      "epoch": 36.69546436285097,
      "grad_norm": 1.6257028619293123e-05,
      "learning_rate": 1.3304535637149029e-05,
      "loss": 0.0001,
      "step": 118930
    },
    {
      "epoch": 36.69854983029929,
      "grad_norm": 0.07634376734495163,
      "learning_rate": 1.3301450169700711e-05,
      "loss": 0.0,
      "step": 118940
    },
    {
      "epoch": 36.70163529774761,
      "grad_norm": 0.0019150413572788239,
      "learning_rate": 1.3298364702252392e-05,
      "loss": 0.0,
      "step": 118950
    },
    {
      "epoch": 36.70472076519593,
      "grad_norm": 0.0005827799905091524,
      "learning_rate": 1.3295279234804073e-05,
      "loss": 0.0,
      "step": 118960
    },
    {
      "epoch": 36.707806232644245,
      "grad_norm": 0.00011048615851905197,
      "learning_rate": 1.3292193767355753e-05,
      "loss": 0.004,
      "step": 118970
    },
    {
      "epoch": 36.71089170009257,
      "grad_norm": 3.213278034763789e-07,
      "learning_rate": 1.3289108299907438e-05,
      "loss": 0.0,
      "step": 118980
    },
    {
      "epoch": 36.71397716754088,
      "grad_norm": 0.00017710664542391896,
      "learning_rate": 1.3286022832459118e-05,
      "loss": 0.0,
      "step": 118990
    },
    {
      "epoch": 36.7170626349892,
      "grad_norm": 9.960827446775511e-05,
      "learning_rate": 1.32829373650108e-05,
      "loss": 0.0,
      "step": 119000
    },
    {
      "epoch": 36.72014810243752,
      "grad_norm": 1.9592655462474795e-06,
      "learning_rate": 1.3279851897562482e-05,
      "loss": 0.0001,
      "step": 119010
    },
    {
      "epoch": 36.723233569885835,
      "grad_norm": 4.189599621895468e-06,
      "learning_rate": 1.3276766430114162e-05,
      "loss": 0.0,
      "step": 119020
    },
    {
      "epoch": 36.72631903733416,
      "grad_norm": 0.00015771968173794448,
      "learning_rate": 1.3273680962665843e-05,
      "loss": 0.0,
      "step": 119030
    },
    {
      "epoch": 36.72940450478247,
      "grad_norm": 5.2241866796975955e-06,
      "learning_rate": 1.3270595495217526e-05,
      "loss": 0.0,
      "step": 119040
    },
    {
      "epoch": 36.732489972230795,
      "grad_norm": 1.6745494804126793e-06,
      "learning_rate": 1.3267510027769208e-05,
      "loss": 0.0,
      "step": 119050
    },
    {
      "epoch": 36.73557543967911,
      "grad_norm": 0.0006391608039848506,
      "learning_rate": 1.326442456032089e-05,
      "loss": 0.0,
      "step": 119060
    },
    {
      "epoch": 36.73866090712743,
      "grad_norm": 2.9089736131027166e-07,
      "learning_rate": 1.3261339092872571e-05,
      "loss": 0.0,
      "step": 119070
    },
    {
      "epoch": 36.74174637457575,
      "grad_norm": 9.809717994357925e-06,
      "learning_rate": 1.3258253625424252e-05,
      "loss": 0.0001,
      "step": 119080
    },
    {
      "epoch": 36.74483184202407,
      "grad_norm": 1.7867089354695054e-06,
      "learning_rate": 1.3255168157975933e-05,
      "loss": 0.0,
      "step": 119090
    },
    {
      "epoch": 36.747917309472385,
      "grad_norm": 6.129961548140272e-05,
      "learning_rate": 1.3252082690527615e-05,
      "loss": 0.0,
      "step": 119100
    },
    {
      "epoch": 36.7510027769207,
      "grad_norm": 7.866105988796335e-07,
      "learning_rate": 1.3248997223079296e-05,
      "loss": 0.0,
      "step": 119110
    },
    {
      "epoch": 36.75408824436902,
      "grad_norm": 7.564568659290671e-05,
      "learning_rate": 1.324591175563098e-05,
      "loss": 0.0,
      "step": 119120
    },
    {
      "epoch": 36.75717371181734,
      "grad_norm": 1.0707200317483512e-06,
      "learning_rate": 1.3242826288182661e-05,
      "loss": 0.0,
      "step": 119130
    },
    {
      "epoch": 36.76025917926566,
      "grad_norm": 1.4266742027757573e-06,
      "learning_rate": 1.3239740820734342e-05,
      "loss": 0.0,
      "step": 119140
    },
    {
      "epoch": 36.763344646713975,
      "grad_norm": 0.0053560989908874035,
      "learning_rate": 1.3236655353286023e-05,
      "loss": 0.0,
      "step": 119150
    },
    {
      "epoch": 36.7664301141623,
      "grad_norm": 0.0001610736653674394,
      "learning_rate": 1.3233569885837705e-05,
      "loss": 0.0,
      "step": 119160
    },
    {
      "epoch": 36.76951558161061,
      "grad_norm": 6.992057137722441e-07,
      "learning_rate": 1.3230484418389386e-05,
      "loss": 0.0,
      "step": 119170
    },
    {
      "epoch": 36.772601049058935,
      "grad_norm": 0.00037933248677290976,
      "learning_rate": 1.322739895094107e-05,
      "loss": 0.0001,
      "step": 119180
    },
    {
      "epoch": 36.77568651650725,
      "grad_norm": 4.038713541376637e-06,
      "learning_rate": 1.3224313483492751e-05,
      "loss": 0.0,
      "step": 119190
    },
    {
      "epoch": 36.77877198395557,
      "grad_norm": 0.0033392333425581455,
      "learning_rate": 1.3221228016044432e-05,
      "loss": 0.0,
      "step": 119200
    },
    {
      "epoch": 36.78185745140389,
      "grad_norm": 6.874420796521008e-05,
      "learning_rate": 1.3218142548596112e-05,
      "loss": 0.0,
      "step": 119210
    },
    {
      "epoch": 36.78494291885221,
      "grad_norm": 0.00012820688425563276,
      "learning_rate": 1.3215057081147795e-05,
      "loss": 0.0001,
      "step": 119220
    },
    {
      "epoch": 36.788028386300525,
      "grad_norm": 5.22290656590485e-06,
      "learning_rate": 1.3211971613699476e-05,
      "loss": 0.0,
      "step": 119230
    },
    {
      "epoch": 36.79111385374884,
      "grad_norm": 0.05462455376982689,
      "learning_rate": 1.3208886146251156e-05,
      "loss": 0.0,
      "step": 119240
    },
    {
      "epoch": 36.79419932119716,
      "grad_norm": 5.124871904627071e-08,
      "learning_rate": 1.320580067880284e-05,
      "loss": 0.0,
      "step": 119250
    },
    {
      "epoch": 36.79728478864548,
      "grad_norm": 2.6578018150758e-06,
      "learning_rate": 1.3202715211354521e-05,
      "loss": 0.0,
      "step": 119260
    },
    {
      "epoch": 36.8003702560938,
      "grad_norm": 6.348086026264355e-05,
      "learning_rate": 1.3199629743906202e-05,
      "loss": 0.0,
      "step": 119270
    },
    {
      "epoch": 36.803455723542115,
      "grad_norm": 8.06143998488551e-06,
      "learning_rate": 1.3196544276457885e-05,
      "loss": 0.0,
      "step": 119280
    },
    {
      "epoch": 36.80654119099044,
      "grad_norm": 5.9499019698705524e-05,
      "learning_rate": 1.3193458809009565e-05,
      "loss": 0.0,
      "step": 119290
    },
    {
      "epoch": 36.80962665843875,
      "grad_norm": 0.005600533913820982,
      "learning_rate": 1.3190373341561246e-05,
      "loss": 0.0,
      "step": 119300
    },
    {
      "epoch": 36.812712125887074,
      "grad_norm": 2.9501830795197748e-05,
      "learning_rate": 1.3187287874112927e-05,
      "loss": 0.0001,
      "step": 119310
    },
    {
      "epoch": 36.81579759333539,
      "grad_norm": 0.0014119625557214022,
      "learning_rate": 1.3184202406664611e-05,
      "loss": 0.0,
      "step": 119320
    },
    {
      "epoch": 36.81888306078371,
      "grad_norm": 5.411377060227096e-05,
      "learning_rate": 1.3181116939216292e-05,
      "loss": 0.0,
      "step": 119330
    },
    {
      "epoch": 36.82196852823203,
      "grad_norm": 9.08467789884071e-09,
      "learning_rate": 1.3178031471767974e-05,
      "loss": 0.0,
      "step": 119340
    },
    {
      "epoch": 36.82505399568034,
      "grad_norm": 1.7518912045488833e-06,
      "learning_rate": 1.3174946004319655e-05,
      "loss": 0.0,
      "step": 119350
    },
    {
      "epoch": 36.828139463128664,
      "grad_norm": 0.003140747081488371,
      "learning_rate": 1.3171860536871336e-05,
      "loss": 0.0002,
      "step": 119360
    },
    {
      "epoch": 36.83122493057698,
      "grad_norm": 0.010917717590928078,
      "learning_rate": 1.3168775069423017e-05,
      "loss": 0.0,
      "step": 119370
    },
    {
      "epoch": 36.8343103980253,
      "grad_norm": 0.0011025071144104004,
      "learning_rate": 1.3165689601974701e-05,
      "loss": 0.0,
      "step": 119380
    },
    {
      "epoch": 36.83739586547362,
      "grad_norm": 2.6428887522911282e-08,
      "learning_rate": 1.3162604134526382e-05,
      "loss": 0.0,
      "step": 119390
    },
    {
      "epoch": 36.84048133292194,
      "grad_norm": 3.170001491525909e-06,
      "learning_rate": 1.3159518667078064e-05,
      "loss": 0.0008,
      "step": 119400
    },
    {
      "epoch": 36.843566800370255,
      "grad_norm": 9.026308589454857e-07,
      "learning_rate": 1.3156433199629745e-05,
      "loss": 0.0,
      "step": 119410
    },
    {
      "epoch": 36.84665226781858,
      "grad_norm": 2.363217830657959,
      "learning_rate": 1.3153347732181426e-05,
      "loss": 0.0106,
      "step": 119420
    },
    {
      "epoch": 36.84973773526689,
      "grad_norm": 6.835638487245888e-05,
      "learning_rate": 1.3150262264733107e-05,
      "loss": 0.0,
      "step": 119430
    },
    {
      "epoch": 36.852823202715214,
      "grad_norm": 1.8826547147909878e-06,
      "learning_rate": 1.3147176797284787e-05,
      "loss": 0.0,
      "step": 119440
    },
    {
      "epoch": 36.85590867016353,
      "grad_norm": 0.00035654433304443955,
      "learning_rate": 1.3144091329836472e-05,
      "loss": 0.0,
      "step": 119450
    },
    {
      "epoch": 36.858994137611845,
      "grad_norm": 2.801521304718335e-06,
      "learning_rate": 1.3141005862388154e-05,
      "loss": 0.0,
      "step": 119460
    },
    {
      "epoch": 36.86207960506017,
      "grad_norm": 4.2573854443617165e-05,
      "learning_rate": 1.3137920394939835e-05,
      "loss": 0.0,
      "step": 119470
    },
    {
      "epoch": 36.86516507250848,
      "grad_norm": 2.155908259737771e-05,
      "learning_rate": 1.3134834927491516e-05,
      "loss": 0.0,
      "step": 119480
    },
    {
      "epoch": 36.868250539956804,
      "grad_norm": 1.4034914784133434e-05,
      "learning_rate": 1.3131749460043196e-05,
      "loss": 0.0,
      "step": 119490
    },
    {
      "epoch": 36.87133600740512,
      "grad_norm": 2.3945813154568896e-07,
      "learning_rate": 1.3128663992594877e-05,
      "loss": 0.0,
      "step": 119500
    },
    {
      "epoch": 36.87442147485344,
      "grad_norm": 1.6090992858153186e-06,
      "learning_rate": 1.312557852514656e-05,
      "loss": 0.0001,
      "step": 119510
    },
    {
      "epoch": 36.87750694230176,
      "grad_norm": 2.060381302726455e-05,
      "learning_rate": 1.3122493057698244e-05,
      "loss": 0.0,
      "step": 119520
    },
    {
      "epoch": 36.88059240975008,
      "grad_norm": 0.000155760018969886,
      "learning_rate": 1.3119407590249925e-05,
      "loss": 0.0,
      "step": 119530
    },
    {
      "epoch": 36.883677877198394,
      "grad_norm": 0.00016807930660434067,
      "learning_rate": 1.3116322122801605e-05,
      "loss": 0.0,
      "step": 119540
    },
    {
      "epoch": 36.88676334464672,
      "grad_norm": 3.9385517993650865e-06,
      "learning_rate": 1.3113236655353286e-05,
      "loss": 0.0,
      "step": 119550
    },
    {
      "epoch": 36.88984881209503,
      "grad_norm": 8.903517300495878e-05,
      "learning_rate": 1.3110151187904967e-05,
      "loss": 0.0002,
      "step": 119560
    },
    {
      "epoch": 36.892934279543354,
      "grad_norm": 4.47015008830931e-06,
      "learning_rate": 1.310706572045665e-05,
      "loss": 0.0,
      "step": 119570
    },
    {
      "epoch": 36.89601974699167,
      "grad_norm": 3.2439555070595816e-05,
      "learning_rate": 1.3103980253008334e-05,
      "loss": 0.0,
      "step": 119580
    },
    {
      "epoch": 36.899105214439984,
      "grad_norm": 1.3264946119306842e-06,
      "learning_rate": 1.3100894785560014e-05,
      "loss": 0.0,
      "step": 119590
    },
    {
      "epoch": 36.90219068188831,
      "grad_norm": 9.82313504209742e-05,
      "learning_rate": 1.3097809318111695e-05,
      "loss": 0.0,
      "step": 119600
    },
    {
      "epoch": 36.90527614933662,
      "grad_norm": 8.529337355867028e-05,
      "learning_rate": 1.3094723850663376e-05,
      "loss": 0.0,
      "step": 119610
    },
    {
      "epoch": 36.908361616784944,
      "grad_norm": 3.481690782791702e-06,
      "learning_rate": 1.3091638383215057e-05,
      "loss": 0.0,
      "step": 119620
    },
    {
      "epoch": 36.91144708423326,
      "grad_norm": 2.3848197088227607e-06,
      "learning_rate": 1.308855291576674e-05,
      "loss": 0.0,
      "step": 119630
    },
    {
      "epoch": 36.91453255168158,
      "grad_norm": 7.5505877248360775e-06,
      "learning_rate": 1.308546744831842e-05,
      "loss": 0.0001,
      "step": 119640
    },
    {
      "epoch": 36.9176180191299,
      "grad_norm": 1.2639521855817293e-06,
      "learning_rate": 1.3082381980870104e-05,
      "loss": 0.0,
      "step": 119650
    },
    {
      "epoch": 36.92070348657822,
      "grad_norm": 4.4992684706812724e-06,
      "learning_rate": 1.3079296513421785e-05,
      "loss": 0.0001,
      "step": 119660
    },
    {
      "epoch": 36.923788954026534,
      "grad_norm": 1.1312717106193304e-05,
      "learning_rate": 1.3076211045973466e-05,
      "loss": 0.0,
      "step": 119670
    },
    {
      "epoch": 36.92687442147486,
      "grad_norm": 0.00013595518248621374,
      "learning_rate": 1.3073125578525147e-05,
      "loss": 0.0,
      "step": 119680
    },
    {
      "epoch": 36.92995988892317,
      "grad_norm": 0.00548509880900383,
      "learning_rate": 1.3070040111076829e-05,
      "loss": 0.0,
      "step": 119690
    },
    {
      "epoch": 36.93304535637149,
      "grad_norm": 0.018048111349344254,
      "learning_rate": 1.306695464362851e-05,
      "loss": 0.0,
      "step": 119700
    },
    {
      "epoch": 36.93613082381981,
      "grad_norm": 0.001078623696230352,
      "learning_rate": 1.306386917618019e-05,
      "loss": 0.0,
      "step": 119710
    },
    {
      "epoch": 36.939216291268124,
      "grad_norm": 1.9392477042856626e-05,
      "learning_rate": 1.3060783708731875e-05,
      "loss": 0.0,
      "step": 119720
    },
    {
      "epoch": 36.94230175871645,
      "grad_norm": 2.715426887789363e-07,
      "learning_rate": 1.3057698241283556e-05,
      "loss": 0.0001,
      "step": 119730
    },
    {
      "epoch": 36.94538722616476,
      "grad_norm": 1.8208059771041007e-07,
      "learning_rate": 1.3054612773835236e-05,
      "loss": 0.0,
      "step": 119740
    },
    {
      "epoch": 36.948472693613084,
      "grad_norm": 4.222997915803717e-07,
      "learning_rate": 1.3051527306386919e-05,
      "loss": 0.0,
      "step": 119750
    },
    {
      "epoch": 36.9515581610614,
      "grad_norm": 8.039411113713868e-06,
      "learning_rate": 1.30484418389386e-05,
      "loss": 0.0,
      "step": 119760
    },
    {
      "epoch": 36.95464362850972,
      "grad_norm": 7.95678988652071e-06,
      "learning_rate": 1.304535637149028e-05,
      "loss": 0.0,
      "step": 119770
    },
    {
      "epoch": 36.95772909595804,
      "grad_norm": 0.00014280207687988877,
      "learning_rate": 1.3042270904041961e-05,
      "loss": 0.0,
      "step": 119780
    },
    {
      "epoch": 36.96081456340636,
      "grad_norm": 2.6545107175479643e-05,
      "learning_rate": 1.3039185436593645e-05,
      "loss": 0.0021,
      "step": 119790
    },
    {
      "epoch": 36.963900030854674,
      "grad_norm": 0.0008238675072789192,
      "learning_rate": 1.3036099969145326e-05,
      "loss": 0.0,
      "step": 119800
    },
    {
      "epoch": 36.96698549830299,
      "grad_norm": 7.449558779626386e-06,
      "learning_rate": 1.3033014501697009e-05,
      "loss": 0.0005,
      "step": 119810
    },
    {
      "epoch": 36.97007096575131,
      "grad_norm": 0.0005088954349048436,
      "learning_rate": 1.302992903424869e-05,
      "loss": 0.0,
      "step": 119820
    },
    {
      "epoch": 36.97315643319963,
      "grad_norm": 0.00013141584349796176,
      "learning_rate": 1.302684356680037e-05,
      "loss": 0.0,
      "step": 119830
    },
    {
      "epoch": 36.97624190064795,
      "grad_norm": 6.270409357966855e-05,
      "learning_rate": 1.3023758099352051e-05,
      "loss": 0.0001,
      "step": 119840
    },
    {
      "epoch": 36.979327368096264,
      "grad_norm": 0.003429393284022808,
      "learning_rate": 1.3020672631903735e-05,
      "loss": 0.0,
      "step": 119850
    },
    {
      "epoch": 36.98241283554459,
      "grad_norm": 1.4617761507906835e-06,
      "learning_rate": 1.3017587164455416e-05,
      "loss": 0.0,
      "step": 119860
    },
    {
      "epoch": 36.9854983029929,
      "grad_norm": 5.163464038560051e-07,
      "learning_rate": 1.3014501697007098e-05,
      "loss": 0.0,
      "step": 119870
    },
    {
      "epoch": 36.988583770441224,
      "grad_norm": 0.02310209535062313,
      "learning_rate": 1.3011416229558779e-05,
      "loss": 0.0,
      "step": 119880
    },
    {
      "epoch": 36.99166923788954,
      "grad_norm": 5.885779614800413e-07,
      "learning_rate": 1.300833076211046e-05,
      "loss": 0.0,
      "step": 119890
    },
    {
      "epoch": 36.99475470533786,
      "grad_norm": 0.0005066647427156568,
      "learning_rate": 1.300524529466214e-05,
      "loss": 0.0,
      "step": 119900
    },
    {
      "epoch": 36.99784017278618,
      "grad_norm": 3.1221728136188176e-07,
      "learning_rate": 1.3002159827213821e-05,
      "loss": 0.0015,
      "step": 119910
    },
    {
      "epoch": 37.0,
      "eval_accuracy_branch1": 1.0,
      "eval_accuracy_branch2": 0.3934010397075702,
      "eval_f1_branch1": 1.0,
      "eval_f1_branch2": 0.3730259499010022,
      "eval_loss": 1.7946904335985892e-06,
      "eval_precision_branch1": 1.0,
      "eval_precision_branch2": 0.5174467549264821,
      "eval_recall_branch1": 1.0,
      "eval_recall_branch2": 0.5101776568965019,
      "eval_runtime": 239.1667,
      "eval_samples_per_second": 433.518,
      "eval_steps_per_second": 54.192,
      "step": 119917
    },
    {
      "epoch": 37.0009256402345,
      "grad_norm": 0.00011587834160309285,
      "learning_rate": 1.2999074359765506e-05,
      "loss": 0.0003,
      "step": 119920
    },
    {
      "epoch": 37.004011107682814,
      "grad_norm": 6.008842319715768e-06,
      "learning_rate": 1.2995988892317188e-05,
      "loss": 0.0,
      "step": 119930
    },
    {
      "epoch": 37.00709657513113,
      "grad_norm": 0.015840129926800728,
      "learning_rate": 1.2992903424868869e-05,
      "loss": 0.0,
      "step": 119940
    },
    {
      "epoch": 37.01018204257945,
      "grad_norm": 2.7934122499573277e-06,
      "learning_rate": 1.298981795742055e-05,
      "loss": 0.0,
      "step": 119950
    },
    {
      "epoch": 37.01326751002777,
      "grad_norm": 8.145497645273281e-07,
      "learning_rate": 1.298673248997223e-05,
      "loss": 0.0005,
      "step": 119960
    },
    {
      "epoch": 37.01635297747609,
      "grad_norm": 0.0018335460918024182,
      "learning_rate": 1.2983647022523911e-05,
      "loss": 0.0,
      "step": 119970
    },
    {
      "epoch": 37.019438444924404,
      "grad_norm": 0.03366190567612648,
      "learning_rate": 1.2980561555075594e-05,
      "loss": 0.0,
      "step": 119980
    },
    {
      "epoch": 37.022523912372726,
      "grad_norm": 1.440497817384312e-05,
      "learning_rate": 1.2977476087627278e-05,
      "loss": 0.0,
      "step": 119990
    },
    {
      "epoch": 37.02560937982104,
      "grad_norm": 0.0002289776166435331,
      "learning_rate": 1.2974390620178959e-05,
      "loss": 0.0003,
      "step": 120000
    },
    {
      "epoch": 37.028694847269364,
      "grad_norm": 1.907537443912588e-05,
      "learning_rate": 1.297130515273064e-05,
      "loss": 0.0,
      "step": 120010
    },
    {
      "epoch": 37.03178031471768,
      "grad_norm": 1.3269760529510677e-05,
      "learning_rate": 1.296821968528232e-05,
      "loss": 0.0,
      "step": 120020
    },
    {
      "epoch": 37.034865782166,
      "grad_norm": 7.992799510248005e-05,
      "learning_rate": 1.2965134217834001e-05,
      "loss": 0.0,
      "step": 120030
    },
    {
      "epoch": 37.037951249614316,
      "grad_norm": 4.798619920620695e-05,
      "learning_rate": 1.2962048750385684e-05,
      "loss": 0.0,
      "step": 120040
    },
    {
      "epoch": 37.04103671706263,
      "grad_norm": 4.921714935335331e-05,
      "learning_rate": 1.2958963282937368e-05,
      "loss": 0.0,
      "step": 120050
    },
    {
      "epoch": 37.044122184510954,
      "grad_norm": 4.86832759634126e-05,
      "learning_rate": 1.2955877815489048e-05,
      "loss": 0.0,
      "step": 120060
    },
    {
      "epoch": 37.04720765195927,
      "grad_norm": 1.6027926221795497e-06,
      "learning_rate": 1.295279234804073e-05,
      "loss": 0.0,
      "step": 120070
    },
    {
      "epoch": 37.05029311940759,
      "grad_norm": 4.544074272416765e-06,
      "learning_rate": 1.294970688059241e-05,
      "loss": 0.0,
      "step": 120080
    },
    {
      "epoch": 37.05337858685591,
      "grad_norm": 2.127894958903198e-06,
      "learning_rate": 1.294662141314409e-05,
      "loss": 0.0,
      "step": 120090
    },
    {
      "epoch": 37.05646405430423,
      "grad_norm": 0.00010035659215645865,
      "learning_rate": 1.2943535945695773e-05,
      "loss": 0.0,
      "step": 120100
    },
    {
      "epoch": 37.059549521752544,
      "grad_norm": 1.672836091870522e-08,
      "learning_rate": 1.2940450478247454e-05,
      "loss": 0.0,
      "step": 120110
    },
    {
      "epoch": 37.062634989200866,
      "grad_norm": 1.2870301588918664e-06,
      "learning_rate": 1.2937365010799138e-05,
      "loss": 0.0,
      "step": 120120
    },
    {
      "epoch": 37.06572045664918,
      "grad_norm": 0.0007068462437018752,
      "learning_rate": 1.2934279543350819e-05,
      "loss": 0.0,
      "step": 120130
    },
    {
      "epoch": 37.068805924097504,
      "grad_norm": 3.628480408224277e-05,
      "learning_rate": 1.29311940759025e-05,
      "loss": 0.0008,
      "step": 120140
    },
    {
      "epoch": 37.07189139154582,
      "grad_norm": 3.239777868202509e-07,
      "learning_rate": 1.292810860845418e-05,
      "loss": 0.0001,
      "step": 120150
    },
    {
      "epoch": 37.07497685899414,
      "grad_norm": 4.302051092963666e-05,
      "learning_rate": 1.2925023141005863e-05,
      "loss": 0.0,
      "step": 120160
    },
    {
      "epoch": 37.078062326442456,
      "grad_norm": 1.6830244064331055,
      "learning_rate": 1.2921937673557544e-05,
      "loss": 0.001,
      "step": 120170
    },
    {
      "epoch": 37.08114779389077,
      "grad_norm": 5.33808815816883e-05,
      "learning_rate": 1.2918852206109225e-05,
      "loss": 0.0,
      "step": 120180
    },
    {
      "epoch": 37.084233261339094,
      "grad_norm": 0.0011615963885560632,
      "learning_rate": 1.2915766738660909e-05,
      "loss": 0.0004,
      "step": 120190
    },
    {
      "epoch": 37.08731872878741,
      "grad_norm": 0.00045833096373826265,
      "learning_rate": 1.291268127121259e-05,
      "loss": 0.0,
      "step": 120200
    },
    {
      "epoch": 37.09040419623573,
      "grad_norm": 1.1595679097808897e-05,
      "learning_rate": 1.290959580376427e-05,
      "loss": 0.0,
      "step": 120210
    },
    {
      "epoch": 37.093489663684046,
      "grad_norm": 2.887474579438276e-07,
      "learning_rate": 1.2906510336315953e-05,
      "loss": 0.0001,
      "step": 120220
    },
    {
      "epoch": 37.09657513113237,
      "grad_norm": 6.843914889032021e-06,
      "learning_rate": 1.2903424868867634e-05,
      "loss": 0.0,
      "step": 120230
    },
    {
      "epoch": 37.099660598580684,
      "grad_norm": 0.002735582645982504,
      "learning_rate": 1.2900339401419314e-05,
      "loss": 0.001,
      "step": 120240
    },
    {
      "epoch": 37.102746066029006,
      "grad_norm": 3.367626277395175e-06,
      "learning_rate": 1.2897253933970999e-05,
      "loss": 0.0,
      "step": 120250
    },
    {
      "epoch": 37.10583153347732,
      "grad_norm": 3.392294456716627e-05,
      "learning_rate": 1.289416846652268e-05,
      "loss": 0.0005,
      "step": 120260
    },
    {
      "epoch": 37.10891700092564,
      "grad_norm": 5.686948134098202e-05,
      "learning_rate": 1.289108299907436e-05,
      "loss": 0.0,
      "step": 120270
    },
    {
      "epoch": 37.11200246837396,
      "grad_norm": 0.001200229162350297,
      "learning_rate": 1.2887997531626043e-05,
      "loss": 0.0,
      "step": 120280
    },
    {
      "epoch": 37.115087935822274,
      "grad_norm": 0.00010281307913828641,
      "learning_rate": 1.2884912064177723e-05,
      "loss": 0.0001,
      "step": 120290
    },
    {
      "epoch": 37.118173403270596,
      "grad_norm": 4.623989298124798e-06,
      "learning_rate": 1.2881826596729404e-05,
      "loss": 0.0,
      "step": 120300
    },
    {
      "epoch": 37.12125887071891,
      "grad_norm": 8.196406753313568e-08,
      "learning_rate": 1.2878741129281085e-05,
      "loss": 0.0005,
      "step": 120310
    },
    {
      "epoch": 37.124344338167234,
      "grad_norm": 0.0005027632578276098,
      "learning_rate": 1.2875655661832769e-05,
      "loss": 0.0,
      "step": 120320
    },
    {
      "epoch": 37.12742980561555,
      "grad_norm": 2.6361176423961297e-06,
      "learning_rate": 1.287257019438445e-05,
      "loss": 0.0,
      "step": 120330
    },
    {
      "epoch": 37.13051527306387,
      "grad_norm": 1.2004697055090219e-05,
      "learning_rate": 1.2869484726936132e-05,
      "loss": 0.0,
      "step": 120340
    },
    {
      "epoch": 37.133600740512186,
      "grad_norm": 5.787766713183373e-05,
      "learning_rate": 1.2866399259487813e-05,
      "loss": 0.0,
      "step": 120350
    },
    {
      "epoch": 37.13668620796051,
      "grad_norm": 0.2754908800125122,
      "learning_rate": 1.2863313792039494e-05,
      "loss": 0.0012,
      "step": 120360
    },
    {
      "epoch": 37.139771675408824,
      "grad_norm": 9.699141401142697e-07,
      "learning_rate": 1.2860228324591175e-05,
      "loss": 0.0,
      "step": 120370
    },
    {
      "epoch": 37.142857142857146,
      "grad_norm": 2.7745267061618506e-07,
      "learning_rate": 1.2857142857142857e-05,
      "loss": 0.0012,
      "step": 120380
    },
    {
      "epoch": 37.14594261030546,
      "grad_norm": 0.005926237441599369,
      "learning_rate": 1.285405738969454e-05,
      "loss": 0.0001,
      "step": 120390
    },
    {
      "epoch": 37.149028077753776,
      "grad_norm": 0.0002072395000141114,
      "learning_rate": 1.2850971922246222e-05,
      "loss": 0.0,
      "step": 120400
    },
    {
      "epoch": 37.1521135452021,
      "grad_norm": 8.072709169937298e-05,
      "learning_rate": 1.2847886454797903e-05,
      "loss": 0.0,
      "step": 120410
    },
    {
      "epoch": 37.155199012650414,
      "grad_norm": 2.6299543380737305,
      "learning_rate": 1.2844800987349584e-05,
      "loss": 0.0066,
      "step": 120420
    },
    {
      "epoch": 37.158284480098736,
      "grad_norm": 0.0017964980797842145,
      "learning_rate": 1.2841715519901265e-05,
      "loss": 0.0001,
      "step": 120430
    },
    {
      "epoch": 37.16136994754705,
      "grad_norm": 4.6608665371650204e-08,
      "learning_rate": 1.2838630052452947e-05,
      "loss": 0.0,
      "step": 120440
    },
    {
      "epoch": 37.16445541499537,
      "grad_norm": 2.996740704475087e-06,
      "learning_rate": 1.283554458500463e-05,
      "loss": 0.0,
      "step": 120450
    },
    {
      "epoch": 37.16754088244369,
      "grad_norm": 3.035387123873079e-07,
      "learning_rate": 1.2832459117556312e-05,
      "loss": 0.0009,
      "step": 120460
    },
    {
      "epoch": 37.17062634989201,
      "grad_norm": 3.094235580647364e-05,
      "learning_rate": 1.2829373650107993e-05,
      "loss": 0.0,
      "step": 120470
    },
    {
      "epoch": 37.173711817340326,
      "grad_norm": 0.17708885669708252,
      "learning_rate": 1.2826288182659674e-05,
      "loss": 0.0001,
      "step": 120480
    },
    {
      "epoch": 37.17679728478865,
      "grad_norm": 0.0006514412816613913,
      "learning_rate": 1.2823202715211354e-05,
      "loss": 0.0,
      "step": 120490
    },
    {
      "epoch": 37.17988275223696,
      "grad_norm": 1.244096984009957e-05,
      "learning_rate": 1.2820117247763037e-05,
      "loss": 0.0,
      "step": 120500
    },
    {
      "epoch": 37.182968219685286,
      "grad_norm": 0.014743206091225147,
      "learning_rate": 1.2817031780314718e-05,
      "loss": 0.0,
      "step": 120510
    },
    {
      "epoch": 37.1860536871336,
      "grad_norm": 2.0802926883334294e-06,
      "learning_rate": 1.2813946312866402e-05,
      "loss": 0.0004,
      "step": 120520
    },
    {
      "epoch": 37.189139154581916,
      "grad_norm": 8.149866334861144e-05,
      "learning_rate": 1.2810860845418083e-05,
      "loss": 0.0,
      "step": 120530
    },
    {
      "epoch": 37.19222462203024,
      "grad_norm": 1.6736068573663943e-05,
      "learning_rate": 1.2807775377969763e-05,
      "loss": 0.0,
      "step": 120540
    },
    {
      "epoch": 37.19531008947855,
      "grad_norm": 5.893906927667558e-05,
      "learning_rate": 1.2804689910521444e-05,
      "loss": 0.0,
      "step": 120550
    },
    {
      "epoch": 37.198395556926876,
      "grad_norm": 0.0002630404196679592,
      "learning_rate": 1.2801604443073127e-05,
      "loss": 0.0,
      "step": 120560
    },
    {
      "epoch": 37.20148102437519,
      "grad_norm": 1.8265063772560097e-05,
      "learning_rate": 1.2798518975624807e-05,
      "loss": 0.0,
      "step": 120570
    },
    {
      "epoch": 37.20456649182351,
      "grad_norm": 1.1280206308583729e-05,
      "learning_rate": 1.2795433508176488e-05,
      "loss": 0.0,
      "step": 120580
    },
    {
      "epoch": 37.20765195927183,
      "grad_norm": 9.098846931010485e-06,
      "learning_rate": 1.2792348040728172e-05,
      "loss": 0.0,
      "step": 120590
    },
    {
      "epoch": 37.21073742672015,
      "grad_norm": 0.00025331054348498583,
      "learning_rate": 1.2789262573279853e-05,
      "loss": 0.0,
      "step": 120600
    },
    {
      "epoch": 37.213822894168466,
      "grad_norm": 3.773235448534251e-07,
      "learning_rate": 1.2786177105831534e-05,
      "loss": 0.0,
      "step": 120610
    },
    {
      "epoch": 37.21690836161679,
      "grad_norm": 6.184144876897335e-05,
      "learning_rate": 1.2783091638383216e-05,
      "loss": 0.0,
      "step": 120620
    },
    {
      "epoch": 37.2199938290651,
      "grad_norm": 6.42494129010629e-08,
      "learning_rate": 1.2780006170934897e-05,
      "loss": 0.0,
      "step": 120630
    },
    {
      "epoch": 37.22307929651342,
      "grad_norm": 2.6725247153081e-06,
      "learning_rate": 1.2776920703486578e-05,
      "loss": 0.0,
      "step": 120640
    },
    {
      "epoch": 37.22616476396174,
      "grad_norm": 6.324120249701082e-07,
      "learning_rate": 1.2773835236038259e-05,
      "loss": 0.0001,
      "step": 120650
    },
    {
      "epoch": 37.229250231410056,
      "grad_norm": 0.00016730604693293571,
      "learning_rate": 1.2770749768589943e-05,
      "loss": 0.0,
      "step": 120660
    },
    {
      "epoch": 37.23233569885838,
      "grad_norm": 1.4244207022784394e-06,
      "learning_rate": 1.2767664301141624e-05,
      "loss": 0.0,
      "step": 120670
    },
    {
      "epoch": 37.23542116630669,
      "grad_norm": 4.064654785906896e-05,
      "learning_rate": 1.2764578833693306e-05,
      "loss": 0.001,
      "step": 120680
    },
    {
      "epoch": 37.238506633755016,
      "grad_norm": 0.005141873378306627,
      "learning_rate": 1.2761493366244987e-05,
      "loss": 0.0017,
      "step": 120690
    },
    {
      "epoch": 37.24159210120333,
      "grad_norm": 4.8313951992895454e-05,
      "learning_rate": 1.2758407898796668e-05,
      "loss": 0.0,
      "step": 120700
    },
    {
      "epoch": 37.24467756865165,
      "grad_norm": 1.3159253285266459e-05,
      "learning_rate": 1.2755322431348348e-05,
      "loss": 0.0,
      "step": 120710
    },
    {
      "epoch": 37.24776303609997,
      "grad_norm": 3.120468136330601e-06,
      "learning_rate": 1.2752236963900033e-05,
      "loss": 0.0,
      "step": 120720
    },
    {
      "epoch": 37.25084850354829,
      "grad_norm": 0.00011408887803554535,
      "learning_rate": 1.2749151496451713e-05,
      "loss": 0.0,
      "step": 120730
    },
    {
      "epoch": 37.253933970996606,
      "grad_norm": 5.976348620606586e-05,
      "learning_rate": 1.2746066029003396e-05,
      "loss": 0.0,
      "step": 120740
    },
    {
      "epoch": 37.25701943844492,
      "grad_norm": 3.4503815982134256e-07,
      "learning_rate": 1.2742980561555077e-05,
      "loss": 0.0,
      "step": 120750
    },
    {
      "epoch": 37.26010490589324,
      "grad_norm": 2.2161088963912334e-07,
      "learning_rate": 1.2739895094106757e-05,
      "loss": 0.0,
      "step": 120760
    },
    {
      "epoch": 37.26319037334156,
      "grad_norm": 5.84628687647637e-05,
      "learning_rate": 1.2736809626658438e-05,
      "loss": 0.0,
      "step": 120770
    },
    {
      "epoch": 37.26627584078988,
      "grad_norm": 3.6219096273271134e-06,
      "learning_rate": 1.2733724159210119e-05,
      "loss": 0.0,
      "step": 120780
    },
    {
      "epoch": 37.269361308238196,
      "grad_norm": 5.101878286950523e-06,
      "learning_rate": 1.2730638691761803e-05,
      "loss": 0.0,
      "step": 120790
    },
    {
      "epoch": 37.27244677568652,
      "grad_norm": 0.00026584556326270103,
      "learning_rate": 1.2727553224313486e-05,
      "loss": 0.0,
      "step": 120800
    },
    {
      "epoch": 37.27553224313483,
      "grad_norm": 0.0008092917851172388,
      "learning_rate": 1.2724467756865166e-05,
      "loss": 0.0,
      "step": 120810
    },
    {
      "epoch": 37.278617710583156,
      "grad_norm": 2.572121229604818e-05,
      "learning_rate": 1.2721382289416847e-05,
      "loss": 0.0001,
      "step": 120820
    },
    {
      "epoch": 37.28170317803147,
      "grad_norm": 0.0006384299485944211,
      "learning_rate": 1.2718296821968528e-05,
      "loss": 0.0,
      "step": 120830
    },
    {
      "epoch": 37.28478864547979,
      "grad_norm": 0.037912171334028244,
      "learning_rate": 1.2715211354520209e-05,
      "loss": 0.0,
      "step": 120840
    },
    {
      "epoch": 37.28787411292811,
      "grad_norm": 2.0641641640395392e-07,
      "learning_rate": 1.2712125887071891e-05,
      "loss": 0.0,
      "step": 120850
    },
    {
      "epoch": 37.29095958037643,
      "grad_norm": 8.729544788366184e-06,
      "learning_rate": 1.2709040419623574e-05,
      "loss": 0.0,
      "step": 120860
    },
    {
      "epoch": 37.294045047824746,
      "grad_norm": 0.4660252034664154,
      "learning_rate": 1.2705954952175256e-05,
      "loss": 0.0029,
      "step": 120870
    },
    {
      "epoch": 37.29713051527306,
      "grad_norm": 0.012794123962521553,
      "learning_rate": 1.2702869484726937e-05,
      "loss": 0.0,
      "step": 120880
    },
    {
      "epoch": 37.30021598272138,
      "grad_norm": 1.201983559440123e-05,
      "learning_rate": 1.2699784017278618e-05,
      "loss": 0.0,
      "step": 120890
    },
    {
      "epoch": 37.3033014501697,
      "grad_norm": 6.072198175388621e-06,
      "learning_rate": 1.2696698549830299e-05,
      "loss": 0.0,
      "step": 120900
    },
    {
      "epoch": 37.30638691761802,
      "grad_norm": 1.619651243345288e-06,
      "learning_rate": 1.2693613082381981e-05,
      "loss": 0.0,
      "step": 120910
    },
    {
      "epoch": 37.309472385066336,
      "grad_norm": 2.0011859760415973e-06,
      "learning_rate": 1.2690527614933664e-05,
      "loss": 0.001,
      "step": 120920
    },
    {
      "epoch": 37.31255785251466,
      "grad_norm": 1.001355212792987e-05,
      "learning_rate": 1.2687442147485346e-05,
      "loss": 0.0,
      "step": 120930
    },
    {
      "epoch": 37.31564331996297,
      "grad_norm": 0.006585581228137016,
      "learning_rate": 1.2684356680037027e-05,
      "loss": 0.0,
      "step": 120940
    },
    {
      "epoch": 37.318728787411295,
      "grad_norm": 0.0017345539527013898,
      "learning_rate": 1.2681271212588708e-05,
      "loss": 0.0001,
      "step": 120950
    },
    {
      "epoch": 37.32181425485961,
      "grad_norm": 2.615747462186846e-06,
      "learning_rate": 1.2678185745140388e-05,
      "loss": 0.0002,
      "step": 120960
    },
    {
      "epoch": 37.32489972230793,
      "grad_norm": 1.167339064522821e-06,
      "learning_rate": 1.2675100277692071e-05,
      "loss": 0.0,
      "step": 120970
    },
    {
      "epoch": 37.32798518975625,
      "grad_norm": 0.0013109894935041666,
      "learning_rate": 1.2672014810243752e-05,
      "loss": 0.0,
      "step": 120980
    },
    {
      "epoch": 37.33107065720456,
      "grad_norm": 1.2935515769640915e-06,
      "learning_rate": 1.2668929342795436e-05,
      "loss": 0.0022,
      "step": 120990
    },
    {
      "epoch": 37.334156124652885,
      "grad_norm": 8.567249132340748e-09,
      "learning_rate": 1.2665843875347117e-05,
      "loss": 0.0,
      "step": 121000
    },
    {
      "epoch": 37.3372415921012,
      "grad_norm": 6.776258942409186e-06,
      "learning_rate": 1.2662758407898797e-05,
      "loss": 0.0007,
      "step": 121010
    },
    {
      "epoch": 37.34032705954952,
      "grad_norm": 1.8687330793909496e-06,
      "learning_rate": 1.2659672940450478e-05,
      "loss": 0.0,
      "step": 121020
    },
    {
      "epoch": 37.34341252699784,
      "grad_norm": 2.0645788936235476e-06,
      "learning_rate": 1.265658747300216e-05,
      "loss": 0.0001,
      "step": 121030
    },
    {
      "epoch": 37.34649799444616,
      "grad_norm": 0.0007014428847469389,
      "learning_rate": 1.2653502005553841e-05,
      "loss": 0.0001,
      "step": 121040
    },
    {
      "epoch": 37.349583461894476,
      "grad_norm": 4.965778543919441e-07,
      "learning_rate": 1.2650416538105522e-05,
      "loss": 0.0005,
      "step": 121050
    },
    {
      "epoch": 37.3526689293428,
      "grad_norm": 0.00013669421605300158,
      "learning_rate": 1.2647331070657206e-05,
      "loss": 0.0,
      "step": 121060
    },
    {
      "epoch": 37.35575439679111,
      "grad_norm": 4.1545862927705457e-07,
      "learning_rate": 1.2644245603208887e-05,
      "loss": 0.0,
      "step": 121070
    },
    {
      "epoch": 37.358839864239435,
      "grad_norm": 0.03225605562329292,
      "learning_rate": 1.2641160135760568e-05,
      "loss": 0.0,
      "step": 121080
    },
    {
      "epoch": 37.36192533168775,
      "grad_norm": 0.00447127316147089,
      "learning_rate": 1.263807466831225e-05,
      "loss": 0.0,
      "step": 121090
    },
    {
      "epoch": 37.365010799136066,
      "grad_norm": 6.843500614195364e-06,
      "learning_rate": 1.2634989200863931e-05,
      "loss": 0.0,
      "step": 121100
    },
    {
      "epoch": 37.36809626658439,
      "grad_norm": 0.0002943103318102658,
      "learning_rate": 1.2631903733415612e-05,
      "loss": 0.0,
      "step": 121110
    },
    {
      "epoch": 37.3711817340327,
      "grad_norm": 7.1028816819307394e-06,
      "learning_rate": 1.2628818265967296e-05,
      "loss": 0.0,
      "step": 121120
    },
    {
      "epoch": 37.374267201481025,
      "grad_norm": 2.1357345758588053e-05,
      "learning_rate": 1.2625732798518977e-05,
      "loss": 0.0,
      "step": 121130
    },
    {
      "epoch": 37.37735266892934,
      "grad_norm": 2.7971461236120376e-07,
      "learning_rate": 1.2622647331070658e-05,
      "loss": 0.0,
      "step": 121140
    },
    {
      "epoch": 37.38043813637766,
      "grad_norm": 4.570013061311329e-07,
      "learning_rate": 1.261956186362234e-05,
      "loss": 0.0,
      "step": 121150
    },
    {
      "epoch": 37.38352360382598,
      "grad_norm": 0.8457297682762146,
      "learning_rate": 1.2616476396174021e-05,
      "loss": 0.0002,
      "step": 121160
    },
    {
      "epoch": 37.3866090712743,
      "grad_norm": 2.2997719497652724e-06,
      "learning_rate": 1.2613390928725702e-05,
      "loss": 0.0,
      "step": 121170
    },
    {
      "epoch": 37.389694538722615,
      "grad_norm": 8.821937080938369e-05,
      "learning_rate": 1.2610305461277383e-05,
      "loss": 0.0,
      "step": 121180
    },
    {
      "epoch": 37.39278000617094,
      "grad_norm": 3.5841285352944396e-06,
      "learning_rate": 1.2607219993829067e-05,
      "loss": 0.0,
      "step": 121190
    },
    {
      "epoch": 37.39586547361925,
      "grad_norm": 0.00031119014602154493,
      "learning_rate": 1.2604134526380747e-05,
      "loss": 0.0,
      "step": 121200
    },
    {
      "epoch": 37.398950941067575,
      "grad_norm": 2.584582716735895e-07,
      "learning_rate": 1.260104905893243e-05,
      "loss": 0.0,
      "step": 121210
    },
    {
      "epoch": 37.40203640851589,
      "grad_norm": 1.1719184840330854e-05,
      "learning_rate": 1.259796359148411e-05,
      "loss": 0.0,
      "step": 121220
    },
    {
      "epoch": 37.405121875964205,
      "grad_norm": 0.015818648040294647,
      "learning_rate": 1.2594878124035792e-05,
      "loss": 0.0,
      "step": 121230
    },
    {
      "epoch": 37.40820734341253,
      "grad_norm": 2.0287670849938877e-05,
      "learning_rate": 1.2591792656587472e-05,
      "loss": 0.0,
      "step": 121240
    },
    {
      "epoch": 37.41129281086084,
      "grad_norm": 0.04614397883415222,
      "learning_rate": 1.2588707189139153e-05,
      "loss": 0.0,
      "step": 121250
    },
    {
      "epoch": 37.414378278309165,
      "grad_norm": 1.294318735745037e-05,
      "learning_rate": 1.2585621721690837e-05,
      "loss": 0.0,
      "step": 121260
    },
    {
      "epoch": 37.41746374575748,
      "grad_norm": 1.7926249711308628e-06,
      "learning_rate": 1.258253625424252e-05,
      "loss": 0.0,
      "step": 121270
    },
    {
      "epoch": 37.4205492132058,
      "grad_norm": 0.0024636101443320513,
      "learning_rate": 1.25794507867942e-05,
      "loss": 0.0,
      "step": 121280
    },
    {
      "epoch": 37.42363468065412,
      "grad_norm": 3.642766614575521e-06,
      "learning_rate": 1.2576365319345881e-05,
      "loss": 0.0,
      "step": 121290
    },
    {
      "epoch": 37.42672014810244,
      "grad_norm": 2.005286205530865e-06,
      "learning_rate": 1.2573279851897562e-05,
      "loss": 0.0,
      "step": 121300
    },
    {
      "epoch": 37.429805615550755,
      "grad_norm": 3.7076647458889056e-06,
      "learning_rate": 1.2570194384449243e-05,
      "loss": 0.0,
      "step": 121310
    },
    {
      "epoch": 37.43289108299908,
      "grad_norm": 2.0697825675597414e-08,
      "learning_rate": 1.2567108917000927e-05,
      "loss": 0.0,
      "step": 121320
    },
    {
      "epoch": 37.43597655044739,
      "grad_norm": 1.1995192608083016e-06,
      "learning_rate": 1.256402344955261e-05,
      "loss": 0.0,
      "step": 121330
    },
    {
      "epoch": 37.43906201789571,
      "grad_norm": 2.870354478545778e-07,
      "learning_rate": 1.256093798210429e-05,
      "loss": 0.0,
      "step": 121340
    },
    {
      "epoch": 37.44214748534403,
      "grad_norm": 3.883754470734857e-05,
      "learning_rate": 1.2557852514655971e-05,
      "loss": 0.0007,
      "step": 121350
    },
    {
      "epoch": 37.445232952792345,
      "grad_norm": 0.0003733744379132986,
      "learning_rate": 1.2554767047207652e-05,
      "loss": 0.0,
      "step": 121360
    },
    {
      "epoch": 37.44831842024067,
      "grad_norm": 4.277284659792713e-08,
      "learning_rate": 1.2551681579759333e-05,
      "loss": 0.0,
      "step": 121370
    },
    {
      "epoch": 37.45140388768898,
      "grad_norm": 7.262463441293221e-06,
      "learning_rate": 1.2548596112311015e-05,
      "loss": 0.0,
      "step": 121380
    },
    {
      "epoch": 37.454489355137305,
      "grad_norm": 4.678601271734806e-06,
      "learning_rate": 1.25455106448627e-05,
      "loss": 0.0,
      "step": 121390
    },
    {
      "epoch": 37.45757482258562,
      "grad_norm": 3.05997133409619e-07,
      "learning_rate": 1.254242517741438e-05,
      "loss": 0.0,
      "step": 121400
    },
    {
      "epoch": 37.46066029003394,
      "grad_norm": 1.5966342687606812,
      "learning_rate": 1.2539339709966061e-05,
      "loss": 0.0012,
      "step": 121410
    },
    {
      "epoch": 37.46374575748226,
      "grad_norm": 0.00011441744572948664,
      "learning_rate": 1.2536254242517742e-05,
      "loss": 0.0001,
      "step": 121420
    },
    {
      "epoch": 37.46683122493058,
      "grad_norm": 3.4732142921711784e-06,
      "learning_rate": 1.2533168775069422e-05,
      "loss": 0.0,
      "step": 121430
    },
    {
      "epoch": 37.469916692378895,
      "grad_norm": 4.57267606179812e-06,
      "learning_rate": 1.2530083307621105e-05,
      "loss": 0.0,
      "step": 121440
    },
    {
      "epoch": 37.47300215982722,
      "grad_norm": 3.6133590128883952e-06,
      "learning_rate": 1.2526997840172786e-05,
      "loss": 0.0,
      "step": 121450
    },
    {
      "epoch": 37.47608762727553,
      "grad_norm": 2.565149316069437e-06,
      "learning_rate": 1.252391237272447e-05,
      "loss": 0.0,
      "step": 121460
    },
    {
      "epoch": 37.47917309472385,
      "grad_norm": 1.0402037332823966e-05,
      "learning_rate": 1.252082690527615e-05,
      "loss": 0.0001,
      "step": 121470
    },
    {
      "epoch": 37.48225856217217,
      "grad_norm": 2.7035428502131253e-05,
      "learning_rate": 1.2517741437827831e-05,
      "loss": 0.0,
      "step": 121480
    },
    {
      "epoch": 37.485344029620485,
      "grad_norm": 1.055165981256323e-07,
      "learning_rate": 1.2514655970379512e-05,
      "loss": 0.0,
      "step": 121490
    },
    {
      "epoch": 37.48842949706881,
      "grad_norm": 1.872541179182008e-05,
      "learning_rate": 1.2511570502931195e-05,
      "loss": 0.0,
      "step": 121500
    },
    {
      "epoch": 37.49151496451712,
      "grad_norm": 6.588391261175275e-05,
      "learning_rate": 1.2508485035482875e-05,
      "loss": 0.0,
      "step": 121510
    },
    {
      "epoch": 37.494600431965445,
      "grad_norm": 7.243558684422169e-06,
      "learning_rate": 1.2505399568034556e-05,
      "loss": 0.0,
      "step": 121520
    },
    {
      "epoch": 37.49768589941376,
      "grad_norm": 2.9268330763443373e-05,
      "learning_rate": 1.250231410058624e-05,
      "loss": 0.0,
      "step": 121530
    },
    {
      "epoch": 37.50077136686208,
      "grad_norm": 9.722820770718954e-09,
      "learning_rate": 1.2499228633137921e-05,
      "loss": 0.0,
      "step": 121540
    },
    {
      "epoch": 37.5038568343104,
      "grad_norm": 8.720599907974247e-06,
      "learning_rate": 1.2496143165689602e-05,
      "loss": 0.0,
      "step": 121550
    },
    {
      "epoch": 37.50694230175872,
      "grad_norm": 0.00011738172179320827,
      "learning_rate": 1.2493057698241284e-05,
      "loss": 0.0,
      "step": 121560
    },
    {
      "epoch": 37.510027769207035,
      "grad_norm": 3.561960681963683e-07,
      "learning_rate": 1.2489972230792965e-05,
      "loss": 0.0,
      "step": 121570
    },
    {
      "epoch": 37.51311323665535,
      "grad_norm": 3.199935960651601e-08,
      "learning_rate": 1.2486886763344648e-05,
      "loss": 0.0005,
      "step": 121580
    },
    {
      "epoch": 37.51619870410367,
      "grad_norm": 0.0008638193248771131,
      "learning_rate": 1.2483801295896329e-05,
      "loss": 0.0,
      "step": 121590
    },
    {
      "epoch": 37.51928417155199,
      "grad_norm": 0.00014171103248372674,
      "learning_rate": 1.248071582844801e-05,
      "loss": 0.0,
      "step": 121600
    },
    {
      "epoch": 37.52236963900031,
      "grad_norm": 9.489536751061678e-06,
      "learning_rate": 1.2477630360999692e-05,
      "loss": 0.0017,
      "step": 121610
    },
    {
      "epoch": 37.525455106448625,
      "grad_norm": 1.1205254395463271e-06,
      "learning_rate": 1.2474544893551374e-05,
      "loss": 0.0,
      "step": 121620
    },
    {
      "epoch": 37.52854057389695,
      "grad_norm": 9.165284427581355e-05,
      "learning_rate": 1.2471459426103055e-05,
      "loss": 0.0,
      "step": 121630
    },
    {
      "epoch": 37.53162604134526,
      "grad_norm": 0.0020306415390223265,
      "learning_rate": 1.2468373958654738e-05,
      "loss": 0.0,
      "step": 121640
    },
    {
      "epoch": 37.534711508793585,
      "grad_norm": 0.03164929896593094,
      "learning_rate": 1.2465288491206418e-05,
      "loss": 0.0001,
      "step": 121650
    },
    {
      "epoch": 37.5377969762419,
      "grad_norm": 4.346004061517306e-06,
      "learning_rate": 1.2462203023758099e-05,
      "loss": 0.0,
      "step": 121660
    },
    {
      "epoch": 37.54088244369022,
      "grad_norm": 4.813088594346482e-07,
      "learning_rate": 1.2459117556309782e-05,
      "loss": 0.0,
      "step": 121670
    },
    {
      "epoch": 37.54396791113854,
      "grad_norm": 3.735438076546416e-05,
      "learning_rate": 1.2456032088861464e-05,
      "loss": 0.0,
      "step": 121680
    },
    {
      "epoch": 37.54705337858685,
      "grad_norm": 1.034734737004328e-06,
      "learning_rate": 1.2452946621413145e-05,
      "loss": 0.0,
      "step": 121690
    },
    {
      "epoch": 37.550138846035175,
      "grad_norm": 1.914949052661541e-06,
      "learning_rate": 1.2449861153964826e-05,
      "loss": 0.0,
      "step": 121700
    },
    {
      "epoch": 37.55322431348349,
      "grad_norm": 0.00010463627404533327,
      "learning_rate": 1.2446775686516508e-05,
      "loss": 0.0,
      "step": 121710
    },
    {
      "epoch": 37.55630978093181,
      "grad_norm": 1.7457006833865307e-05,
      "learning_rate": 1.2443690219068189e-05,
      "loss": 0.0,
      "step": 121720
    },
    {
      "epoch": 37.55939524838013,
      "grad_norm": 3.7015533962403424e-06,
      "learning_rate": 1.2440604751619871e-05,
      "loss": 0.0,
      "step": 121730
    },
    {
      "epoch": 37.56248071582845,
      "grad_norm": 4.385914564863924e-08,
      "learning_rate": 1.2437519284171554e-05,
      "loss": 0.0,
      "step": 121740
    },
    {
      "epoch": 37.565566183276765,
      "grad_norm": 9.344599675387144e-06,
      "learning_rate": 1.2434433816723235e-05,
      "loss": 0.0,
      "step": 121750
    },
    {
      "epoch": 37.56865165072509,
      "grad_norm": 0.006937119178473949,
      "learning_rate": 1.2431348349274915e-05,
      "loss": 0.0,
      "step": 121760
    },
    {
      "epoch": 37.5717371181734,
      "grad_norm": 3.38538084179163e-05,
      "learning_rate": 1.2428262881826596e-05,
      "loss": 0.0,
      "step": 121770
    },
    {
      "epoch": 37.574822585621725,
      "grad_norm": 8.366240763280075e-06,
      "learning_rate": 1.2425177414378279e-05,
      "loss": 0.0,
      "step": 121780
    },
    {
      "epoch": 37.57790805307004,
      "grad_norm": 3.934148367079615e-07,
      "learning_rate": 1.2422091946929961e-05,
      "loss": 0.0,
      "step": 121790
    },
    {
      "epoch": 37.58099352051836,
      "grad_norm": 5.456641247292282e-06,
      "learning_rate": 1.2419006479481642e-05,
      "loss": 0.0,
      "step": 121800
    },
    {
      "epoch": 37.58407898796668,
      "grad_norm": 5.601085462103583e-08,
      "learning_rate": 1.2415921012033324e-05,
      "loss": 0.0,
      "step": 121810
    },
    {
      "epoch": 37.58716445541499,
      "grad_norm": 2.5185916456393898e-05,
      "learning_rate": 1.2412835544585005e-05,
      "loss": 0.0,
      "step": 121820
    },
    {
      "epoch": 37.590249922863315,
      "grad_norm": 4.4705124047084155e-09,
      "learning_rate": 1.2409750077136686e-05,
      "loss": 0.0,
      "step": 121830
    },
    {
      "epoch": 37.59333539031163,
      "grad_norm": 9.250393304682802e-07,
      "learning_rate": 1.2406664609688368e-05,
      "loss": 0.0001,
      "step": 121840
    },
    {
      "epoch": 37.59642085775995,
      "grad_norm": 1.0008990102505777e-05,
      "learning_rate": 1.2403579142240051e-05,
      "loss": 0.0,
      "step": 121850
    },
    {
      "epoch": 37.59950632520827,
      "grad_norm": 0.0007127816206775606,
      "learning_rate": 1.2400493674791732e-05,
      "loss": 0.0,
      "step": 121860
    },
    {
      "epoch": 37.60259179265659,
      "grad_norm": 0.0001603706186870113,
      "learning_rate": 1.2397408207343412e-05,
      "loss": 0.0,
      "step": 121870
    },
    {
      "epoch": 37.605677260104905,
      "grad_norm": 0.00015067616186570376,
      "learning_rate": 1.2394322739895095e-05,
      "loss": 0.0,
      "step": 121880
    },
    {
      "epoch": 37.60876272755323,
      "grad_norm": 4.441150380785075e-08,
      "learning_rate": 1.2391237272446776e-05,
      "loss": 0.0,
      "step": 121890
    },
    {
      "epoch": 37.61184819500154,
      "grad_norm": 0.0010432779090479016,
      "learning_rate": 1.2388151804998458e-05,
      "loss": 0.0,
      "step": 121900
    },
    {
      "epoch": 37.614933662449864,
      "grad_norm": 2.7349938136467244e-07,
      "learning_rate": 1.238506633755014e-05,
      "loss": 0.0,
      "step": 121910
    },
    {
      "epoch": 37.61801912989818,
      "grad_norm": 0.00014599828864447773,
      "learning_rate": 1.2381980870101821e-05,
      "loss": 0.0,
      "step": 121920
    },
    {
      "epoch": 37.621104597346495,
      "grad_norm": 1.8857369923352962e-06,
      "learning_rate": 1.2378895402653502e-05,
      "loss": 0.0,
      "step": 121930
    },
    {
      "epoch": 37.62419006479482,
      "grad_norm": 1.3351254892768338e-05,
      "learning_rate": 1.2375809935205185e-05,
      "loss": 0.0057,
      "step": 121940
    },
    {
      "epoch": 37.62727553224313,
      "grad_norm": 2.9251182240841445e-06,
      "learning_rate": 1.2372724467756866e-05,
      "loss": 0.0,
      "step": 121950
    },
    {
      "epoch": 37.630360999691455,
      "grad_norm": 2.9231830922071822e-05,
      "learning_rate": 1.2369639000308548e-05,
      "loss": 0.0,
      "step": 121960
    },
    {
      "epoch": 37.63344646713977,
      "grad_norm": 2.1466235733402783e-10,
      "learning_rate": 1.2366553532860229e-05,
      "loss": 0.0,
      "step": 121970
    },
    {
      "epoch": 37.63653193458809,
      "grad_norm": 6.803933843002596e-07,
      "learning_rate": 1.2363468065411911e-05,
      "loss": 0.0,
      "step": 121980
    },
    {
      "epoch": 37.63961740203641,
      "grad_norm": 0.036860160529613495,
      "learning_rate": 1.2360382597963592e-05,
      "loss": 0.0,
      "step": 121990
    },
    {
      "epoch": 37.64270286948473,
      "grad_norm": 1.4368282119647802e-09,
      "learning_rate": 1.2357297130515273e-05,
      "loss": 0.0,
      "step": 122000
    },
    {
      "epoch": 37.645788336933045,
      "grad_norm": 1.2908820963275502e-06,
      "learning_rate": 1.2354211663066955e-05,
      "loss": 0.0,
      "step": 122010
    },
    {
      "epoch": 37.64887380438137,
      "grad_norm": 1.945116537171998e-06,
      "learning_rate": 1.2351126195618638e-05,
      "loss": 0.0006,
      "step": 122020
    },
    {
      "epoch": 37.65195927182968,
      "grad_norm": 0.0001491136645199731,
      "learning_rate": 1.2348040728170319e-05,
      "loss": 0.0,
      "step": 122030
    },
    {
      "epoch": 37.655044739278,
      "grad_norm": 6.59973102301592e-06,
      "learning_rate": 1.2344955260722001e-05,
      "loss": 0.0,
      "step": 122040
    },
    {
      "epoch": 37.65813020672632,
      "grad_norm": 2.4438597392872907e-05,
      "learning_rate": 1.2341869793273682e-05,
      "loss": 0.0,
      "step": 122050
    },
    {
      "epoch": 37.661215674174635,
      "grad_norm": 2.097292053804267e-06,
      "learning_rate": 1.2338784325825363e-05,
      "loss": 0.0,
      "step": 122060
    },
    {
      "epoch": 37.66430114162296,
      "grad_norm": 2.558333562774351e-06,
      "learning_rate": 1.2335698858377043e-05,
      "loss": 0.0,
      "step": 122070
    },
    {
      "epoch": 37.66738660907127,
      "grad_norm": 1.1990537132078316e-06,
      "learning_rate": 1.2332613390928728e-05,
      "loss": 0.0003,
      "step": 122080
    },
    {
      "epoch": 37.670472076519594,
      "grad_norm": 2.68859675998101e-05,
      "learning_rate": 1.2329527923480408e-05,
      "loss": 0.0,
      "step": 122090
    },
    {
      "epoch": 37.67355754396791,
      "grad_norm": 1.8796857830238878e-06,
      "learning_rate": 1.2326442456032089e-05,
      "loss": 0.0,
      "step": 122100
    },
    {
      "epoch": 37.67664301141623,
      "grad_norm": 3.304691290395567e-06,
      "learning_rate": 1.2323356988583772e-05,
      "loss": 0.0,
      "step": 122110
    },
    {
      "epoch": 37.67972847886455,
      "grad_norm": 7.001152653174358e-07,
      "learning_rate": 1.2320271521135452e-05,
      "loss": 0.0,
      "step": 122120
    },
    {
      "epoch": 37.68281394631287,
      "grad_norm": 1.1279648788331542e-05,
      "learning_rate": 1.2317186053687133e-05,
      "loss": 0.0,
      "step": 122130
    },
    {
      "epoch": 37.685899413761184,
      "grad_norm": 9.168995165964589e-05,
      "learning_rate": 1.2314100586238816e-05,
      "loss": 0.0,
      "step": 122140
    },
    {
      "epoch": 37.68898488120951,
      "grad_norm": 0.0004011709534097463,
      "learning_rate": 1.2311015118790498e-05,
      "loss": 0.0,
      "step": 122150
    },
    {
      "epoch": 37.69207034865782,
      "grad_norm": 1.1743785535145435e-06,
      "learning_rate": 1.2307929651342179e-05,
      "loss": 0.0003,
      "step": 122160
    },
    {
      "epoch": 37.69515581610614,
      "grad_norm": 0.00016810801753308624,
      "learning_rate": 1.230484418389386e-05,
      "loss": 0.0,
      "step": 122170
    },
    {
      "epoch": 37.69824128355446,
      "grad_norm": 0.00011569714843062684,
      "learning_rate": 1.2301758716445542e-05,
      "loss": 0.0,
      "step": 122180
    },
    {
      "epoch": 37.701326751002775,
      "grad_norm": 7.176749022619333e-06,
      "learning_rate": 1.2298673248997223e-05,
      "loss": 0.0001,
      "step": 122190
    },
    {
      "epoch": 37.7044122184511,
      "grad_norm": 6.64337733269349e-07,
      "learning_rate": 1.2295587781548905e-05,
      "loss": 0.0,
      "step": 122200
    },
    {
      "epoch": 37.70749768589941,
      "grad_norm": 2.781905550364172e-07,
      "learning_rate": 1.2292502314100588e-05,
      "loss": 0.0023,
      "step": 122210
    },
    {
      "epoch": 37.710583153347734,
      "grad_norm": 0.002723840530961752,
      "learning_rate": 1.2289416846652269e-05,
      "loss": 0.0,
      "step": 122220
    },
    {
      "epoch": 37.71366862079605,
      "grad_norm": 0.0002876767539419234,
      "learning_rate": 1.228633137920395e-05,
      "loss": 0.0,
      "step": 122230
    },
    {
      "epoch": 37.71675408824437,
      "grad_norm": 5.6252890345831474e-08,
      "learning_rate": 1.228324591175563e-05,
      "loss": 0.0001,
      "step": 122240
    },
    {
      "epoch": 37.71983955569269,
      "grad_norm": 0.008419487625360489,
      "learning_rate": 1.2280160444307313e-05,
      "loss": 0.0,
      "step": 122250
    },
    {
      "epoch": 37.72292502314101,
      "grad_norm": 2.9150376690267876e-07,
      "learning_rate": 1.2277074976858995e-05,
      "loss": 0.0,
      "step": 122260
    },
    {
      "epoch": 37.726010490589324,
      "grad_norm": 4.34672938354197e-06,
      "learning_rate": 1.2273989509410676e-05,
      "loss": 0.0,
      "step": 122270
    },
    {
      "epoch": 37.72909595803764,
      "grad_norm": 0.0018599635222926736,
      "learning_rate": 1.2270904041962358e-05,
      "loss": 0.0004,
      "step": 122280
    },
    {
      "epoch": 37.73218142548596,
      "grad_norm": 8.21097387415648e-07,
      "learning_rate": 1.226781857451404e-05,
      "loss": 0.0,
      "step": 122290
    },
    {
      "epoch": 37.73526689293428,
      "grad_norm": 0.00015241689106915146,
      "learning_rate": 1.226473310706572e-05,
      "loss": 0.0,
      "step": 122300
    },
    {
      "epoch": 37.7383523603826,
      "grad_norm": 0.04322558268904686,
      "learning_rate": 1.2261647639617402e-05,
      "loss": 0.0,
      "step": 122310
    },
    {
      "epoch": 37.741437827830914,
      "grad_norm": 9.197315193887334e-06,
      "learning_rate": 1.2258562172169085e-05,
      "loss": 0.0,
      "step": 122320
    },
    {
      "epoch": 37.74452329527924,
      "grad_norm": 9.261979698749201e-07,
      "learning_rate": 1.2255476704720766e-05,
      "loss": 0.0005,
      "step": 122330
    },
    {
      "epoch": 37.74760876272755,
      "grad_norm": 1.1749749319278635e-05,
      "learning_rate": 1.2252391237272447e-05,
      "loss": 0.0,
      "step": 122340
    },
    {
      "epoch": 37.750694230175874,
      "grad_norm": 9.64193418440118e-07,
      "learning_rate": 1.2249305769824129e-05,
      "loss": 0.0,
      "step": 122350
    },
    {
      "epoch": 37.75377969762419,
      "grad_norm": 0.0003550871042534709,
      "learning_rate": 1.224622030237581e-05,
      "loss": 0.0,
      "step": 122360
    },
    {
      "epoch": 37.75686516507251,
      "grad_norm": 5.084059750970482e-08,
      "learning_rate": 1.2243134834927492e-05,
      "loss": 0.0,
      "step": 122370
    },
    {
      "epoch": 37.75995063252083,
      "grad_norm": 2.3137761218094965e-06,
      "learning_rate": 1.2240049367479175e-05,
      "loss": 0.0,
      "step": 122380
    },
    {
      "epoch": 37.76303609996914,
      "grad_norm": 5.488638635142706e-05,
      "learning_rate": 1.2236963900030856e-05,
      "loss": 0.0,
      "step": 122390
    },
    {
      "epoch": 37.766121567417464,
      "grad_norm": 4.191480184090324e-05,
      "learning_rate": 1.2233878432582536e-05,
      "loss": 0.0001,
      "step": 122400
    },
    {
      "epoch": 37.76920703486578,
      "grad_norm": 4.1667411210255523e-07,
      "learning_rate": 1.2230792965134219e-05,
      "loss": 0.0,
      "step": 122410
    },
    {
      "epoch": 37.7722925023141,
      "grad_norm": 3.2275218586619303e-07,
      "learning_rate": 1.22277074976859e-05,
      "loss": 0.0,
      "step": 122420
    },
    {
      "epoch": 37.77537796976242,
      "grad_norm": 7.349611405516043e-05,
      "learning_rate": 1.2224622030237582e-05,
      "loss": 0.0,
      "step": 122430
    },
    {
      "epoch": 37.77846343721074,
      "grad_norm": 4.191415658993947e-09,
      "learning_rate": 1.2221536562789263e-05,
      "loss": 0.0,
      "step": 122440
    },
    {
      "epoch": 37.781548904659054,
      "grad_norm": 3.552584530552849e-06,
      "learning_rate": 1.2218451095340945e-05,
      "loss": 0.0,
      "step": 122450
    },
    {
      "epoch": 37.78463437210738,
      "grad_norm": 8.444916602456942e-05,
      "learning_rate": 1.2215365627892626e-05,
      "loss": 0.0,
      "step": 122460
    },
    {
      "epoch": 37.78771983955569,
      "grad_norm": 0.08235369622707367,
      "learning_rate": 1.2212280160444307e-05,
      "loss": 0.0001,
      "step": 122470
    },
    {
      "epoch": 37.790805307004014,
      "grad_norm": 1.637390050746035e-05,
      "learning_rate": 1.220919469299599e-05,
      "loss": 0.0,
      "step": 122480
    },
    {
      "epoch": 37.79389077445233,
      "grad_norm": 5.990445060888305e-06,
      "learning_rate": 1.2206109225547672e-05,
      "loss": 0.0,
      "step": 122490
    },
    {
      "epoch": 37.79697624190065,
      "grad_norm": 1.100930148822954e-05,
      "learning_rate": 1.2203023758099353e-05,
      "loss": 0.0,
      "step": 122500
    },
    {
      "epoch": 37.80006170934897,
      "grad_norm": 2.8281226605031407e-07,
      "learning_rate": 1.2199938290651035e-05,
      "loss": 0.0,
      "step": 122510
    },
    {
      "epoch": 37.80314717679728,
      "grad_norm": 2.473787503731728e-07,
      "learning_rate": 1.2196852823202716e-05,
      "loss": 0.0,
      "step": 122520
    },
    {
      "epoch": 37.806232644245604,
      "grad_norm": 0.004948463290929794,
      "learning_rate": 1.2193767355754397e-05,
      "loss": 0.0,
      "step": 122530
    },
    {
      "epoch": 37.80931811169392,
      "grad_norm": 3.545732397469692e-06,
      "learning_rate": 1.2190681888306079e-05,
      "loss": 0.0,
      "step": 122540
    },
    {
      "epoch": 37.81240357914224,
      "grad_norm": 1.6514786693733186e-05,
      "learning_rate": 1.2187596420857762e-05,
      "loss": 0.0,
      "step": 122550
    },
    {
      "epoch": 37.81548904659056,
      "grad_norm": 1.5384634011184062e-08,
      "learning_rate": 1.2184510953409442e-05,
      "loss": 0.0,
      "step": 122560
    },
    {
      "epoch": 37.81857451403888,
      "grad_norm": 0.006088048219680786,
      "learning_rate": 1.2181425485961123e-05,
      "loss": 0.0,
      "step": 122570
    },
    {
      "epoch": 37.821659981487194,
      "grad_norm": 1.0369637493568007e-05,
      "learning_rate": 1.2178340018512806e-05,
      "loss": 0.0,
      "step": 122580
    },
    {
      "epoch": 37.824745448935516,
      "grad_norm": 1.7549265976413153e-05,
      "learning_rate": 1.2175254551064486e-05,
      "loss": 0.0,
      "step": 122590
    },
    {
      "epoch": 37.82783091638383,
      "grad_norm": 0.01033174991607666,
      "learning_rate": 1.2172169083616169e-05,
      "loss": 0.0001,
      "step": 122600
    },
    {
      "epoch": 37.830916383832154,
      "grad_norm": 0.000704291567672044,
      "learning_rate": 1.2169083616167851e-05,
      "loss": 0.0001,
      "step": 122610
    },
    {
      "epoch": 37.83400185128047,
      "grad_norm": 9.15871078177588e-06,
      "learning_rate": 1.2165998148719532e-05,
      "loss": 0.0,
      "step": 122620
    },
    {
      "epoch": 37.837087318728784,
      "grad_norm": 7.145783911255421e-06,
      "learning_rate": 1.2162912681271213e-05,
      "loss": 0.0,
      "step": 122630
    },
    {
      "epoch": 37.840172786177106,
      "grad_norm": 1.8687704141484573e-05,
      "learning_rate": 1.2159827213822894e-05,
      "loss": 0.0,
      "step": 122640
    },
    {
      "epoch": 37.84325825362542,
      "grad_norm": 1.298667598348402e-06,
      "learning_rate": 1.2156741746374576e-05,
      "loss": 0.0011,
      "step": 122650
    },
    {
      "epoch": 37.846343721073744,
      "grad_norm": 0.00019980677461717278,
      "learning_rate": 1.2153656278926259e-05,
      "loss": 0.0,
      "step": 122660
    },
    {
      "epoch": 37.84942918852206,
      "grad_norm": 2.7084292014478706e-05,
      "learning_rate": 1.215057081147794e-05,
      "loss": 0.0,
      "step": 122670
    },
    {
      "epoch": 37.85251465597038,
      "grad_norm": 4.834897140426619e-07,
      "learning_rate": 1.2147485344029622e-05,
      "loss": 0.0,
      "step": 122680
    },
    {
      "epoch": 37.8556001234187,
      "grad_norm": 2.0642903564294102e-07,
      "learning_rate": 1.2144399876581303e-05,
      "loss": 0.0001,
      "step": 122690
    },
    {
      "epoch": 37.85868559086702,
      "grad_norm": 3.1361751098302193e-06,
      "learning_rate": 1.2141314409132984e-05,
      "loss": 0.0001,
      "step": 122700
    },
    {
      "epoch": 37.861771058315334,
      "grad_norm": 0.00032335217110812664,
      "learning_rate": 1.2138228941684666e-05,
      "loss": 0.0,
      "step": 122710
    },
    {
      "epoch": 37.864856525763656,
      "grad_norm": 8.507014172209892e-06,
      "learning_rate": 1.2135143474236347e-05,
      "loss": 0.0,
      "step": 122720
    },
    {
      "epoch": 37.86794199321197,
      "grad_norm": 0.015174046158790588,
      "learning_rate": 1.213205800678803e-05,
      "loss": 0.0,
      "step": 122730
    },
    {
      "epoch": 37.87102746066029,
      "grad_norm": 4.4159773437968397e-07,
      "learning_rate": 1.212897253933971e-05,
      "loss": 0.0,
      "step": 122740
    },
    {
      "epoch": 37.87411292810861,
      "grad_norm": 3.234505356886075e-06,
      "learning_rate": 1.2125887071891393e-05,
      "loss": 0.0,
      "step": 122750
    },
    {
      "epoch": 37.877198395556924,
      "grad_norm": 0.0008710519759915769,
      "learning_rate": 1.2122801604443073e-05,
      "loss": 0.0,
      "step": 122760
    },
    {
      "epoch": 37.880283863005246,
      "grad_norm": 0.00024159986060112715,
      "learning_rate": 1.2119716136994754e-05,
      "loss": 0.0,
      "step": 122770
    },
    {
      "epoch": 37.88336933045356,
      "grad_norm": 7.960796466477404e-08,
      "learning_rate": 1.2116630669546437e-05,
      "loss": 0.0,
      "step": 122780
    },
    {
      "epoch": 37.886454797901884,
      "grad_norm": 5.286562554829288e-06,
      "learning_rate": 1.2113545202098119e-05,
      "loss": 0.0,
      "step": 122790
    },
    {
      "epoch": 37.8895402653502,
      "grad_norm": 2.5219186738922872e-08,
      "learning_rate": 1.21104597346498e-05,
      "loss": 0.0,
      "step": 122800
    },
    {
      "epoch": 37.89262573279852,
      "grad_norm": 3.8810827618362964e-07,
      "learning_rate": 1.2107374267201482e-05,
      "loss": 0.0,
      "step": 122810
    },
    {
      "epoch": 37.895711200246836,
      "grad_norm": 2.3212825794871605e-07,
      "learning_rate": 1.2104288799753163e-05,
      "loss": 0.0,
      "step": 122820
    },
    {
      "epoch": 37.89879666769516,
      "grad_norm": 3.791472772718407e-05,
      "learning_rate": 1.2101203332304844e-05,
      "loss": 0.0,
      "step": 122830
    },
    {
      "epoch": 37.901882135143474,
      "grad_norm": 2.5019512577273417e-06,
      "learning_rate": 1.2098117864856526e-05,
      "loss": 0.0,
      "step": 122840
    },
    {
      "epoch": 37.904967602591796,
      "grad_norm": 0.00015802498091943562,
      "learning_rate": 1.2095032397408209e-05,
      "loss": 0.0,
      "step": 122850
    },
    {
      "epoch": 37.90805307004011,
      "grad_norm": 5.194111167838855e-07,
      "learning_rate": 1.209194692995989e-05,
      "loss": 0.0,
      "step": 122860
    },
    {
      "epoch": 37.911138537488426,
      "grad_norm": 0.004534123931080103,
      "learning_rate": 1.208886146251157e-05,
      "loss": 0.0,
      "step": 122870
    },
    {
      "epoch": 37.91422400493675,
      "grad_norm": 0.00020855976617895067,
      "learning_rate": 1.2085775995063253e-05,
      "loss": 0.0,
      "step": 122880
    },
    {
      "epoch": 37.917309472385064,
      "grad_norm": 1.6325715250786743e-06,
      "learning_rate": 1.2082690527614934e-05,
      "loss": 0.0,
      "step": 122890
    },
    {
      "epoch": 37.920394939833386,
      "grad_norm": 2.1721312805311754e-05,
      "learning_rate": 1.2079605060166616e-05,
      "loss": 0.0003,
      "step": 122900
    },
    {
      "epoch": 37.9234804072817,
      "grad_norm": 3.1501474495598814e-06,
      "learning_rate": 1.2076519592718299e-05,
      "loss": 0.0,
      "step": 122910
    },
    {
      "epoch": 37.926565874730024,
      "grad_norm": 8.99166043382138e-05,
      "learning_rate": 1.207343412526998e-05,
      "loss": 0.0,
      "step": 122920
    },
    {
      "epoch": 37.92965134217834,
      "grad_norm": 0.00043050418025813997,
      "learning_rate": 1.207034865782166e-05,
      "loss": 0.0,
      "step": 122930
    },
    {
      "epoch": 37.93273680962666,
      "grad_norm": 1.0538309652474709e-05,
      "learning_rate": 1.2067263190373341e-05,
      "loss": 0.0,
      "step": 122940
    },
    {
      "epoch": 37.935822277074976,
      "grad_norm": 3.38420113621396e-06,
      "learning_rate": 1.2064177722925023e-05,
      "loss": 0.0,
      "step": 122950
    },
    {
      "epoch": 37.9389077445233,
      "grad_norm": 0.48691219091415405,
      "learning_rate": 1.2061092255476706e-05,
      "loss": 0.0002,
      "step": 122960
    },
    {
      "epoch": 37.941993211971614,
      "grad_norm": 0.00023899840016383678,
      "learning_rate": 1.2058006788028387e-05,
      "loss": 0.0,
      "step": 122970
    },
    {
      "epoch": 37.94507867941993,
      "grad_norm": 4.715750456796286e-09,
      "learning_rate": 1.205492132058007e-05,
      "loss": 0.0,
      "step": 122980
    },
    {
      "epoch": 37.94816414686825,
      "grad_norm": 0.00023096281802281737,
      "learning_rate": 1.205183585313175e-05,
      "loss": 0.0001,
      "step": 122990
    },
    {
      "epoch": 37.951249614316566,
      "grad_norm": 1.144888847193215e-05,
      "learning_rate": 1.204875038568343e-05,
      "loss": 0.0,
      "step": 123000
    },
    {
      "epoch": 37.95433508176489,
      "grad_norm": 3.119427161024646e-09,
      "learning_rate": 1.2045664918235113e-05,
      "loss": 0.0,
      "step": 123010
    },
    {
      "epoch": 37.957420549213204,
      "grad_norm": 9.135832806350663e-05,
      "learning_rate": 1.2042579450786796e-05,
      "loss": 0.0,
      "step": 123020
    },
    {
      "epoch": 37.960506016661526,
      "grad_norm": 3.16756342044755e-07,
      "learning_rate": 1.2039493983338476e-05,
      "loss": 0.0,
      "step": 123030
    },
    {
      "epoch": 37.96359148410984,
      "grad_norm": 6.621011380048003e-06,
      "learning_rate": 1.2036408515890157e-05,
      "loss": 0.0,
      "step": 123040
    },
    {
      "epoch": 37.96667695155816,
      "grad_norm": 2.698058324313024e-06,
      "learning_rate": 1.203332304844184e-05,
      "loss": 0.0,
      "step": 123050
    },
    {
      "epoch": 37.96976241900648,
      "grad_norm": 3.0992785013950197e-06,
      "learning_rate": 1.203023758099352e-05,
      "loss": 0.0,
      "step": 123060
    },
    {
      "epoch": 37.9728478864548,
      "grad_norm": 1.4370591088663787e-05,
      "learning_rate": 1.2027152113545203e-05,
      "loss": 0.0,
      "step": 123070
    },
    {
      "epoch": 37.975933353903116,
      "grad_norm": 0.015014098025858402,
      "learning_rate": 1.2024066646096885e-05,
      "loss": 0.0,
      "step": 123080
    },
    {
      "epoch": 37.97901882135143,
      "grad_norm": 0.00010825901699718088,
      "learning_rate": 1.2020981178648566e-05,
      "loss": 0.0,
      "step": 123090
    },
    {
      "epoch": 37.98210428879975,
      "grad_norm": 1.4057093721930869e-05,
      "learning_rate": 1.2017895711200247e-05,
      "loss": 0.0,
      "step": 123100
    },
    {
      "epoch": 37.98518975624807,
      "grad_norm": 5.837260346197581e-07,
      "learning_rate": 1.2014810243751928e-05,
      "loss": 0.0,
      "step": 123110
    },
    {
      "epoch": 37.98827522369639,
      "grad_norm": 5.9323244983033874e-08,
      "learning_rate": 1.201172477630361e-05,
      "loss": 0.0,
      "step": 123120
    },
    {
      "epoch": 37.991360691144706,
      "grad_norm": 1.7798056717310828e-07,
      "learning_rate": 1.2008639308855293e-05,
      "loss": 0.0,
      "step": 123130
    },
    {
      "epoch": 37.99444615859303,
      "grad_norm": 3.4782780858222395e-05,
      "learning_rate": 1.2005553841406974e-05,
      "loss": 0.0,
      "step": 123140
    },
    {
      "epoch": 37.997531626041344,
      "grad_norm": 3.2660480542290315e-07,
      "learning_rate": 1.2002468373958656e-05,
      "loss": 0.0,
      "step": 123150
    },
    {
      "epoch": 38.0,
      "eval_accuracy_branch1": 1.0,
      "eval_accuracy_branch2": 0.3933238814463316,
      "eval_f1_branch1": 1.0,
      "eval_f1_branch2": 0.37330504643757106,
      "eval_loss": 1.3725194776270655e-06,
      "eval_precision_branch1": 1.0,
      "eval_precision_branch2": 0.5161726709341368,
      "eval_recall_branch1": 1.0,
      "eval_recall_branch2": 0.509512166893319,
      "eval_runtime": 238.2641,
      "eval_samples_per_second": 435.16,
      "eval_steps_per_second": 54.398,
      "step": 123158
    },
    {
      "epoch": 38.000617093489666,
      "grad_norm": 1.0383488415754982e-06,
      "learning_rate": 1.1999382906510337e-05,
      "loss": 0.0,
      "step": 123160
    },
    {
      "epoch": 38.00370256093798,
      "grad_norm": 7.991711026988924e-05,
      "learning_rate": 1.1996297439062018e-05,
      "loss": 0.0,
      "step": 123170
    },
    {
      "epoch": 38.0067880283863,
      "grad_norm": 1.4220111665963486e-07,
      "learning_rate": 1.19932119716137e-05,
      "loss": 0.0,
      "step": 123180
    },
    {
      "epoch": 38.00987349583462,
      "grad_norm": 2.350080194446491e-06,
      "learning_rate": 1.1990126504165383e-05,
      "loss": 0.0,
      "step": 123190
    },
    {
      "epoch": 38.01295896328294,
      "grad_norm": 6.997086643423245e-08,
      "learning_rate": 1.1987041036717063e-05,
      "loss": 0.0001,
      "step": 123200
    },
    {
      "epoch": 38.016044430731256,
      "grad_norm": 7.502123025915353e-06,
      "learning_rate": 1.1983955569268744e-05,
      "loss": 0.0,
      "step": 123210
    },
    {
      "epoch": 38.01912989817957,
      "grad_norm": 3.1562976232635265e-07,
      "learning_rate": 1.1980870101820427e-05,
      "loss": 0.0,
      "step": 123220
    },
    {
      "epoch": 38.02221536562789,
      "grad_norm": 1.1952826071137679e-06,
      "learning_rate": 1.1977784634372107e-05,
      "loss": 0.0,
      "step": 123230
    },
    {
      "epoch": 38.02530083307621,
      "grad_norm": 1.4779542425458203e-06,
      "learning_rate": 1.197469916692379e-05,
      "loss": 0.0,
      "step": 123240
    },
    {
      "epoch": 38.02838630052453,
      "grad_norm": 8.78487917361781e-05,
      "learning_rate": 1.1971613699475472e-05,
      "loss": 0.0,
      "step": 123250
    },
    {
      "epoch": 38.031471767972846,
      "grad_norm": 6.003251229458328e-08,
      "learning_rate": 1.1968528232027153e-05,
      "loss": 0.0,
      "step": 123260
    },
    {
      "epoch": 38.03455723542117,
      "grad_norm": 9.403258900420042e-07,
      "learning_rate": 1.1965442764578834e-05,
      "loss": 0.0,
      "step": 123270
    },
    {
      "epoch": 38.03764270286948,
      "grad_norm": 0.0004942469531670213,
      "learning_rate": 1.1962357297130516e-05,
      "loss": 0.0009,
      "step": 123280
    },
    {
      "epoch": 38.040728170317806,
      "grad_norm": 2.817784263697831e-07,
      "learning_rate": 1.1959271829682197e-05,
      "loss": 0.0,
      "step": 123290
    },
    {
      "epoch": 38.04381363776612,
      "grad_norm": 8.509644544574257e-07,
      "learning_rate": 1.195618636223388e-05,
      "loss": 0.0,
      "step": 123300
    },
    {
      "epoch": 38.04689910521444,
      "grad_norm": 2.1521718736039475e-06,
      "learning_rate": 1.195310089478556e-05,
      "loss": 0.0,
      "step": 123310
    },
    {
      "epoch": 38.04998457266276,
      "grad_norm": 1.0565040611254517e-05,
      "learning_rate": 1.1950015427337243e-05,
      "loss": 0.0015,
      "step": 123320
    },
    {
      "epoch": 38.05307004011107,
      "grad_norm": 1.8868919369197101e-06,
      "learning_rate": 1.1946929959888924e-05,
      "loss": 0.0,
      "step": 123330
    },
    {
      "epoch": 38.056155507559396,
      "grad_norm": 1.8248098058393225e-05,
      "learning_rate": 1.1943844492440604e-05,
      "loss": 0.0002,
      "step": 123340
    },
    {
      "epoch": 38.05924097500771,
      "grad_norm": 0.04438180476427078,
      "learning_rate": 1.1940759024992287e-05,
      "loss": 0.0,
      "step": 123350
    },
    {
      "epoch": 38.06232644245603,
      "grad_norm": 0.0018940491136163473,
      "learning_rate": 1.1937673557543968e-05,
      "loss": 0.0,
      "step": 123360
    },
    {
      "epoch": 38.06541190990435,
      "grad_norm": 0.03938575088977814,
      "learning_rate": 1.193458809009565e-05,
      "loss": 0.0008,
      "step": 123370
    },
    {
      "epoch": 38.06849737735267,
      "grad_norm": 0.0003511770046316087,
      "learning_rate": 1.1931502622647333e-05,
      "loss": 0.0,
      "step": 123380
    },
    {
      "epoch": 38.071582844800986,
      "grad_norm": 1.2228300874994602e-05,
      "learning_rate": 1.1928417155199013e-05,
      "loss": 0.0,
      "step": 123390
    },
    {
      "epoch": 38.07466831224931,
      "grad_norm": 0.00017148477490991354,
      "learning_rate": 1.1925331687750694e-05,
      "loss": 0.0002,
      "step": 123400
    },
    {
      "epoch": 38.07775377969762,
      "grad_norm": 0.003916394431143999,
      "learning_rate": 1.1922246220302375e-05,
      "loss": 0.0,
      "step": 123410
    },
    {
      "epoch": 38.080839247145946,
      "grad_norm": 4.4975695345783606e-07,
      "learning_rate": 1.1919160752854057e-05,
      "loss": 0.0,
      "step": 123420
    },
    {
      "epoch": 38.08392471459426,
      "grad_norm": 4.148219545641041e-07,
      "learning_rate": 1.191607528540574e-05,
      "loss": 0.0,
      "step": 123430
    },
    {
      "epoch": 38.087010182042576,
      "grad_norm": 0.0006407877081073821,
      "learning_rate": 1.191298981795742e-05,
      "loss": 0.0001,
      "step": 123440
    },
    {
      "epoch": 38.0900956494909,
      "grad_norm": 0.0021488750353455544,
      "learning_rate": 1.1909904350509103e-05,
      "loss": 0.0003,
      "step": 123450
    },
    {
      "epoch": 38.09318111693921,
      "grad_norm": 4.131200270762747e-09,
      "learning_rate": 1.1906818883060784e-05,
      "loss": 0.0,
      "step": 123460
    },
    {
      "epoch": 38.096266584387536,
      "grad_norm": 1.7886702607938787e-06,
      "learning_rate": 1.1903733415612465e-05,
      "loss": 0.0,
      "step": 123470
    },
    {
      "epoch": 38.09935205183585,
      "grad_norm": 9.253010375687154e-07,
      "learning_rate": 1.1900647948164147e-05,
      "loss": 0.0,
      "step": 123480
    },
    {
      "epoch": 38.10243751928417,
      "grad_norm": 0.004727522376924753,
      "learning_rate": 1.189756248071583e-05,
      "loss": 0.0,
      "step": 123490
    },
    {
      "epoch": 38.10552298673249,
      "grad_norm": 1.588511440786533e-05,
      "learning_rate": 1.189447701326751e-05,
      "loss": 0.0,
      "step": 123500
    },
    {
      "epoch": 38.10860845418081,
      "grad_norm": 0.022217098623514175,
      "learning_rate": 1.1891391545819191e-05,
      "loss": 0.0,
      "step": 123510
    },
    {
      "epoch": 38.111693921629126,
      "grad_norm": 5.901527765672654e-05,
      "learning_rate": 1.1888306078370874e-05,
      "loss": 0.0,
      "step": 123520
    },
    {
      "epoch": 38.11477938907745,
      "grad_norm": 9.472893580664277e-09,
      "learning_rate": 1.1885220610922555e-05,
      "loss": 0.0,
      "step": 123530
    },
    {
      "epoch": 38.11786485652576,
      "grad_norm": 0.0007835741271264851,
      "learning_rate": 1.1882135143474237e-05,
      "loss": 0.0,
      "step": 123540
    },
    {
      "epoch": 38.120950323974085,
      "grad_norm": 0.0002818067732732743,
      "learning_rate": 1.187904967602592e-05,
      "loss": 0.0,
      "step": 123550
    },
    {
      "epoch": 38.1240357914224,
      "grad_norm": 1.6708873999959906e-06,
      "learning_rate": 1.18759642085776e-05,
      "loss": 0.0,
      "step": 123560
    },
    {
      "epoch": 38.127121258870716,
      "grad_norm": 0.0021244236268103123,
      "learning_rate": 1.1872878741129281e-05,
      "loss": 0.0,
      "step": 123570
    },
    {
      "epoch": 38.13020672631904,
      "grad_norm": 2.642660206220171e-07,
      "learning_rate": 1.1869793273680964e-05,
      "loss": 0.0,
      "step": 123580
    },
    {
      "epoch": 38.13329219376735,
      "grad_norm": 2.9391562748060096e-06,
      "learning_rate": 1.1866707806232644e-05,
      "loss": 0.0,
      "step": 123590
    },
    {
      "epoch": 38.136377661215676,
      "grad_norm": 7.908528232292156e-07,
      "learning_rate": 1.1863622338784327e-05,
      "loss": 0.0001,
      "step": 123600
    },
    {
      "epoch": 38.13946312866399,
      "grad_norm": 0.00013210954784881324,
      "learning_rate": 1.1860536871336008e-05,
      "loss": 0.0,
      "step": 123610
    },
    {
      "epoch": 38.14254859611231,
      "grad_norm": 0.00013587172725237906,
      "learning_rate": 1.185745140388769e-05,
      "loss": 0.0,
      "step": 123620
    },
    {
      "epoch": 38.14563406356063,
      "grad_norm": 0.003584094811230898,
      "learning_rate": 1.1854365936439371e-05,
      "loss": 0.0,
      "step": 123630
    },
    {
      "epoch": 38.14871953100895,
      "grad_norm": 1.0260646376991645e-05,
      "learning_rate": 1.1851280468991052e-05,
      "loss": 0.0,
      "step": 123640
    },
    {
      "epoch": 38.151804998457266,
      "grad_norm": 1.2522600627562497e-06,
      "learning_rate": 1.1848195001542734e-05,
      "loss": 0.0,
      "step": 123650
    },
    {
      "epoch": 38.15489046590559,
      "grad_norm": 2.25733618464119e-08,
      "learning_rate": 1.1845109534094417e-05,
      "loss": 0.0,
      "step": 123660
    },
    {
      "epoch": 38.1579759333539,
      "grad_norm": 1.5591734836561955e-07,
      "learning_rate": 1.1842024066646097e-05,
      "loss": 0.0,
      "step": 123670
    },
    {
      "epoch": 38.16106140080222,
      "grad_norm": 3.089587335125543e-05,
      "learning_rate": 1.183893859919778e-05,
      "loss": 0.0,
      "step": 123680
    },
    {
      "epoch": 38.16414686825054,
      "grad_norm": 4.238326134498038e-09,
      "learning_rate": 1.183585313174946e-05,
      "loss": 0.0,
      "step": 123690
    },
    {
      "epoch": 38.167232335698856,
      "grad_norm": 4.768086455442244e-06,
      "learning_rate": 1.1832767664301141e-05,
      "loss": 0.0,
      "step": 123700
    },
    {
      "epoch": 38.17031780314718,
      "grad_norm": 5.788418638985604e-05,
      "learning_rate": 1.1829682196852824e-05,
      "loss": 0.0,
      "step": 123710
    },
    {
      "epoch": 38.17340327059549,
      "grad_norm": 0.05479106679558754,
      "learning_rate": 1.1826596729404506e-05,
      "loss": 0.0,
      "step": 123720
    },
    {
      "epoch": 38.176488738043815,
      "grad_norm": 0.0001726532500470057,
      "learning_rate": 1.1823511261956187e-05,
      "loss": 0.0,
      "step": 123730
    },
    {
      "epoch": 38.17957420549213,
      "grad_norm": 0.00022649517632089555,
      "learning_rate": 1.1820425794507868e-05,
      "loss": 0.0,
      "step": 123740
    },
    {
      "epoch": 38.18265967294045,
      "grad_norm": 1.1949319969062344e-06,
      "learning_rate": 1.181734032705955e-05,
      "loss": 0.0009,
      "step": 123750
    },
    {
      "epoch": 38.18574514038877,
      "grad_norm": 2.3105836532977264e-07,
      "learning_rate": 1.1814254859611231e-05,
      "loss": 0.0,
      "step": 123760
    },
    {
      "epoch": 38.18883060783709,
      "grad_norm": 5.552940820052754e-06,
      "learning_rate": 1.1811169392162914e-05,
      "loss": 0.0,
      "step": 123770
    },
    {
      "epoch": 38.191916075285405,
      "grad_norm": 0.0018810284091159701,
      "learning_rate": 1.1808083924714596e-05,
      "loss": 0.0,
      "step": 123780
    },
    {
      "epoch": 38.19500154273372,
      "grad_norm": 0.00011705100769177079,
      "learning_rate": 1.1804998457266277e-05,
      "loss": 0.0,
      "step": 123790
    },
    {
      "epoch": 38.19808701018204,
      "grad_norm": 2.925501585006714,
      "learning_rate": 1.1801912989817958e-05,
      "loss": 0.0014,
      "step": 123800
    },
    {
      "epoch": 38.20117247763036,
      "grad_norm": 1.9313881693960866e-06,
      "learning_rate": 1.1798827522369639e-05,
      "loss": 0.0,
      "step": 123810
    },
    {
      "epoch": 38.20425794507868,
      "grad_norm": 2.4402902454312425e-06,
      "learning_rate": 1.1795742054921321e-05,
      "loss": 0.0003,
      "step": 123820
    },
    {
      "epoch": 38.207343412526996,
      "grad_norm": 3.931381070287898e-05,
      "learning_rate": 1.1792656587473003e-05,
      "loss": 0.0001,
      "step": 123830
    },
    {
      "epoch": 38.21042887997532,
      "grad_norm": 0.000773786217905581,
      "learning_rate": 1.1789571120024684e-05,
      "loss": 0.0,
      "step": 123840
    },
    {
      "epoch": 38.21351434742363,
      "grad_norm": 0.0005814988981001079,
      "learning_rate": 1.1786485652576367e-05,
      "loss": 0.0,
      "step": 123850
    },
    {
      "epoch": 38.216599814871955,
      "grad_norm": 1.9307913780212402,
      "learning_rate": 1.1783400185128048e-05,
      "loss": 0.0016,
      "step": 123860
    },
    {
      "epoch": 38.21968528232027,
      "grad_norm": 0.00018885657482314855,
      "learning_rate": 1.1780314717679728e-05,
      "loss": 0.0,
      "step": 123870
    },
    {
      "epoch": 38.22277074976859,
      "grad_norm": 8.318732398038264e-06,
      "learning_rate": 1.177722925023141e-05,
      "loss": 0.0001,
      "step": 123880
    },
    {
      "epoch": 38.22585621721691,
      "grad_norm": 8.085349691100419e-05,
      "learning_rate": 1.1774143782783093e-05,
      "loss": 0.0,
      "step": 123890
    },
    {
      "epoch": 38.22894168466523,
      "grad_norm": 6.987550023040967e-06,
      "learning_rate": 1.1771058315334774e-05,
      "loss": 0.0,
      "step": 123900
    },
    {
      "epoch": 38.232027152113545,
      "grad_norm": 0.0004584792477544397,
      "learning_rate": 1.1767972847886455e-05,
      "loss": 0.0,
      "step": 123910
    },
    {
      "epoch": 38.23511261956186,
      "grad_norm": 6.740766593793523e-07,
      "learning_rate": 1.1764887380438137e-05,
      "loss": 0.0028,
      "step": 123920
    },
    {
      "epoch": 38.23819808701018,
      "grad_norm": 0.00040153434383682907,
      "learning_rate": 1.1761801912989818e-05,
      "loss": 0.0023,
      "step": 123930
    },
    {
      "epoch": 38.2412835544585,
      "grad_norm": 3.555700232027448e-07,
      "learning_rate": 1.17587164455415e-05,
      "loss": 0.0,
      "step": 123940
    },
    {
      "epoch": 38.24436902190682,
      "grad_norm": 3.5339605801709695e-06,
      "learning_rate": 1.1755630978093183e-05,
      "loss": 0.0,
      "step": 123950
    },
    {
      "epoch": 38.247454489355135,
      "grad_norm": 1.025546771415975e-05,
      "learning_rate": 1.1752545510644864e-05,
      "loss": 0.0,
      "step": 123960
    },
    {
      "epoch": 38.25053995680346,
      "grad_norm": 3.834597737295553e-05,
      "learning_rate": 1.1749460043196545e-05,
      "loss": 0.0,
      "step": 123970
    },
    {
      "epoch": 38.25362542425177,
      "grad_norm": 5.619504736387171e-05,
      "learning_rate": 1.1746374575748225e-05,
      "loss": 0.0,
      "step": 123980
    },
    {
      "epoch": 38.256710891700095,
      "grad_norm": 0.009953507222235203,
      "learning_rate": 1.1743289108299908e-05,
      "loss": 0.001,
      "step": 123990
    },
    {
      "epoch": 38.25979635914841,
      "grad_norm": 0.00016569030412938446,
      "learning_rate": 1.1740203640851589e-05,
      "loss": 0.0,
      "step": 124000
    },
    {
      "epoch": 38.26288182659673,
      "grad_norm": 5.413785402197391e-05,
      "learning_rate": 1.1737118173403271e-05,
      "loss": 0.0012,
      "step": 124010
    },
    {
      "epoch": 38.26596729404505,
      "grad_norm": 0.007173715624958277,
      "learning_rate": 1.1734032705954954e-05,
      "loss": 0.0001,
      "step": 124020
    },
    {
      "epoch": 38.26905276149336,
      "grad_norm": 0.007382548414170742,
      "learning_rate": 1.1730947238506634e-05,
      "loss": 0.0,
      "step": 124030
    },
    {
      "epoch": 38.272138228941685,
      "grad_norm": 0.0004797317960765213,
      "learning_rate": 1.1727861771058315e-05,
      "loss": 0.0,
      "step": 124040
    },
    {
      "epoch": 38.27522369639,
      "grad_norm": 7.198521780082956e-05,
      "learning_rate": 1.1724776303609998e-05,
      "loss": 0.0,
      "step": 124050
    },
    {
      "epoch": 38.27830916383832,
      "grad_norm": 2.4142156007656013e-07,
      "learning_rate": 1.1721690836161678e-05,
      "loss": 0.0136,
      "step": 124060
    },
    {
      "epoch": 38.28139463128664,
      "grad_norm": 3.522127087762783e-07,
      "learning_rate": 1.1718605368713361e-05,
      "loss": 0.0,
      "step": 124070
    },
    {
      "epoch": 38.28448009873496,
      "grad_norm": 6.140705954749137e-05,
      "learning_rate": 1.1715519901265042e-05,
      "loss": 0.0,
      "step": 124080
    },
    {
      "epoch": 38.287565566183275,
      "grad_norm": 7.783553996887349e-07,
      "learning_rate": 1.1712434433816724e-05,
      "loss": 0.0,
      "step": 124090
    },
    {
      "epoch": 38.2906510336316,
      "grad_norm": 5.183937901165336e-06,
      "learning_rate": 1.1709348966368405e-05,
      "loss": 0.0,
      "step": 124100
    },
    {
      "epoch": 38.29373650107991,
      "grad_norm": 7.5136144914722536e-06,
      "learning_rate": 1.1706263498920086e-05,
      "loss": 0.0006,
      "step": 124110
    },
    {
      "epoch": 38.296821968528235,
      "grad_norm": 1.985413518923451e-06,
      "learning_rate": 1.1703178031471768e-05,
      "loss": 0.0,
      "step": 124120
    },
    {
      "epoch": 38.29990743597655,
      "grad_norm": 1.029666600516066e-05,
      "learning_rate": 1.170009256402345e-05,
      "loss": 0.0,
      "step": 124130
    },
    {
      "epoch": 38.302992903424865,
      "grad_norm": 1.251827029591368e-06,
      "learning_rate": 1.1697007096575131e-05,
      "loss": 0.0,
      "step": 124140
    },
    {
      "epoch": 38.30607837087319,
      "grad_norm": 0.017315518110990524,
      "learning_rate": 1.1693921629126814e-05,
      "loss": 0.0001,
      "step": 124150
    },
    {
      "epoch": 38.3091638383215,
      "grad_norm": 3.022682449227432e-06,
      "learning_rate": 1.1690836161678495e-05,
      "loss": 0.0,
      "step": 124160
    },
    {
      "epoch": 38.312249305769825,
      "grad_norm": 2.8533447675727075e-06,
      "learning_rate": 1.1687750694230175e-05,
      "loss": 0.0,
      "step": 124170
    },
    {
      "epoch": 38.31533477321814,
      "grad_norm": 3.291742905275896e-05,
      "learning_rate": 1.1684665226781858e-05,
      "loss": 0.0,
      "step": 124180
    },
    {
      "epoch": 38.31842024066646,
      "grad_norm": 1.989980180638895e-09,
      "learning_rate": 1.168157975933354e-05,
      "loss": 0.0,
      "step": 124190
    },
    {
      "epoch": 38.32150570811478,
      "grad_norm": 5.055363772044075e-07,
      "learning_rate": 1.1678494291885221e-05,
      "loss": 0.0,
      "step": 124200
    },
    {
      "epoch": 38.3245911755631,
      "grad_norm": 1.5244230766597866e-08,
      "learning_rate": 1.1675408824436902e-05,
      "loss": 0.0,
      "step": 124210
    },
    {
      "epoch": 38.327676643011415,
      "grad_norm": 8.569038811856444e-09,
      "learning_rate": 1.1672323356988584e-05,
      "loss": 0.0029,
      "step": 124220
    },
    {
      "epoch": 38.33076211045974,
      "grad_norm": 0.0006631584838032722,
      "learning_rate": 1.1669237889540265e-05,
      "loss": 0.0,
      "step": 124230
    },
    {
      "epoch": 38.33384757790805,
      "grad_norm": 7.290240318980068e-06,
      "learning_rate": 1.1666152422091948e-05,
      "loss": 0.0,
      "step": 124240
    },
    {
      "epoch": 38.336933045356375,
      "grad_norm": 0.010306009091436863,
      "learning_rate": 1.166306695464363e-05,
      "loss": 0.0,
      "step": 124250
    },
    {
      "epoch": 38.34001851280469,
      "grad_norm": 9.560608305037022e-05,
      "learning_rate": 1.1659981487195311e-05,
      "loss": 0.0,
      "step": 124260
    },
    {
      "epoch": 38.343103980253005,
      "grad_norm": 1.4317142813524697e-06,
      "learning_rate": 1.1656896019746992e-05,
      "loss": 0.0,
      "step": 124270
    },
    {
      "epoch": 38.34618944770133,
      "grad_norm": 4.3025261220464017e-07,
      "learning_rate": 1.1653810552298673e-05,
      "loss": 0.0011,
      "step": 124280
    },
    {
      "epoch": 38.34927491514964,
      "grad_norm": 0.00020172461518086493,
      "learning_rate": 1.1650725084850355e-05,
      "loss": 0.0,
      "step": 124290
    },
    {
      "epoch": 38.352360382597965,
      "grad_norm": 1.197355913973297e-06,
      "learning_rate": 1.1647639617402038e-05,
      "loss": 0.0,
      "step": 124300
    },
    {
      "epoch": 38.35544585004628,
      "grad_norm": 0.00020155793754383922,
      "learning_rate": 1.1644554149953718e-05,
      "loss": 0.0,
      "step": 124310
    },
    {
      "epoch": 38.3585313174946,
      "grad_norm": 0.0004446803650353104,
      "learning_rate": 1.16414686825054e-05,
      "loss": 0.0003,
      "step": 124320
    },
    {
      "epoch": 38.36161678494292,
      "grad_norm": 2.0269507672310283e-07,
      "learning_rate": 1.1638383215057082e-05,
      "loss": 0.0,
      "step": 124330
    },
    {
      "epoch": 38.36470225239124,
      "grad_norm": 6.8109179665043484e-06,
      "learning_rate": 1.1635297747608762e-05,
      "loss": 0.0,
      "step": 124340
    },
    {
      "epoch": 38.367787719839555,
      "grad_norm": 5.419887543212099e-07,
      "learning_rate": 1.1632212280160445e-05,
      "loss": 0.0,
      "step": 124350
    },
    {
      "epoch": 38.37087318728788,
      "grad_norm": 0.000662163773085922,
      "learning_rate": 1.1629126812712127e-05,
      "loss": 0.0001,
      "step": 124360
    },
    {
      "epoch": 38.37395865473619,
      "grad_norm": 2.2939895643503405e-05,
      "learning_rate": 1.1626041345263808e-05,
      "loss": 0.0,
      "step": 124370
    },
    {
      "epoch": 38.37704412218451,
      "grad_norm": 2.3738863092148677e-05,
      "learning_rate": 1.1622955877815489e-05,
      "loss": 0.0,
      "step": 124380
    },
    {
      "epoch": 38.38012958963283,
      "grad_norm": 7.713728700764477e-05,
      "learning_rate": 1.1619870410367171e-05,
      "loss": 0.0,
      "step": 124390
    },
    {
      "epoch": 38.383215057081145,
      "grad_norm": 0.00013273622607812285,
      "learning_rate": 1.1616784942918852e-05,
      "loss": 0.0,
      "step": 124400
    },
    {
      "epoch": 38.38630052452947,
      "grad_norm": 1.6113790479721501e-07,
      "learning_rate": 1.1613699475470535e-05,
      "loss": 0.0,
      "step": 124410
    },
    {
      "epoch": 38.38938599197778,
      "grad_norm": 2.095067657137406e-07,
      "learning_rate": 1.1610614008022217e-05,
      "loss": 0.002,
      "step": 124420
    },
    {
      "epoch": 38.392471459426105,
      "grad_norm": 3.930972070520511e-06,
      "learning_rate": 1.1607528540573898e-05,
      "loss": 0.0,
      "step": 124430
    },
    {
      "epoch": 38.39555692687442,
      "grad_norm": 6.240345101105049e-06,
      "learning_rate": 1.1604443073125579e-05,
      "loss": 0.0,
      "step": 124440
    },
    {
      "epoch": 38.39864239432274,
      "grad_norm": 0.0001199870093842037,
      "learning_rate": 1.1601357605677261e-05,
      "loss": 0.0,
      "step": 124450
    },
    {
      "epoch": 38.40172786177106,
      "grad_norm": 4.708043732648548e-08,
      "learning_rate": 1.1598272138228942e-05,
      "loss": 0.0,
      "step": 124460
    },
    {
      "epoch": 38.40481332921938,
      "grad_norm": 1.5159237591433339e-05,
      "learning_rate": 1.1595186670780624e-05,
      "loss": 0.0,
      "step": 124470
    },
    {
      "epoch": 38.407898796667695,
      "grad_norm": 0.7323710918426514,
      "learning_rate": 1.1592101203332305e-05,
      "loss": 0.001,
      "step": 124480
    },
    {
      "epoch": 38.41098426411602,
      "grad_norm": 2.8726286473101936e-05,
      "learning_rate": 1.1589015735883988e-05,
      "loss": 0.0,
      "step": 124490
    },
    {
      "epoch": 38.41406973156433,
      "grad_norm": 0.0001983063411898911,
      "learning_rate": 1.1585930268435668e-05,
      "loss": 0.0,
      "step": 124500
    },
    {
      "epoch": 38.41715519901265,
      "grad_norm": 3.9889396674652744e-08,
      "learning_rate": 1.158284480098735e-05,
      "loss": 0.0,
      "step": 124510
    },
    {
      "epoch": 38.42024066646097,
      "grad_norm": 6.087276778998785e-05,
      "learning_rate": 1.1579759333539032e-05,
      "loss": 0.0,
      "step": 124520
    },
    {
      "epoch": 38.423326133909285,
      "grad_norm": 9.884121391223744e-05,
      "learning_rate": 1.1576673866090714e-05,
      "loss": 0.0,
      "step": 124530
    },
    {
      "epoch": 38.42641160135761,
      "grad_norm": 9.323703852714971e-05,
      "learning_rate": 1.1573588398642395e-05,
      "loss": 0.0,
      "step": 124540
    },
    {
      "epoch": 38.42949706880592,
      "grad_norm": 9.748248430696549e-07,
      "learning_rate": 1.1570502931194077e-05,
      "loss": 0.0001,
      "step": 124550
    },
    {
      "epoch": 38.432582536254245,
      "grad_norm": 2.5039728370757075e-06,
      "learning_rate": 1.1567417463745758e-05,
      "loss": 0.0,
      "step": 124560
    },
    {
      "epoch": 38.43566800370256,
      "grad_norm": 4.972612441633828e-05,
      "learning_rate": 1.1564331996297439e-05,
      "loss": 0.0,
      "step": 124570
    },
    {
      "epoch": 38.43875347115088,
      "grad_norm": 9.47893874503336e-10,
      "learning_rate": 1.156124652884912e-05,
      "loss": 0.0,
      "step": 124580
    },
    {
      "epoch": 38.4418389385992,
      "grad_norm": 2.304615918546915e-06,
      "learning_rate": 1.1558161061400804e-05,
      "loss": 0.0,
      "step": 124590
    },
    {
      "epoch": 38.44492440604752,
      "grad_norm": 1.6708690964151174e-05,
      "learning_rate": 1.1555075593952485e-05,
      "loss": 0.0,
      "step": 124600
    },
    {
      "epoch": 38.448009873495835,
      "grad_norm": 6.917916834936477e-07,
      "learning_rate": 1.1551990126504166e-05,
      "loss": 0.0,
      "step": 124610
    },
    {
      "epoch": 38.45109534094415,
      "grad_norm": 5.298241489981592e-07,
      "learning_rate": 1.1548904659055848e-05,
      "loss": 0.0,
      "step": 124620
    },
    {
      "epoch": 38.45418080839247,
      "grad_norm": 0.0001167385489679873,
      "learning_rate": 1.1545819191607529e-05,
      "loss": 0.0,
      "step": 124630
    },
    {
      "epoch": 38.45726627584079,
      "grad_norm": 1.6460587630717782e-06,
      "learning_rate": 1.154273372415921e-05,
      "loss": 0.0,
      "step": 124640
    },
    {
      "epoch": 38.46035174328911,
      "grad_norm": 0.0007897904142737389,
      "learning_rate": 1.1539648256710894e-05,
      "loss": 0.0,
      "step": 124650
    },
    {
      "epoch": 38.463437210737425,
      "grad_norm": 2.0435825263120933e-06,
      "learning_rate": 1.1536562789262575e-05,
      "loss": 0.0004,
      "step": 124660
    },
    {
      "epoch": 38.46652267818575,
      "grad_norm": 8.354730596238369e-08,
      "learning_rate": 1.1533477321814255e-05,
      "loss": 0.0,
      "step": 124670
    },
    {
      "epoch": 38.46960814563406,
      "grad_norm": 0.002267050789669156,
      "learning_rate": 1.1530391854365936e-05,
      "loss": 0.0,
      "step": 124680
    },
    {
      "epoch": 38.472693613082384,
      "grad_norm": 0.0003787224995903671,
      "learning_rate": 1.1527306386917619e-05,
      "loss": 0.0018,
      "step": 124690
    },
    {
      "epoch": 38.4757790805307,
      "grad_norm": 0.001854629721492529,
      "learning_rate": 1.15242209194693e-05,
      "loss": 0.0,
      "step": 124700
    },
    {
      "epoch": 38.47886454797902,
      "grad_norm": 0.01751648634672165,
      "learning_rate": 1.1521135452020982e-05,
      "loss": 0.0,
      "step": 124710
    },
    {
      "epoch": 38.48195001542734,
      "grad_norm": 3.115912932116771e-06,
      "learning_rate": 1.1518049984572664e-05,
      "loss": 0.0,
      "step": 124720
    },
    {
      "epoch": 38.48503548287565,
      "grad_norm": 4.0621916923555546e-06,
      "learning_rate": 1.1514964517124345e-05,
      "loss": 0.0,
      "step": 124730
    },
    {
      "epoch": 38.488120950323975,
      "grad_norm": 4.6267936681942956e-07,
      "learning_rate": 1.1511879049676026e-05,
      "loss": 0.0,
      "step": 124740
    },
    {
      "epoch": 38.49120641777229,
      "grad_norm": 3.608769247875898e-06,
      "learning_rate": 1.1508793582227707e-05,
      "loss": 0.0002,
      "step": 124750
    },
    {
      "epoch": 38.49429188522061,
      "grad_norm": 7.819058737368323e-06,
      "learning_rate": 1.1505708114779389e-05,
      "loss": 0.0,
      "step": 124760
    },
    {
      "epoch": 38.49737735266893,
      "grad_norm": 7.236668011501024e-07,
      "learning_rate": 1.1502622647331072e-05,
      "loss": 0.0002,
      "step": 124770
    },
    {
      "epoch": 38.50046282011725,
      "grad_norm": 8.254032195509353e-07,
      "learning_rate": 1.1499537179882752e-05,
      "loss": 0.0013,
      "step": 124780
    },
    {
      "epoch": 38.503548287565565,
      "grad_norm": 0.011513946577906609,
      "learning_rate": 1.1496451712434435e-05,
      "loss": 0.0,
      "step": 124790
    },
    {
      "epoch": 38.50663375501389,
      "grad_norm": 3.3697211620165035e-05,
      "learning_rate": 1.1493366244986116e-05,
      "loss": 0.0,
      "step": 124800
    },
    {
      "epoch": 38.5097192224622,
      "grad_norm": 6.662185114691965e-06,
      "learning_rate": 1.1490280777537796e-05,
      "loss": 0.0,
      "step": 124810
    },
    {
      "epoch": 38.512804689910524,
      "grad_norm": 0.0002026310976361856,
      "learning_rate": 1.1487195310089479e-05,
      "loss": 0.0001,
      "step": 124820
    },
    {
      "epoch": 38.51589015735884,
      "grad_norm": 1.2286498041191862e-08,
      "learning_rate": 1.1484109842641161e-05,
      "loss": 0.0,
      "step": 124830
    },
    {
      "epoch": 38.51897562480716,
      "grad_norm": 0.03908669948577881,
      "learning_rate": 1.1481024375192842e-05,
      "loss": 0.0,
      "step": 124840
    },
    {
      "epoch": 38.52206109225548,
      "grad_norm": 5.479475476022344e-06,
      "learning_rate": 1.1477938907744523e-05,
      "loss": 0.0,
      "step": 124850
    },
    {
      "epoch": 38.52514655970379,
      "grad_norm": 3.472181830943555e-08,
      "learning_rate": 1.1474853440296205e-05,
      "loss": 0.0,
      "step": 124860
    },
    {
      "epoch": 38.528232027152114,
      "grad_norm": 3.108222301761998e-08,
      "learning_rate": 1.1471767972847886e-05,
      "loss": 0.0,
      "step": 124870
    },
    {
      "epoch": 38.53131749460043,
      "grad_norm": 5.4748987167840824e-05,
      "learning_rate": 1.1468682505399569e-05,
      "loss": 0.0,
      "step": 124880
    },
    {
      "epoch": 38.53440296204875,
      "grad_norm": 0.00013216208026278764,
      "learning_rate": 1.1465597037951251e-05,
      "loss": 0.0,
      "step": 124890
    },
    {
      "epoch": 38.53748842949707,
      "grad_norm": 5.7510600726118355e-09,
      "learning_rate": 1.1462511570502932e-05,
      "loss": 0.0,
      "step": 124900
    },
    {
      "epoch": 38.54057389694539,
      "grad_norm": 4.662646006181603e-06,
      "learning_rate": 1.1459426103054613e-05,
      "loss": 0.0,
      "step": 124910
    },
    {
      "epoch": 38.543659364393704,
      "grad_norm": 7.904806409442244e-08,
      "learning_rate": 1.1456340635606295e-05,
      "loss": 0.0,
      "step": 124920
    },
    {
      "epoch": 38.54674483184203,
      "grad_norm": 1.319856437476119e-06,
      "learning_rate": 1.1453255168157976e-05,
      "loss": 0.0,
      "step": 124930
    },
    {
      "epoch": 38.54983029929034,
      "grad_norm": 0.00014642081805504858,
      "learning_rate": 1.1450169700709658e-05,
      "loss": 0.0,
      "step": 124940
    },
    {
      "epoch": 38.552915766738664,
      "grad_norm": 7.03768091625534e-05,
      "learning_rate": 1.144708423326134e-05,
      "loss": 0.0,
      "step": 124950
    },
    {
      "epoch": 38.55600123418698,
      "grad_norm": 1.1572399671422318e-05,
      "learning_rate": 1.1443998765813022e-05,
      "loss": 0.0,
      "step": 124960
    },
    {
      "epoch": 38.559086701635295,
      "grad_norm": 3.0645232982351445e-06,
      "learning_rate": 1.1440913298364703e-05,
      "loss": 0.0,
      "step": 124970
    },
    {
      "epoch": 38.56217216908362,
      "grad_norm": 1.6824810700200032e-07,
      "learning_rate": 1.1437827830916383e-05,
      "loss": 0.0,
      "step": 124980
    },
    {
      "epoch": 38.56525763653193,
      "grad_norm": 0.031153753399848938,
      "learning_rate": 1.1434742363468066e-05,
      "loss": 0.0,
      "step": 124990
    },
    {
      "epoch": 38.568343103980254,
      "grad_norm": 2.4230830604210496e-06,
      "learning_rate": 1.1431656896019748e-05,
      "loss": 0.0,
      "step": 125000
    },
    {
      "epoch": 38.57142857142857,
      "grad_norm": 1.7686392084215186e-07,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 0.0,
      "step": 125010
    },
    {
      "epoch": 38.57451403887689,
      "grad_norm": 2.369734829699155e-05,
      "learning_rate": 1.1425485961123111e-05,
      "loss": 0.0,
      "step": 125020
    },
    {
      "epoch": 38.57759950632521,
      "grad_norm": 8.227876242017373e-05,
      "learning_rate": 1.1422400493674792e-05,
      "loss": 0.0,
      "step": 125030
    },
    {
      "epoch": 38.58068497377353,
      "grad_norm": 4.030370746477274e-06,
      "learning_rate": 1.1419315026226473e-05,
      "loss": 0.0,
      "step": 125040
    },
    {
      "epoch": 38.583770441221844,
      "grad_norm": 5.24596146078693e-07,
      "learning_rate": 1.1416229558778156e-05,
      "loss": 0.0,
      "step": 125050
    },
    {
      "epoch": 38.58685590867017,
      "grad_norm": 1.8096415033141966e-06,
      "learning_rate": 1.1413144091329838e-05,
      "loss": 0.0,
      "step": 125060
    },
    {
      "epoch": 38.58994137611848,
      "grad_norm": 4.064403765369207e-05,
      "learning_rate": 1.1410058623881519e-05,
      "loss": 0.0,
      "step": 125070
    },
    {
      "epoch": 38.5930268435668,
      "grad_norm": 9.390826107846806e-07,
      "learning_rate": 1.14069731564332e-05,
      "loss": 0.0,
      "step": 125080
    },
    {
      "epoch": 38.59611231101512,
      "grad_norm": 1.2246188063613772e-08,
      "learning_rate": 1.1403887688984882e-05,
      "loss": 0.0,
      "step": 125090
    },
    {
      "epoch": 38.599197778463434,
      "grad_norm": 2.993223642988596e-05,
      "learning_rate": 1.1400802221536563e-05,
      "loss": 0.0,
      "step": 125100
    },
    {
      "epoch": 38.60228324591176,
      "grad_norm": 1.0712656148825772e-05,
      "learning_rate": 1.1397716754088245e-05,
      "loss": 0.0,
      "step": 125110
    },
    {
      "epoch": 38.60536871336007,
      "grad_norm": 0.00016747129848226905,
      "learning_rate": 1.1394631286639928e-05,
      "loss": 0.0,
      "step": 125120
    },
    {
      "epoch": 38.608454180808394,
      "grad_norm": 0.0002940651902463287,
      "learning_rate": 1.1391545819191609e-05,
      "loss": 0.0,
      "step": 125130
    },
    {
      "epoch": 38.61153964825671,
      "grad_norm": 1.0826728669144359e-07,
      "learning_rate": 1.138846035174329e-05,
      "loss": 0.0,
      "step": 125140
    },
    {
      "epoch": 38.61462511570503,
      "grad_norm": 1.8489778085495345e-05,
      "learning_rate": 1.138537488429497e-05,
      "loss": 0.0003,
      "step": 125150
    },
    {
      "epoch": 38.61771058315335,
      "grad_norm": 8.497477210767101e-07,
      "learning_rate": 1.1382289416846653e-05,
      "loss": 0.0,
      "step": 125160
    },
    {
      "epoch": 38.62079605060167,
      "grad_norm": 4.6484754534503736e-07,
      "learning_rate": 1.1379203949398335e-05,
      "loss": 0.0001,
      "step": 125170
    },
    {
      "epoch": 38.623881518049984,
      "grad_norm": 1.110179539409728e-07,
      "learning_rate": 1.1376118481950016e-05,
      "loss": 0.0,
      "step": 125180
    },
    {
      "epoch": 38.626966985498306,
      "grad_norm": 1.4163261766952928e-05,
      "learning_rate": 1.1373033014501698e-05,
      "loss": 0.0,
      "step": 125190
    },
    {
      "epoch": 38.63005245294662,
      "grad_norm": 1.051264007401187e-06,
      "learning_rate": 1.1369947547053379e-05,
      "loss": 0.0,
      "step": 125200
    },
    {
      "epoch": 38.63313792039494,
      "grad_norm": 8.86414639467148e-08,
      "learning_rate": 1.136686207960506e-05,
      "loss": 0.0001,
      "step": 125210
    },
    {
      "epoch": 38.63622338784326,
      "grad_norm": 3.7159830412747397e-07,
      "learning_rate": 1.1363776612156742e-05,
      "loss": 0.0,
      "step": 125220
    },
    {
      "epoch": 38.639308855291574,
      "grad_norm": 2.0034912040500785e-07,
      "learning_rate": 1.1360691144708425e-05,
      "loss": 0.0,
      "step": 125230
    },
    {
      "epoch": 38.6423943227399,
      "grad_norm": 7.708234761594213e-07,
      "learning_rate": 1.1357605677260106e-05,
      "loss": 0.0001,
      "step": 125240
    },
    {
      "epoch": 38.64547979018821,
      "grad_norm": 1.4027220913703786e-06,
      "learning_rate": 1.1354520209811786e-05,
      "loss": 0.0,
      "step": 125250
    },
    {
      "epoch": 38.648565257636534,
      "grad_norm": 1.224910855293274,
      "learning_rate": 1.1351434742363469e-05,
      "loss": 0.0003,
      "step": 125260
    },
    {
      "epoch": 38.65165072508485,
      "grad_norm": 0.010535022243857384,
      "learning_rate": 1.134834927491515e-05,
      "loss": 0.0,
      "step": 125270
    },
    {
      "epoch": 38.65473619253317,
      "grad_norm": 0.0020555516239255667,
      "learning_rate": 1.134526380746683e-05,
      "loss": 0.0,
      "step": 125280
    },
    {
      "epoch": 38.65782165998149,
      "grad_norm": 4.747721504827496e-06,
      "learning_rate": 1.1342178340018515e-05,
      "loss": 0.0,
      "step": 125290
    },
    {
      "epoch": 38.66090712742981,
      "grad_norm": 1.0822082003869582e-05,
      "learning_rate": 1.1339092872570195e-05,
      "loss": 0.0029,
      "step": 125300
    },
    {
      "epoch": 38.663992594878124,
      "grad_norm": 1.84425209681649e-06,
      "learning_rate": 1.1336007405121876e-05,
      "loss": 0.0,
      "step": 125310
    },
    {
      "epoch": 38.66707806232644,
      "grad_norm": 8.602334560237068e-07,
      "learning_rate": 1.1332921937673559e-05,
      "loss": 0.0,
      "step": 125320
    },
    {
      "epoch": 38.67016352977476,
      "grad_norm": 6.681138074782211e-06,
      "learning_rate": 1.132983647022524e-05,
      "loss": 0.0,
      "step": 125330
    },
    {
      "epoch": 38.67324899722308,
      "grad_norm": 0.0018672298174351454,
      "learning_rate": 1.132675100277692e-05,
      "loss": 0.0,
      "step": 125340
    },
    {
      "epoch": 38.6763344646714,
      "grad_norm": 0.00869831070303917,
      "learning_rate": 1.1323665535328603e-05,
      "loss": 0.0,
      "step": 125350
    },
    {
      "epoch": 38.679419932119714,
      "grad_norm": 1.4968558161854162e-06,
      "learning_rate": 1.1320580067880285e-05,
      "loss": 0.0,
      "step": 125360
    },
    {
      "epoch": 38.682505399568036,
      "grad_norm": 0.00014259225281421095,
      "learning_rate": 1.1317494600431966e-05,
      "loss": 0.0,
      "step": 125370
    },
    {
      "epoch": 38.68559086701635,
      "grad_norm": 1.4481358903140062e-06,
      "learning_rate": 1.1314409132983647e-05,
      "loss": 0.0,
      "step": 125380
    },
    {
      "epoch": 38.688676334464674,
      "grad_norm": 0.00023380809579975903,
      "learning_rate": 1.131132366553533e-05,
      "loss": 0.0,
      "step": 125390
    },
    {
      "epoch": 38.69176180191299,
      "grad_norm": 0.15676836669445038,
      "learning_rate": 1.130823819808701e-05,
      "loss": 0.0,
      "step": 125400
    },
    {
      "epoch": 38.69484726936131,
      "grad_norm": 1.2779808457707986e-05,
      "learning_rate": 1.1305152730638693e-05,
      "loss": 0.0,
      "step": 125410
    },
    {
      "epoch": 38.697932736809626,
      "grad_norm": 7.172276582423365e-06,
      "learning_rate": 1.1302067263190375e-05,
      "loss": 0.0,
      "step": 125420
    },
    {
      "epoch": 38.70101820425794,
      "grad_norm": 2.450841307677365e-08,
      "learning_rate": 1.1298981795742056e-05,
      "loss": 0.0,
      "step": 125430
    },
    {
      "epoch": 38.704103671706264,
      "grad_norm": 4.908501523459563e-06,
      "learning_rate": 1.1295896328293737e-05,
      "loss": 0.0,
      "step": 125440
    },
    {
      "epoch": 38.70718913915458,
      "grad_norm": 3.2479903211424244e-08,
      "learning_rate": 1.1292810860845417e-05,
      "loss": 0.0,
      "step": 125450
    },
    {
      "epoch": 38.7102746066029,
      "grad_norm": 9.297080396208912e-05,
      "learning_rate": 1.12897253933971e-05,
      "loss": 0.0,
      "step": 125460
    },
    {
      "epoch": 38.71336007405122,
      "grad_norm": 0.00025248093879781663,
      "learning_rate": 1.1286639925948782e-05,
      "loss": 0.0,
      "step": 125470
    },
    {
      "epoch": 38.71644554149954,
      "grad_norm": 1.7700156604405493e-05,
      "learning_rate": 1.1283554458500463e-05,
      "loss": 0.0,
      "step": 125480
    },
    {
      "epoch": 38.719531008947854,
      "grad_norm": 0.001905961660668254,
      "learning_rate": 1.1280468991052146e-05,
      "loss": 0.0,
      "step": 125490
    },
    {
      "epoch": 38.722616476396176,
      "grad_norm": 4.2672589188441634e-05,
      "learning_rate": 1.1277383523603826e-05,
      "loss": 0.0,
      "step": 125500
    },
    {
      "epoch": 38.72570194384449,
      "grad_norm": 3.086032302235253e-05,
      "learning_rate": 1.1274298056155507e-05,
      "loss": 0.0,
      "step": 125510
    },
    {
      "epoch": 38.728787411292814,
      "grad_norm": 0.00011856119817821309,
      "learning_rate": 1.127121258870719e-05,
      "loss": 0.0,
      "step": 125520
    },
    {
      "epoch": 38.73187287874113,
      "grad_norm": 0.0001002247809083201,
      "learning_rate": 1.1268127121258872e-05,
      "loss": 0.0,
      "step": 125530
    },
    {
      "epoch": 38.73495834618945,
      "grad_norm": 0.0009241725201718509,
      "learning_rate": 1.1265041653810553e-05,
      "loss": 0.0,
      "step": 125540
    },
    {
      "epoch": 38.738043813637766,
      "grad_norm": 2.8751315994668403e-08,
      "learning_rate": 1.1261956186362234e-05,
      "loss": 0.0,
      "step": 125550
    },
    {
      "epoch": 38.74112928108608,
      "grad_norm": 1.601531585038174e-05,
      "learning_rate": 1.1258870718913916e-05,
      "loss": 0.0,
      "step": 125560
    },
    {
      "epoch": 38.744214748534404,
      "grad_norm": 1.8189143702329602e-07,
      "learning_rate": 1.1255785251465597e-05,
      "loss": 0.0,
      "step": 125570
    },
    {
      "epoch": 38.74730021598272,
      "grad_norm": 7.73357751313597e-05,
      "learning_rate": 1.125269978401728e-05,
      "loss": 0.0,
      "step": 125580
    },
    {
      "epoch": 38.75038568343104,
      "grad_norm": 1.4566587196895853e-05,
      "learning_rate": 1.1249614316568962e-05,
      "loss": 0.0,
      "step": 125590
    },
    {
      "epoch": 38.753471150879356,
      "grad_norm": 3.2931984605966136e-05,
      "learning_rate": 1.1246528849120643e-05,
      "loss": 0.0009,
      "step": 125600
    },
    {
      "epoch": 38.75655661832768,
      "grad_norm": 1.4827585800958332e-05,
      "learning_rate": 1.1243443381672323e-05,
      "loss": 0.0,
      "step": 125610
    },
    {
      "epoch": 38.759642085775994,
      "grad_norm": 4.616611022356665e-06,
      "learning_rate": 1.1240357914224004e-05,
      "loss": 0.0,
      "step": 125620
    },
    {
      "epoch": 38.762727553224316,
      "grad_norm": 3.0759219615816846e-09,
      "learning_rate": 1.1237272446775687e-05,
      "loss": 0.0,
      "step": 125630
    },
    {
      "epoch": 38.76581302067263,
      "grad_norm": 3.053927139262669e-05,
      "learning_rate": 1.123418697932737e-05,
      "loss": 0.0,
      "step": 125640
    },
    {
      "epoch": 38.76889848812095,
      "grad_norm": 4.38890265286318e-06,
      "learning_rate": 1.123110151187905e-05,
      "loss": 0.0,
      "step": 125650
    },
    {
      "epoch": 38.77198395556927,
      "grad_norm": 0.00010332667443435639,
      "learning_rate": 1.1228016044430732e-05,
      "loss": 0.0,
      "step": 125660
    },
    {
      "epoch": 38.775069423017584,
      "grad_norm": 0.00030444911681115627,
      "learning_rate": 1.1224930576982413e-05,
      "loss": 0.0,
      "step": 125670
    },
    {
      "epoch": 38.778154890465906,
      "grad_norm": 3.7540087305387715e-07,
      "learning_rate": 1.1221845109534094e-05,
      "loss": 0.0,
      "step": 125680
    },
    {
      "epoch": 38.78124035791422,
      "grad_norm": 0.0001535137416794896,
      "learning_rate": 1.1218759642085776e-05,
      "loss": 0.0,
      "step": 125690
    },
    {
      "epoch": 38.784325825362544,
      "grad_norm": 2.7056728868046775e-05,
      "learning_rate": 1.1215674174637459e-05,
      "loss": 0.0001,
      "step": 125700
    },
    {
      "epoch": 38.78741129281086,
      "grad_norm": 0.00010830985411303118,
      "learning_rate": 1.121258870718914e-05,
      "loss": 0.0,
      "step": 125710
    },
    {
      "epoch": 38.79049676025918,
      "grad_norm": 3.1229374144459143e-06,
      "learning_rate": 1.120950323974082e-05,
      "loss": 0.0,
      "step": 125720
    },
    {
      "epoch": 38.793582227707496,
      "grad_norm": 0.0004267043259460479,
      "learning_rate": 1.1206417772292503e-05,
      "loss": 0.0,
      "step": 125730
    },
    {
      "epoch": 38.79666769515582,
      "grad_norm": 5.494496804203663e-07,
      "learning_rate": 1.1203332304844184e-05,
      "loss": 0.0,
      "step": 125740
    },
    {
      "epoch": 38.799753162604134,
      "grad_norm": 4.4496553641693026e-07,
      "learning_rate": 1.1200246837395866e-05,
      "loss": 0.0,
      "step": 125750
    },
    {
      "epoch": 38.802838630052456,
      "grad_norm": 4.1444789644629054e-07,
      "learning_rate": 1.1197161369947549e-05,
      "loss": 0.0,
      "step": 125760
    },
    {
      "epoch": 38.80592409750077,
      "grad_norm": 6.544505595229566e-07,
      "learning_rate": 1.119407590249923e-05,
      "loss": 0.0,
      "step": 125770
    },
    {
      "epoch": 38.80900956494909,
      "grad_norm": 5.548402896238258e-06,
      "learning_rate": 1.119099043505091e-05,
      "loss": 0.0,
      "step": 125780
    },
    {
      "epoch": 38.81209503239741,
      "grad_norm": 1.9031915599043714e-06,
      "learning_rate": 1.1187904967602593e-05,
      "loss": 0.0012,
      "step": 125790
    },
    {
      "epoch": 38.815180499845724,
      "grad_norm": 1.0791802651510807e-06,
      "learning_rate": 1.1184819500154274e-05,
      "loss": 0.0,
      "step": 125800
    },
    {
      "epoch": 38.818265967294046,
      "grad_norm": 5.287797102937475e-05,
      "learning_rate": 1.1181734032705956e-05,
      "loss": 0.0,
      "step": 125810
    },
    {
      "epoch": 38.82135143474236,
      "grad_norm": 6.475301688624313e-06,
      "learning_rate": 1.1178648565257637e-05,
      "loss": 0.0,
      "step": 125820
    },
    {
      "epoch": 38.82443690219068,
      "grad_norm": 4.176058254756754e-08,
      "learning_rate": 1.117556309780932e-05,
      "loss": 0.0002,
      "step": 125830
    },
    {
      "epoch": 38.827522369639,
      "grad_norm": 1.2933429616168723e-06,
      "learning_rate": 1.1172477630361e-05,
      "loss": 0.0001,
      "step": 125840
    },
    {
      "epoch": 38.83060783708732,
      "grad_norm": 4.7050204443621624e-07,
      "learning_rate": 1.1169392162912681e-05,
      "loss": 0.0,
      "step": 125850
    },
    {
      "epoch": 38.833693304535636,
      "grad_norm": 3.1288691388908774e-05,
      "learning_rate": 1.1166306695464363e-05,
      "loss": 0.003,
      "step": 125860
    },
    {
      "epoch": 38.83677877198396,
      "grad_norm": 4.566669531413936e-07,
      "learning_rate": 1.1163221228016046e-05,
      "loss": 0.0025,
      "step": 125870
    },
    {
      "epoch": 38.83986423943227,
      "grad_norm": 1.1208654642105103,
      "learning_rate": 1.1160135760567727e-05,
      "loss": 0.0009,
      "step": 125880
    },
    {
      "epoch": 38.842949706880596,
      "grad_norm": 3.876286402970663e-09,
      "learning_rate": 1.1157050293119409e-05,
      "loss": 0.0,
      "step": 125890
    },
    {
      "epoch": 38.84603517432891,
      "grad_norm": 4.9856816453086594e-09,
      "learning_rate": 1.115396482567109e-05,
      "loss": 0.0001,
      "step": 125900
    },
    {
      "epoch": 38.849120641777226,
      "grad_norm": 9.899389624479227e-06,
      "learning_rate": 1.115087935822277e-05,
      "loss": 0.0,
      "step": 125910
    },
    {
      "epoch": 38.85220610922555,
      "grad_norm": 1.2476143638195936e-05,
      "learning_rate": 1.1147793890774451e-05,
      "loss": 0.0,
      "step": 125920
    },
    {
      "epoch": 38.855291576673864,
      "grad_norm": 1.4035643403076392e-07,
      "learning_rate": 1.1144708423326136e-05,
      "loss": 0.0,
      "step": 125930
    },
    {
      "epoch": 38.858377044122186,
      "grad_norm": 0.00020309236424509436,
      "learning_rate": 1.1141622955877816e-05,
      "loss": 0.0,
      "step": 125940
    },
    {
      "epoch": 38.8614625115705,
      "grad_norm": 1.8904988792201038e-06,
      "learning_rate": 1.1138537488429497e-05,
      "loss": 0.0,
      "step": 125950
    },
    {
      "epoch": 38.86454797901882,
      "grad_norm": 4.423818154464243e-06,
      "learning_rate": 1.113545202098118e-05,
      "loss": 0.0,
      "step": 125960
    },
    {
      "epoch": 38.86763344646714,
      "grad_norm": 1.5912823982944246e-06,
      "learning_rate": 1.113236655353286e-05,
      "loss": 0.0,
      "step": 125970
    },
    {
      "epoch": 38.87071891391546,
      "grad_norm": 9.22781546250917e-05,
      "learning_rate": 1.1129281086084541e-05,
      "loss": 0.0,
      "step": 125980
    },
    {
      "epoch": 38.873804381363776,
      "grad_norm": 6.231967404346506e-07,
      "learning_rate": 1.1126195618636225e-05,
      "loss": 0.0,
      "step": 125990
    },
    {
      "epoch": 38.8768898488121,
      "grad_norm": 0.00047755814739502966,
      "learning_rate": 1.1123110151187906e-05,
      "loss": 0.0,
      "step": 126000
    },
    {
      "epoch": 38.87997531626041,
      "grad_norm": 0.00012527467333711684,
      "learning_rate": 1.1120024683739587e-05,
      "loss": 0.0,
      "step": 126010
    },
    {
      "epoch": 38.88306078370873,
      "grad_norm": 0.00043684590491466224,
      "learning_rate": 1.1116939216291268e-05,
      "loss": 0.0,
      "step": 126020
    },
    {
      "epoch": 38.88614625115705,
      "grad_norm": 0.0016542368102818727,
      "learning_rate": 1.111385374884295e-05,
      "loss": 0.0,
      "step": 126030
    },
    {
      "epoch": 38.889231718605366,
      "grad_norm": 2.283091362187406e-06,
      "learning_rate": 1.1110768281394631e-05,
      "loss": 0.0,
      "step": 126040
    },
    {
      "epoch": 38.89231718605369,
      "grad_norm": 7.333899532113719e-08,
      "learning_rate": 1.1107682813946313e-05,
      "loss": 0.0,
      "step": 126050
    },
    {
      "epoch": 38.895402653502,
      "grad_norm": 0.00011009417357854545,
      "learning_rate": 1.1104597346497996e-05,
      "loss": 0.0,
      "step": 126060
    },
    {
      "epoch": 38.898488120950326,
      "grad_norm": 2.1258148308334057e-07,
      "learning_rate": 1.1101511879049677e-05,
      "loss": 0.0001,
      "step": 126070
    },
    {
      "epoch": 38.90157358839864,
      "grad_norm": 3.940870374208316e-05,
      "learning_rate": 1.1098426411601357e-05,
      "loss": 0.0,
      "step": 126080
    },
    {
      "epoch": 38.90465905584696,
      "grad_norm": 1.7480348333265283e-06,
      "learning_rate": 1.109534094415304e-05,
      "loss": 0.0,
      "step": 126090
    },
    {
      "epoch": 38.90774452329528,
      "grad_norm": 1.1862787008285522,
      "learning_rate": 1.109225547670472e-05,
      "loss": 0.0008,
      "step": 126100
    },
    {
      "epoch": 38.9108299907436,
      "grad_norm": 0.0007984749972820282,
      "learning_rate": 1.1089170009256403e-05,
      "loss": 0.0,
      "step": 126110
    },
    {
      "epoch": 38.913915458191916,
      "grad_norm": 1.8274575097620982e-07,
      "learning_rate": 1.1086084541808084e-05,
      "loss": 0.0,
      "step": 126120
    },
    {
      "epoch": 38.91700092564024,
      "grad_norm": 0.05908358469605446,
      "learning_rate": 1.1082999074359766e-05,
      "loss": 0.0,
      "step": 126130
    },
    {
      "epoch": 38.92008639308855,
      "grad_norm": 1.3956284874439007e-06,
      "learning_rate": 1.1079913606911447e-05,
      "loss": 0.0,
      "step": 126140
    },
    {
      "epoch": 38.92317186053687,
      "grad_norm": 3.859600383293582e-06,
      "learning_rate": 1.1076828139463128e-05,
      "loss": 0.0,
      "step": 126150
    },
    {
      "epoch": 38.92625732798519,
      "grad_norm": 0.001024475903250277,
      "learning_rate": 1.107374267201481e-05,
      "loss": 0.0,
      "step": 126160
    },
    {
      "epoch": 38.929342795433506,
      "grad_norm": 3.910858868039213e-05,
      "learning_rate": 1.1070657204566493e-05,
      "loss": 0.0,
      "step": 126170
    },
    {
      "epoch": 38.93242826288183,
      "grad_norm": 5.0816775001294445e-06,
      "learning_rate": 1.1067571737118174e-05,
      "loss": 0.0,
      "step": 126180
    },
    {
      "epoch": 38.93551373033014,
      "grad_norm": 2.062303428829182e-05,
      "learning_rate": 1.1064486269669856e-05,
      "loss": 0.0,
      "step": 126190
    },
    {
      "epoch": 38.938599197778466,
      "grad_norm": 1.963694273854344e-08,
      "learning_rate": 1.1061400802221537e-05,
      "loss": 0.001,
      "step": 126200
    },
    {
      "epoch": 38.94168466522678,
      "grad_norm": 4.798985628440278e-06,
      "learning_rate": 1.1058315334773218e-05,
      "loss": 0.0,
      "step": 126210
    },
    {
      "epoch": 38.9447701326751,
      "grad_norm": 4.195213477942161e-06,
      "learning_rate": 1.10552298673249e-05,
      "loss": 0.0,
      "step": 126220
    },
    {
      "epoch": 38.94785560012342,
      "grad_norm": 0.004855920094996691,
      "learning_rate": 1.1052144399876583e-05,
      "loss": 0.0006,
      "step": 126230
    },
    {
      "epoch": 38.95094106757174,
      "grad_norm": 1.0428158020658884e-05,
      "learning_rate": 1.1049058932428264e-05,
      "loss": 0.0,
      "step": 126240
    },
    {
      "epoch": 38.954026535020056,
      "grad_norm": 6.479011972260196e-06,
      "learning_rate": 1.1045973464979944e-05,
      "loss": 0.0001,
      "step": 126250
    },
    {
      "epoch": 38.95711200246837,
      "grad_norm": 0.0006439913995563984,
      "learning_rate": 1.1042887997531627e-05,
      "loss": 0.0,
      "step": 126260
    },
    {
      "epoch": 38.96019746991669,
      "grad_norm": 0.20074181258678436,
      "learning_rate": 1.1039802530083308e-05,
      "loss": 0.0001,
      "step": 126270
    },
    {
      "epoch": 38.96328293736501,
      "grad_norm": 1.7744046090228949e-06,
      "learning_rate": 1.103671706263499e-05,
      "loss": 0.0001,
      "step": 126280
    },
    {
      "epoch": 38.96636840481333,
      "grad_norm": 2.1470661522471346e-05,
      "learning_rate": 1.1033631595186673e-05,
      "loss": 0.0001,
      "step": 126290
    },
    {
      "epoch": 38.969453872261646,
      "grad_norm": 0.035169072449207306,
      "learning_rate": 1.1030546127738353e-05,
      "loss": 0.0001,
      "step": 126300
    },
    {
      "epoch": 38.97253933970997,
      "grad_norm": 0.0011614292161539197,
      "learning_rate": 1.1027460660290034e-05,
      "loss": 0.0001,
      "step": 126310
    },
    {
      "epoch": 38.97562480715828,
      "grad_norm": 3.253624163335189e-05,
      "learning_rate": 1.1024375192841715e-05,
      "loss": 0.0,
      "step": 126320
    },
    {
      "epoch": 38.978710274606605,
      "grad_norm": 0.00022414677368942648,
      "learning_rate": 1.1021289725393397e-05,
      "loss": 0.0,
      "step": 126330
    },
    {
      "epoch": 38.98179574205492,
      "grad_norm": 2.237932858406566e-05,
      "learning_rate": 1.101820425794508e-05,
      "loss": 0.0,
      "step": 126340
    },
    {
      "epoch": 38.98488120950324,
      "grad_norm": 0.00011882004037033767,
      "learning_rate": 1.101511879049676e-05,
      "loss": 0.0,
      "step": 126350
    },
    {
      "epoch": 38.98796667695156,
      "grad_norm": 1.2919959999635466e-06,
      "learning_rate": 1.1012033323048443e-05,
      "loss": 0.0,
      "step": 126360
    },
    {
      "epoch": 38.99105214439987,
      "grad_norm": 1.1001764050888596e-06,
      "learning_rate": 1.1008947855600124e-05,
      "loss": 0.0,
      "step": 126370
    },
    {
      "epoch": 38.994137611848195,
      "grad_norm": 7.627604645676911e-06,
      "learning_rate": 1.1005862388151805e-05,
      "loss": 0.0,
      "step": 126380
    },
    {
      "epoch": 38.99722307929651,
      "grad_norm": 3.250195368309505e-05,
      "learning_rate": 1.1002776920703487e-05,
      "loss": 0.0,
      "step": 126390
    },
    {
      "epoch": 39.0,
      "eval_accuracy_branch1": 1.0,
      "eval_accuracy_branch2": 0.3859070435847728,
      "eval_f1_branch1": 1.0,
      "eval_f1_branch2": 0.3594285240221923,
      "eval_loss": 1.7284886553170509e-06,
      "eval_precision_branch1": 1.0,
      "eval_precision_branch2": 0.5204066853677691,
      "eval_recall_branch1": 1.0,
      "eval_recall_branch2": 0.5103874309192442,
      "eval_runtime": 239.8378,
      "eval_samples_per_second": 432.305,
      "eval_steps_per_second": 54.041,
      "step": 126399
    },
    {
      "epoch": 39.00030854674483,
      "grad_norm": 1.4677226545245503e-08,
      "learning_rate": 1.099969145325517e-05,
      "loss": 0.0038,
      "step": 126400
    },
    {
      "epoch": 39.00339401419315,
      "grad_norm": 8.225884471357858e-07,
      "learning_rate": 1.099660598580685e-05,
      "loss": 0.0,
      "step": 126410
    },
    {
      "epoch": 39.00647948164147,
      "grad_norm": 1.0728521147029824e-06,
      "learning_rate": 1.0993520518358531e-05,
      "loss": 0.0,
      "step": 126420
    },
    {
      "epoch": 39.009564949089786,
      "grad_norm": 1.721464855108934e-06,
      "learning_rate": 1.0990435050910214e-05,
      "loss": 0.0,
      "step": 126430
    },
    {
      "epoch": 39.01265041653811,
      "grad_norm": 0.0006651532603427768,
      "learning_rate": 1.0987349583461894e-05,
      "loss": 0.0001,
      "step": 126440
    },
    {
      "epoch": 39.01573588398642,
      "grad_norm": 0.0003139305335935205,
      "learning_rate": 1.0984264116013577e-05,
      "loss": 0.0,
      "step": 126450
    },
    {
      "epoch": 39.018821351434745,
      "grad_norm": 0.03382732719182968,
      "learning_rate": 1.098117864856526e-05,
      "loss": 0.0,
      "step": 126460
    },
    {
      "epoch": 39.02190681888306,
      "grad_norm": 5.7873187131463055e-08,
      "learning_rate": 1.097809318111694e-05,
      "loss": 0.0,
      "step": 126470
    },
    {
      "epoch": 39.02499228633138,
      "grad_norm": 6.058050530555192e-06,
      "learning_rate": 1.0975007713668621e-05,
      "loss": 0.0001,
      "step": 126480
    },
    {
      "epoch": 39.0280777537797,
      "grad_norm": 1.6000807363525382e-06,
      "learning_rate": 1.0971922246220302e-05,
      "loss": 0.0,
      "step": 126490
    },
    {
      "epoch": 39.03116322122801,
      "grad_norm": 6.742103778378805e-06,
      "learning_rate": 1.0968836778771984e-05,
      "loss": 0.0,
      "step": 126500
    },
    {
      "epoch": 39.034248688676335,
      "grad_norm": 0.24263416230678558,
      "learning_rate": 1.0965751311323667e-05,
      "loss": 0.0001,
      "step": 126510
    },
    {
      "epoch": 39.03733415612465,
      "grad_norm": 7.3613205131550785e-06,
      "learning_rate": 1.0962665843875348e-05,
      "loss": 0.0,
      "step": 126520
    },
    {
      "epoch": 39.04041962357297,
      "grad_norm": 2.7491825676406734e-05,
      "learning_rate": 1.095958037642703e-05,
      "loss": 0.0,
      "step": 126530
    },
    {
      "epoch": 39.04350509102129,
      "grad_norm": 3.819224403400767e-08,
      "learning_rate": 1.095649490897871e-05,
      "loss": 0.0,
      "step": 126540
    },
    {
      "epoch": 39.04659055846961,
      "grad_norm": 0.0044961245730519295,
      "learning_rate": 1.0953409441530392e-05,
      "loss": 0.0,
      "step": 126550
    },
    {
      "epoch": 39.049676025917925,
      "grad_norm": 0.0009252299787476659,
      "learning_rate": 1.0950323974082074e-05,
      "loss": 0.0,
      "step": 126560
    },
    {
      "epoch": 39.05276149336625,
      "grad_norm": 0.00024696870241314173,
      "learning_rate": 1.0947238506633757e-05,
      "loss": 0.0,
      "step": 126570
    },
    {
      "epoch": 39.05584696081456,
      "grad_norm": 0.00014728268433827907,
      "learning_rate": 1.0944153039185437e-05,
      "loss": 0.0,
      "step": 126580
    },
    {
      "epoch": 39.058932428262885,
      "grad_norm": 1.750107367115561e-05,
      "learning_rate": 1.0941067571737118e-05,
      "loss": 0.0,
      "step": 126590
    },
    {
      "epoch": 39.0620178957112,
      "grad_norm": 9.066204142982315e-07,
      "learning_rate": 1.09379821042888e-05,
      "loss": 0.0,
      "step": 126600
    },
    {
      "epoch": 39.065103363159515,
      "grad_norm": 1.8580527694211924e-07,
      "learning_rate": 1.0934896636840481e-05,
      "loss": 0.0,
      "step": 126610
    },
    {
      "epoch": 39.06818883060784,
      "grad_norm": 7.768546311126556e-06,
      "learning_rate": 1.0931811169392162e-05,
      "loss": 0.0,
      "step": 126620
    },
    {
      "epoch": 39.07127429805615,
      "grad_norm": 2.2493560436487314e-07,
      "learning_rate": 1.0928725701943846e-05,
      "loss": 0.0,
      "step": 126630
    },
    {
      "epoch": 39.074359765504475,
      "grad_norm": 0.037053726613521576,
      "learning_rate": 1.0925640234495527e-05,
      "loss": 0.0,
      "step": 126640
    },
    {
      "epoch": 39.07744523295279,
      "grad_norm": 7.291386623364815e-07,
      "learning_rate": 1.0922554767047208e-05,
      "loss": 0.0,
      "step": 126650
    },
    {
      "epoch": 39.08053070040111,
      "grad_norm": 5.6309545470867306e-05,
      "learning_rate": 1.091946929959889e-05,
      "loss": 0.0,
      "step": 126660
    },
    {
      "epoch": 39.08361616784943,
      "grad_norm": 9.628577046782993e-09,
      "learning_rate": 1.0916383832150571e-05,
      "loss": 0.0,
      "step": 126670
    },
    {
      "epoch": 39.08670163529775,
      "grad_norm": 5.301626060827402e-06,
      "learning_rate": 1.0913298364702252e-05,
      "loss": 0.0,
      "step": 126680
    },
    {
      "epoch": 39.089787102746065,
      "grad_norm": 5.003740170650417e-06,
      "learning_rate": 1.0910212897253934e-05,
      "loss": 0.0,
      "step": 126690
    },
    {
      "epoch": 39.09287257019439,
      "grad_norm": 4.772991246682068e-07,
      "learning_rate": 1.0907127429805617e-05,
      "loss": 0.0,
      "step": 126700
    },
    {
      "epoch": 39.0959580376427,
      "grad_norm": 3.111355545115657e-05,
      "learning_rate": 1.0904041962357298e-05,
      "loss": 0.0,
      "step": 126710
    },
    {
      "epoch": 39.09904350509102,
      "grad_norm": 7.774152436468285e-06,
      "learning_rate": 1.0900956494908978e-05,
      "loss": 0.0,
      "step": 126720
    },
    {
      "epoch": 39.10212897253934,
      "grad_norm": 1.2061207144142827e-06,
      "learning_rate": 1.0897871027460661e-05,
      "loss": 0.0,
      "step": 126730
    },
    {
      "epoch": 39.105214439987655,
      "grad_norm": 5.668835365213454e-05,
      "learning_rate": 1.0894785560012342e-05,
      "loss": 0.0,
      "step": 126740
    },
    {
      "epoch": 39.10829990743598,
      "grad_norm": 0.0003076599969062954,
      "learning_rate": 1.0891700092564024e-05,
      "loss": 0.0,
      "step": 126750
    },
    {
      "epoch": 39.11138537488429,
      "grad_norm": 4.892943934464711e-07,
      "learning_rate": 1.0888614625115707e-05,
      "loss": 0.0,
      "step": 126760
    },
    {
      "epoch": 39.114470842332615,
      "grad_norm": 0.0013858109014108777,
      "learning_rate": 1.0885529157667387e-05,
      "loss": 0.0,
      "step": 126770
    },
    {
      "epoch": 39.11755630978093,
      "grad_norm": 1.2764417078869883e-05,
      "learning_rate": 1.0882443690219068e-05,
      "loss": 0.0,
      "step": 126780
    },
    {
      "epoch": 39.12064177722925,
      "grad_norm": 1.5024462300061714e-05,
      "learning_rate": 1.0879358222770749e-05,
      "loss": 0.0,
      "step": 126790
    },
    {
      "epoch": 39.12372724467757,
      "grad_norm": 1.3577378332740864e-08,
      "learning_rate": 1.0876272755322431e-05,
      "loss": 0.0001,
      "step": 126800
    },
    {
      "epoch": 39.12681271212589,
      "grad_norm": 0.0002643780899234116,
      "learning_rate": 1.0873187287874114e-05,
      "loss": 0.0,
      "step": 126810
    },
    {
      "epoch": 39.129898179574205,
      "grad_norm": 0.0015611377311870456,
      "learning_rate": 1.0870101820425795e-05,
      "loss": 0.0,
      "step": 126820
    },
    {
      "epoch": 39.13298364702253,
      "grad_norm": 0.0006248947465792298,
      "learning_rate": 1.0867016352977477e-05,
      "loss": 0.0,
      "step": 126830
    },
    {
      "epoch": 39.13606911447084,
      "grad_norm": 0.0014284991193562746,
      "learning_rate": 1.0863930885529158e-05,
      "loss": 0.0,
      "step": 126840
    },
    {
      "epoch": 39.13915458191916,
      "grad_norm": 7.090599041248424e-08,
      "learning_rate": 1.0860845418080839e-05,
      "loss": 0.0,
      "step": 126850
    },
    {
      "epoch": 39.14224004936748,
      "grad_norm": 8.323387010022998e-05,
      "learning_rate": 1.0857759950632521e-05,
      "loss": 0.0,
      "step": 126860
    },
    {
      "epoch": 39.145325516815795,
      "grad_norm": 0.00012663174129556865,
      "learning_rate": 1.0854674483184204e-05,
      "loss": 0.0001,
      "step": 126870
    },
    {
      "epoch": 39.14841098426412,
      "grad_norm": 0.00043745138100348413,
      "learning_rate": 1.0851589015735885e-05,
      "loss": 0.0,
      "step": 126880
    },
    {
      "epoch": 39.15149645171243,
      "grad_norm": 8.547982724849135e-05,
      "learning_rate": 1.0848503548287565e-05,
      "loss": 0.014,
      "step": 126890
    },
    {
      "epoch": 39.154581919160755,
      "grad_norm": 5.864935701538343e-06,
      "learning_rate": 1.0845418080839248e-05,
      "loss": 0.0,
      "step": 126900
    },
    {
      "epoch": 39.15766738660907,
      "grad_norm": 4.7109810452639067e-07,
      "learning_rate": 1.0842332613390929e-05,
      "loss": 0.0,
      "step": 126910
    },
    {
      "epoch": 39.16075285405739,
      "grad_norm": 7.743843161733821e-05,
      "learning_rate": 1.0839247145942611e-05,
      "loss": 0.0,
      "step": 126920
    },
    {
      "epoch": 39.16383832150571,
      "grad_norm": 1.1494602176753688e-06,
      "learning_rate": 1.0836161678494294e-05,
      "loss": 0.0,
      "step": 126930
    },
    {
      "epoch": 39.16692378895403,
      "grad_norm": 1.4844623308363225e-08,
      "learning_rate": 1.0833076211045974e-05,
      "loss": 0.0,
      "step": 126940
    },
    {
      "epoch": 39.170009256402345,
      "grad_norm": 6.749407475581393e-05,
      "learning_rate": 1.0829990743597655e-05,
      "loss": 0.0,
      "step": 126950
    },
    {
      "epoch": 39.17309472385066,
      "grad_norm": 6.697387533449728e-08,
      "learning_rate": 1.0826905276149338e-05,
      "loss": 0.0,
      "step": 126960
    },
    {
      "epoch": 39.17618019129898,
      "grad_norm": 1.604856834092061e-06,
      "learning_rate": 1.0823819808701018e-05,
      "loss": 0.0,
      "step": 126970
    },
    {
      "epoch": 39.1792656587473,
      "grad_norm": 6.363123975461349e-05,
      "learning_rate": 1.08207343412527e-05,
      "loss": 0.0,
      "step": 126980
    },
    {
      "epoch": 39.18235112619562,
      "grad_norm": 1.1603415259742178e-06,
      "learning_rate": 1.0817648873804382e-05,
      "loss": 0.0,
      "step": 126990
    },
    {
      "epoch": 39.185436593643935,
      "grad_norm": 0.0005187092465348542,
      "learning_rate": 1.0814563406356064e-05,
      "loss": 0.0,
      "step": 127000
    },
    {
      "epoch": 39.18852206109226,
      "grad_norm": 0.00013675179798156023,
      "learning_rate": 1.0811477938907745e-05,
      "loss": 0.0,
      "step": 127010
    },
    {
      "epoch": 39.19160752854057,
      "grad_norm": 1.909002094180323e-06,
      "learning_rate": 1.0808392471459426e-05,
      "loss": 0.0,
      "step": 127020
    },
    {
      "epoch": 39.194692995988895,
      "grad_norm": 3.7986649203958223e-06,
      "learning_rate": 1.0805307004011108e-05,
      "loss": 0.0,
      "step": 127030
    },
    {
      "epoch": 39.19777846343721,
      "grad_norm": 3.4458045661267533e-07,
      "learning_rate": 1.080222153656279e-05,
      "loss": 0.0,
      "step": 127040
    },
    {
      "epoch": 39.20086393088553,
      "grad_norm": 1.1060065844503697e-05,
      "learning_rate": 1.0799136069114471e-05,
      "loss": 0.0,
      "step": 127050
    },
    {
      "epoch": 39.20394939833385,
      "grad_norm": 1.3312941291587777e-06,
      "learning_rate": 1.0796050601666154e-05,
      "loss": 0.0,
      "step": 127060
    },
    {
      "epoch": 39.20703486578216,
      "grad_norm": 0.0006097255973145366,
      "learning_rate": 1.0792965134217835e-05,
      "loss": 0.0,
      "step": 127070
    },
    {
      "epoch": 39.210120333230485,
      "grad_norm": 9.340882388642058e-05,
      "learning_rate": 1.0789879666769515e-05,
      "loss": 0.0,
      "step": 127080
    },
    {
      "epoch": 39.2132058006788,
      "grad_norm": 0.0016189977759495378,
      "learning_rate": 1.0786794199321198e-05,
      "loss": 0.0,
      "step": 127090
    },
    {
      "epoch": 39.21629126812712,
      "grad_norm": 1.7279448982776557e-09,
      "learning_rate": 1.078370873187288e-05,
      "loss": 0.0,
      "step": 127100
    },
    {
      "epoch": 39.21937673557544,
      "grad_norm": 3.13178105670886e-07,
      "learning_rate": 1.0780623264424561e-05,
      "loss": 0.0,
      "step": 127110
    },
    {
      "epoch": 39.22246220302376,
      "grad_norm": 0.00013137757196091115,
      "learning_rate": 1.0777537796976242e-05,
      "loss": 0.0,
      "step": 127120
    },
    {
      "epoch": 39.225547670472075,
      "grad_norm": 3.36092647046371e-08,
      "learning_rate": 1.0774452329527924e-05,
      "loss": 0.0001,
      "step": 127130
    },
    {
      "epoch": 39.2286331379204,
      "grad_norm": 3.9537258800237396e-08,
      "learning_rate": 1.0771366862079605e-05,
      "loss": 0.0,
      "step": 127140
    },
    {
      "epoch": 39.23171860536871,
      "grad_norm": 3.73330622096546e-05,
      "learning_rate": 1.0768281394631288e-05,
      "loss": 0.0,
      "step": 127150
    },
    {
      "epoch": 39.234804072817035,
      "grad_norm": 0.00023605355818290263,
      "learning_rate": 1.0765195927182968e-05,
      "loss": 0.0,
      "step": 127160
    },
    {
      "epoch": 39.23788954026535,
      "grad_norm": 9.227493865182623e-05,
      "learning_rate": 1.0762110459734651e-05,
      "loss": 0.0,
      "step": 127170
    },
    {
      "epoch": 39.24097500771367,
      "grad_norm": 1.2420609429852902e-08,
      "learning_rate": 1.0759024992286332e-05,
      "loss": 0.0,
      "step": 127180
    },
    {
      "epoch": 39.24406047516199,
      "grad_norm": 1.6010861145332456e-05,
      "learning_rate": 1.0755939524838012e-05,
      "loss": 0.0,
      "step": 127190
    },
    {
      "epoch": 39.2471459426103,
      "grad_norm": 1.7009369912557304e-07,
      "learning_rate": 1.0752854057389695e-05,
      "loss": 0.0,
      "step": 127200
    },
    {
      "epoch": 39.250231410058625,
      "grad_norm": 3.2088166790344985e-06,
      "learning_rate": 1.0749768589941377e-05,
      "loss": 0.0,
      "step": 127210
    },
    {
      "epoch": 39.25331687750694,
      "grad_norm": 0.00014146255853120238,
      "learning_rate": 1.0746683122493058e-05,
      "loss": 0.0,
      "step": 127220
    },
    {
      "epoch": 39.25640234495526,
      "grad_norm": 0.000822230416815728,
      "learning_rate": 1.074359765504474e-05,
      "loss": 0.0,
      "step": 127230
    },
    {
      "epoch": 39.25948781240358,
      "grad_norm": 7.220508450700436e-06,
      "learning_rate": 1.0740512187596421e-05,
      "loss": 0.0,
      "step": 127240
    },
    {
      "epoch": 39.2625732798519,
      "grad_norm": 1.8099477472333092e-09,
      "learning_rate": 1.0737426720148102e-05,
      "loss": 0.0,
      "step": 127250
    },
    {
      "epoch": 39.265658747300215,
      "grad_norm": 8.21618471036345e-07,
      "learning_rate": 1.0734341252699783e-05,
      "loss": 0.0,
      "step": 127260
    },
    {
      "epoch": 39.26874421474854,
      "grad_norm": 4.66374743268716e-08,
      "learning_rate": 1.0731255785251467e-05,
      "loss": 0.0,
      "step": 127270
    },
    {
      "epoch": 39.27182968219685,
      "grad_norm": 1.7060661150480882e-07,
      "learning_rate": 1.0728170317803148e-05,
      "loss": 0.0,
      "step": 127280
    },
    {
      "epoch": 39.274915149645174,
      "grad_norm": 8.046169568842743e-06,
      "learning_rate": 1.0725084850354829e-05,
      "loss": 0.0,
      "step": 127290
    },
    {
      "epoch": 39.27800061709349,
      "grad_norm": 3.0732564937352436e-07,
      "learning_rate": 1.0721999382906511e-05,
      "loss": 0.0,
      "step": 127300
    },
    {
      "epoch": 39.281086084541805,
      "grad_norm": 2.3058218800997565e-07,
      "learning_rate": 1.0718913915458192e-05,
      "loss": 0.0001,
      "step": 127310
    },
    {
      "epoch": 39.28417155199013,
      "grad_norm": 2.302386974406545e-06,
      "learning_rate": 1.0715828448009873e-05,
      "loss": 0.0003,
      "step": 127320
    },
    {
      "epoch": 39.28725701943844,
      "grad_norm": 4.5571013629341905e-07,
      "learning_rate": 1.0712742980561557e-05,
      "loss": 0.0,
      "step": 127330
    },
    {
      "epoch": 39.290342486886765,
      "grad_norm": 2.098173865761055e-07,
      "learning_rate": 1.0709657513113238e-05,
      "loss": 0.0,
      "step": 127340
    },
    {
      "epoch": 39.29342795433508,
      "grad_norm": 1.0711617051128997e-06,
      "learning_rate": 1.0706572045664919e-05,
      "loss": 0.0,
      "step": 127350
    },
    {
      "epoch": 39.2965134217834,
      "grad_norm": 0.02468557097017765,
      "learning_rate": 1.07034865782166e-05,
      "loss": 0.0,
      "step": 127360
    },
    {
      "epoch": 39.29959888923172,
      "grad_norm": 2.410310298728291e-05,
      "learning_rate": 1.0700401110768282e-05,
      "loss": 0.0,
      "step": 127370
    },
    {
      "epoch": 39.30268435668004,
      "grad_norm": 1.9199529560864903e-05,
      "learning_rate": 1.0697315643319963e-05,
      "loss": 0.0,
      "step": 127380
    },
    {
      "epoch": 39.305769824128355,
      "grad_norm": 0.02181091718375683,
      "learning_rate": 1.0694230175871645e-05,
      "loss": 0.0,
      "step": 127390
    },
    {
      "epoch": 39.30885529157668,
      "grad_norm": 3.59221849066671e-06,
      "learning_rate": 1.0691144708423328e-05,
      "loss": 0.0,
      "step": 127400
    },
    {
      "epoch": 39.31194075902499,
      "grad_norm": 1.8846474631573074e-05,
      "learning_rate": 1.0688059240975008e-05,
      "loss": 0.0001,
      "step": 127410
    },
    {
      "epoch": 39.31502622647331,
      "grad_norm": 3.419162385398522e-05,
      "learning_rate": 1.0684973773526689e-05,
      "loss": 0.0,
      "step": 127420
    },
    {
      "epoch": 39.31811169392163,
      "grad_norm": 4.957694545737468e-05,
      "learning_rate": 1.0681888306078372e-05,
      "loss": 0.0,
      "step": 127430
    },
    {
      "epoch": 39.321197161369945,
      "grad_norm": 1.9493038507789606e-06,
      "learning_rate": 1.0678802838630052e-05,
      "loss": 0.0,
      "step": 127440
    },
    {
      "epoch": 39.32428262881827,
      "grad_norm": 0.004395723808556795,
      "learning_rate": 1.0675717371181735e-05,
      "loss": 0.0011,
      "step": 127450
    },
    {
      "epoch": 39.32736809626658,
      "grad_norm": 8.441164709438453e-07,
      "learning_rate": 1.0672631903733416e-05,
      "loss": 0.0,
      "step": 127460
    },
    {
      "epoch": 39.330453563714904,
      "grad_norm": 1.1610722140176222e-05,
      "learning_rate": 1.0669546436285098e-05,
      "loss": 0.0,
      "step": 127470
    },
    {
      "epoch": 39.33353903116322,
      "grad_norm": 0.0001931066217366606,
      "learning_rate": 1.0666460968836779e-05,
      "loss": 0.0,
      "step": 127480
    },
    {
      "epoch": 39.33662449861154,
      "grad_norm": 0.006576189771294594,
      "learning_rate": 1.066337550138846e-05,
      "loss": 0.0,
      "step": 127490
    },
    {
      "epoch": 39.33970996605986,
      "grad_norm": 5.099548616271932e-06,
      "learning_rate": 1.0660290033940142e-05,
      "loss": 0.0,
      "step": 127500
    },
    {
      "epoch": 39.34279543350818,
      "grad_norm": 9.738253083924064e-07,
      "learning_rate": 1.0657204566491825e-05,
      "loss": 0.0,
      "step": 127510
    },
    {
      "epoch": 39.345880900956494,
      "grad_norm": 7.677494068047963e-06,
      "learning_rate": 1.0654119099043505e-05,
      "loss": 0.0,
      "step": 127520
    },
    {
      "epoch": 39.34896636840482,
      "grad_norm": 1.2927017678521224e-08,
      "learning_rate": 1.0651033631595188e-05,
      "loss": 0.0004,
      "step": 127530
    },
    {
      "epoch": 39.35205183585313,
      "grad_norm": 2.808463079873036e-07,
      "learning_rate": 1.0647948164146869e-05,
      "loss": 0.0,
      "step": 127540
    },
    {
      "epoch": 39.35513730330145,
      "grad_norm": 4.360547609394416e-05,
      "learning_rate": 1.064486269669855e-05,
      "loss": 0.0,
      "step": 127550
    },
    {
      "epoch": 39.35822277074977,
      "grad_norm": 7.631851076439489e-06,
      "learning_rate": 1.0641777229250232e-05,
      "loss": 0.0,
      "step": 127560
    },
    {
      "epoch": 39.361308238198085,
      "grad_norm": 3.0010784257683554e-07,
      "learning_rate": 1.0638691761801914e-05,
      "loss": 0.0,
      "step": 127570
    },
    {
      "epoch": 39.36439370564641,
      "grad_norm": 5.561279881050041e-09,
      "learning_rate": 1.0635606294353595e-05,
      "loss": 0.0,
      "step": 127580
    },
    {
      "epoch": 39.36747917309472,
      "grad_norm": 3.7306685953808483e-06,
      "learning_rate": 1.0632520826905276e-05,
      "loss": 0.0,
      "step": 127590
    },
    {
      "epoch": 39.370564640543044,
      "grad_norm": 2.7475374736241065e-05,
      "learning_rate": 1.0629435359456958e-05,
      "loss": 0.0,
      "step": 127600
    },
    {
      "epoch": 39.37365010799136,
      "grad_norm": 7.01730655805477e-08,
      "learning_rate": 1.062634989200864e-05,
      "loss": 0.0,
      "step": 127610
    },
    {
      "epoch": 39.37673557543968,
      "grad_norm": 2.341958406759659e-06,
      "learning_rate": 1.0623264424560322e-05,
      "loss": 0.0,
      "step": 127620
    },
    {
      "epoch": 39.379821042888,
      "grad_norm": 4.5651077584807354e-08,
      "learning_rate": 1.0620178957112004e-05,
      "loss": 0.0,
      "step": 127630
    },
    {
      "epoch": 39.38290651033632,
      "grad_norm": 1.9631295700150986e-08,
      "learning_rate": 1.0617093489663685e-05,
      "loss": 0.0,
      "step": 127640
    },
    {
      "epoch": 39.385991977784634,
      "grad_norm": 3.675680636661127e-05,
      "learning_rate": 1.0614008022215366e-05,
      "loss": 0.0,
      "step": 127650
    },
    {
      "epoch": 39.38907744523295,
      "grad_norm": 2.8071716062783025e-09,
      "learning_rate": 1.0610922554767047e-05,
      "loss": 0.0,
      "step": 127660
    },
    {
      "epoch": 39.39216291268127,
      "grad_norm": 3.8758994236332e-08,
      "learning_rate": 1.0607837087318729e-05,
      "loss": 0.0001,
      "step": 127670
    },
    {
      "epoch": 39.39524838012959,
      "grad_norm": 0.001339125563390553,
      "learning_rate": 1.0604751619870412e-05,
      "loss": 0.0,
      "step": 127680
    },
    {
      "epoch": 39.39833384757791,
      "grad_norm": 5.24932056578109e-06,
      "learning_rate": 1.0601666152422092e-05,
      "loss": 0.0,
      "step": 127690
    },
    {
      "epoch": 39.401419315026224,
      "grad_norm": 3.5531145840650424e-05,
      "learning_rate": 1.0598580684973775e-05,
      "loss": 0.0,
      "step": 127700
    },
    {
      "epoch": 39.40450478247455,
      "grad_norm": 3.755397119675763e-05,
      "learning_rate": 1.0595495217525456e-05,
      "loss": 0.0,
      "step": 127710
    },
    {
      "epoch": 39.40759024992286,
      "grad_norm": 2.9233820697527335e-08,
      "learning_rate": 1.0592409750077136e-05,
      "loss": 0.0,
      "step": 127720
    },
    {
      "epoch": 39.410675717371184,
      "grad_norm": 3.053453838219866e-05,
      "learning_rate": 1.0589324282628819e-05,
      "loss": 0.0,
      "step": 127730
    },
    {
      "epoch": 39.4137611848195,
      "grad_norm": 1.0595736057439353e-05,
      "learning_rate": 1.0586238815180501e-05,
      "loss": 0.0,
      "step": 127740
    },
    {
      "epoch": 39.41684665226782,
      "grad_norm": 0.0002003493718802929,
      "learning_rate": 1.0583153347732182e-05,
      "loss": 0.0,
      "step": 127750
    },
    {
      "epoch": 39.41993211971614,
      "grad_norm": 2.6072541459143395e-06,
      "learning_rate": 1.0580067880283863e-05,
      "loss": 0.0,
      "step": 127760
    },
    {
      "epoch": 39.42301758716445,
      "grad_norm": 5.843801318405895e-07,
      "learning_rate": 1.0576982412835545e-05,
      "loss": 0.0,
      "step": 127770
    },
    {
      "epoch": 39.426103054612774,
      "grad_norm": 3.211673174519092e-05,
      "learning_rate": 1.0573896945387226e-05,
      "loss": 0.0,
      "step": 127780
    },
    {
      "epoch": 39.42918852206109,
      "grad_norm": 7.315132825169712e-05,
      "learning_rate": 1.0570811477938909e-05,
      "loss": 0.0,
      "step": 127790
    },
    {
      "epoch": 39.43227398950941,
      "grad_norm": 0.015917595475912094,
      "learning_rate": 1.0567726010490591e-05,
      "loss": 0.0,
      "step": 127800
    },
    {
      "epoch": 39.43535945695773,
      "grad_norm": 6.954234095246647e-07,
      "learning_rate": 1.0564640543042272e-05,
      "loss": 0.0,
      "step": 127810
    },
    {
      "epoch": 39.43844492440605,
      "grad_norm": 9.440888959488802e-08,
      "learning_rate": 1.0561555075593953e-05,
      "loss": 0.0,
      "step": 127820
    },
    {
      "epoch": 39.441530391854364,
      "grad_norm": 0.0006637207116000354,
      "learning_rate": 1.0558469608145635e-05,
      "loss": 0.0,
      "step": 127830
    },
    {
      "epoch": 39.44461585930269,
      "grad_norm": 1.0491290595382452e-05,
      "learning_rate": 1.0555384140697316e-05,
      "loss": 0.0,
      "step": 127840
    },
    {
      "epoch": 39.447701326751,
      "grad_norm": 2.8446818305383204e-06,
      "learning_rate": 1.0552298673248998e-05,
      "loss": 0.0,
      "step": 127850
    },
    {
      "epoch": 39.450786794199324,
      "grad_norm": 0.00010605646821204573,
      "learning_rate": 1.054921320580068e-05,
      "loss": 0.0,
      "step": 127860
    },
    {
      "epoch": 39.45387226164764,
      "grad_norm": 4.3360570689543465e-10,
      "learning_rate": 1.0546127738352362e-05,
      "loss": 0.0,
      "step": 127870
    },
    {
      "epoch": 39.45695772909596,
      "grad_norm": 5.815987151436275e-06,
      "learning_rate": 1.0543042270904042e-05,
      "loss": 0.0,
      "step": 127880
    },
    {
      "epoch": 39.46004319654428,
      "grad_norm": 3.757344302357524e-08,
      "learning_rate": 1.0539956803455723e-05,
      "loss": 0.0,
      "step": 127890
    },
    {
      "epoch": 39.46312866399259,
      "grad_norm": 4.3143824512981155e-08,
      "learning_rate": 1.0536871336007406e-05,
      "loss": 0.0,
      "step": 127900
    },
    {
      "epoch": 39.466214131440914,
      "grad_norm": 1.3133553693478461e-05,
      "learning_rate": 1.0533785868559088e-05,
      "loss": 0.0012,
      "step": 127910
    },
    {
      "epoch": 39.46929959888923,
      "grad_norm": 0.00031366542680189013,
      "learning_rate": 1.0530700401110769e-05,
      "loss": 0.0004,
      "step": 127920
    },
    {
      "epoch": 39.47238506633755,
      "grad_norm": 7.878628025537182e-07,
      "learning_rate": 1.0527614933662451e-05,
      "loss": 0.0,
      "step": 127930
    },
    {
      "epoch": 39.47547053378587,
      "grad_norm": 0.00010089202260132879,
      "learning_rate": 1.0524529466214132e-05,
      "loss": 0.0,
      "step": 127940
    },
    {
      "epoch": 39.47855600123419,
      "grad_norm": 0.00021947093773633242,
      "learning_rate": 1.0521443998765813e-05,
      "loss": 0.0,
      "step": 127950
    },
    {
      "epoch": 39.481641468682504,
      "grad_norm": 4.577483196044341e-06,
      "learning_rate": 1.0518358531317494e-05,
      "loss": 0.0001,
      "step": 127960
    },
    {
      "epoch": 39.484726936130826,
      "grad_norm": 2.3964043066371232e-05,
      "learning_rate": 1.0515273063869178e-05,
      "loss": 0.0029,
      "step": 127970
    },
    {
      "epoch": 39.48781240357914,
      "grad_norm": 2.1502145841623133e-08,
      "learning_rate": 1.0512187596420859e-05,
      "loss": 0.0,
      "step": 127980
    },
    {
      "epoch": 39.490897871027464,
      "grad_norm": 0.0007802087347954512,
      "learning_rate": 1.050910212897254e-05,
      "loss": 0.0,
      "step": 127990
    },
    {
      "epoch": 39.49398333847578,
      "grad_norm": 0.00017481214308645576,
      "learning_rate": 1.0506016661524222e-05,
      "loss": 0.0,
      "step": 128000
    },
    {
      "epoch": 39.497068805924094,
      "grad_norm": 6.716302323184209e-06,
      "learning_rate": 1.0502931194075903e-05,
      "loss": 0.0042,
      "step": 128010
    },
    {
      "epoch": 39.50015427337242,
      "grad_norm": 2.069337597276899e-06,
      "learning_rate": 1.0499845726627584e-05,
      "loss": 0.0015,
      "step": 128020
    },
    {
      "epoch": 39.50323974082073,
      "grad_norm": 4.17088508605957,
      "learning_rate": 1.0496760259179266e-05,
      "loss": 0.0101,
      "step": 128030
    },
    {
      "epoch": 39.506325208269054,
      "grad_norm": 4.933021457986797e-08,
      "learning_rate": 1.0493674791730948e-05,
      "loss": 0.0,
      "step": 128040
    },
    {
      "epoch": 39.50941067571737,
      "grad_norm": 3.2877110243134666e-06,
      "learning_rate": 1.049058932428263e-05,
      "loss": 0.0,
      "step": 128050
    },
    {
      "epoch": 39.51249614316569,
      "grad_norm": 0.0007239881088025868,
      "learning_rate": 1.048750385683431e-05,
      "loss": 0.0,
      "step": 128060
    },
    {
      "epoch": 39.51558161061401,
      "grad_norm": 1.14284716801194e-06,
      "learning_rate": 1.0484418389385993e-05,
      "loss": 0.0003,
      "step": 128070
    },
    {
      "epoch": 39.51866707806233,
      "grad_norm": 9.873174633412418e-08,
      "learning_rate": 1.0481332921937673e-05,
      "loss": 0.0001,
      "step": 128080
    },
    {
      "epoch": 39.521752545510644,
      "grad_norm": 0.00014735937293153256,
      "learning_rate": 1.0478247454489356e-05,
      "loss": 0.0,
      "step": 128090
    },
    {
      "epoch": 39.524838012958966,
      "grad_norm": 1.6018522046579164e-06,
      "learning_rate": 1.0475161987041038e-05,
      "loss": 0.0001,
      "step": 128100
    },
    {
      "epoch": 39.52792348040728,
      "grad_norm": 0.0007246003369800746,
      "learning_rate": 1.0472076519592719e-05,
      "loss": 0.0,
      "step": 128110
    },
    {
      "epoch": 39.5310089478556,
      "grad_norm": 1.3249469930087798e-06,
      "learning_rate": 1.04689910521444e-05,
      "loss": 0.0,
      "step": 128120
    },
    {
      "epoch": 39.53409441530392,
      "grad_norm": 3.960528374591377e-06,
      "learning_rate": 1.046590558469608e-05,
      "loss": 0.0021,
      "step": 128130
    },
    {
      "epoch": 39.537179882752234,
      "grad_norm": 2.3658953978156205e-06,
      "learning_rate": 1.0462820117247763e-05,
      "loss": 0.0,
      "step": 128140
    },
    {
      "epoch": 39.540265350200556,
      "grad_norm": 4.395345211029053,
      "learning_rate": 1.0459734649799446e-05,
      "loss": 0.0012,
      "step": 128150
    },
    {
      "epoch": 39.54335081764887,
      "grad_norm": 1.075420374974101e-08,
      "learning_rate": 1.0456649182351126e-05,
      "loss": 0.0,
      "step": 128160
    },
    {
      "epoch": 39.546436285097194,
      "grad_norm": 0.2531888782978058,
      "learning_rate": 1.0453563714902809e-05,
      "loss": 0.0001,
      "step": 128170
    },
    {
      "epoch": 39.54952175254551,
      "grad_norm": 0.00012986799993086606,
      "learning_rate": 1.045047824745449e-05,
      "loss": 0.0,
      "step": 128180
    },
    {
      "epoch": 39.55260721999383,
      "grad_norm": 5.743401061408804e-07,
      "learning_rate": 1.044739278000617e-05,
      "loss": 0.0,
      "step": 128190
    },
    {
      "epoch": 39.555692687442146,
      "grad_norm": 3.0153728403092828e-06,
      "learning_rate": 1.0444307312557853e-05,
      "loss": 0.0,
      "step": 128200
    },
    {
      "epoch": 39.55877815489047,
      "grad_norm": 5.961176441360294e-08,
      "learning_rate": 1.0441221845109535e-05,
      "loss": 0.0,
      "step": 128210
    },
    {
      "epoch": 39.561863622338784,
      "grad_norm": 3.6617691989704326e-08,
      "learning_rate": 1.0438136377661216e-05,
      "loss": 0.0,
      "step": 128220
    },
    {
      "epoch": 39.564949089787106,
      "grad_norm": 0.0012622893555089831,
      "learning_rate": 1.0435050910212897e-05,
      "loss": 0.0,
      "step": 128230
    },
    {
      "epoch": 39.56803455723542,
      "grad_norm": 9.073993112451717e-09,
      "learning_rate": 1.043196544276458e-05,
      "loss": 0.0,
      "step": 128240
    },
    {
      "epoch": 39.57112002468374,
      "grad_norm": 7.524762622779235e-06,
      "learning_rate": 1.042887997531626e-05,
      "loss": 0.0,
      "step": 128250
    },
    {
      "epoch": 39.57420549213206,
      "grad_norm": 4.384775991184142e-07,
      "learning_rate": 1.0425794507867943e-05,
      "loss": 0.0,
      "step": 128260
    },
    {
      "epoch": 39.577290959580374,
      "grad_norm": 2.8330799750619917e-07,
      "learning_rate": 1.0422709040419625e-05,
      "loss": 0.0,
      "step": 128270
    },
    {
      "epoch": 39.580376427028696,
      "grad_norm": 1.6560436051804572e-05,
      "learning_rate": 1.0419623572971306e-05,
      "loss": 0.0001,
      "step": 128280
    },
    {
      "epoch": 39.58346189447701,
      "grad_norm": 5.621621994578163e-07,
      "learning_rate": 1.0416538105522987e-05,
      "loss": 0.0,
      "step": 128290
    },
    {
      "epoch": 39.586547361925334,
      "grad_norm": 7.121089993233909e-07,
      "learning_rate": 1.041345263807467e-05,
      "loss": 0.0004,
      "step": 128300
    },
    {
      "epoch": 39.58963282937365,
      "grad_norm": 2.6396253360871924e-06,
      "learning_rate": 1.041036717062635e-05,
      "loss": 0.0,
      "step": 128310
    },
    {
      "epoch": 39.59271829682197,
      "grad_norm": 1.6631147445878014e-06,
      "learning_rate": 1.0407281703178032e-05,
      "loss": 0.0,
      "step": 128320
    },
    {
      "epoch": 39.595803764270286,
      "grad_norm": 4.255899057170609e-06,
      "learning_rate": 1.0404196235729713e-05,
      "loss": 0.0,
      "step": 128330
    },
    {
      "epoch": 39.59888923171861,
      "grad_norm": 5.481389919737012e-08,
      "learning_rate": 1.0401110768281396e-05,
      "loss": 0.0,
      "step": 128340
    },
    {
      "epoch": 39.601974699166924,
      "grad_norm": 2.439650779706426e-05,
      "learning_rate": 1.0398025300833076e-05,
      "loss": 0.0001,
      "step": 128350
    },
    {
      "epoch": 39.60506016661524,
      "grad_norm": 4.419130164023954e-06,
      "learning_rate": 1.0394939833384757e-05,
      "loss": 0.0,
      "step": 128360
    },
    {
      "epoch": 39.60814563406356,
      "grad_norm": 6.404080522770528e-06,
      "learning_rate": 1.039185436593644e-05,
      "loss": 0.0,
      "step": 128370
    },
    {
      "epoch": 39.611231101511876,
      "grad_norm": 0.0003327227896079421,
      "learning_rate": 1.0388768898488122e-05,
      "loss": 0.0001,
      "step": 128380
    },
    {
      "epoch": 39.6143165689602,
      "grad_norm": 0.004344357177615166,
      "learning_rate": 1.0385683431039803e-05,
      "loss": 0.0,
      "step": 128390
    },
    {
      "epoch": 39.617402036408514,
      "grad_norm": 4.837001597479684e-06,
      "learning_rate": 1.0382597963591485e-05,
      "loss": 0.0,
      "step": 128400
    },
    {
      "epoch": 39.620487503856836,
      "grad_norm": 2.7478615720610833e-06,
      "learning_rate": 1.0379512496143166e-05,
      "loss": 0.0,
      "step": 128410
    },
    {
      "epoch": 39.62357297130515,
      "grad_norm": 3.3446199267928023e-06,
      "learning_rate": 1.0376427028694847e-05,
      "loss": 0.0,
      "step": 128420
    },
    {
      "epoch": 39.62665843875347,
      "grad_norm": 2.1692005702789174e-06,
      "learning_rate": 1.037334156124653e-05,
      "loss": 0.0,
      "step": 128430
    },
    {
      "epoch": 39.62974390620179,
      "grad_norm": 4.831398427995737e-07,
      "learning_rate": 1.0370256093798212e-05,
      "loss": 0.0,
      "step": 128440
    },
    {
      "epoch": 39.63282937365011,
      "grad_norm": 5.223202151682926e-06,
      "learning_rate": 1.0367170626349893e-05,
      "loss": 0.0,
      "step": 128450
    },
    {
      "epoch": 39.635914841098426,
      "grad_norm": 2.5375704808539012e-06,
      "learning_rate": 1.0364085158901574e-05,
      "loss": 0.0,
      "step": 128460
    },
    {
      "epoch": 39.63900030854674,
      "grad_norm": 0.00041457716724835336,
      "learning_rate": 1.0360999691453256e-05,
      "loss": 0.0,
      "step": 128470
    },
    {
      "epoch": 39.642085775995064,
      "grad_norm": 4.6985431367829733e-07,
      "learning_rate": 1.0357914224004937e-05,
      "loss": 0.0,
      "step": 128480
    },
    {
      "epoch": 39.64517124344338,
      "grad_norm": 0.005103838164359331,
      "learning_rate": 1.035482875655662e-05,
      "loss": 0.0,
      "step": 128490
    },
    {
      "epoch": 39.6482567108917,
      "grad_norm": 1.7887012759842946e-08,
      "learning_rate": 1.0351743289108302e-05,
      "loss": 0.0,
      "step": 128500
    },
    {
      "epoch": 39.651342178340016,
      "grad_norm": 0.10397601127624512,
      "learning_rate": 1.0348657821659983e-05,
      "loss": 0.0,
      "step": 128510
    },
    {
      "epoch": 39.65442764578834,
      "grad_norm": 1.7461514289607294e-05,
      "learning_rate": 1.0345572354211663e-05,
      "loss": 0.0,
      "step": 128520
    },
    {
      "epoch": 39.657513113236654,
      "grad_norm": 9.047599291989172e-07,
      "learning_rate": 1.0342486886763344e-05,
      "loss": 0.0011,
      "step": 128530
    },
    {
      "epoch": 39.660598580684976,
      "grad_norm": 6.772074243599491e-07,
      "learning_rate": 1.0339401419315027e-05,
      "loss": 0.0,
      "step": 128540
    },
    {
      "epoch": 39.66368404813329,
      "grad_norm": 2.541686683343869e-07,
      "learning_rate": 1.0336315951866709e-05,
      "loss": 0.0,
      "step": 128550
    },
    {
      "epoch": 39.66676951558161,
      "grad_norm": 0.00033228358370251954,
      "learning_rate": 1.033323048441839e-05,
      "loss": 0.0,
      "step": 128560
    },
    {
      "epoch": 39.66985498302993,
      "grad_norm": 2.9815881134709343e-05,
      "learning_rate": 1.0330145016970072e-05,
      "loss": 0.0,
      "step": 128570
    },
    {
      "epoch": 39.67294045047825,
      "grad_norm": 1.3698017937713303e-05,
      "learning_rate": 1.0327059549521753e-05,
      "loss": 0.0,
      "step": 128580
    },
    {
      "epoch": 39.676025917926566,
      "grad_norm": 2.1987289073877037e-06,
      "learning_rate": 1.0323974082073434e-05,
      "loss": 0.0,
      "step": 128590
    },
    {
      "epoch": 39.67911138537488,
      "grad_norm": 2.0226056221872568e-05,
      "learning_rate": 1.0320888614625116e-05,
      "loss": 0.0,
      "step": 128600
    },
    {
      "epoch": 39.6821968528232,
      "grad_norm": 2.661729922692757e-06,
      "learning_rate": 1.0317803147176799e-05,
      "loss": 0.0,
      "step": 128610
    },
    {
      "epoch": 39.68528232027152,
      "grad_norm": 0.0010467623360455036,
      "learning_rate": 1.031471767972848e-05,
      "loss": 0.0,
      "step": 128620
    },
    {
      "epoch": 39.68836778771984,
      "grad_norm": 0.0013133015017956495,
      "learning_rate": 1.031163221228016e-05,
      "loss": 0.0007,
      "step": 128630
    },
    {
      "epoch": 39.691453255168156,
      "grad_norm": 4.330583396949805e-05,
      "learning_rate": 1.0308546744831843e-05,
      "loss": 0.0,
      "step": 128640
    },
    {
      "epoch": 39.69453872261648,
      "grad_norm": 8.818434480417636e-07,
      "learning_rate": 1.0305461277383524e-05,
      "loss": 0.0,
      "step": 128650
    },
    {
      "epoch": 39.69762419006479,
      "grad_norm": 3.852713416563347e-05,
      "learning_rate": 1.0302375809935204e-05,
      "loss": 0.0,
      "step": 128660
    },
    {
      "epoch": 39.700709657513116,
      "grad_norm": 0.000734992150682956,
      "learning_rate": 1.0299290342486887e-05,
      "loss": 0.0,
      "step": 128670
    },
    {
      "epoch": 39.70379512496143,
      "grad_norm": 0.00021521913004107773,
      "learning_rate": 1.029620487503857e-05,
      "loss": 0.0,
      "step": 128680
    },
    {
      "epoch": 39.70688059240975,
      "grad_norm": 5.371102815843187e-05,
      "learning_rate": 1.029311940759025e-05,
      "loss": 0.0,
      "step": 128690
    },
    {
      "epoch": 39.70996605985807,
      "grad_norm": 1.9417033314539367e-08,
      "learning_rate": 1.0290033940141933e-05,
      "loss": 0.0,
      "step": 128700
    },
    {
      "epoch": 39.71305152730638,
      "grad_norm": 1.1761247833419475e-06,
      "learning_rate": 1.0286948472693613e-05,
      "loss": 0.0,
      "step": 128710
    },
    {
      "epoch": 39.716136994754706,
      "grad_norm": 2.1288010429998394e-06,
      "learning_rate": 1.0283863005245294e-05,
      "loss": 0.0,
      "step": 128720
    },
    {
      "epoch": 39.71922246220302,
      "grad_norm": 7.538854788435856e-06,
      "learning_rate": 1.0280777537796977e-05,
      "loss": 0.0,
      "step": 128730
    },
    {
      "epoch": 39.72230792965134,
      "grad_norm": 2.4001257770578377e-05,
      "learning_rate": 1.027769207034866e-05,
      "loss": 0.0001,
      "step": 128740
    },
    {
      "epoch": 39.72539339709966,
      "grad_norm": 0.001189533737488091,
      "learning_rate": 1.027460660290034e-05,
      "loss": 0.0,
      "step": 128750
    },
    {
      "epoch": 39.72847886454798,
      "grad_norm": 5.613520315250753e-09,
      "learning_rate": 1.027152113545202e-05,
      "loss": 0.0,
      "step": 128760
    },
    {
      "epoch": 39.731564331996296,
      "grad_norm": 4.2279254557797685e-05,
      "learning_rate": 1.0268435668003703e-05,
      "loss": 0.0009,
      "step": 128770
    },
    {
      "epoch": 39.73464979944462,
      "grad_norm": 0.00011180768342455849,
      "learning_rate": 1.0265350200555384e-05,
      "loss": 0.0,
      "step": 128780
    },
    {
      "epoch": 39.73773526689293,
      "grad_norm": 3.9743030356476083e-05,
      "learning_rate": 1.0262264733107067e-05,
      "loss": 0.0,
      "step": 128790
    },
    {
      "epoch": 39.740820734341256,
      "grad_norm": 0.00021331965399440378,
      "learning_rate": 1.0259179265658749e-05,
      "loss": 0.0,
      "step": 128800
    },
    {
      "epoch": 39.74390620178957,
      "grad_norm": 3.6586841360986e-06,
      "learning_rate": 1.025609379821043e-05,
      "loss": 0.0,
      "step": 128810
    },
    {
      "epoch": 39.746991669237886,
      "grad_norm": 4.74688749818597e-06,
      "learning_rate": 1.025300833076211e-05,
      "loss": 0.0005,
      "step": 128820
    },
    {
      "epoch": 39.75007713668621,
      "grad_norm": 1.0107841319495492e-07,
      "learning_rate": 1.0249922863313791e-05,
      "loss": 0.0,
      "step": 128830
    },
    {
      "epoch": 39.75316260413452,
      "grad_norm": 9.857081749942154e-06,
      "learning_rate": 1.0246837395865474e-05,
      "loss": 0.0,
      "step": 128840
    },
    {
      "epoch": 39.756248071582846,
      "grad_norm": 0.00024378910893574357,
      "learning_rate": 1.0243751928417156e-05,
      "loss": 0.0,
      "step": 128850
    },
    {
      "epoch": 39.75933353903116,
      "grad_norm": 2.734049076025258e-06,
      "learning_rate": 1.0240666460968837e-05,
      "loss": 0.0,
      "step": 128860
    },
    {
      "epoch": 39.76241900647948,
      "grad_norm": 4.674179763242137e-06,
      "learning_rate": 1.023758099352052e-05,
      "loss": 0.0,
      "step": 128870
    },
    {
      "epoch": 39.7655044739278,
      "grad_norm": 0.0010314702522009611,
      "learning_rate": 1.02344955260722e-05,
      "loss": 0.0002,
      "step": 128880
    },
    {
      "epoch": 39.76858994137612,
      "grad_norm": 1.041412588165258e-06,
      "learning_rate": 1.0231410058623881e-05,
      "loss": 0.0,
      "step": 128890
    },
    {
      "epoch": 39.771675408824436,
      "grad_norm": 4.41520541016871e-07,
      "learning_rate": 1.0228324591175564e-05,
      "loss": 0.0,
      "step": 128900
    },
    {
      "epoch": 39.77476087627276,
      "grad_norm": 0.0002447156293783337,
      "learning_rate": 1.0225239123727246e-05,
      "loss": 0.0,
      "step": 128910
    },
    {
      "epoch": 39.77784634372107,
      "grad_norm": 0.05128907412290573,
      "learning_rate": 1.0222153656278927e-05,
      "loss": 0.0,
      "step": 128920
    },
    {
      "epoch": 39.780931811169395,
      "grad_norm": 2.9420869395835325e-05,
      "learning_rate": 1.0219068188830608e-05,
      "loss": 0.0,
      "step": 128930
    },
    {
      "epoch": 39.78401727861771,
      "grad_norm": 1.5538811567239463e-05,
      "learning_rate": 1.021598272138229e-05,
      "loss": 0.0054,
      "step": 128940
    },
    {
      "epoch": 39.787102746066026,
      "grad_norm": 9.346524166176096e-05,
      "learning_rate": 1.0212897253933971e-05,
      "loss": 0.0,
      "step": 128950
    },
    {
      "epoch": 39.79018821351435,
      "grad_norm": 1.2952835248825068e-08,
      "learning_rate": 1.0209811786485653e-05,
      "loss": 0.0,
      "step": 128960
    },
    {
      "epoch": 39.79327368096266,
      "grad_norm": 9.073027484873819e-08,
      "learning_rate": 1.0206726319037336e-05,
      "loss": 0.0,
      "step": 128970
    },
    {
      "epoch": 39.796359148410986,
      "grad_norm": 1.1262554266977531e-07,
      "learning_rate": 1.0203640851589017e-05,
      "loss": 0.0,
      "step": 128980
    },
    {
      "epoch": 39.7994446158593,
      "grad_norm": 0.0020393196027725935,
      "learning_rate": 1.0200555384140697e-05,
      "loss": 0.0,
      "step": 128990
    },
    {
      "epoch": 39.80253008330762,
      "grad_norm": 0.00022633974731434137,
      "learning_rate": 1.0197469916692378e-05,
      "loss": 0.0,
      "step": 129000
    },
    {
      "epoch": 39.80561555075594,
      "grad_norm": 0.005445971619337797,
      "learning_rate": 1.019438444924406e-05,
      "loss": 0.0,
      "step": 129010
    },
    {
      "epoch": 39.80870101820426,
      "grad_norm": 0.001428929390385747,
      "learning_rate": 1.0191298981795743e-05,
      "loss": 0.0,
      "step": 129020
    },
    {
      "epoch": 39.811786485652576,
      "grad_norm": 1.728592913252669e-08,
      "learning_rate": 1.0188213514347424e-05,
      "loss": 0.0001,
      "step": 129030
    },
    {
      "epoch": 39.8148719531009,
      "grad_norm": 0.0022867219522595406,
      "learning_rate": 1.0185128046899106e-05,
      "loss": 0.0,
      "step": 129040
    },
    {
      "epoch": 39.81795742054921,
      "grad_norm": 1.7564337895237259e-06,
      "learning_rate": 1.0182042579450787e-05,
      "loss": 0.0,
      "step": 129050
    },
    {
      "epoch": 39.82104288799753,
      "grad_norm": 0.0010225025471299887,
      "learning_rate": 1.0178957112002468e-05,
      "loss": 0.0,
      "step": 129060
    },
    {
      "epoch": 39.82412835544585,
      "grad_norm": 8.921240350900916e-07,
      "learning_rate": 1.017587164455415e-05,
      "loss": 0.0,
      "step": 129070
    },
    {
      "epoch": 39.827213822894166,
      "grad_norm": 0.00013130133447702974,
      "learning_rate": 1.0172786177105833e-05,
      "loss": 0.0,
      "step": 129080
    },
    {
      "epoch": 39.83029929034249,
      "grad_norm": 5.2468049034359865e-06,
      "learning_rate": 1.0169700709657514e-05,
      "loss": 0.0004,
      "step": 129090
    },
    {
      "epoch": 39.8333847577908,
      "grad_norm": 2.4628377559565706e-06,
      "learning_rate": 1.0166615242209194e-05,
      "loss": 0.0,
      "step": 129100
    },
    {
      "epoch": 39.836470225239125,
      "grad_norm": 1.3615998568639043e-06,
      "learning_rate": 1.0163529774760877e-05,
      "loss": 0.0,
      "step": 129110
    },
    {
      "epoch": 39.83955569268744,
      "grad_norm": 3.11062080982083e-06,
      "learning_rate": 1.0160444307312558e-05,
      "loss": 0.0,
      "step": 129120
    },
    {
      "epoch": 39.84264116013576,
      "grad_norm": 2.011569222304388e-06,
      "learning_rate": 1.015735883986424e-05,
      "loss": 0.0,
      "step": 129130
    },
    {
      "epoch": 39.84572662758408,
      "grad_norm": 2.531610476808055e-08,
      "learning_rate": 1.0154273372415923e-05,
      "loss": 0.0,
      "step": 129140
    },
    {
      "epoch": 39.8488120950324,
      "grad_norm": 0.00010113369353348389,
      "learning_rate": 1.0151187904967603e-05,
      "loss": 0.0,
      "step": 129150
    },
    {
      "epoch": 39.851897562480715,
      "grad_norm": 0.00010773370740935206,
      "learning_rate": 1.0148102437519284e-05,
      "loss": 0.0,
      "step": 129160
    },
    {
      "epoch": 39.85498302992904,
      "grad_norm": 6.522942840092583e-06,
      "learning_rate": 1.0145016970070967e-05,
      "loss": 0.0001,
      "step": 129170
    },
    {
      "epoch": 39.85806849737735,
      "grad_norm": 3.4457579545232875e-07,
      "learning_rate": 1.0141931502622648e-05,
      "loss": 0.0,
      "step": 129180
    },
    {
      "epoch": 39.86115396482567,
      "grad_norm": 8.759019465287565e-07,
      "learning_rate": 1.013884603517433e-05,
      "loss": 0.0,
      "step": 129190
    },
    {
      "epoch": 39.86423943227399,
      "grad_norm": 0.00011032746988348663,
      "learning_rate": 1.013576056772601e-05,
      "loss": 0.0,
      "step": 129200
    },
    {
      "epoch": 39.867324899722306,
      "grad_norm": 2.3414530403442768e-07,
      "learning_rate": 1.0132675100277693e-05,
      "loss": 0.0,
      "step": 129210
    },
    {
      "epoch": 39.87041036717063,
      "grad_norm": 0.006710753310471773,
      "learning_rate": 1.0129589632829374e-05,
      "loss": 0.0,
      "step": 129220
    },
    {
      "epoch": 39.87349583461894,
      "grad_norm": 4.797141173185082e-07,
      "learning_rate": 1.0126504165381055e-05,
      "loss": 0.0,
      "step": 129230
    },
    {
      "epoch": 39.876581302067265,
      "grad_norm": 0.0021720847580581903,
      "learning_rate": 1.0123418697932737e-05,
      "loss": 0.0,
      "step": 129240
    },
    {
      "epoch": 39.87966676951558,
      "grad_norm": 0.000585123838391155,
      "learning_rate": 1.012033323048442e-05,
      "loss": 0.0,
      "step": 129250
    },
    {
      "epoch": 39.8827522369639,
      "grad_norm": 3.770917444967381e-08,
      "learning_rate": 1.01172477630361e-05,
      "loss": 0.0,
      "step": 129260
    },
    {
      "epoch": 39.88583770441222,
      "grad_norm": 4.533747812729416e-07,
      "learning_rate": 1.0114162295587783e-05,
      "loss": 0.0,
      "step": 129270
    },
    {
      "epoch": 39.88892317186054,
      "grad_norm": 0.15326882898807526,
      "learning_rate": 1.0111076828139464e-05,
      "loss": 0.0001,
      "step": 129280
    },
    {
      "epoch": 39.892008639308855,
      "grad_norm": 6.414898052753415e-06,
      "learning_rate": 1.0107991360691145e-05,
      "loss": 0.0,
      "step": 129290
    },
    {
      "epoch": 39.89509410675717,
      "grad_norm": 7.709463716309983e-07,
      "learning_rate": 1.0104905893242825e-05,
      "loss": 0.0,
      "step": 129300
    },
    {
      "epoch": 39.89817957420549,
      "grad_norm": 7.268741228472209e-06,
      "learning_rate": 1.0101820425794508e-05,
      "loss": 0.0,
      "step": 129310
    },
    {
      "epoch": 39.90126504165381,
      "grad_norm": 1.072539816959761e-06,
      "learning_rate": 1.009873495834619e-05,
      "loss": 0.0,
      "step": 129320
    },
    {
      "epoch": 39.90435050910213,
      "grad_norm": 1.4395682512713392e-07,
      "learning_rate": 1.0095649490897871e-05,
      "loss": 0.0,
      "step": 129330
    },
    {
      "epoch": 39.907435976550445,
      "grad_norm": 0.0005914628854952753,
      "learning_rate": 1.0092564023449554e-05,
      "loss": 0.0,
      "step": 129340
    },
    {
      "epoch": 39.91052144399877,
      "grad_norm": 6.968758953007637e-06,
      "learning_rate": 1.0089478556001234e-05,
      "loss": 0.0,
      "step": 129350
    },
    {
      "epoch": 39.91360691144708,
      "grad_norm": 0.0006982978084124625,
      "learning_rate": 1.0086393088552915e-05,
      "loss": 0.0001,
      "step": 129360
    },
    {
      "epoch": 39.916692378895405,
      "grad_norm": 5.073340162198292e-06,
      "learning_rate": 1.0083307621104598e-05,
      "loss": 0.0,
      "step": 129370
    },
    {
      "epoch": 39.91977784634372,
      "grad_norm": 1.810673779800709e-07,
      "learning_rate": 1.008022215365628e-05,
      "loss": 0.0001,
      "step": 129380
    },
    {
      "epoch": 39.92286331379204,
      "grad_norm": 2.163981207559118e-07,
      "learning_rate": 1.0077136686207961e-05,
      "loss": 0.0001,
      "step": 129390
    },
    {
      "epoch": 39.92594878124036,
      "grad_norm": 2.5372131062795233e-09,
      "learning_rate": 1.0074051218759642e-05,
      "loss": 0.0,
      "step": 129400
    },
    {
      "epoch": 39.92903424868867,
      "grad_norm": 2.957533773439991e-08,
      "learning_rate": 1.0070965751311324e-05,
      "loss": 0.0,
      "step": 129410
    },
    {
      "epoch": 39.932119716136995,
      "grad_norm": 4.03889953304315e-06,
      "learning_rate": 1.0067880283863005e-05,
      "loss": 0.0,
      "step": 129420
    },
    {
      "epoch": 39.93520518358531,
      "grad_norm": 1.2397265436447924e-07,
      "learning_rate": 1.0064794816414687e-05,
      "loss": 0.0,
      "step": 129430
    },
    {
      "epoch": 39.93829065103363,
      "grad_norm": 2.5492813193750408e-08,
      "learning_rate": 1.006170934896637e-05,
      "loss": 0.0,
      "step": 129440
    },
    {
      "epoch": 39.94137611848195,
      "grad_norm": 5.514547751772625e-07,
      "learning_rate": 1.005862388151805e-05,
      "loss": 0.0008,
      "step": 129450
    },
    {
      "epoch": 39.94446158593027,
      "grad_norm": 1.5783576600369997e-05,
      "learning_rate": 1.0055538414069731e-05,
      "loss": 0.0,
      "step": 129460
    },
    {
      "epoch": 39.947547053378585,
      "grad_norm": 0.0003408583579584956,
      "learning_rate": 1.0052452946621414e-05,
      "loss": 0.0,
      "step": 129470
    },
    {
      "epoch": 39.95063252082691,
      "grad_norm": 3.223071871616412e-07,
      "learning_rate": 1.0049367479173095e-05,
      "loss": 0.0001,
      "step": 129480
    },
    {
      "epoch": 39.95371798827522,
      "grad_norm": 1.4916964573785663e-05,
      "learning_rate": 1.0046282011724777e-05,
      "loss": 0.0,
      "step": 129490
    },
    {
      "epoch": 39.956803455723545,
      "grad_norm": 8.823011012282223e-05,
      "learning_rate": 1.0043196544276458e-05,
      "loss": 0.0,
      "step": 129500
    },
    {
      "epoch": 39.95988892317186,
      "grad_norm": 9.945692909241188e-07,
      "learning_rate": 1.004011107682814e-05,
      "loss": 0.0,
      "step": 129510
    },
    {
      "epoch": 39.96297439062018,
      "grad_norm": 5.889185922569595e-05,
      "learning_rate": 1.0037025609379821e-05,
      "loss": 0.0,
      "step": 129520
    },
    {
      "epoch": 39.9660598580685,
      "grad_norm": 4.468862698558951e-06,
      "learning_rate": 1.0033940141931502e-05,
      "loss": 0.0,
      "step": 129530
    },
    {
      "epoch": 39.96914532551681,
      "grad_norm": 3.3022686807271384e-08,
      "learning_rate": 1.0030854674483185e-05,
      "loss": 0.0,
      "step": 129540
    },
    {
      "epoch": 39.972230792965135,
      "grad_norm": 5.8941761693631634e-08,
      "learning_rate": 1.0027769207034867e-05,
      "loss": 0.0001,
      "step": 129550
    },
    {
      "epoch": 39.97531626041345,
      "grad_norm": 2.563335328886751e-05,
      "learning_rate": 1.0024683739586548e-05,
      "loss": 0.0,
      "step": 129560
    },
    {
      "epoch": 39.97840172786177,
      "grad_norm": 3.1192627147902385e-07,
      "learning_rate": 1.002159827213823e-05,
      "loss": 0.0,
      "step": 129570
    },
    {
      "epoch": 39.98148719531009,
      "grad_norm": 5.387249757404788e-07,
      "learning_rate": 1.0018512804689911e-05,
      "loss": 0.0,
      "step": 129580
    },
    {
      "epoch": 39.98457266275841,
      "grad_norm": 2.371337899376158e-07,
      "learning_rate": 1.0015427337241592e-05,
      "loss": 0.0,
      "step": 129590
    },
    {
      "epoch": 39.987658130206725,
      "grad_norm": 7.71905277474616e-08,
      "learning_rate": 1.0012341869793274e-05,
      "loss": 0.0,
      "step": 129600
    },
    {
      "epoch": 39.99074359765505,
      "grad_norm": 0.02566637098789215,
      "learning_rate": 1.0009256402344957e-05,
      "loss": 0.0,
      "step": 129610
    },
    {
      "epoch": 39.99382906510336,
      "grad_norm": 0.00043947677477262914,
      "learning_rate": 1.0006170934896638e-05,
      "loss": 0.0002,
      "step": 129620
    },
    {
      "epoch": 39.996914532551685,
      "grad_norm": 1.2699047147179954e-06,
      "learning_rate": 1.0003085467448318e-05,
      "loss": 0.0,
      "step": 129630
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.0,
      "learning_rate": 1e-05,
      "loss": 0.0,
      "step": 129640
    },
    {
      "epoch": 40.0,
      "eval_accuracy_branch1": 0.9999903552173451,
      "eval_accuracy_branch2": 0.3923015344849204,
      "eval_f1_branch1": 0.9999779341150886,
      "eval_f1_branch2": 0.3736003097231094,
      "eval_loss": 3.963762537750881e-06,
      "eval_precision_branch1": 0.9999782044855169,
      "eval_precision_branch2": 0.5101143587332619,
      "eval_recall_branch1": 0.9999776691007347,
      "eval_recall_branch2": 0.5061340817684673,
      "eval_runtime": 240.9219,
      "eval_samples_per_second": 430.359,
      "eval_steps_per_second": 53.798,
      "step": 129640
    },
    {
      "epoch": 40.003085467448315,
      "grad_norm": 7.599823584314436e-05,
      "learning_rate": 9.996914532551682e-06,
      "loss": 0.0,
      "step": 129650
    },
    {
      "epoch": 40.00617093489664,
      "grad_norm": 9.001159196486697e-05,
      "learning_rate": 9.993829065103364e-06,
      "loss": 0.0,
      "step": 129660
    },
    {
      "epoch": 40.00925640234495,
      "grad_norm": 2.7138382208136136e-08,
      "learning_rate": 9.990743597655045e-06,
      "loss": 0.0,
      "step": 129670
    },
    {
      "epoch": 40.012341869793275,
      "grad_norm": 1.0587193628452951e-06,
      "learning_rate": 9.987658130206727e-06,
      "loss": 0.0,
      "step": 129680
    },
    {
      "epoch": 40.01542733724159,
      "grad_norm": 4.404125320434105e-06,
      "learning_rate": 9.984572662758408e-06,
      "loss": 0.0,
      "step": 129690
    },
    {
      "epoch": 40.01851280468991,
      "grad_norm": 2.7637518940082373e-08,
      "learning_rate": 9.981487195310089e-06,
      "loss": 0.0,
      "step": 129700
    },
    {
      "epoch": 40.02159827213823,
      "grad_norm": 2.412773767446197e-07,
      "learning_rate": 9.978401727861771e-06,
      "loss": 0.0,
      "step": 129710
    },
    {
      "epoch": 40.02468373958655,
      "grad_norm": 5.259550448499795e-07,
      "learning_rate": 9.975316260413454e-06,
      "loss": 0.0,
      "step": 129720
    },
    {
      "epoch": 40.027769207034865,
      "grad_norm": 0.00021957933495286852,
      "learning_rate": 9.972230792965135e-06,
      "loss": 0.0,
      "step": 129730
    },
    {
      "epoch": 40.03085467448319,
      "grad_norm": 0.0013355838600546122,
      "learning_rate": 9.969145325516817e-06,
      "loss": 0.0,
      "step": 129740
    },
    {
      "epoch": 40.0339401419315,
      "grad_norm": 8.451275061815977e-05,
      "learning_rate": 9.966059858068498e-06,
      "loss": 0.0,
      "step": 129750
    },
    {
      "epoch": 40.03702560937982,
      "grad_norm": 1.4833487512078136e-05,
      "learning_rate": 9.962974390620179e-06,
      "loss": 0.0,
      "step": 129760
    },
    {
      "epoch": 40.04011107682814,
      "grad_norm": 4.608379011727948e-09,
      "learning_rate": 9.959888923171861e-06,
      "loss": 0.0,
      "step": 129770
    },
    {
      "epoch": 40.043196544276455,
      "grad_norm": 0.00033448313479311764,
      "learning_rate": 9.956803455723544e-06,
      "loss": 0.0,
      "step": 129780
    },
    {
      "epoch": 40.04628201172478,
      "grad_norm": 0.00017335775191895664,
      "learning_rate": 9.953717988275224e-06,
      "loss": 0.0,
      "step": 129790
    },
    {
      "epoch": 40.04936747917309,
      "grad_norm": 0.09421709179878235,
      "learning_rate": 9.950632520826905e-06,
      "loss": 0.0,
      "step": 129800
    },
    {
      "epoch": 40.052452946621415,
      "grad_norm": 4.297524469620839e-08,
      "learning_rate": 9.947547053378588e-06,
      "loss": 0.0,
      "step": 129810
    },
    {
      "epoch": 40.05553841406973,
      "grad_norm": 0.001651208265684545,
      "learning_rate": 9.944461585930268e-06,
      "loss": 0.0,
      "step": 129820
    },
    {
      "epoch": 40.05862388151805,
      "grad_norm": 1.0598174640108482e-06,
      "learning_rate": 9.941376118481951e-06,
      "loss": 0.0001,
      "step": 129830
    },
    {
      "epoch": 40.06170934896637,
      "grad_norm": 3.3551131650710886e-07,
      "learning_rate": 9.938290651033633e-06,
      "loss": 0.0,
      "step": 129840
    },
    {
      "epoch": 40.06479481641469,
      "grad_norm": 4.0929823086344186e-08,
      "learning_rate": 9.935205183585314e-06,
      "loss": 0.0,
      "step": 129850
    },
    {
      "epoch": 40.067880283863005,
      "grad_norm": 3.052880128961988e-05,
      "learning_rate": 9.932119716136995e-06,
      "loss": 0.0,
      "step": 129860
    },
    {
      "epoch": 40.07096575131133,
      "grad_norm": 4.619752189682913e-07,
      "learning_rate": 9.929034248688676e-06,
      "loss": 0.0,
      "step": 129870
    },
    {
      "epoch": 40.07405121875964,
      "grad_norm": 0.0011107426835224032,
      "learning_rate": 9.925948781240358e-06,
      "loss": 0.0,
      "step": 129880
    },
    {
      "epoch": 40.07713668620796,
      "grad_norm": 1.7988379852340586e-07,
      "learning_rate": 9.922863313792039e-06,
      "loss": 0.0,
      "step": 129890
    },
    {
      "epoch": 40.08022215365628,
      "grad_norm": 0.00010741488949861377,
      "learning_rate": 9.919777846343722e-06,
      "loss": 0.0,
      "step": 129900
    },
    {
      "epoch": 40.083307621104595,
      "grad_norm": 2.6477835035620956e-07,
      "learning_rate": 9.916692378895404e-06,
      "loss": 0.0,
      "step": 129910
    },
    {
      "epoch": 40.08639308855292,
      "grad_norm": 3.1909475950442356e-08,
      "learning_rate": 9.913606911447085e-06,
      "loss": 0.0,
      "step": 129920
    },
    {
      "epoch": 40.08947855600123,
      "grad_norm": 1.4928624295862392e-05,
      "learning_rate": 9.910521443998766e-06,
      "loss": 0.0,
      "step": 129930
    },
    {
      "epoch": 40.092564023449555,
      "grad_norm": 0.00032198935514315963,
      "learning_rate": 9.907435976550448e-06,
      "loss": 0.0002,
      "step": 129940
    },
    {
      "epoch": 40.09564949089787,
      "grad_norm": 2.9631362252757754e-08,
      "learning_rate": 9.904350509102129e-06,
      "loss": 0.0,
      "step": 129950
    },
    {
      "epoch": 40.09873495834619,
      "grad_norm": 1.192950662698422e-06,
      "learning_rate": 9.901265041653811e-06,
      "loss": 0.0,
      "step": 129960
    },
    {
      "epoch": 40.10182042579451,
      "grad_norm": 6.1746672145091e-05,
      "learning_rate": 9.898179574205492e-06,
      "loss": 0.0,
      "step": 129970
    },
    {
      "epoch": 40.10490589324283,
      "grad_norm": 7.829164587747073e-07,
      "learning_rate": 9.895094106757175e-06,
      "loss": 0.0,
      "step": 129980
    },
    {
      "epoch": 40.107991360691145,
      "grad_norm": 0.0010633483761921525,
      "learning_rate": 9.892008639308855e-06,
      "loss": 0.0,
      "step": 129990
    },
    {
      "epoch": 40.11107682813946,
      "grad_norm": 0.0005559014389291406,
      "learning_rate": 9.888923171860536e-06,
      "loss": 0.0,
      "step": 130000
    },
    {
      "epoch": 40.11416229558778,
      "grad_norm": 1.7051009493229685e-09,
      "learning_rate": 9.885837704412219e-06,
      "loss": 0.0,
      "step": 130010
    },
    {
      "epoch": 40.1172477630361,
      "grad_norm": 0.0027604768984019756,
      "learning_rate": 9.882752236963901e-06,
      "loss": 0.0,
      "step": 130020
    },
    {
      "epoch": 40.12033323048442,
      "grad_norm": 8.322040230268613e-06,
      "learning_rate": 9.879666769515582e-06,
      "loss": 0.0,
      "step": 130030
    },
    {
      "epoch": 40.123418697932735,
      "grad_norm": 8.592437552579213e-07,
      "learning_rate": 9.876581302067264e-06,
      "loss": 0.0,
      "step": 130040
    },
    {
      "epoch": 40.12650416538106,
      "grad_norm": 2.4050643787632e-07,
      "learning_rate": 9.873495834618945e-06,
      "loss": 0.0,
      "step": 130050
    },
    {
      "epoch": 40.12958963282937,
      "grad_norm": 8.22260626591742e-05,
      "learning_rate": 9.870410367170626e-06,
      "loss": 0.0,
      "step": 130060
    },
    {
      "epoch": 40.132675100277694,
      "grad_norm": 0.0003547016822267324,
      "learning_rate": 9.867324899722308e-06,
      "loss": 0.0,
      "step": 130070
    },
    {
      "epoch": 40.13576056772601,
      "grad_norm": 4.810453901882283e-07,
      "learning_rate": 9.86423943227399e-06,
      "loss": 0.0,
      "step": 130080
    },
    {
      "epoch": 40.13884603517433,
      "grad_norm": 5.8675809668784495e-06,
      "learning_rate": 9.861153964825672e-06,
      "loss": 0.0,
      "step": 130090
    },
    {
      "epoch": 40.14193150262265,
      "grad_norm": 6.204953388078138e-05,
      "learning_rate": 9.858068497377352e-06,
      "loss": 0.0,
      "step": 130100
    },
    {
      "epoch": 40.14501697007096,
      "grad_norm": 1.0262308336450587e-07,
      "learning_rate": 9.854983029929035e-06,
      "loss": 0.0001,
      "step": 130110
    },
    {
      "epoch": 40.148102437519285,
      "grad_norm": 1.0011610811488936e-06,
      "learning_rate": 9.851897562480716e-06,
      "loss": 0.0,
      "step": 130120
    },
    {
      "epoch": 40.1511879049676,
      "grad_norm": 3.063223630306311e-05,
      "learning_rate": 9.848812095032398e-06,
      "loss": 0.0,
      "step": 130130
    },
    {
      "epoch": 40.15427337241592,
      "grad_norm": 0.000773041567299515,
      "learning_rate": 9.84572662758408e-06,
      "loss": 0.0,
      "step": 130140
    },
    {
      "epoch": 40.15735883986424,
      "grad_norm": 0.00016335085092578083,
      "learning_rate": 9.842641160135761e-06,
      "loss": 0.0,
      "step": 130150
    },
    {
      "epoch": 40.16044430731256,
      "grad_norm": 1.4461906339136021e-08,
      "learning_rate": 9.839555692687442e-06,
      "loss": 0.0,
      "step": 130160
    },
    {
      "epoch": 40.163529774760875,
      "grad_norm": 5.705885268980637e-05,
      "learning_rate": 9.836470225239123e-06,
      "loss": 0.0,
      "step": 130170
    },
    {
      "epoch": 40.1666152422092,
      "grad_norm": 7.746995720481209e-07,
      "learning_rate": 9.833384757790805e-06,
      "loss": 0.0,
      "step": 130180
    },
    {
      "epoch": 40.16970070965751,
      "grad_norm": 6.688857752124022e-07,
      "learning_rate": 9.830299290342488e-06,
      "loss": 0.0,
      "step": 130190
    },
    {
      "epoch": 40.172786177105834,
      "grad_norm": 3.1325929739978164e-05,
      "learning_rate": 9.827213822894169e-06,
      "loss": 0.0004,
      "step": 130200
    },
    {
      "epoch": 40.17587164455415,
      "grad_norm": 0.0075421459041535854,
      "learning_rate": 9.824128355445851e-06,
      "loss": 0.0,
      "step": 130210
    },
    {
      "epoch": 40.17895711200247,
      "grad_norm": 4.314277646244591e-07,
      "learning_rate": 9.821042887997532e-06,
      "loss": 0.0,
      "step": 130220
    },
    {
      "epoch": 40.18204257945079,
      "grad_norm": 8.5942744476597e-08,
      "learning_rate": 9.817957420549213e-06,
      "loss": 0.0,
      "step": 130230
    },
    {
      "epoch": 40.1851280468991,
      "grad_norm": 3.171982825733721e-05,
      "learning_rate": 9.814871953100895e-06,
      "loss": 0.0,
      "step": 130240
    },
    {
      "epoch": 40.188213514347424,
      "grad_norm": 1.1191265230081626e-06,
      "learning_rate": 9.811786485652578e-06,
      "loss": 0.0008,
      "step": 130250
    },
    {
      "epoch": 40.19129898179574,
      "grad_norm": 0.002668112749233842,
      "learning_rate": 9.808701018204258e-06,
      "loss": 0.0001,
      "step": 130260
    },
    {
      "epoch": 40.19438444924406,
      "grad_norm": 7.0382757257902995e-06,
      "learning_rate": 9.80561555075594e-06,
      "loss": 0.0,
      "step": 130270
    },
    {
      "epoch": 40.19746991669238,
      "grad_norm": 5.446869181469083e-06,
      "learning_rate": 9.802530083307622e-06,
      "loss": 0.0001,
      "step": 130280
    },
    {
      "epoch": 40.2005553841407,
      "grad_norm": 0.035628050565719604,
      "learning_rate": 9.799444615859303e-06,
      "loss": 0.0005,
      "step": 130290
    },
    {
      "epoch": 40.203640851589014,
      "grad_norm": 0.0021299729123711586,
      "learning_rate": 9.796359148410985e-06,
      "loss": 0.0,
      "step": 130300
    },
    {
      "epoch": 40.20672631903734,
      "grad_norm": 0.00011190587974851951,
      "learning_rate": 9.793273680962667e-06,
      "loss": 0.0,
      "step": 130310
    },
    {
      "epoch": 40.20981178648565,
      "grad_norm": 3.9239246518718573e-08,
      "learning_rate": 9.790188213514348e-06,
      "loss": 0.0,
      "step": 130320
    },
    {
      "epoch": 40.212897253933974,
      "grad_norm": 4.851581820730644e-07,
      "learning_rate": 9.787102746066029e-06,
      "loss": 0.0,
      "step": 130330
    },
    {
      "epoch": 40.21598272138229,
      "grad_norm": 2.7131400770485925e-07,
      "learning_rate": 9.784017278617712e-06,
      "loss": 0.0,
      "step": 130340
    },
    {
      "epoch": 40.219068188830605,
      "grad_norm": 0.5015142560005188,
      "learning_rate": 9.780931811169392e-06,
      "loss": 0.0002,
      "step": 130350
    },
    {
      "epoch": 40.22215365627893,
      "grad_norm": 1.8552406118033105e-06,
      "learning_rate": 9.777846343721075e-06,
      "loss": 0.0,
      "step": 130360
    },
    {
      "epoch": 40.22523912372724,
      "grad_norm": 4.033789764434914e-07,
      "learning_rate": 9.774760876272756e-06,
      "loss": 0.0,
      "step": 130370
    },
    {
      "epoch": 40.228324591175564,
      "grad_norm": 1.1547787153176614e-06,
      "learning_rate": 9.771675408824438e-06,
      "loss": 0.0,
      "step": 130380
    },
    {
      "epoch": 40.23141005862388,
      "grad_norm": 8.930458534450736e-06,
      "learning_rate": 9.768589941376119e-06,
      "loss": 0.0,
      "step": 130390
    },
    {
      "epoch": 40.2344955260722,
      "grad_norm": 2.670148569450248e-05,
      "learning_rate": 9.7655044739278e-06,
      "loss": 0.0,
      "step": 130400
    },
    {
      "epoch": 40.23758099352052,
      "grad_norm": 5.714453550353937e-07,
      "learning_rate": 9.762419006479482e-06,
      "loss": 0.0,
      "step": 130410
    },
    {
      "epoch": 40.24066646096884,
      "grad_norm": 9.534380183140456e-07,
      "learning_rate": 9.759333539031165e-06,
      "loss": 0.0,
      "step": 130420
    },
    {
      "epoch": 40.243751928417154,
      "grad_norm": 7.349564068448444e-09,
      "learning_rate": 9.756248071582845e-06,
      "loss": 0.0,
      "step": 130430
    },
    {
      "epoch": 40.24683739586548,
      "grad_norm": 5.466523361974396e-05,
      "learning_rate": 9.753162604134528e-06,
      "loss": 0.0,
      "step": 130440
    },
    {
      "epoch": 40.24992286331379,
      "grad_norm": 3.762444009680621e-07,
      "learning_rate": 9.750077136686209e-06,
      "loss": 0.0,
      "step": 130450
    },
    {
      "epoch": 40.25300833076211,
      "grad_norm": 0.00010453280992805958,
      "learning_rate": 9.74699166923789e-06,
      "loss": 0.0,
      "step": 130460
    },
    {
      "epoch": 40.25609379821043,
      "grad_norm": 9.228120347870572e-07,
      "learning_rate": 9.743906201789572e-06,
      "loss": 0.0,
      "step": 130470
    },
    {
      "epoch": 40.259179265658744,
      "grad_norm": 3.592971609123197e-08,
      "learning_rate": 9.740820734341254e-06,
      "loss": 0.0,
      "step": 130480
    },
    {
      "epoch": 40.26226473310707,
      "grad_norm": 5.575614192565581e-09,
      "learning_rate": 9.737735266892935e-06,
      "loss": 0.0,
      "step": 130490
    },
    {
      "epoch": 40.26535020055538,
      "grad_norm": 1.753118908709439e-06,
      "learning_rate": 9.734649799444616e-06,
      "loss": 0.0,
      "step": 130500
    },
    {
      "epoch": 40.268435668003704,
      "grad_norm": 4.469640043680556e-05,
      "learning_rate": 9.731564331996298e-06,
      "loss": 0.0,
      "step": 130510
    },
    {
      "epoch": 40.27152113545202,
      "grad_norm": 0.006225159857422113,
      "learning_rate": 9.72847886454798e-06,
      "loss": 0.0,
      "step": 130520
    },
    {
      "epoch": 40.27460660290034,
      "grad_norm": 0.010307356715202332,
      "learning_rate": 9.72539339709966e-06,
      "loss": 0.0001,
      "step": 130530
    },
    {
      "epoch": 40.27769207034866,
      "grad_norm": 1.0660744464985328e-06,
      "learning_rate": 9.722307929651342e-06,
      "loss": 0.0003,
      "step": 130540
    },
    {
      "epoch": 40.28077753779698,
      "grad_norm": 0.19408462941646576,
      "learning_rate": 9.719222462203025e-06,
      "loss": 0.0001,
      "step": 130550
    },
    {
      "epoch": 40.283863005245294,
      "grad_norm": 0.00013334432151168585,
      "learning_rate": 9.716136994754706e-06,
      "loss": 0.0,
      "step": 130560
    },
    {
      "epoch": 40.28694847269362,
      "grad_norm": 0.00026947318110615015,
      "learning_rate": 9.713051527306386e-06,
      "loss": 0.0,
      "step": 130570
    },
    {
      "epoch": 40.29003394014193,
      "grad_norm": 2.538633680160274e-06,
      "learning_rate": 9.709966059858069e-06,
      "loss": 0.0,
      "step": 130580
    },
    {
      "epoch": 40.29311940759025,
      "grad_norm": 9.628356565372087e-07,
      "learning_rate": 9.70688059240975e-06,
      "loss": 0.0,
      "step": 130590
    },
    {
      "epoch": 40.29620487503857,
      "grad_norm": 5.014729822505615e-07,
      "learning_rate": 9.703795124961432e-06,
      "loss": 0.0,
      "step": 130600
    },
    {
      "epoch": 40.299290342486884,
      "grad_norm": 3.7121651530469535e-08,
      "learning_rate": 9.700709657513115e-06,
      "loss": 0.0,
      "step": 130610
    },
    {
      "epoch": 40.30237580993521,
      "grad_norm": 1.3472676982928533e-06,
      "learning_rate": 9.697624190064795e-06,
      "loss": 0.0001,
      "step": 130620
    },
    {
      "epoch": 40.30546127738352,
      "grad_norm": 4.4865007708949634e-08,
      "learning_rate": 9.694538722616476e-06,
      "loss": 0.0,
      "step": 130630
    },
    {
      "epoch": 40.308546744831844,
      "grad_norm": 3.468995782895945e-05,
      "learning_rate": 9.691453255168157e-06,
      "loss": 0.0001,
      "step": 130640
    },
    {
      "epoch": 40.31163221228016,
      "grad_norm": 2.0870343178103212e-06,
      "learning_rate": 9.68836778771984e-06,
      "loss": 0.0,
      "step": 130650
    },
    {
      "epoch": 40.31471767972848,
      "grad_norm": 3.133689460810274e-05,
      "learning_rate": 9.685282320271522e-06,
      "loss": 0.0,
      "step": 130660
    },
    {
      "epoch": 40.3178031471768,
      "grad_norm": 1.0755354651337257e-06,
      "learning_rate": 9.682196852823203e-06,
      "loss": 0.0,
      "step": 130670
    },
    {
      "epoch": 40.32088861462512,
      "grad_norm": 1.3976767149870284e-05,
      "learning_rate": 9.679111385374885e-06,
      "loss": 0.0,
      "step": 130680
    },
    {
      "epoch": 40.323974082073434,
      "grad_norm": 4.5804558368445214e-08,
      "learning_rate": 9.676025917926566e-06,
      "loss": 0.0,
      "step": 130690
    },
    {
      "epoch": 40.32705954952175,
      "grad_norm": 4.0139067891686864e-07,
      "learning_rate": 9.672940450478247e-06,
      "loss": 0.0029,
      "step": 130700
    },
    {
      "epoch": 40.33014501697007,
      "grad_norm": 3.4439415230735904e-07,
      "learning_rate": 9.66985498302993e-06,
      "loss": 0.0,
      "step": 130710
    },
    {
      "epoch": 40.33323048441839,
      "grad_norm": 1.2113899856558419e-06,
      "learning_rate": 9.666769515581612e-06,
      "loss": 0.0,
      "step": 130720
    },
    {
      "epoch": 40.33631595186671,
      "grad_norm": 4.455296576111323e-08,
      "learning_rate": 9.663684048133293e-06,
      "loss": 0.0,
      "step": 130730
    },
    {
      "epoch": 40.339401419315024,
      "grad_norm": 1.4790775537676382e-07,
      "learning_rate": 9.660598580684973e-06,
      "loss": 0.0,
      "step": 130740
    },
    {
      "epoch": 40.342486886763346,
      "grad_norm": 6.298895186773734e-06,
      "learning_rate": 9.657513113236656e-06,
      "loss": 0.0,
      "step": 130750
    },
    {
      "epoch": 40.34557235421166,
      "grad_norm": 8.684383487889136e-07,
      "learning_rate": 9.654427645788337e-06,
      "loss": 0.0,
      "step": 130760
    },
    {
      "epoch": 40.348657821659984,
      "grad_norm": 0.00029295915737748146,
      "learning_rate": 9.651342178340019e-06,
      "loss": 0.0,
      "step": 130770
    },
    {
      "epoch": 40.3517432891083,
      "grad_norm": 9.788863280846272e-06,
      "learning_rate": 9.648256710891702e-06,
      "loss": 0.0,
      "step": 130780
    },
    {
      "epoch": 40.35482875655662,
      "grad_norm": 0.003459430765360594,
      "learning_rate": 9.645171243443382e-06,
      "loss": 0.0,
      "step": 130790
    },
    {
      "epoch": 40.357914224004936,
      "grad_norm": 9.434342018721509e-07,
      "learning_rate": 9.642085775995063e-06,
      "loss": 0.0,
      "step": 130800
    },
    {
      "epoch": 40.36099969145326,
      "grad_norm": 1.4763219041924458e-05,
      "learning_rate": 9.639000308546746e-06,
      "loss": 0.0,
      "step": 130810
    },
    {
      "epoch": 40.364085158901574,
      "grad_norm": 1.169043230220268e-06,
      "learning_rate": 9.635914841098426e-06,
      "loss": 0.0,
      "step": 130820
    },
    {
      "epoch": 40.36717062634989,
      "grad_norm": 6.30600334261544e-05,
      "learning_rate": 9.632829373650109e-06,
      "loss": 0.0001,
      "step": 130830
    },
    {
      "epoch": 40.37025609379821,
      "grad_norm": 0.0003923861659131944,
      "learning_rate": 9.62974390620179e-06,
      "loss": 0.0,
      "step": 130840
    },
    {
      "epoch": 40.37334156124653,
      "grad_norm": 1.7924368876265362e-05,
      "learning_rate": 9.626658438753472e-06,
      "loss": 0.0,
      "step": 130850
    },
    {
      "epoch": 40.37642702869485,
      "grad_norm": 7.109508442226797e-05,
      "learning_rate": 9.623572971305153e-06,
      "loss": 0.0,
      "step": 130860
    },
    {
      "epoch": 40.379512496143164,
      "grad_norm": 1.9406403225730173e-05,
      "learning_rate": 9.620487503856834e-06,
      "loss": 0.0,
      "step": 130870
    },
    {
      "epoch": 40.382597963591486,
      "grad_norm": 0.00031346542527899146,
      "learning_rate": 9.617402036408516e-06,
      "loss": 0.0,
      "step": 130880
    },
    {
      "epoch": 40.3856834310398,
      "grad_norm": 7.493913045664158e-08,
      "learning_rate": 9.614316568960199e-06,
      "loss": 0.0,
      "step": 130890
    },
    {
      "epoch": 40.388768898488124,
      "grad_norm": 1.8206440017820569e-06,
      "learning_rate": 9.61123110151188e-06,
      "loss": 0.0,
      "step": 130900
    },
    {
      "epoch": 40.39185436593644,
      "grad_norm": 2.757695438049268e-05,
      "learning_rate": 9.608145634063562e-06,
      "loss": 0.0,
      "step": 130910
    },
    {
      "epoch": 40.39493983338476,
      "grad_norm": 3.907598147634417e-05,
      "learning_rate": 9.605060166615243e-06,
      "loss": 0.0,
      "step": 130920
    },
    {
      "epoch": 40.398025300833076,
      "grad_norm": 2.069499259960139e-06,
      "learning_rate": 9.601974699166923e-06,
      "loss": 0.0,
      "step": 130930
    },
    {
      "epoch": 40.40111076828139,
      "grad_norm": 0.01890813186764717,
      "learning_rate": 9.598889231718606e-06,
      "loss": 0.0,
      "step": 130940
    },
    {
      "epoch": 40.404196235729714,
      "grad_norm": 0.0011223088949918747,
      "learning_rate": 9.595803764270288e-06,
      "loss": 0.0,
      "step": 130950
    },
    {
      "epoch": 40.40728170317803,
      "grad_norm": 5.041141321271425e-06,
      "learning_rate": 9.59271829682197e-06,
      "loss": 0.0,
      "step": 130960
    },
    {
      "epoch": 40.41036717062635,
      "grad_norm": 2.6006404141298844e-07,
      "learning_rate": 9.58963282937365e-06,
      "loss": 0.0,
      "step": 130970
    },
    {
      "epoch": 40.413452638074666,
      "grad_norm": 5.563911145145539e-07,
      "learning_rate": 9.586547361925332e-06,
      "loss": 0.0,
      "step": 130980
    },
    {
      "epoch": 40.41653810552299,
      "grad_norm": 5.08636439633392e-08,
      "learning_rate": 9.583461894477013e-06,
      "loss": 0.0001,
      "step": 130990
    },
    {
      "epoch": 40.419623572971304,
      "grad_norm": 2.4809251044644043e-06,
      "learning_rate": 9.580376427028696e-06,
      "loss": 0.0,
      "step": 131000
    },
    {
      "epoch": 40.422709040419626,
      "grad_norm": 6.135038006505056e-07,
      "learning_rate": 9.577290959580378e-06,
      "loss": 0.0,
      "step": 131010
    },
    {
      "epoch": 40.42579450786794,
      "grad_norm": 8.358114769180247e-07,
      "learning_rate": 9.574205492132059e-06,
      "loss": 0.0,
      "step": 131020
    },
    {
      "epoch": 40.42887997531626,
      "grad_norm": 1.7887067826904968e-07,
      "learning_rate": 9.57112002468374e-06,
      "loss": 0.0,
      "step": 131030
    },
    {
      "epoch": 40.43196544276458,
      "grad_norm": 1.0793049796120613e-06,
      "learning_rate": 9.56803455723542e-06,
      "loss": 0.0,
      "step": 131040
    },
    {
      "epoch": 40.435050910212894,
      "grad_norm": 7.739424745523138e-07,
      "learning_rate": 9.564949089787103e-06,
      "loss": 0.0,
      "step": 131050
    },
    {
      "epoch": 40.438136377661216,
      "grad_norm": 0.003720314707607031,
      "learning_rate": 9.561863622338785e-06,
      "loss": 0.0,
      "step": 131060
    },
    {
      "epoch": 40.44122184510953,
      "grad_norm": 1.7988621038966812e-05,
      "learning_rate": 9.558778154890466e-06,
      "loss": 0.0,
      "step": 131070
    },
    {
      "epoch": 40.444307312557854,
      "grad_norm": 2.212537566492756e-07,
      "learning_rate": 9.555692687442149e-06,
      "loss": 0.0,
      "step": 131080
    },
    {
      "epoch": 40.44739278000617,
      "grad_norm": 5.920483658883313e-07,
      "learning_rate": 9.55260721999383e-06,
      "loss": 0.0,
      "step": 131090
    },
    {
      "epoch": 40.45047824745449,
      "grad_norm": 3.204156882929965e-06,
      "learning_rate": 9.54952175254551e-06,
      "loss": 0.0,
      "step": 131100
    },
    {
      "epoch": 40.453563714902806,
      "grad_norm": 1.0312065569451079e-05,
      "learning_rate": 9.546436285097193e-06,
      "loss": 0.0,
      "step": 131110
    },
    {
      "epoch": 40.45664918235113,
      "grad_norm": 3.0465116651612334e-07,
      "learning_rate": 9.543350817648875e-06,
      "loss": 0.0,
      "step": 131120
    },
    {
      "epoch": 40.459734649799444,
      "grad_norm": 3.980949713877635e-06,
      "learning_rate": 9.540265350200556e-06,
      "loss": 0.0001,
      "step": 131130
    },
    {
      "epoch": 40.462820117247766,
      "grad_norm": 0.00039257033495232463,
      "learning_rate": 9.537179882752237e-06,
      "loss": 0.0,
      "step": 131140
    },
    {
      "epoch": 40.46590558469608,
      "grad_norm": 3.7537583352786896e-07,
      "learning_rate": 9.53409441530392e-06,
      "loss": 0.0,
      "step": 131150
    },
    {
      "epoch": 40.4689910521444,
      "grad_norm": 4.374820949948344e-09,
      "learning_rate": 9.5310089478556e-06,
      "loss": 0.0,
      "step": 131160
    },
    {
      "epoch": 40.47207651959272,
      "grad_norm": 5.765605237684213e-07,
      "learning_rate": 9.527923480407281e-06,
      "loss": 0.0,
      "step": 131170
    },
    {
      "epoch": 40.475161987041034,
      "grad_norm": 1.0589425336604563e-08,
      "learning_rate": 9.524838012958965e-06,
      "loss": 0.0,
      "step": 131180
    },
    {
      "epoch": 40.478247454489356,
      "grad_norm": 1.236370223978156e-07,
      "learning_rate": 9.521752545510646e-06,
      "loss": 0.0,
      "step": 131190
    },
    {
      "epoch": 40.48133292193767,
      "grad_norm": 1.0443210385346902e-06,
      "learning_rate": 9.518667078062327e-06,
      "loss": 0.0,
      "step": 131200
    },
    {
      "epoch": 40.48441838938599,
      "grad_norm": 1.9155724658048712e-05,
      "learning_rate": 9.515581610614009e-06,
      "loss": 0.0,
      "step": 131210
    },
    {
      "epoch": 40.48750385683431,
      "grad_norm": 0.0002554762177169323,
      "learning_rate": 9.51249614316569e-06,
      "loss": 0.0,
      "step": 131220
    },
    {
      "epoch": 40.49058932428263,
      "grad_norm": 2.464915996824857e-05,
      "learning_rate": 9.50941067571737e-06,
      "loss": 0.0,
      "step": 131230
    },
    {
      "epoch": 40.493674791730946,
      "grad_norm": 2.2178062053512804e-08,
      "learning_rate": 9.506325208269053e-06,
      "loss": 0.0,
      "step": 131240
    },
    {
      "epoch": 40.49676025917927,
      "grad_norm": 8.418022844125517e-06,
      "learning_rate": 9.503239740820736e-06,
      "loss": 0.0,
      "step": 131250
    },
    {
      "epoch": 40.49984572662758,
      "grad_norm": 4.1290240915259346e-05,
      "learning_rate": 9.500154273372416e-06,
      "loss": 0.0,
      "step": 131260
    },
    {
      "epoch": 40.502931194075906,
      "grad_norm": 0.0004672988725360483,
      "learning_rate": 9.497068805924097e-06,
      "loss": 0.0,
      "step": 131270
    },
    {
      "epoch": 40.50601666152422,
      "grad_norm": 8.97892823559232e-06,
      "learning_rate": 9.49398333847578e-06,
      "loss": 0.0002,
      "step": 131280
    },
    {
      "epoch": 40.509102128972536,
      "grad_norm": 0.11329828202724457,
      "learning_rate": 9.49089787102746e-06,
      "loss": 0.0,
      "step": 131290
    },
    {
      "epoch": 40.51218759642086,
      "grad_norm": 0.0016749879578128457,
      "learning_rate": 9.487812403579143e-06,
      "loss": 0.0,
      "step": 131300
    },
    {
      "epoch": 40.515273063869174,
      "grad_norm": 3.6842200188402785e-06,
      "learning_rate": 9.484726936130824e-06,
      "loss": 0.0,
      "step": 131310
    },
    {
      "epoch": 40.518358531317496,
      "grad_norm": 1.2021823749819305e-06,
      "learning_rate": 9.481641468682506e-06,
      "loss": 0.0,
      "step": 131320
    },
    {
      "epoch": 40.52144399876581,
      "grad_norm": 6.820505973337276e-07,
      "learning_rate": 9.478556001234187e-06,
      "loss": 0.0,
      "step": 131330
    },
    {
      "epoch": 40.52452946621413,
      "grad_norm": 9.926273136784403e-09,
      "learning_rate": 9.475470533785868e-06,
      "loss": 0.0,
      "step": 131340
    },
    {
      "epoch": 40.52761493366245,
      "grad_norm": 4.559753506327979e-06,
      "learning_rate": 9.47238506633755e-06,
      "loss": 0.0003,
      "step": 131350
    },
    {
      "epoch": 40.53070040111077,
      "grad_norm": 1.958987240868737e-06,
      "learning_rate": 9.469299598889233e-06,
      "loss": 0.0,
      "step": 131360
    },
    {
      "epoch": 40.533785868559086,
      "grad_norm": 2.9250864827190526e-05,
      "learning_rate": 9.466214131440913e-06,
      "loss": 0.0,
      "step": 131370
    },
    {
      "epoch": 40.53687133600741,
      "grad_norm": 2.829504808232741e-07,
      "learning_rate": 9.463128663992596e-06,
      "loss": 0.0002,
      "step": 131380
    },
    {
      "epoch": 40.53995680345572,
      "grad_norm": 1.8281551774634863e-06,
      "learning_rate": 9.460043196544277e-06,
      "loss": 0.0,
      "step": 131390
    },
    {
      "epoch": 40.54304227090404,
      "grad_norm": 1.978963155124802e-05,
      "learning_rate": 9.456957729095958e-06,
      "loss": 0.0,
      "step": 131400
    },
    {
      "epoch": 40.54612773835236,
      "grad_norm": 0.6160045862197876,
      "learning_rate": 9.45387226164764e-06,
      "loss": 0.0002,
      "step": 131410
    },
    {
      "epoch": 40.549213205800676,
      "grad_norm": 0.0006046890048310161,
      "learning_rate": 9.450786794199322e-06,
      "loss": 0.0,
      "step": 131420
    },
    {
      "epoch": 40.552298673249,
      "grad_norm": 1.2523219083959702e-05,
      "learning_rate": 9.447701326751003e-06,
      "loss": 0.0,
      "step": 131430
    },
    {
      "epoch": 40.55538414069731,
      "grad_norm": 1.6485863785220545e-09,
      "learning_rate": 9.444615859302684e-06,
      "loss": 0.0,
      "step": 131440
    },
    {
      "epoch": 40.558469608145636,
      "grad_norm": 4.835139577608061e-08,
      "learning_rate": 9.441530391854367e-06,
      "loss": 0.0,
      "step": 131450
    },
    {
      "epoch": 40.56155507559395,
      "grad_norm": 0.032501742243766785,
      "learning_rate": 9.438444924406047e-06,
      "loss": 0.0,
      "step": 131460
    },
    {
      "epoch": 40.56464054304227,
      "grad_norm": 4.656108387735003e-08,
      "learning_rate": 9.43535945695773e-06,
      "loss": 0.0,
      "step": 131470
    },
    {
      "epoch": 40.56772601049059,
      "grad_norm": 3.724001089722151e-07,
      "learning_rate": 9.432273989509412e-06,
      "loss": 0.0,
      "step": 131480
    },
    {
      "epoch": 40.57081147793891,
      "grad_norm": 7.18642741048825e-06,
      "learning_rate": 9.429188522061093e-06,
      "loss": 0.0,
      "step": 131490
    },
    {
      "epoch": 40.573896945387226,
      "grad_norm": 9.947477519745007e-05,
      "learning_rate": 9.426103054612774e-06,
      "loss": 0.0,
      "step": 131500
    },
    {
      "epoch": 40.57698241283555,
      "grad_norm": 7.400379331556906e-07,
      "learning_rate": 9.423017587164455e-06,
      "loss": 0.0,
      "step": 131510
    },
    {
      "epoch": 40.58006788028386,
      "grad_norm": 1.3319041727299918e-06,
      "learning_rate": 9.419932119716137e-06,
      "loss": 0.0,
      "step": 131520
    },
    {
      "epoch": 40.58315334773218,
      "grad_norm": 6.85327131577651e-06,
      "learning_rate": 9.41684665226782e-06,
      "loss": 0.0,
      "step": 131530
    },
    {
      "epoch": 40.5862388151805,
      "grad_norm": 5.397765345804828e-09,
      "learning_rate": 9.4137611848195e-06,
      "loss": 0.0,
      "step": 131540
    },
    {
      "epoch": 40.589324282628816,
      "grad_norm": 1.0800584959724802e-07,
      "learning_rate": 9.410675717371183e-06,
      "loss": 0.0,
      "step": 131550
    },
    {
      "epoch": 40.59240975007714,
      "grad_norm": 4.0957253077067435e-05,
      "learning_rate": 9.407590249922864e-06,
      "loss": 0.0,
      "step": 131560
    },
    {
      "epoch": 40.59549521752545,
      "grad_norm": 0.00022931683633942157,
      "learning_rate": 9.404504782474544e-06,
      "loss": 0.0,
      "step": 131570
    },
    {
      "epoch": 40.598580684973776,
      "grad_norm": 4.4241652119580976e-08,
      "learning_rate": 9.401419315026227e-06,
      "loss": 0.0,
      "step": 131580
    },
    {
      "epoch": 40.60166615242209,
      "grad_norm": 1.1791819787276836e-07,
      "learning_rate": 9.39833384757791e-06,
      "loss": 0.0,
      "step": 131590
    },
    {
      "epoch": 40.60475161987041,
      "grad_norm": 4.8892805352807045e-05,
      "learning_rate": 9.39524838012959e-06,
      "loss": 0.0,
      "step": 131600
    },
    {
      "epoch": 40.60783708731873,
      "grad_norm": 1.5278717455657898e-06,
      "learning_rate": 9.392162912681271e-06,
      "loss": 0.0,
      "step": 131610
    },
    {
      "epoch": 40.61092255476705,
      "grad_norm": 4.1696644359490165e-08,
      "learning_rate": 9.389077445232953e-06,
      "loss": 0.0,
      "step": 131620
    },
    {
      "epoch": 40.614008022215366,
      "grad_norm": 6.802181451348588e-05,
      "learning_rate": 9.385991977784634e-06,
      "loss": 0.0001,
      "step": 131630
    },
    {
      "epoch": 40.61709348966368,
      "grad_norm": 0.00030297914054244757,
      "learning_rate": 9.382906510336317e-06,
      "loss": 0.0,
      "step": 131640
    },
    {
      "epoch": 40.620178957112,
      "grad_norm": 0.0003981620538979769,
      "learning_rate": 9.379821042887999e-06,
      "loss": 0.0,
      "step": 131650
    },
    {
      "epoch": 40.62326442456032,
      "grad_norm": 1.782225211854893e-08,
      "learning_rate": 9.37673557543968e-06,
      "loss": 0.0,
      "step": 131660
    },
    {
      "epoch": 40.62634989200864,
      "grad_norm": 5.116030621366008e-08,
      "learning_rate": 9.37365010799136e-06,
      "loss": 0.0,
      "step": 131670
    },
    {
      "epoch": 40.629435359456956,
      "grad_norm": 6.664592547167558e-06,
      "learning_rate": 9.370564640543043e-06,
      "loss": 0.0002,
      "step": 131680
    },
    {
      "epoch": 40.63252082690528,
      "grad_norm": 6.608127023355337e-06,
      "learning_rate": 9.367479173094724e-06,
      "loss": 0.0,
      "step": 131690
    },
    {
      "epoch": 40.63560629435359,
      "grad_norm": 3.961486527259694e-06,
      "learning_rate": 9.364393705646406e-06,
      "loss": 0.0012,
      "step": 131700
    },
    {
      "epoch": 40.638691761801915,
      "grad_norm": 2.4925277841703064e-08,
      "learning_rate": 9.361308238198087e-06,
      "loss": 0.0,
      "step": 131710
    },
    {
      "epoch": 40.64177722925023,
      "grad_norm": 0.0005968183977529407,
      "learning_rate": 9.35822277074977e-06,
      "loss": 0.0011,
      "step": 131720
    },
    {
      "epoch": 40.64486269669855,
      "grad_norm": 4.464368075218772e-08,
      "learning_rate": 9.35513730330145e-06,
      "loss": 0.0,
      "step": 131730
    },
    {
      "epoch": 40.64794816414687,
      "grad_norm": 8.506886750581089e-09,
      "learning_rate": 9.352051835853131e-06,
      "loss": 0.0,
      "step": 131740
    },
    {
      "epoch": 40.65103363159518,
      "grad_norm": 6.625588412134675e-06,
      "learning_rate": 9.348966368404814e-06,
      "loss": 0.0,
      "step": 131750
    },
    {
      "epoch": 40.654119099043506,
      "grad_norm": 6.501861935248598e-05,
      "learning_rate": 9.345880900956496e-06,
      "loss": 0.0,
      "step": 131760
    },
    {
      "epoch": 40.65720456649182,
      "grad_norm": 1.7129060552178998e-06,
      "learning_rate": 9.342795433508177e-06,
      "loss": 0.0,
      "step": 131770
    },
    {
      "epoch": 40.66029003394014,
      "grad_norm": 1.3530292562791146e-05,
      "learning_rate": 9.33970996605986e-06,
      "loss": 0.0,
      "step": 131780
    },
    {
      "epoch": 40.66337550138846,
      "grad_norm": 1.099998598874663e-06,
      "learning_rate": 9.33662449861154e-06,
      "loss": 0.0,
      "step": 131790
    },
    {
      "epoch": 40.66646096883678,
      "grad_norm": 6.891188775171031e-08,
      "learning_rate": 9.333539031163221e-06,
      "loss": 0.0,
      "step": 131800
    },
    {
      "epoch": 40.669546436285096,
      "grad_norm": 2.145388407370774e-06,
      "learning_rate": 9.330453563714902e-06,
      "loss": 0.0,
      "step": 131810
    },
    {
      "epoch": 40.67263190373342,
      "grad_norm": 0.00030492624500766397,
      "learning_rate": 9.327368096266586e-06,
      "loss": 0.0,
      "step": 131820
    },
    {
      "epoch": 40.67571737118173,
      "grad_norm": 3.724023190443404e-05,
      "learning_rate": 9.324282628818267e-06,
      "loss": 0.0,
      "step": 131830
    },
    {
      "epoch": 40.678802838630055,
      "grad_norm": 0.00021993258269503713,
      "learning_rate": 9.321197161369948e-06,
      "loss": 0.0,
      "step": 131840
    },
    {
      "epoch": 40.68188830607837,
      "grad_norm": 2.824270268320106e-06,
      "learning_rate": 9.31811169392163e-06,
      "loss": 0.0,
      "step": 131850
    },
    {
      "epoch": 40.68497377352669,
      "grad_norm": 5.425529892022496e-08,
      "learning_rate": 9.31502622647331e-06,
      "loss": 0.0,
      "step": 131860
    },
    {
      "epoch": 40.68805924097501,
      "grad_norm": 1.0080383390231873e-06,
      "learning_rate": 9.311940759024992e-06,
      "loss": 0.0,
      "step": 131870
    },
    {
      "epoch": 40.69114470842332,
      "grad_norm": 1.0324374670744874e-06,
      "learning_rate": 9.308855291576676e-06,
      "loss": 0.0002,
      "step": 131880
    },
    {
      "epoch": 40.694230175871645,
      "grad_norm": 3.323129021737259e-06,
      "learning_rate": 9.305769824128357e-06,
      "loss": 0.0,
      "step": 131890
    },
    {
      "epoch": 40.69731564331996,
      "grad_norm": 1.7586018657311797e-05,
      "learning_rate": 9.302684356680037e-06,
      "loss": 0.0,
      "step": 131900
    },
    {
      "epoch": 40.70040111076828,
      "grad_norm": 4.020833088702602e-08,
      "learning_rate": 9.299598889231718e-06,
      "loss": 0.0,
      "step": 131910
    },
    {
      "epoch": 40.7034865782166,
      "grad_norm": 5.565510718952282e-07,
      "learning_rate": 9.2965134217834e-06,
      "loss": 0.0,
      "step": 131920
    },
    {
      "epoch": 40.70657204566492,
      "grad_norm": 8.003710263437824e-07,
      "learning_rate": 9.293427954335081e-06,
      "loss": 0.0,
      "step": 131930
    },
    {
      "epoch": 40.709657513113235,
      "grad_norm": 2.4495757315889932e-06,
      "learning_rate": 9.290342486886764e-06,
      "loss": 0.0,
      "step": 131940
    },
    {
      "epoch": 40.71274298056156,
      "grad_norm": 0.0009277776116505265,
      "learning_rate": 9.287257019438446e-06,
      "loss": 0.0,
      "step": 131950
    },
    {
      "epoch": 40.71582844800987,
      "grad_norm": 5.5008039474487305,
      "learning_rate": 9.284171551990127e-06,
      "loss": 0.0035,
      "step": 131960
    },
    {
      "epoch": 40.718913915458195,
      "grad_norm": 2.704046892176848e-06,
      "learning_rate": 9.281086084541808e-06,
      "loss": 0.0018,
      "step": 131970
    },
    {
      "epoch": 40.72199938290651,
      "grad_norm": 3.210038357792655e-06,
      "learning_rate": 9.27800061709349e-06,
      "loss": 0.0,
      "step": 131980
    },
    {
      "epoch": 40.725084850354826,
      "grad_norm": 4.712615577773249e-07,
      "learning_rate": 9.274915149645171e-06,
      "loss": 0.0,
      "step": 131990
    },
    {
      "epoch": 40.72817031780315,
      "grad_norm": 0.0014264275087043643,
      "learning_rate": 9.271829682196854e-06,
      "loss": 0.0,
      "step": 132000
    },
    {
      "epoch": 40.73125578525146,
      "grad_norm": 7.906271639512852e-05,
      "learning_rate": 9.268744214748534e-06,
      "loss": 0.0,
      "step": 132010
    },
    {
      "epoch": 40.734341252699785,
      "grad_norm": 1.005598187475698e-05,
      "learning_rate": 9.265658747300217e-06,
      "loss": 0.0,
      "step": 132020
    },
    {
      "epoch": 40.7374267201481,
      "grad_norm": 2.940246076832409e-06,
      "learning_rate": 9.262573279851898e-06,
      "loss": 0.0,
      "step": 132030
    },
    {
      "epoch": 40.74051218759642,
      "grad_norm": 2.1613269396425494e-08,
      "learning_rate": 9.259487812403578e-06,
      "loss": 0.0,
      "step": 132040
    },
    {
      "epoch": 40.74359765504474,
      "grad_norm": 3.6716246540891007e-05,
      "learning_rate": 9.256402344955261e-06,
      "loss": 0.0,
      "step": 132050
    },
    {
      "epoch": 40.74668312249306,
      "grad_norm": 1.615872315596789e-05,
      "learning_rate": 9.253316877506943e-06,
      "loss": 0.0,
      "step": 132060
    },
    {
      "epoch": 40.749768589941375,
      "grad_norm": 2.432818924091862e-08,
      "learning_rate": 9.250231410058624e-06,
      "loss": 0.0001,
      "step": 132070
    },
    {
      "epoch": 40.7528540573897,
      "grad_norm": 4.816396170781445e-08,
      "learning_rate": 9.247145942610307e-06,
      "loss": 0.0003,
      "step": 132080
    },
    {
      "epoch": 40.75593952483801,
      "grad_norm": 0.7274502515792847,
      "learning_rate": 9.244060475161987e-06,
      "loss": 0.0002,
      "step": 132090
    },
    {
      "epoch": 40.75902499228633,
      "grad_norm": 0.006885585840791464,
      "learning_rate": 9.240975007713668e-06,
      "loss": 0.0,
      "step": 132100
    },
    {
      "epoch": 40.76211045973465,
      "grad_norm": 9.38797040106465e-09,
      "learning_rate": 9.23788954026535e-06,
      "loss": 0.0,
      "step": 132110
    },
    {
      "epoch": 40.765195927182965,
      "grad_norm": 3.800735157710733e-06,
      "learning_rate": 9.234804072817033e-06,
      "loss": 0.0,
      "step": 132120
    },
    {
      "epoch": 40.76828139463129,
      "grad_norm": 4.1226321627618745e-05,
      "learning_rate": 9.231718605368714e-06,
      "loss": 0.0064,
      "step": 132130
    },
    {
      "epoch": 40.7713668620796,
      "grad_norm": 1.6545175185456173e-06,
      "learning_rate": 9.228633137920395e-06,
      "loss": 0.0043,
      "step": 132140
    },
    {
      "epoch": 40.774452329527925,
      "grad_norm": 4.310335498303175e-06,
      "learning_rate": 9.225547670472077e-06,
      "loss": 0.0001,
      "step": 132150
    },
    {
      "epoch": 40.77753779697624,
      "grad_norm": 0.0008524177246727049,
      "learning_rate": 9.222462203023758e-06,
      "loss": 0.0,
      "step": 132160
    },
    {
      "epoch": 40.78062326442456,
      "grad_norm": 1.23589200029528e-06,
      "learning_rate": 9.21937673557544e-06,
      "loss": 0.0,
      "step": 132170
    },
    {
      "epoch": 40.78370873187288,
      "grad_norm": 3.0180633103782384e-08,
      "learning_rate": 9.216291268127121e-06,
      "loss": 0.0,
      "step": 132180
    },
    {
      "epoch": 40.7867941993212,
      "grad_norm": 0.00716360891237855,
      "learning_rate": 9.213205800678804e-06,
      "loss": 0.0,
      "step": 132190
    },
    {
      "epoch": 40.789879666769515,
      "grad_norm": 0.0767563134431839,
      "learning_rate": 9.210120333230485e-06,
      "loss": 0.0,
      "step": 132200
    },
    {
      "epoch": 40.79296513421784,
      "grad_norm": 1.936138141900301e-05,
      "learning_rate": 9.207034865782165e-06,
      "loss": 0.0,
      "step": 132210
    },
    {
      "epoch": 40.79605060166615,
      "grad_norm": 3.7191378510215145e-07,
      "learning_rate": 9.203949398333848e-06,
      "loss": 0.0,
      "step": 132220
    },
    {
      "epoch": 40.79913606911447,
      "grad_norm": 2.692119598388672,
      "learning_rate": 9.20086393088553e-06,
      "loss": 0.0028,
      "step": 132230
    },
    {
      "epoch": 40.80222153656279,
      "grad_norm": 5.751749085902702e-07,
      "learning_rate": 9.197778463437211e-06,
      "loss": 0.0,
      "step": 132240
    },
    {
      "epoch": 40.805307004011105,
      "grad_norm": 8.403640450183048e-09,
      "learning_rate": 9.194692995988894e-06,
      "loss": 0.0002,
      "step": 132250
    },
    {
      "epoch": 40.80839247145943,
      "grad_norm": 1.229015023085367e-08,
      "learning_rate": 9.191607528540574e-06,
      "loss": 0.0,
      "step": 132260
    },
    {
      "epoch": 40.81147793890774,
      "grad_norm": 1.4485628980764886e-06,
      "learning_rate": 9.188522061092255e-06,
      "loss": 0.0,
      "step": 132270
    },
    {
      "epoch": 40.814563406356065,
      "grad_norm": 9.434471053282323e-07,
      "learning_rate": 9.185436593643938e-06,
      "loss": 0.0006,
      "step": 132280
    },
    {
      "epoch": 40.81764887380438,
      "grad_norm": 0.005583796184509993,
      "learning_rate": 9.18235112619562e-06,
      "loss": 0.0,
      "step": 132290
    },
    {
      "epoch": 40.8207343412527,
      "grad_norm": 0.00019769632490351796,
      "learning_rate": 9.1792656587473e-06,
      "loss": 0.0,
      "step": 132300
    },
    {
      "epoch": 40.82381980870102,
      "grad_norm": 1.6274008203254198e-06,
      "learning_rate": 9.176180191298982e-06,
      "loss": 0.0,
      "step": 132310
    },
    {
      "epoch": 40.82690527614934,
      "grad_norm": 7.689030212532089e-07,
      "learning_rate": 9.173094723850664e-06,
      "loss": 0.0,
      "step": 132320
    },
    {
      "epoch": 40.829990743597655,
      "grad_norm": 1.9156870223469014e-07,
      "learning_rate": 9.170009256402345e-06,
      "loss": 0.0,
      "step": 132330
    },
    {
      "epoch": 40.83307621104597,
      "grad_norm": 7.123858836166619e-08,
      "learning_rate": 9.166923788954027e-06,
      "loss": 0.0001,
      "step": 132340
    },
    {
      "epoch": 40.83616167849429,
      "grad_norm": 0.34309521317481995,
      "learning_rate": 9.16383832150571e-06,
      "loss": 0.0019,
      "step": 132350
    },
    {
      "epoch": 40.83924714594261,
      "grad_norm": 2.6737652660813183e-05,
      "learning_rate": 9.16075285405739e-06,
      "loss": 0.0,
      "step": 132360
    },
    {
      "epoch": 40.84233261339093,
      "grad_norm": 4.4495781281739255e-08,
      "learning_rate": 9.157667386609071e-06,
      "loss": 0.0,
      "step": 132370
    },
    {
      "epoch": 40.845418080839245,
      "grad_norm": 2.2551114398083882e-06,
      "learning_rate": 9.154581919160752e-06,
      "loss": 0.0,
      "step": 132380
    },
    {
      "epoch": 40.84850354828757,
      "grad_norm": 2.3510430935402837e-08,
      "learning_rate": 9.151496451712435e-06,
      "loss": 0.0,
      "step": 132390
    },
    {
      "epoch": 40.85158901573588,
      "grad_norm": 3.920854396710638e-06,
      "learning_rate": 9.148410984264117e-06,
      "loss": 0.0,
      "step": 132400
    },
    {
      "epoch": 40.854674483184205,
      "grad_norm": 9.618006879463792e-05,
      "learning_rate": 9.145325516815798e-06,
      "loss": 0.0,
      "step": 132410
    },
    {
      "epoch": 40.85775995063252,
      "grad_norm": 0.003309675958007574,
      "learning_rate": 9.14224004936748e-06,
      "loss": 0.0,
      "step": 132420
    },
    {
      "epoch": 40.86084541808084,
      "grad_norm": 5.2317598601803184e-05,
      "learning_rate": 9.139154581919161e-06,
      "loss": 0.0,
      "step": 132430
    },
    {
      "epoch": 40.86393088552916,
      "grad_norm": 1.8481250663171522e-06,
      "learning_rate": 9.136069114470842e-06,
      "loss": 0.0005,
      "step": 132440
    },
    {
      "epoch": 40.86701635297747,
      "grad_norm": 4.443125192210573e-07,
      "learning_rate": 9.132983647022524e-06,
      "loss": 0.0001,
      "step": 132450
    },
    {
      "epoch": 40.870101820425795,
      "grad_norm": 6.856746637140532e-08,
      "learning_rate": 9.129898179574207e-06,
      "loss": 0.0,
      "step": 132460
    },
    {
      "epoch": 40.87318728787411,
      "grad_norm": 1.3718788238747948e-07,
      "learning_rate": 9.126812712125888e-06,
      "loss": 0.0,
      "step": 132470
    },
    {
      "epoch": 40.87627275532243,
      "grad_norm": 4.300221462472109e-06,
      "learning_rate": 9.123727244677568e-06,
      "loss": 0.0004,
      "step": 132480
    },
    {
      "epoch": 40.87935822277075,
      "grad_norm": 3.7293347077138606e-07,
      "learning_rate": 9.120641777229251e-06,
      "loss": 0.0,
      "step": 132490
    },
    {
      "epoch": 40.88244369021907,
      "grad_norm": 4.588298543239944e-05,
      "learning_rate": 9.117556309780932e-06,
      "loss": 0.0,
      "step": 132500
    },
    {
      "epoch": 40.885529157667385,
      "grad_norm": 1.1379308700561523,
      "learning_rate": 9.114470842332613e-06,
      "loss": 0.0004,
      "step": 132510
    },
    {
      "epoch": 40.88861462511571,
      "grad_norm": 2.978396651087678e-06,
      "learning_rate": 9.111385374884297e-06,
      "loss": 0.0,
      "step": 132520
    },
    {
      "epoch": 40.89170009256402,
      "grad_norm": 2.7003794755842137e-08,
      "learning_rate": 9.108299907435977e-06,
      "loss": 0.0,
      "step": 132530
    },
    {
      "epoch": 40.894785560012345,
      "grad_norm": 2.170931111322716e-06,
      "learning_rate": 9.105214439987658e-06,
      "loss": 0.0,
      "step": 132540
    },
    {
      "epoch": 40.89787102746066,
      "grad_norm": 4.466689684790026e-09,
      "learning_rate": 9.10212897253934e-06,
      "loss": 0.0,
      "step": 132550
    },
    {
      "epoch": 40.90095649490898,
      "grad_norm": 4.8498895921511576e-05,
      "learning_rate": 9.099043505091022e-06,
      "loss": 0.0,
      "step": 132560
    },
    {
      "epoch": 40.9040419623573,
      "grad_norm": 0.00021360142272897065,
      "learning_rate": 9.095958037642702e-06,
      "loss": 0.0,
      "step": 132570
    },
    {
      "epoch": 40.90712742980561,
      "grad_norm": 0.0001091932354029268,
      "learning_rate": 9.092872570194385e-06,
      "loss": 0.0,
      "step": 132580
    },
    {
      "epoch": 40.910212897253935,
      "grad_norm": 2.7622723552944706e-10,
      "learning_rate": 9.089787102746067e-06,
      "loss": 0.0,
      "step": 132590
    },
    {
      "epoch": 40.91329836470225,
      "grad_norm": 0.03856264427304268,
      "learning_rate": 9.086701635297748e-06,
      "loss": 0.0001,
      "step": 132600
    },
    {
      "epoch": 40.91638383215057,
      "grad_norm": 3.7052842571938527e-07,
      "learning_rate": 9.083616167849429e-06,
      "loss": 0.0,
      "step": 132610
    },
    {
      "epoch": 40.91946929959889,
      "grad_norm": 9.293540301769099e-07,
      "learning_rate": 9.080530700401111e-06,
      "loss": 0.0,
      "step": 132620
    },
    {
      "epoch": 40.92255476704721,
      "grad_norm": 1.3771741578239016e-06,
      "learning_rate": 9.077445232952792e-06,
      "loss": 0.0,
      "step": 132630
    },
    {
      "epoch": 40.925640234495525,
      "grad_norm": 1.001134114630986e-05,
      "learning_rate": 9.074359765504475e-06,
      "loss": 0.0,
      "step": 132640
    },
    {
      "epoch": 40.92872570194385,
      "grad_norm": 7.264362011483172e-06,
      "learning_rate": 9.071274298056157e-06,
      "loss": 0.0019,
      "step": 132650
    },
    {
      "epoch": 40.93181116939216,
      "grad_norm": 0.00011534599616425112,
      "learning_rate": 9.068188830607838e-06,
      "loss": 0.0,
      "step": 132660
    },
    {
      "epoch": 40.934896636840485,
      "grad_norm": 0.000235231316764839,
      "learning_rate": 9.065103363159519e-06,
      "loss": 0.0,
      "step": 132670
    },
    {
      "epoch": 40.9379821042888,
      "grad_norm": 7.108548743417487e-05,
      "learning_rate": 9.0620178957112e-06,
      "loss": 0.0018,
      "step": 132680
    },
    {
      "epoch": 40.941067571737115,
      "grad_norm": 2.4351078536710702e-05,
      "learning_rate": 9.058932428262882e-06,
      "loss": 0.0,
      "step": 132690
    },
    {
      "epoch": 40.94415303918544,
      "grad_norm": 1.0364737136114854e-05,
      "learning_rate": 9.055846960814564e-06,
      "loss": 0.0,
      "step": 132700
    },
    {
      "epoch": 40.94723850663375,
      "grad_norm": 4.03247391034256e-08,
      "learning_rate": 9.052761493366245e-06,
      "loss": 0.0,
      "step": 132710
    },
    {
      "epoch": 40.950323974082075,
      "grad_norm": 3.4741617582767503e-06,
      "learning_rate": 9.049676025917928e-06,
      "loss": 0.0,
      "step": 132720
    },
    {
      "epoch": 40.95340944153039,
      "grad_norm": 8.38321284390986e-07,
      "learning_rate": 9.046590558469608e-06,
      "loss": 0.0,
      "step": 132730
    },
    {
      "epoch": 40.95649490897871,
      "grad_norm": 2.24525001613074e-06,
      "learning_rate": 9.04350509102129e-06,
      "loss": 0.0,
      "step": 132740
    },
    {
      "epoch": 40.95958037642703,
      "grad_norm": 6.334577733468905e-07,
      "learning_rate": 9.040419623572972e-06,
      "loss": 0.0,
      "step": 132750
    },
    {
      "epoch": 40.96266584387535,
      "grad_norm": 6.224750904948451e-06,
      "learning_rate": 9.037334156124654e-06,
      "loss": 0.0,
      "step": 132760
    },
    {
      "epoch": 40.965751311323665,
      "grad_norm": 2.0908082376536186e-08,
      "learning_rate": 9.034248688676335e-06,
      "loss": 0.0,
      "step": 132770
    },
    {
      "epoch": 40.96883677877199,
      "grad_norm": 3.65729846407703e-07,
      "learning_rate": 9.031163221228016e-06,
      "loss": 0.0,
      "step": 132780
    },
    {
      "epoch": 40.9719222462203,
      "grad_norm": 1.5908925661278772e-06,
      "learning_rate": 9.028077753779698e-06,
      "loss": 0.0,
      "step": 132790
    },
    {
      "epoch": 40.97500771366862,
      "grad_norm": 4.968297844243352e-07,
      "learning_rate": 9.024992286331379e-06,
      "loss": 0.0,
      "step": 132800
    },
    {
      "epoch": 40.97809318111694,
      "grad_norm": 7.579346572583745e-08,
      "learning_rate": 9.021906818883061e-06,
      "loss": 0.0,
      "step": 132810
    },
    {
      "epoch": 40.981178648565255,
      "grad_norm": 1.3246678918221733e-06,
      "learning_rate": 9.018821351434744e-06,
      "loss": 0.0,
      "step": 132820
    },
    {
      "epoch": 40.98426411601358,
      "grad_norm": 1.1399673667256138e-06,
      "learning_rate": 9.015735883986425e-06,
      "loss": 0.0,
      "step": 132830
    },
    {
      "epoch": 40.98734958346189,
      "grad_norm": 1.2362684174149763e-06,
      "learning_rate": 9.012650416538105e-06,
      "loss": 0.0,
      "step": 132840
    },
    {
      "epoch": 40.990435050910214,
      "grad_norm": 0.0044707502238452435,
      "learning_rate": 9.009564949089788e-06,
      "loss": 0.0,
      "step": 132850
    },
    {
      "epoch": 40.99352051835853,
      "grad_norm": 3.149806798319332e-05,
      "learning_rate": 9.006479481641469e-06,
      "loss": 0.0004,
      "step": 132860
    },
    {
      "epoch": 40.99660598580685,
      "grad_norm": 4.462208025302061e-08,
      "learning_rate": 9.003394014193151e-06,
      "loss": 0.0,
      "step": 132870
    },
    {
      "epoch": 40.99969145325517,
      "grad_norm": 3.1461784146813443e-06,
      "learning_rate": 9.000308546744832e-06,
      "loss": 0.0,
      "step": 132880
    },
    {
      "epoch": 41.0,
      "eval_accuracy_branch1": 0.9999807104346904,
      "eval_accuracy_branch2": 0.42560496899202377,
      "eval_f1_branch1": 0.9999765706343158,
      "eval_f1_branch2": 0.42128120122456736,
      "eval_loss": 2.842180265361094e-06,
      "eval_precision_branch1": 0.999969025863404,
      "eval_precision_branch2": 0.5134085880751175,
      "eval_recall_branch1": 0.9999841220695295,
      "eval_recall_branch2": 0.5112192934232227,
      "eval_runtime": 232.6745,
      "eval_samples_per_second": 445.614,
      "eval_steps_per_second": 55.704,
      "step": 132881
    },
    {
      "epoch": 41.00277692070349,
      "grad_norm": 4.549798177322373e-06,
      "learning_rate": 8.997223079296514e-06,
      "loss": 0.0,
      "step": 132890
    },
    {
      "epoch": 41.005862388151805,
      "grad_norm": 2.603619395813439e-05,
      "learning_rate": 8.994137611848195e-06,
      "loss": 0.0,
      "step": 132900
    },
    {
      "epoch": 41.00894785560013,
      "grad_norm": 3.903128344973084e-06,
      "learning_rate": 8.991052144399876e-06,
      "loss": 0.0,
      "step": 132910
    },
    {
      "epoch": 41.01203332304844,
      "grad_norm": 2.244925845218404e-08,
      "learning_rate": 8.987966676951559e-06,
      "loss": 0.0,
      "step": 132920
    },
    {
      "epoch": 41.01511879049676,
      "grad_norm": 1.7883187410916435e-06,
      "learning_rate": 8.984881209503241e-06,
      "loss": 0.0,
      "step": 132930
    },
    {
      "epoch": 41.01820425794508,
      "grad_norm": 0.00013973336899653077,
      "learning_rate": 8.981795742054922e-06,
      "loss": 0.0,
      "step": 132940
    },
    {
      "epoch": 41.021289725393395,
      "grad_norm": 7.580574106214044e-07,
      "learning_rate": 8.978710274606604e-06,
      "loss": 0.0,
      "step": 132950
    },
    {
      "epoch": 41.02437519284172,
      "grad_norm": 2.707435669435654e-06,
      "learning_rate": 8.975624807158285e-06,
      "loss": 0.0,
      "step": 132960
    },
    {
      "epoch": 41.02746066029003,
      "grad_norm": 9.995133041229565e-06,
      "learning_rate": 8.972539339709966e-06,
      "loss": 0.0,
      "step": 132970
    },
    {
      "epoch": 41.030546127738354,
      "grad_norm": 6.791892519686371e-05,
      "learning_rate": 8.969453872261648e-06,
      "loss": 0.0,
      "step": 132980
    },
    {
      "epoch": 41.03363159518667,
      "grad_norm": 1.1247650945733767e-05,
      "learning_rate": 8.96636840481333e-06,
      "loss": 0.0,
      "step": 132990
    },
    {
      "epoch": 41.03671706263499,
      "grad_norm": 2.864584166673012e-05,
      "learning_rate": 8.963282937365012e-06,
      "loss": 0.0,
      "step": 133000
    },
    {
      "epoch": 41.03980253008331,
      "grad_norm": 6.457306881202385e-05,
      "learning_rate": 8.960197469916692e-06,
      "loss": 0.0,
      "step": 133010
    },
    {
      "epoch": 41.04288799753163,
      "grad_norm": 0.00016613022307865322,
      "learning_rate": 8.957112002468375e-06,
      "loss": 0.0,
      "step": 133020
    },
    {
      "epoch": 41.045973464979944,
      "grad_norm": 1.1836787052743603e-05,
      "learning_rate": 8.954026535020056e-06,
      "loss": 0.0,
      "step": 133030
    },
    {
      "epoch": 41.04905893242826,
      "grad_norm": 1.4604566786147188e-05,
      "learning_rate": 8.950941067571738e-06,
      "loss": 0.0,
      "step": 133040
    },
    {
      "epoch": 41.05214439987658,
      "grad_norm": 3.985595412814291e-06,
      "learning_rate": 8.947855600123419e-06,
      "loss": 0.0,
      "step": 133050
    },
    {
      "epoch": 41.0552298673249,
      "grad_norm": 7.093659223755822e-05,
      "learning_rate": 8.944770132675101e-06,
      "loss": 0.0,
      "step": 133060
    },
    {
      "epoch": 41.05831533477322,
      "grad_norm": 0.022540543228387833,
      "learning_rate": 8.941684665226782e-06,
      "loss": 0.0002,
      "step": 133070
    },
    {
      "epoch": 41.061400802221534,
      "grad_norm": 1.7111337911046576e-06,
      "learning_rate": 8.938599197778463e-06,
      "loss": 0.0,
      "step": 133080
    },
    {
      "epoch": 41.06448626966986,
      "grad_norm": 0.00119977502617985,
      "learning_rate": 8.935513730330145e-06,
      "loss": 0.0,
      "step": 133090
    },
    {
      "epoch": 41.06757173711817,
      "grad_norm": 2.2693095161230303e-05,
      "learning_rate": 8.932428262881828e-06,
      "loss": 0.0,
      "step": 133100
    },
    {
      "epoch": 41.070657204566494,
      "grad_norm": 0.07174442708492279,
      "learning_rate": 8.929342795433509e-06,
      "loss": 0.0002,
      "step": 133110
    },
    {
      "epoch": 41.07374267201481,
      "grad_norm": 1.2985125863451685e-08,
      "learning_rate": 8.926257327985191e-06,
      "loss": 0.0035,
      "step": 133120
    },
    {
      "epoch": 41.07682813946313,
      "grad_norm": 1.3664056268680724e-06,
      "learning_rate": 8.923171860536872e-06,
      "loss": 0.0,
      "step": 133130
    },
    {
      "epoch": 41.07991360691145,
      "grad_norm": 5.224168653228389e-09,
      "learning_rate": 8.920086393088553e-06,
      "loss": 0.0,
      "step": 133140
    },
    {
      "epoch": 41.08299907435976,
      "grad_norm": 0.0005073201609775424,
      "learning_rate": 8.917000925640233e-06,
      "loss": 0.0,
      "step": 133150
    },
    {
      "epoch": 41.086084541808084,
      "grad_norm": 9.460338645794764e-08,
      "learning_rate": 8.913915458191918e-06,
      "loss": 0.0,
      "step": 133160
    },
    {
      "epoch": 41.0891700092564,
      "grad_norm": 3.7682657421100885e-06,
      "learning_rate": 8.910829990743598e-06,
      "loss": 0.0,
      "step": 133170
    },
    {
      "epoch": 41.09225547670472,
      "grad_norm": 4.4939614696204444e-08,
      "learning_rate": 8.90774452329528e-06,
      "loss": 0.0,
      "step": 133180
    },
    {
      "epoch": 41.09534094415304,
      "grad_norm": 5.9896551647398155e-06,
      "learning_rate": 8.904659055846962e-06,
      "loss": 0.0,
      "step": 133190
    },
    {
      "epoch": 41.09842641160136,
      "grad_norm": 0.00031695837969891727,
      "learning_rate": 8.901573588398642e-06,
      "loss": 0.0,
      "step": 133200
    },
    {
      "epoch": 41.101511879049674,
      "grad_norm": 0.0038305451162159443,
      "learning_rate": 8.898488120950323e-06,
      "loss": 0.0,
      "step": 133210
    },
    {
      "epoch": 41.104597346498,
      "grad_norm": 4.495992982356256e-07,
      "learning_rate": 8.895402653502007e-06,
      "loss": 0.0,
      "step": 133220
    },
    {
      "epoch": 41.10768281394631,
      "grad_norm": 0.0009381271665915847,
      "learning_rate": 8.892317186053688e-06,
      "loss": 0.0,
      "step": 133230
    },
    {
      "epoch": 41.110768281394634,
      "grad_norm": 4.7897461627144367e-05,
      "learning_rate": 8.889231718605369e-06,
      "loss": 0.0,
      "step": 133240
    },
    {
      "epoch": 41.11385374884295,
      "grad_norm": 6.261082489800174e-06,
      "learning_rate": 8.88614625115705e-06,
      "loss": 0.0,
      "step": 133250
    },
    {
      "epoch": 41.11693921629127,
      "grad_norm": 3.465676172709209e-07,
      "learning_rate": 8.883060783708732e-06,
      "loss": 0.0,
      "step": 133260
    },
    {
      "epoch": 41.12002468373959,
      "grad_norm": 3.2663242564012762e-06,
      "learning_rate": 8.879975316260413e-06,
      "loss": 0.0,
      "step": 133270
    },
    {
      "epoch": 41.1231101511879,
      "grad_norm": 7.288255119419773e-07,
      "learning_rate": 8.876889848812095e-06,
      "loss": 0.0,
      "step": 133280
    },
    {
      "epoch": 41.126195618636224,
      "grad_norm": 7.920247568904415e-09,
      "learning_rate": 8.873804381363778e-06,
      "loss": 0.0,
      "step": 133290
    },
    {
      "epoch": 41.12928108608454,
      "grad_norm": 4.2618643192327e-07,
      "learning_rate": 8.870718913915459e-06,
      "loss": 0.0,
      "step": 133300
    },
    {
      "epoch": 41.13236655353286,
      "grad_norm": 1.948362751136301e-06,
      "learning_rate": 8.86763344646714e-06,
      "loss": 0.0,
      "step": 133310
    },
    {
      "epoch": 41.13545202098118,
      "grad_norm": 2.651695695021772e-06,
      "learning_rate": 8.864547979018822e-06,
      "loss": 0.0,
      "step": 133320
    },
    {
      "epoch": 41.1385374884295,
      "grad_norm": 0.04821828007698059,
      "learning_rate": 8.861462511570503e-06,
      "loss": 0.0,
      "step": 133330
    },
    {
      "epoch": 41.141622955877814,
      "grad_norm": 2.19051088379274e-09,
      "learning_rate": 8.858377044122185e-06,
      "loss": 0.0,
      "step": 133340
    },
    {
      "epoch": 41.144708423326136,
      "grad_norm": 1.378243905492127e-05,
      "learning_rate": 8.855291576673866e-06,
      "loss": 0.0,
      "step": 133350
    },
    {
      "epoch": 41.14779389077445,
      "grad_norm": 2.011279866565019e-05,
      "learning_rate": 8.852206109225549e-06,
      "loss": 0.0,
      "step": 133360
    },
    {
      "epoch": 41.150879358222774,
      "grad_norm": 6.0472234508779366e-06,
      "learning_rate": 8.84912064177723e-06,
      "loss": 0.0,
      "step": 133370
    },
    {
      "epoch": 41.15396482567109,
      "grad_norm": 5.803998703868274e-08,
      "learning_rate": 8.84603517432891e-06,
      "loss": 0.0,
      "step": 133380
    },
    {
      "epoch": 41.157050293119404,
      "grad_norm": 0.001046581193804741,
      "learning_rate": 8.842949706880593e-06,
      "loss": 0.0,
      "step": 133390
    },
    {
      "epoch": 41.16013576056773,
      "grad_norm": 0.0002706411760300398,
      "learning_rate": 8.839864239432275e-06,
      "loss": 0.0,
      "step": 133400
    },
    {
      "epoch": 41.16322122801604,
      "grad_norm": 1.089085458261252e-06,
      "learning_rate": 8.836778771983956e-06,
      "loss": 0.0,
      "step": 133410
    },
    {
      "epoch": 41.166306695464364,
      "grad_norm": 2.3930988390929997e-06,
      "learning_rate": 8.833693304535638e-06,
      "loss": 0.0,
      "step": 133420
    },
    {
      "epoch": 41.16939216291268,
      "grad_norm": 1.38259366622151e-07,
      "learning_rate": 8.830607837087319e-06,
      "loss": 0.0029,
      "step": 133430
    },
    {
      "epoch": 41.172477630361,
      "grad_norm": 5.6468653752972386e-08,
      "learning_rate": 8.827522369639e-06,
      "loss": 0.0,
      "step": 133440
    },
    {
      "epoch": 41.17556309780932,
      "grad_norm": 0.00022027136583346874,
      "learning_rate": 8.824436902190682e-06,
      "loss": 0.0,
      "step": 133450
    },
    {
      "epoch": 41.17864856525764,
      "grad_norm": 2.3259313820744865e-05,
      "learning_rate": 8.821351434742365e-06,
      "loss": 0.0,
      "step": 133460
    },
    {
      "epoch": 41.181734032705954,
      "grad_norm": 7.424745263051591e-07,
      "learning_rate": 8.818265967294046e-06,
      "loss": 0.0,
      "step": 133470
    },
    {
      "epoch": 41.184819500154276,
      "grad_norm": 3.380761270932453e-08,
      "learning_rate": 8.815180499845726e-06,
      "loss": 0.003,
      "step": 133480
    },
    {
      "epoch": 41.18790496760259,
      "grad_norm": 2.7517973677504415e-08,
      "learning_rate": 8.812095032397409e-06,
      "loss": 0.0,
      "step": 133490
    },
    {
      "epoch": 41.190990435050914,
      "grad_norm": 1.856502862551679e-08,
      "learning_rate": 8.80900956494909e-06,
      "loss": 0.0001,
      "step": 133500
    },
    {
      "epoch": 41.19407590249923,
      "grad_norm": 5.062253762844193e-07,
      "learning_rate": 8.805924097500772e-06,
      "loss": 0.0,
      "step": 133510
    },
    {
      "epoch": 41.197161369947544,
      "grad_norm": 1.8508929997551604e-06,
      "learning_rate": 8.802838630052455e-06,
      "loss": 0.0,
      "step": 133520
    },
    {
      "epoch": 41.200246837395866,
      "grad_norm": 2.3415864802700526e-07,
      "learning_rate": 8.799753162604135e-06,
      "loss": 0.0,
      "step": 133530
    },
    {
      "epoch": 41.20333230484418,
      "grad_norm": 1.3558767442134467e-09,
      "learning_rate": 8.796667695155816e-06,
      "loss": 0.0,
      "step": 133540
    },
    {
      "epoch": 41.206417772292504,
      "grad_norm": 8.601976333011407e-06,
      "learning_rate": 8.793582227707497e-06,
      "loss": 0.0,
      "step": 133550
    },
    {
      "epoch": 41.20950323974082,
      "grad_norm": 0.0005493065691553056,
      "learning_rate": 8.79049676025918e-06,
      "loss": 0.0,
      "step": 133560
    },
    {
      "epoch": 41.21258870718914,
      "grad_norm": 1.687931785454566e-07,
      "learning_rate": 8.787411292810862e-06,
      "loss": 0.0,
      "step": 133570
    },
    {
      "epoch": 41.215674174637456,
      "grad_norm": 2.5063590669560654e-07,
      "learning_rate": 8.784325825362543e-06,
      "loss": 0.0,
      "step": 133580
    },
    {
      "epoch": 41.21875964208578,
      "grad_norm": 0.013154531829059124,
      "learning_rate": 8.781240357914225e-06,
      "loss": 0.0,
      "step": 133590
    },
    {
      "epoch": 41.221845109534094,
      "grad_norm": 9.479892923991429e-07,
      "learning_rate": 8.778154890465906e-06,
      "loss": 0.0,
      "step": 133600
    },
    {
      "epoch": 41.224930576982416,
      "grad_norm": 1.345925852547225e-06,
      "learning_rate": 8.775069423017587e-06,
      "loss": 0.0,
      "step": 133610
    },
    {
      "epoch": 41.22801604443073,
      "grad_norm": 1.2510759916040115e-05,
      "learning_rate": 8.77198395556927e-06,
      "loss": 0.0,
      "step": 133620
    },
    {
      "epoch": 41.23110151187905,
      "grad_norm": 6.480755928350845e-06,
      "learning_rate": 8.768898488120952e-06,
      "loss": 0.0,
      "step": 133630
    },
    {
      "epoch": 41.23418697932737,
      "grad_norm": 2.7039975520892767e-06,
      "learning_rate": 8.765813020672632e-06,
      "loss": 0.0,
      "step": 133640
    },
    {
      "epoch": 41.237272446775684,
      "grad_norm": 2.460517833924314e-08,
      "learning_rate": 8.762727553224313e-06,
      "loss": 0.0,
      "step": 133650
    },
    {
      "epoch": 41.240357914224006,
      "grad_norm": 0.00013821572065353394,
      "learning_rate": 8.759642085775996e-06,
      "loss": 0.0,
      "step": 133660
    },
    {
      "epoch": 41.24344338167232,
      "grad_norm": 2.467292290475598e-07,
      "learning_rate": 8.756556618327677e-06,
      "loss": 0.0008,
      "step": 133670
    },
    {
      "epoch": 41.246528849120644,
      "grad_norm": 2.0119884993619053e-06,
      "learning_rate": 8.753471150879359e-06,
      "loss": 0.0,
      "step": 133680
    },
    {
      "epoch": 41.24961431656896,
      "grad_norm": 9.132319974014536e-06,
      "learning_rate": 8.750385683431041e-06,
      "loss": 0.0,
      "step": 133690
    },
    {
      "epoch": 41.25269978401728,
      "grad_norm": 6.2736749129044256e-09,
      "learning_rate": 8.747300215982722e-06,
      "loss": 0.0,
      "step": 133700
    },
    {
      "epoch": 41.255785251465596,
      "grad_norm": 2.3394242987251346e-07,
      "learning_rate": 8.744214748534403e-06,
      "loss": 0.0,
      "step": 133710
    },
    {
      "epoch": 41.25887071891392,
      "grad_norm": 3.5229692940674795e-08,
      "learning_rate": 8.741129281086086e-06,
      "loss": 0.0,
      "step": 133720
    },
    {
      "epoch": 41.261956186362234,
      "grad_norm": 0.005830273497849703,
      "learning_rate": 8.738043813637766e-06,
      "loss": 0.0,
      "step": 133730
    },
    {
      "epoch": 41.26504165381055,
      "grad_norm": 7.234700660774251e-08,
      "learning_rate": 8.734958346189449e-06,
      "loss": 0.0,
      "step": 133740
    },
    {
      "epoch": 41.26812712125887,
      "grad_norm": 5.777743616874886e-09,
      "learning_rate": 8.73187287874113e-06,
      "loss": 0.0,
      "step": 133750
    },
    {
      "epoch": 41.271212588707186,
      "grad_norm": 1.6949512655628496e-06,
      "learning_rate": 8.728787411292812e-06,
      "loss": 0.0,
      "step": 133760
    },
    {
      "epoch": 41.27429805615551,
      "grad_norm": 7.596149771416094e-07,
      "learning_rate": 8.725701943844493e-06,
      "loss": 0.0,
      "step": 133770
    },
    {
      "epoch": 41.277383523603824,
      "grad_norm": 8.943080942458437e-09,
      "learning_rate": 8.722616476396174e-06,
      "loss": 0.0,
      "step": 133780
    },
    {
      "epoch": 41.280468991052146,
      "grad_norm": 5.947105819359422e-06,
      "learning_rate": 8.719531008947856e-06,
      "loss": 0.0005,
      "step": 133790
    },
    {
      "epoch": 41.28355445850046,
      "grad_norm": 4.5686971134273335e-05,
      "learning_rate": 8.716445541499539e-06,
      "loss": 0.0,
      "step": 133800
    },
    {
      "epoch": 41.28663992594878,
      "grad_norm": 7.637165253981948e-06,
      "learning_rate": 8.71336007405122e-06,
      "loss": 0.0,
      "step": 133810
    },
    {
      "epoch": 41.2897253933971,
      "grad_norm": 0.16822834312915802,
      "learning_rate": 8.7102746066029e-06,
      "loss": 0.0,
      "step": 133820
    },
    {
      "epoch": 41.29281086084542,
      "grad_norm": 1.811974016163731e-06,
      "learning_rate": 8.707189139154583e-06,
      "loss": 0.0,
      "step": 133830
    },
    {
      "epoch": 41.295896328293736,
      "grad_norm": 3.6207376297170413e-07,
      "learning_rate": 8.704103671706263e-06,
      "loss": 0.0,
      "step": 133840
    },
    {
      "epoch": 41.29898179574206,
      "grad_norm": 8.264978532679379e-07,
      "learning_rate": 8.701018204257944e-06,
      "loss": 0.0,
      "step": 133850
    },
    {
      "epoch": 41.302067263190374,
      "grad_norm": 3.824762586646102e-07,
      "learning_rate": 8.697932736809628e-06,
      "loss": 0.0,
      "step": 133860
    },
    {
      "epoch": 41.30515273063869,
      "grad_norm": 1.8553371319285361e-06,
      "learning_rate": 8.694847269361309e-06,
      "loss": 0.0,
      "step": 133870
    },
    {
      "epoch": 41.30823819808701,
      "grad_norm": 4.4059474021196365e-05,
      "learning_rate": 8.69176180191299e-06,
      "loss": 0.0001,
      "step": 133880
    },
    {
      "epoch": 41.311323665535326,
      "grad_norm": 2.0764991859323345e-06,
      "learning_rate": 8.688676334464672e-06,
      "loss": 0.0,
      "step": 133890
    },
    {
      "epoch": 41.31440913298365,
      "grad_norm": 3.447055973992974e-08,
      "learning_rate": 8.685590867016353e-06,
      "loss": 0.0007,
      "step": 133900
    },
    {
      "epoch": 41.317494600431964,
      "grad_norm": 5.306428629836546e-09,
      "learning_rate": 8.682505399568034e-06,
      "loss": 0.0,
      "step": 133910
    },
    {
      "epoch": 41.320580067880286,
      "grad_norm": 1.3811809473907033e-08,
      "learning_rate": 8.679419932119716e-06,
      "loss": 0.0,
      "step": 133920
    },
    {
      "epoch": 41.3236655353286,
      "grad_norm": 1.2961230595465167e-06,
      "learning_rate": 8.676334464671399e-06,
      "loss": 0.0001,
      "step": 133930
    },
    {
      "epoch": 41.32675100277692,
      "grad_norm": 3.9244213212441537e-08,
      "learning_rate": 8.67324899722308e-06,
      "loss": 0.0,
      "step": 133940
    },
    {
      "epoch": 41.32983647022524,
      "grad_norm": 4.3008975580960396e-07,
      "learning_rate": 8.67016352977476e-06,
      "loss": 0.0,
      "step": 133950
    },
    {
      "epoch": 41.33292193767356,
      "grad_norm": 0.0003981426707468927,
      "learning_rate": 8.667078062326443e-06,
      "loss": 0.0,
      "step": 133960
    },
    {
      "epoch": 41.336007405121876,
      "grad_norm": 6.811209818380348e-09,
      "learning_rate": 8.663992594878124e-06,
      "loss": 0.0,
      "step": 133970
    },
    {
      "epoch": 41.33909287257019,
      "grad_norm": 5.312072630658804e-07,
      "learning_rate": 8.660907127429806e-06,
      "loss": 0.0,
      "step": 133980
    },
    {
      "epoch": 41.34217834001851,
      "grad_norm": 0.0006464255275204778,
      "learning_rate": 8.657821659981489e-06,
      "loss": 0.0,
      "step": 133990
    },
    {
      "epoch": 41.34526380746683,
      "grad_norm": 5.886848271074996e-07,
      "learning_rate": 8.65473619253317e-06,
      "loss": 0.0,
      "step": 134000
    },
    {
      "epoch": 41.34834927491515,
      "grad_norm": 9.623771113353996e-09,
      "learning_rate": 8.65165072508485e-06,
      "loss": 0.0001,
      "step": 134010
    },
    {
      "epoch": 41.351434742363466,
      "grad_norm": 1.561639066949283e-07,
      "learning_rate": 8.648565257636531e-06,
      "loss": 0.0,
      "step": 134020
    },
    {
      "epoch": 41.35452020981179,
      "grad_norm": 0.002761914161965251,
      "learning_rate": 8.645479790188213e-06,
      "loss": 0.0,
      "step": 134030
    },
    {
      "epoch": 41.3576056772601,
      "grad_norm": 1.9993115074612433e-06,
      "learning_rate": 8.642394322739896e-06,
      "loss": 0.0,
      "step": 134040
    },
    {
      "epoch": 41.360691144708426,
      "grad_norm": 5.001214594813064e-05,
      "learning_rate": 8.639308855291577e-06,
      "loss": 0.0,
      "step": 134050
    },
    {
      "epoch": 41.36377661215674,
      "grad_norm": 0.00026710351812653244,
      "learning_rate": 8.63622338784326e-06,
      "loss": 0.0,
      "step": 134060
    },
    {
      "epoch": 41.36686207960506,
      "grad_norm": 2.3695976381077344e-07,
      "learning_rate": 8.63313792039494e-06,
      "loss": 0.0,
      "step": 134070
    },
    {
      "epoch": 41.36994754705338,
      "grad_norm": 1.3448378410885198e-07,
      "learning_rate": 8.63005245294662e-06,
      "loss": 0.0,
      "step": 134080
    },
    {
      "epoch": 41.373033014501694,
      "grad_norm": 2.337658088436001e-06,
      "learning_rate": 8.626966985498303e-06,
      "loss": 0.0,
      "step": 134090
    },
    {
      "epoch": 41.376118481950016,
      "grad_norm": 1.2776696394212195e-06,
      "learning_rate": 8.623881518049986e-06,
      "loss": 0.0,
      "step": 134100
    },
    {
      "epoch": 41.37920394939833,
      "grad_norm": 6.5056383391493e-08,
      "learning_rate": 8.620796050601667e-06,
      "loss": 0.0,
      "step": 134110
    },
    {
      "epoch": 41.38228941684665,
      "grad_norm": 6.240214861463755e-05,
      "learning_rate": 8.617710583153347e-06,
      "loss": 0.0001,
      "step": 134120
    },
    {
      "epoch": 41.38537488429497,
      "grad_norm": 5.981037887181628e-09,
      "learning_rate": 8.61462511570503e-06,
      "loss": 0.0,
      "step": 134130
    },
    {
      "epoch": 41.38846035174329,
      "grad_norm": 0.0002221176982857287,
      "learning_rate": 8.61153964825671e-06,
      "loss": 0.0,
      "step": 134140
    },
    {
      "epoch": 41.391545819191606,
      "grad_norm": 0.0004729383217636496,
      "learning_rate": 8.608454180808393e-06,
      "loss": 0.0,
      "step": 134150
    },
    {
      "epoch": 41.39463128663993,
      "grad_norm": 5.7206388959230026e-08,
      "learning_rate": 8.605368713360076e-06,
      "loss": 0.0,
      "step": 134160
    },
    {
      "epoch": 41.39771675408824,
      "grad_norm": 5.1039947379649675e-08,
      "learning_rate": 8.602283245911756e-06,
      "loss": 0.0,
      "step": 134170
    },
    {
      "epoch": 41.400802221536566,
      "grad_norm": 4.2902817654066894e-07,
      "learning_rate": 8.599197778463437e-06,
      "loss": 0.0,
      "step": 134180
    },
    {
      "epoch": 41.40388768898488,
      "grad_norm": 4.455389728263981e-07,
      "learning_rate": 8.59611231101512e-06,
      "loss": 0.0,
      "step": 134190
    },
    {
      "epoch": 41.4069731564332,
      "grad_norm": 1.8077737422572682e-06,
      "learning_rate": 8.5930268435668e-06,
      "loss": 0.0,
      "step": 134200
    },
    {
      "epoch": 41.41005862388152,
      "grad_norm": 0.0006865892792120576,
      "learning_rate": 8.589941376118483e-06,
      "loss": 0.0,
      "step": 134210
    },
    {
      "epoch": 41.41314409132983,
      "grad_norm": 4.942114628647687e-07,
      "learning_rate": 8.586855908670164e-06,
      "loss": 0.0,
      "step": 134220
    },
    {
      "epoch": 41.416229558778156,
      "grad_norm": 5.82210450374987e-05,
      "learning_rate": 8.583770441221846e-06,
      "loss": 0.0,
      "step": 134230
    },
    {
      "epoch": 41.41931502622647,
      "grad_norm": 1.4753817595192231e-05,
      "learning_rate": 8.580684973773527e-06,
      "loss": 0.0,
      "step": 134240
    },
    {
      "epoch": 41.42240049367479,
      "grad_norm": 1.1799912726928596e-06,
      "learning_rate": 8.577599506325208e-06,
      "loss": 0.0,
      "step": 134250
    },
    {
      "epoch": 41.42548596112311,
      "grad_norm": 9.216084890795173e-07,
      "learning_rate": 8.57451403887689e-06,
      "loss": 0.0,
      "step": 134260
    },
    {
      "epoch": 41.42857142857143,
      "grad_norm": 0.00010210153413936496,
      "learning_rate": 8.571428571428573e-06,
      "loss": 0.0,
      "step": 134270
    },
    {
      "epoch": 41.431656896019746,
      "grad_norm": 4.44802481069928e-06,
      "learning_rate": 8.568343103980253e-06,
      "loss": 0.0,
      "step": 134280
    },
    {
      "epoch": 41.43474236346807,
      "grad_norm": 3.928855949197896e-05,
      "learning_rate": 8.565257636531936e-06,
      "loss": 0.0,
      "step": 134290
    },
    {
      "epoch": 41.43782783091638,
      "grad_norm": 0.16979295015335083,
      "learning_rate": 8.562172169083617e-06,
      "loss": 0.0001,
      "step": 134300
    },
    {
      "epoch": 41.440913298364705,
      "grad_norm": 6.179948286444414e-07,
      "learning_rate": 8.559086701635297e-06,
      "loss": 0.0,
      "step": 134310
    },
    {
      "epoch": 41.44399876581302,
      "grad_norm": 1.4575444851061548e-08,
      "learning_rate": 8.55600123418698e-06,
      "loss": 0.0,
      "step": 134320
    },
    {
      "epoch": 41.447084233261336,
      "grad_norm": 4.6330584154929966e-05,
      "learning_rate": 8.552915766738662e-06,
      "loss": 0.0,
      "step": 134330
    },
    {
      "epoch": 41.45016970070966,
      "grad_norm": 3.1197985663311556e-05,
      "learning_rate": 8.549830299290343e-06,
      "loss": 0.0,
      "step": 134340
    },
    {
      "epoch": 41.45325516815797,
      "grad_norm": 2.608407612569863e-06,
      "learning_rate": 8.546744831842024e-06,
      "loss": 0.0009,
      "step": 134350
    },
    {
      "epoch": 41.456340635606296,
      "grad_norm": 5.0357335567241535e-05,
      "learning_rate": 8.543659364393706e-06,
      "loss": 0.0,
      "step": 134360
    },
    {
      "epoch": 41.45942610305461,
      "grad_norm": 2.990717362649775e-08,
      "learning_rate": 8.540573896945387e-06,
      "loss": 0.0,
      "step": 134370
    },
    {
      "epoch": 41.46251157050293,
      "grad_norm": 1.996393393710605e-06,
      "learning_rate": 8.53748842949707e-06,
      "loss": 0.0,
      "step": 134380
    },
    {
      "epoch": 41.46559703795125,
      "grad_norm": 1.0099699210286417e-07,
      "learning_rate": 8.534402962048752e-06,
      "loss": 0.0001,
      "step": 134390
    },
    {
      "epoch": 41.46868250539957,
      "grad_norm": 4.468929759582352e-08,
      "learning_rate": 8.531317494600433e-06,
      "loss": 0.0,
      "step": 134400
    },
    {
      "epoch": 41.471767972847886,
      "grad_norm": 0.0003045274643227458,
      "learning_rate": 8.528232027152114e-06,
      "loss": 0.0,
      "step": 134410
    },
    {
      "epoch": 41.47485344029621,
      "grad_norm": 3.295989969842594e-08,
      "learning_rate": 8.525146559703795e-06,
      "loss": 0.0,
      "step": 134420
    },
    {
      "epoch": 41.47793890774452,
      "grad_norm": 5.627939572150353e-06,
      "learning_rate": 8.522061092255477e-06,
      "loss": 0.0,
      "step": 134430
    },
    {
      "epoch": 41.48102437519284,
      "grad_norm": 4.3305539065841003e-07,
      "learning_rate": 8.51897562480716e-06,
      "loss": 0.0,
      "step": 134440
    },
    {
      "epoch": 41.48410984264116,
      "grad_norm": 4.399709723656997e-05,
      "learning_rate": 8.51589015735884e-06,
      "loss": 0.0,
      "step": 134450
    },
    {
      "epoch": 41.487195310089476,
      "grad_norm": 2.6302146238776913e-07,
      "learning_rate": 8.512804689910523e-06,
      "loss": 0.0,
      "step": 134460
    },
    {
      "epoch": 41.4902807775378,
      "grad_norm": 1.0977601959893946e-05,
      "learning_rate": 8.509719222462204e-06,
      "loss": 0.0002,
      "step": 134470
    },
    {
      "epoch": 41.49336624498611,
      "grad_norm": 5.489156365001691e-07,
      "learning_rate": 8.506633755013884e-06,
      "loss": 0.0,
      "step": 134480
    },
    {
      "epoch": 41.496451712434435,
      "grad_norm": 3.349691723997239e-06,
      "learning_rate": 8.503548287565567e-06,
      "loss": 0.0,
      "step": 134490
    },
    {
      "epoch": 41.49953717988275,
      "grad_norm": 4.365887798485346e-05,
      "learning_rate": 8.50046282011725e-06,
      "loss": 0.0,
      "step": 134500
    },
    {
      "epoch": 41.50262264733107,
      "grad_norm": 1.0837391428708543e-08,
      "learning_rate": 8.49737735266893e-06,
      "loss": 0.0,
      "step": 134510
    },
    {
      "epoch": 41.50570811477939,
      "grad_norm": 5.255407664606082e-09,
      "learning_rate": 8.49429188522061e-06,
      "loss": 0.0,
      "step": 134520
    },
    {
      "epoch": 41.50879358222771,
      "grad_norm": 2.2755594386580924e-07,
      "learning_rate": 8.491206417772293e-06,
      "loss": 0.0,
      "step": 134530
    },
    {
      "epoch": 41.511879049676025,
      "grad_norm": 3.3490769624222594e-07,
      "learning_rate": 8.488120950323974e-06,
      "loss": 0.0,
      "step": 134540
    },
    {
      "epoch": 41.51496451712435,
      "grad_norm": 4.619019122742429e-08,
      "learning_rate": 8.485035482875655e-06,
      "loss": 0.0,
      "step": 134550
    },
    {
      "epoch": 41.51804998457266,
      "grad_norm": 4.993185243051812e-08,
      "learning_rate": 8.481950015427339e-06,
      "loss": 0.0001,
      "step": 134560
    },
    {
      "epoch": 41.52113545202098,
      "grad_norm": 1.6889587186597055e-06,
      "learning_rate": 8.47886454797902e-06,
      "loss": 0.0,
      "step": 134570
    },
    {
      "epoch": 41.5242209194693,
      "grad_norm": 4.870818884228356e-05,
      "learning_rate": 8.4757790805307e-06,
      "loss": 0.0,
      "step": 134580
    },
    {
      "epoch": 41.527306386917616,
      "grad_norm": 1.1785199376390665e-06,
      "learning_rate": 8.472693613082383e-06,
      "loss": 0.0,
      "step": 134590
    },
    {
      "epoch": 41.53039185436594,
      "grad_norm": 2.6826251996681094e-05,
      "learning_rate": 8.469608145634064e-06,
      "loss": 0.0,
      "step": 134600
    },
    {
      "epoch": 41.53347732181425,
      "grad_norm": 0.00031876133289188147,
      "learning_rate": 8.466522678185745e-06,
      "loss": 0.0,
      "step": 134610
    },
    {
      "epoch": 41.536562789262575,
      "grad_norm": 1.128318763221614e-05,
      "learning_rate": 8.463437210737427e-06,
      "loss": 0.0,
      "step": 134620
    },
    {
      "epoch": 41.53964825671089,
      "grad_norm": 0.00032557809026911855,
      "learning_rate": 8.46035174328911e-06,
      "loss": 0.0,
      "step": 134630
    },
    {
      "epoch": 41.54273372415921,
      "grad_norm": 0.00012820298434235156,
      "learning_rate": 8.45726627584079e-06,
      "loss": 0.0,
      "step": 134640
    },
    {
      "epoch": 41.54581919160753,
      "grad_norm": 6.086659709580999e-08,
      "learning_rate": 8.454180808392471e-06,
      "loss": 0.0,
      "step": 134650
    },
    {
      "epoch": 41.54890465905585,
      "grad_norm": 8.400478691328317e-06,
      "learning_rate": 8.451095340944154e-06,
      "loss": 0.0,
      "step": 134660
    },
    {
      "epoch": 41.551990126504165,
      "grad_norm": 3.1742520150146447e-06,
      "learning_rate": 8.448009873495834e-06,
      "loss": 0.0001,
      "step": 134670
    },
    {
      "epoch": 41.55507559395248,
      "grad_norm": 0.000229417608352378,
      "learning_rate": 8.444924406047517e-06,
      "loss": 0.0,
      "step": 134680
    },
    {
      "epoch": 41.5581610614008,
      "grad_norm": 3.1981713277673407e-07,
      "learning_rate": 8.441838938599198e-06,
      "loss": 0.0,
      "step": 134690
    },
    {
      "epoch": 41.56124652884912,
      "grad_norm": 1.3212041238830352e-08,
      "learning_rate": 8.43875347115088e-06,
      "loss": 0.0,
      "step": 134700
    },
    {
      "epoch": 41.56433199629744,
      "grad_norm": 8.892881851352286e-06,
      "learning_rate": 8.435668003702561e-06,
      "loss": 0.0,
      "step": 134710
    },
    {
      "epoch": 41.567417463745755,
      "grad_norm": 7.809813951098477e-07,
      "learning_rate": 8.432582536254242e-06,
      "loss": 0.0,
      "step": 134720
    },
    {
      "epoch": 41.57050293119408,
      "grad_norm": 2.8708879540317866e-07,
      "learning_rate": 8.429497068805924e-06,
      "loss": 0.0,
      "step": 134730
    },
    {
      "epoch": 41.57358839864239,
      "grad_norm": 9.328220585302915e-06,
      "learning_rate": 8.426411601357607e-06,
      "loss": 0.0,
      "step": 134740
    },
    {
      "epoch": 41.576673866090715,
      "grad_norm": 7.559769528597826e-06,
      "learning_rate": 8.423326133909287e-06,
      "loss": 0.0,
      "step": 134750
    },
    {
      "epoch": 41.57975933353903,
      "grad_norm": 0.0031363354064524174,
      "learning_rate": 8.42024066646097e-06,
      "loss": 0.0,
      "step": 134760
    },
    {
      "epoch": 41.58284480098735,
      "grad_norm": 3.602651759138098e-07,
      "learning_rate": 8.41715519901265e-06,
      "loss": 0.0,
      "step": 134770
    },
    {
      "epoch": 41.58593026843567,
      "grad_norm": 2.1581282538818414e-08,
      "learning_rate": 8.414069731564332e-06,
      "loss": 0.0029,
      "step": 134780
    },
    {
      "epoch": 41.58901573588398,
      "grad_norm": 2.0093973707169255e-10,
      "learning_rate": 8.410984264116014e-06,
      "loss": 0.0,
      "step": 134790
    },
    {
      "epoch": 41.592101203332305,
      "grad_norm": 8.779859854257666e-06,
      "learning_rate": 8.407898796667696e-06,
      "loss": 0.0,
      "step": 134800
    },
    {
      "epoch": 41.59518667078062,
      "grad_norm": 9.263197320308336e-09,
      "learning_rate": 8.404813329219377e-06,
      "loss": 0.0,
      "step": 134810
    },
    {
      "epoch": 41.59827213822894,
      "grad_norm": 3.3398131904505135e-07,
      "learning_rate": 8.401727861771058e-06,
      "loss": 0.0,
      "step": 134820
    },
    {
      "epoch": 41.60135760567726,
      "grad_norm": 8.375309903385642e-07,
      "learning_rate": 8.39864239432274e-06,
      "loss": 0.0001,
      "step": 134830
    },
    {
      "epoch": 41.60444307312558,
      "grad_norm": 4.777240610565059e-05,
      "learning_rate": 8.395556926874421e-06,
      "loss": 0.0,
      "step": 134840
    },
    {
      "epoch": 41.607528540573895,
      "grad_norm": 8.803741025076306e-07,
      "learning_rate": 8.392471459426104e-06,
      "loss": 0.0,
      "step": 134850
    },
    {
      "epoch": 41.61061400802222,
      "grad_norm": 2.558516030148894e-07,
      "learning_rate": 8.389385991977786e-06,
      "loss": 0.0,
      "step": 134860
    },
    {
      "epoch": 41.61369947547053,
      "grad_norm": 5.164336471352726e-05,
      "learning_rate": 8.386300524529467e-06,
      "loss": 0.0,
      "step": 134870
    },
    {
      "epoch": 41.616784942918855,
      "grad_norm": 9.194069505724656e-09,
      "learning_rate": 8.383215057081148e-06,
      "loss": 0.0,
      "step": 134880
    },
    {
      "epoch": 41.61987041036717,
      "grad_norm": 0.0028750314377248287,
      "learning_rate": 8.380129589632829e-06,
      "loss": 0.0,
      "step": 134890
    },
    {
      "epoch": 41.62295587781549,
      "grad_norm": 4.07953339163214e-05,
      "learning_rate": 8.377044122184511e-06,
      "loss": 0.0,
      "step": 134900
    },
    {
      "epoch": 41.62604134526381,
      "grad_norm": 2.808959607136785e-07,
      "learning_rate": 8.373958654736194e-06,
      "loss": 0.0,
      "step": 134910
    },
    {
      "epoch": 41.62912681271212,
      "grad_norm": 3.3502771668025844e-09,
      "learning_rate": 8.370873187287874e-06,
      "loss": 0.0,
      "step": 134920
    },
    {
      "epoch": 41.632212280160445,
      "grad_norm": 6.255698394852516e-07,
      "learning_rate": 8.367787719839557e-06,
      "loss": 0.0,
      "step": 134930
    },
    {
      "epoch": 41.63529774760876,
      "grad_norm": 1.416477061866317e-06,
      "learning_rate": 8.364702252391238e-06,
      "loss": 0.0,
      "step": 134940
    },
    {
      "epoch": 41.63838321505708,
      "grad_norm": 9.375307996606352e-08,
      "learning_rate": 8.361616784942918e-06,
      "loss": 0.0,
      "step": 134950
    },
    {
      "epoch": 41.6414686825054,
      "grad_norm": 0.009758743457496166,
      "learning_rate": 8.3585313174946e-06,
      "loss": 0.0,
      "step": 134960
    },
    {
      "epoch": 41.64455414995372,
      "grad_norm": 9.776199476618785e-06,
      "learning_rate": 8.355445850046283e-06,
      "loss": 0.0,
      "step": 134970
    },
    {
      "epoch": 41.647639617402035,
      "grad_norm": 0.0006010420620441437,
      "learning_rate": 8.352360382597964e-06,
      "loss": 0.0,
      "step": 134980
    },
    {
      "epoch": 41.65072508485036,
      "grad_norm": 3.709382508532144e-05,
      "learning_rate": 8.349274915149645e-06,
      "loss": 0.0,
      "step": 134990
    },
    {
      "epoch": 41.65381055229867,
      "grad_norm": 1.342136602033861e-05,
      "learning_rate": 8.346189447701327e-06,
      "loss": 0.0,
      "step": 135000
    },
    {
      "epoch": 41.656896019746995,
      "grad_norm": 6.196341564645991e-05,
      "learning_rate": 8.343103980253008e-06,
      "loss": 0.0,
      "step": 135010
    },
    {
      "epoch": 41.65998148719531,
      "grad_norm": 1.8246720401293715e-06,
      "learning_rate": 8.34001851280469e-06,
      "loss": 0.0,
      "step": 135020
    },
    {
      "epoch": 41.663066954643625,
      "grad_norm": 3.290283245860337e-07,
      "learning_rate": 8.336933045356373e-06,
      "loss": 0.0,
      "step": 135030
    },
    {
      "epoch": 41.66615242209195,
      "grad_norm": 1.0618765372782946e-05,
      "learning_rate": 8.333847577908054e-06,
      "loss": 0.0,
      "step": 135040
    },
    {
      "epoch": 41.66923788954026,
      "grad_norm": 4.209699181956239e-05,
      "learning_rate": 8.330762110459735e-06,
      "loss": 0.0005,
      "step": 135050
    },
    {
      "epoch": 41.672323356988585,
      "grad_norm": 1.5275243640644476e-05,
      "learning_rate": 8.327676643011417e-06,
      "loss": 0.0,
      "step": 135060
    },
    {
      "epoch": 41.6754088244369,
      "grad_norm": 3.593509934063377e-09,
      "learning_rate": 8.324591175563098e-06,
      "loss": 0.0,
      "step": 135070
    },
    {
      "epoch": 41.67849429188522,
      "grad_norm": 7.777699693178874e-07,
      "learning_rate": 8.32150570811478e-06,
      "loss": 0.0,
      "step": 135080
    },
    {
      "epoch": 41.68157975933354,
      "grad_norm": 9.655925168772228e-06,
      "learning_rate": 8.318420240666461e-06,
      "loss": 0.0,
      "step": 135090
    },
    {
      "epoch": 41.68466522678186,
      "grad_norm": 3.5265088627056684e-07,
      "learning_rate": 8.315334773218144e-06,
      "loss": 0.0,
      "step": 135100
    },
    {
      "epoch": 41.687750694230175,
      "grad_norm": 4.8899669309321325e-06,
      "learning_rate": 8.312249305769824e-06,
      "loss": 0.0,
      "step": 135110
    },
    {
      "epoch": 41.6908361616785,
      "grad_norm": 3.742577609955333e-05,
      "learning_rate": 8.309163838321505e-06,
      "loss": 0.0,
      "step": 135120
    },
    {
      "epoch": 41.69392162912681,
      "grad_norm": 2.6881583835347556e-05,
      "learning_rate": 8.306078370873188e-06,
      "loss": 0.0,
      "step": 135130
    },
    {
      "epoch": 41.697007096575135,
      "grad_norm": 6.108806474003359e-07,
      "learning_rate": 8.30299290342487e-06,
      "loss": 0.0,
      "step": 135140
    },
    {
      "epoch": 41.70009256402345,
      "grad_norm": 0.00656979251652956,
      "learning_rate": 8.299907435976551e-06,
      "loss": 0.0002,
      "step": 135150
    },
    {
      "epoch": 41.703178031471765,
      "grad_norm": 5.9633992350427434e-05,
      "learning_rate": 8.296821968528233e-06,
      "loss": 0.0,
      "step": 135160
    },
    {
      "epoch": 41.70626349892009,
      "grad_norm": 0.002666060347110033,
      "learning_rate": 8.293736501079914e-06,
      "loss": 0.0,
      "step": 135170
    },
    {
      "epoch": 41.7093489663684,
      "grad_norm": 4.3696562812556294e-08,
      "learning_rate": 8.290651033631595e-06,
      "loss": 0.0,
      "step": 135180
    },
    {
      "epoch": 41.712434433816725,
      "grad_norm": 8.576970685680863e-06,
      "learning_rate": 8.287565566183276e-06,
      "loss": 0.0,
      "step": 135190
    },
    {
      "epoch": 41.71551990126504,
      "grad_norm": 7.973010838213668e-07,
      "learning_rate": 8.284480098734958e-06,
      "loss": 0.0,
      "step": 135200
    },
    {
      "epoch": 41.71860536871336,
      "grad_norm": 0.010349034331738949,
      "learning_rate": 8.28139463128664e-06,
      "loss": 0.0,
      "step": 135210
    },
    {
      "epoch": 41.72169083616168,
      "grad_norm": 4.143750174989691e-06,
      "learning_rate": 8.278309163838322e-06,
      "loss": 0.0,
      "step": 135220
    },
    {
      "epoch": 41.72477630361,
      "grad_norm": 0.15758100152015686,
      "learning_rate": 8.275223696390004e-06,
      "loss": 0.0001,
      "step": 135230
    },
    {
      "epoch": 41.727861771058315,
      "grad_norm": 0.00021248853590805084,
      "learning_rate": 8.272138228941685e-06,
      "loss": 0.0,
      "step": 135240
    },
    {
      "epoch": 41.73094723850664,
      "grad_norm": 3.942621518149281e-08,
      "learning_rate": 8.269052761493366e-06,
      "loss": 0.0,
      "step": 135250
    },
    {
      "epoch": 41.73403270595495,
      "grad_norm": 0.0003594151057768613,
      "learning_rate": 8.265967294045048e-06,
      "loss": 0.0,
      "step": 135260
    },
    {
      "epoch": 41.73711817340327,
      "grad_norm": 2.3611984545368614e-07,
      "learning_rate": 8.26288182659673e-06,
      "loss": 0.0,
      "step": 135270
    },
    {
      "epoch": 41.74020364085159,
      "grad_norm": 1.75480581674492e-05,
      "learning_rate": 8.259796359148411e-06,
      "loss": 0.0,
      "step": 135280
    },
    {
      "epoch": 41.743289108299905,
      "grad_norm": 3.7085240478518244e-07,
      "learning_rate": 8.256710891700092e-06,
      "loss": 0.0,
      "step": 135290
    },
    {
      "epoch": 41.74637457574823,
      "grad_norm": 1.7476623952461523e-06,
      "learning_rate": 8.253625424251775e-06,
      "loss": 0.0,
      "step": 135300
    },
    {
      "epoch": 41.74946004319654,
      "grad_norm": 0.00039477203972637653,
      "learning_rate": 8.250539956803455e-06,
      "loss": 0.0,
      "step": 135310
    },
    {
      "epoch": 41.752545510644865,
      "grad_norm": 9.221415631088803e-09,
      "learning_rate": 8.247454489355138e-06,
      "loss": 0.0017,
      "step": 135320
    },
    {
      "epoch": 41.75563097809318,
      "grad_norm": 0.00033050880301743746,
      "learning_rate": 8.24436902190682e-06,
      "loss": 0.0001,
      "step": 135330
    },
    {
      "epoch": 41.7587164455415,
      "grad_norm": 0.00010072054283227772,
      "learning_rate": 8.241283554458501e-06,
      "loss": 0.0,
      "step": 135340
    },
    {
      "epoch": 41.76180191298982,
      "grad_norm": 1.8204638081442681e-06,
      "learning_rate": 8.238198087010182e-06,
      "loss": 0.0,
      "step": 135350
    },
    {
      "epoch": 41.76488738043814,
      "grad_norm": 4.984592010259803e-07,
      "learning_rate": 8.235112619561864e-06,
      "loss": 0.0,
      "step": 135360
    },
    {
      "epoch": 41.767972847886455,
      "grad_norm": 6.383920059249704e-09,
      "learning_rate": 8.232027152113545e-06,
      "loss": 0.0,
      "step": 135370
    },
    {
      "epoch": 41.77105831533477,
      "grad_norm": 7.957468369568232e-06,
      "learning_rate": 8.228941684665228e-06,
      "loss": 0.0,
      "step": 135380
    },
    {
      "epoch": 41.77414378278309,
      "grad_norm": 2.1365384128557707e-08,
      "learning_rate": 8.225856217216908e-06,
      "loss": 0.0,
      "step": 135390
    },
    {
      "epoch": 41.77722925023141,
      "grad_norm": 5.12343240188784e-06,
      "learning_rate": 8.222770749768591e-06,
      "loss": 0.0,
      "step": 135400
    },
    {
      "epoch": 41.78031471767973,
      "grad_norm": 2.0980973403084135e-08,
      "learning_rate": 8.219685282320272e-06,
      "loss": 0.0,
      "step": 135410
    },
    {
      "epoch": 41.783400185128045,
      "grad_norm": 0.0004379278689157218,
      "learning_rate": 8.216599814871952e-06,
      "loss": 0.0,
      "step": 135420
    },
    {
      "epoch": 41.78648565257637,
      "grad_norm": 4.023529009966609e-10,
      "learning_rate": 8.213514347423635e-06,
      "loss": 0.0,
      "step": 135430
    },
    {
      "epoch": 41.78957112002468,
      "grad_norm": 7.282853857759619e-07,
      "learning_rate": 8.210428879975317e-06,
      "loss": 0.0,
      "step": 135440
    },
    {
      "epoch": 41.792656587473004,
      "grad_norm": 2.4363819761674677e-07,
      "learning_rate": 8.207343412526998e-06,
      "loss": 0.0,
      "step": 135450
    },
    {
      "epoch": 41.79574205492132,
      "grad_norm": 2.8365944672259502e-05,
      "learning_rate": 8.204257945078679e-06,
      "loss": 0.0,
      "step": 135460
    },
    {
      "epoch": 41.79882752236964,
      "grad_norm": 1.5862517557252431e-06,
      "learning_rate": 8.201172477630361e-06,
      "loss": 0.0,
      "step": 135470
    },
    {
      "epoch": 41.80191298981796,
      "grad_norm": 2.906160867510721e-09,
      "learning_rate": 8.198087010182042e-06,
      "loss": 0.0,
      "step": 135480
    },
    {
      "epoch": 41.80499845726628,
      "grad_norm": 2.5031246764228854e-07,
      "learning_rate": 8.195001542733725e-06,
      "loss": 0.0,
      "step": 135490
    },
    {
      "epoch": 41.808083924714595,
      "grad_norm": 3.67548977919796e-06,
      "learning_rate": 8.191916075285407e-06,
      "loss": 0.0,
      "step": 135500
    },
    {
      "epoch": 41.81116939216291,
      "grad_norm": 3.528317392920144e-05,
      "learning_rate": 8.188830607837088e-06,
      "loss": 0.0,
      "step": 135510
    },
    {
      "epoch": 41.81425485961123,
      "grad_norm": 1.7069952491510776e-06,
      "learning_rate": 8.185745140388769e-06,
      "loss": 0.0,
      "step": 135520
    },
    {
      "epoch": 41.81734032705955,
      "grad_norm": 0.0006742360419593751,
      "learning_rate": 8.182659672940451e-06,
      "loss": 0.0,
      "step": 135530
    },
    {
      "epoch": 41.82042579450787,
      "grad_norm": 6.348935954747503e-08,
      "learning_rate": 8.179574205492132e-06,
      "loss": 0.0,
      "step": 135540
    },
    {
      "epoch": 41.823511261956185,
      "grad_norm": 2.0467909052968025e-05,
      "learning_rate": 8.176488738043814e-06,
      "loss": 0.0,
      "step": 135550
    },
    {
      "epoch": 41.82659672940451,
      "grad_norm": 3.795426164288074e-05,
      "learning_rate": 8.173403270595495e-06,
      "loss": 0.0,
      "step": 135560
    },
    {
      "epoch": 41.82968219685282,
      "grad_norm": 1.8481794086255832e-06,
      "learning_rate": 8.170317803147178e-06,
      "loss": 0.0,
      "step": 135570
    },
    {
      "epoch": 41.832767664301144,
      "grad_norm": 1.4461415958066937e-06,
      "learning_rate": 8.167232335698859e-06,
      "loss": 0.0021,
      "step": 135580
    },
    {
      "epoch": 41.83585313174946,
      "grad_norm": 2.0225666048645508e-06,
      "learning_rate": 8.16414686825054e-06,
      "loss": 0.0,
      "step": 135590
    },
    {
      "epoch": 41.83893859919778,
      "grad_norm": 8.021446410566568e-05,
      "learning_rate": 8.161061400802222e-06,
      "loss": 0.0,
      "step": 135600
    },
    {
      "epoch": 41.8420240666461,
      "grad_norm": 5.498348514265672e-07,
      "learning_rate": 8.157975933353904e-06,
      "loss": 0.0,
      "step": 135610
    },
    {
      "epoch": 41.84510953409441,
      "grad_norm": 2.6004954634117894e-07,
      "learning_rate": 8.154890465905585e-06,
      "loss": 0.0,
      "step": 135620
    },
    {
      "epoch": 41.848195001542734,
      "grad_norm": 8.045654794841539e-06,
      "learning_rate": 8.151804998457268e-06,
      "loss": 0.0,
      "step": 135630
    },
    {
      "epoch": 41.85128046899105,
      "grad_norm": 2.0062302610313054e-06,
      "learning_rate": 8.148719531008948e-06,
      "loss": 0.0,
      "step": 135640
    },
    {
      "epoch": 41.85436593643937,
      "grad_norm": 3.4428123285579204e-07,
      "learning_rate": 8.145634063560629e-06,
      "loss": 0.0,
      "step": 135650
    },
    {
      "epoch": 41.85745140388769,
      "grad_norm": 6.09223377523449e-07,
      "learning_rate": 8.142548596112312e-06,
      "loss": 0.0,
      "step": 135660
    },
    {
      "epoch": 41.86053687133601,
      "grad_norm": 9.547827175993007e-06,
      "learning_rate": 8.139463128663994e-06,
      "loss": 0.0,
      "step": 135670
    },
    {
      "epoch": 41.863622338784324,
      "grad_norm": 6.048026079952251e-08,
      "learning_rate": 8.136377661215675e-06,
      "loss": 0.0,
      "step": 135680
    },
    {
      "epoch": 41.86670780623265,
      "grad_norm": 3.311000114081253e-07,
      "learning_rate": 8.133292193767356e-06,
      "loss": 0.0,
      "step": 135690
    },
    {
      "epoch": 41.86979327368096,
      "grad_norm": 4.096555130672641e-06,
      "learning_rate": 8.130206726319038e-06,
      "loss": 0.0,
      "step": 135700
    },
    {
      "epoch": 41.872878741129284,
      "grad_norm": 8.39220592752099e-05,
      "learning_rate": 8.127121258870719e-06,
      "loss": 0.0,
      "step": 135710
    },
    {
      "epoch": 41.8759642085776,
      "grad_norm": 3.063857079155241e-08,
      "learning_rate": 8.124035791422401e-06,
      "loss": 0.0,
      "step": 135720
    },
    {
      "epoch": 41.879049676025915,
      "grad_norm": 9.277731471968309e-09,
      "learning_rate": 8.120950323974084e-06,
      "loss": 0.0,
      "step": 135730
    },
    {
      "epoch": 41.88213514347424,
      "grad_norm": 1.0980994602505234e-07,
      "learning_rate": 8.117864856525765e-06,
      "loss": 0.0,
      "step": 135740
    },
    {
      "epoch": 41.88522061092255,
      "grad_norm": 9.440626854484435e-06,
      "learning_rate": 8.114779389077445e-06,
      "loss": 0.0,
      "step": 135750
    },
    {
      "epoch": 41.888306078370874,
      "grad_norm": 2.2310964595817495e-06,
      "learning_rate": 8.111693921629126e-06,
      "loss": 0.0,
      "step": 135760
    },
    {
      "epoch": 41.89139154581919,
      "grad_norm": 1.9478520698612556e-06,
      "learning_rate": 8.108608454180809e-06,
      "loss": 0.0,
      "step": 135770
    },
    {
      "epoch": 41.89447701326751,
      "grad_norm": 1.6856299680512166e-06,
      "learning_rate": 8.105522986732491e-06,
      "loss": 0.0,
      "step": 135780
    },
    {
      "epoch": 41.89756248071583,
      "grad_norm": 6.344792200252414e-05,
      "learning_rate": 8.102437519284172e-06,
      "loss": 0.0,
      "step": 135790
    },
    {
      "epoch": 41.90064794816415,
      "grad_norm": 0.002858392894268036,
      "learning_rate": 8.099352051835854e-06,
      "loss": 0.0,
      "step": 135800
    },
    {
      "epoch": 41.903733415612464,
      "grad_norm": 9.362180571770296e-05,
      "learning_rate": 8.096266584387535e-06,
      "loss": 0.0,
      "step": 135810
    },
    {
      "epoch": 41.90681888306079,
      "grad_norm": 3.753424948627071e-07,
      "learning_rate": 8.093181116939216e-06,
      "loss": 0.0,
      "step": 135820
    },
    {
      "epoch": 41.9099043505091,
      "grad_norm": 8.052246158740672e-08,
      "learning_rate": 8.090095649490898e-06,
      "loss": 0.0,
      "step": 135830
    },
    {
      "epoch": 41.912989817957424,
      "grad_norm": 1.0670357823983068e-06,
      "learning_rate": 8.08701018204258e-06,
      "loss": 0.0,
      "step": 135840
    },
    {
      "epoch": 41.91607528540574,
      "grad_norm": 3.1848880865936735e-08,
      "learning_rate": 8.083924714594262e-06,
      "loss": 0.0,
      "step": 135850
    },
    {
      "epoch": 41.919160752854054,
      "grad_norm": 7.929248567961622e-06,
      "learning_rate": 8.080839247145942e-06,
      "loss": 0.0,
      "step": 135860
    },
    {
      "epoch": 41.92224622030238,
      "grad_norm": 3.331132347739185e-08,
      "learning_rate": 8.077753779697625e-06,
      "loss": 0.0,
      "step": 135870
    },
    {
      "epoch": 41.92533168775069,
      "grad_norm": 0.0004165564605500549,
      "learning_rate": 8.074668312249306e-06,
      "loss": 0.0,
      "step": 135880
    },
    {
      "epoch": 41.928417155199014,
      "grad_norm": 1.0522664524614811e-05,
      "learning_rate": 8.071582844800987e-06,
      "loss": 0.0,
      "step": 135890
    },
    {
      "epoch": 41.93150262264733,
      "grad_norm": 0.004547099117189646,
      "learning_rate": 8.068497377352669e-06,
      "loss": 0.0,
      "step": 135900
    },
    {
      "epoch": 41.93458809009565,
      "grad_norm": 9.674508874013554e-07,
      "learning_rate": 8.065411909904351e-06,
      "loss": 0.0,
      "step": 135910
    },
    {
      "epoch": 41.93767355754397,
      "grad_norm": 2.2993262405179848e-07,
      "learning_rate": 8.062326442456032e-06,
      "loss": 0.0001,
      "step": 135920
    },
    {
      "epoch": 41.94075902499229,
      "grad_norm": 2.0117886379011907e-06,
      "learning_rate": 8.059240975007715e-06,
      "loss": 0.0,
      "step": 135930
    },
    {
      "epoch": 41.943844492440604,
      "grad_norm": 4.97078190164757e-06,
      "learning_rate": 8.056155507559395e-06,
      "loss": 0.0,
      "step": 135940
    },
    {
      "epoch": 41.94692995988893,
      "grad_norm": 1.8976672436110675e-05,
      "learning_rate": 8.053070040111076e-06,
      "loss": 0.0,
      "step": 135950
    },
    {
      "epoch": 41.95001542733724,
      "grad_norm": 8.855752184899757e-07,
      "learning_rate": 8.049984572662759e-06,
      "loss": 0.0,
      "step": 135960
    },
    {
      "epoch": 41.95310089478556,
      "grad_norm": 3.4125835668419313e-07,
      "learning_rate": 8.046899105214441e-06,
      "loss": 0.0,
      "step": 135970
    },
    {
      "epoch": 41.95618636223388,
      "grad_norm": 0.00014529093459714204,
      "learning_rate": 8.043813637766122e-06,
      "loss": 0.0,
      "step": 135980
    },
    {
      "epoch": 41.959271829682194,
      "grad_norm": 2.0010675143566914e-06,
      "learning_rate": 8.040728170317803e-06,
      "loss": 0.0,
      "step": 135990
    },
    {
      "epoch": 41.96235729713052,
      "grad_norm": 1.030106795951724e-05,
      "learning_rate": 8.037642702869485e-06,
      "loss": 0.0,
      "step": 136000
    },
    {
      "epoch": 41.96544276457883,
      "grad_norm": 2.255448862342746e-06,
      "learning_rate": 8.034557235421166e-06,
      "loss": 0.0,
      "step": 136010
    },
    {
      "epoch": 41.968528232027154,
      "grad_norm": 3.0779796361457556e-05,
      "learning_rate": 8.031471767972849e-06,
      "loss": 0.0,
      "step": 136020
    },
    {
      "epoch": 41.97161369947547,
      "grad_norm": 0.0006008223863318563,
      "learning_rate": 8.028386300524531e-06,
      "loss": 0.0,
      "step": 136030
    },
    {
      "epoch": 41.97469916692379,
      "grad_norm": 0.00033688952680677176,
      "learning_rate": 8.025300833076212e-06,
      "loss": 0.0,
      "step": 136040
    },
    {
      "epoch": 41.97778463437211,
      "grad_norm": 4.0010032535064965e-05,
      "learning_rate": 8.022215365627893e-06,
      "loss": 0.0,
      "step": 136050
    },
    {
      "epoch": 41.98087010182043,
      "grad_norm": 2.6938034352497198e-05,
      "learning_rate": 8.019129898179573e-06,
      "loss": 0.0,
      "step": 136060
    },
    {
      "epoch": 41.983955569268744,
      "grad_norm": 6.42659188088146e-06,
      "learning_rate": 8.016044430731256e-06,
      "loss": 0.0,
      "step": 136070
    },
    {
      "epoch": 41.98704103671706,
      "grad_norm": 2.692309635676793e-06,
      "learning_rate": 8.012958963282938e-06,
      "loss": 0.0,
      "step": 136080
    },
    {
      "epoch": 41.99012650416538,
      "grad_norm": 1.8683921325646224e-06,
      "learning_rate": 8.009873495834619e-06,
      "loss": 0.0,
      "step": 136090
    },
    {
      "epoch": 41.9932119716137,
      "grad_norm": 7.202596316346899e-05,
      "learning_rate": 8.006788028386302e-06,
      "loss": 0.0,
      "step": 136100
    },
    {
      "epoch": 41.99629743906202,
      "grad_norm": 1.4332779301184928e-06,
      "learning_rate": 8.003702560937982e-06,
      "loss": 0.0,
      "step": 136110
    },
    {
      "epoch": 41.999382906510334,
      "grad_norm": 2.5408808141946793e-05,
      "learning_rate": 8.000617093489663e-06,
      "loss": 0.0,
      "step": 136120
    },
    {
      "epoch": 42.0,
      "eval_accuracy_branch1": 1.0,
      "eval_accuracy_branch2": 0.41353934589084035,
      "eval_f1_branch1": 1.0,
      "eval_f1_branch2": 0.40502806773339173,
      "eval_loss": 4.185490070085507e-07,
      "eval_precision_branch1": 1.0,
      "eval_precision_branch2": 0.5133342676742774,
      "eval_recall_branch1": 1.0,
      "eval_recall_branch2": 0.5100836202656173,
      "eval_runtime": 238.5378,
      "eval_samples_per_second": 434.661,
      "eval_steps_per_second": 54.335,
      "step": 136122
    },
    {
      "epoch": 42.002468373958656,
      "grad_norm": 4.142410148233466e-08,
      "learning_rate": 7.997531626041346e-06,
      "loss": 0.0,
      "step": 136130
    },
    {
      "epoch": 42.00555384140697,
      "grad_norm": 6.356184167088941e-05,
      "learning_rate": 7.994446158593028e-06,
      "loss": 0.0,
      "step": 136140
    },
    {
      "epoch": 42.008639308855294,
      "grad_norm": 0.0012682626256719232,
      "learning_rate": 7.991360691144709e-06,
      "loss": 0.0,
      "step": 136150
    },
    {
      "epoch": 42.01172477630361,
      "grad_norm": 3.522466840877314e-06,
      "learning_rate": 7.98827522369639e-06,
      "loss": 0.0,
      "step": 136160
    },
    {
      "epoch": 42.01481024375193,
      "grad_norm": 5.064461947767995e-05,
      "learning_rate": 7.985189756248072e-06,
      "loss": 0.0,
      "step": 136170
    },
    {
      "epoch": 42.01789571120025,
      "grad_norm": 3.951324288209435e-06,
      "learning_rate": 7.982104288799753e-06,
      "loss": 0.0001,
      "step": 136180
    },
    {
      "epoch": 42.02098117864857,
      "grad_norm": 2.3480765776184853e-06,
      "learning_rate": 7.979018821351435e-06,
      "loss": 0.0,
      "step": 136190
    },
    {
      "epoch": 42.024066646096884,
      "grad_norm": 2.0409643184393644e-06,
      "learning_rate": 7.975933353903118e-06,
      "loss": 0.0,
      "step": 136200
    },
    {
      "epoch": 42.0271521135452,
      "grad_norm": 1.4436653145821765e-05,
      "learning_rate": 7.972847886454799e-06,
      "loss": 0.0,
      "step": 136210
    },
    {
      "epoch": 42.03023758099352,
      "grad_norm": 3.2230188935500337e-06,
      "learning_rate": 7.96976241900648e-06,
      "loss": 0.0,
      "step": 136220
    },
    {
      "epoch": 42.03332304844184,
      "grad_norm": 1.4080515029490925e-06,
      "learning_rate": 7.966676951558162e-06,
      "loss": 0.0,
      "step": 136230
    },
    {
      "epoch": 42.03640851589016,
      "grad_norm": 0.00010806071077240631,
      "learning_rate": 7.963591484109843e-06,
      "loss": 0.0,
      "step": 136240
    },
    {
      "epoch": 42.039493983338474,
      "grad_norm": 9.04175237792515e-07,
      "learning_rate": 7.960506016661525e-06,
      "loss": 0.0,
      "step": 136250
    },
    {
      "epoch": 42.042579450786796,
      "grad_norm": 1.7786565877031535e-05,
      "learning_rate": 7.957420549213206e-06,
      "loss": 0.0,
      "step": 136260
    },
    {
      "epoch": 42.04566491823511,
      "grad_norm": 5.8367611188714363e-08,
      "learning_rate": 7.954335081764888e-06,
      "loss": 0.0,
      "step": 136270
    },
    {
      "epoch": 42.048750385683434,
      "grad_norm": 1.3746206395381932e-09,
      "learning_rate": 7.95124961431657e-06,
      "loss": 0.0,
      "step": 136280
    },
    {
      "epoch": 42.05183585313175,
      "grad_norm": 8.766498353907082e-07,
      "learning_rate": 7.94816414686825e-06,
      "loss": 0.0,
      "step": 136290
    },
    {
      "epoch": 42.05492132058007,
      "grad_norm": 1.957543190655997e-06,
      "learning_rate": 7.945078679419932e-06,
      "loss": 0.0,
      "step": 136300
    },
    {
      "epoch": 42.058006788028386,
      "grad_norm": 2.583942659839522e-06,
      "learning_rate": 7.941993211971615e-06,
      "loss": 0.0,
      "step": 136310
    },
    {
      "epoch": 42.0610922554767,
      "grad_norm": 1.57373699494201e-06,
      "learning_rate": 7.938907744523296e-06,
      "loss": 0.0,
      "step": 136320
    },
    {
      "epoch": 42.064177722925024,
      "grad_norm": 2.91796477540629e-05,
      "learning_rate": 7.935822277074977e-06,
      "loss": 0.0,
      "step": 136330
    },
    {
      "epoch": 42.06726319037334,
      "grad_norm": 1.811922516026243e-06,
      "learning_rate": 7.932736809626659e-06,
      "loss": 0.0,
      "step": 136340
    },
    {
      "epoch": 42.07034865782166,
      "grad_norm": 1.648573189072522e-08,
      "learning_rate": 7.92965134217834e-06,
      "loss": 0.0,
      "step": 136350
    },
    {
      "epoch": 42.073434125269976,
      "grad_norm": 4.7141696768449037e-07,
      "learning_rate": 7.926565874730022e-06,
      "loss": 0.0,
      "step": 136360
    },
    {
      "epoch": 42.0765195927183,
      "grad_norm": 2.794650299620116e-06,
      "learning_rate": 7.923480407281705e-06,
      "loss": 0.0,
      "step": 136370
    },
    {
      "epoch": 42.079605060166614,
      "grad_norm": 2.189416363762575e-06,
      "learning_rate": 7.920394939833386e-06,
      "loss": 0.0,
      "step": 136380
    },
    {
      "epoch": 42.082690527614936,
      "grad_norm": 6.56703268759884e-05,
      "learning_rate": 7.917309472385066e-06,
      "loss": 0.0,
      "step": 136390
    },
    {
      "epoch": 42.08577599506325,
      "grad_norm": 2.1316323000064585e-06,
      "learning_rate": 7.914224004936749e-06,
      "loss": 0.0,
      "step": 136400
    },
    {
      "epoch": 42.088861462511574,
      "grad_norm": 0.0001274145906791091,
      "learning_rate": 7.91113853748843e-06,
      "loss": 0.0,
      "step": 136410
    },
    {
      "epoch": 42.09194692995989,
      "grad_norm": 1.3462890819937456e-06,
      "learning_rate": 7.908053070040112e-06,
      "loss": 0.0003,
      "step": 136420
    },
    {
      "epoch": 42.095032397408204,
      "grad_norm": 1.6241627918134327e-06,
      "learning_rate": 7.904967602591793e-06,
      "loss": 0.0,
      "step": 136430
    },
    {
      "epoch": 42.098117864856526,
      "grad_norm": 2.901314521963627e-09,
      "learning_rate": 7.901882135143475e-06,
      "loss": 0.0,
      "step": 136440
    },
    {
      "epoch": 42.10120333230484,
      "grad_norm": 1.4782702237425838e-05,
      "learning_rate": 7.898796667695156e-06,
      "loss": 0.0,
      "step": 136450
    },
    {
      "epoch": 42.104288799753164,
      "grad_norm": 1.3871593182557262e-05,
      "learning_rate": 7.895711200246837e-06,
      "loss": 0.0,
      "step": 136460
    },
    {
      "epoch": 42.10737426720148,
      "grad_norm": 9.247317393601406e-06,
      "learning_rate": 7.89262573279852e-06,
      "loss": 0.0,
      "step": 136470
    },
    {
      "epoch": 42.1104597346498,
      "grad_norm": 7.327329853978881e-08,
      "learning_rate": 7.8895402653502e-06,
      "loss": 0.0005,
      "step": 136480
    },
    {
      "epoch": 42.113545202098116,
      "grad_norm": 1.412271988243674e-08,
      "learning_rate": 7.886454797901883e-06,
      "loss": 0.0,
      "step": 136490
    },
    {
      "epoch": 42.11663066954644,
      "grad_norm": 1.416741479687289e-08,
      "learning_rate": 7.883369330453565e-06,
      "loss": 0.0,
      "step": 136500
    },
    {
      "epoch": 42.119716136994754,
      "grad_norm": 5.779527256777328e-08,
      "learning_rate": 7.880283863005246e-06,
      "loss": 0.0,
      "step": 136510
    },
    {
      "epoch": 42.122801604443076,
      "grad_norm": 4.5253997086547315e-05,
      "learning_rate": 7.877198395556927e-06,
      "loss": 0.0,
      "step": 136520
    },
    {
      "epoch": 42.12588707189139,
      "grad_norm": 0.0001179800892714411,
      "learning_rate": 7.874112928108607e-06,
      "loss": 0.0001,
      "step": 136530
    },
    {
      "epoch": 42.12897253933971,
      "grad_norm": 3.426776231663098e-07,
      "learning_rate": 7.87102746066029e-06,
      "loss": 0.0,
      "step": 136540
    },
    {
      "epoch": 42.13205800678803,
      "grad_norm": 0.00020383026276249439,
      "learning_rate": 7.867941993211972e-06,
      "loss": 0.0,
      "step": 136550
    },
    {
      "epoch": 42.135143474236344,
      "grad_norm": 5.341128780855797e-05,
      "learning_rate": 7.864856525763653e-06,
      "loss": 0.0,
      "step": 136560
    },
    {
      "epoch": 42.138228941684666,
      "grad_norm": 2.604947439976968e-05,
      "learning_rate": 7.861771058315336e-06,
      "loss": 0.0046,
      "step": 136570
    },
    {
      "epoch": 42.14131440913298,
      "grad_norm": 0.0013266501482576132,
      "learning_rate": 7.858685590867016e-06,
      "loss": 0.0,
      "step": 136580
    },
    {
      "epoch": 42.1443998765813,
      "grad_norm": 7.832865911439058e-09,
      "learning_rate": 7.855600123418697e-06,
      "loss": 0.0005,
      "step": 136590
    },
    {
      "epoch": 42.14748534402962,
      "grad_norm": 5.120976766193053e-06,
      "learning_rate": 7.85251465597038e-06,
      "loss": 0.0,
      "step": 136600
    },
    {
      "epoch": 42.15057081147794,
      "grad_norm": 0.003951763268560171,
      "learning_rate": 7.849429188522062e-06,
      "loss": 0.0,
      "step": 136610
    },
    {
      "epoch": 42.153656278926256,
      "grad_norm": 9.065006878472559e-08,
      "learning_rate": 7.846343721073743e-06,
      "loss": 0.0,
      "step": 136620
    },
    {
      "epoch": 42.15674174637458,
      "grad_norm": 1.1715814252966084e-05,
      "learning_rate": 7.843258253625424e-06,
      "loss": 0.0,
      "step": 136630
    },
    {
      "epoch": 42.159827213822894,
      "grad_norm": 1.1300220648990944e-05,
      "learning_rate": 7.840172786177106e-06,
      "loss": 0.0,
      "step": 136640
    },
    {
      "epoch": 42.162912681271216,
      "grad_norm": 1.4602683222619817e-05,
      "learning_rate": 7.837087318728787e-06,
      "loss": 0.0001,
      "step": 136650
    },
    {
      "epoch": 42.16599814871953,
      "grad_norm": 2.0514549760264345e-05,
      "learning_rate": 7.83400185128047e-06,
      "loss": 0.0001,
      "step": 136660
    },
    {
      "epoch": 42.169083616167846,
      "grad_norm": 9.00928644114174e-05,
      "learning_rate": 7.830916383832152e-06,
      "loss": 0.0001,
      "step": 136670
    },
    {
      "epoch": 42.17216908361617,
      "grad_norm": 3.813401417573914e-05,
      "learning_rate": 7.827830916383833e-06,
      "loss": 0.0,
      "step": 136680
    },
    {
      "epoch": 42.175254551064484,
      "grad_norm": 0.0001398143795086071,
      "learning_rate": 7.824745448935514e-06,
      "loss": 0.0,
      "step": 136690
    },
    {
      "epoch": 42.178340018512806,
      "grad_norm": 4.013999568996951e-05,
      "learning_rate": 7.821659981487196e-06,
      "loss": 0.0,
      "step": 136700
    },
    {
      "epoch": 42.18142548596112,
      "grad_norm": 2.7498275812831707e-05,
      "learning_rate": 7.818574514038877e-06,
      "loss": 0.0,
      "step": 136710
    },
    {
      "epoch": 42.18451095340944,
      "grad_norm": 1.1751661759262788e-06,
      "learning_rate": 7.81548904659056e-06,
      "loss": 0.0,
      "step": 136720
    },
    {
      "epoch": 42.18759642085776,
      "grad_norm": 1.6427789887529798e-05,
      "learning_rate": 7.81240357914224e-06,
      "loss": 0.0,
      "step": 136730
    },
    {
      "epoch": 42.19068188830608,
      "grad_norm": 4.9861027946462855e-05,
      "learning_rate": 7.809318111693923e-06,
      "loss": 0.0,
      "step": 136740
    },
    {
      "epoch": 42.193767355754396,
      "grad_norm": 3.3057374366762815e-06,
      "learning_rate": 7.806232644245603e-06,
      "loss": 0.0,
      "step": 136750
    },
    {
      "epoch": 42.19685282320272,
      "grad_norm": 1.0266253411828075e-05,
      "learning_rate": 7.803147176797284e-06,
      "loss": 0.0,
      "step": 136760
    },
    {
      "epoch": 42.19993829065103,
      "grad_norm": 5.206523837841814e-06,
      "learning_rate": 7.800061709348967e-06,
      "loss": 0.0,
      "step": 136770
    },
    {
      "epoch": 42.20302375809935,
      "grad_norm": 1.6270915281779708e-08,
      "learning_rate": 7.796976241900649e-06,
      "loss": 0.0,
      "step": 136780
    },
    {
      "epoch": 42.20610922554767,
      "grad_norm": 3.073240151252321e-08,
      "learning_rate": 7.79389077445233e-06,
      "loss": 0.0,
      "step": 136790
    },
    {
      "epoch": 42.209194692995986,
      "grad_norm": 6.218278940650634e-07,
      "learning_rate": 7.790805307004012e-06,
      "loss": 0.0,
      "step": 136800
    },
    {
      "epoch": 42.21228016044431,
      "grad_norm": 2.0930601749569178e-06,
      "learning_rate": 7.787719839555693e-06,
      "loss": 0.0,
      "step": 136810
    },
    {
      "epoch": 42.21536562789262,
      "grad_norm": 4.429729870025767e-06,
      "learning_rate": 7.784634372107374e-06,
      "loss": 0.0,
      "step": 136820
    },
    {
      "epoch": 42.218451095340946,
      "grad_norm": 1.5751738828839734e-06,
      "learning_rate": 7.781548904659056e-06,
      "loss": 0.0,
      "step": 136830
    },
    {
      "epoch": 42.22153656278926,
      "grad_norm": 0.00010720764112193137,
      "learning_rate": 7.778463437210739e-06,
      "loss": 0.0,
      "step": 136840
    },
    {
      "epoch": 42.22462203023758,
      "grad_norm": 2.5467777504672995e-06,
      "learning_rate": 7.77537796976242e-06,
      "loss": 0.0,
      "step": 136850
    },
    {
      "epoch": 42.2277074976859,
      "grad_norm": 1.5501009329454973e-06,
      "learning_rate": 7.7722925023141e-06,
      "loss": 0.0001,
      "step": 136860
    },
    {
      "epoch": 42.23079296513422,
      "grad_norm": 0.017038699239492416,
      "learning_rate": 7.769207034865783e-06,
      "loss": 0.0,
      "step": 136870
    },
    {
      "epoch": 42.233878432582536,
      "grad_norm": 9.702053205273842e-08,
      "learning_rate": 7.766121567417464e-06,
      "loss": 0.0,
      "step": 136880
    },
    {
      "epoch": 42.23696390003086,
      "grad_norm": 1.1682562217174564e-05,
      "learning_rate": 7.763036099969146e-06,
      "loss": 0.0004,
      "step": 136890
    },
    {
      "epoch": 42.24004936747917,
      "grad_norm": 5.298087853589095e-05,
      "learning_rate": 7.759950632520829e-06,
      "loss": 0.0,
      "step": 136900
    },
    {
      "epoch": 42.24313483492749,
      "grad_norm": 1.2290577615203802e-05,
      "learning_rate": 7.75686516507251e-06,
      "loss": 0.0,
      "step": 136910
    },
    {
      "epoch": 42.24622030237581,
      "grad_norm": 1.4101299711910542e-05,
      "learning_rate": 7.75377969762419e-06,
      "loss": 0.0,
      "step": 136920
    },
    {
      "epoch": 42.249305769824126,
      "grad_norm": 7.929779854976005e-08,
      "learning_rate": 7.750694230175871e-06,
      "loss": 0.0,
      "step": 136930
    },
    {
      "epoch": 42.25239123727245,
      "grad_norm": 1.7410002328688279e-06,
      "learning_rate": 7.747608762727553e-06,
      "loss": 0.0,
      "step": 136940
    },
    {
      "epoch": 42.25547670472076,
      "grad_norm": 0.012662125751376152,
      "learning_rate": 7.744523295279236e-06,
      "loss": 0.0,
      "step": 136950
    },
    {
      "epoch": 42.258562172169086,
      "grad_norm": 5.389425041357754e-06,
      "learning_rate": 7.741437827830917e-06,
      "loss": 0.0,
      "step": 136960
    },
    {
      "epoch": 42.2616476396174,
      "grad_norm": 0.00015539754531346262,
      "learning_rate": 7.738352360382599e-06,
      "loss": 0.0,
      "step": 136970
    },
    {
      "epoch": 42.26473310706572,
      "grad_norm": 5.129794226377271e-05,
      "learning_rate": 7.73526689293428e-06,
      "loss": 0.0,
      "step": 136980
    },
    {
      "epoch": 42.26781857451404,
      "grad_norm": 4.556774456432322e-06,
      "learning_rate": 7.73218142548596e-06,
      "loss": 0.0,
      "step": 136990
    },
    {
      "epoch": 42.27090404196236,
      "grad_norm": 0.003206417430192232,
      "learning_rate": 7.729095958037643e-06,
      "loss": 0.0,
      "step": 137000
    },
    {
      "epoch": 42.273989509410676,
      "grad_norm": 6.31813009022153e-06,
      "learning_rate": 7.726010490589326e-06,
      "loss": 0.0,
      "step": 137010
    },
    {
      "epoch": 42.27707497685899,
      "grad_norm": 0.0006457337876781821,
      "learning_rate": 7.722925023141006e-06,
      "loss": 0.0,
      "step": 137020
    },
    {
      "epoch": 42.28016044430731,
      "grad_norm": 3.1158635920292e-06,
      "learning_rate": 7.719839555692687e-06,
      "loss": 0.0,
      "step": 137030
    },
    {
      "epoch": 42.28324591175563,
      "grad_norm": 9.687780675449176e-07,
      "learning_rate": 7.71675408824437e-06,
      "loss": 0.0,
      "step": 137040
    },
    {
      "epoch": 42.28633137920395,
      "grad_norm": 3.938864665542496e-06,
      "learning_rate": 7.71366862079605e-06,
      "loss": 0.0,
      "step": 137050
    },
    {
      "epoch": 42.289416846652266,
      "grad_norm": 3.3487186357206156e-08,
      "learning_rate": 7.710583153347733e-06,
      "loss": 0.0,
      "step": 137060
    },
    {
      "epoch": 42.29250231410059,
      "grad_norm": 0.0007935679168440402,
      "learning_rate": 7.707497685899415e-06,
      "loss": 0.0,
      "step": 137070
    },
    {
      "epoch": 42.2955877815489,
      "grad_norm": 0.00026458234060555696,
      "learning_rate": 7.704412218451096e-06,
      "loss": 0.0,
      "step": 137080
    },
    {
      "epoch": 42.298673248997225,
      "grad_norm": 5.5981754485401325e-06,
      "learning_rate": 7.701326751002777e-06,
      "loss": 0.0,
      "step": 137090
    },
    {
      "epoch": 42.30175871644554,
      "grad_norm": 8.6486033978872e-05,
      "learning_rate": 7.69824128355446e-06,
      "loss": 0.0004,
      "step": 137100
    },
    {
      "epoch": 42.30484418389386,
      "grad_norm": 1.8426052292852546e-06,
      "learning_rate": 7.69515581610614e-06,
      "loss": 0.0,
      "step": 137110
    },
    {
      "epoch": 42.30792965134218,
      "grad_norm": 1.8423351377805375e-07,
      "learning_rate": 7.692070348657821e-06,
      "loss": 0.0,
      "step": 137120
    },
    {
      "epoch": 42.31101511879049,
      "grad_norm": 4.062936568516307e-06,
      "learning_rate": 7.688984881209504e-06,
      "loss": 0.0,
      "step": 137130
    },
    {
      "epoch": 42.314100586238816,
      "grad_norm": 8.246488505392335e-06,
      "learning_rate": 7.685899413761186e-06,
      "loss": 0.0,
      "step": 137140
    },
    {
      "epoch": 42.31718605368713,
      "grad_norm": 5.55536360025144e-07,
      "learning_rate": 7.682813946312867e-06,
      "loss": 0.0,
      "step": 137150
    },
    {
      "epoch": 42.32027152113545,
      "grad_norm": 4.36633627032279e-06,
      "learning_rate": 7.679728478864548e-06,
      "loss": 0.0,
      "step": 137160
    },
    {
      "epoch": 42.32335698858377,
      "grad_norm": 0.00012334600614849478,
      "learning_rate": 7.67664301141623e-06,
      "loss": 0.0,
      "step": 137170
    },
    {
      "epoch": 42.32644245603209,
      "grad_norm": 0.0011478742817416787,
      "learning_rate": 7.67355754396791e-06,
      "loss": 0.0002,
      "step": 137180
    },
    {
      "epoch": 42.329527923480406,
      "grad_norm": 3.8836667215491616e-08,
      "learning_rate": 7.670472076519593e-06,
      "loss": 0.0,
      "step": 137190
    },
    {
      "epoch": 42.33261339092873,
      "grad_norm": 0.00018817429372575134,
      "learning_rate": 7.667386609071274e-06,
      "loss": 0.0,
      "step": 137200
    },
    {
      "epoch": 42.33569885837704,
      "grad_norm": 3.4588541893754154e-05,
      "learning_rate": 7.664301141622957e-06,
      "loss": 0.0002,
      "step": 137210
    },
    {
      "epoch": 42.338784325825365,
      "grad_norm": 0.0027317048516124487,
      "learning_rate": 7.661215674174637e-06,
      "loss": 0.0,
      "step": 137220
    },
    {
      "epoch": 42.34186979327368,
      "grad_norm": 1.7075583969017316e-07,
      "learning_rate": 7.658130206726318e-06,
      "loss": 0.0,
      "step": 137230
    },
    {
      "epoch": 42.344955260722,
      "grad_norm": 8.927734597818926e-05,
      "learning_rate": 7.655044739278e-06,
      "loss": 0.0,
      "step": 137240
    },
    {
      "epoch": 42.34804072817032,
      "grad_norm": 0.00012928534124512225,
      "learning_rate": 7.651959271829683e-06,
      "loss": 0.0,
      "step": 137250
    },
    {
      "epoch": 42.35112619561863,
      "grad_norm": 0.0011666676728054881,
      "learning_rate": 7.648873804381364e-06,
      "loss": 0.0,
      "step": 137260
    },
    {
      "epoch": 42.354211663066955,
      "grad_norm": 3.085089338128455e-05,
      "learning_rate": 7.645788336933046e-06,
      "loss": 0.0001,
      "step": 137270
    },
    {
      "epoch": 42.35729713051527,
      "grad_norm": 2.5384510049519804e-09,
      "learning_rate": 7.642702869484727e-06,
      "loss": 0.0001,
      "step": 137280
    },
    {
      "epoch": 42.36038259796359,
      "grad_norm": 1.0162979151573381e-06,
      "learning_rate": 7.639617402036408e-06,
      "loss": 0.0,
      "step": 137290
    },
    {
      "epoch": 42.36346806541191,
      "grad_norm": 8.506863196089398e-06,
      "learning_rate": 7.63653193458809e-06,
      "loss": 0.0,
      "step": 137300
    },
    {
      "epoch": 42.36655353286023,
      "grad_norm": 5.690795887858258e-07,
      "learning_rate": 7.633446467139773e-06,
      "loss": 0.0,
      "step": 137310
    },
    {
      "epoch": 42.369639000308545,
      "grad_norm": 4.375202777850973e-08,
      "learning_rate": 7.630360999691454e-06,
      "loss": 0.0,
      "step": 137320
    },
    {
      "epoch": 42.37272446775687,
      "grad_norm": 4.2620723661457305e-07,
      "learning_rate": 7.6272755322431344e-06,
      "loss": 0.0,
      "step": 137330
    },
    {
      "epoch": 42.37580993520518,
      "grad_norm": 6.534558139037472e-08,
      "learning_rate": 7.624190064794817e-06,
      "loss": 0.0,
      "step": 137340
    },
    {
      "epoch": 42.378895402653505,
      "grad_norm": 0.0013052878202870488,
      "learning_rate": 7.6211045973464985e-06,
      "loss": 0.0,
      "step": 137350
    },
    {
      "epoch": 42.38198087010182,
      "grad_norm": 2.2766430163301266e-07,
      "learning_rate": 7.618019129898179e-06,
      "loss": 0.0,
      "step": 137360
    },
    {
      "epoch": 42.385066337550136,
      "grad_norm": 5.776188481831923e-05,
      "learning_rate": 7.614933662449862e-06,
      "loss": 0.0,
      "step": 137370
    },
    {
      "epoch": 42.38815180499846,
      "grad_norm": 5.03603303059208e-07,
      "learning_rate": 7.6118481950015434e-06,
      "loss": 0.0,
      "step": 137380
    },
    {
      "epoch": 42.39123727244677,
      "grad_norm": 3.4444935863575665e-06,
      "learning_rate": 7.608762727553224e-06,
      "loss": 0.0,
      "step": 137390
    },
    {
      "epoch": 42.394322739895095,
      "grad_norm": 1.7295327779720537e-05,
      "learning_rate": 7.605677260104906e-06,
      "loss": 0.0,
      "step": 137400
    },
    {
      "epoch": 42.39740820734341,
      "grad_norm": 8.345632629414013e-09,
      "learning_rate": 7.602591792656588e-06,
      "loss": 0.0,
      "step": 137410
    },
    {
      "epoch": 42.40049367479173,
      "grad_norm": 3.7026707104814705e-06,
      "learning_rate": 7.599506325208269e-06,
      "loss": 0.0,
      "step": 137420
    },
    {
      "epoch": 42.40357914224005,
      "grad_norm": 1.2198576371247327e-07,
      "learning_rate": 7.596420857759951e-06,
      "loss": 0.0,
      "step": 137430
    },
    {
      "epoch": 42.40666460968837,
      "grad_norm": 4.8726430890155825e-08,
      "learning_rate": 7.593335390311633e-06,
      "loss": 0.0,
      "step": 137440
    },
    {
      "epoch": 42.409750077136685,
      "grad_norm": 0.00039959000423550606,
      "learning_rate": 7.590249922863314e-06,
      "loss": 0.0,
      "step": 137450
    },
    {
      "epoch": 42.41283554458501,
      "grad_norm": 3.983808767316077e-07,
      "learning_rate": 7.587164455414996e-06,
      "loss": 0.0005,
      "step": 137460
    },
    {
      "epoch": 42.41592101203332,
      "grad_norm": 7.748513598926365e-05,
      "learning_rate": 7.584078987966678e-06,
      "loss": 0.0,
      "step": 137470
    },
    {
      "epoch": 42.41900647948164,
      "grad_norm": 2.9125433798071754e-07,
      "learning_rate": 7.580993520518359e-06,
      "loss": 0.0,
      "step": 137480
    },
    {
      "epoch": 42.42209194692996,
      "grad_norm": 4.126912589441645e-09,
      "learning_rate": 7.5779080530700405e-06,
      "loss": 0.0,
      "step": 137490
    },
    {
      "epoch": 42.425177414378275,
      "grad_norm": 1.528740313005983e-06,
      "learning_rate": 7.574822585621721e-06,
      "loss": 0.0,
      "step": 137500
    },
    {
      "epoch": 42.4282628818266,
      "grad_norm": 1.5633213479304686e-07,
      "learning_rate": 7.571737118173404e-06,
      "loss": 0.0,
      "step": 137510
    },
    {
      "epoch": 42.43134834927491,
      "grad_norm": 0.03464842587709427,
      "learning_rate": 7.568651650725085e-06,
      "loss": 0.0,
      "step": 137520
    },
    {
      "epoch": 42.434433816723235,
      "grad_norm": 4.0153156533051515e-07,
      "learning_rate": 7.565566183276766e-06,
      "loss": 0.0,
      "step": 137530
    },
    {
      "epoch": 42.43751928417155,
      "grad_norm": 5.781879008281976e-05,
      "learning_rate": 7.562480715828449e-06,
      "loss": 0.0,
      "step": 137540
    },
    {
      "epoch": 42.44060475161987,
      "grad_norm": 5.308876097842585e-06,
      "learning_rate": 7.55939524838013e-06,
      "loss": 0.0,
      "step": 137550
    },
    {
      "epoch": 42.44369021906819,
      "grad_norm": 8.287901778203377e-07,
      "learning_rate": 7.556309780931811e-06,
      "loss": 0.0,
      "step": 137560
    },
    {
      "epoch": 42.44677568651651,
      "grad_norm": 2.834728547895793e-06,
      "learning_rate": 7.5532243134834936e-06,
      "loss": 0.0,
      "step": 137570
    },
    {
      "epoch": 42.449861153964825,
      "grad_norm": 5.0082039706467185e-06,
      "learning_rate": 7.550138846035175e-06,
      "loss": 0.0,
      "step": 137580
    },
    {
      "epoch": 42.45294662141315,
      "grad_norm": 2.6612764258970856e-07,
      "learning_rate": 7.547053378586856e-06,
      "loss": 0.0014,
      "step": 137590
    },
    {
      "epoch": 42.45603208886146,
      "grad_norm": 2.7601933183518668e-08,
      "learning_rate": 7.543967911138538e-06,
      "loss": 0.0,
      "step": 137600
    },
    {
      "epoch": 42.45911755630978,
      "grad_norm": 0.0012174785370007157,
      "learning_rate": 7.54088244369022e-06,
      "loss": 0.0,
      "step": 137610
    },
    {
      "epoch": 42.4622030237581,
      "grad_norm": 1.7287868558923947e-06,
      "learning_rate": 7.537796976241901e-06,
      "loss": 0.0,
      "step": 137620
    },
    {
      "epoch": 42.465288491206415,
      "grad_norm": 2.6649179289961467e-06,
      "learning_rate": 7.5347115087935825e-06,
      "loss": 0.0,
      "step": 137630
    },
    {
      "epoch": 42.46837395865474,
      "grad_norm": 0.0006736561772413552,
      "learning_rate": 7.531626041345265e-06,
      "loss": 0.0,
      "step": 137640
    },
    {
      "epoch": 42.47145942610305,
      "grad_norm": 0.0007859560428187251,
      "learning_rate": 7.528540573896946e-06,
      "loss": 0.0,
      "step": 137650
    },
    {
      "epoch": 42.474544893551375,
      "grad_norm": 7.790928293616162e-07,
      "learning_rate": 7.525455106448627e-06,
      "loss": 0.0,
      "step": 137660
    },
    {
      "epoch": 42.47763036099969,
      "grad_norm": 1.2703279026027303e-05,
      "learning_rate": 7.52236963900031e-06,
      "loss": 0.0,
      "step": 137670
    },
    {
      "epoch": 42.48071582844801,
      "grad_norm": 7.897126863554149e-08,
      "learning_rate": 7.519284171551991e-06,
      "loss": 0.0,
      "step": 137680
    },
    {
      "epoch": 42.48380129589633,
      "grad_norm": 6.28173992822667e-08,
      "learning_rate": 7.516198704103672e-06,
      "loss": 0.0,
      "step": 137690
    },
    {
      "epoch": 42.48688676334465,
      "grad_norm": 0.0017406174447387457,
      "learning_rate": 7.513113236655353e-06,
      "loss": 0.0,
      "step": 137700
    },
    {
      "epoch": 42.489972230792965,
      "grad_norm": 5.481815605890006e-07,
      "learning_rate": 7.5100277692070355e-06,
      "loss": 0.0,
      "step": 137710
    },
    {
      "epoch": 42.49305769824128,
      "grad_norm": 3.640040802110889e-08,
      "learning_rate": 7.506942301758717e-06,
      "loss": 0.0001,
      "step": 137720
    },
    {
      "epoch": 42.4961431656896,
      "grad_norm": 4.0269220846766984e-08,
      "learning_rate": 7.503856834310398e-06,
      "loss": 0.0,
      "step": 137730
    },
    {
      "epoch": 42.49922863313792,
      "grad_norm": 2.4196994630187874e-08,
      "learning_rate": 7.50077136686208e-06,
      "loss": 0.0,
      "step": 137740
    },
    {
      "epoch": 42.50231410058624,
      "grad_norm": 1.745262670738157e-05,
      "learning_rate": 7.497685899413762e-06,
      "loss": 0.0001,
      "step": 137750
    },
    {
      "epoch": 42.505399568034555,
      "grad_norm": 0.021729350090026855,
      "learning_rate": 7.494600431965443e-06,
      "loss": 0.0003,
      "step": 137760
    },
    {
      "epoch": 42.50848503548288,
      "grad_norm": 6.551219371431216e-07,
      "learning_rate": 7.491514964517125e-06,
      "loss": 0.0,
      "step": 137770
    },
    {
      "epoch": 42.51157050293119,
      "grad_norm": 2.9586655614366464e-07,
      "learning_rate": 7.488429497068807e-06,
      "loss": 0.0,
      "step": 137780
    },
    {
      "epoch": 42.514655970379515,
      "grad_norm": 6.401223345164908e-06,
      "learning_rate": 7.485344029620488e-06,
      "loss": 0.0,
      "step": 137790
    },
    {
      "epoch": 42.51774143782783,
      "grad_norm": 1.9032591058731896e-09,
      "learning_rate": 7.4822585621721685e-06,
      "loss": 0.0,
      "step": 137800
    },
    {
      "epoch": 42.52082690527615,
      "grad_norm": 0.005277398973703384,
      "learning_rate": 7.479173094723852e-06,
      "loss": 0.0,
      "step": 137810
    },
    {
      "epoch": 42.52391237272447,
      "grad_norm": 5.228129680290294e-07,
      "learning_rate": 7.476087627275533e-06,
      "loss": 0.0,
      "step": 137820
    },
    {
      "epoch": 42.52699784017278,
      "grad_norm": 1.497149924034602e-06,
      "learning_rate": 7.473002159827213e-06,
      "loss": 0.0,
      "step": 137830
    },
    {
      "epoch": 42.530083307621105,
      "grad_norm": 2.922020847506701e-09,
      "learning_rate": 7.469916692378897e-06,
      "loss": 0.0,
      "step": 137840
    },
    {
      "epoch": 42.53316877506942,
      "grad_norm": 1.2572018022183329e-06,
      "learning_rate": 7.4668312249305775e-06,
      "loss": 0.0,
      "step": 137850
    },
    {
      "epoch": 42.53625424251774,
      "grad_norm": 6.689849669783143e-07,
      "learning_rate": 7.463745757482258e-06,
      "loss": 0.0,
      "step": 137860
    },
    {
      "epoch": 42.53933970996606,
      "grad_norm": 1.7080104441902222e-08,
      "learning_rate": 7.460660290033941e-06,
      "loss": 0.0,
      "step": 137870
    },
    {
      "epoch": 42.54242517741438,
      "grad_norm": 1.2373543977737427,
      "learning_rate": 7.457574822585622e-06,
      "loss": 0.0009,
      "step": 137880
    },
    {
      "epoch": 42.545510644862695,
      "grad_norm": 2.3258410237758653e-06,
      "learning_rate": 7.454489355137303e-06,
      "loss": 0.0,
      "step": 137890
    },
    {
      "epoch": 42.54859611231102,
      "grad_norm": 4.875611466559349e-06,
      "learning_rate": 7.451403887688985e-06,
      "loss": 0.0,
      "step": 137900
    },
    {
      "epoch": 42.55168157975933,
      "grad_norm": 1.2664892210523249e-06,
      "learning_rate": 7.448318420240667e-06,
      "loss": 0.0,
      "step": 137910
    },
    {
      "epoch": 42.554767047207655,
      "grad_norm": 5.5090367823140696e-05,
      "learning_rate": 7.445232952792348e-06,
      "loss": 0.0,
      "step": 137920
    },
    {
      "epoch": 42.55785251465597,
      "grad_norm": 1.361377570674449e-07,
      "learning_rate": 7.44214748534403e-06,
      "loss": 0.0,
      "step": 137930
    },
    {
      "epoch": 42.56093798210429,
      "grad_norm": 1.105637875298271e-05,
      "learning_rate": 7.439062017895712e-06,
      "loss": 0.0,
      "step": 137940
    },
    {
      "epoch": 42.56402344955261,
      "grad_norm": 6.20531466211105e-07,
      "learning_rate": 7.435976550447393e-06,
      "loss": 0.0,
      "step": 137950
    },
    {
      "epoch": 42.56710891700092,
      "grad_norm": 4.216759407427162e-05,
      "learning_rate": 7.432891082999075e-06,
      "loss": 0.0,
      "step": 137960
    },
    {
      "epoch": 42.570194384449245,
      "grad_norm": 2.288530032146241e-09,
      "learning_rate": 7.429805615550755e-06,
      "loss": 0.0,
      "step": 137970
    },
    {
      "epoch": 42.57327985189756,
      "grad_norm": 1.3326404769031797e-05,
      "learning_rate": 7.426720148102438e-06,
      "loss": 0.0,
      "step": 137980
    },
    {
      "epoch": 42.57636531934588,
      "grad_norm": 2.8770679705303337e-07,
      "learning_rate": 7.4236346806541195e-06,
      "loss": 0.0,
      "step": 137990
    },
    {
      "epoch": 42.5794507867942,
      "grad_norm": 3.931979364324434e-08,
      "learning_rate": 7.4205492132058e-06,
      "loss": 0.0,
      "step": 138000
    },
    {
      "epoch": 42.58253625424252,
      "grad_norm": 1.6472793049615575e-06,
      "learning_rate": 7.417463745757483e-06,
      "loss": 0.0,
      "step": 138010
    },
    {
      "epoch": 42.585621721690835,
      "grad_norm": 6.4372630959042e-07,
      "learning_rate": 7.414378278309164e-06,
      "loss": 0.0,
      "step": 138020
    },
    {
      "epoch": 42.58870718913916,
      "grad_norm": 3.69363660865929e-05,
      "learning_rate": 7.411292810860845e-06,
      "loss": 0.0,
      "step": 138030
    },
    {
      "epoch": 42.59179265658747,
      "grad_norm": 3.106638146732621e-08,
      "learning_rate": 7.408207343412528e-06,
      "loss": 0.0,
      "step": 138040
    },
    {
      "epoch": 42.594878124035795,
      "grad_norm": 1.0029029908764642e-06,
      "learning_rate": 7.405121875964209e-06,
      "loss": 0.0,
      "step": 138050
    },
    {
      "epoch": 42.59796359148411,
      "grad_norm": 1.7558279068907723e-05,
      "learning_rate": 7.40203640851589e-06,
      "loss": 0.0,
      "step": 138060
    },
    {
      "epoch": 42.601049058932425,
      "grad_norm": 1.3255395060696173e-05,
      "learning_rate": 7.398950941067572e-06,
      "loss": 0.0,
      "step": 138070
    },
    {
      "epoch": 42.60413452638075,
      "grad_norm": 5.856302891515952e-07,
      "learning_rate": 7.395865473619254e-06,
      "loss": 0.0,
      "step": 138080
    },
    {
      "epoch": 42.60721999382906,
      "grad_norm": 0.0005124543677084148,
      "learning_rate": 7.392780006170935e-06,
      "loss": 0.0,
      "step": 138090
    },
    {
      "epoch": 42.610305461277385,
      "grad_norm": 1.5681082743412844e-07,
      "learning_rate": 7.3896945387226166e-06,
      "loss": 0.0001,
      "step": 138100
    },
    {
      "epoch": 42.6133909287257,
      "grad_norm": 4.900483574488135e-08,
      "learning_rate": 7.386609071274299e-06,
      "loss": 0.0,
      "step": 138110
    },
    {
      "epoch": 42.61647639617402,
      "grad_norm": 1.5648260465184194e-09,
      "learning_rate": 7.38352360382598e-06,
      "loss": 0.0,
      "step": 138120
    },
    {
      "epoch": 42.61956186362234,
      "grad_norm": 1.1175167855981272e-05,
      "learning_rate": 7.3804381363776614e-06,
      "loss": 0.0,
      "step": 138130
    },
    {
      "epoch": 42.62264733107066,
      "grad_norm": 4.4214648369234055e-05,
      "learning_rate": 7.377352668929344e-06,
      "loss": 0.0,
      "step": 138140
    },
    {
      "epoch": 42.625732798518975,
      "grad_norm": 3.083948467974551e-05,
      "learning_rate": 7.374267201481025e-06,
      "loss": 0.0,
      "step": 138150
    },
    {
      "epoch": 42.6288182659673,
      "grad_norm": 7.7823489164075e-07,
      "learning_rate": 7.371181734032706e-06,
      "loss": 0.0,
      "step": 138160
    },
    {
      "epoch": 42.63190373341561,
      "grad_norm": 4.330415581677016e-09,
      "learning_rate": 7.368096266584387e-06,
      "loss": 0.0,
      "step": 138170
    },
    {
      "epoch": 42.63498920086393,
      "grad_norm": 6.283937636908377e-08,
      "learning_rate": 7.36501079913607e-06,
      "loss": 0.0,
      "step": 138180
    },
    {
      "epoch": 42.63807466831225,
      "grad_norm": 0.0007919982308521867,
      "learning_rate": 7.361925331687751e-06,
      "loss": 0.0004,
      "step": 138190
    },
    {
      "epoch": 42.641160135760565,
      "grad_norm": 2.164171775120849e-08,
      "learning_rate": 7.358839864239432e-06,
      "loss": 0.0,
      "step": 138200
    },
    {
      "epoch": 42.64424560320889,
      "grad_norm": 6.335880708974173e-09,
      "learning_rate": 7.3557543967911145e-06,
      "loss": 0.0,
      "step": 138210
    },
    {
      "epoch": 42.6473310706572,
      "grad_norm": 4.850744250717298e-09,
      "learning_rate": 7.352668929342796e-06,
      "loss": 0.0,
      "step": 138220
    },
    {
      "epoch": 42.650416538105524,
      "grad_norm": 3.385952004464343e-05,
      "learning_rate": 7.349583461894477e-06,
      "loss": 0.0,
      "step": 138230
    },
    {
      "epoch": 42.65350200555384,
      "grad_norm": 1.1550577255547978e-05,
      "learning_rate": 7.346497994446159e-06,
      "loss": 0.0,
      "step": 138240
    },
    {
      "epoch": 42.65658747300216,
      "grad_norm": 1.6533363123016898e-07,
      "learning_rate": 7.343412526997841e-06,
      "loss": 0.0,
      "step": 138250
    },
    {
      "epoch": 42.65967294045048,
      "grad_norm": 2.729983066274144e-07,
      "learning_rate": 7.340327059549522e-06,
      "loss": 0.0,
      "step": 138260
    },
    {
      "epoch": 42.6627584078988,
      "grad_norm": 0.00013573173782788217,
      "learning_rate": 7.337241592101203e-06,
      "loss": 0.0,
      "step": 138270
    },
    {
      "epoch": 42.665843875347115,
      "grad_norm": 0.01576917991042137,
      "learning_rate": 7.334156124652886e-06,
      "loss": 0.0,
      "step": 138280
    },
    {
      "epoch": 42.66892934279544,
      "grad_norm": 1.4658381530807674e-07,
      "learning_rate": 7.331070657204567e-06,
      "loss": 0.0,
      "step": 138290
    },
    {
      "epoch": 42.67201481024375,
      "grad_norm": 6.085037806968785e-09,
      "learning_rate": 7.327985189756248e-06,
      "loss": 0.0,
      "step": 138300
    },
    {
      "epoch": 42.67510027769207,
      "grad_norm": 5.891445908901005e-08,
      "learning_rate": 7.324899722307931e-06,
      "loss": 0.0,
      "step": 138310
    },
    {
      "epoch": 42.67818574514039,
      "grad_norm": 2.4062879333541787e-07,
      "learning_rate": 7.3218142548596116e-06,
      "loss": 0.0,
      "step": 138320
    },
    {
      "epoch": 42.681271212588705,
      "grad_norm": 3.3030160011549015e-06,
      "learning_rate": 7.318728787411293e-06,
      "loss": 0.0,
      "step": 138330
    },
    {
      "epoch": 42.68435668003703,
      "grad_norm": 8.051026156863372e-08,
      "learning_rate": 7.315643319962976e-06,
      "loss": 0.0,
      "step": 138340
    },
    {
      "epoch": 42.68744214748534,
      "grad_norm": 4.792900199390715e-06,
      "learning_rate": 7.3125578525146565e-06,
      "loss": 0.0,
      "step": 138350
    },
    {
      "epoch": 42.690527614933664,
      "grad_norm": 1.1754074336067788e-07,
      "learning_rate": 7.309472385066338e-06,
      "loss": 0.0,
      "step": 138360
    },
    {
      "epoch": 42.69361308238198,
      "grad_norm": 9.584106010152027e-05,
      "learning_rate": 7.306386917618019e-06,
      "loss": 0.0,
      "step": 138370
    },
    {
      "epoch": 42.6966985498303,
      "grad_norm": 4.230780541547574e-05,
      "learning_rate": 7.303301450169701e-06,
      "loss": 0.0,
      "step": 138380
    },
    {
      "epoch": 42.69978401727862,
      "grad_norm": 0.00027153303381055593,
      "learning_rate": 7.300215982721383e-06,
      "loss": 0.0,
      "step": 138390
    },
    {
      "epoch": 42.70286948472694,
      "grad_norm": 3.079090404867202e-08,
      "learning_rate": 7.297130515273064e-06,
      "loss": 0.0,
      "step": 138400
    },
    {
      "epoch": 42.705954952175254,
      "grad_norm": 1.0649061010781224e-07,
      "learning_rate": 7.294045047824746e-06,
      "loss": 0.0,
      "step": 138410
    },
    {
      "epoch": 42.70904041962357,
      "grad_norm": 0.0065222508274018764,
      "learning_rate": 7.290959580376428e-06,
      "loss": 0.0,
      "step": 138420
    },
    {
      "epoch": 42.71212588707189,
      "grad_norm": 0.00010718726844061166,
      "learning_rate": 7.287874112928109e-06,
      "loss": 0.0,
      "step": 138430
    },
    {
      "epoch": 42.71521135452021,
      "grad_norm": 5.27464144397527e-05,
      "learning_rate": 7.284788645479791e-06,
      "loss": 0.0,
      "step": 138440
    },
    {
      "epoch": 42.71829682196853,
      "grad_norm": 7.024320680670826e-09,
      "learning_rate": 7.281703178031473e-06,
      "loss": 0.0,
      "step": 138450
    },
    {
      "epoch": 42.721382289416844,
      "grad_norm": 0.02501484379172325,
      "learning_rate": 7.2786177105831535e-06,
      "loss": 0.0,
      "step": 138460
    },
    {
      "epoch": 42.72446775686517,
      "grad_norm": 0.06697414070367813,
      "learning_rate": 7.275532243134834e-06,
      "loss": 0.0,
      "step": 138470
    },
    {
      "epoch": 42.72755322431348,
      "grad_norm": 1.2879218957095873e-05,
      "learning_rate": 7.272446775686517e-06,
      "loss": 0.0,
      "step": 138480
    },
    {
      "epoch": 42.730638691761804,
      "grad_norm": 8.705665095476434e-06,
      "learning_rate": 7.2693613082381984e-06,
      "loss": 0.0,
      "step": 138490
    },
    {
      "epoch": 42.73372415921012,
      "grad_norm": 0.0006001203437335789,
      "learning_rate": 7.266275840789879e-06,
      "loss": 0.0,
      "step": 138500
    },
    {
      "epoch": 42.73680962665844,
      "grad_norm": 3.067105353693478e-06,
      "learning_rate": 7.263190373341562e-06,
      "loss": 0.0,
      "step": 138510
    },
    {
      "epoch": 42.73989509410676,
      "grad_norm": 8.422130485996604e-05,
      "learning_rate": 7.260104905893243e-06,
      "loss": 0.0,
      "step": 138520
    },
    {
      "epoch": 42.74298056155508,
      "grad_norm": 6.906388989591505e-07,
      "learning_rate": 7.257019438444924e-06,
      "loss": 0.0,
      "step": 138530
    },
    {
      "epoch": 42.746066029003394,
      "grad_norm": 7.508373300879612e-07,
      "learning_rate": 7.253933970996607e-06,
      "loss": 0.0,
      "step": 138540
    },
    {
      "epoch": 42.74915149645171,
      "grad_norm": 0.00014932258636690676,
      "learning_rate": 7.250848503548288e-06,
      "loss": 0.0,
      "step": 138550
    },
    {
      "epoch": 42.75223696390003,
      "grad_norm": 8.330040145665407e-05,
      "learning_rate": 7.247763036099969e-06,
      "loss": 0.0,
      "step": 138560
    },
    {
      "epoch": 42.75532243134835,
      "grad_norm": 1.0852351124412962e-06,
      "learning_rate": 7.244677568651651e-06,
      "loss": 0.0,
      "step": 138570
    },
    {
      "epoch": 42.75840789879667,
      "grad_norm": 2.468844104441814e-05,
      "learning_rate": 7.241592101203333e-06,
      "loss": 0.0,
      "step": 138580
    },
    {
      "epoch": 42.761493366244984,
      "grad_norm": 6.596332582375908e-07,
      "learning_rate": 7.238506633755014e-06,
      "loss": 0.0,
      "step": 138590
    },
    {
      "epoch": 42.76457883369331,
      "grad_norm": 1.5529116353718564e-05,
      "learning_rate": 7.2354211663066955e-06,
      "loss": 0.0,
      "step": 138600
    },
    {
      "epoch": 42.76766430114162,
      "grad_norm": 1.0738673950072553e-08,
      "learning_rate": 7.232335698858378e-06,
      "loss": 0.0,
      "step": 138610
    },
    {
      "epoch": 42.770749768589944,
      "grad_norm": 3.240060948428436e-07,
      "learning_rate": 7.229250231410059e-06,
      "loss": 0.0,
      "step": 138620
    },
    {
      "epoch": 42.77383523603826,
      "grad_norm": 8.083409284154186e-07,
      "learning_rate": 7.22616476396174e-06,
      "loss": 0.0,
      "step": 138630
    },
    {
      "epoch": 42.77692070348658,
      "grad_norm": 1.1957695278397296e-08,
      "learning_rate": 7.223079296513423e-06,
      "loss": 0.0,
      "step": 138640
    },
    {
      "epoch": 42.7800061709349,
      "grad_norm": 5.433968908619136e-06,
      "learning_rate": 7.219993829065104e-06,
      "loss": 0.0,
      "step": 138650
    },
    {
      "epoch": 42.78309163838321,
      "grad_norm": 7.618985478075047e-07,
      "learning_rate": 7.216908361616785e-06,
      "loss": 0.0,
      "step": 138660
    },
    {
      "epoch": 42.786177105831534,
      "grad_norm": 2.3603726972964978e-08,
      "learning_rate": 7.213822894168466e-06,
      "loss": 0.0,
      "step": 138670
    },
    {
      "epoch": 42.78926257327985,
      "grad_norm": 2.1778773771075066e-06,
      "learning_rate": 7.2107374267201486e-06,
      "loss": 0.0,
      "step": 138680
    },
    {
      "epoch": 42.79234804072817,
      "grad_norm": 2.9577423177329365e-08,
      "learning_rate": 7.20765195927183e-06,
      "loss": 0.0,
      "step": 138690
    },
    {
      "epoch": 42.79543350817649,
      "grad_norm": 9.117101740230282e-07,
      "learning_rate": 7.204566491823511e-06,
      "loss": 0.0,
      "step": 138700
    },
    {
      "epoch": 42.79851897562481,
      "grad_norm": 2.5842405193543527e-07,
      "learning_rate": 7.2014810243751934e-06,
      "loss": 0.0,
      "step": 138710
    },
    {
      "epoch": 42.801604443073124,
      "grad_norm": 9.669396604294889e-06,
      "learning_rate": 7.198395556926875e-06,
      "loss": 0.0,
      "step": 138720
    },
    {
      "epoch": 42.80468991052145,
      "grad_norm": 7.580333090118074e-07,
      "learning_rate": 7.195310089478556e-06,
      "loss": 0.0,
      "step": 138730
    },
    {
      "epoch": 42.80777537796976,
      "grad_norm": 0.00035500634112395346,
      "learning_rate": 7.192224622030238e-06,
      "loss": 0.0,
      "step": 138740
    },
    {
      "epoch": 42.810860845418084,
      "grad_norm": 1.7204573765638997e-08,
      "learning_rate": 7.18913915458192e-06,
      "loss": 0.0001,
      "step": 138750
    },
    {
      "epoch": 42.8139463128664,
      "grad_norm": 1.613184963389358e-06,
      "learning_rate": 7.186053687133601e-06,
      "loss": 0.0,
      "step": 138760
    },
    {
      "epoch": 42.817031780314714,
      "grad_norm": 5.076841489426442e-07,
      "learning_rate": 7.182968219685282e-06,
      "loss": 0.0,
      "step": 138770
    },
    {
      "epoch": 42.82011724776304,
      "grad_norm": 0.0019204637501388788,
      "learning_rate": 7.179882752236965e-06,
      "loss": 0.0,
      "step": 138780
    },
    {
      "epoch": 42.82320271521135,
      "grad_norm": 3.224720899197564e-07,
      "learning_rate": 7.176797284788646e-06,
      "loss": 0.0,
      "step": 138790
    },
    {
      "epoch": 42.826288182659674,
      "grad_norm": 2.0471170500968583e-06,
      "learning_rate": 7.173711817340327e-06,
      "loss": 0.0,
      "step": 138800
    },
    {
      "epoch": 42.82937365010799,
      "grad_norm": 8.424276529694907e-06,
      "learning_rate": 7.17062634989201e-06,
      "loss": 0.0,
      "step": 138810
    },
    {
      "epoch": 42.83245911755631,
      "grad_norm": 6.699981895508245e-05,
      "learning_rate": 7.1675408824436905e-06,
      "loss": 0.0,
      "step": 138820
    },
    {
      "epoch": 42.83554458500463,
      "grad_norm": 9.39786605158588e-06,
      "learning_rate": 7.164455414995372e-06,
      "loss": 0.0,
      "step": 138830
    },
    {
      "epoch": 42.83863005245295,
      "grad_norm": 2.523246322994055e-08,
      "learning_rate": 7.161369947547053e-06,
      "loss": 0.0,
      "step": 138840
    },
    {
      "epoch": 42.841715519901264,
      "grad_norm": 4.501618633412363e-09,
      "learning_rate": 7.158284480098735e-06,
      "loss": 0.0,
      "step": 138850
    },
    {
      "epoch": 42.844800987349586,
      "grad_norm": 0.022102901712059975,
      "learning_rate": 7.155199012650417e-06,
      "loss": 0.0,
      "step": 138860
    },
    {
      "epoch": 42.8478864547979,
      "grad_norm": 7.796894578859792e-07,
      "learning_rate": 7.152113545202098e-06,
      "loss": 0.0,
      "step": 138870
    },
    {
      "epoch": 42.850971922246224,
      "grad_norm": 6.938931164768292e-06,
      "learning_rate": 7.14902807775378e-06,
      "loss": 0.0,
      "step": 138880
    },
    {
      "epoch": 42.85405738969454,
      "grad_norm": 0.012815482914447784,
      "learning_rate": 7.145942610305462e-06,
      "loss": 0.0,
      "step": 138890
    },
    {
      "epoch": 42.857142857142854,
      "grad_norm": 2.568452117657216e-08,
      "learning_rate": 7.142857142857143e-06,
      "loss": 0.0,
      "step": 138900
    },
    {
      "epoch": 42.860228324591176,
      "grad_norm": 2.144113523172564e-06,
      "learning_rate": 7.139771675408825e-06,
      "loss": 0.0,
      "step": 138910
    },
    {
      "epoch": 42.86331379203949,
      "grad_norm": 0.00019856671860907227,
      "learning_rate": 7.136686207960507e-06,
      "loss": 0.0,
      "step": 138920
    },
    {
      "epoch": 42.866399259487814,
      "grad_norm": 4.72377223559306e-07,
      "learning_rate": 7.133600740512188e-06,
      "loss": 0.0,
      "step": 138930
    },
    {
      "epoch": 42.86948472693613,
      "grad_norm": 4.800839633389842e-06,
      "learning_rate": 7.130515273063869e-06,
      "loss": 0.0,
      "step": 138940
    },
    {
      "epoch": 42.87257019438445,
      "grad_norm": 4.507551420829259e-05,
      "learning_rate": 7.127429805615552e-06,
      "loss": 0.0,
      "step": 138950
    },
    {
      "epoch": 42.875655661832766,
      "grad_norm": 3.6459380226006033e-07,
      "learning_rate": 7.1243443381672325e-06,
      "loss": 0.0,
      "step": 138960
    },
    {
      "epoch": 42.87874112928109,
      "grad_norm": 7.589422423848191e-09,
      "learning_rate": 7.121258870718914e-06,
      "loss": 0.0,
      "step": 138970
    },
    {
      "epoch": 42.881826596729404,
      "grad_norm": 0.07103227823972702,
      "learning_rate": 7.118173403270597e-06,
      "loss": 0.0,
      "step": 138980
    },
    {
      "epoch": 42.884912064177726,
      "grad_norm": 1.5971111224644119e-06,
      "learning_rate": 7.115087935822277e-06,
      "loss": 0.0,
      "step": 138990
    },
    {
      "epoch": 42.88799753162604,
      "grad_norm": 4.2989628127543256e-05,
      "learning_rate": 7.112002468373959e-06,
      "loss": 0.0,
      "step": 139000
    },
    {
      "epoch": 42.89108299907436,
      "grad_norm": 3.2939809102572326e-07,
      "learning_rate": 7.1089170009256415e-06,
      "loss": 0.0,
      "step": 139010
    },
    {
      "epoch": 42.89416846652268,
      "grad_norm": 1.692652745077794e-06,
      "learning_rate": 7.105831533477322e-06,
      "loss": 0.0,
      "step": 139020
    },
    {
      "epoch": 42.897253933970994,
      "grad_norm": 3.980485274723833e-08,
      "learning_rate": 7.102746066029004e-06,
      "loss": 0.0,
      "step": 139030
    },
    {
      "epoch": 42.900339401419316,
      "grad_norm": 9.928977306117304e-06,
      "learning_rate": 7.099660598580685e-06,
      "loss": 0.0,
      "step": 139040
    },
    {
      "epoch": 42.90342486886763,
      "grad_norm": 0.00010192037734668702,
      "learning_rate": 7.096575131132367e-06,
      "loss": 0.0,
      "step": 139050
    },
    {
      "epoch": 42.906510336315954,
      "grad_norm": 1.3798768350170576e-06,
      "learning_rate": 7.093489663684049e-06,
      "loss": 0.0,
      "step": 139060
    },
    {
      "epoch": 42.90959580376427,
      "grad_norm": 2.0873740425031428e-07,
      "learning_rate": 7.09040419623573e-06,
      "loss": 0.0,
      "step": 139070
    },
    {
      "epoch": 42.91268127121259,
      "grad_norm": 6.448157563454515e-08,
      "learning_rate": 7.087318728787412e-06,
      "loss": 0.0,
      "step": 139080
    },
    {
      "epoch": 42.915766738660906,
      "grad_norm": 0.00032376692979596555,
      "learning_rate": 7.084233261339094e-06,
      "loss": 0.0,
      "step": 139090
    },
    {
      "epoch": 42.91885220610923,
      "grad_norm": 1.1113892242065049e-06,
      "learning_rate": 7.0811477938907745e-06,
      "loss": 0.0,
      "step": 139100
    },
    {
      "epoch": 42.921937673557544,
      "grad_norm": 4.0735312722972594e-07,
      "learning_rate": 7.078062326442457e-06,
      "loss": 0.0,
      "step": 139110
    },
    {
      "epoch": 42.92502314100586,
      "grad_norm": 3.976706182129419e-07,
      "learning_rate": 7.074976858994138e-06,
      "loss": 0.0,
      "step": 139120
    },
    {
      "epoch": 42.92810860845418,
      "grad_norm": 3.0447338872363616e-07,
      "learning_rate": 7.071891391545819e-06,
      "loss": 0.0,
      "step": 139130
    },
    {
      "epoch": 42.931194075902496,
      "grad_norm": 3.953340637963265e-06,
      "learning_rate": 7.0688059240975e-06,
      "loss": 0.0,
      "step": 139140
    },
    {
      "epoch": 42.93427954335082,
      "grad_norm": 6.231508677956299e-07,
      "learning_rate": 7.065720456649183e-06,
      "loss": 0.0,
      "step": 139150
    },
    {
      "epoch": 42.937365010799134,
      "grad_norm": 0.00013783820031676441,
      "learning_rate": 7.062634989200864e-06,
      "loss": 0.0,
      "step": 139160
    },
    {
      "epoch": 42.940450478247456,
      "grad_norm": 6.268889410421252e-05,
      "learning_rate": 7.059549521752545e-06,
      "loss": 0.0,
      "step": 139170
    },
    {
      "epoch": 42.94353594569577,
      "grad_norm": 0.0001379043242195621,
      "learning_rate": 7.0564640543042275e-06,
      "loss": 0.0,
      "step": 139180
    },
    {
      "epoch": 42.94662141314409,
      "grad_norm": 1.8404498405288905e-05,
      "learning_rate": 7.053378586855909e-06,
      "loss": 0.0,
      "step": 139190
    },
    {
      "epoch": 42.94970688059241,
      "grad_norm": 2.0610773532325766e-08,
      "learning_rate": 7.05029311940759e-06,
      "loss": 0.0,
      "step": 139200
    },
    {
      "epoch": 42.95279234804073,
      "grad_norm": 8.434458891315444e-07,
      "learning_rate": 7.047207651959272e-06,
      "loss": 0.0,
      "step": 139210
    },
    {
      "epoch": 42.955877815489046,
      "grad_norm": 5.503561169462046e-06,
      "learning_rate": 7.044122184510954e-06,
      "loss": 0.0,
      "step": 139220
    },
    {
      "epoch": 42.95896328293737,
      "grad_norm": 2.226830110885203e-05,
      "learning_rate": 7.041036717062635e-06,
      "loss": 0.0,
      "step": 139230
    },
    {
      "epoch": 42.962048750385684,
      "grad_norm": 1.4167231938699842e-06,
      "learning_rate": 7.0379512496143164e-06,
      "loss": 0.0,
      "step": 139240
    },
    {
      "epoch": 42.965134217834,
      "grad_norm": 3.33918364958663e-07,
      "learning_rate": 7.034865782165999e-06,
      "loss": 0.0,
      "step": 139250
    },
    {
      "epoch": 42.96821968528232,
      "grad_norm": 1.5953004250945924e-08,
      "learning_rate": 7.03178031471768e-06,
      "loss": 0.0,
      "step": 139260
    },
    {
      "epoch": 42.971305152730636,
      "grad_norm": 0.0009297870565205812,
      "learning_rate": 7.028694847269361e-06,
      "loss": 0.0,
      "step": 139270
    },
    {
      "epoch": 42.97439062017896,
      "grad_norm": 2.2726950987816963e-07,
      "learning_rate": 7.025609379821044e-06,
      "loss": 0.0,
      "step": 139280
    },
    {
      "epoch": 42.977476087627274,
      "grad_norm": 2.5334414566202668e-09,
      "learning_rate": 7.022523912372725e-06,
      "loss": 0.0,
      "step": 139290
    },
    {
      "epoch": 42.980561555075596,
      "grad_norm": 7.496370635351468e-09,
      "learning_rate": 7.019438444924406e-06,
      "loss": 0.0,
      "step": 139300
    },
    {
      "epoch": 42.98364702252391,
      "grad_norm": 1.827399920273365e-08,
      "learning_rate": 7.016352977476089e-06,
      "loss": 0.0,
      "step": 139310
    },
    {
      "epoch": 42.98673248997223,
      "grad_norm": 4.0566152392784716e-07,
      "learning_rate": 7.0132675100277695e-06,
      "loss": 0.0,
      "step": 139320
    },
    {
      "epoch": 42.98981795742055,
      "grad_norm": 3.259075924688659e-07,
      "learning_rate": 7.010182042579451e-06,
      "loss": 0.0,
      "step": 139330
    },
    {
      "epoch": 42.99290342486887,
      "grad_norm": 0.00018568677478469908,
      "learning_rate": 7.007096575131132e-06,
      "loss": 0.0,
      "step": 139340
    },
    {
      "epoch": 42.995988892317186,
      "grad_norm": 3.5268064948468236e-06,
      "learning_rate": 7.004011107682814e-06,
      "loss": 0.0,
      "step": 139350
    },
    {
      "epoch": 42.9990743597655,
      "grad_norm": 5.909357423661277e-05,
      "learning_rate": 7.000925640234496e-06,
      "loss": 0.0,
      "step": 139360
    },
    {
      "epoch": 43.0,
      "eval_accuracy_branch1": 1.0,
      "eval_accuracy_branch2": 0.4072798819478603,
      "eval_f1_branch1": 1.0,
      "eval_f1_branch2": 0.3991069411149816,
      "eval_loss": 3.652986890756438e-07,
      "eval_precision_branch1": 1.0,
      "eval_precision_branch2": 0.5025189717420931,
      "eval_recall_branch1": 1.0,
      "eval_recall_branch2": 0.5019241341396372,
      "eval_runtime": 239.1626,
      "eval_samples_per_second": 433.525,
      "eval_steps_per_second": 54.193,
      "step": 139363
    },
    {
      "epoch": 43.00215982721382,
      "grad_norm": 4.7401396585655675e-08,
      "learning_rate": 6.997840172786177e-06,
      "loss": 0.0,
      "step": 139370
    },
    {
      "epoch": 43.00524529466214,
      "grad_norm": 6.438367705641213e-08,
      "learning_rate": 6.994754705337859e-06,
      "loss": 0.0,
      "step": 139380
    },
    {
      "epoch": 43.00833076211046,
      "grad_norm": 1.2743610966481356e-07,
      "learning_rate": 6.991669237889541e-06,
      "loss": 0.0,
      "step": 139390
    },
    {
      "epoch": 43.011416229558776,
      "grad_norm": 1.7257688966765272e-07,
      "learning_rate": 6.988583770441222e-06,
      "loss": 0.0,
      "step": 139400
    },
    {
      "epoch": 43.0145016970071,
      "grad_norm": 3.5216330616094638e-06,
      "learning_rate": 6.985498302992904e-06,
      "loss": 0.0,
      "step": 139410
    },
    {
      "epoch": 43.01758716445541,
      "grad_norm": 2.6969882327421146e-08,
      "learning_rate": 6.982412835544586e-06,
      "loss": 0.0,
      "step": 139420
    },
    {
      "epoch": 43.020672631903736,
      "grad_norm": 1.3440070389947323e-08,
      "learning_rate": 6.9793273680962666e-06,
      "loss": 0.0,
      "step": 139430
    },
    {
      "epoch": 43.02375809935205,
      "grad_norm": 2.282941522935289e-06,
      "learning_rate": 6.976241900647948e-06,
      "loss": 0.0,
      "step": 139440
    },
    {
      "epoch": 43.02684356680037,
      "grad_norm": 1.0266787420221135e-08,
      "learning_rate": 6.973156433199631e-06,
      "loss": 0.0,
      "step": 139450
    },
    {
      "epoch": 43.02992903424869,
      "grad_norm": 4.279879249224905e-06,
      "learning_rate": 6.9700709657513115e-06,
      "loss": 0.0,
      "step": 139460
    },
    {
      "epoch": 43.033014501697004,
      "grad_norm": 9.103392244469433e-07,
      "learning_rate": 6.966985498302993e-06,
      "loss": 0.0,
      "step": 139470
    },
    {
      "epoch": 43.036099969145326,
      "grad_norm": 2.8661013857345097e-05,
      "learning_rate": 6.9639000308546756e-06,
      "loss": 0.0,
      "step": 139480
    },
    {
      "epoch": 43.03918543659364,
      "grad_norm": 5.715037776354848e-09,
      "learning_rate": 6.960814563406356e-06,
      "loss": 0.0,
      "step": 139490
    },
    {
      "epoch": 43.04227090404196,
      "grad_norm": 9.487036578548214e-08,
      "learning_rate": 6.957729095958038e-06,
      "loss": 0.0,
      "step": 139500
    },
    {
      "epoch": 43.04535637149028,
      "grad_norm": 4.34695539297536e-06,
      "learning_rate": 6.9546436285097204e-06,
      "loss": 0.0,
      "step": 139510
    },
    {
      "epoch": 43.0484418389386,
      "grad_norm": 7.360831659752876e-05,
      "learning_rate": 6.951558161061401e-06,
      "loss": 0.0,
      "step": 139520
    },
    {
      "epoch": 43.051527306386916,
      "grad_norm": 1.257069470739225e-08,
      "learning_rate": 6.948472693613083e-06,
      "loss": 0.0,
      "step": 139530
    },
    {
      "epoch": 43.05461277383524,
      "grad_norm": 3.825439165439093e-08,
      "learning_rate": 6.945387226164764e-06,
      "loss": 0.0,
      "step": 139540
    },
    {
      "epoch": 43.05769824128355,
      "grad_norm": 3.974938408646267e-06,
      "learning_rate": 6.942301758716446e-06,
      "loss": 0.0,
      "step": 139550
    },
    {
      "epoch": 43.060783708731876,
      "grad_norm": 0.03941096365451813,
      "learning_rate": 6.939216291268128e-06,
      "loss": 0.0,
      "step": 139560
    },
    {
      "epoch": 43.06386917618019,
      "grad_norm": 3.841181239749858e-07,
      "learning_rate": 6.9361308238198085e-06,
      "loss": 0.0,
      "step": 139570
    },
    {
      "epoch": 43.06695464362851,
      "grad_norm": 2.118585973320819e-09,
      "learning_rate": 6.933045356371491e-06,
      "loss": 0.0,
      "step": 139580
    },
    {
      "epoch": 43.07004011107683,
      "grad_norm": 3.1303061405196786e-06,
      "learning_rate": 6.929959888923173e-06,
      "loss": 0.0,
      "step": 139590
    },
    {
      "epoch": 43.07312557852514,
      "grad_norm": 1.9026721531645308e-07,
      "learning_rate": 6.9268744214748534e-06,
      "loss": 0.0,
      "step": 139600
    },
    {
      "epoch": 43.076211045973466,
      "grad_norm": 4.83883333401991e-09,
      "learning_rate": 6.923788954026536e-06,
      "loss": 0.0,
      "step": 139610
    },
    {
      "epoch": 43.07929651342178,
      "grad_norm": 3.391416782960732e-07,
      "learning_rate": 6.9207034865782175e-06,
      "loss": 0.0,
      "step": 139620
    },
    {
      "epoch": 43.0823819808701,
      "grad_norm": 9.685449185781181e-05,
      "learning_rate": 6.917618019129898e-06,
      "loss": 0.0,
      "step": 139630
    },
    {
      "epoch": 43.08546744831842,
      "grad_norm": 1.0100262670675875e-06,
      "learning_rate": 6.91453255168158e-06,
      "loss": 0.0,
      "step": 139640
    },
    {
      "epoch": 43.08855291576674,
      "grad_norm": 2.4843908263960657e-08,
      "learning_rate": 6.911447084233262e-06,
      "loss": 0.0,
      "step": 139650
    },
    {
      "epoch": 43.091638383215056,
      "grad_norm": 1.2822901851450297e-07,
      "learning_rate": 6.908361616784943e-06,
      "loss": 0.0,
      "step": 139660
    },
    {
      "epoch": 43.09472385066338,
      "grad_norm": 4.799499038199428e-07,
      "learning_rate": 6.905276149336625e-06,
      "loss": 0.0,
      "step": 139670
    },
    {
      "epoch": 43.09780931811169,
      "grad_norm": 0.00012464991596061736,
      "learning_rate": 6.902190681888307e-06,
      "loss": 0.0,
      "step": 139680
    },
    {
      "epoch": 43.100894785560016,
      "grad_norm": 0.00020067540754098445,
      "learning_rate": 6.899105214439988e-06,
      "loss": 0.0,
      "step": 139690
    },
    {
      "epoch": 43.10398025300833,
      "grad_norm": 1.8708836702074905e-09,
      "learning_rate": 6.89601974699167e-06,
      "loss": 0.0,
      "step": 139700
    },
    {
      "epoch": 43.107065720456646,
      "grad_norm": 2.391387283751101e-07,
      "learning_rate": 6.8929342795433505e-06,
      "loss": 0.0,
      "step": 139710
    },
    {
      "epoch": 43.11015118790497,
      "grad_norm": 2.4638689311018425e-08,
      "learning_rate": 6.889848812095033e-06,
      "loss": 0.0,
      "step": 139720
    },
    {
      "epoch": 43.11323665535328,
      "grad_norm": 1.080228457794874e-06,
      "learning_rate": 6.886763344646714e-06,
      "loss": 0.0,
      "step": 139730
    },
    {
      "epoch": 43.116322122801606,
      "grad_norm": 5.017267176299356e-05,
      "learning_rate": 6.883677877198395e-06,
      "loss": 0.0,
      "step": 139740
    },
    {
      "epoch": 43.11940759024992,
      "grad_norm": 9.731035243021324e-05,
      "learning_rate": 6.880592409750078e-06,
      "loss": 0.0,
      "step": 139750
    },
    {
      "epoch": 43.12249305769824,
      "grad_norm": 1.974783003788616e-09,
      "learning_rate": 6.877506942301759e-06,
      "loss": 0.0,
      "step": 139760
    },
    {
      "epoch": 43.12557852514656,
      "grad_norm": 5.133061335982347e-07,
      "learning_rate": 6.87442147485344e-06,
      "loss": 0.0,
      "step": 139770
    },
    {
      "epoch": 43.12866399259488,
      "grad_norm": 1.1738680768758059e-05,
      "learning_rate": 6.871336007405123e-06,
      "loss": 0.0,
      "step": 139780
    },
    {
      "epoch": 43.131749460043196,
      "grad_norm": 1.1055811377502778e-08,
      "learning_rate": 6.8682505399568035e-06,
      "loss": 0.0,
      "step": 139790
    },
    {
      "epoch": 43.13483492749152,
      "grad_norm": 7.63505304348655e-05,
      "learning_rate": 6.865165072508485e-06,
      "loss": 0.0,
      "step": 139800
    },
    {
      "epoch": 43.13792039493983,
      "grad_norm": 4.579769452561777e-08,
      "learning_rate": 6.862079605060166e-06,
      "loss": 0.0,
      "step": 139810
    },
    {
      "epoch": 43.14100586238815,
      "grad_norm": 0.00268775736913085,
      "learning_rate": 6.8589941376118484e-06,
      "loss": 0.0,
      "step": 139820
    },
    {
      "epoch": 43.14409132983647,
      "grad_norm": 6.110087156230293e-07,
      "learning_rate": 6.85590867016353e-06,
      "loss": 0.0,
      "step": 139830
    },
    {
      "epoch": 43.147176797284786,
      "grad_norm": 6.758510551208019e-08,
      "learning_rate": 6.852823202715211e-06,
      "loss": 0.0,
      "step": 139840
    },
    {
      "epoch": 43.15026226473311,
      "grad_norm": 1.1051341175516427e-07,
      "learning_rate": 6.849737735266893e-06,
      "loss": 0.0,
      "step": 139850
    },
    {
      "epoch": 43.15334773218142,
      "grad_norm": 0.00011895052739419043,
      "learning_rate": 6.846652267818575e-06,
      "loss": 0.0,
      "step": 139860
    },
    {
      "epoch": 43.156433199629745,
      "grad_norm": 1.801582402549684e-05,
      "learning_rate": 6.843566800370256e-06,
      "loss": 0.0,
      "step": 139870
    },
    {
      "epoch": 43.15951866707806,
      "grad_norm": 2.5309966076747514e-05,
      "learning_rate": 6.840481332921938e-06,
      "loss": 0.0,
      "step": 139880
    },
    {
      "epoch": 43.16260413452638,
      "grad_norm": 5.0795537390513346e-05,
      "learning_rate": 6.83739586547362e-06,
      "loss": 0.0,
      "step": 139890
    },
    {
      "epoch": 43.1656896019747,
      "grad_norm": 1.0222970558970701e-05,
      "learning_rate": 6.834310398025301e-06,
      "loss": 0.0,
      "step": 139900
    },
    {
      "epoch": 43.16877506942302,
      "grad_norm": 3.4924423744087107e-06,
      "learning_rate": 6.831224930576982e-06,
      "loss": 0.0,
      "step": 139910
    },
    {
      "epoch": 43.171860536871336,
      "grad_norm": 2.313151448163353e-09,
      "learning_rate": 6.828139463128665e-06,
      "loss": 0.0,
      "step": 139920
    },
    {
      "epoch": 43.17494600431966,
      "grad_norm": 7.082908126676557e-08,
      "learning_rate": 6.8250539956803455e-06,
      "loss": 0.0,
      "step": 139930
    },
    {
      "epoch": 43.17803147176797,
      "grad_norm": 5.838274432790058e-07,
      "learning_rate": 6.821968528232027e-06,
      "loss": 0.0,
      "step": 139940
    },
    {
      "epoch": 43.18111693921629,
      "grad_norm": 6.826394951531256e-07,
      "learning_rate": 6.81888306078371e-06,
      "loss": 0.0,
      "step": 139950
    },
    {
      "epoch": 43.18420240666461,
      "grad_norm": 9.402464229424368e-07,
      "learning_rate": 6.81579759333539e-06,
      "loss": 0.0,
      "step": 139960
    },
    {
      "epoch": 43.187287874112926,
      "grad_norm": 3.338212081871461e-06,
      "learning_rate": 6.812712125887072e-06,
      "loss": 0.0,
      "step": 139970
    },
    {
      "epoch": 43.19037334156125,
      "grad_norm": 8.732180276638246e-07,
      "learning_rate": 6.8096266584387545e-06,
      "loss": 0.0,
      "step": 139980
    },
    {
      "epoch": 43.19345880900956,
      "grad_norm": 2.382967601022301e-09,
      "learning_rate": 6.806541190990435e-06,
      "loss": 0.0,
      "step": 139990
    },
    {
      "epoch": 43.196544276457885,
      "grad_norm": 1.979909427518578e-07,
      "learning_rate": 6.803455723542117e-06,
      "loss": 0.0,
      "step": 140000
    },
    {
      "epoch": 43.1996297439062,
      "grad_norm": 1.4163252615162492e-07,
      "learning_rate": 6.800370256093798e-06,
      "loss": 0.0,
      "step": 140010
    },
    {
      "epoch": 43.20271521135452,
      "grad_norm": 4.361767878435785e-06,
      "learning_rate": 6.79728478864548e-06,
      "loss": 0.0,
      "step": 140020
    },
    {
      "epoch": 43.20580067880284,
      "grad_norm": 2.8409976948751137e-07,
      "learning_rate": 6.794199321197162e-06,
      "loss": 0.0,
      "step": 140030
    },
    {
      "epoch": 43.20888614625116,
      "grad_norm": 1.2658190051695328e-08,
      "learning_rate": 6.791113853748843e-06,
      "loss": 0.0,
      "step": 140040
    },
    {
      "epoch": 43.211971613699475,
      "grad_norm": 1.5663927115383558e-06,
      "learning_rate": 6.788028386300525e-06,
      "loss": 0.0,
      "step": 140050
    },
    {
      "epoch": 43.21505708114779,
      "grad_norm": 8.71752980913243e-09,
      "learning_rate": 6.784942918852207e-06,
      "loss": 0.0,
      "step": 140060
    },
    {
      "epoch": 43.21814254859611,
      "grad_norm": 1.7102296396842576e-06,
      "learning_rate": 6.7818574514038875e-06,
      "loss": 0.0,
      "step": 140070
    },
    {
      "epoch": 43.22122801604443,
      "grad_norm": 5.443791337711446e-07,
      "learning_rate": 6.77877198395557e-06,
      "loss": 0.0,
      "step": 140080
    },
    {
      "epoch": 43.22431348349275,
      "grad_norm": 9.468104522625254e-09,
      "learning_rate": 6.775686516507252e-06,
      "loss": 0.0,
      "step": 140090
    },
    {
      "epoch": 43.227398950941065,
      "grad_norm": 4.204341337299411e-07,
      "learning_rate": 6.772601049058932e-06,
      "loss": 0.0,
      "step": 140100
    },
    {
      "epoch": 43.23048441838939,
      "grad_norm": 0.06361837685108185,
      "learning_rate": 6.769515581610614e-06,
      "loss": 0.0,
      "step": 140110
    },
    {
      "epoch": 43.2335698858377,
      "grad_norm": 1.2088222867134846e-08,
      "learning_rate": 6.7664301141622965e-06,
      "loss": 0.0,
      "step": 140120
    },
    {
      "epoch": 43.236655353286025,
      "grad_norm": 1.5598885738654644e-06,
      "learning_rate": 6.763344646713977e-06,
      "loss": 0.0,
      "step": 140130
    },
    {
      "epoch": 43.23974082073434,
      "grad_norm": 1.9425195205258206e-05,
      "learning_rate": 6.760259179265659e-06,
      "loss": 0.0,
      "step": 140140
    },
    {
      "epoch": 43.24282628818266,
      "grad_norm": 5.980350579193328e-07,
      "learning_rate": 6.757173711817341e-06,
      "loss": 0.0,
      "step": 140150
    },
    {
      "epoch": 43.24591175563098,
      "grad_norm": 4.202510808681836e-06,
      "learning_rate": 6.754088244369022e-06,
      "loss": 0.0,
      "step": 140160
    },
    {
      "epoch": 43.2489972230793,
      "grad_norm": 2.3551213246264524e-07,
      "learning_rate": 6.751002776920704e-06,
      "loss": 0.0,
      "step": 140170
    },
    {
      "epoch": 43.252082690527615,
      "grad_norm": 4.7176319640129805e-05,
      "learning_rate": 6.747917309472386e-06,
      "loss": 0.0001,
      "step": 140180
    },
    {
      "epoch": 43.25516815797593,
      "grad_norm": 2.4782334548945073e-06,
      "learning_rate": 6.744831842024067e-06,
      "loss": 0.0,
      "step": 140190
    },
    {
      "epoch": 43.25825362542425,
      "grad_norm": 8.901342880562879e-07,
      "learning_rate": 6.741746374575749e-06,
      "loss": 0.0,
      "step": 140200
    },
    {
      "epoch": 43.26133909287257,
      "grad_norm": 9.659697042252446e-09,
      "learning_rate": 6.7386609071274295e-06,
      "loss": 0.0,
      "step": 140210
    },
    {
      "epoch": 43.26442456032089,
      "grad_norm": 2.0064323535962103e-08,
      "learning_rate": 6.735575439679112e-06,
      "loss": 0.0,
      "step": 140220
    },
    {
      "epoch": 43.267510027769205,
      "grad_norm": 0.0021478780545294285,
      "learning_rate": 6.7324899722307936e-06,
      "loss": 0.0,
      "step": 140230
    },
    {
      "epoch": 43.27059549521753,
      "grad_norm": 7.664874283364043e-05,
      "learning_rate": 6.729404504782474e-06,
      "loss": 0.0,
      "step": 140240
    },
    {
      "epoch": 43.27368096266584,
      "grad_norm": 4.264980191237555e-07,
      "learning_rate": 6.726319037334157e-06,
      "loss": 0.0,
      "step": 140250
    },
    {
      "epoch": 43.276766430114165,
      "grad_norm": 4.365204858913785e-06,
      "learning_rate": 6.7232335698858385e-06,
      "loss": 0.0,
      "step": 140260
    },
    {
      "epoch": 43.27985189756248,
      "grad_norm": 1.9936009266530164e-05,
      "learning_rate": 6.720148102437519e-06,
      "loss": 0.0,
      "step": 140270
    },
    {
      "epoch": 43.2829373650108,
      "grad_norm": 4.733820446745085e-08,
      "learning_rate": 6.717062634989202e-06,
      "loss": 0.0,
      "step": 140280
    },
    {
      "epoch": 43.28602283245912,
      "grad_norm": 4.509204387659338e-08,
      "learning_rate": 6.713977167540883e-06,
      "loss": 0.0,
      "step": 140290
    },
    {
      "epoch": 43.28910829990743,
      "grad_norm": 2.8271904284338234e-07,
      "learning_rate": 6.710891700092564e-06,
      "loss": 0.0,
      "step": 140300
    },
    {
      "epoch": 43.292193767355755,
      "grad_norm": 2.091281658067601e-06,
      "learning_rate": 6.707806232644246e-06,
      "loss": 0.0,
      "step": 140310
    },
    {
      "epoch": 43.29527923480407,
      "grad_norm": 6.65065017528832e-05,
      "learning_rate": 6.704720765195928e-06,
      "loss": 0.0,
      "step": 140320
    },
    {
      "epoch": 43.29836470225239,
      "grad_norm": 1.0282309226283814e-08,
      "learning_rate": 6.701635297747609e-06,
      "loss": 0.0,
      "step": 140330
    },
    {
      "epoch": 43.30145016970071,
      "grad_norm": 0.0003330887120682746,
      "learning_rate": 6.698549830299291e-06,
      "loss": 0.0,
      "step": 140340
    },
    {
      "epoch": 43.30453563714903,
      "grad_norm": 3.1012825729703763e-07,
      "learning_rate": 6.695464362850973e-06,
      "loss": 0.0,
      "step": 140350
    },
    {
      "epoch": 43.307621104597345,
      "grad_norm": 2.942432365671266e-05,
      "learning_rate": 6.692378895402654e-06,
      "loss": 0.0,
      "step": 140360
    },
    {
      "epoch": 43.31070657204567,
      "grad_norm": 2.2392937637505383e-07,
      "learning_rate": 6.689293427954335e-06,
      "loss": 0.0,
      "step": 140370
    },
    {
      "epoch": 43.31379203949398,
      "grad_norm": 4.70041896960538e-07,
      "learning_rate": 6.686207960506018e-06,
      "loss": 0.0,
      "step": 140380
    },
    {
      "epoch": 43.316877506942305,
      "grad_norm": 0.0002211278333561495,
      "learning_rate": 6.683122493057699e-06,
      "loss": 0.0,
      "step": 140390
    },
    {
      "epoch": 43.31996297439062,
      "grad_norm": 3.5240148577031505e-07,
      "learning_rate": 6.68003702560938e-06,
      "loss": 0.0,
      "step": 140400
    },
    {
      "epoch": 43.323048441838935,
      "grad_norm": 2.733841938606929e-06,
      "learning_rate": 6.676951558161061e-06,
      "loss": 0.0,
      "step": 140410
    },
    {
      "epoch": 43.32613390928726,
      "grad_norm": 4.065859684487805e-06,
      "learning_rate": 6.673866090712744e-06,
      "loss": 0.0,
      "step": 140420
    },
    {
      "epoch": 43.32921937673557,
      "grad_norm": 1.500119708452985e-07,
      "learning_rate": 6.6707806232644245e-06,
      "loss": 0.0,
      "step": 140430
    },
    {
      "epoch": 43.332304844183895,
      "grad_norm": 0.00010515542089706287,
      "learning_rate": 6.667695155816106e-06,
      "loss": 0.0,
      "step": 140440
    },
    {
      "epoch": 43.33539031163221,
      "grad_norm": 1.19667440401372e-08,
      "learning_rate": 6.664609688367789e-06,
      "loss": 0.0,
      "step": 140450
    },
    {
      "epoch": 43.33847577908053,
      "grad_norm": 1.3340003768291808e-08,
      "learning_rate": 6.661524220919469e-06,
      "loss": 0.0,
      "step": 140460
    },
    {
      "epoch": 43.34156124652885,
      "grad_norm": 2.6661484753276454e-07,
      "learning_rate": 6.658438753471151e-06,
      "loss": 0.0,
      "step": 140470
    },
    {
      "epoch": 43.34464671397717,
      "grad_norm": 1.8528581904320163e-06,
      "learning_rate": 6.655353286022832e-06,
      "loss": 0.0,
      "step": 140480
    },
    {
      "epoch": 43.347732181425485,
      "grad_norm": 1.732619807626179e-07,
      "learning_rate": 6.652267818574514e-06,
      "loss": 0.0,
      "step": 140490
    },
    {
      "epoch": 43.35081764887381,
      "grad_norm": 6.354846959766292e-07,
      "learning_rate": 6.649182351126196e-06,
      "loss": 0.0,
      "step": 140500
    },
    {
      "epoch": 43.35390311632212,
      "grad_norm": 0.004147788509726524,
      "learning_rate": 6.646096883677877e-06,
      "loss": 0.0,
      "step": 140510
    },
    {
      "epoch": 43.356988583770445,
      "grad_norm": 2.1598874866413098e-07,
      "learning_rate": 6.643011416229559e-06,
      "loss": 0.0,
      "step": 140520
    },
    {
      "epoch": 43.36007405121876,
      "grad_norm": 1.4298375390353613e-06,
      "learning_rate": 6.639925948781241e-06,
      "loss": 0.0,
      "step": 140530
    },
    {
      "epoch": 43.363159518667075,
      "grad_norm": 0.00043796878890134394,
      "learning_rate": 6.6368404813329216e-06,
      "loss": 0.0,
      "step": 140540
    },
    {
      "epoch": 43.3662449861154,
      "grad_norm": 2.976210566885129e-07,
      "learning_rate": 6.633755013884604e-06,
      "loss": 0.0,
      "step": 140550
    },
    {
      "epoch": 43.36933045356371,
      "grad_norm": 1.6882732722933724e-07,
      "learning_rate": 6.630669546436286e-06,
      "loss": 0.0,
      "step": 140560
    },
    {
      "epoch": 43.372415921012035,
      "grad_norm": 2.7465880236832163e-08,
      "learning_rate": 6.6275840789879664e-06,
      "loss": 0.0,
      "step": 140570
    },
    {
      "epoch": 43.37550138846035,
      "grad_norm": 1.5337034753315493e-08,
      "learning_rate": 6.624498611539648e-06,
      "loss": 0.0,
      "step": 140580
    },
    {
      "epoch": 43.37858685590867,
      "grad_norm": 1.5419000476413203e-07,
      "learning_rate": 6.6214131440913306e-06,
      "loss": 0.0,
      "step": 140590
    },
    {
      "epoch": 43.38167232335699,
      "grad_norm": 4.367115252534859e-05,
      "learning_rate": 6.618327676643011e-06,
      "loss": 0.0,
      "step": 140600
    },
    {
      "epoch": 43.38475779080531,
      "grad_norm": 9.822254121161222e-10,
      "learning_rate": 6.615242209194693e-06,
      "loss": 0.0,
      "step": 140610
    },
    {
      "epoch": 43.387843258253625,
      "grad_norm": 0.00023174166562967002,
      "learning_rate": 6.6121567417463754e-06,
      "loss": 0.0,
      "step": 140620
    },
    {
      "epoch": 43.39092872570195,
      "grad_norm": 3.330794243083801e-06,
      "learning_rate": 6.609071274298056e-06,
      "loss": 0.0,
      "step": 140630
    },
    {
      "epoch": 43.39401419315026,
      "grad_norm": 4.734343139745079e-09,
      "learning_rate": 6.605985806849738e-06,
      "loss": 0.0,
      "step": 140640
    },
    {
      "epoch": 43.39709966059858,
      "grad_norm": 4.385451120469952e-06,
      "learning_rate": 6.60290033940142e-06,
      "loss": 0.0,
      "step": 140650
    },
    {
      "epoch": 43.4001851280469,
      "grad_norm": 3.918574407180131e-07,
      "learning_rate": 6.599814871953101e-06,
      "loss": 0.0,
      "step": 140660
    },
    {
      "epoch": 43.403270595495215,
      "grad_norm": 6.323040793176915e-07,
      "learning_rate": 6.596729404504783e-06,
      "loss": 0.0,
      "step": 140670
    },
    {
      "epoch": 43.40635606294354,
      "grad_norm": 2.419087650196161e-06,
      "learning_rate": 6.5936439370564635e-06,
      "loss": 0.0,
      "step": 140680
    },
    {
      "epoch": 43.40944153039185,
      "grad_norm": 6.895947990415152e-08,
      "learning_rate": 6.590558469608146e-06,
      "loss": 0.0,
      "step": 140690
    },
    {
      "epoch": 43.412526997840175,
      "grad_norm": 0.001263079117052257,
      "learning_rate": 6.587473002159828e-06,
      "loss": 0.0,
      "step": 140700
    },
    {
      "epoch": 43.41561246528849,
      "grad_norm": 3.940583610528847e-07,
      "learning_rate": 6.584387534711508e-06,
      "loss": 0.0,
      "step": 140710
    },
    {
      "epoch": 43.41869793273681,
      "grad_norm": 2.609012172971603e-10,
      "learning_rate": 6.581302067263191e-06,
      "loss": 0.0,
      "step": 140720
    },
    {
      "epoch": 43.42178340018513,
      "grad_norm": 1.5309186807144215e-08,
      "learning_rate": 6.5782165998148725e-06,
      "loss": 0.0,
      "step": 140730
    },
    {
      "epoch": 43.42486886763345,
      "grad_norm": 1.9152109871356515e-06,
      "learning_rate": 6.575131132366553e-06,
      "loss": 0.0,
      "step": 140740
    },
    {
      "epoch": 43.427954335081765,
      "grad_norm": 1.6160917937213526e-08,
      "learning_rate": 6.572045664918236e-06,
      "loss": 0.0,
      "step": 140750
    },
    {
      "epoch": 43.43103980253008,
      "grad_norm": 2.5311479475931264e-05,
      "learning_rate": 6.568960197469917e-06,
      "loss": 0.0,
      "step": 140760
    },
    {
      "epoch": 43.4341252699784,
      "grad_norm": 9.145894000539556e-05,
      "learning_rate": 6.565874730021598e-06,
      "loss": 0.0,
      "step": 140770
    },
    {
      "epoch": 43.43721073742672,
      "grad_norm": 4.314414603356909e-09,
      "learning_rate": 6.56278926257328e-06,
      "loss": 0.0,
      "step": 140780
    },
    {
      "epoch": 43.44029620487504,
      "grad_norm": 5.962709792584064e-07,
      "learning_rate": 6.559703795124962e-06,
      "loss": 0.0,
      "step": 140790
    },
    {
      "epoch": 43.443381672323355,
      "grad_norm": 0.0042466046288609505,
      "learning_rate": 6.556618327676643e-06,
      "loss": 0.0,
      "step": 140800
    },
    {
      "epoch": 43.44646713977168,
      "grad_norm": 3.1203828712023096e-06,
      "learning_rate": 6.553532860228325e-06,
      "loss": 0.0,
      "step": 140810
    },
    {
      "epoch": 43.44955260721999,
      "grad_norm": 3.226878764195362e-10,
      "learning_rate": 6.550447392780007e-06,
      "loss": 0.0,
      "step": 140820
    },
    {
      "epoch": 43.452638074668315,
      "grad_norm": 1.7139689134637592e-07,
      "learning_rate": 6.547361925331688e-06,
      "loss": 0.0,
      "step": 140830
    },
    {
      "epoch": 43.45572354211663,
      "grad_norm": 2.8514888981590047e-05,
      "learning_rate": 6.54427645788337e-06,
      "loss": 0.0,
      "step": 140840
    },
    {
      "epoch": 43.45880900956495,
      "grad_norm": 7.568409010616506e-09,
      "learning_rate": 6.541190990435052e-06,
      "loss": 0.0,
      "step": 140850
    },
    {
      "epoch": 43.46189447701327,
      "grad_norm": 1.0278198487867485e-06,
      "learning_rate": 6.538105522986733e-06,
      "loss": 0.0,
      "step": 140860
    },
    {
      "epoch": 43.46497994446159,
      "grad_norm": 3.6411006476555485e-07,
      "learning_rate": 6.5350200555384145e-06,
      "loss": 0.0,
      "step": 140870
    },
    {
      "epoch": 43.468065411909905,
      "grad_norm": 4.069594439215507e-08,
      "learning_rate": 6.531934588090095e-06,
      "loss": 0.0,
      "step": 140880
    },
    {
      "epoch": 43.47115087935822,
      "grad_norm": 0.004872910678386688,
      "learning_rate": 6.528849120641778e-06,
      "loss": 0.0,
      "step": 140890
    },
    {
      "epoch": 43.47423634680654,
      "grad_norm": 9.263023912353674e-07,
      "learning_rate": 6.525763653193459e-06,
      "loss": 0.0,
      "step": 140900
    },
    {
      "epoch": 43.47732181425486,
      "grad_norm": 2.2691804133501137e-06,
      "learning_rate": 6.52267818574514e-06,
      "loss": 0.0001,
      "step": 140910
    },
    {
      "epoch": 43.48040728170318,
      "grad_norm": 4.154684120294405e-06,
      "learning_rate": 6.519592718296823e-06,
      "loss": 0.0,
      "step": 140920
    },
    {
      "epoch": 43.483492749151495,
      "grad_norm": 5.170487042960303e-07,
      "learning_rate": 6.516507250848504e-06,
      "loss": 0.0,
      "step": 140930
    },
    {
      "epoch": 43.48657821659982,
      "grad_norm": 4.252319172337593e-07,
      "learning_rate": 6.513421783400185e-06,
      "loss": 0.0,
      "step": 140940
    },
    {
      "epoch": 43.48966368404813,
      "grad_norm": 1.4383387814120852e-08,
      "learning_rate": 6.5103363159518675e-06,
      "loss": 0.0,
      "step": 140950
    },
    {
      "epoch": 43.492749151496454,
      "grad_norm": 2.1380614271038212e-05,
      "learning_rate": 6.507250848503549e-06,
      "loss": 0.0,
      "step": 140960
    },
    {
      "epoch": 43.49583461894477,
      "grad_norm": 1.2609993973455857e-05,
      "learning_rate": 6.50416538105523e-06,
      "loss": 0.0,
      "step": 140970
    },
    {
      "epoch": 43.49892008639309,
      "grad_norm": 9.523198229999252e-09,
      "learning_rate": 6.501079913606911e-06,
      "loss": 0.0,
      "step": 140980
    },
    {
      "epoch": 43.50200555384141,
      "grad_norm": 3.639389234422197e-08,
      "learning_rate": 6.497994446158594e-06,
      "loss": 0.0,
      "step": 140990
    },
    {
      "epoch": 43.50509102128972,
      "grad_norm": 2.3038566610011912e-08,
      "learning_rate": 6.494908978710275e-06,
      "loss": 0.0,
      "step": 141000
    },
    {
      "epoch": 43.508176488738044,
      "grad_norm": 6.332255253482799e-08,
      "learning_rate": 6.491823511261956e-06,
      "loss": 0.0,
      "step": 141010
    },
    {
      "epoch": 43.51126195618636,
      "grad_norm": 9.657866684165128e-08,
      "learning_rate": 6.488738043813639e-06,
      "loss": 0.0,
      "step": 141020
    },
    {
      "epoch": 43.51434742363468,
      "grad_norm": 2.8105864657845814e-07,
      "learning_rate": 6.48565257636532e-06,
      "loss": 0.0,
      "step": 141030
    },
    {
      "epoch": 43.517432891083,
      "grad_norm": 1.3521417940864922e-06,
      "learning_rate": 6.4825671089170005e-06,
      "loss": 0.0,
      "step": 141040
    },
    {
      "epoch": 43.52051835853132,
      "grad_norm": 0.00014610469224862754,
      "learning_rate": 6.479481641468684e-06,
      "loss": 0.0,
      "step": 141050
    },
    {
      "epoch": 43.523603825979635,
      "grad_norm": 2.4602115900052013e-06,
      "learning_rate": 6.476396174020365e-06,
      "loss": 0.0,
      "step": 141060
    },
    {
      "epoch": 43.52668929342796,
      "grad_norm": 3.24362626997754e-05,
      "learning_rate": 6.473310706572045e-06,
      "loss": 0.0,
      "step": 141070
    },
    {
      "epoch": 43.52977476087627,
      "grad_norm": 5.353004084440727e-08,
      "learning_rate": 6.470225239123727e-06,
      "loss": 0.0,
      "step": 141080
    },
    {
      "epoch": 43.532860228324594,
      "grad_norm": 0.0018217449542135,
      "learning_rate": 6.4671397716754095e-06,
      "loss": 0.0,
      "step": 141090
    },
    {
      "epoch": 43.53594569577291,
      "grad_norm": 2.1488015136128524e-06,
      "learning_rate": 6.46405430422709e-06,
      "loss": 0.0,
      "step": 141100
    },
    {
      "epoch": 43.539031163221225,
      "grad_norm": 6.765703108868593e-09,
      "learning_rate": 6.460968836778772e-06,
      "loss": 0.0,
      "step": 141110
    },
    {
      "epoch": 43.54211663066955,
      "grad_norm": 2.1709781776735326e-06,
      "learning_rate": 6.457883369330454e-06,
      "loss": 0.0,
      "step": 141120
    },
    {
      "epoch": 43.54520209811786,
      "grad_norm": 0.00015472585801035166,
      "learning_rate": 6.454797901882135e-06,
      "loss": 0.0,
      "step": 141130
    },
    {
      "epoch": 43.548287565566184,
      "grad_norm": 0.000136987044243142,
      "learning_rate": 6.451712434433817e-06,
      "loss": 0.0,
      "step": 141140
    },
    {
      "epoch": 43.5513730330145,
      "grad_norm": 1.7320385126140536e-08,
      "learning_rate": 6.448626966985499e-06,
      "loss": 0.0,
      "step": 141150
    },
    {
      "epoch": 43.55445850046282,
      "grad_norm": 6.34215098216373e-07,
      "learning_rate": 6.44554149953718e-06,
      "loss": 0.0,
      "step": 141160
    },
    {
      "epoch": 43.55754396791114,
      "grad_norm": 3.550809602945182e-12,
      "learning_rate": 6.442456032088862e-06,
      "loss": 0.0,
      "step": 141170
    },
    {
      "epoch": 43.56062943535946,
      "grad_norm": 1.6297857428071438e-06,
      "learning_rate": 6.4393705646405425e-06,
      "loss": 0.0,
      "step": 141180
    },
    {
      "epoch": 43.563714902807774,
      "grad_norm": 2.6907416668109363e-06,
      "learning_rate": 6.436285097192225e-06,
      "loss": 0.0,
      "step": 141190
    },
    {
      "epoch": 43.5668003702561,
      "grad_norm": 1.9348999558133073e-06,
      "learning_rate": 6.433199629743907e-06,
      "loss": 0.0,
      "step": 141200
    },
    {
      "epoch": 43.56988583770441,
      "grad_norm": 5.127198619447881e-06,
      "learning_rate": 6.430114162295587e-06,
      "loss": 0.0,
      "step": 141210
    },
    {
      "epoch": 43.572971305152734,
      "grad_norm": 3.486054112045167e-08,
      "learning_rate": 6.42702869484727e-06,
      "loss": 0.0,
      "step": 141220
    },
    {
      "epoch": 43.57605677260105,
      "grad_norm": 1.5949303815432359e-06,
      "learning_rate": 6.4239432273989515e-06,
      "loss": 0.0,
      "step": 141230
    },
    {
      "epoch": 43.579142240049364,
      "grad_norm": 1.8472681404091418e-05,
      "learning_rate": 6.420857759950632e-06,
      "loss": 0.0,
      "step": 141240
    },
    {
      "epoch": 43.58222770749769,
      "grad_norm": 0.00020881682576145977,
      "learning_rate": 6.417772292502315e-06,
      "loss": 0.0,
      "step": 141250
    },
    {
      "epoch": 43.585313174946,
      "grad_norm": 1.6911536704355967e-06,
      "learning_rate": 6.414686825053996e-06,
      "loss": 0.0,
      "step": 141260
    },
    {
      "epoch": 43.588398642394324,
      "grad_norm": 2.809355947874792e-08,
      "learning_rate": 6.411601357605677e-06,
      "loss": 0.0,
      "step": 141270
    },
    {
      "epoch": 43.59148410984264,
      "grad_norm": 1.3668377505382523e-06,
      "learning_rate": 6.408515890157359e-06,
      "loss": 0.0,
      "step": 141280
    },
    {
      "epoch": 43.59456957729096,
      "grad_norm": 2.8749036928843452e-08,
      "learning_rate": 6.405430422709041e-06,
      "loss": 0.0,
      "step": 141290
    },
    {
      "epoch": 43.59765504473928,
      "grad_norm": 9.49746390688233e-06,
      "learning_rate": 6.402344955260722e-06,
      "loss": 0.0,
      "step": 141300
    },
    {
      "epoch": 43.6007405121876,
      "grad_norm": 2.2399692767294255e-08,
      "learning_rate": 6.399259487812404e-06,
      "loss": 0.0,
      "step": 141310
    },
    {
      "epoch": 43.603825979635914,
      "grad_norm": 3.2738395816522825e-07,
      "learning_rate": 6.396174020364086e-06,
      "loss": 0.0,
      "step": 141320
    },
    {
      "epoch": 43.60691144708424,
      "grad_norm": 2.3267602955456823e-08,
      "learning_rate": 6.393088552915767e-06,
      "loss": 0.0,
      "step": 141330
    },
    {
      "epoch": 43.60999691453255,
      "grad_norm": 1.9004571072400722e-07,
      "learning_rate": 6.3900030854674486e-06,
      "loss": 0.0,
      "step": 141340
    },
    {
      "epoch": 43.61308238198087,
      "grad_norm": 4.418398020789027e-06,
      "learning_rate": 6.386917618019129e-06,
      "loss": 0.0,
      "step": 141350
    },
    {
      "epoch": 43.61616784942919,
      "grad_norm": 2.754309753072448e-05,
      "learning_rate": 6.383832150570812e-06,
      "loss": 0.0,
      "step": 141360
    },
    {
      "epoch": 43.619253316877504,
      "grad_norm": 5.625075800708146e-07,
      "learning_rate": 6.3807466831224935e-06,
      "loss": 0.0,
      "step": 141370
    },
    {
      "epoch": 43.62233878432583,
      "grad_norm": 9.662557204137556e-06,
      "learning_rate": 6.377661215674174e-06,
      "loss": 0.0,
      "step": 141380
    },
    {
      "epoch": 43.62542425177414,
      "grad_norm": 7.846678613532276e-07,
      "learning_rate": 6.374575748225857e-06,
      "loss": 0.0,
      "step": 141390
    },
    {
      "epoch": 43.628509719222464,
      "grad_norm": 2.8387280508468393e-06,
      "learning_rate": 6.371490280777538e-06,
      "loss": 0.0,
      "step": 141400
    },
    {
      "epoch": 43.63159518667078,
      "grad_norm": 8.795122994342819e-06,
      "learning_rate": 6.368404813329219e-06,
      "loss": 0.0,
      "step": 141410
    },
    {
      "epoch": 43.6346806541191,
      "grad_norm": 2.4761654948690648e-09,
      "learning_rate": 6.365319345880902e-06,
      "loss": 0.0,
      "step": 141420
    },
    {
      "epoch": 43.63776612156742,
      "grad_norm": 5.538702680496499e-05,
      "learning_rate": 6.362233878432583e-06,
      "loss": 0.0,
      "step": 141430
    },
    {
      "epoch": 43.64085158901574,
      "grad_norm": 3.4208344459329965e-06,
      "learning_rate": 6.359148410984264e-06,
      "loss": 0.0,
      "step": 141440
    },
    {
      "epoch": 43.643937056464054,
      "grad_norm": 4.087458819412859e-06,
      "learning_rate": 6.356062943535946e-06,
      "loss": 0.0,
      "step": 141450
    },
    {
      "epoch": 43.64702252391237,
      "grad_norm": 5.245681222731946e-09,
      "learning_rate": 6.352977476087628e-06,
      "loss": 0.0,
      "step": 141460
    },
    {
      "epoch": 43.65010799136069,
      "grad_norm": 0.0010452395072206855,
      "learning_rate": 6.349892008639309e-06,
      "loss": 0.0,
      "step": 141470
    },
    {
      "epoch": 43.65319345880901,
      "grad_norm": 0.002249689307063818,
      "learning_rate": 6.3468065411909905e-06,
      "loss": 0.0,
      "step": 141480
    },
    {
      "epoch": 43.65627892625733,
      "grad_norm": 8.69279858761729e-07,
      "learning_rate": 6.343721073742673e-06,
      "loss": 0.0,
      "step": 141490
    },
    {
      "epoch": 43.659364393705644,
      "grad_norm": 0.0006287374417297542,
      "learning_rate": 6.340635606294354e-06,
      "loss": 0.0,
      "step": 141500
    },
    {
      "epoch": 43.662449861153966,
      "grad_norm": 0.00012265365512575954,
      "learning_rate": 6.3375501388460354e-06,
      "loss": 0.0,
      "step": 141510
    },
    {
      "epoch": 43.66553532860228,
      "grad_norm": 5.278195203572977e-06,
      "learning_rate": 6.334464671397718e-06,
      "loss": 0.0,
      "step": 141520
    },
    {
      "epoch": 43.668620796050604,
      "grad_norm": 6.179797651384433e-07,
      "learning_rate": 6.331379203949399e-06,
      "loss": 0.0,
      "step": 141530
    },
    {
      "epoch": 43.67170626349892,
      "grad_norm": 9.615239832783118e-06,
      "learning_rate": 6.32829373650108e-06,
      "loss": 0.0,
      "step": 141540
    },
    {
      "epoch": 43.67479173094724,
      "grad_norm": 5.652329491567798e-05,
      "learning_rate": 6.325208269052761e-06,
      "loss": 0.0,
      "step": 141550
    },
    {
      "epoch": 43.67787719839556,
      "grad_norm": 4.6148105070642487e-07,
      "learning_rate": 6.3221228016044436e-06,
      "loss": 0.0,
      "step": 141560
    },
    {
      "epoch": 43.68096266584388,
      "grad_norm": 1.0415172724265176e-08,
      "learning_rate": 6.319037334156125e-06,
      "loss": 0.0,
      "step": 141570
    },
    {
      "epoch": 43.684048133292194,
      "grad_norm": 1.0994189096891205e-06,
      "learning_rate": 6.315951866707806e-06,
      "loss": 0.0,
      "step": 141580
    },
    {
      "epoch": 43.68713360074051,
      "grad_norm": 6.338231059999089e-07,
      "learning_rate": 6.3128663992594885e-06,
      "loss": 0.0,
      "step": 141590
    },
    {
      "epoch": 43.69021906818883,
      "grad_norm": 0.00016930443234741688,
      "learning_rate": 6.30978093181117e-06,
      "loss": 0.0,
      "step": 141600
    },
    {
      "epoch": 43.69330453563715,
      "grad_norm": 9.876681161813394e-08,
      "learning_rate": 6.306695464362851e-06,
      "loss": 0.0,
      "step": 141610
    },
    {
      "epoch": 43.69639000308547,
      "grad_norm": 2.180178307753522e-05,
      "learning_rate": 6.303609996914533e-06,
      "loss": 0.0,
      "step": 141620
    },
    {
      "epoch": 43.699475470533784,
      "grad_norm": 3.6520909816317726e-06,
      "learning_rate": 6.300524529466215e-06,
      "loss": 0.0,
      "step": 141630
    },
    {
      "epoch": 43.702560937982106,
      "grad_norm": 0.0012465141480788589,
      "learning_rate": 6.297439062017896e-06,
      "loss": 0.0,
      "step": 141640
    },
    {
      "epoch": 43.70564640543042,
      "grad_norm": 3.1077545372681925e-06,
      "learning_rate": 6.2943535945695766e-06,
      "loss": 0.0,
      "step": 141650
    },
    {
      "epoch": 43.708731872878744,
      "grad_norm": 6.665337878075661e-06,
      "learning_rate": 6.29126812712126e-06,
      "loss": 0.0,
      "step": 141660
    },
    {
      "epoch": 43.71181734032706,
      "grad_norm": 1.5200714642560342e-06,
      "learning_rate": 6.288182659672941e-06,
      "loss": 0.0,
      "step": 141670
    },
    {
      "epoch": 43.71490280777538,
      "grad_norm": 3.6013929616274254e-08,
      "learning_rate": 6.2850971922246214e-06,
      "loss": 0.0,
      "step": 141680
    },
    {
      "epoch": 43.717988275223696,
      "grad_norm": 5.776961916126311e-05,
      "learning_rate": 6.282011724776305e-06,
      "loss": 0.0,
      "step": 141690
    },
    {
      "epoch": 43.72107374267201,
      "grad_norm": 4.060182412501945e-09,
      "learning_rate": 6.2789262573279855e-06,
      "loss": 0.0,
      "step": 141700
    },
    {
      "epoch": 43.724159210120334,
      "grad_norm": 1.003460511128651e-05,
      "learning_rate": 6.275840789879666e-06,
      "loss": 0.0,
      "step": 141710
    },
    {
      "epoch": 43.72724467756865,
      "grad_norm": 6.114624966357951e-07,
      "learning_rate": 6.27275532243135e-06,
      "loss": 0.0,
      "step": 141720
    },
    {
      "epoch": 43.73033014501697,
      "grad_norm": 8.236726898758207e-06,
      "learning_rate": 6.2696698549830304e-06,
      "loss": 0.0,
      "step": 141730
    },
    {
      "epoch": 43.733415612465286,
      "grad_norm": 3.9781756555612446e-08,
      "learning_rate": 6.266584387534711e-06,
      "loss": 0.0,
      "step": 141740
    },
    {
      "epoch": 43.73650107991361,
      "grad_norm": 2.0728195977426367e-06,
      "learning_rate": 6.263498920086393e-06,
      "loss": 0.0,
      "step": 141750
    },
    {
      "epoch": 43.739586547361924,
      "grad_norm": 3.7308559512894135e-06,
      "learning_rate": 6.260413452638075e-06,
      "loss": 0.0,
      "step": 141760
    },
    {
      "epoch": 43.742672014810246,
      "grad_norm": 0.011052032932639122,
      "learning_rate": 6.257327985189756e-06,
      "loss": 0.0,
      "step": 141770
    },
    {
      "epoch": 43.74575748225856,
      "grad_norm": 6.122960627408247e-08,
      "learning_rate": 6.254242517741438e-06,
      "loss": 0.0,
      "step": 141780
    },
    {
      "epoch": 43.748842949706884,
      "grad_norm": 8.911698387237266e-05,
      "learning_rate": 6.25115705029312e-06,
      "loss": 0.0,
      "step": 141790
    },
    {
      "epoch": 43.7519284171552,
      "grad_norm": 1.8037504560197704e-05,
      "learning_rate": 6.248071582844801e-06,
      "loss": 0.0,
      "step": 141800
    },
    {
      "epoch": 43.755013884603514,
      "grad_norm": 3.9092511450178336e-09,
      "learning_rate": 6.244986115396483e-06,
      "loss": 0.0,
      "step": 141810
    },
    {
      "epoch": 43.758099352051836,
      "grad_norm": 4.599899057211587e-06,
      "learning_rate": 6.241900647948164e-06,
      "loss": 0.0,
      "step": 141820
    },
    {
      "epoch": 43.76118481950015,
      "grad_norm": 3.0331684683915228e-06,
      "learning_rate": 6.238815180499846e-06,
      "loss": 0.0,
      "step": 141830
    },
    {
      "epoch": 43.764270286948474,
      "grad_norm": 2.8050806122337235e-07,
      "learning_rate": 6.2357297130515275e-06,
      "loss": 0.0,
      "step": 141840
    },
    {
      "epoch": 43.76735575439679,
      "grad_norm": 4.086020908289356e-07,
      "learning_rate": 6.232644245603209e-06,
      "loss": 0.0,
      "step": 141850
    },
    {
      "epoch": 43.77044122184511,
      "grad_norm": 8.813902496740411e-09,
      "learning_rate": 6.229558778154891e-06,
      "loss": 0.0,
      "step": 141860
    },
    {
      "epoch": 43.773526689293426,
      "grad_norm": 1.4491347428702284e-06,
      "learning_rate": 6.226473310706572e-06,
      "loss": 0.0,
      "step": 141870
    },
    {
      "epoch": 43.77661215674175,
      "grad_norm": 4.811347480426775e-07,
      "learning_rate": 6.223387843258254e-06,
      "loss": 0.0,
      "step": 141880
    },
    {
      "epoch": 43.779697624190064,
      "grad_norm": 4.004528708634325e-09,
      "learning_rate": 6.220302375809936e-06,
      "loss": 0.0,
      "step": 141890
    },
    {
      "epoch": 43.782783091638386,
      "grad_norm": 8.139990903544003e-09,
      "learning_rate": 6.217216908361617e-06,
      "loss": 0.0,
      "step": 141900
    },
    {
      "epoch": 43.7858685590867,
      "grad_norm": 0.00020090270845685154,
      "learning_rate": 6.214131440913298e-06,
      "loss": 0.0,
      "step": 141910
    },
    {
      "epoch": 43.78895402653502,
      "grad_norm": 6.801299605285749e-06,
      "learning_rate": 6.2110459734649806e-06,
      "loss": 0.0,
      "step": 141920
    },
    {
      "epoch": 43.79203949398334,
      "grad_norm": 6.137352670521068e-07,
      "learning_rate": 6.207960506016662e-06,
      "loss": 0.0,
      "step": 141930
    },
    {
      "epoch": 43.795124961431654,
      "grad_norm": 3.385103397590683e-08,
      "learning_rate": 6.204875038568343e-06,
      "loss": 0.0,
      "step": 141940
    },
    {
      "epoch": 43.798210428879976,
      "grad_norm": 4.4449807319324464e-05,
      "learning_rate": 6.2017895711200254e-06,
      "loss": 0.0,
      "step": 141950
    },
    {
      "epoch": 43.80129589632829,
      "grad_norm": 3.215024264591193e-07,
      "learning_rate": 6.198704103671706e-06,
      "loss": 0.0,
      "step": 141960
    },
    {
      "epoch": 43.80438136377661,
      "grad_norm": 4.354424021357772e-08,
      "learning_rate": 6.195618636223388e-06,
      "loss": 0.0,
      "step": 141970
    },
    {
      "epoch": 43.80746683122493,
      "grad_norm": 0.0009324226411990821,
      "learning_rate": 6.19253316877507e-06,
      "loss": 0.0,
      "step": 141980
    },
    {
      "epoch": 43.81055229867325,
      "grad_norm": 5.490059074020337e-09,
      "learning_rate": 6.189447701326751e-06,
      "loss": 0.0,
      "step": 141990
    },
    {
      "epoch": 43.813637766121566,
      "grad_norm": 5.295614300848683e-06,
      "learning_rate": 6.186362233878433e-06,
      "loss": 0.0,
      "step": 142000
    },
    {
      "epoch": 43.81672323356989,
      "grad_norm": 2.1971020558453347e-08,
      "learning_rate": 6.183276766430114e-06,
      "loss": 0.0,
      "step": 142010
    },
    {
      "epoch": 43.819808701018204,
      "grad_norm": 0.00029675691621378064,
      "learning_rate": 6.180191298981796e-06,
      "loss": 0.0,
      "step": 142020
    },
    {
      "epoch": 43.822894168466526,
      "grad_norm": 1.0820814395628986e-06,
      "learning_rate": 6.177105831533478e-06,
      "loss": 0.0,
      "step": 142030
    },
    {
      "epoch": 43.82597963591484,
      "grad_norm": 5.519933954367673e-10,
      "learning_rate": 6.174020364085159e-06,
      "loss": 0.0,
      "step": 142040
    },
    {
      "epoch": 43.829065103363156,
      "grad_norm": 1.2799730484402971e-06,
      "learning_rate": 6.170934896636841e-06,
      "loss": 0.0,
      "step": 142050
    },
    {
      "epoch": 43.83215057081148,
      "grad_norm": 1.290701101552827e-09,
      "learning_rate": 6.167849429188522e-06,
      "loss": 0.0,
      "step": 142060
    },
    {
      "epoch": 43.835236038259794,
      "grad_norm": 4.112989115956367e-10,
      "learning_rate": 6.164763961740204e-06,
      "loss": 0.0,
      "step": 142070
    },
    {
      "epoch": 43.838321505708116,
      "grad_norm": 2.3686402528255712e-06,
      "learning_rate": 6.161678494291886e-06,
      "loss": 0.0,
      "step": 142080
    },
    {
      "epoch": 43.84140697315643,
      "grad_norm": 3.659514788978413e-07,
      "learning_rate": 6.1585930268435666e-06,
      "loss": 0.0,
      "step": 142090
    },
    {
      "epoch": 43.84449244060475,
      "grad_norm": 6.89010903442977e-06,
      "learning_rate": 6.155507559395249e-06,
      "loss": 0.0,
      "step": 142100
    },
    {
      "epoch": 43.84757790805307,
      "grad_norm": 2.1340704847716552e-07,
      "learning_rate": 6.15242209194693e-06,
      "loss": 0.0,
      "step": 142110
    },
    {
      "epoch": 43.85066337550139,
      "grad_norm": 7.196843216661364e-05,
      "learning_rate": 6.1493366244986115e-06,
      "loss": 0.0,
      "step": 142120
    },
    {
      "epoch": 43.853748842949706,
      "grad_norm": 1.7097548266065132e-08,
      "learning_rate": 6.146251157050294e-06,
      "loss": 0.0,
      "step": 142130
    },
    {
      "epoch": 43.85683431039803,
      "grad_norm": 5.420748948381515e-06,
      "learning_rate": 6.143165689601975e-06,
      "loss": 0.0,
      "step": 142140
    },
    {
      "epoch": 43.85991977784634,
      "grad_norm": 4.945101750308822e-07,
      "learning_rate": 6.140080222153656e-06,
      "loss": 0.0,
      "step": 142150
    },
    {
      "epoch": 43.86300524529466,
      "grad_norm": 0.00020020361989736557,
      "learning_rate": 6.136994754705338e-06,
      "loss": 0.0,
      "step": 142160
    },
    {
      "epoch": 43.86609071274298,
      "grad_norm": 0.00011397477646823972,
      "learning_rate": 6.13390928725702e-06,
      "loss": 0.0,
      "step": 142170
    },
    {
      "epoch": 43.869176180191296,
      "grad_norm": 3.970647867390653e-06,
      "learning_rate": 6.130823819808701e-06,
      "loss": 0.0,
      "step": 142180
    },
    {
      "epoch": 43.87226164763962,
      "grad_norm": 0.000252359954174608,
      "learning_rate": 6.127738352360383e-06,
      "loss": 0.0,
      "step": 142190
    },
    {
      "epoch": 43.87534711508793,
      "grad_norm": 1.9825423080988003e-08,
      "learning_rate": 6.1246528849120645e-06,
      "loss": 0.0,
      "step": 142200
    },
    {
      "epoch": 43.878432582536256,
      "grad_norm": 1.1876379630848533e-06,
      "learning_rate": 6.121567417463746e-06,
      "loss": 0.0,
      "step": 142210
    },
    {
      "epoch": 43.88151804998457,
      "grad_norm": 0.002251169877126813,
      "learning_rate": 6.118481950015428e-06,
      "loss": 0.0,
      "step": 142220
    },
    {
      "epoch": 43.88460351743289,
      "grad_norm": 1.2302454024393228e-06,
      "learning_rate": 6.115396482567109e-06,
      "loss": 0.0,
      "step": 142230
    },
    {
      "epoch": 43.88768898488121,
      "grad_norm": 1.2631594437095828e-08,
      "learning_rate": 6.112311015118791e-06,
      "loss": 0.0,
      "step": 142240
    },
    {
      "epoch": 43.89077445232953,
      "grad_norm": 9.225235159115996e-11,
      "learning_rate": 6.109225547670473e-06,
      "loss": 0.0,
      "step": 142250
    },
    {
      "epoch": 43.893859919777846,
      "grad_norm": 1.1963738870690577e-06,
      "learning_rate": 6.1061400802221534e-06,
      "loss": 0.0,
      "step": 142260
    },
    {
      "epoch": 43.89694538722617,
      "grad_norm": 8.419371511081408e-08,
      "learning_rate": 6.103054612773836e-06,
      "loss": 0.0,
      "step": 142270
    },
    {
      "epoch": 43.90003085467448,
      "grad_norm": 1.4262918739404995e-05,
      "learning_rate": 6.0999691453255175e-06,
      "loss": 0.0,
      "step": 142280
    },
    {
      "epoch": 43.9031163221228,
      "grad_norm": 1.2905018138553714e-06,
      "learning_rate": 6.096883677877198e-06,
      "loss": 0.0,
      "step": 142290
    },
    {
      "epoch": 43.90620178957112,
      "grad_norm": 2.170949665014632e-05,
      "learning_rate": 6.093798210428881e-06,
      "loss": 0.0,
      "step": 142300
    },
    {
      "epoch": 43.909287257019436,
      "grad_norm": 1.9439860352576943e-06,
      "learning_rate": 6.090712742980562e-06,
      "loss": 0.0,
      "step": 142310
    },
    {
      "epoch": 43.91237272446776,
      "grad_norm": 4.6900171923880407e-07,
      "learning_rate": 6.087627275532243e-06,
      "loss": 0.0,
      "step": 142320
    },
    {
      "epoch": 43.91545819191607,
      "grad_norm": 8.847595017869025e-05,
      "learning_rate": 6.084541808083926e-06,
      "loss": 0.0,
      "step": 142330
    },
    {
      "epoch": 43.918543659364396,
      "grad_norm": 1.1133211955893785e-05,
      "learning_rate": 6.0814563406356065e-06,
      "loss": 0.0,
      "step": 142340
    },
    {
      "epoch": 43.92162912681271,
      "grad_norm": 7.847734906363257e-08,
      "learning_rate": 6.078370873187288e-06,
      "loss": 0.0,
      "step": 142350
    },
    {
      "epoch": 43.92471459426103,
      "grad_norm": 8.217847607738804e-06,
      "learning_rate": 6.07528540573897e-06,
      "loss": 0.0,
      "step": 142360
    },
    {
      "epoch": 43.92780006170935,
      "grad_norm": 8.825786790112033e-05,
      "learning_rate": 6.072199938290651e-06,
      "loss": 0.0,
      "step": 142370
    },
    {
      "epoch": 43.93088552915767,
      "grad_norm": 4.08841707155716e-08,
      "learning_rate": 6.069114470842333e-06,
      "loss": 0.0,
      "step": 142380
    },
    {
      "epoch": 43.933970996605986,
      "grad_norm": 2.1340934836189263e-05,
      "learning_rate": 6.066029003394015e-06,
      "loss": 0.0,
      "step": 142390
    },
    {
      "epoch": 43.9370564640543,
      "grad_norm": 1.9907247406081297e-05,
      "learning_rate": 6.062943535945696e-06,
      "loss": 0.0,
      "step": 142400
    },
    {
      "epoch": 43.94014193150262,
      "grad_norm": 3.058701986446977e-05,
      "learning_rate": 6.059858068497377e-06,
      "loss": 0.0,
      "step": 142410
    },
    {
      "epoch": 43.94322739895094,
      "grad_norm": 9.002479828268406e-07,
      "learning_rate": 6.0567726010490595e-06,
      "loss": 0.0,
      "step": 142420
    },
    {
      "epoch": 43.94631286639926,
      "grad_norm": 4.686548038534966e-09,
      "learning_rate": 6.053687133600741e-06,
      "loss": 0.0,
      "step": 142430
    },
    {
      "epoch": 43.949398333847576,
      "grad_norm": 0.0004078777856193483,
      "learning_rate": 6.050601666152422e-06,
      "loss": 0.0,
      "step": 142440
    },
    {
      "epoch": 43.9524838012959,
      "grad_norm": 1.1133320185763296e-06,
      "learning_rate": 6.047516198704104e-06,
      "loss": 0.0,
      "step": 142450
    },
    {
      "epoch": 43.95556926874421,
      "grad_norm": 1.9003495253855363e-05,
      "learning_rate": 6.044430731255785e-06,
      "loss": 0.0,
      "step": 142460
    },
    {
      "epoch": 43.958654736192535,
      "grad_norm": 3.111639657049636e-08,
      "learning_rate": 6.041345263807467e-06,
      "loss": 0.0,
      "step": 142470
    },
    {
      "epoch": 43.96174020364085,
      "grad_norm": 1.6963605631303835e-08,
      "learning_rate": 6.038259796359149e-06,
      "loss": 0.0,
      "step": 142480
    },
    {
      "epoch": 43.96482567108917,
      "grad_norm": 0.00034883900661952794,
      "learning_rate": 6.03517432891083e-06,
      "loss": 0.0,
      "step": 142490
    },
    {
      "epoch": 43.96791113853749,
      "grad_norm": 0.003914177417755127,
      "learning_rate": 6.032088861462512e-06,
      "loss": 0.0,
      "step": 142500
    },
    {
      "epoch": 43.9709966059858,
      "grad_norm": 3.156571983709e-05,
      "learning_rate": 6.029003394014193e-06,
      "loss": 0.0,
      "step": 142510
    },
    {
      "epoch": 43.974082073434126,
      "grad_norm": 3.1724882774142316e-06,
      "learning_rate": 6.025917926565875e-06,
      "loss": 0.0,
      "step": 142520
    },
    {
      "epoch": 43.97716754088244,
      "grad_norm": 2.427407075344945e-08,
      "learning_rate": 6.022832459117557e-06,
      "loss": 0.0,
      "step": 142530
    },
    {
      "epoch": 43.98025300833076,
      "grad_norm": 2.1215719243627973e-05,
      "learning_rate": 6.019746991669238e-06,
      "loss": 0.0,
      "step": 142540
    },
    {
      "epoch": 43.98333847577908,
      "grad_norm": 1.1559179711184697e-06,
      "learning_rate": 6.01666152422092e-06,
      "loss": 0.0,
      "step": 142550
    },
    {
      "epoch": 43.9864239432274,
      "grad_norm": 7.633317181898747e-06,
      "learning_rate": 6.0135760567726015e-06,
      "loss": 0.0,
      "step": 142560
    },
    {
      "epoch": 43.989509410675716,
      "grad_norm": 1.8206762888439698e-06,
      "learning_rate": 6.010490589324283e-06,
      "loss": 0.0,
      "step": 142570
    },
    {
      "epoch": 43.99259487812404,
      "grad_norm": 6.069413757359143e-06,
      "learning_rate": 6.007405121875964e-06,
      "loss": 0.0,
      "step": 142580
    },
    {
      "epoch": 43.99568034557235,
      "grad_norm": 9.257593660549901e-07,
      "learning_rate": 6.004319654427646e-06,
      "loss": 0.0,
      "step": 142590
    },
    {
      "epoch": 43.998765813020675,
      "grad_norm": 7.213326966848399e-07,
      "learning_rate": 6.001234186979328e-06,
      "loss": 0.0,
      "step": 142600
    },
    {
      "epoch": 44.0,
      "eval_accuracy_branch1": 1.0,
      "eval_accuracy_branch2": 0.4096042745676726,
      "eval_f1_branch1": 1.0,
      "eval_f1_branch2": 0.4026878586879057,
      "eval_loss": 6.804990704267766e-08,
      "eval_precision_branch1": 1.0,
      "eval_precision_branch2": 0.5014715812427437,
      "eval_recall_branch1": 1.0,
      "eval_recall_branch2": 0.5011573739185787,
      "eval_runtime": 239.685,
      "eval_samples_per_second": 432.58,
      "eval_steps_per_second": 54.075,
      "step": 142604
    },
    {
      "epoch": 44.00185128046899,
      "grad_norm": 3.672169623314403e-05,
      "learning_rate": 5.998148719531009e-06,
      "loss": 0.0,
      "step": 142610
    },
    {
      "epoch": 44.00493674791731,
      "grad_norm": 1.7031345223017524e-08,
      "learning_rate": 5.995063252082691e-06,
      "loss": 0.0,
      "step": 142620
    },
    {
      "epoch": 44.00802221536563,
      "grad_norm": 9.596397831046488e-06,
      "learning_rate": 5.991977784634372e-06,
      "loss": 0.0,
      "step": 142630
    },
    {
      "epoch": 44.01110768281394,
      "grad_norm": 1.3493153119270573e-06,
      "learning_rate": 5.988892317186054e-06,
      "loss": 0.0,
      "step": 142640
    },
    {
      "epoch": 44.014193150262265,
      "grad_norm": 4.286220701033017e-06,
      "learning_rate": 5.985806849737736e-06,
      "loss": 0.0,
      "step": 142650
    },
    {
      "epoch": 44.01727861771058,
      "grad_norm": 7.937187547213398e-06,
      "learning_rate": 5.982721382289417e-06,
      "loss": 0.0,
      "step": 142660
    },
    {
      "epoch": 44.0203640851589,
      "grad_norm": 3.2811355854533986e-09,
      "learning_rate": 5.9796359148410986e-06,
      "loss": 0.0,
      "step": 142670
    },
    {
      "epoch": 44.02344955260722,
      "grad_norm": 3.483296495687682e-07,
      "learning_rate": 5.97655044739278e-06,
      "loss": 0.0,
      "step": 142680
    },
    {
      "epoch": 44.02653502005554,
      "grad_norm": 1.1192437199269989e-08,
      "learning_rate": 5.973464979944462e-06,
      "loss": 0.0,
      "step": 142690
    },
    {
      "epoch": 44.029620487503855,
      "grad_norm": 9.521524013678118e-09,
      "learning_rate": 5.9703795124961435e-06,
      "loss": 0.0,
      "step": 142700
    },
    {
      "epoch": 44.03270595495218,
      "grad_norm": 0.0046151066198945045,
      "learning_rate": 5.967294045047825e-06,
      "loss": 0.0,
      "step": 142710
    },
    {
      "epoch": 44.03579142240049,
      "grad_norm": 8.615630235908611e-07,
      "learning_rate": 5.964208577599507e-06,
      "loss": 0.0,
      "step": 142720
    },
    {
      "epoch": 44.038876889848815,
      "grad_norm": 7.73526487307663e-09,
      "learning_rate": 5.9611231101511875e-06,
      "loss": 0.0,
      "step": 142730
    },
    {
      "epoch": 44.04196235729713,
      "grad_norm": 2.5926512989826733e-06,
      "learning_rate": 5.95803764270287e-06,
      "loss": 0.0,
      "step": 142740
    },
    {
      "epoch": 44.045047824745446,
      "grad_norm": 2.1429764274216723e-06,
      "learning_rate": 5.954952175254552e-06,
      "loss": 0.0,
      "step": 142750
    },
    {
      "epoch": 44.04813329219377,
      "grad_norm": 1.7689042124402476e-06,
      "learning_rate": 5.951866707806232e-06,
      "loss": 0.0,
      "step": 142760
    },
    {
      "epoch": 44.05121875964208,
      "grad_norm": 3.708152871695347e-05,
      "learning_rate": 5.948781240357915e-06,
      "loss": 0.0,
      "step": 142770
    },
    {
      "epoch": 44.054304227090405,
      "grad_norm": 7.366811018982844e-07,
      "learning_rate": 5.945695772909596e-06,
      "loss": 0.0,
      "step": 142780
    },
    {
      "epoch": 44.05738969453872,
      "grad_norm": 2.654742957020062e-06,
      "learning_rate": 5.942610305461277e-06,
      "loss": 0.0,
      "step": 142790
    },
    {
      "epoch": 44.06047516198704,
      "grad_norm": 3.0355802664416842e-05,
      "learning_rate": 5.93952483801296e-06,
      "loss": 0.0,
      "step": 142800
    },
    {
      "epoch": 44.06356062943536,
      "grad_norm": 3.8200300878088456e-07,
      "learning_rate": 5.9364393705646405e-06,
      "loss": 0.0,
      "step": 142810
    },
    {
      "epoch": 44.06664609688368,
      "grad_norm": 9.44870862440439e-06,
      "learning_rate": 5.933353903116322e-06,
      "loss": 0.0,
      "step": 142820
    },
    {
      "epoch": 44.069731564331995,
      "grad_norm": 5.005935577173659e-07,
      "learning_rate": 5.930268435668004e-06,
      "loss": 0.0,
      "step": 142830
    },
    {
      "epoch": 44.07281703178032,
      "grad_norm": 1.741022629175859e-06,
      "learning_rate": 5.9271829682196854e-06,
      "loss": 0.0,
      "step": 142840
    },
    {
      "epoch": 44.07590249922863,
      "grad_norm": 2.0172281622876653e-08,
      "learning_rate": 5.924097500771367e-06,
      "loss": 0.0,
      "step": 142850
    },
    {
      "epoch": 44.078987966676955,
      "grad_norm": 2.4050848423939897e-07,
      "learning_rate": 5.921012033323049e-06,
      "loss": 0.0,
      "step": 142860
    },
    {
      "epoch": 44.08207343412527,
      "grad_norm": 2.284015998554878e-08,
      "learning_rate": 5.91792656587473e-06,
      "loss": 0.0,
      "step": 142870
    },
    {
      "epoch": 44.085158901573585,
      "grad_norm": 6.527664595523675e-07,
      "learning_rate": 5.914841098426412e-06,
      "loss": 0.0,
      "step": 142880
    },
    {
      "epoch": 44.08824436902191,
      "grad_norm": 1.4650465800514212e-06,
      "learning_rate": 5.911755630978094e-06,
      "loss": 0.0,
      "step": 142890
    },
    {
      "epoch": 44.09132983647022,
      "grad_norm": 1.3424973487854004,
      "learning_rate": 5.908670163529775e-06,
      "loss": 0.0007,
      "step": 142900
    },
    {
      "epoch": 44.094415303918545,
      "grad_norm": 0.0003833115624729544,
      "learning_rate": 5.905584696081457e-06,
      "loss": 0.0,
      "step": 142910
    },
    {
      "epoch": 44.09750077136686,
      "grad_norm": 8.725712064006075e-07,
      "learning_rate": 5.9024992286331385e-06,
      "loss": 0.0,
      "step": 142920
    },
    {
      "epoch": 44.10058623881518,
      "grad_norm": 1.8566861399449408e-06,
      "learning_rate": 5.899413761184819e-06,
      "loss": 0.0,
      "step": 142930
    },
    {
      "epoch": 44.1036717062635,
      "grad_norm": 3.595009911805391e-05,
      "learning_rate": 5.896328293736502e-06,
      "loss": 0.0004,
      "step": 142940
    },
    {
      "epoch": 44.10675717371182,
      "grad_norm": 3.078848180848581e-07,
      "learning_rate": 5.893242826288183e-06,
      "loss": 0.0001,
      "step": 142950
    },
    {
      "epoch": 44.109842641160135,
      "grad_norm": 5.661932505063305e-07,
      "learning_rate": 5.890157358839864e-06,
      "loss": 0.0,
      "step": 142960
    },
    {
      "epoch": 44.11292810860846,
      "grad_norm": 7.982087481650524e-06,
      "learning_rate": 5.887071891391547e-06,
      "loss": 0.0,
      "step": 142970
    },
    {
      "epoch": 44.11601357605677,
      "grad_norm": 1.4453567928285338e-05,
      "learning_rate": 5.883986423943227e-06,
      "loss": 0.0,
      "step": 142980
    },
    {
      "epoch": 44.11909904350509,
      "grad_norm": 1.0584803931124043e-06,
      "learning_rate": 5.880900956494909e-06,
      "loss": 0.0,
      "step": 142990
    },
    {
      "epoch": 44.12218451095341,
      "grad_norm": 5.3268349802237935e-06,
      "learning_rate": 5.8778154890465915e-06,
      "loss": 0.0,
      "step": 143000
    },
    {
      "epoch": 44.125269978401725,
      "grad_norm": 1.039237029765161e-09,
      "learning_rate": 5.874730021598272e-06,
      "loss": 0.0,
      "step": 143010
    },
    {
      "epoch": 44.12835544585005,
      "grad_norm": 6.758329504918947e-07,
      "learning_rate": 5.871644554149954e-06,
      "loss": 0.0,
      "step": 143020
    },
    {
      "epoch": 44.13144091329836,
      "grad_norm": 4.23187630076427e-05,
      "learning_rate": 5.8685590867016356e-06,
      "loss": 0.0,
      "step": 143030
    },
    {
      "epoch": 44.134526380746685,
      "grad_norm": 2.935419445293519e-07,
      "learning_rate": 5.865473619253317e-06,
      "loss": 0.0,
      "step": 143040
    },
    {
      "epoch": 44.137611848195,
      "grad_norm": 2.3039137886371464e-05,
      "learning_rate": 5.862388151804999e-06,
      "loss": 0.0,
      "step": 143050
    },
    {
      "epoch": 44.14069731564332,
      "grad_norm": 0.0009030080982483923,
      "learning_rate": 5.8593026843566804e-06,
      "loss": 0.0,
      "step": 143060
    },
    {
      "epoch": 44.14378278309164,
      "grad_norm": 1.9074700929877508e-08,
      "learning_rate": 5.856217216908362e-06,
      "loss": 0.0,
      "step": 143070
    },
    {
      "epoch": 44.14686825053996,
      "grad_norm": 2.9284075164781598e-09,
      "learning_rate": 5.853131749460043e-06,
      "loss": 0.0,
      "step": 143080
    },
    {
      "epoch": 44.149953717988275,
      "grad_norm": 3.346848842511463e-08,
      "learning_rate": 5.850046282011725e-06,
      "loss": 0.0,
      "step": 143090
    },
    {
      "epoch": 44.15303918543659,
      "grad_norm": 1.4006968740432058e-06,
      "learning_rate": 5.846960814563407e-06,
      "loss": 0.0002,
      "step": 143100
    },
    {
      "epoch": 44.15612465288491,
      "grad_norm": 1.227084248967003e-05,
      "learning_rate": 5.843875347115088e-06,
      "loss": 0.0,
      "step": 143110
    },
    {
      "epoch": 44.15921012033323,
      "grad_norm": 8.552533472538926e-07,
      "learning_rate": 5.84078987966677e-06,
      "loss": 0.0,
      "step": 143120
    },
    {
      "epoch": 44.16229558778155,
      "grad_norm": 4.839237988107925e-08,
      "learning_rate": 5.837704412218451e-06,
      "loss": 0.0,
      "step": 143130
    },
    {
      "epoch": 44.165381055229865,
      "grad_norm": 1.5342664028139552e-06,
      "learning_rate": 5.834618944770133e-06,
      "loss": 0.0,
      "step": 143140
    },
    {
      "epoch": 44.16846652267819,
      "grad_norm": 4.346427384671614e-10,
      "learning_rate": 5.831533477321815e-06,
      "loss": 0.0,
      "step": 143150
    },
    {
      "epoch": 44.1715519901265,
      "grad_norm": 8.478913514409214e-05,
      "learning_rate": 5.828448009873496e-06,
      "loss": 0.0,
      "step": 143160
    },
    {
      "epoch": 44.174637457574825,
      "grad_norm": 9.647539627621882e-06,
      "learning_rate": 5.8253625424251775e-06,
      "loss": 0.0,
      "step": 143170
    },
    {
      "epoch": 44.17772292502314,
      "grad_norm": 7.759297915299612e-08,
      "learning_rate": 5.822277074976859e-06,
      "loss": 0.0,
      "step": 143180
    },
    {
      "epoch": 44.18080839247146,
      "grad_norm": 6.247430519579211e-06,
      "learning_rate": 5.819191607528541e-06,
      "loss": 0.0,
      "step": 143190
    },
    {
      "epoch": 44.18389385991978,
      "grad_norm": 9.166277514793819e-09,
      "learning_rate": 5.816106140080222e-06,
      "loss": 0.0005,
      "step": 143200
    },
    {
      "epoch": 44.1869793273681,
      "grad_norm": 2.2603693139444658e-07,
      "learning_rate": 5.813020672631904e-06,
      "loss": 0.0,
      "step": 143210
    },
    {
      "epoch": 44.190064794816415,
      "grad_norm": 0.05517646297812462,
      "learning_rate": 5.809935205183586e-06,
      "loss": 0.0,
      "step": 143220
    },
    {
      "epoch": 44.19315026226473,
      "grad_norm": 6.966117638285141e-08,
      "learning_rate": 5.806849737735267e-06,
      "loss": 0.0,
      "step": 143230
    },
    {
      "epoch": 44.19623572971305,
      "grad_norm": 3.1164749088929966e-05,
      "learning_rate": 5.803764270286949e-06,
      "loss": 0.0,
      "step": 143240
    },
    {
      "epoch": 44.19932119716137,
      "grad_norm": 3.6421097320271656e-06,
      "learning_rate": 5.8006788028386306e-06,
      "loss": 0.0002,
      "step": 143250
    },
    {
      "epoch": 44.20240666460969,
      "grad_norm": 1.3692794027519994e-06,
      "learning_rate": 5.797593335390312e-06,
      "loss": 0.0,
      "step": 143260
    },
    {
      "epoch": 44.205492132058005,
      "grad_norm": 6.945551831449848e-06,
      "learning_rate": 5.794507867941994e-06,
      "loss": 0.0,
      "step": 143270
    },
    {
      "epoch": 44.20857759950633,
      "grad_norm": 5.415654413809534e-07,
      "learning_rate": 5.791422400493675e-06,
      "loss": 0.0,
      "step": 143280
    },
    {
      "epoch": 44.21166306695464,
      "grad_norm": 9.949967534339521e-07,
      "learning_rate": 5.788336933045357e-06,
      "loss": 0.0001,
      "step": 143290
    },
    {
      "epoch": 44.214748534402965,
      "grad_norm": 6.488348844868597e-06,
      "learning_rate": 5.785251465597039e-06,
      "loss": 0.0,
      "step": 143300
    },
    {
      "epoch": 44.21783400185128,
      "grad_norm": 0.011674510315060616,
      "learning_rate": 5.7821659981487195e-06,
      "loss": 0.0,
      "step": 143310
    },
    {
      "epoch": 44.2209194692996,
      "grad_norm": 3.2353582035682393e-09,
      "learning_rate": 5.779080530700402e-06,
      "loss": 0.0,
      "step": 143320
    },
    {
      "epoch": 44.22400493674792,
      "grad_norm": 1.2018031902982784e-08,
      "learning_rate": 5.775995063252083e-06,
      "loss": 0.0,
      "step": 143330
    },
    {
      "epoch": 44.22709040419623,
      "grad_norm": 6.882858724566177e-05,
      "learning_rate": 5.772909595803764e-06,
      "loss": 0.0,
      "step": 143340
    },
    {
      "epoch": 44.230175871644555,
      "grad_norm": 4.102087416413269e-07,
      "learning_rate": 5.769824128355447e-06,
      "loss": 0.0,
      "step": 143350
    },
    {
      "epoch": 44.23326133909287,
      "grad_norm": 9.289062745665433e-07,
      "learning_rate": 5.766738660907128e-06,
      "loss": 0.0,
      "step": 143360
    },
    {
      "epoch": 44.23634680654119,
      "grad_norm": 1.2091069265807164e-06,
      "learning_rate": 5.763653193458809e-06,
      "loss": 0.0,
      "step": 143370
    },
    {
      "epoch": 44.23943227398951,
      "grad_norm": 2.9003629720136814e-07,
      "learning_rate": 5.760567726010491e-06,
      "loss": 0.0,
      "step": 143380
    },
    {
      "epoch": 44.24251774143783,
      "grad_norm": 3.6225937805056674e-08,
      "learning_rate": 5.7574822585621725e-06,
      "loss": 0.0,
      "step": 143390
    },
    {
      "epoch": 44.245603208886145,
      "grad_norm": 1.8933339163140772e-07,
      "learning_rate": 5.754396791113853e-06,
      "loss": 0.0,
      "step": 143400
    },
    {
      "epoch": 44.24868867633447,
      "grad_norm": 4.493391614346365e-08,
      "learning_rate": 5.751311323665536e-06,
      "loss": 0.0,
      "step": 143410
    },
    {
      "epoch": 44.25177414378278,
      "grad_norm": 1.0610499430185882e-06,
      "learning_rate": 5.7482258562172174e-06,
      "loss": 0.0001,
      "step": 143420
    },
    {
      "epoch": 44.254859611231105,
      "grad_norm": 0.0001633043575566262,
      "learning_rate": 5.745140388768898e-06,
      "loss": 0.0,
      "step": 143430
    },
    {
      "epoch": 44.25794507867942,
      "grad_norm": 7.708176781306975e-06,
      "learning_rate": 5.742054921320581e-06,
      "loss": 0.0,
      "step": 143440
    },
    {
      "epoch": 44.261030546127735,
      "grad_norm": 1.4478739103651606e-05,
      "learning_rate": 5.7389694538722615e-06,
      "loss": 0.0,
      "step": 143450
    },
    {
      "epoch": 44.26411601357606,
      "grad_norm": 1.3070256272840197e-06,
      "learning_rate": 5.735883986423943e-06,
      "loss": 0.0,
      "step": 143460
    },
    {
      "epoch": 44.26720148102437,
      "grad_norm": 3.68789841331818e-07,
      "learning_rate": 5.732798518975626e-06,
      "loss": 0.0,
      "step": 143470
    },
    {
      "epoch": 44.270286948472695,
      "grad_norm": 1.722009187687945e-06,
      "learning_rate": 5.729713051527306e-06,
      "loss": 0.0,
      "step": 143480
    },
    {
      "epoch": 44.27337241592101,
      "grad_norm": 5.195745700348198e-08,
      "learning_rate": 5.726627584078988e-06,
      "loss": 0.0,
      "step": 143490
    },
    {
      "epoch": 44.27645788336933,
      "grad_norm": 0.0035330893006175756,
      "learning_rate": 5.72354211663067e-06,
      "loss": 0.0,
      "step": 143500
    },
    {
      "epoch": 44.27954335081765,
      "grad_norm": 2.7101134492113488e-06,
      "learning_rate": 5.720456649182351e-06,
      "loss": 0.0001,
      "step": 143510
    },
    {
      "epoch": 44.28262881826597,
      "grad_norm": 2.116703399224207e-06,
      "learning_rate": 5.717371181734033e-06,
      "loss": 0.0,
      "step": 143520
    },
    {
      "epoch": 44.285714285714285,
      "grad_norm": 0.0001602560223545879,
      "learning_rate": 5.7142857142857145e-06,
      "loss": 0.0,
      "step": 143530
    },
    {
      "epoch": 44.28879975316261,
      "grad_norm": 1.6483303397762938e-06,
      "learning_rate": 5.711200246837396e-06,
      "loss": 0.0,
      "step": 143540
    },
    {
      "epoch": 44.29188522061092,
      "grad_norm": 1.8820815057551954e-06,
      "learning_rate": 5.708114779389078e-06,
      "loss": 0.0,
      "step": 143550
    },
    {
      "epoch": 44.294970688059244,
      "grad_norm": 5.796834443572152e-07,
      "learning_rate": 5.705029311940759e-06,
      "loss": 0.0,
      "step": 143560
    },
    {
      "epoch": 44.29805615550756,
      "grad_norm": 0.00032011736766435206,
      "learning_rate": 5.701943844492441e-06,
      "loss": 0.0,
      "step": 143570
    },
    {
      "epoch": 44.301141622955875,
      "grad_norm": 2.6162924768868834e-05,
      "learning_rate": 5.698858377044123e-06,
      "loss": 0.0,
      "step": 143580
    },
    {
      "epoch": 44.3042270904042,
      "grad_norm": 3.0584800470023765e-07,
      "learning_rate": 5.695772909595804e-06,
      "loss": 0.0,
      "step": 143590
    },
    {
      "epoch": 44.30731255785251,
      "grad_norm": 9.449414051232452e-07,
      "learning_rate": 5.692687442147485e-06,
      "loss": 0.0,
      "step": 143600
    },
    {
      "epoch": 44.310398025300834,
      "grad_norm": 0.0007030136184766889,
      "learning_rate": 5.6896019746991676e-06,
      "loss": 0.0,
      "step": 143610
    },
    {
      "epoch": 44.31348349274915,
      "grad_norm": 1.996140554183512e-06,
      "learning_rate": 5.686516507250849e-06,
      "loss": 0.0,
      "step": 143620
    },
    {
      "epoch": 44.31656896019747,
      "grad_norm": 0.00010576958447927609,
      "learning_rate": 5.68343103980253e-06,
      "loss": 0.0,
      "step": 143630
    },
    {
      "epoch": 44.31965442764579,
      "grad_norm": 4.135279596084729e-05,
      "learning_rate": 5.6803455723542124e-06,
      "loss": 0.0001,
      "step": 143640
    },
    {
      "epoch": 44.32273989509411,
      "grad_norm": 3.5800709952127363e-07,
      "learning_rate": 5.677260104905893e-06,
      "loss": 0.0,
      "step": 143650
    },
    {
      "epoch": 44.325825362542425,
      "grad_norm": 2.6570753561827587e-06,
      "learning_rate": 5.674174637457575e-06,
      "loss": 0.0,
      "step": 143660
    },
    {
      "epoch": 44.32891082999075,
      "grad_norm": 0.0009845888707786798,
      "learning_rate": 5.671089170009257e-06,
      "loss": 0.0,
      "step": 143670
    },
    {
      "epoch": 44.33199629743906,
      "grad_norm": 2.79148906656701e-07,
      "learning_rate": 5.668003702560938e-06,
      "loss": 0.0,
      "step": 143680
    },
    {
      "epoch": 44.33508176488738,
      "grad_norm": 9.438981942366809e-05,
      "learning_rate": 5.66491823511262e-06,
      "loss": 0.0,
      "step": 143690
    },
    {
      "epoch": 44.3381672323357,
      "grad_norm": 7.078150332517907e-08,
      "learning_rate": 5.661832767664301e-06,
      "loss": 0.0,
      "step": 143700
    },
    {
      "epoch": 44.341252699784015,
      "grad_norm": 4.105755238015263e-07,
      "learning_rate": 5.658747300215983e-06,
      "loss": 0.0,
      "step": 143710
    },
    {
      "epoch": 44.34433816723234,
      "grad_norm": 1.3810437167194323e-06,
      "learning_rate": 5.655661832767665e-06,
      "loss": 0.0,
      "step": 143720
    },
    {
      "epoch": 44.34742363468065,
      "grad_norm": 2.155451372942707e-09,
      "learning_rate": 5.652576365319346e-06,
      "loss": 0.0,
      "step": 143730
    },
    {
      "epoch": 44.350509102128974,
      "grad_norm": 5.329763439476665e-07,
      "learning_rate": 5.649490897871028e-06,
      "loss": 0.0,
      "step": 143740
    },
    {
      "epoch": 44.35359456957729,
      "grad_norm": 4.447161245479947e-06,
      "learning_rate": 5.646405430422709e-06,
      "loss": 0.0,
      "step": 143750
    },
    {
      "epoch": 44.35668003702561,
      "grad_norm": 9.207070661432226e-07,
      "learning_rate": 5.643319962974391e-06,
      "loss": 0.0,
      "step": 143760
    },
    {
      "epoch": 44.35976550447393,
      "grad_norm": 4.807960749531048e-07,
      "learning_rate": 5.640234495526073e-06,
      "loss": 0.0,
      "step": 143770
    },
    {
      "epoch": 44.36285097192225,
      "grad_norm": 3.615440036242035e-08,
      "learning_rate": 5.6371490280777536e-06,
      "loss": 0.0,
      "step": 143780
    },
    {
      "epoch": 44.365936439370564,
      "grad_norm": 0.0001085035182768479,
      "learning_rate": 5.634063560629436e-06,
      "loss": 0.0,
      "step": 143790
    },
    {
      "epoch": 44.36902190681888,
      "grad_norm": 3.255140086366737e-07,
      "learning_rate": 5.630978093181117e-06,
      "loss": 0.0,
      "step": 143800
    },
    {
      "epoch": 44.3721073742672,
      "grad_norm": 1.1240786079724785e-05,
      "learning_rate": 5.6278926257327985e-06,
      "loss": 0.0,
      "step": 143810
    },
    {
      "epoch": 44.37519284171552,
      "grad_norm": 5.34497758053476e-06,
      "learning_rate": 5.624807158284481e-06,
      "loss": 0.0,
      "step": 143820
    },
    {
      "epoch": 44.37827830916384,
      "grad_norm": 6.214822860783897e-06,
      "learning_rate": 5.621721690836162e-06,
      "loss": 0.0,
      "step": 143830
    },
    {
      "epoch": 44.381363776612154,
      "grad_norm": 1.5113167606273237e-08,
      "learning_rate": 5.618636223387843e-06,
      "loss": 0.0,
      "step": 143840
    },
    {
      "epoch": 44.38444924406048,
      "grad_norm": 6.784770523182715e-10,
      "learning_rate": 5.615550755939525e-06,
      "loss": 0.0,
      "step": 143850
    },
    {
      "epoch": 44.38753471150879,
      "grad_norm": 4.884405102600908e-10,
      "learning_rate": 5.612465288491207e-06,
      "loss": 0.0,
      "step": 143860
    },
    {
      "epoch": 44.390620178957114,
      "grad_norm": 0.001543601742014289,
      "learning_rate": 5.609379821042888e-06,
      "loss": 0.0,
      "step": 143870
    },
    {
      "epoch": 44.39370564640543,
      "grad_norm": 2.4777035978473805e-09,
      "learning_rate": 5.60629435359457e-06,
      "loss": 0.0,
      "step": 143880
    },
    {
      "epoch": 44.39679111385375,
      "grad_norm": 1.9027471154231534e-08,
      "learning_rate": 5.6032088861462515e-06,
      "loss": 0.0,
      "step": 143890
    },
    {
      "epoch": 44.39987658130207,
      "grad_norm": 7.735391882590648e-09,
      "learning_rate": 5.600123418697933e-06,
      "loss": 0.0001,
      "step": 143900
    },
    {
      "epoch": 44.40296204875039,
      "grad_norm": 1.888919996417826e-06,
      "learning_rate": 5.597037951249615e-06,
      "loss": 0.0,
      "step": 143910
    },
    {
      "epoch": 44.406047516198704,
      "grad_norm": 1.1619974429777358e-05,
      "learning_rate": 5.593952483801296e-06,
      "loss": 0.0,
      "step": 143920
    },
    {
      "epoch": 44.40913298364702,
      "grad_norm": 0.0001278795680264011,
      "learning_rate": 5.590867016352978e-06,
      "loss": 0.0,
      "step": 143930
    },
    {
      "epoch": 44.41221845109534,
      "grad_norm": 1.2682159766796985e-09,
      "learning_rate": 5.58778154890466e-06,
      "loss": 0.0011,
      "step": 143940
    },
    {
      "epoch": 44.41530391854366,
      "grad_norm": 1.3476487481511867e-08,
      "learning_rate": 5.5846960814563404e-06,
      "loss": 0.0,
      "step": 143950
    },
    {
      "epoch": 44.41838938599198,
      "grad_norm": 2.4006427956635434e-09,
      "learning_rate": 5.581610614008023e-06,
      "loss": 0.0,
      "step": 143960
    },
    {
      "epoch": 44.421474853440294,
      "grad_norm": 2.417159237211308e-07,
      "learning_rate": 5.5785251465597045e-06,
      "loss": 0.0,
      "step": 143970
    },
    {
      "epoch": 44.42456032088862,
      "grad_norm": 1.9205689483214883e-08,
      "learning_rate": 5.575439679111385e-06,
      "loss": 0.0,
      "step": 143980
    },
    {
      "epoch": 44.42764578833693,
      "grad_norm": 2.1892990531569012e-08,
      "learning_rate": 5.572354211663068e-06,
      "loss": 0.0,
      "step": 143990
    },
    {
      "epoch": 44.430731255785254,
      "grad_norm": 1.8983159861818422e-06,
      "learning_rate": 5.569268744214749e-06,
      "loss": 0.0,
      "step": 144000
    },
    {
      "epoch": 44.43381672323357,
      "grad_norm": 4.576327858329954e-11,
      "learning_rate": 5.56618327676643e-06,
      "loss": 0.0,
      "step": 144010
    },
    {
      "epoch": 44.43690219068189,
      "grad_norm": 2.603402471379468e-08,
      "learning_rate": 5.563097809318113e-06,
      "loss": 0.0,
      "step": 144020
    },
    {
      "epoch": 44.43998765813021,
      "grad_norm": 2.2163098947203252e-06,
      "learning_rate": 5.5600123418697935e-06,
      "loss": 0.0,
      "step": 144030
    },
    {
      "epoch": 44.44307312557852,
      "grad_norm": 2.0185798632610386e-07,
      "learning_rate": 5.556926874421475e-06,
      "loss": 0.0,
      "step": 144040
    },
    {
      "epoch": 44.446158593026844,
      "grad_norm": 8.273572348116431e-06,
      "learning_rate": 5.553841406973157e-06,
      "loss": 0.0001,
      "step": 144050
    },
    {
      "epoch": 44.44924406047516,
      "grad_norm": 5.401653790926275e-09,
      "learning_rate": 5.550755939524838e-06,
      "loss": 0.0,
      "step": 144060
    },
    {
      "epoch": 44.45232952792348,
      "grad_norm": 3.5805205698125064e-06,
      "learning_rate": 5.54767047207652e-06,
      "loss": 0.0,
      "step": 144070
    },
    {
      "epoch": 44.4554149953718,
      "grad_norm": 4.3232940782900187e-08,
      "learning_rate": 5.544585004628202e-06,
      "loss": 0.0,
      "step": 144080
    },
    {
      "epoch": 44.45850046282012,
      "grad_norm": 2.581524859124329e-05,
      "learning_rate": 5.541499537179883e-06,
      "loss": 0.0,
      "step": 144090
    },
    {
      "epoch": 44.461585930268434,
      "grad_norm": 2.6500071470536568e-08,
      "learning_rate": 5.538414069731564e-06,
      "loss": 0.0,
      "step": 144100
    },
    {
      "epoch": 44.46467139771676,
      "grad_norm": 0.000345181324519217,
      "learning_rate": 5.5353286022832465e-06,
      "loss": 0.0,
      "step": 144110
    },
    {
      "epoch": 44.46775686516507,
      "grad_norm": 8.425509179232904e-09,
      "learning_rate": 5.532243134834928e-06,
      "loss": 0.0,
      "step": 144120
    },
    {
      "epoch": 44.470842332613394,
      "grad_norm": 3.3001035237845144e-09,
      "learning_rate": 5.529157667386609e-06,
      "loss": 0.0,
      "step": 144130
    },
    {
      "epoch": 44.47392780006171,
      "grad_norm": 4.090500806341879e-05,
      "learning_rate": 5.526072199938291e-06,
      "loss": 0.0,
      "step": 144140
    },
    {
      "epoch": 44.477013267510024,
      "grad_norm": 6.563447641383391e-06,
      "learning_rate": 5.522986732489972e-06,
      "loss": 0.0,
      "step": 144150
    },
    {
      "epoch": 44.48009873495835,
      "grad_norm": 7.527666525675158e-07,
      "learning_rate": 5.519901265041654e-06,
      "loss": 0.0003,
      "step": 144160
    },
    {
      "epoch": 44.48318420240666,
      "grad_norm": 3.3473265830252785e-06,
      "learning_rate": 5.516815797593336e-06,
      "loss": 0.0,
      "step": 144170
    },
    {
      "epoch": 44.486269669854984,
      "grad_norm": 5.076877229726051e-08,
      "learning_rate": 5.513730330145017e-06,
      "loss": 0.0,
      "step": 144180
    },
    {
      "epoch": 44.4893551373033,
      "grad_norm": 2.5957597244996578e-06,
      "learning_rate": 5.510644862696699e-06,
      "loss": 0.0,
      "step": 144190
    },
    {
      "epoch": 44.49244060475162,
      "grad_norm": 3.135057568215416e-06,
      "learning_rate": 5.50755939524838e-06,
      "loss": 0.0,
      "step": 144200
    },
    {
      "epoch": 44.49552607219994,
      "grad_norm": 2.3329850591835566e-05,
      "learning_rate": 5.504473927800062e-06,
      "loss": 0.0,
      "step": 144210
    },
    {
      "epoch": 44.49861153964826,
      "grad_norm": 7.701741537857743e-07,
      "learning_rate": 5.501388460351744e-06,
      "loss": 0.0,
      "step": 144220
    },
    {
      "epoch": 44.501697007096574,
      "grad_norm": 4.791302998796709e-08,
      "learning_rate": 5.498302992903425e-06,
      "loss": 0.0,
      "step": 144230
    },
    {
      "epoch": 44.504782474544896,
      "grad_norm": 1.1035301668016473e-06,
      "learning_rate": 5.495217525455107e-06,
      "loss": 0.0,
      "step": 144240
    },
    {
      "epoch": 44.50786794199321,
      "grad_norm": 1.2903348611814636e-08,
      "learning_rate": 5.4921320580067885e-06,
      "loss": 0.0,
      "step": 144250
    },
    {
      "epoch": 44.510953409441534,
      "grad_norm": 7.090863505254674e-07,
      "learning_rate": 5.48904659055847e-06,
      "loss": 0.0,
      "step": 144260
    },
    {
      "epoch": 44.51403887688985,
      "grad_norm": 1.4062849551521595e-08,
      "learning_rate": 5.485961123110151e-06,
      "loss": 0.0,
      "step": 144270
    },
    {
      "epoch": 44.517124344338164,
      "grad_norm": 4.3998321075378044e-07,
      "learning_rate": 5.482875655661833e-06,
      "loss": 0.0,
      "step": 144280
    },
    {
      "epoch": 44.520209811786486,
      "grad_norm": 3.6660530167154093e-10,
      "learning_rate": 5.479790188213515e-06,
      "loss": 0.0,
      "step": 144290
    },
    {
      "epoch": 44.5232952792348,
      "grad_norm": 3.0755047646380262e-06,
      "learning_rate": 5.476704720765196e-06,
      "loss": 0.0,
      "step": 144300
    },
    {
      "epoch": 44.526380746683124,
      "grad_norm": 3.8958523873589e-07,
      "learning_rate": 5.473619253316878e-06,
      "loss": 0.0,
      "step": 144310
    },
    {
      "epoch": 44.52946621413144,
      "grad_norm": 1.579358155368027e-07,
      "learning_rate": 5.470533785868559e-06,
      "loss": 0.0,
      "step": 144320
    },
    {
      "epoch": 44.53255168157976,
      "grad_norm": 0.0002562427835073322,
      "learning_rate": 5.467448318420241e-06,
      "loss": 0.0,
      "step": 144330
    },
    {
      "epoch": 44.53563714902808,
      "grad_norm": 2.2764077129977522e-06,
      "learning_rate": 5.464362850971923e-06,
      "loss": 0.0001,
      "step": 144340
    },
    {
      "epoch": 44.5387226164764,
      "grad_norm": 1.6714466255507432e-06,
      "learning_rate": 5.461277383523604e-06,
      "loss": 0.0,
      "step": 144350
    },
    {
      "epoch": 44.541808083924714,
      "grad_norm": 8.676017237974065e-09,
      "learning_rate": 5.4581919160752856e-06,
      "loss": 0.0,
      "step": 144360
    },
    {
      "epoch": 44.544893551373036,
      "grad_norm": 1.1469056815371914e-08,
      "learning_rate": 5.455106448626967e-06,
      "loss": 0.0,
      "step": 144370
    },
    {
      "epoch": 44.54797901882135,
      "grad_norm": 9.119357127929106e-05,
      "learning_rate": 5.452020981178649e-06,
      "loss": 0.0,
      "step": 144380
    },
    {
      "epoch": 44.55106448626967,
      "grad_norm": 6.817334678999032e-07,
      "learning_rate": 5.4489355137303305e-06,
      "loss": 0.0,
      "step": 144390
    },
    {
      "epoch": 44.55414995371799,
      "grad_norm": 1.2786921388396877e-06,
      "learning_rate": 5.445850046282012e-06,
      "loss": 0.0,
      "step": 144400
    },
    {
      "epoch": 44.557235421166304,
      "grad_norm": 3.204318090865854e-07,
      "learning_rate": 5.442764578833694e-06,
      "loss": 0.0,
      "step": 144410
    },
    {
      "epoch": 44.560320888614626,
      "grad_norm": 1.4744212421646807e-05,
      "learning_rate": 5.4396791113853745e-06,
      "loss": 0.0,
      "step": 144420
    },
    {
      "epoch": 44.56340635606294,
      "grad_norm": 1.7025250542701542e-07,
      "learning_rate": 5.436593643937057e-06,
      "loss": 0.0,
      "step": 144430
    },
    {
      "epoch": 44.566491823511264,
      "grad_norm": 8.6685586211388e-06,
      "learning_rate": 5.433508176488739e-06,
      "loss": 0.0,
      "step": 144440
    },
    {
      "epoch": 44.56957729095958,
      "grad_norm": 7.82603383413516e-05,
      "learning_rate": 5.430422709040419e-06,
      "loss": 0.0,
      "step": 144450
    },
    {
      "epoch": 44.5726627584079,
      "grad_norm": 1.263115905203449e-07,
      "learning_rate": 5.427337241592102e-06,
      "loss": 0.0,
      "step": 144460
    },
    {
      "epoch": 44.575748225856216,
      "grad_norm": 1.2897229680675082e-05,
      "learning_rate": 5.424251774143783e-06,
      "loss": 0.0,
      "step": 144470
    },
    {
      "epoch": 44.57883369330454,
      "grad_norm": 0.0010122701060026884,
      "learning_rate": 5.421166306695464e-06,
      "loss": 0.0,
      "step": 144480
    },
    {
      "epoch": 44.581919160752854,
      "grad_norm": 2.0426998981193378e-10,
      "learning_rate": 5.418080839247147e-06,
      "loss": 0.0001,
      "step": 144490
    },
    {
      "epoch": 44.585004628201176,
      "grad_norm": 0.025158056989312172,
      "learning_rate": 5.4149953717988275e-06,
      "loss": 0.0,
      "step": 144500
    },
    {
      "epoch": 44.58809009564949,
      "grad_norm": 3.1930053978612705e-07,
      "learning_rate": 5.411909904350509e-06,
      "loss": 0.0,
      "step": 144510
    },
    {
      "epoch": 44.591175563097806,
      "grad_norm": 5.43104441419473e-08,
      "learning_rate": 5.408824436902191e-06,
      "loss": 0.0,
      "step": 144520
    },
    {
      "epoch": 44.59426103054613,
      "grad_norm": 0.001245827996172011,
      "learning_rate": 5.4057389694538724e-06,
      "loss": 0.0,
      "step": 144530
    },
    {
      "epoch": 44.597346497994444,
      "grad_norm": 0.17092154920101166,
      "learning_rate": 5.402653502005554e-06,
      "loss": 0.0001,
      "step": 144540
    },
    {
      "epoch": 44.600431965442766,
      "grad_norm": 1.9798134243131926e-09,
      "learning_rate": 5.399568034557236e-06,
      "loss": 0.0,
      "step": 144550
    },
    {
      "epoch": 44.60351743289108,
      "grad_norm": 1.869511470431462e-05,
      "learning_rate": 5.396482567108917e-06,
      "loss": 0.0,
      "step": 144560
    },
    {
      "epoch": 44.606602900339404,
      "grad_norm": 2.1484103385205344e-09,
      "learning_rate": 5.393397099660599e-06,
      "loss": 0.0,
      "step": 144570
    },
    {
      "epoch": 44.60968836778772,
      "grad_norm": 8.389221193283447e-07,
      "learning_rate": 5.3903116322122806e-06,
      "loss": 0.0,
      "step": 144580
    },
    {
      "epoch": 44.61277383523604,
      "grad_norm": 1.9398655126678932e-08,
      "learning_rate": 5.387226164763962e-06,
      "loss": 0.0,
      "step": 144590
    },
    {
      "epoch": 44.615859302684356,
      "grad_norm": 2.0753777363324843e-08,
      "learning_rate": 5.384140697315644e-06,
      "loss": 0.0,
      "step": 144600
    },
    {
      "epoch": 44.61894477013268,
      "grad_norm": 1.932417248440288e-08,
      "learning_rate": 5.3810552298673255e-06,
      "loss": 0.0,
      "step": 144610
    },
    {
      "epoch": 44.622030237580994,
      "grad_norm": 2.608935028547421e-05,
      "learning_rate": 5.377969762419006e-06,
      "loss": 0.0002,
      "step": 144620
    },
    {
      "epoch": 44.62511570502931,
      "grad_norm": 2.4707722445782565e-07,
      "learning_rate": 5.374884294970689e-06,
      "loss": 0.0,
      "step": 144630
    },
    {
      "epoch": 44.62820117247763,
      "grad_norm": 1.4136913932816242e-06,
      "learning_rate": 5.37179882752237e-06,
      "loss": 0.0,
      "step": 144640
    },
    {
      "epoch": 44.631286639925946,
      "grad_norm": 3.2693997127353214e-06,
      "learning_rate": 5.368713360074051e-06,
      "loss": 0.0,
      "step": 144650
    },
    {
      "epoch": 44.63437210737427,
      "grad_norm": 4.093650574077401e-08,
      "learning_rate": 5.365627892625734e-06,
      "loss": 0.0,
      "step": 144660
    },
    {
      "epoch": 44.637457574822584,
      "grad_norm": 3.927114812540822e-05,
      "learning_rate": 5.362542425177414e-06,
      "loss": 0.0,
      "step": 144670
    },
    {
      "epoch": 44.640543042270906,
      "grad_norm": 1.0391338456372523e-08,
      "learning_rate": 5.359456957729096e-06,
      "loss": 0.0,
      "step": 144680
    },
    {
      "epoch": 44.64362850971922,
      "grad_norm": 0.000382602505851537,
      "learning_rate": 5.3563714902807785e-06,
      "loss": 0.0,
      "step": 144690
    },
    {
      "epoch": 44.64671397716754,
      "grad_norm": 1.1909693284906098e-06,
      "learning_rate": 5.353286022832459e-06,
      "loss": 0.0,
      "step": 144700
    },
    {
      "epoch": 44.64979944461586,
      "grad_norm": 8.054937097767834e-06,
      "learning_rate": 5.350200555384141e-06,
      "loss": 0.0,
      "step": 144710
    },
    {
      "epoch": 44.65288491206418,
      "grad_norm": 3.693365442813956e-06,
      "learning_rate": 5.3471150879358225e-06,
      "loss": 0.0,
      "step": 144720
    },
    {
      "epoch": 44.655970379512496,
      "grad_norm": 0.0009586182422935963,
      "learning_rate": 5.344029620487504e-06,
      "loss": 0.0,
      "step": 144730
    },
    {
      "epoch": 44.65905584696081,
      "grad_norm": 3.34550970260139e-10,
      "learning_rate": 5.340944153039186e-06,
      "loss": 0.0,
      "step": 144740
    },
    {
      "epoch": 44.66214131440913,
      "grad_norm": 1.3128925274941139e-05,
      "learning_rate": 5.3378586855908674e-06,
      "loss": 0.0,
      "step": 144750
    },
    {
      "epoch": 44.66522678185745,
      "grad_norm": 5.7784072851063684e-05,
      "learning_rate": 5.334773218142549e-06,
      "loss": 0.0,
      "step": 144760
    },
    {
      "epoch": 44.66831224930577,
      "grad_norm": 3.3794960927480133e-06,
      "learning_rate": 5.33168775069423e-06,
      "loss": 0.0,
      "step": 144770
    },
    {
      "epoch": 44.671397716754086,
      "grad_norm": 1.2662108694883045e-08,
      "learning_rate": 5.328602283245912e-06,
      "loss": 0.0,
      "step": 144780
    },
    {
      "epoch": 44.67448318420241,
      "grad_norm": 2.43553557766063e-07,
      "learning_rate": 5.325516815797594e-06,
      "loss": 0.0,
      "step": 144790
    },
    {
      "epoch": 44.67756865165072,
      "grad_norm": 6.983239472901914e-06,
      "learning_rate": 5.322431348349275e-06,
      "loss": 0.0,
      "step": 144800
    },
    {
      "epoch": 44.680654119099046,
      "grad_norm": 4.5334789433582046e-07,
      "learning_rate": 5.319345880900957e-06,
      "loss": 0.0,
      "step": 144810
    },
    {
      "epoch": 44.68373958654736,
      "grad_norm": 7.345143239945173e-05,
      "learning_rate": 5.316260413452638e-06,
      "loss": 0.0,
      "step": 144820
    },
    {
      "epoch": 44.68682505399568,
      "grad_norm": 1.3678222785529215e-06,
      "learning_rate": 5.31317494600432e-06,
      "loss": 0.0,
      "step": 144830
    },
    {
      "epoch": 44.689910521444,
      "grad_norm": 1.6342301734084685e-08,
      "learning_rate": 5.310089478556002e-06,
      "loss": 0.0,
      "step": 144840
    },
    {
      "epoch": 44.69299598889232,
      "grad_norm": 5.288911353318326e-08,
      "learning_rate": 5.307004011107683e-06,
      "loss": 0.0,
      "step": 144850
    },
    {
      "epoch": 44.696081456340636,
      "grad_norm": 1.6601164887219966e-08,
      "learning_rate": 5.3039185436593645e-06,
      "loss": 0.0,
      "step": 144860
    },
    {
      "epoch": 44.69916692378895,
      "grad_norm": 4.455631597011234e-08,
      "learning_rate": 5.300833076211046e-06,
      "loss": 0.0,
      "step": 144870
    },
    {
      "epoch": 44.70225239123727,
      "grad_norm": 6.119850581853825e-08,
      "learning_rate": 5.297747608762728e-06,
      "loss": 0.0,
      "step": 144880
    },
    {
      "epoch": 44.70533785868559,
      "grad_norm": 7.9739610470142e-09,
      "learning_rate": 5.294662141314409e-06,
      "loss": 0.0,
      "step": 144890
    },
    {
      "epoch": 44.70842332613391,
      "grad_norm": 8.146222967297945e-07,
      "learning_rate": 5.291576673866091e-06,
      "loss": 0.0,
      "step": 144900
    },
    {
      "epoch": 44.711508793582226,
      "grad_norm": 5.139283416610851e-07,
      "learning_rate": 5.288491206417773e-06,
      "loss": 0.0,
      "step": 144910
    },
    {
      "epoch": 44.71459426103055,
      "grad_norm": 1.3960987921279866e-08,
      "learning_rate": 5.285405738969454e-06,
      "loss": 0.0002,
      "step": 144920
    },
    {
      "epoch": 44.71767972847886,
      "grad_norm": 2.538570953447561e-08,
      "learning_rate": 5.282320271521136e-06,
      "loss": 0.0,
      "step": 144930
    },
    {
      "epoch": 44.720765195927186,
      "grad_norm": 4.7641466949244204e-07,
      "learning_rate": 5.2792348040728176e-06,
      "loss": 0.0001,
      "step": 144940
    },
    {
      "epoch": 44.7238506633755,
      "grad_norm": 4.5606530107988874e-08,
      "learning_rate": 5.276149336624499e-06,
      "loss": 0.0,
      "step": 144950
    },
    {
      "epoch": 44.72693613082382,
      "grad_norm": 0.0003562594356480986,
      "learning_rate": 5.273063869176181e-06,
      "loss": 0.0,
      "step": 144960
    },
    {
      "epoch": 44.73002159827214,
      "grad_norm": 1.592288572282996e-05,
      "learning_rate": 5.269978401727862e-06,
      "loss": 0.0,
      "step": 144970
    },
    {
      "epoch": 44.73310706572045,
      "grad_norm": 1.404011484851253e-08,
      "learning_rate": 5.266892934279544e-06,
      "loss": 0.0,
      "step": 144980
    },
    {
      "epoch": 44.736192533168776,
      "grad_norm": 3.055957975561796e-08,
      "learning_rate": 5.263807466831226e-06,
      "loss": 0.0004,
      "step": 144990
    },
    {
      "epoch": 44.73927800061709,
      "grad_norm": 7.191709272547087e-08,
      "learning_rate": 5.2607219993829065e-06,
      "loss": 0.0,
      "step": 145000
    },
    {
      "epoch": 44.74236346806541,
      "grad_norm": 3.804284887110043e-09,
      "learning_rate": 5.257636531934589e-06,
      "loss": 0.0,
      "step": 145010
    },
    {
      "epoch": 44.74544893551373,
      "grad_norm": 8.621486102811105e-08,
      "learning_rate": 5.25455106448627e-06,
      "loss": 0.0,
      "step": 145020
    },
    {
      "epoch": 44.74853440296205,
      "grad_norm": 4.7687689352926554e-09,
      "learning_rate": 5.251465597037951e-06,
      "loss": 0.0,
      "step": 145030
    },
    {
      "epoch": 44.751619870410366,
      "grad_norm": 6.896437980685732e-07,
      "learning_rate": 5.248380129589633e-06,
      "loss": 0.0,
      "step": 145040
    },
    {
      "epoch": 44.75470533785869,
      "grad_norm": 3.999219188699499e-06,
      "learning_rate": 5.245294662141315e-06,
      "loss": 0.0,
      "step": 145050
    },
    {
      "epoch": 44.757790805307,
      "grad_norm": 2.6288816457054054e-08,
      "learning_rate": 5.242209194692996e-06,
      "loss": 0.0,
      "step": 145060
    },
    {
      "epoch": 44.760876272755326,
      "grad_norm": 2.5340497700199194e-07,
      "learning_rate": 5.239123727244678e-06,
      "loss": 0.0,
      "step": 145070
    },
    {
      "epoch": 44.76396174020364,
      "grad_norm": 2.2609247025684454e-06,
      "learning_rate": 5.2360382597963595e-06,
      "loss": 0.0,
      "step": 145080
    },
    {
      "epoch": 44.767047207651956,
      "grad_norm": 2.5485210244369227e-06,
      "learning_rate": 5.23295279234804e-06,
      "loss": 0.0,
      "step": 145090
    },
    {
      "epoch": 44.77013267510028,
      "grad_norm": 1.562175270919397e-06,
      "learning_rate": 5.229867324899723e-06,
      "loss": 0.0,
      "step": 145100
    },
    {
      "epoch": 44.77321814254859,
      "grad_norm": 2.8127329642302357e-05,
      "learning_rate": 5.226781857451404e-06,
      "loss": 0.0,
      "step": 145110
    },
    {
      "epoch": 44.776303609996916,
      "grad_norm": 4.263875652554816e-08,
      "learning_rate": 5.223696390003085e-06,
      "loss": 0.0,
      "step": 145120
    },
    {
      "epoch": 44.77938907744523,
      "grad_norm": 3.9972795207177114e-07,
      "learning_rate": 5.220610922554768e-06,
      "loss": 0.0,
      "step": 145130
    },
    {
      "epoch": 44.78247454489355,
      "grad_norm": 8.415291574692674e-08,
      "learning_rate": 5.2175254551064485e-06,
      "loss": 0.0,
      "step": 145140
    },
    {
      "epoch": 44.78556001234187,
      "grad_norm": 0.00020024029072374105,
      "learning_rate": 5.21443998765813e-06,
      "loss": 0.0,
      "step": 145150
    },
    {
      "epoch": 44.78864547979019,
      "grad_norm": 0.0003219348145648837,
      "learning_rate": 5.2113545202098126e-06,
      "loss": 0.0,
      "step": 145160
    },
    {
      "epoch": 44.791730947238506,
      "grad_norm": 6.150423281781059e-09,
      "learning_rate": 5.208269052761493e-06,
      "loss": 0.0,
      "step": 145170
    },
    {
      "epoch": 44.79481641468683,
      "grad_norm": 3.369841351741343e-06,
      "learning_rate": 5.205183585313175e-06,
      "loss": 0.0,
      "step": 145180
    },
    {
      "epoch": 44.79790188213514,
      "grad_norm": 7.293490966731042e-07,
      "learning_rate": 5.202098117864857e-06,
      "loss": 0.0,
      "step": 145190
    },
    {
      "epoch": 44.800987349583465,
      "grad_norm": 4.161040578765096e-08,
      "learning_rate": 5.199012650416538e-06,
      "loss": 0.0,
      "step": 145200
    },
    {
      "epoch": 44.80407281703178,
      "grad_norm": 6.145123279566178e-06,
      "learning_rate": 5.19592718296822e-06,
      "loss": 0.0,
      "step": 145210
    },
    {
      "epoch": 44.807158284480096,
      "grad_norm": 5.012789188185707e-06,
      "learning_rate": 5.1928417155199015e-06,
      "loss": 0.0,
      "step": 145220
    },
    {
      "epoch": 44.81024375192842,
      "grad_norm": 0.00129057711455971,
      "learning_rate": 5.189756248071583e-06,
      "loss": 0.0,
      "step": 145230
    },
    {
      "epoch": 44.81332921937673,
      "grad_norm": 1.5579125545173156e-08,
      "learning_rate": 5.186670780623265e-06,
      "loss": 0.0,
      "step": 145240
    },
    {
      "epoch": 44.816414686825055,
      "grad_norm": 3.034820394987037e-08,
      "learning_rate": 5.183585313174946e-06,
      "loss": 0.0,
      "step": 145250
    },
    {
      "epoch": 44.81950015427337,
      "grad_norm": 4.3162014407016613e-08,
      "learning_rate": 5.180499845726628e-06,
      "loss": 0.0,
      "step": 145260
    },
    {
      "epoch": 44.82258562172169,
      "grad_norm": 9.256149979819384e-08,
      "learning_rate": 5.17741437827831e-06,
      "loss": 0.0,
      "step": 145270
    },
    {
      "epoch": 44.82567108917001,
      "grad_norm": 1.3790802313451422e-06,
      "learning_rate": 5.174328910829991e-06,
      "loss": 0.0,
      "step": 145280
    },
    {
      "epoch": 44.82875655661833,
      "grad_norm": 1.120048818847863e-05,
      "learning_rate": 5.171243443381672e-06,
      "loss": 0.0,
      "step": 145290
    },
    {
      "epoch": 44.831842024066646,
      "grad_norm": 4.4974349577842077e-08,
      "learning_rate": 5.1681579759333545e-06,
      "loss": 0.0,
      "step": 145300
    },
    {
      "epoch": 44.83492749151497,
      "grad_norm": 2.753523767751176e-05,
      "learning_rate": 5.165072508485036e-06,
      "loss": 0.0006,
      "step": 145310
    },
    {
      "epoch": 44.83801295896328,
      "grad_norm": 3.783962310155431e-10,
      "learning_rate": 5.161987041036717e-06,
      "loss": 0.0,
      "step": 145320
    },
    {
      "epoch": 44.8410984264116,
      "grad_norm": 8.958764396993502e-08,
      "learning_rate": 5.1589015735883994e-06,
      "loss": 0.0,
      "step": 145330
    },
    {
      "epoch": 44.84418389385992,
      "grad_norm": 1.9080827939887968e-07,
      "learning_rate": 5.15581610614008e-06,
      "loss": 0.0,
      "step": 145340
    },
    {
      "epoch": 44.847269361308236,
      "grad_norm": 0.000213238614378497,
      "learning_rate": 5.152730638691762e-06,
      "loss": 0.0,
      "step": 145350
    },
    {
      "epoch": 44.85035482875656,
      "grad_norm": 1.888655134507644e-07,
      "learning_rate": 5.1496451712434435e-06,
      "loss": 0.0,
      "step": 145360
    },
    {
      "epoch": 44.85344029620487,
      "grad_norm": 2.7394091262067377e-07,
      "learning_rate": 5.146559703795125e-06,
      "loss": 0.0,
      "step": 145370
    },
    {
      "epoch": 44.856525763653195,
      "grad_norm": 3.2504157587709415e-08,
      "learning_rate": 5.143474236346807e-06,
      "loss": 0.0,
      "step": 145380
    },
    {
      "epoch": 44.85961123110151,
      "grad_norm": 1.1040734534617513e-05,
      "learning_rate": 5.140388768898488e-06,
      "loss": 0.0,
      "step": 145390
    },
    {
      "epoch": 44.86269669854983,
      "grad_norm": 3.173115317167685e-07,
      "learning_rate": 5.13730330145017e-06,
      "loss": 0.0,
      "step": 145400
    },
    {
      "epoch": 44.86578216599815,
      "grad_norm": 2.2207849781352706e-07,
      "learning_rate": 5.134217834001852e-06,
      "loss": 0.0,
      "step": 145410
    },
    {
      "epoch": 44.86886763344647,
      "grad_norm": 1.6906381006265292e-07,
      "learning_rate": 5.131132366553533e-06,
      "loss": 0.0,
      "step": 145420
    },
    {
      "epoch": 44.871953100894785,
      "grad_norm": 2.3037054486252373e-09,
      "learning_rate": 5.128046899105215e-06,
      "loss": 0.0,
      "step": 145430
    },
    {
      "epoch": 44.8750385683431,
      "grad_norm": 2.807078480770997e-08,
      "learning_rate": 5.124961431656896e-06,
      "loss": 0.0,
      "step": 145440
    },
    {
      "epoch": 44.87812403579142,
      "grad_norm": 0.016016431152820587,
      "learning_rate": 5.121875964208578e-06,
      "loss": 0.0005,
      "step": 145450
    },
    {
      "epoch": 44.88120950323974,
      "grad_norm": 8.784069471801104e-09,
      "learning_rate": 5.11879049676026e-06,
      "loss": 0.0,
      "step": 145460
    },
    {
      "epoch": 44.88429497068806,
      "grad_norm": 9.414259594109353e-09,
      "learning_rate": 5.1157050293119406e-06,
      "loss": 0.0,
      "step": 145470
    },
    {
      "epoch": 44.887380438136375,
      "grad_norm": 0.0002933702489826828,
      "learning_rate": 5.112619561863623e-06,
      "loss": 0.0,
      "step": 145480
    },
    {
      "epoch": 44.8904659055847,
      "grad_norm": 1.540345692774281e-06,
      "learning_rate": 5.109534094415304e-06,
      "loss": 0.0,
      "step": 145490
    },
    {
      "epoch": 44.89355137303301,
      "grad_norm": 2.5068601416933234e-07,
      "learning_rate": 5.1064486269669854e-06,
      "loss": 0.0,
      "step": 145500
    },
    {
      "epoch": 44.896636840481335,
      "grad_norm": 4.138290933042299e-06,
      "learning_rate": 5.103363159518668e-06,
      "loss": 0.0,
      "step": 145510
    },
    {
      "epoch": 44.89972230792965,
      "grad_norm": 0.00031272482010535896,
      "learning_rate": 5.100277692070349e-06,
      "loss": 0.0,
      "step": 145520
    },
    {
      "epoch": 44.90280777537797,
      "grad_norm": 6.8138805708883865e-09,
      "learning_rate": 5.09719222462203e-06,
      "loss": 0.0,
      "step": 145530
    },
    {
      "epoch": 44.90589324282629,
      "grad_norm": 1.3199868975632967e-09,
      "learning_rate": 5.094106757173712e-06,
      "loss": 0.0,
      "step": 145540
    },
    {
      "epoch": 44.90897871027461,
      "grad_norm": 3.359140876568745e-08,
      "learning_rate": 5.091021289725394e-06,
      "loss": 0.0,
      "step": 145550
    },
    {
      "epoch": 44.912064177722925,
      "grad_norm": 1.5845189409446903e-06,
      "learning_rate": 5.087935822277075e-06,
      "loss": 0.0,
      "step": 145560
    },
    {
      "epoch": 44.91514964517124,
      "grad_norm": 5.727853191750398e-10,
      "learning_rate": 5.084850354828757e-06,
      "loss": 0.0,
      "step": 145570
    },
    {
      "epoch": 44.91823511261956,
      "grad_norm": 4.049562818408958e-08,
      "learning_rate": 5.0817648873804385e-06,
      "loss": 0.0,
      "step": 145580
    },
    {
      "epoch": 44.92132058006788,
      "grad_norm": 8.790592431751065e-08,
      "learning_rate": 5.07867941993212e-06,
      "loss": 0.0,
      "step": 145590
    },
    {
      "epoch": 44.9244060475162,
      "grad_norm": 8.454222779619158e-07,
      "learning_rate": 5.075593952483802e-06,
      "loss": 0.0,
      "step": 145600
    },
    {
      "epoch": 44.927491514964515,
      "grad_norm": 0.0005069064209237695,
      "learning_rate": 5.072508485035483e-06,
      "loss": 0.0,
      "step": 145610
    },
    {
      "epoch": 44.93057698241284,
      "grad_norm": 4.3425163909205367e-08,
      "learning_rate": 5.069423017587165e-06,
      "loss": 0.0,
      "step": 145620
    },
    {
      "epoch": 44.93366244986115,
      "grad_norm": 4.66873871118878e-06,
      "learning_rate": 5.066337550138847e-06,
      "loss": 0.0,
      "step": 145630
    },
    {
      "epoch": 44.936747917309475,
      "grad_norm": 4.528270437731408e-06,
      "learning_rate": 5.063252082690527e-06,
      "loss": 0.0,
      "step": 145640
    },
    {
      "epoch": 44.93983338475779,
      "grad_norm": 8.270917169284075e-05,
      "learning_rate": 5.06016661524221e-06,
      "loss": 0.0,
      "step": 145650
    },
    {
      "epoch": 44.94291885220611,
      "grad_norm": 1.3711457746978795e-08,
      "learning_rate": 5.0570811477938915e-06,
      "loss": 0.0,
      "step": 145660
    },
    {
      "epoch": 44.94600431965443,
      "grad_norm": 6.33807132999209e-07,
      "learning_rate": 5.053995680345572e-06,
      "loss": 0.0,
      "step": 145670
    },
    {
      "epoch": 44.94908978710274,
      "grad_norm": 3.005727577942707e-08,
      "learning_rate": 5.050910212897254e-06,
      "loss": 0.0,
      "step": 145680
    },
    {
      "epoch": 44.952175254551065,
      "grad_norm": 3.879551346841481e-09,
      "learning_rate": 5.0478247454489356e-06,
      "loss": 0.0,
      "step": 145690
    },
    {
      "epoch": 44.95526072199938,
      "grad_norm": 0.00014143217413220555,
      "learning_rate": 5.044739278000617e-06,
      "loss": 0.0,
      "step": 145700
    },
    {
      "epoch": 44.9583461894477,
      "grad_norm": 8.246909601439256e-06,
      "learning_rate": 5.041653810552299e-06,
      "loss": 0.0,
      "step": 145710
    },
    {
      "epoch": 44.96143165689602,
      "grad_norm": 2.0220783270019638e-08,
      "learning_rate": 5.0385683431039805e-06,
      "loss": 0.0,
      "step": 145720
    },
    {
      "epoch": 44.96451712434434,
      "grad_norm": 5.154262572304447e-10,
      "learning_rate": 5.035482875655662e-06,
      "loss": 0.0,
      "step": 145730
    },
    {
      "epoch": 44.967602591792655,
      "grad_norm": 7.208967872429639e-05,
      "learning_rate": 5.032397408207344e-06,
      "loss": 0.0,
      "step": 145740
    },
    {
      "epoch": 44.97068805924098,
      "grad_norm": 3.5829910149942634e-09,
      "learning_rate": 5.029311940759025e-06,
      "loss": 0.0,
      "step": 145750
    },
    {
      "epoch": 44.97377352668929,
      "grad_norm": 2.4499530582033913e-07,
      "learning_rate": 5.026226473310707e-06,
      "loss": 0.0,
      "step": 145760
    },
    {
      "epoch": 44.976858994137615,
      "grad_norm": 4.774564743570409e-09,
      "learning_rate": 5.023141005862389e-06,
      "loss": 0.0,
      "step": 145770
    },
    {
      "epoch": 44.97994446158593,
      "grad_norm": 8.791615255177021e-05,
      "learning_rate": 5.02005553841407e-06,
      "loss": 0.0,
      "step": 145780
    },
    {
      "epoch": 44.983029929034245,
      "grad_norm": 1.0225379654116296e-08,
      "learning_rate": 5.016970070965751e-06,
      "loss": 0.0,
      "step": 145790
    },
    {
      "epoch": 44.98611539648257,
      "grad_norm": 3.2497948154741607e-07,
      "learning_rate": 5.0138846035174335e-06,
      "loss": 0.0,
      "step": 145800
    },
    {
      "epoch": 44.98920086393088,
      "grad_norm": 0.00021929587819613516,
      "learning_rate": 5.010799136069115e-06,
      "loss": 0.0,
      "step": 145810
    },
    {
      "epoch": 44.992286331379205,
      "grad_norm": 4.3861774656761554e-08,
      "learning_rate": 5.007713668620796e-06,
      "loss": 0.0,
      "step": 145820
    },
    {
      "epoch": 44.99537179882752,
      "grad_norm": 1.6216690490455932e-10,
      "learning_rate": 5.004628201172478e-06,
      "loss": 0.0,
      "step": 145830
    },
    {
      "epoch": 44.99845726627584,
      "grad_norm": 3.383993316674605e-05,
      "learning_rate": 5.001542733724159e-06,
      "loss": 0.0,
      "step": 145840
    },
    {
      "epoch": 45.0,
      "eval_accuracy_branch1": 1.0,
      "eval_accuracy_branch2": 0.4195576902674498,
      "eval_f1_branch1": 1.0,
      "eval_f1_branch2": 0.41460271729054443,
      "eval_loss": 1.3789082231596694e-07,
      "eval_precision_branch1": 1.0,
      "eval_precision_branch2": 0.5078928620641476,
      "eval_recall_branch1": 1.0,
      "eval_recall_branch2": 0.5065029947050143,
      "eval_runtime": 132.8973,
      "eval_samples_per_second": 780.174,
      "eval_steps_per_second": 97.526,
      "step": 145845
    },
    {
      "epoch": 45.00154273372416,
      "grad_norm": 3.656063451984437e-09,
      "learning_rate": 4.998457266275841e-06,
      "loss": 0.0,
      "step": 145850
    },
    {
      "epoch": 45.00462820117248,
      "grad_norm": 2.949228949944427e-08,
      "learning_rate": 4.9953717988275224e-06,
      "loss": 0.0,
      "step": 145860
    },
    {
      "epoch": 45.007713668620795,
      "grad_norm": 1.8230691978260438e-07,
      "learning_rate": 4.992286331379204e-06,
      "loss": 0.0,
      "step": 145870
    },
    {
      "epoch": 45.01079913606912,
      "grad_norm": 3.254931755236612e-07,
      "learning_rate": 4.989200863930886e-06,
      "loss": 0.0001,
      "step": 145880
    },
    {
      "epoch": 45.01388460351743,
      "grad_norm": 3.5215954596878873e-08,
      "learning_rate": 4.986115396482567e-06,
      "loss": 0.0,
      "step": 145890
    },
    {
      "epoch": 45.016970070965755,
      "grad_norm": 1.5454145341209369e-06,
      "learning_rate": 4.983029929034249e-06,
      "loss": 0.0,
      "step": 145900
    },
    {
      "epoch": 45.02005553841407,
      "grad_norm": 7.845872396217146e-09,
      "learning_rate": 4.979944461585931e-06,
      "loss": 0.0,
      "step": 145910
    },
    {
      "epoch": 45.023141005862385,
      "grad_norm": 0.002024734625592828,
      "learning_rate": 4.976858994137612e-06,
      "loss": 0.0,
      "step": 145920
    },
    {
      "epoch": 45.02622647331071,
      "grad_norm": 0.28988707065582275,
      "learning_rate": 4.973773526689294e-06,
      "loss": 0.0001,
      "step": 145930
    },
    {
      "epoch": 45.02931194075902,
      "grad_norm": 3.582820795600128e-07,
      "learning_rate": 4.9706880592409755e-06,
      "loss": 0.0,
      "step": 145940
    },
    {
      "epoch": 45.032397408207345,
      "grad_norm": 7.555973752459977e-06,
      "learning_rate": 4.967602591792657e-06,
      "loss": 0.0,
      "step": 145950
    },
    {
      "epoch": 45.03548287565566,
      "grad_norm": 6.82419624808972e-07,
      "learning_rate": 4.964517124344338e-06,
      "loss": 0.0,
      "step": 145960
    },
    {
      "epoch": 45.03856834310398,
      "grad_norm": 5.143400358065264e-06,
      "learning_rate": 4.9614316568960195e-06,
      "loss": 0.0,
      "step": 145970
    },
    {
      "epoch": 45.0416538105523,
      "grad_norm": 1.195857180391613e-06,
      "learning_rate": 4.958346189447702e-06,
      "loss": 0.0,
      "step": 145980
    },
    {
      "epoch": 45.04473927800062,
      "grad_norm": 1.7766856430512235e-08,
      "learning_rate": 4.955260721999383e-06,
      "loss": 0.0,
      "step": 145990
    },
    {
      "epoch": 45.047824745448935,
      "grad_norm": 6.621513421123382e-06,
      "learning_rate": 4.952175254551064e-06,
      "loss": 0.0,
      "step": 146000
    },
    {
      "epoch": 45.05091021289726,
      "grad_norm": 5.0609800794632065e-09,
      "learning_rate": 4.949089787102746e-06,
      "loss": 0.0,
      "step": 146010
    },
    {
      "epoch": 45.05399568034557,
      "grad_norm": 1.343577650914085e-06,
      "learning_rate": 4.946004319654428e-06,
      "loss": 0.0,
      "step": 146020
    },
    {
      "epoch": 45.05708114779389,
      "grad_norm": 1.6429172688958715e-08,
      "learning_rate": 4.942918852206109e-06,
      "loss": 0.0,
      "step": 146030
    },
    {
      "epoch": 45.06016661524221,
      "grad_norm": 0.0009499457664787769,
      "learning_rate": 4.939833384757791e-06,
      "loss": 0.0,
      "step": 146040
    },
    {
      "epoch": 45.063252082690525,
      "grad_norm": 1.299399787768607e-08,
      "learning_rate": 4.9367479173094726e-06,
      "loss": 0.0,
      "step": 146050
    },
    {
      "epoch": 45.06633755013885,
      "grad_norm": 9.967336154659279e-06,
      "learning_rate": 4.933662449861154e-06,
      "loss": 0.0,
      "step": 146060
    },
    {
      "epoch": 45.06942301758716,
      "grad_norm": 1.0852322596122121e-08,
      "learning_rate": 4.930576982412836e-06,
      "loss": 0.0,
      "step": 146070
    },
    {
      "epoch": 45.072508485035485,
      "grad_norm": 2.687053211047896e-07,
      "learning_rate": 4.9274915149645174e-06,
      "loss": 0.0,
      "step": 146080
    },
    {
      "epoch": 45.0755939524838,
      "grad_norm": 7.93601895310303e-09,
      "learning_rate": 4.924406047516199e-06,
      "loss": 0.0,
      "step": 146090
    },
    {
      "epoch": 45.07867941993212,
      "grad_norm": 2.3750910127517955e-09,
      "learning_rate": 4.921320580067881e-06,
      "loss": 0.0,
      "step": 146100
    },
    {
      "epoch": 45.08176488738044,
      "grad_norm": 1.8597108919493621e-06,
      "learning_rate": 4.9182351126195615e-06,
      "loss": 0.0,
      "step": 146110
    },
    {
      "epoch": 45.08485035482876,
      "grad_norm": 2.934614506955313e-08,
      "learning_rate": 4.915149645171244e-06,
      "loss": 0.0,
      "step": 146120
    },
    {
      "epoch": 45.087935822277075,
      "grad_norm": 8.255792494082925e-08,
      "learning_rate": 4.912064177722926e-06,
      "loss": 0.0,
      "step": 146130
    },
    {
      "epoch": 45.09102128972539,
      "grad_norm": 1.0222074742216591e-08,
      "learning_rate": 4.908978710274606e-06,
      "loss": 0.0,
      "step": 146140
    },
    {
      "epoch": 45.09410675717371,
      "grad_norm": 4.5152773964218795e-08,
      "learning_rate": 4.905893242826289e-06,
      "loss": 0.0,
      "step": 146150
    },
    {
      "epoch": 45.09719222462203,
      "grad_norm": 5.583179358836787e-07,
      "learning_rate": 4.90280777537797e-06,
      "loss": 0.0,
      "step": 146160
    },
    {
      "epoch": 45.10027769207035,
      "grad_norm": 1.6297485672112089e-06,
      "learning_rate": 4.899722307929651e-06,
      "loss": 0.0,
      "step": 146170
    },
    {
      "epoch": 45.103363159518665,
      "grad_norm": 3.1673029297962785e-05,
      "learning_rate": 4.896636840481334e-06,
      "loss": 0.0,
      "step": 146180
    },
    {
      "epoch": 45.10644862696699,
      "grad_norm": 3.028270111826714e-05,
      "learning_rate": 4.8935513730330145e-06,
      "loss": 0.0,
      "step": 146190
    },
    {
      "epoch": 45.1095340944153,
      "grad_norm": 3.1373025421999046e-07,
      "learning_rate": 4.890465905584696e-06,
      "loss": 0.0,
      "step": 146200
    },
    {
      "epoch": 45.112619561863625,
      "grad_norm": 0.0013033306458964944,
      "learning_rate": 4.887380438136378e-06,
      "loss": 0.0,
      "step": 146210
    },
    {
      "epoch": 45.11570502931194,
      "grad_norm": 6.949931297128842e-09,
      "learning_rate": 4.884294970688059e-06,
      "loss": 0.0,
      "step": 146220
    },
    {
      "epoch": 45.11879049676026,
      "grad_norm": 2.232994347650674e-06,
      "learning_rate": 4.881209503239741e-06,
      "loss": 0.0,
      "step": 146230
    },
    {
      "epoch": 45.12187596420858,
      "grad_norm": 0.0005183459725230932,
      "learning_rate": 4.878124035791423e-06,
      "loss": 0.0,
      "step": 146240
    },
    {
      "epoch": 45.1249614316569,
      "grad_norm": 3.0474716083972453e-09,
      "learning_rate": 4.875038568343104e-06,
      "loss": 0.0,
      "step": 146250
    },
    {
      "epoch": 45.128046899105215,
      "grad_norm": 3.539420134757165e-08,
      "learning_rate": 4.871953100894786e-06,
      "loss": 0.0,
      "step": 146260
    },
    {
      "epoch": 45.13113236655353,
      "grad_norm": 2.915440555639748e-09,
      "learning_rate": 4.8688676334464676e-06,
      "loss": 0.0,
      "step": 146270
    },
    {
      "epoch": 45.13421783400185,
      "grad_norm": 3.6443171325117873e-07,
      "learning_rate": 4.865782165998149e-06,
      "loss": 0.0,
      "step": 146280
    },
    {
      "epoch": 45.13730330145017,
      "grad_norm": 1.1622468264249619e-05,
      "learning_rate": 4.86269669854983e-06,
      "loss": 0.0,
      "step": 146290
    },
    {
      "epoch": 45.14038876889849,
      "grad_norm": 3.997857675130945e-06,
      "learning_rate": 4.8596112311015125e-06,
      "loss": 0.0,
      "step": 146300
    },
    {
      "epoch": 45.143474236346805,
      "grad_norm": 4.096450356882997e-05,
      "learning_rate": 4.856525763653193e-06,
      "loss": 0.0,
      "step": 146310
    },
    {
      "epoch": 45.14655970379513,
      "grad_norm": 3.1870720704318956e-05,
      "learning_rate": 4.853440296204875e-06,
      "loss": 0.0,
      "step": 146320
    },
    {
      "epoch": 45.14964517124344,
      "grad_norm": 9.889948842101148e-07,
      "learning_rate": 4.850354828756557e-06,
      "loss": 0.0,
      "step": 146330
    },
    {
      "epoch": 45.152730638691764,
      "grad_norm": 2.289309804837103e-06,
      "learning_rate": 4.847269361308238e-06,
      "loss": 0.0,
      "step": 146340
    },
    {
      "epoch": 45.15581610614008,
      "grad_norm": 7.174814982136013e-07,
      "learning_rate": 4.84418389385992e-06,
      "loss": 0.0,
      "step": 146350
    },
    {
      "epoch": 45.1589015735884,
      "grad_norm": 1.9247675027145306e-06,
      "learning_rate": 4.841098426411601e-06,
      "loss": 0.0,
      "step": 146360
    },
    {
      "epoch": 45.16198704103672,
      "grad_norm": 4.1397058225811634e-08,
      "learning_rate": 4.838012958963283e-06,
      "loss": 0.0,
      "step": 146370
    },
    {
      "epoch": 45.16507250848503,
      "grad_norm": 3.05722494431393e-07,
      "learning_rate": 4.834927491514965e-06,
      "loss": 0.0,
      "step": 146380
    },
    {
      "epoch": 45.168157975933354,
      "grad_norm": 6.608641633931711e-09,
      "learning_rate": 4.831842024066646e-06,
      "loss": 0.0,
      "step": 146390
    },
    {
      "epoch": 45.17124344338167,
      "grad_norm": 6.089442194934236e-08,
      "learning_rate": 4.828756556618328e-06,
      "loss": 0.0,
      "step": 146400
    },
    {
      "epoch": 45.17432891082999,
      "grad_norm": 1.6949852010839095e-07,
      "learning_rate": 4.8256710891700095e-06,
      "loss": 0.0,
      "step": 146410
    },
    {
      "epoch": 45.17741437827831,
      "grad_norm": 2.9820785130141303e-07,
      "learning_rate": 4.822585621721691e-06,
      "loss": 0.0,
      "step": 146420
    },
    {
      "epoch": 45.18049984572663,
      "grad_norm": 1.7866877897176892e-06,
      "learning_rate": 4.819500154273373e-06,
      "loss": 0.0,
      "step": 146430
    },
    {
      "epoch": 45.183585313174945,
      "grad_norm": 6.811088582026059e-08,
      "learning_rate": 4.8164146868250544e-06,
      "loss": 0.0,
      "step": 146440
    },
    {
      "epoch": 45.18667078062327,
      "grad_norm": 2.441912511130795e-05,
      "learning_rate": 4.813329219376736e-06,
      "loss": 0.0,
      "step": 146450
    },
    {
      "epoch": 45.18975624807158,
      "grad_norm": 0.00018598834867589176,
      "learning_rate": 4.810243751928417e-06,
      "loss": 0.0,
      "step": 146460
    },
    {
      "epoch": 45.192841715519904,
      "grad_norm": 4.395070573082194e-05,
      "learning_rate": 4.807158284480099e-06,
      "loss": 0.0,
      "step": 146470
    },
    {
      "epoch": 45.19592718296822,
      "grad_norm": 3.2118274248205125e-05,
      "learning_rate": 4.804072817031781e-06,
      "loss": 0.0,
      "step": 146480
    },
    {
      "epoch": 45.199012650416535,
      "grad_norm": 9.310980999543972e-07,
      "learning_rate": 4.800987349583462e-06,
      "loss": 0.0,
      "step": 146490
    },
    {
      "epoch": 45.20209811786486,
      "grad_norm": 2.850853442204482e-10,
      "learning_rate": 4.797901882135144e-06,
      "loss": 0.0,
      "step": 146500
    },
    {
      "epoch": 45.20518358531317,
      "grad_norm": 2.7142514902323e-09,
      "learning_rate": 4.794816414686825e-06,
      "loss": 0.0,
      "step": 146510
    },
    {
      "epoch": 45.208269052761494,
      "grad_norm": 3.1465415162301724e-08,
      "learning_rate": 4.791730947238507e-06,
      "loss": 0.0,
      "step": 146520
    },
    {
      "epoch": 45.21135452020981,
      "grad_norm": 2.2285306044977915e-07,
      "learning_rate": 4.788645479790189e-06,
      "loss": 0.0,
      "step": 146530
    },
    {
      "epoch": 45.21443998765813,
      "grad_norm": 1.7685282500679023e-06,
      "learning_rate": 4.78556001234187e-06,
      "loss": 0.0,
      "step": 146540
    },
    {
      "epoch": 45.21752545510645,
      "grad_norm": 7.410256512230262e-05,
      "learning_rate": 4.7824745448935515e-06,
      "loss": 0.0,
      "step": 146550
    },
    {
      "epoch": 45.22061092255477,
      "grad_norm": 0.0018657577456906438,
      "learning_rate": 4.779389077445233e-06,
      "loss": 0.0,
      "step": 146560
    },
    {
      "epoch": 45.223696390003084,
      "grad_norm": 9.315443094237708e-06,
      "learning_rate": 4.776303609996915e-06,
      "loss": 0.0,
      "step": 146570
    },
    {
      "epoch": 45.22678185745141,
      "grad_norm": 0.0003283573023509234,
      "learning_rate": 4.773218142548596e-06,
      "loss": 0.0,
      "step": 146580
    },
    {
      "epoch": 45.22986732489972,
      "grad_norm": 2.04374237000593e-06,
      "learning_rate": 4.770132675100278e-06,
      "loss": 0.0001,
      "step": 146590
    },
    {
      "epoch": 45.232952792348044,
      "grad_norm": 5.437648837869347e-07,
      "learning_rate": 4.76704720765196e-06,
      "loss": 0.0,
      "step": 146600
    },
    {
      "epoch": 45.23603825979636,
      "grad_norm": 2.2616643491346622e-07,
      "learning_rate": 4.7639617402036404e-06,
      "loss": 0.0,
      "step": 146610
    },
    {
      "epoch": 45.239123727244674,
      "grad_norm": 1.2239293937454931e-05,
      "learning_rate": 4.760876272755323e-06,
      "loss": 0.0003,
      "step": 146620
    },
    {
      "epoch": 45.242209194693,
      "grad_norm": 2.4483259863927742e-08,
      "learning_rate": 4.7577908053070045e-06,
      "loss": 0.0,
      "step": 146630
    },
    {
      "epoch": 45.24529466214131,
      "grad_norm": 8.289373454317683e-07,
      "learning_rate": 4.754705337858685e-06,
      "loss": 0.0,
      "step": 146640
    },
    {
      "epoch": 45.248380129589634,
      "grad_norm": 2.5560157155268826e-06,
      "learning_rate": 4.751619870410368e-06,
      "loss": 0.0,
      "step": 146650
    },
    {
      "epoch": 45.25146559703795,
      "grad_norm": 2.853306568795233e-07,
      "learning_rate": 4.748534402962049e-06,
      "loss": 0.0,
      "step": 146660
    },
    {
      "epoch": 45.25455106448627,
      "grad_norm": 3.5313345847498567e-07,
      "learning_rate": 4.74544893551373e-06,
      "loss": 0.0,
      "step": 146670
    },
    {
      "epoch": 45.25763653193459,
      "grad_norm": 2.474355476067558e-08,
      "learning_rate": 4.742363468065412e-06,
      "loss": 0.0,
      "step": 146680
    },
    {
      "epoch": 45.26072199938291,
      "grad_norm": 4.680574261506365e-10,
      "learning_rate": 4.7392780006170935e-06,
      "loss": 0.0,
      "step": 146690
    },
    {
      "epoch": 45.263807466831224,
      "grad_norm": 1.21206269909635e-07,
      "learning_rate": 4.736192533168775e-06,
      "loss": 0.0,
      "step": 146700
    },
    {
      "epoch": 45.26689293427955,
      "grad_norm": 0.00014878260844852775,
      "learning_rate": 4.733107065720457e-06,
      "loss": 0.0,
      "step": 146710
    },
    {
      "epoch": 45.26997840172786,
      "grad_norm": 5.024019174015848e-07,
      "learning_rate": 4.730021598272138e-06,
      "loss": 0.0,
      "step": 146720
    },
    {
      "epoch": 45.27306386917618,
      "grad_norm": 1.5847390386625193e-06,
      "learning_rate": 4.72693613082382e-06,
      "loss": 0.0001,
      "step": 146730
    },
    {
      "epoch": 45.2761493366245,
      "grad_norm": 1.847631736495714e-08,
      "learning_rate": 4.723850663375502e-06,
      "loss": 0.0,
      "step": 146740
    },
    {
      "epoch": 45.279234804072814,
      "grad_norm": 4.1232128751289565e-06,
      "learning_rate": 4.720765195927183e-06,
      "loss": 0.0,
      "step": 146750
    },
    {
      "epoch": 45.28232027152114,
      "grad_norm": 9.56478984903697e-09,
      "learning_rate": 4.717679728478865e-06,
      "loss": 0.0,
      "step": 146760
    },
    {
      "epoch": 45.28540573896945,
      "grad_norm": 0.0004642050771508366,
      "learning_rate": 4.7145942610305465e-06,
      "loss": 0.0,
      "step": 146770
    },
    {
      "epoch": 45.288491206417774,
      "grad_norm": 2.797929141706845e-07,
      "learning_rate": 4.711508793582227e-06,
      "loss": 0.0,
      "step": 146780
    },
    {
      "epoch": 45.29157667386609,
      "grad_norm": 2.264242993987864e-06,
      "learning_rate": 4.70842332613391e-06,
      "loss": 0.0,
      "step": 146790
    },
    {
      "epoch": 45.29466214131441,
      "grad_norm": 9.09237840573951e-09,
      "learning_rate": 4.705337858685591e-06,
      "loss": 0.0,
      "step": 146800
    },
    {
      "epoch": 45.29774760876273,
      "grad_norm": 0.0030379104427993298,
      "learning_rate": 4.702252391237272e-06,
      "loss": 0.0,
      "step": 146810
    },
    {
      "epoch": 45.30083307621105,
      "grad_norm": 6.115562456443513e-08,
      "learning_rate": 4.699166923788955e-06,
      "loss": 0.0,
      "step": 146820
    },
    {
      "epoch": 45.303918543659364,
      "grad_norm": 1.8269874146881193e-07,
      "learning_rate": 4.6960814563406355e-06,
      "loss": 0.0,
      "step": 146830
    },
    {
      "epoch": 45.30700401110768,
      "grad_norm": 2.974427616209141e-06,
      "learning_rate": 4.692995988892317e-06,
      "loss": 0.0,
      "step": 146840
    },
    {
      "epoch": 45.310089478556,
      "grad_norm": 6.814911746033658e-09,
      "learning_rate": 4.6899105214439996e-06,
      "loss": 0.0,
      "step": 146850
    },
    {
      "epoch": 45.31317494600432,
      "grad_norm": 5.441292159957811e-06,
      "learning_rate": 4.68682505399568e-06,
      "loss": 0.0,
      "step": 146860
    },
    {
      "epoch": 45.31626041345264,
      "grad_norm": 4.264858034730423e-06,
      "learning_rate": 4.683739586547362e-06,
      "loss": 0.0,
      "step": 146870
    },
    {
      "epoch": 45.319345880900954,
      "grad_norm": 1.559791940053401e-06,
      "learning_rate": 4.680654119099044e-06,
      "loss": 0.0,
      "step": 146880
    },
    {
      "epoch": 45.32243134834928,
      "grad_norm": 4.522275176555013e-08,
      "learning_rate": 4.677568651650725e-06,
      "loss": 0.0,
      "step": 146890
    },
    {
      "epoch": 45.32551681579759,
      "grad_norm": 2.2918366084923036e-05,
      "learning_rate": 4.674483184202407e-06,
      "loss": 0.0,
      "step": 146900
    },
    {
      "epoch": 45.328602283245914,
      "grad_norm": 1.0143581619104225e-07,
      "learning_rate": 4.6713977167540885e-06,
      "loss": 0.0,
      "step": 146910
    },
    {
      "epoch": 45.33168775069423,
      "grad_norm": 2.807348309374902e-08,
      "learning_rate": 4.66831224930577e-06,
      "loss": 0.0,
      "step": 146920
    },
    {
      "epoch": 45.33477321814255,
      "grad_norm": 4.8401460617242265e-08,
      "learning_rate": 4.665226781857451e-06,
      "loss": 0.0,
      "step": 146930
    },
    {
      "epoch": 45.33785868559087,
      "grad_norm": 4.955102284043278e-08,
      "learning_rate": 4.662141314409133e-06,
      "loss": 0.0,
      "step": 146940
    },
    {
      "epoch": 45.34094415303919,
      "grad_norm": 1.4020955632076948e-06,
      "learning_rate": 4.659055846960815e-06,
      "loss": 0.0,
      "step": 146950
    },
    {
      "epoch": 45.344029620487504,
      "grad_norm": 2.988147063121005e-09,
      "learning_rate": 4.655970379512496e-06,
      "loss": 0.0,
      "step": 146960
    },
    {
      "epoch": 45.34711508793582,
      "grad_norm": 5.652776025044659e-08,
      "learning_rate": 4.652884912064178e-06,
      "loss": 0.0,
      "step": 146970
    },
    {
      "epoch": 45.35020055538414,
      "grad_norm": 3.529643066713106e-08,
      "learning_rate": 4.649799444615859e-06,
      "loss": 0.0,
      "step": 146980
    },
    {
      "epoch": 45.35328602283246,
      "grad_norm": 2.7789017167378915e-06,
      "learning_rate": 4.646713977167541e-06,
      "loss": 0.0,
      "step": 146990
    },
    {
      "epoch": 45.35637149028078,
      "grad_norm": 0.719708263874054,
      "learning_rate": 4.643628509719223e-06,
      "loss": 0.0003,
      "step": 147000
    },
    {
      "epoch": 45.359456957729094,
      "grad_norm": 1.8166714426115504e-06,
      "learning_rate": 4.640543042270904e-06,
      "loss": 0.0,
      "step": 147010
    },
    {
      "epoch": 45.362542425177416,
      "grad_norm": 3.803720346695627e-06,
      "learning_rate": 4.6374575748225856e-06,
      "loss": 0.0,
      "step": 147020
    },
    {
      "epoch": 45.36562789262573,
      "grad_norm": 4.852175266023551e-07,
      "learning_rate": 4.634372107374267e-06,
      "loss": 0.0,
      "step": 147030
    },
    {
      "epoch": 45.368713360074054,
      "grad_norm": 4.487759724725038e-06,
      "learning_rate": 4.631286639925949e-06,
      "loss": 0.0,
      "step": 147040
    },
    {
      "epoch": 45.37179882752237,
      "grad_norm": 1.5495064786819057e-08,
      "learning_rate": 4.6282011724776305e-06,
      "loss": 0.0,
      "step": 147050
    },
    {
      "epoch": 45.37488429497069,
      "grad_norm": 7.26890831970195e-08,
      "learning_rate": 4.625115705029312e-06,
      "loss": 0.0,
      "step": 147060
    },
    {
      "epoch": 45.377969762419006,
      "grad_norm": 5.7719549658941105e-05,
      "learning_rate": 4.622030237580994e-06,
      "loss": 0.0,
      "step": 147070
    },
    {
      "epoch": 45.38105522986732,
      "grad_norm": 1.698345357681319e-07,
      "learning_rate": 4.618944770132675e-06,
      "loss": 0.0,
      "step": 147080
    },
    {
      "epoch": 45.384140697315644,
      "grad_norm": 0.0031915565486997366,
      "learning_rate": 4.615859302684357e-06,
      "loss": 0.0,
      "step": 147090
    },
    {
      "epoch": 45.38722616476396,
      "grad_norm": 1.5198537983707183e-09,
      "learning_rate": 4.612773835236039e-06,
      "loss": 0.0,
      "step": 147100
    },
    {
      "epoch": 45.39031163221228,
      "grad_norm": 0.0004580129461828619,
      "learning_rate": 4.60968836778772e-06,
      "loss": 0.0,
      "step": 147110
    },
    {
      "epoch": 45.393397099660596,
      "grad_norm": 5.926413450652035e-06,
      "learning_rate": 4.606602900339402e-06,
      "loss": 0.0,
      "step": 147120
    },
    {
      "epoch": 45.39648256710892,
      "grad_norm": 1.537124080641661e-05,
      "learning_rate": 4.603517432891083e-06,
      "loss": 0.0,
      "step": 147130
    },
    {
      "epoch": 45.399568034557234,
      "grad_norm": 4.22064695158042e-05,
      "learning_rate": 4.600431965442765e-06,
      "loss": 0.0,
      "step": 147140
    },
    {
      "epoch": 45.402653502005556,
      "grad_norm": 1.5731538951513357e-06,
      "learning_rate": 4.597346497994447e-06,
      "loss": 0.0,
      "step": 147150
    },
    {
      "epoch": 45.40573896945387,
      "grad_norm": 3.019030714312976e-07,
      "learning_rate": 4.5942610305461275e-06,
      "loss": 0.0,
      "step": 147160
    },
    {
      "epoch": 45.408824436902194,
      "grad_norm": 3.0775215265066436e-08,
      "learning_rate": 4.59117556309781e-06,
      "loss": 0.0,
      "step": 147170
    },
    {
      "epoch": 45.41190990435051,
      "grad_norm": 5.571266228798777e-05,
      "learning_rate": 4.588090095649491e-06,
      "loss": 0.0,
      "step": 147180
    },
    {
      "epoch": 45.414995371798824,
      "grad_norm": 5.646055797114968e-05,
      "learning_rate": 4.5850046282011724e-06,
      "loss": 0.0,
      "step": 147190
    },
    {
      "epoch": 45.418080839247146,
      "grad_norm": 3.0010023692739196e-05,
      "learning_rate": 4.581919160752855e-06,
      "loss": 0.0,
      "step": 147200
    },
    {
      "epoch": 45.42116630669546,
      "grad_norm": 2.2258643639361253e-06,
      "learning_rate": 4.578833693304536e-06,
      "loss": 0.0,
      "step": 147210
    },
    {
      "epoch": 45.424251774143784,
      "grad_norm": 2.8113038297306048e-06,
      "learning_rate": 4.575748225856217e-06,
      "loss": 0.0,
      "step": 147220
    },
    {
      "epoch": 45.4273372415921,
      "grad_norm": 6.888779807923129e-06,
      "learning_rate": 4.572662758407899e-06,
      "loss": 0.0009,
      "step": 147230
    },
    {
      "epoch": 45.43042270904042,
      "grad_norm": 1.2385193031150266e-06,
      "learning_rate": 4.569577290959581e-06,
      "loss": 0.0,
      "step": 147240
    },
    {
      "epoch": 45.433508176488736,
      "grad_norm": 1.262525106682233e-08,
      "learning_rate": 4.566491823511262e-06,
      "loss": 0.0,
      "step": 147250
    },
    {
      "epoch": 45.43659364393706,
      "grad_norm": 4.7581685258535344e-09,
      "learning_rate": 4.563406356062944e-06,
      "loss": 0.0,
      "step": 147260
    },
    {
      "epoch": 45.439679111385374,
      "grad_norm": 1.8990183434652863e-06,
      "learning_rate": 4.5603208886146255e-06,
      "loss": 0.0,
      "step": 147270
    },
    {
      "epoch": 45.442764578833696,
      "grad_norm": 3.4770902601621856e-08,
      "learning_rate": 4.557235421166306e-06,
      "loss": 0.0,
      "step": 147280
    },
    {
      "epoch": 45.44585004628201,
      "grad_norm": 6.13487463851925e-06,
      "learning_rate": 4.554149953717989e-06,
      "loss": 0.0,
      "step": 147290
    },
    {
      "epoch": 45.44893551373033,
      "grad_norm": 1.0392711828899337e-06,
      "learning_rate": 4.55106448626967e-06,
      "loss": 0.0,
      "step": 147300
    },
    {
      "epoch": 45.45202098117865,
      "grad_norm": 0.016911666840314865,
      "learning_rate": 4.547979018821351e-06,
      "loss": 0.0,
      "step": 147310
    },
    {
      "epoch": 45.455106448626964,
      "grad_norm": 0.00798269733786583,
      "learning_rate": 4.544893551373034e-06,
      "loss": 0.0,
      "step": 147320
    },
    {
      "epoch": 45.458191916075286,
      "grad_norm": 3.80858125481609e-07,
      "learning_rate": 4.541808083924714e-06,
      "loss": 0.0,
      "step": 147330
    },
    {
      "epoch": 45.4612773835236,
      "grad_norm": 1.4998172446212266e-06,
      "learning_rate": 4.538722616476396e-06,
      "loss": 0.0,
      "step": 147340
    },
    {
      "epoch": 45.46436285097192,
      "grad_norm": 7.883269859121356e-07,
      "learning_rate": 4.5356371490280785e-06,
      "loss": 0.0,
      "step": 147350
    },
    {
      "epoch": 45.46744831842024,
      "grad_norm": 4.227282079938277e-09,
      "learning_rate": 4.532551681579759e-06,
      "loss": 0.0001,
      "step": 147360
    },
    {
      "epoch": 45.47053378586856,
      "grad_norm": 4.0622840060677845e-06,
      "learning_rate": 4.529466214131441e-06,
      "loss": 0.0,
      "step": 147370
    },
    {
      "epoch": 45.473619253316876,
      "grad_norm": 9.310309678767226e-08,
      "learning_rate": 4.5263807466831226e-06,
      "loss": 0.0,
      "step": 147380
    },
    {
      "epoch": 45.4767047207652,
      "grad_norm": 2.3324645326283644e-07,
      "learning_rate": 4.523295279234804e-06,
      "loss": 0.0,
      "step": 147390
    },
    {
      "epoch": 45.479790188213514,
      "grad_norm": 6.394143525767504e-08,
      "learning_rate": 4.520209811786486e-06,
      "loss": 0.0,
      "step": 147400
    },
    {
      "epoch": 45.482875655661836,
      "grad_norm": 2.623841588444975e-08,
      "learning_rate": 4.5171243443381674e-06,
      "loss": 0.0,
      "step": 147410
    },
    {
      "epoch": 45.48596112311015,
      "grad_norm": 1.2867055829701712e-06,
      "learning_rate": 4.514038876889849e-06,
      "loss": 0.0,
      "step": 147420
    },
    {
      "epoch": 45.489046590558466,
      "grad_norm": 9.812822554522427e-09,
      "learning_rate": 4.510953409441531e-06,
      "loss": 0.0,
      "step": 147430
    },
    {
      "epoch": 45.49213205800679,
      "grad_norm": 7.89427213021554e-05,
      "learning_rate": 4.507867941993212e-06,
      "loss": 0.0,
      "step": 147440
    },
    {
      "epoch": 45.495217525455104,
      "grad_norm": 7.708135241202285e-10,
      "learning_rate": 4.504782474544894e-06,
      "loss": 0.0,
      "step": 147450
    },
    {
      "epoch": 45.498302992903426,
      "grad_norm": 1.1833819826279068e-06,
      "learning_rate": 4.501697007096576e-06,
      "loss": 0.0,
      "step": 147460
    },
    {
      "epoch": 45.50138846035174,
      "grad_norm": 1.319115511266844e-10,
      "learning_rate": 4.498611539648257e-06,
      "loss": 0.0,
      "step": 147470
    },
    {
      "epoch": 45.50447392780006,
      "grad_norm": 8.610730795055588e-09,
      "learning_rate": 4.495526072199938e-06,
      "loss": 0.0,
      "step": 147480
    },
    {
      "epoch": 45.50755939524838,
      "grad_norm": 4.04805300391331e-09,
      "learning_rate": 4.4924406047516205e-06,
      "loss": 0.0,
      "step": 147490
    },
    {
      "epoch": 45.5106448626967,
      "grad_norm": 2.769092688481578e-08,
      "learning_rate": 4.489355137303302e-06,
      "loss": 0.0,
      "step": 147500
    },
    {
      "epoch": 45.513730330145016,
      "grad_norm": 5.710377171119774e-10,
      "learning_rate": 4.486269669854983e-06,
      "loss": 0.0,
      "step": 147510
    },
    {
      "epoch": 45.51681579759334,
      "grad_norm": 1.4773857692773618e-09,
      "learning_rate": 4.483184202406665e-06,
      "loss": 0.0,
      "step": 147520
    },
    {
      "epoch": 45.51990126504165,
      "grad_norm": 5.1246715315755864e-08,
      "learning_rate": 4.480098734958346e-06,
      "loss": 0.0,
      "step": 147530
    },
    {
      "epoch": 45.52298673248997,
      "grad_norm": 3.635705797933042e-05,
      "learning_rate": 4.477013267510028e-06,
      "loss": 0.0,
      "step": 147540
    },
    {
      "epoch": 45.52607219993829,
      "grad_norm": 4.401493072236917e-07,
      "learning_rate": 4.473927800061709e-06,
      "loss": 0.0,
      "step": 147550
    },
    {
      "epoch": 45.529157667386606,
      "grad_norm": 1.3653158021043055e-05,
      "learning_rate": 4.470842332613391e-06,
      "loss": 0.0,
      "step": 147560
    },
    {
      "epoch": 45.53224313483493,
      "grad_norm": 3.253049101203942e-07,
      "learning_rate": 4.467756865165073e-06,
      "loss": 0.0,
      "step": 147570
    },
    {
      "epoch": 45.53532860228324,
      "grad_norm": 2.3910906588042735e-09,
      "learning_rate": 4.464671397716754e-06,
      "loss": 0.0,
      "step": 147580
    },
    {
      "epoch": 45.538414069731566,
      "grad_norm": 3.6970213557196985e-08,
      "learning_rate": 4.461585930268436e-06,
      "loss": 0.0,
      "step": 147590
    },
    {
      "epoch": 45.54149953717988,
      "grad_norm": 3.038604701188774e-09,
      "learning_rate": 4.458500462820117e-06,
      "loss": 0.0,
      "step": 147600
    },
    {
      "epoch": 45.5445850046282,
      "grad_norm": 3.760952882458923e-09,
      "learning_rate": 4.455414995371799e-06,
      "loss": 0.0,
      "step": 147610
    },
    {
      "epoch": 45.54767047207652,
      "grad_norm": 3.945004937122576e-05,
      "learning_rate": 4.452329527923481e-06,
      "loss": 0.0,
      "step": 147620
    },
    {
      "epoch": 45.55075593952484,
      "grad_norm": 6.7181908889324404e-06,
      "learning_rate": 4.449244060475162e-06,
      "loss": 0.0,
      "step": 147630
    },
    {
      "epoch": 45.553841406973156,
      "grad_norm": 3.451797283560154e-06,
      "learning_rate": 4.446158593026844e-06,
      "loss": 0.0,
      "step": 147640
    },
    {
      "epoch": 45.55692687442148,
      "grad_norm": 5.149176729446481e-08,
      "learning_rate": 4.443073125578525e-06,
      "loss": 0.0,
      "step": 147650
    },
    {
      "epoch": 45.56001234186979,
      "grad_norm": 6.322494755295338e-06,
      "learning_rate": 4.4399876581302065e-06,
      "loss": 0.0,
      "step": 147660
    },
    {
      "epoch": 45.56309780931811,
      "grad_norm": 1.7201239543851443e-08,
      "learning_rate": 4.436902190681889e-06,
      "loss": 0.0,
      "step": 147670
    },
    {
      "epoch": 45.56618327676643,
      "grad_norm": 3.2696691050659865e-05,
      "learning_rate": 4.43381672323357e-06,
      "loss": 0.0,
      "step": 147680
    },
    {
      "epoch": 45.569268744214746,
      "grad_norm": 3.980890284083216e-08,
      "learning_rate": 4.430731255785251e-06,
      "loss": 0.0001,
      "step": 147690
    },
    {
      "epoch": 45.57235421166307,
      "grad_norm": 0.0010040757479146123,
      "learning_rate": 4.427645788336933e-06,
      "loss": 0.0,
      "step": 147700
    },
    {
      "epoch": 45.57543967911138,
      "grad_norm": 1.7036947610904463e-05,
      "learning_rate": 4.424560320888615e-06,
      "loss": 0.0,
      "step": 147710
    },
    {
      "epoch": 45.578525146559706,
      "grad_norm": 5.930061774961359e-09,
      "learning_rate": 4.421474853440296e-06,
      "loss": 0.0,
      "step": 147720
    },
    {
      "epoch": 45.58161061400802,
      "grad_norm": 0.011825385503470898,
      "learning_rate": 4.418389385991978e-06,
      "loss": 0.0,
      "step": 147730
    },
    {
      "epoch": 45.58469608145634,
      "grad_norm": 3.586779584452415e-08,
      "learning_rate": 4.4153039185436595e-06,
      "loss": 0.0,
      "step": 147740
    },
    {
      "epoch": 45.58778154890466,
      "grad_norm": 2.357861017543428e-09,
      "learning_rate": 4.412218451095341e-06,
      "loss": 0.0,
      "step": 147750
    },
    {
      "epoch": 45.59086701635298,
      "grad_norm": 1.7661857327766484e-06,
      "learning_rate": 4.409132983647023e-06,
      "loss": 0.0,
      "step": 147760
    },
    {
      "epoch": 45.593952483801296,
      "grad_norm": 4.75253244758278e-07,
      "learning_rate": 4.4060475161987044e-06,
      "loss": 0.0,
      "step": 147770
    },
    {
      "epoch": 45.59703795124961,
      "grad_norm": 2.1375544889679077e-08,
      "learning_rate": 4.402962048750386e-06,
      "loss": 0.0,
      "step": 147780
    },
    {
      "epoch": 45.60012341869793,
      "grad_norm": 1.646506819774629e-09,
      "learning_rate": 4.399876581302068e-06,
      "loss": 0.0,
      "step": 147790
    },
    {
      "epoch": 45.60320888614625,
      "grad_norm": 1.9996731737137452e-07,
      "learning_rate": 4.3967911138537485e-06,
      "loss": 0.0,
      "step": 147800
    },
    {
      "epoch": 45.60629435359457,
      "grad_norm": 2.7059256808570353e-06,
      "learning_rate": 4.393705646405431e-06,
      "loss": 0.0,
      "step": 147810
    },
    {
      "epoch": 45.609379821042886,
      "grad_norm": 0.0005859272205270827,
      "learning_rate": 4.390620178957113e-06,
      "loss": 0.0,
      "step": 147820
    },
    {
      "epoch": 45.61246528849121,
      "grad_norm": 9.304849113433988e-10,
      "learning_rate": 4.387534711508793e-06,
      "loss": 0.0,
      "step": 147830
    },
    {
      "epoch": 45.61555075593952,
      "grad_norm": 5.593501217759922e-09,
      "learning_rate": 4.384449244060476e-06,
      "loss": 0.0,
      "step": 147840
    },
    {
      "epoch": 45.618636223387846,
      "grad_norm": 3.2423535856196395e-08,
      "learning_rate": 4.381363776612157e-06,
      "loss": 0.0,
      "step": 147850
    },
    {
      "epoch": 45.62172169083616,
      "grad_norm": 9.554430107527878e-06,
      "learning_rate": 4.378278309163838e-06,
      "loss": 0.0,
      "step": 147860
    },
    {
      "epoch": 45.62480715828448,
      "grad_norm": 2.5309699225317672e-08,
      "learning_rate": 4.375192841715521e-06,
      "loss": 0.0,
      "step": 147870
    },
    {
      "epoch": 45.6278926257328,
      "grad_norm": 4.1154944483423606e-06,
      "learning_rate": 4.3721073742672015e-06,
      "loss": 0.0,
      "step": 147880
    },
    {
      "epoch": 45.63097809318112,
      "grad_norm": 3.5530927561922e-05,
      "learning_rate": 4.369021906818883e-06,
      "loss": 0.0,
      "step": 147890
    },
    {
      "epoch": 45.634063560629436,
      "grad_norm": 2.560529708262038e-07,
      "learning_rate": 4.365936439370565e-06,
      "loss": 0.0,
      "step": 147900
    },
    {
      "epoch": 45.63714902807775,
      "grad_norm": 2.280316584801767e-05,
      "learning_rate": 4.362850971922246e-06,
      "loss": 0.0,
      "step": 147910
    },
    {
      "epoch": 45.64023449552607,
      "grad_norm": 3.8869936247465375e-07,
      "learning_rate": 4.359765504473928e-06,
      "loss": 0.0,
      "step": 147920
    },
    {
      "epoch": 45.64331996297439,
      "grad_norm": 1.173427310874331e-08,
      "learning_rate": 4.35668003702561e-06,
      "loss": 0.0,
      "step": 147930
    },
    {
      "epoch": 45.64640543042271,
      "grad_norm": 7.99124245531857e-06,
      "learning_rate": 4.353594569577291e-06,
      "loss": 0.0,
      "step": 147940
    },
    {
      "epoch": 45.649490897871026,
      "grad_norm": 3.54838107341493e-07,
      "learning_rate": 4.350509102128972e-06,
      "loss": 0.0,
      "step": 147950
    },
    {
      "epoch": 45.65257636531935,
      "grad_norm": 2.476224025826923e-08,
      "learning_rate": 4.3474236346806546e-06,
      "loss": 0.0,
      "step": 147960
    },
    {
      "epoch": 45.65566183276766,
      "grad_norm": 5.237556251813658e-06,
      "learning_rate": 4.344338167232336e-06,
      "loss": 0.0,
      "step": 147970
    },
    {
      "epoch": 45.658747300215985,
      "grad_norm": 1.154853768170483e-09,
      "learning_rate": 4.341252699784017e-06,
      "loss": 0.0,
      "step": 147980
    },
    {
      "epoch": 45.6618327676643,
      "grad_norm": 3.2104833280754974e-07,
      "learning_rate": 4.3381672323356994e-06,
      "loss": 0.0,
      "step": 147990
    },
    {
      "epoch": 45.66491823511262,
      "grad_norm": 1.6080051864264533e-05,
      "learning_rate": 4.33508176488738e-06,
      "loss": 0.0,
      "step": 148000
    },
    {
      "epoch": 45.66800370256094,
      "grad_norm": 2.4885917326855633e-08,
      "learning_rate": 4.331996297439062e-06,
      "loss": 0.0,
      "step": 148010
    },
    {
      "epoch": 45.67108917000925,
      "grad_norm": 0.0004392577684484422,
      "learning_rate": 4.328910829990744e-06,
      "loss": 0.0,
      "step": 148020
    },
    {
      "epoch": 45.674174637457575,
      "grad_norm": 1.5095287242417044e-09,
      "learning_rate": 4.325825362542425e-06,
      "loss": 0.0,
      "step": 148030
    },
    {
      "epoch": 45.67726010490589,
      "grad_norm": 0.028042135760188103,
      "learning_rate": 4.322739895094107e-06,
      "loss": 0.0,
      "step": 148040
    },
    {
      "epoch": 45.68034557235421,
      "grad_norm": 8.611950619297204e-08,
      "learning_rate": 4.319654427645788e-06,
      "loss": 0.0,
      "step": 148050
    },
    {
      "epoch": 45.68343103980253,
      "grad_norm": 8.938716291595483e-07,
      "learning_rate": 4.31656896019747e-06,
      "loss": 0.0,
      "step": 148060
    },
    {
      "epoch": 45.68651650725085,
      "grad_norm": 0.0012112930417060852,
      "learning_rate": 4.313483492749152e-06,
      "loss": 0.0,
      "step": 148070
    },
    {
      "epoch": 45.689601974699166,
      "grad_norm": 1.4401567938193693e-08,
      "learning_rate": 4.310398025300833e-06,
      "loss": 0.0,
      "step": 148080
    },
    {
      "epoch": 45.69268744214749,
      "grad_norm": 3.878017551528501e-08,
      "learning_rate": 4.307312557852515e-06,
      "loss": 0.0,
      "step": 148090
    },
    {
      "epoch": 45.6957729095958,
      "grad_norm": 9.560062963487326e-09,
      "learning_rate": 4.3042270904041965e-06,
      "loss": 0.0,
      "step": 148100
    },
    {
      "epoch": 45.698858377044125,
      "grad_norm": 0.0014935361687093973,
      "learning_rate": 4.301141622955878e-06,
      "loss": 0.0,
      "step": 148110
    },
    {
      "epoch": 45.70194384449244,
      "grad_norm": 4.158888987149112e-05,
      "learning_rate": 4.29805615550756e-06,
      "loss": 0.0,
      "step": 148120
    },
    {
      "epoch": 45.705029311940756,
      "grad_norm": 8.599445777690562e-08,
      "learning_rate": 4.294970688059241e-06,
      "loss": 0.0,
      "step": 148130
    },
    {
      "epoch": 45.70811477938908,
      "grad_norm": 0.00010258006659569219,
      "learning_rate": 4.291885220610923e-06,
      "loss": 0.0,
      "step": 148140
    },
    {
      "epoch": 45.71120024683739,
      "grad_norm": 3.6763810840056976e-07,
      "learning_rate": 4.288799753162604e-06,
      "loss": 0.0,
      "step": 148150
    },
    {
      "epoch": 45.714285714285715,
      "grad_norm": 1.494761505682618e-07,
      "learning_rate": 4.285714285714286e-06,
      "loss": 0.0,
      "step": 148160
    },
    {
      "epoch": 45.71737118173403,
      "grad_norm": 8.299421239144067e-08,
      "learning_rate": 4.282628818265968e-06,
      "loss": 0.0025,
      "step": 148170
    },
    {
      "epoch": 45.72045664918235,
      "grad_norm": 1.6023555815536383e-08,
      "learning_rate": 4.279543350817649e-06,
      "loss": 0.0,
      "step": 148180
    },
    {
      "epoch": 45.72354211663067,
      "grad_norm": 4.564619970892636e-08,
      "learning_rate": 4.276457883369331e-06,
      "loss": 0.0,
      "step": 148190
    },
    {
      "epoch": 45.72662758407899,
      "grad_norm": 2.9937818890601875e-09,
      "learning_rate": 4.273372415921012e-06,
      "loss": 0.0,
      "step": 148200
    },
    {
      "epoch": 45.729713051527305,
      "grad_norm": 2.5048454972420586e-06,
      "learning_rate": 4.270286948472694e-06,
      "loss": 0.0,
      "step": 148210
    },
    {
      "epoch": 45.73279851897563,
      "grad_norm": 1.2732560783490499e-08,
      "learning_rate": 4.267201481024376e-06,
      "loss": 0.0,
      "step": 148220
    },
    {
      "epoch": 45.73588398642394,
      "grad_norm": 2.6930102592359617e-08,
      "learning_rate": 4.264116013576057e-06,
      "loss": 0.0,
      "step": 148230
    },
    {
      "epoch": 45.738969453872265,
      "grad_norm": 6.596268775638237e-08,
      "learning_rate": 4.2610305461277385e-06,
      "loss": 0.0,
      "step": 148240
    },
    {
      "epoch": 45.74205492132058,
      "grad_norm": 0.0004550987796392292,
      "learning_rate": 4.25794507867942e-06,
      "loss": 0.0,
      "step": 148250
    },
    {
      "epoch": 45.745140388768895,
      "grad_norm": 6.226426648936467e-06,
      "learning_rate": 4.254859611231102e-06,
      "loss": 0.0,
      "step": 148260
    },
    {
      "epoch": 45.74822585621722,
      "grad_norm": 1.4913766790414229e-05,
      "learning_rate": 4.251774143782783e-06,
      "loss": 0.0,
      "step": 148270
    },
    {
      "epoch": 45.75131132366553,
      "grad_norm": 3.156431921524927e-05,
      "learning_rate": 4.248688676334465e-06,
      "loss": 0.0,
      "step": 148280
    },
    {
      "epoch": 45.754396791113855,
      "grad_norm": 9.24346110764418e-08,
      "learning_rate": 4.245603208886147e-06,
      "loss": 0.0,
      "step": 148290
    },
    {
      "epoch": 45.75748225856217,
      "grad_norm": 4.452321622494537e-09,
      "learning_rate": 4.2425177414378274e-06,
      "loss": 0.0,
      "step": 148300
    },
    {
      "epoch": 45.76056772601049,
      "grad_norm": 1.821854027639347e-07,
      "learning_rate": 4.23943227398951e-06,
      "loss": 0.0001,
      "step": 148310
    },
    {
      "epoch": 45.76365319345881,
      "grad_norm": 1.729926111693203e-06,
      "learning_rate": 4.2363468065411915e-06,
      "loss": 0.0,
      "step": 148320
    },
    {
      "epoch": 45.76673866090713,
      "grad_norm": 2.7106716871116987e-08,
      "learning_rate": 4.233261339092872e-06,
      "loss": 0.0,
      "step": 148330
    },
    {
      "epoch": 45.769824128355445,
      "grad_norm": 0.00016887097444850951,
      "learning_rate": 4.230175871644555e-06,
      "loss": 0.0,
      "step": 148340
    },
    {
      "epoch": 45.77290959580377,
      "grad_norm": 2.876255621231394e-06,
      "learning_rate": 4.227090404196236e-06,
      "loss": 0.0,
      "step": 148350
    },
    {
      "epoch": 45.77599506325208,
      "grad_norm": 2.5343758203177913e-09,
      "learning_rate": 4.224004936747917e-06,
      "loss": 0.0,
      "step": 148360
    },
    {
      "epoch": 45.7790805307004,
      "grad_norm": 4.554315182758728e-06,
      "learning_rate": 4.220919469299599e-06,
      "loss": 0.0,
      "step": 148370
    },
    {
      "epoch": 45.78216599814872,
      "grad_norm": 1.9215539737160725e-07,
      "learning_rate": 4.2178340018512805e-06,
      "loss": 0.0,
      "step": 148380
    },
    {
      "epoch": 45.785251465597035,
      "grad_norm": 9.46877698879689e-05,
      "learning_rate": 4.214748534402962e-06,
      "loss": 0.0,
      "step": 148390
    },
    {
      "epoch": 45.78833693304536,
      "grad_norm": 9.503630105101024e-10,
      "learning_rate": 4.211663066954644e-06,
      "loss": 0.0,
      "step": 148400
    },
    {
      "epoch": 45.79142240049367,
      "grad_norm": 3.4786456382107644e-08,
      "learning_rate": 4.208577599506325e-06,
      "loss": 0.0,
      "step": 148410
    },
    {
      "epoch": 45.794507867941995,
      "grad_norm": 0.0004520890361163765,
      "learning_rate": 4.205492132058007e-06,
      "loss": 0.0,
      "step": 148420
    },
    {
      "epoch": 45.79759333539031,
      "grad_norm": 7.776476991239178e-07,
      "learning_rate": 4.202406664609689e-06,
      "loss": 0.0,
      "step": 148430
    },
    {
      "epoch": 45.80067880283863,
      "grad_norm": 1.7476028233431862e-06,
      "learning_rate": 4.19932119716137e-06,
      "loss": 0.0,
      "step": 148440
    },
    {
      "epoch": 45.80376427028695,
      "grad_norm": 2.2814738542820123e-08,
      "learning_rate": 4.196235729713052e-06,
      "loss": 0.0,
      "step": 148450
    },
    {
      "epoch": 45.80684973773527,
      "grad_norm": 2.509891317004076e-07,
      "learning_rate": 4.1931502622647335e-06,
      "loss": 0.0,
      "step": 148460
    },
    {
      "epoch": 45.809935205183585,
      "grad_norm": 5.5799817346269265e-05,
      "learning_rate": 4.190064794816414e-06,
      "loss": 0.0,
      "step": 148470
    },
    {
      "epoch": 45.8130206726319,
      "grad_norm": 2.1524822813034916e-08,
      "learning_rate": 4.186979327368097e-06,
      "loss": 0.0,
      "step": 148480
    },
    {
      "epoch": 45.81610614008022,
      "grad_norm": 1.5257935193080385e-10,
      "learning_rate": 4.183893859919778e-06,
      "loss": 0.0009,
      "step": 148490
    },
    {
      "epoch": 45.81919160752854,
      "grad_norm": 2.2037957023712806e-06,
      "learning_rate": 4.180808392471459e-06,
      "loss": 0.0002,
      "step": 148500
    },
    {
      "epoch": 45.82227707497686,
      "grad_norm": 0.0003063000040128827,
      "learning_rate": 4.177722925023142e-06,
      "loss": 0.0,
      "step": 148510
    },
    {
      "epoch": 45.825362542425175,
      "grad_norm": 7.759106779303693e-07,
      "learning_rate": 4.1746374575748224e-06,
      "loss": 0.0,
      "step": 148520
    },
    {
      "epoch": 45.8284480098735,
      "grad_norm": 6.176088618303766e-07,
      "learning_rate": 4.171551990126504e-06,
      "loss": 0.0,
      "step": 148530
    },
    {
      "epoch": 45.83153347732181,
      "grad_norm": 3.103190238107345e-06,
      "learning_rate": 4.1684665226781866e-06,
      "loss": 0.0,
      "step": 148540
    },
    {
      "epoch": 45.834618944770135,
      "grad_norm": 4.380699136774524e-10,
      "learning_rate": 4.165381055229867e-06,
      "loss": 0.0,
      "step": 148550
    },
    {
      "epoch": 45.83770441221845,
      "grad_norm": 4.191361711036734e-07,
      "learning_rate": 4.162295587781549e-06,
      "loss": 0.0,
      "step": 148560
    },
    {
      "epoch": 45.84078987966677,
      "grad_norm": 1.9508795958245173e-05,
      "learning_rate": 4.159210120333231e-06,
      "loss": 0.0,
      "step": 148570
    },
    {
      "epoch": 45.84387534711509,
      "grad_norm": 3.3055953281291295e-06,
      "learning_rate": 4.156124652884912e-06,
      "loss": 0.0,
      "step": 148580
    },
    {
      "epoch": 45.84696081456341,
      "grad_norm": 0.00030513308593071997,
      "learning_rate": 4.153039185436594e-06,
      "loss": 0.0,
      "step": 148590
    },
    {
      "epoch": 45.850046282011725,
      "grad_norm": 1.123867718888505e-06,
      "learning_rate": 4.1499537179882755e-06,
      "loss": 0.0,
      "step": 148600
    },
    {
      "epoch": 45.85313174946004,
      "grad_norm": 6.424677394534228e-07,
      "learning_rate": 4.146868250539957e-06,
      "loss": 0.0,
      "step": 148610
    },
    {
      "epoch": 45.85621721690836,
      "grad_norm": 6.210996605915398e-09,
      "learning_rate": 4.143782783091638e-06,
      "loss": 0.0,
      "step": 148620
    },
    {
      "epoch": 45.85930268435668,
      "grad_norm": 9.870439043879742e-08,
      "learning_rate": 4.14069731564332e-06,
      "loss": 0.0,
      "step": 148630
    },
    {
      "epoch": 45.862388151805,
      "grad_norm": 3.4164986573159695e-07,
      "learning_rate": 4.137611848195002e-06,
      "loss": 0.0,
      "step": 148640
    },
    {
      "epoch": 45.865473619253315,
      "grad_norm": 4.111085218028165e-06,
      "learning_rate": 4.134526380746683e-06,
      "loss": 0.0,
      "step": 148650
    },
    {
      "epoch": 45.86855908670164,
      "grad_norm": 1.4171743714541662e-05,
      "learning_rate": 4.131440913298365e-06,
      "loss": 0.0,
      "step": 148660
    },
    {
      "epoch": 45.87164455414995,
      "grad_norm": 2.189572398947348e-07,
      "learning_rate": 4.128355445850046e-06,
      "loss": 0.0001,
      "step": 148670
    },
    {
      "epoch": 45.874730021598275,
      "grad_norm": 2.6585349033325656e-08,
      "learning_rate": 4.125269978401728e-06,
      "loss": 0.0,
      "step": 148680
    },
    {
      "epoch": 45.87781548904659,
      "grad_norm": 2.2991370940417255e-07,
      "learning_rate": 4.12218451095341e-06,
      "loss": 0.0,
      "step": 148690
    },
    {
      "epoch": 45.88090095649491,
      "grad_norm": 3.1221421892269063e-08,
      "learning_rate": 4.119099043505091e-06,
      "loss": 0.0,
      "step": 148700
    },
    {
      "epoch": 45.88398642394323,
      "grad_norm": 1.3923273911586875e-07,
      "learning_rate": 4.1160135760567726e-06,
      "loss": 0.0,
      "step": 148710
    },
    {
      "epoch": 45.88707189139154,
      "grad_norm": 1.0795821481224266e-06,
      "learning_rate": 4.112928108608454e-06,
      "loss": 0.0,
      "step": 148720
    },
    {
      "epoch": 45.890157358839865,
      "grad_norm": 5.967696779407561e-06,
      "learning_rate": 4.109842641160136e-06,
      "loss": 0.0,
      "step": 148730
    },
    {
      "epoch": 45.89324282628818,
      "grad_norm": 2.5000454115797766e-06,
      "learning_rate": 4.1067571737118175e-06,
      "loss": 0.0,
      "step": 148740
    },
    {
      "epoch": 45.8963282937365,
      "grad_norm": 6.837814794380392e-07,
      "learning_rate": 4.103671706263499e-06,
      "loss": 0.0,
      "step": 148750
    },
    {
      "epoch": 45.89941376118482,
      "grad_norm": 0.0001866900856839493,
      "learning_rate": 4.100586238815181e-06,
      "loss": 0.0,
      "step": 148760
    },
    {
      "epoch": 45.90249922863314,
      "grad_norm": 1.0315470717614517e-06,
      "learning_rate": 4.097500771366862e-06,
      "loss": 0.0,
      "step": 148770
    },
    {
      "epoch": 45.905584696081455,
      "grad_norm": 0.00019557090126909316,
      "learning_rate": 4.094415303918544e-06,
      "loss": 0.0,
      "step": 148780
    },
    {
      "epoch": 45.90867016352978,
      "grad_norm": 2.6433164990180558e-08,
      "learning_rate": 4.091329836470226e-06,
      "loss": 0.0,
      "step": 148790
    },
    {
      "epoch": 45.91175563097809,
      "grad_norm": 3.34394940182392e-07,
      "learning_rate": 4.088244369021907e-06,
      "loss": 0.0,
      "step": 148800
    },
    {
      "epoch": 45.914841098426415,
      "grad_norm": 7.016508334345417e-06,
      "learning_rate": 4.085158901573589e-06,
      "loss": 0.0,
      "step": 148810
    },
    {
      "epoch": 45.91792656587473,
      "grad_norm": 2.5886386367801606e-08,
      "learning_rate": 4.08207343412527e-06,
      "loss": 0.0,
      "step": 148820
    },
    {
      "epoch": 45.92101203332305,
      "grad_norm": 5.201071076044173e-07,
      "learning_rate": 4.078987966676952e-06,
      "loss": 0.0,
      "step": 148830
    },
    {
      "epoch": 45.92409750077137,
      "grad_norm": 1.7197824035974918e-06,
      "learning_rate": 4.075902499228634e-06,
      "loss": 0.0,
      "step": 148840
    },
    {
      "epoch": 45.92718296821968,
      "grad_norm": 4.543807818890855e-08,
      "learning_rate": 4.0728170317803145e-06,
      "loss": 0.0,
      "step": 148850
    },
    {
      "epoch": 45.930268435668005,
      "grad_norm": 1.3936632058175746e-05,
      "learning_rate": 4.069731564331997e-06,
      "loss": 0.0,
      "step": 148860
    },
    {
      "epoch": 45.93335390311632,
      "grad_norm": 3.0574480547329586e-07,
      "learning_rate": 4.066646096883678e-06,
      "loss": 0.0,
      "step": 148870
    },
    {
      "epoch": 45.93643937056464,
      "grad_norm": 8.34119020964863e-07,
      "learning_rate": 4.0635606294353594e-06,
      "loss": 0.0,
      "step": 148880
    },
    {
      "epoch": 45.93952483801296,
      "grad_norm": 4.948654375169781e-09,
      "learning_rate": 4.060475161987042e-06,
      "loss": 0.0,
      "step": 148890
    },
    {
      "epoch": 45.94261030546128,
      "grad_norm": 3.478280419244584e-08,
      "learning_rate": 4.057389694538723e-06,
      "loss": 0.0,
      "step": 148900
    },
    {
      "epoch": 45.945695772909595,
      "grad_norm": 8.923510904423892e-06,
      "learning_rate": 4.054304227090404e-06,
      "loss": 0.0,
      "step": 148910
    },
    {
      "epoch": 45.94878124035792,
      "grad_norm": 6.87708165969525e-08,
      "learning_rate": 4.051218759642086e-06,
      "loss": 0.0,
      "step": 148920
    },
    {
      "epoch": 45.95186670780623,
      "grad_norm": 2.955501656742854e-07,
      "learning_rate": 4.048133292193768e-06,
      "loss": 0.0,
      "step": 148930
    },
    {
      "epoch": 45.954952175254554,
      "grad_norm": 2.1714919640203334e-08,
      "learning_rate": 4.045047824745449e-06,
      "loss": 0.0,
      "step": 148940
    },
    {
      "epoch": 45.95803764270287,
      "grad_norm": 6.146509434756808e-08,
      "learning_rate": 4.041962357297131e-06,
      "loss": 0.0,
      "step": 148950
    },
    {
      "epoch": 45.961123110151185,
      "grad_norm": 2.3577752017445164e-06,
      "learning_rate": 4.0388768898488125e-06,
      "loss": 0.0,
      "step": 148960
    },
    {
      "epoch": 45.96420857759951,
      "grad_norm": 2.718626745945585e-08,
      "learning_rate": 4.035791422400493e-06,
      "loss": 0.0,
      "step": 148970
    },
    {
      "epoch": 45.96729404504782,
      "grad_norm": 7.509657393711677e-07,
      "learning_rate": 4.032705954952176e-06,
      "loss": 0.0,
      "step": 148980
    },
    {
      "epoch": 45.970379512496145,
      "grad_norm": 8.961510977734122e-10,
      "learning_rate": 4.029620487503857e-06,
      "loss": 0.0,
      "step": 148990
    },
    {
      "epoch": 45.97346497994446,
      "grad_norm": 1.1194334547326434e-05,
      "learning_rate": 4.026535020055538e-06,
      "loss": 0.0,
      "step": 149000
    },
    {
      "epoch": 45.97655044739278,
      "grad_norm": 1.1463981536508072e-05,
      "learning_rate": 4.023449552607221e-06,
      "loss": 0.0,
      "step": 149010
    },
    {
      "epoch": 45.9796359148411,
      "grad_norm": 1.000362743752703e-07,
      "learning_rate": 4.020364085158901e-06,
      "loss": 0.0,
      "step": 149020
    },
    {
      "epoch": 45.98272138228942,
      "grad_norm": 4.1732278077688534e-07,
      "learning_rate": 4.017278617710583e-06,
      "loss": 0.0,
      "step": 149030
    },
    {
      "epoch": 45.985806849737735,
      "grad_norm": 0.0004205683362670243,
      "learning_rate": 4.0141931502622655e-06,
      "loss": 0.0,
      "step": 149040
    },
    {
      "epoch": 45.98889231718606,
      "grad_norm": 2.221127104462539e-08,
      "learning_rate": 4.011107682813946e-06,
      "loss": 0.0,
      "step": 149050
    },
    {
      "epoch": 45.99197778463437,
      "grad_norm": 0.000305958092212677,
      "learning_rate": 4.008022215365628e-06,
      "loss": 0.0,
      "step": 149060
    },
    {
      "epoch": 45.99506325208269,
      "grad_norm": 1.0349701369705144e-05,
      "learning_rate": 4.0049367479173095e-06,
      "loss": 0.0,
      "step": 149070
    },
    {
      "epoch": 45.99814871953101,
      "grad_norm": 7.492815257137408e-07,
      "learning_rate": 4.001851280468991e-06,
      "loss": 0.0,
      "step": 149080
    },
    {
      "epoch": 46.0,
      "eval_accuracy_branch1": 1.0,
      "eval_accuracy_branch2": 0.4213130407106276,
      "eval_f1_branch1": 1.0,
      "eval_f1_branch2": 0.4161105091218117,
      "eval_loss": 2.4413174060100573e-07,
      "eval_precision_branch1": 1.0,
      "eval_precision_branch2": 0.511456148458313,
      "eval_recall_branch1": 1.0,
      "eval_recall_branch2": 0.5093747287404878,
      "eval_runtime": 132.2417,
      "eval_samples_per_second": 784.041,
      "eval_steps_per_second": 98.01,
      "step": 149086
    },
    {
      "epoch": 46.001234186979325,
      "grad_norm": 0.00013916938041802496,
      "learning_rate": 3.998765813020673e-06,
      "loss": 0.0003,
      "step": 149090
    },
    {
      "epoch": 46.00431965442765,
      "grad_norm": 6.273503095144406e-05,
      "learning_rate": 3.9956803455723544e-06,
      "loss": 0.0,
      "step": 149100
    },
    {
      "epoch": 46.00740512187596,
      "grad_norm": 7.966620074739694e-08,
      "learning_rate": 3.992594878124036e-06,
      "loss": 0.0,
      "step": 149110
    },
    {
      "epoch": 46.010490589324284,
      "grad_norm": 2.02873743546661e-05,
      "learning_rate": 3.989509410675718e-06,
      "loss": 0.0,
      "step": 149120
    },
    {
      "epoch": 46.0135760567726,
      "grad_norm": 1.0732686632763944e-06,
      "learning_rate": 3.986423943227399e-06,
      "loss": 0.0,
      "step": 149130
    },
    {
      "epoch": 46.01666152422092,
      "grad_norm": 1.5392768546007574e-05,
      "learning_rate": 3.983338475779081e-06,
      "loss": 0.0,
      "step": 149140
    },
    {
      "epoch": 46.01974699166924,
      "grad_norm": 2.5699995021000177e-08,
      "learning_rate": 3.980253008330763e-06,
      "loss": 0.0,
      "step": 149150
    },
    {
      "epoch": 46.02283245911756,
      "grad_norm": 1.6265246813418344e-05,
      "learning_rate": 3.977167540882444e-06,
      "loss": 0.0,
      "step": 149160
    },
    {
      "epoch": 46.025917926565874,
      "grad_norm": 1.6704213567919624e-09,
      "learning_rate": 3.974082073434125e-06,
      "loss": 0.0,
      "step": 149170
    },
    {
      "epoch": 46.02900339401419,
      "grad_norm": 2.0646888287956244e-07,
      "learning_rate": 3.9709966059858075e-06,
      "loss": 0.0,
      "step": 149180
    },
    {
      "epoch": 46.03208886146251,
      "grad_norm": 1.1996035937045235e-05,
      "learning_rate": 3.967911138537488e-06,
      "loss": 0.0,
      "step": 149190
    },
    {
      "epoch": 46.03517432891083,
      "grad_norm": 3.3595533466268535e-08,
      "learning_rate": 3.96482567108917e-06,
      "loss": 0.0,
      "step": 149200
    },
    {
      "epoch": 46.03825979635915,
      "grad_norm": 5.830835902997933e-08,
      "learning_rate": 3.961740203640852e-06,
      "loss": 0.0,
      "step": 149210
    },
    {
      "epoch": 46.041345263807465,
      "grad_norm": 3.2097671009978512e-06,
      "learning_rate": 3.958654736192533e-06,
      "loss": 0.0,
      "step": 149220
    },
    {
      "epoch": 46.04443073125579,
      "grad_norm": 9.24003558111508e-08,
      "learning_rate": 3.955569268744215e-06,
      "loss": 0.0,
      "step": 149230
    },
    {
      "epoch": 46.0475161987041,
      "grad_norm": 1.1719008625732386e-06,
      "learning_rate": 3.952483801295896e-06,
      "loss": 0.0,
      "step": 149240
    },
    {
      "epoch": 46.050601666152424,
      "grad_norm": 1.965959199878853e-06,
      "learning_rate": 3.949398333847578e-06,
      "loss": 0.0,
      "step": 149250
    },
    {
      "epoch": 46.05368713360074,
      "grad_norm": 2.734860338193812e-08,
      "learning_rate": 3.94631286639926e-06,
      "loss": 0.0,
      "step": 149260
    },
    {
      "epoch": 46.05677260104906,
      "grad_norm": 1.2635168467056701e-08,
      "learning_rate": 3.943227398950941e-06,
      "loss": 0.0,
      "step": 149270
    },
    {
      "epoch": 46.05985806849738,
      "grad_norm": 0.002135886112228036,
      "learning_rate": 3.940141931502623e-06,
      "loss": 0.0,
      "step": 149280
    },
    {
      "epoch": 46.0629435359457,
      "grad_norm": 2.8675243513021087e-08,
      "learning_rate": 3.937056464054304e-06,
      "loss": 0.0,
      "step": 149290
    },
    {
      "epoch": 46.066029003394014,
      "grad_norm": 4.9554053305200796e-08,
      "learning_rate": 3.933970996605986e-06,
      "loss": 0.0,
      "step": 149300
    },
    {
      "epoch": 46.06911447084233,
      "grad_norm": 0.00039928194019012153,
      "learning_rate": 3.930885529157668e-06,
      "loss": 0.0,
      "step": 149310
    },
    {
      "epoch": 46.07219993829065,
      "grad_norm": 2.0940767626598245e-06,
      "learning_rate": 3.927800061709349e-06,
      "loss": 0.0,
      "step": 149320
    },
    {
      "epoch": 46.07528540573897,
      "grad_norm": 6.715793254841174e-09,
      "learning_rate": 3.924714594261031e-06,
      "loss": 0.0,
      "step": 149330
    },
    {
      "epoch": 46.07837087318729,
      "grad_norm": 3.879436007991899e-07,
      "learning_rate": 3.921629126812712e-06,
      "loss": 0.0,
      "step": 149340
    },
    {
      "epoch": 46.081456340635604,
      "grad_norm": 3.595376620069146e-05,
      "learning_rate": 3.9185436593643935e-06,
      "loss": 0.0,
      "step": 149350
    },
    {
      "epoch": 46.08454180808393,
      "grad_norm": 2.517512882604933e-07,
      "learning_rate": 3.915458191916076e-06,
      "loss": 0.0,
      "step": 149360
    },
    {
      "epoch": 46.08762727553224,
      "grad_norm": 1.7835121468579018e-07,
      "learning_rate": 3.912372724467757e-06,
      "loss": 0.0,
      "step": 149370
    },
    {
      "epoch": 46.090712742980564,
      "grad_norm": 1.6543835954507813e-06,
      "learning_rate": 3.909287257019438e-06,
      "loss": 0.0,
      "step": 149380
    },
    {
      "epoch": 46.09379821042888,
      "grad_norm": 0.00028488109819591045,
      "learning_rate": 3.90620178957112e-06,
      "loss": 0.0,
      "step": 149390
    },
    {
      "epoch": 46.0968836778772,
      "grad_norm": 2.093567763594706e-09,
      "learning_rate": 3.903116322122802e-06,
      "loss": 0.0,
      "step": 149400
    },
    {
      "epoch": 46.09996914532552,
      "grad_norm": 2.617331574583659e-06,
      "learning_rate": 3.900030854674483e-06,
      "loss": 0.0,
      "step": 149410
    },
    {
      "epoch": 46.10305461277383,
      "grad_norm": 1.8402281057205983e-05,
      "learning_rate": 3.896945387226165e-06,
      "loss": 0.0,
      "step": 149420
    },
    {
      "epoch": 46.106140080222154,
      "grad_norm": 5.546607062534292e-10,
      "learning_rate": 3.8938599197778465e-06,
      "loss": 0.0004,
      "step": 149430
    },
    {
      "epoch": 46.10922554767047,
      "grad_norm": 1.0888487622651155e-06,
      "learning_rate": 3.890774452329528e-06,
      "loss": 0.0,
      "step": 149440
    },
    {
      "epoch": 46.11231101511879,
      "grad_norm": 3.145841276364081e-08,
      "learning_rate": 3.88768898488121e-06,
      "loss": 0.0,
      "step": 149450
    },
    {
      "epoch": 46.11539648256711,
      "grad_norm": 8.923261018978224e-10,
      "learning_rate": 3.8846035174328914e-06,
      "loss": 0.0,
      "step": 149460
    },
    {
      "epoch": 46.11848195001543,
      "grad_norm": 3.2915597785176942e-06,
      "learning_rate": 3.881518049984573e-06,
      "loss": 0.0,
      "step": 149470
    },
    {
      "epoch": 46.121567417463744,
      "grad_norm": 2.573443964593025e-07,
      "learning_rate": 3.878432582536255e-06,
      "loss": 0.0,
      "step": 149480
    },
    {
      "epoch": 46.12465288491207,
      "grad_norm": 1.1083217898999465e-08,
      "learning_rate": 3.8753471150879355e-06,
      "loss": 0.0,
      "step": 149490
    },
    {
      "epoch": 46.12773835236038,
      "grad_norm": 3.5800585607148605e-08,
      "learning_rate": 3.872261647639618e-06,
      "loss": 0.0,
      "step": 149500
    },
    {
      "epoch": 46.130823819808704,
      "grad_norm": 2.9996495868545026e-05,
      "learning_rate": 3.8691761801912996e-06,
      "loss": 0.0,
      "step": 149510
    },
    {
      "epoch": 46.13390928725702,
      "grad_norm": 6.230774306459352e-05,
      "learning_rate": 3.86609071274298e-06,
      "loss": 0.0,
      "step": 149520
    },
    {
      "epoch": 46.13699475470534,
      "grad_norm": 1.8574828573036939e-06,
      "learning_rate": 3.863005245294663e-06,
      "loss": 0.0,
      "step": 149530
    },
    {
      "epoch": 46.14008022215366,
      "grad_norm": 0.010188239626586437,
      "learning_rate": 3.859919777846344e-06,
      "loss": 0.0,
      "step": 149540
    },
    {
      "epoch": 46.14316568960197,
      "grad_norm": 6.171429959067609e-06,
      "learning_rate": 3.856834310398025e-06,
      "loss": 0.0,
      "step": 149550
    },
    {
      "epoch": 46.146251157050294,
      "grad_norm": 7.889196240284946e-06,
      "learning_rate": 3.853748842949708e-06,
      "loss": 0.0,
      "step": 149560
    },
    {
      "epoch": 46.14933662449861,
      "grad_norm": 3.381041153716069e-07,
      "learning_rate": 3.8506633755013885e-06,
      "loss": 0.0,
      "step": 149570
    },
    {
      "epoch": 46.15242209194693,
      "grad_norm": 4.335478820394201e-08,
      "learning_rate": 3.84757790805307e-06,
      "loss": 0.0,
      "step": 149580
    },
    {
      "epoch": 46.15550755939525,
      "grad_norm": 5.1909428293583915e-06,
      "learning_rate": 3.844492440604752e-06,
      "loss": 0.0,
      "step": 149590
    },
    {
      "epoch": 46.15859302684357,
      "grad_norm": 0.0017114345682784915,
      "learning_rate": 3.841406973156433e-06,
      "loss": 0.0,
      "step": 149600
    },
    {
      "epoch": 46.161678494291884,
      "grad_norm": 7.180330430855975e-05,
      "learning_rate": 3.838321505708115e-06,
      "loss": 0.0,
      "step": 149610
    },
    {
      "epoch": 46.164763961740206,
      "grad_norm": 5.467985465656966e-05,
      "learning_rate": 3.835236038259797e-06,
      "loss": 0.0,
      "step": 149620
    },
    {
      "epoch": 46.16784942918852,
      "grad_norm": 4.1199164115823805e-06,
      "learning_rate": 3.832150570811478e-06,
      "loss": 0.0,
      "step": 149630
    },
    {
      "epoch": 46.170934896636844,
      "grad_norm": 5.581223376793787e-07,
      "learning_rate": 3.829065103363159e-06,
      "loss": 0.0,
      "step": 149640
    },
    {
      "epoch": 46.17402036408516,
      "grad_norm": 0.00021387914603110403,
      "learning_rate": 3.8259796359148415e-06,
      "loss": 0.0,
      "step": 149650
    },
    {
      "epoch": 46.177105831533474,
      "grad_norm": 3.88677744922461e-06,
      "learning_rate": 3.822894168466523e-06,
      "loss": 0.0,
      "step": 149660
    },
    {
      "epoch": 46.180191298981796,
      "grad_norm": 4.719594471680466e-06,
      "learning_rate": 3.819808701018204e-06,
      "loss": 0.0,
      "step": 149670
    },
    {
      "epoch": 46.18327676643011,
      "grad_norm": 4.45562278628131e-07,
      "learning_rate": 3.8167232335698864e-06,
      "loss": 0.0,
      "step": 149680
    },
    {
      "epoch": 46.186362233878434,
      "grad_norm": 2.406464716386836e-07,
      "learning_rate": 3.8136377661215672e-06,
      "loss": 0.0,
      "step": 149690
    },
    {
      "epoch": 46.18944770132675,
      "grad_norm": 6.0932139334113344e-09,
      "learning_rate": 3.8105522986732493e-06,
      "loss": 0.0,
      "step": 149700
    },
    {
      "epoch": 46.19253316877507,
      "grad_norm": 1.4195838948793948e-09,
      "learning_rate": 3.807466831224931e-06,
      "loss": 0.0,
      "step": 149710
    },
    {
      "epoch": 46.19561863622339,
      "grad_norm": 1.4598110283259302e-05,
      "learning_rate": 3.804381363776612e-06,
      "loss": 0.0,
      "step": 149720
    },
    {
      "epoch": 46.19870410367171,
      "grad_norm": 4.877305173067725e-07,
      "learning_rate": 3.801295896328294e-06,
      "loss": 0.0,
      "step": 149730
    },
    {
      "epoch": 46.201789571120024,
      "grad_norm": 1.2307896213314962e-06,
      "learning_rate": 3.7982104288799754e-06,
      "loss": 0.0,
      "step": 149740
    },
    {
      "epoch": 46.204875038568346,
      "grad_norm": 0.006055805832147598,
      "learning_rate": 3.795124961431657e-06,
      "loss": 0.0,
      "step": 149750
    },
    {
      "epoch": 46.20796050601666,
      "grad_norm": 3.8717843153790454e-07,
      "learning_rate": 3.792039493983339e-06,
      "loss": 0.0,
      "step": 149760
    },
    {
      "epoch": 46.21104597346498,
      "grad_norm": 2.3537502329418203e-06,
      "learning_rate": 3.7889540265350203e-06,
      "loss": 0.0,
      "step": 149770
    },
    {
      "epoch": 46.2141314409133,
      "grad_norm": 1.347268607787555e-06,
      "learning_rate": 3.785868559086702e-06,
      "loss": 0.0,
      "step": 149780
    },
    {
      "epoch": 46.217216908361614,
      "grad_norm": 7.419521921292471e-07,
      "learning_rate": 3.782783091638383e-06,
      "loss": 0.0,
      "step": 149790
    },
    {
      "epoch": 46.220302375809936,
      "grad_norm": 5.835686778254967e-08,
      "learning_rate": 3.779697624190065e-06,
      "loss": 0.0,
      "step": 149800
    },
    {
      "epoch": 46.22338784325825,
      "grad_norm": 2.072816940312805e-08,
      "learning_rate": 3.7766121567417468e-06,
      "loss": 0.0,
      "step": 149810
    },
    {
      "epoch": 46.226473310706574,
      "grad_norm": 8.247294317698106e-06,
      "learning_rate": 3.773526689293428e-06,
      "loss": 0.0,
      "step": 149820
    },
    {
      "epoch": 46.22955877815489,
      "grad_norm": 3.270626223184081e-07,
      "learning_rate": 3.77044122184511e-06,
      "loss": 0.0,
      "step": 149830
    },
    {
      "epoch": 46.23264424560321,
      "grad_norm": 1.7144113371614367e-05,
      "learning_rate": 3.7673557543967912e-06,
      "loss": 0.0027,
      "step": 149840
    },
    {
      "epoch": 46.235729713051526,
      "grad_norm": 4.58053106555667e-09,
      "learning_rate": 3.764270286948473e-06,
      "loss": 0.0,
      "step": 149850
    },
    {
      "epoch": 46.23881518049985,
      "grad_norm": 2.7469346605357714e-05,
      "learning_rate": 3.761184819500155e-06,
      "loss": 0.0,
      "step": 149860
    },
    {
      "epoch": 46.241900647948164,
      "grad_norm": 1.5785601590323495e-06,
      "learning_rate": 3.758099352051836e-06,
      "loss": 0.0,
      "step": 149870
    },
    {
      "epoch": 46.244986115396486,
      "grad_norm": 5.563201739278156e-07,
      "learning_rate": 3.7550138846035178e-06,
      "loss": 0.0,
      "step": 149880
    },
    {
      "epoch": 46.2480715828448,
      "grad_norm": 5.860843543814553e-07,
      "learning_rate": 3.751928417155199e-06,
      "loss": 0.0,
      "step": 149890
    },
    {
      "epoch": 46.251157050293116,
      "grad_norm": 7.358493121500942e-07,
      "learning_rate": 3.748842949706881e-06,
      "loss": 0.0,
      "step": 149900
    },
    {
      "epoch": 46.25424251774144,
      "grad_norm": 1.4463394926167439e-08,
      "learning_rate": 3.7457574822585627e-06,
      "loss": 0.0,
      "step": 149910
    },
    {
      "epoch": 46.257327985189754,
      "grad_norm": 0.0006321165128611028,
      "learning_rate": 3.742672014810244e-06,
      "loss": 0.0,
      "step": 149920
    },
    {
      "epoch": 46.260413452638076,
      "grad_norm": 1.6085550669231452e-09,
      "learning_rate": 3.739586547361926e-06,
      "loss": 0.0,
      "step": 149930
    },
    {
      "epoch": 46.26349892008639,
      "grad_norm": 0.0022349990904331207,
      "learning_rate": 3.7365010799136067e-06,
      "loss": 0.0,
      "step": 149940
    },
    {
      "epoch": 46.266584387534714,
      "grad_norm": 1.312858266544481e-08,
      "learning_rate": 3.7334156124652888e-06,
      "loss": 0.0,
      "step": 149950
    },
    {
      "epoch": 46.26966985498303,
      "grad_norm": 1.8607366655487567e-05,
      "learning_rate": 3.7303301450169704e-06,
      "loss": 0.0,
      "step": 149960
    },
    {
      "epoch": 46.27275532243135,
      "grad_norm": 4.9678424147714395e-06,
      "learning_rate": 3.7272446775686516e-06,
      "loss": 0.0,
      "step": 149970
    },
    {
      "epoch": 46.275840789879666,
      "grad_norm": 3.727941511044719e-09,
      "learning_rate": 3.7241592101203336e-06,
      "loss": 0.0,
      "step": 149980
    },
    {
      "epoch": 46.27892625732799,
      "grad_norm": 8.842681563692167e-05,
      "learning_rate": 3.721073742672015e-06,
      "loss": 0.0,
      "step": 149990
    },
    {
      "epoch": 46.282011724776304,
      "grad_norm": 0.21454069018363953,
      "learning_rate": 3.7179882752236965e-06,
      "loss": 0.0001,
      "step": 150000
    },
    {
      "epoch": 46.28509719222462,
      "grad_norm": 0.0012105510104447603,
      "learning_rate": 3.7149028077753777e-06,
      "loss": 0.0,
      "step": 150010
    },
    {
      "epoch": 46.28818265967294,
      "grad_norm": 2.771794171962938e-08,
      "learning_rate": 3.7118173403270597e-06,
      "loss": 0.0,
      "step": 150020
    },
    {
      "epoch": 46.291268127121256,
      "grad_norm": 2.891132169224875e-07,
      "learning_rate": 3.7087318728787414e-06,
      "loss": 0.0,
      "step": 150030
    },
    {
      "epoch": 46.29435359456958,
      "grad_norm": 1.0630134283928783e-06,
      "learning_rate": 3.7056464054304226e-06,
      "loss": 0.0,
      "step": 150040
    },
    {
      "epoch": 46.297439062017894,
      "grad_norm": 3.1758958130012616e-07,
      "learning_rate": 3.7025609379821046e-06,
      "loss": 0.0,
      "step": 150050
    },
    {
      "epoch": 46.300524529466216,
      "grad_norm": 1.7760949333478493e-07,
      "learning_rate": 3.699475470533786e-06,
      "loss": 0.0,
      "step": 150060
    },
    {
      "epoch": 46.30360999691453,
      "grad_norm": 3.740065949386917e-05,
      "learning_rate": 3.6963900030854675e-06,
      "loss": 0.0,
      "step": 150070
    },
    {
      "epoch": 46.30669546436285,
      "grad_norm": 1.1386748610675568e-06,
      "learning_rate": 3.6933045356371495e-06,
      "loss": 0.0,
      "step": 150080
    },
    {
      "epoch": 46.30978093181117,
      "grad_norm": 4.2852386172853585e-07,
      "learning_rate": 3.6902190681888307e-06,
      "loss": 0.0,
      "step": 150090
    },
    {
      "epoch": 46.31286639925949,
      "grad_norm": 2.1688264517649714e-09,
      "learning_rate": 3.6871336007405124e-06,
      "loss": 0.0,
      "step": 150100
    },
    {
      "epoch": 46.315951866707806,
      "grad_norm": 1.068095745182518e-08,
      "learning_rate": 3.6840481332921936e-06,
      "loss": 0.0,
      "step": 150110
    },
    {
      "epoch": 46.31903733415612,
      "grad_norm": 7.22614174719638e-07,
      "learning_rate": 3.6809626658438756e-06,
      "loss": 0.0,
      "step": 150120
    },
    {
      "epoch": 46.32212280160444,
      "grad_norm": 7.320725785575632e-07,
      "learning_rate": 3.6778771983955572e-06,
      "loss": 0.0001,
      "step": 150130
    },
    {
      "epoch": 46.32520826905276,
      "grad_norm": 7.159086976571416e-07,
      "learning_rate": 3.6747917309472384e-06,
      "loss": 0.0,
      "step": 150140
    },
    {
      "epoch": 46.32829373650108,
      "grad_norm": 1.1743177097400803e-08,
      "learning_rate": 3.6717062634989205e-06,
      "loss": 0.0,
      "step": 150150
    },
    {
      "epoch": 46.331379203949396,
      "grad_norm": 6.048674663361453e-07,
      "learning_rate": 3.6686207960506017e-06,
      "loss": 0.0,
      "step": 150160
    },
    {
      "epoch": 46.33446467139772,
      "grad_norm": 4.971801672581933e-07,
      "learning_rate": 3.6655353286022833e-06,
      "loss": 0.0,
      "step": 150170
    },
    {
      "epoch": 46.337550138846034,
      "grad_norm": 2.4242865492851706e-07,
      "learning_rate": 3.6624498611539654e-06,
      "loss": 0.0,
      "step": 150180
    },
    {
      "epoch": 46.340635606294356,
      "grad_norm": 5.045984835305717e-06,
      "learning_rate": 3.6593643937056466e-06,
      "loss": 0.0,
      "step": 150190
    },
    {
      "epoch": 46.34372107374267,
      "grad_norm": 2.223058572781156e-06,
      "learning_rate": 3.6562789262573282e-06,
      "loss": 0.0,
      "step": 150200
    },
    {
      "epoch": 46.34680654119099,
      "grad_norm": 1.3118362403474748e-05,
      "learning_rate": 3.6531934588090094e-06,
      "loss": 0.0,
      "step": 150210
    },
    {
      "epoch": 46.34989200863931,
      "grad_norm": 1.7661490119280643e-06,
      "learning_rate": 3.6501079913606915e-06,
      "loss": 0.0,
      "step": 150220
    },
    {
      "epoch": 46.35297747608763,
      "grad_norm": 2.359862305567617e-10,
      "learning_rate": 3.647022523912373e-06,
      "loss": 0.0,
      "step": 150230
    },
    {
      "epoch": 46.356062943535946,
      "grad_norm": 9.518544175080024e-06,
      "learning_rate": 3.6439370564640543e-06,
      "loss": 0.0,
      "step": 150240
    },
    {
      "epoch": 46.35914841098426,
      "grad_norm": 7.94352945376886e-06,
      "learning_rate": 3.6408515890157364e-06,
      "loss": 0.0,
      "step": 150250
    },
    {
      "epoch": 46.36223387843258,
      "grad_norm": 4.8287223108900434e-08,
      "learning_rate": 3.637766121567417e-06,
      "loss": 0.0,
      "step": 150260
    },
    {
      "epoch": 46.3653193458809,
      "grad_norm": 0.0006860971916466951,
      "learning_rate": 3.6346806541190992e-06,
      "loss": 0.0,
      "step": 150270
    },
    {
      "epoch": 46.36840481332922,
      "grad_norm": 3.206314431736246e-07,
      "learning_rate": 3.631595186670781e-06,
      "loss": 0.0,
      "step": 150280
    },
    {
      "epoch": 46.371490280777536,
      "grad_norm": 7.363173182284299e-09,
      "learning_rate": 3.628509719222462e-06,
      "loss": 0.0,
      "step": 150290
    },
    {
      "epoch": 46.37457574822586,
      "grad_norm": 4.051196356158471e-08,
      "learning_rate": 3.625424251774144e-06,
      "loss": 0.0,
      "step": 150300
    },
    {
      "epoch": 46.37766121567417,
      "grad_norm": 1.8917393163064844e-06,
      "learning_rate": 3.6223387843258253e-06,
      "loss": 0.0,
      "step": 150310
    },
    {
      "epoch": 46.380746683122496,
      "grad_norm": 1.1213913921892527e-06,
      "learning_rate": 3.619253316877507e-06,
      "loss": 0.0,
      "step": 150320
    },
    {
      "epoch": 46.38383215057081,
      "grad_norm": 2.838329783116933e-05,
      "learning_rate": 3.616167849429189e-06,
      "loss": 0.0,
      "step": 150330
    },
    {
      "epoch": 46.38691761801913,
      "grad_norm": 2.1827499807614004e-09,
      "learning_rate": 3.61308238198087e-06,
      "loss": 0.0,
      "step": 150340
    },
    {
      "epoch": 46.39000308546745,
      "grad_norm": 3.5927536146118655e-07,
      "learning_rate": 3.609996914532552e-06,
      "loss": 0.0,
      "step": 150350
    },
    {
      "epoch": 46.39308855291576,
      "grad_norm": 4.1093298932537436e-05,
      "learning_rate": 3.606911447084233e-06,
      "loss": 0.0,
      "step": 150360
    },
    {
      "epoch": 46.396174020364086,
      "grad_norm": 4.641073303446319e-07,
      "learning_rate": 3.603825979635915e-06,
      "loss": 0.0,
      "step": 150370
    },
    {
      "epoch": 46.3992594878124,
      "grad_norm": 6.984205924709386e-07,
      "learning_rate": 3.6007405121875967e-06,
      "loss": 0.0,
      "step": 150380
    },
    {
      "epoch": 46.40234495526072,
      "grad_norm": 8.751755444791343e-07,
      "learning_rate": 3.597655044739278e-06,
      "loss": 0.0,
      "step": 150390
    },
    {
      "epoch": 46.40543042270904,
      "grad_norm": 6.651450235040102e-07,
      "learning_rate": 3.59456957729096e-06,
      "loss": 0.0,
      "step": 150400
    },
    {
      "epoch": 46.40851589015736,
      "grad_norm": 4.353824806457851e-06,
      "learning_rate": 3.591484109842641e-06,
      "loss": 0.0,
      "step": 150410
    },
    {
      "epoch": 46.411601357605676,
      "grad_norm": 1.5237186801186908e-07,
      "learning_rate": 3.588398642394323e-06,
      "loss": 0.0,
      "step": 150420
    },
    {
      "epoch": 46.414686825054,
      "grad_norm": 2.432997280266136e-05,
      "learning_rate": 3.585313174946005e-06,
      "loss": 0.0,
      "step": 150430
    },
    {
      "epoch": 46.41777229250231,
      "grad_norm": 3.4496286389185116e-05,
      "learning_rate": 3.582227707497686e-06,
      "loss": 0.0,
      "step": 150440
    },
    {
      "epoch": 46.420857759950636,
      "grad_norm": 1.0008422535179307e-08,
      "learning_rate": 3.5791422400493677e-06,
      "loss": 0.0,
      "step": 150450
    },
    {
      "epoch": 46.42394322739895,
      "grad_norm": 3.8499584320561553e-07,
      "learning_rate": 3.576056772601049e-06,
      "loss": 0.0,
      "step": 150460
    },
    {
      "epoch": 46.427028694847266,
      "grad_norm": 9.866034815786406e-06,
      "learning_rate": 3.572971305152731e-06,
      "loss": 0.0,
      "step": 150470
    },
    {
      "epoch": 46.43011416229559,
      "grad_norm": 3.898257546097739e-06,
      "learning_rate": 3.5698858377044126e-06,
      "loss": 0.0,
      "step": 150480
    },
    {
      "epoch": 46.4331996297439,
      "grad_norm": 2.999487605848117e-06,
      "learning_rate": 3.566800370256094e-06,
      "loss": 0.0,
      "step": 150490
    },
    {
      "epoch": 46.436285097192226,
      "grad_norm": 2.003445615628152e-06,
      "learning_rate": 3.563714902807776e-06,
      "loss": 0.0,
      "step": 150500
    },
    {
      "epoch": 46.43937056464054,
      "grad_norm": 3.32137005898403e-06,
      "learning_rate": 3.560629435359457e-06,
      "loss": 0.0,
      "step": 150510
    },
    {
      "epoch": 46.44245603208886,
      "grad_norm": 3.419183158825945e-08,
      "learning_rate": 3.5575439679111387e-06,
      "loss": 0.0,
      "step": 150520
    },
    {
      "epoch": 46.44554149953718,
      "grad_norm": 1.7718487015372375e-06,
      "learning_rate": 3.5544585004628207e-06,
      "loss": 0.0,
      "step": 150530
    },
    {
      "epoch": 46.4486269669855,
      "grad_norm": 5.71451380437793e-07,
      "learning_rate": 3.551373033014502e-06,
      "loss": 0.0,
      "step": 150540
    },
    {
      "epoch": 46.451712434433816,
      "grad_norm": 2.245204466788664e-09,
      "learning_rate": 3.5482875655661836e-06,
      "loss": 0.0,
      "step": 150550
    },
    {
      "epoch": 46.45479790188214,
      "grad_norm": 1.436036927771056e-05,
      "learning_rate": 3.545202098117865e-06,
      "loss": 0.0,
      "step": 150560
    },
    {
      "epoch": 46.45788336933045,
      "grad_norm": 0.004103436600416899,
      "learning_rate": 3.542116630669547e-06,
      "loss": 0.0,
      "step": 150570
    },
    {
      "epoch": 46.460968836778775,
      "grad_norm": 4.94895324720801e-09,
      "learning_rate": 3.5390311632212285e-06,
      "loss": 0.0,
      "step": 150580
    },
    {
      "epoch": 46.46405430422709,
      "grad_norm": 4.771883368448471e-07,
      "learning_rate": 3.5359456957729097e-06,
      "loss": 0.0,
      "step": 150590
    },
    {
      "epoch": 46.467139771675406,
      "grad_norm": 3.901908712578006e-06,
      "learning_rate": 3.5328602283245913e-06,
      "loss": 0.0,
      "step": 150600
    },
    {
      "epoch": 46.47022523912373,
      "grad_norm": 3.1295425628741214e-07,
      "learning_rate": 3.5297747608762725e-06,
      "loss": 0.0,
      "step": 150610
    },
    {
      "epoch": 46.47331070657204,
      "grad_norm": 6.467285857070237e-06,
      "learning_rate": 3.5266892934279546e-06,
      "loss": 0.0,
      "step": 150620
    },
    {
      "epoch": 46.476396174020365,
      "grad_norm": 2.4496131345586036e-07,
      "learning_rate": 3.523603825979636e-06,
      "loss": 0.0,
      "step": 150630
    },
    {
      "epoch": 46.47948164146868,
      "grad_norm": 7.222640707738037e-09,
      "learning_rate": 3.5205183585313174e-06,
      "loss": 0.0,
      "step": 150640
    },
    {
      "epoch": 46.482567108917,
      "grad_norm": 3.319754978292622e-05,
      "learning_rate": 3.5174328910829995e-06,
      "loss": 0.0,
      "step": 150650
    },
    {
      "epoch": 46.48565257636532,
      "grad_norm": 4.1055971955472614e-09,
      "learning_rate": 3.5143474236346807e-06,
      "loss": 0.0,
      "step": 150660
    },
    {
      "epoch": 46.48873804381364,
      "grad_norm": 0.005935997236520052,
      "learning_rate": 3.5112619561863623e-06,
      "loss": 0.0,
      "step": 150670
    },
    {
      "epoch": 46.491823511261956,
      "grad_norm": 5.317151021699829e-07,
      "learning_rate": 3.5081764887380443e-06,
      "loss": 0.0,
      "step": 150680
    },
    {
      "epoch": 46.49490897871028,
      "grad_norm": 0.00014690546959172934,
      "learning_rate": 3.5050910212897256e-06,
      "loss": 0.0,
      "step": 150690
    },
    {
      "epoch": 46.49799444615859,
      "grad_norm": 1.4242594659208407e-08,
      "learning_rate": 3.502005553841407e-06,
      "loss": 0.0,
      "step": 150700
    },
    {
      "epoch": 46.50107991360691,
      "grad_norm": 4.70420673082117e-05,
      "learning_rate": 3.4989200863930884e-06,
      "loss": 0.0,
      "step": 150710
    },
    {
      "epoch": 46.50416538105523,
      "grad_norm": 8.398722606273168e-09,
      "learning_rate": 3.4958346189447704e-06,
      "loss": 0.0,
      "step": 150720
    },
    {
      "epoch": 46.507250848503546,
      "grad_norm": 4.487689693633001e-06,
      "learning_rate": 3.492749151496452e-06,
      "loss": 0.0,
      "step": 150730
    },
    {
      "epoch": 46.51033631595187,
      "grad_norm": 2.4204633852775714e-09,
      "learning_rate": 3.4896636840481333e-06,
      "loss": 0.0001,
      "step": 150740
    },
    {
      "epoch": 46.51342178340018,
      "grad_norm": 8.374769890906464e-07,
      "learning_rate": 3.4865782165998153e-06,
      "loss": 0.0,
      "step": 150750
    },
    {
      "epoch": 46.516507250848505,
      "grad_norm": 1.524104842332008e-09,
      "learning_rate": 3.4834927491514965e-06,
      "loss": 0.0,
      "step": 150760
    },
    {
      "epoch": 46.51959271829682,
      "grad_norm": 9.742835572978947e-06,
      "learning_rate": 3.480407281703178e-06,
      "loss": 0.0,
      "step": 150770
    },
    {
      "epoch": 46.52267818574514,
      "grad_norm": 3.4315402075435486e-08,
      "learning_rate": 3.4773218142548602e-06,
      "loss": 0.0,
      "step": 150780
    },
    {
      "epoch": 46.52576365319346,
      "grad_norm": 0.00019511445134412497,
      "learning_rate": 3.4742363468065414e-06,
      "loss": 0.0,
      "step": 150790
    },
    {
      "epoch": 46.52884912064178,
      "grad_norm": 5.749138267674425e-07,
      "learning_rate": 3.471150879358223e-06,
      "loss": 0.0,
      "step": 150800
    },
    {
      "epoch": 46.531934588090095,
      "grad_norm": 5.7412179899074545e-08,
      "learning_rate": 3.4680654119099043e-06,
      "loss": 0.0,
      "step": 150810
    },
    {
      "epoch": 46.53502005553841,
      "grad_norm": 1.9662441275158926e-07,
      "learning_rate": 3.4649799444615863e-06,
      "loss": 0.0,
      "step": 150820
    },
    {
      "epoch": 46.53810552298673,
      "grad_norm": 7.698507147324563e-07,
      "learning_rate": 3.461894477013268e-06,
      "loss": 0.0,
      "step": 150830
    },
    {
      "epoch": 46.54119099043505,
      "grad_norm": 1.4126168935035821e-05,
      "learning_rate": 3.458809009564949e-06,
      "loss": 0.0,
      "step": 150840
    },
    {
      "epoch": 46.54427645788337,
      "grad_norm": 2.8707319188470137e-07,
      "learning_rate": 3.455723542116631e-06,
      "loss": 0.0,
      "step": 150850
    },
    {
      "epoch": 46.547361925331685,
      "grad_norm": 6.915412814123556e-05,
      "learning_rate": 3.4526380746683124e-06,
      "loss": 0.0,
      "step": 150860
    },
    {
      "epoch": 46.55044739278001,
      "grad_norm": 2.0438849333004327e-06,
      "learning_rate": 3.449552607219994e-06,
      "loss": 0.0,
      "step": 150870
    },
    {
      "epoch": 46.55353286022832,
      "grad_norm": 5.6377349011427214e-08,
      "learning_rate": 3.4464671397716753e-06,
      "loss": 0.0,
      "step": 150880
    },
    {
      "epoch": 46.556618327676645,
      "grad_norm": 2.018292866168281e-09,
      "learning_rate": 3.443381672323357e-06,
      "loss": 0.0,
      "step": 150890
    },
    {
      "epoch": 46.55970379512496,
      "grad_norm": 3.616615458668093e-06,
      "learning_rate": 3.440296204875039e-06,
      "loss": 0.0,
      "step": 150900
    },
    {
      "epoch": 46.56278926257328,
      "grad_norm": 1.589159523973649e-07,
      "learning_rate": 3.43721073742672e-06,
      "loss": 0.0,
      "step": 150910
    },
    {
      "epoch": 46.5658747300216,
      "grad_norm": 2.397739251591702e-07,
      "learning_rate": 3.4341252699784018e-06,
      "loss": 0.0,
      "step": 150920
    },
    {
      "epoch": 46.56896019746992,
      "grad_norm": 6.397240940714255e-05,
      "learning_rate": 3.431039802530083e-06,
      "loss": 0.0,
      "step": 150930
    },
    {
      "epoch": 46.572045664918235,
      "grad_norm": 9.109741938573279e-08,
      "learning_rate": 3.427954335081765e-06,
      "loss": 0.0,
      "step": 150940
    },
    {
      "epoch": 46.57513113236655,
      "grad_norm": 0.00012660276843234897,
      "learning_rate": 3.4248688676334467e-06,
      "loss": 0.0,
      "step": 150950
    },
    {
      "epoch": 46.57821659981487,
      "grad_norm": 1.8362745322519913e-05,
      "learning_rate": 3.421783400185128e-06,
      "loss": 0.0,
      "step": 150960
    },
    {
      "epoch": 46.58130206726319,
      "grad_norm": 1.5899306163191795e-05,
      "learning_rate": 3.41869793273681e-06,
      "loss": 0.0,
      "step": 150970
    },
    {
      "epoch": 46.58438753471151,
      "grad_norm": 2.3629670977243222e-05,
      "learning_rate": 3.415612465288491e-06,
      "loss": 0.0,
      "step": 150980
    },
    {
      "epoch": 46.587473002159825,
      "grad_norm": 5.309158979116546e-08,
      "learning_rate": 3.4125269978401728e-06,
      "loss": 0.0,
      "step": 150990
    },
    {
      "epoch": 46.59055846960815,
      "grad_norm": 8.687875947543944e-07,
      "learning_rate": 3.409441530391855e-06,
      "loss": 0.0,
      "step": 151000
    },
    {
      "epoch": 46.59364393705646,
      "grad_norm": 1.810754213238397e-07,
      "learning_rate": 3.406356062943536e-06,
      "loss": 0.0001,
      "step": 151010
    },
    {
      "epoch": 46.596729404504785,
      "grad_norm": 3.1071031116880476e-06,
      "learning_rate": 3.4032705954952176e-06,
      "loss": 0.0,
      "step": 151020
    },
    {
      "epoch": 46.5998148719531,
      "grad_norm": 2.8698004825855605e-06,
      "learning_rate": 3.400185128046899e-06,
      "loss": 0.0,
      "step": 151030
    },
    {
      "epoch": 46.60290033940142,
      "grad_norm": 5.0541178353569194e-08,
      "learning_rate": 3.397099660598581e-06,
      "loss": 0.0,
      "step": 151040
    },
    {
      "epoch": 46.60598580684974,
      "grad_norm": 7.784010449540801e-06,
      "learning_rate": 3.3940141931502625e-06,
      "loss": 0.0,
      "step": 151050
    },
    {
      "epoch": 46.60907127429805,
      "grad_norm": 3.284748117948766e-08,
      "learning_rate": 3.3909287257019437e-06,
      "loss": 0.0,
      "step": 151060
    },
    {
      "epoch": 46.612156741746375,
      "grad_norm": 5.902558086745557e-07,
      "learning_rate": 3.387843258253626e-06,
      "loss": 0.0,
      "step": 151070
    },
    {
      "epoch": 46.61524220919469,
      "grad_norm": 3.893465280532837,
      "learning_rate": 3.384757790805307e-06,
      "loss": 0.0015,
      "step": 151080
    },
    {
      "epoch": 46.61832767664301,
      "grad_norm": 2.6894438676094978e-08,
      "learning_rate": 3.3816723233569886e-06,
      "loss": 0.0,
      "step": 151090
    },
    {
      "epoch": 46.62141314409133,
      "grad_norm": 7.717976018284389e-07,
      "learning_rate": 3.3785868559086707e-06,
      "loss": 0.0,
      "step": 151100
    },
    {
      "epoch": 46.62449861153965,
      "grad_norm": 2.556846993684303e-06,
      "learning_rate": 3.375501388460352e-06,
      "loss": 0.0,
      "step": 151110
    },
    {
      "epoch": 46.627584078987965,
      "grad_norm": 2.5633033828853513e-07,
      "learning_rate": 3.3724159210120335e-06,
      "loss": 0.0,
      "step": 151120
    },
    {
      "epoch": 46.63066954643629,
      "grad_norm": 1.1534232413623613e-07,
      "learning_rate": 3.3693304535637147e-06,
      "loss": 0.0,
      "step": 151130
    },
    {
      "epoch": 46.6337550138846,
      "grad_norm": 0.0010226828744634986,
      "learning_rate": 3.3662449861153968e-06,
      "loss": 0.0,
      "step": 151140
    },
    {
      "epoch": 46.636840481332925,
      "grad_norm": 3.731162360054441e-05,
      "learning_rate": 3.3631595186670784e-06,
      "loss": 0.0,
      "step": 151150
    },
    {
      "epoch": 46.63992594878124,
      "grad_norm": 7.240313948386756e-08,
      "learning_rate": 3.3600740512187596e-06,
      "loss": 0.0,
      "step": 151160
    },
    {
      "epoch": 46.643011416229555,
      "grad_norm": 1.3719316349636301e-08,
      "learning_rate": 3.3569885837704417e-06,
      "loss": 0.0,
      "step": 151170
    },
    {
      "epoch": 46.64609688367788,
      "grad_norm": 2.181015048563495e-07,
      "learning_rate": 3.353903116322123e-06,
      "loss": 0.0,
      "step": 151180
    },
    {
      "epoch": 46.64918235112619,
      "grad_norm": 5.107071956444997e-06,
      "learning_rate": 3.3508176488738045e-06,
      "loss": 0.0,
      "step": 151190
    },
    {
      "epoch": 46.652267818574515,
      "grad_norm": 9.637020411901176e-06,
      "learning_rate": 3.3477321814254866e-06,
      "loss": 0.0,
      "step": 151200
    },
    {
      "epoch": 46.65535328602283,
      "grad_norm": 1.2754616918186912e-08,
      "learning_rate": 3.3446467139771673e-06,
      "loss": 0.0,
      "step": 151210
    },
    {
      "epoch": 46.65843875347115,
      "grad_norm": 4.861434717895463e-06,
      "learning_rate": 3.3415612465288494e-06,
      "loss": 0.0,
      "step": 151220
    },
    {
      "epoch": 46.66152422091947,
      "grad_norm": 4.872428689850494e-06,
      "learning_rate": 3.3384757790805306e-06,
      "loss": 0.0,
      "step": 151230
    },
    {
      "epoch": 46.66460968836779,
      "grad_norm": 5.159370175533695e-07,
      "learning_rate": 3.3353903116322122e-06,
      "loss": 0.0,
      "step": 151240
    },
    {
      "epoch": 46.667695155816105,
      "grad_norm": 5.451533411360288e-07,
      "learning_rate": 3.3323048441838943e-06,
      "loss": 0.0,
      "step": 151250
    },
    {
      "epoch": 46.67078062326443,
      "grad_norm": 1.8846055382937266e-08,
      "learning_rate": 3.3292193767355755e-06,
      "loss": 0.0,
      "step": 151260
    },
    {
      "epoch": 46.67386609071274,
      "grad_norm": 2.936921873697429e-06,
      "learning_rate": 3.326133909287257e-06,
      "loss": 0.0,
      "step": 151270
    },
    {
      "epoch": 46.676951558161065,
      "grad_norm": 4.487588012125343e-05,
      "learning_rate": 3.3230484418389383e-06,
      "loss": 0.0,
      "step": 151280
    },
    {
      "epoch": 46.68003702560938,
      "grad_norm": 1.3341900739760604e-06,
      "learning_rate": 3.3199629743906204e-06,
      "loss": 0.0,
      "step": 151290
    },
    {
      "epoch": 46.683122493057695,
      "grad_norm": 2.6133545816264814e-07,
      "learning_rate": 3.316877506942302e-06,
      "loss": 0.0,
      "step": 151300
    },
    {
      "epoch": 46.68620796050602,
      "grad_norm": 9.203517379319237e-07,
      "learning_rate": 3.3137920394939832e-06,
      "loss": 0.0,
      "step": 151310
    },
    {
      "epoch": 46.68929342795433,
      "grad_norm": 1.0895442756009288e-05,
      "learning_rate": 3.3107065720456653e-06,
      "loss": 0.0,
      "step": 151320
    },
    {
      "epoch": 46.692378895402655,
      "grad_norm": 2.06242329880979e-08,
      "learning_rate": 3.3076211045973465e-06,
      "loss": 0.0,
      "step": 151330
    },
    {
      "epoch": 46.69546436285097,
      "grad_norm": 1.3302779962032218e-06,
      "learning_rate": 3.304535637149028e-06,
      "loss": 0.0,
      "step": 151340
    },
    {
      "epoch": 46.69854983029929,
      "grad_norm": 3.297733928775415e-05,
      "learning_rate": 3.30145016970071e-06,
      "loss": 0.0,
      "step": 151350
    },
    {
      "epoch": 46.70163529774761,
      "grad_norm": 0.00010727888002293184,
      "learning_rate": 3.2983647022523914e-06,
      "loss": 0.0,
      "step": 151360
    },
    {
      "epoch": 46.70472076519593,
      "grad_norm": 0.006930377800017595,
      "learning_rate": 3.295279234804073e-06,
      "loss": 0.0,
      "step": 151370
    },
    {
      "epoch": 46.707806232644245,
      "grad_norm": 5.717959083995083e-06,
      "learning_rate": 3.292193767355754e-06,
      "loss": 0.0,
      "step": 151380
    },
    {
      "epoch": 46.71089170009257,
      "grad_norm": 0.00010949993156827986,
      "learning_rate": 3.2891082999074363e-06,
      "loss": 0.0,
      "step": 151390
    },
    {
      "epoch": 46.71397716754088,
      "grad_norm": 1.4277841131615787e-08,
      "learning_rate": 3.286022832459118e-06,
      "loss": 0.0,
      "step": 151400
    },
    {
      "epoch": 46.7170626349892,
      "grad_norm": 3.0750729251849407e-07,
      "learning_rate": 3.282937365010799e-06,
      "loss": 0.0,
      "step": 151410
    },
    {
      "epoch": 46.72014810243752,
      "grad_norm": 2.849658926606935e-07,
      "learning_rate": 3.279851897562481e-06,
      "loss": 0.0,
      "step": 151420
    },
    {
      "epoch": 46.723233569885835,
      "grad_norm": 4.555491983637694e-08,
      "learning_rate": 3.2767664301141624e-06,
      "loss": 0.0,
      "step": 151430
    },
    {
      "epoch": 46.72631903733416,
      "grad_norm": 1.2604053836184903e-06,
      "learning_rate": 3.273680962665844e-06,
      "loss": 0.0002,
      "step": 151440
    },
    {
      "epoch": 46.72940450478247,
      "grad_norm": 1.072253930090028e-08,
      "learning_rate": 3.270595495217526e-06,
      "loss": 0.0,
      "step": 151450
    },
    {
      "epoch": 46.732489972230795,
      "grad_norm": 9.498697295384773e-07,
      "learning_rate": 3.2675100277692072e-06,
      "loss": 0.0,
      "step": 151460
    },
    {
      "epoch": 46.73557543967911,
      "grad_norm": 0.0063346619717776775,
      "learning_rate": 3.264424560320889e-06,
      "loss": 0.0,
      "step": 151470
    },
    {
      "epoch": 46.73866090712743,
      "grad_norm": 2.1038198383394047e-07,
      "learning_rate": 3.26133909287257e-06,
      "loss": 0.0,
      "step": 151480
    },
    {
      "epoch": 46.74174637457575,
      "grad_norm": 9.44879593589576e-06,
      "learning_rate": 3.258253625424252e-06,
      "loss": 0.0,
      "step": 151490
    },
    {
      "epoch": 46.74483184202407,
      "grad_norm": 8.501348020217847e-06,
      "learning_rate": 3.2551681579759338e-06,
      "loss": 0.0,
      "step": 151500
    },
    {
      "epoch": 46.747917309472385,
      "grad_norm": 5.637664912683249e-08,
      "learning_rate": 3.252082690527615e-06,
      "loss": 0.0,
      "step": 151510
    },
    {
      "epoch": 46.7510027769207,
      "grad_norm": 4.2880355977104045e-07,
      "learning_rate": 3.248997223079297e-06,
      "loss": 0.0,
      "step": 151520
    },
    {
      "epoch": 46.75408824436902,
      "grad_norm": 6.998897816856697e-08,
      "learning_rate": 3.245911755630978e-06,
      "loss": 0.0,
      "step": 151530
    },
    {
      "epoch": 46.75717371181734,
      "grad_norm": 1.7976921299123205e-05,
      "learning_rate": 3.24282628818266e-06,
      "loss": 0.0,
      "step": 151540
    },
    {
      "epoch": 46.76025917926566,
      "grad_norm": 0.0014346232637763023,
      "learning_rate": 3.239740820734342e-06,
      "loss": 0.0,
      "step": 151550
    },
    {
      "epoch": 46.763344646713975,
      "grad_norm": 0.022569740191102028,
      "learning_rate": 3.2366553532860227e-06,
      "loss": 0.0,
      "step": 151560
    },
    {
      "epoch": 46.7664301141623,
      "grad_norm": 0.00029775695293210447,
      "learning_rate": 3.2335698858377048e-06,
      "loss": 0.0,
      "step": 151570
    },
    {
      "epoch": 46.76951558161061,
      "grad_norm": 1.2502638355726958e-06,
      "learning_rate": 3.230484418389386e-06,
      "loss": 0.0,
      "step": 151580
    },
    {
      "epoch": 46.772601049058935,
      "grad_norm": 2.798486207211681e-07,
      "learning_rate": 3.2273989509410676e-06,
      "loss": 0.0,
      "step": 151590
    },
    {
      "epoch": 46.77568651650725,
      "grad_norm": 0.0001328880898654461,
      "learning_rate": 3.2243134834927496e-06,
      "loss": 0.0,
      "step": 151600
    },
    {
      "epoch": 46.77877198395557,
      "grad_norm": 3.465500386656828e-10,
      "learning_rate": 3.221228016044431e-06,
      "loss": 0.0,
      "step": 151610
    },
    {
      "epoch": 46.78185745140389,
      "grad_norm": 0.00011666415957733989,
      "learning_rate": 3.2181425485961125e-06,
      "loss": 0.0,
      "step": 151620
    },
    {
      "epoch": 46.78494291885221,
      "grad_norm": 3.5130131436744705e-05,
      "learning_rate": 3.2150570811477937e-06,
      "loss": 0.0,
      "step": 151630
    },
    {
      "epoch": 46.788028386300525,
      "grad_norm": 1.964514694918762e-06,
      "learning_rate": 3.2119716136994757e-06,
      "loss": 0.0,
      "step": 151640
    },
    {
      "epoch": 46.79111385374884,
      "grad_norm": 1.9262047317170072e-06,
      "learning_rate": 3.2088861462511574e-06,
      "loss": 0.0,
      "step": 151650
    },
    {
      "epoch": 46.79419932119716,
      "grad_norm": 2.1582997078439803e-07,
      "learning_rate": 3.2058006788028386e-06,
      "loss": 0.0,
      "step": 151660
    },
    {
      "epoch": 46.79728478864548,
      "grad_norm": 8.271955266536679e-06,
      "learning_rate": 3.2027152113545206e-06,
      "loss": 0.0,
      "step": 151670
    },
    {
      "epoch": 46.8003702560938,
      "grad_norm": 8.25725328468252e-06,
      "learning_rate": 3.199629743906202e-06,
      "loss": 0.0,
      "step": 151680
    },
    {
      "epoch": 46.803455723542115,
      "grad_norm": 3.476235974630981e-07,
      "learning_rate": 3.1965442764578835e-06,
      "loss": 0.0,
      "step": 151690
    },
    {
      "epoch": 46.80654119099044,
      "grad_norm": 8.727691601961851e-05,
      "learning_rate": 3.1934588090095647e-06,
      "loss": 0.0,
      "step": 151700
    },
    {
      "epoch": 46.80962665843875,
      "grad_norm": 7.833633571863174e-05,
      "learning_rate": 3.1903733415612467e-06,
      "loss": 0.0,
      "step": 151710
    },
    {
      "epoch": 46.812712125887074,
      "grad_norm": 3.0818557661405066e-06,
      "learning_rate": 3.1872878741129284e-06,
      "loss": 0.0,
      "step": 151720
    },
    {
      "epoch": 46.81579759333539,
      "grad_norm": 0.00023390530259348452,
      "learning_rate": 3.1842024066646096e-06,
      "loss": 0.0,
      "step": 151730
    },
    {
      "epoch": 46.81888306078371,
      "grad_norm": 1.9982790036010556e-06,
      "learning_rate": 3.1811169392162916e-06,
      "loss": 0.0,
      "step": 151740
    },
    {
      "epoch": 46.82196852823203,
      "grad_norm": 3.7768216998301796e-07,
      "learning_rate": 3.178031471767973e-06,
      "loss": 0.0,
      "step": 151750
    },
    {
      "epoch": 46.82505399568034,
      "grad_norm": 4.1062354284804314e-05,
      "learning_rate": 3.1749460043196545e-06,
      "loss": 0.0,
      "step": 151760
    },
    {
      "epoch": 46.828139463128664,
      "grad_norm": 0.0003716920327860862,
      "learning_rate": 3.1718605368713365e-06,
      "loss": 0.0,
      "step": 151770
    },
    {
      "epoch": 46.83122493057698,
      "grad_norm": 5.036408310843399e-06,
      "learning_rate": 3.1687750694230177e-06,
      "loss": 0.0,
      "step": 151780
    },
    {
      "epoch": 46.8343103980253,
      "grad_norm": 7.735144080811551e-09,
      "learning_rate": 3.1656896019746993e-06,
      "loss": 0.0,
      "step": 151790
    },
    {
      "epoch": 46.83739586547362,
      "grad_norm": 1.493950740893979e-08,
      "learning_rate": 3.1626041345263805e-06,
      "loss": 0.0,
      "step": 151800
    },
    {
      "epoch": 46.84048133292194,
      "grad_norm": 1.4023348740010988e-05,
      "learning_rate": 3.1595186670780626e-06,
      "loss": 0.0,
      "step": 151810
    },
    {
      "epoch": 46.843566800370255,
      "grad_norm": 3.3281833111686865e-07,
      "learning_rate": 3.1564331996297442e-06,
      "loss": 0.0,
      "step": 151820
    },
    {
      "epoch": 46.84665226781858,
      "grad_norm": 5.425785332136002e-08,
      "learning_rate": 3.1533477321814254e-06,
      "loss": 0.0,
      "step": 151830
    },
    {
      "epoch": 46.84973773526689,
      "grad_norm": 0.00022153372992761433,
      "learning_rate": 3.1502622647331075e-06,
      "loss": 0.0,
      "step": 151840
    },
    {
      "epoch": 46.852823202715214,
      "grad_norm": 1.7022367959640405e-09,
      "learning_rate": 3.1471767972847883e-06,
      "loss": 0.0,
      "step": 151850
    },
    {
      "epoch": 46.85590867016353,
      "grad_norm": 2.9127523504257624e-08,
      "learning_rate": 3.1440913298364703e-06,
      "loss": 0.0,
      "step": 151860
    },
    {
      "epoch": 46.858994137611845,
      "grad_norm": 0.00013271838543005288,
      "learning_rate": 3.1410058623881524e-06,
      "loss": 0.0,
      "step": 151870
    },
    {
      "epoch": 46.86207960506017,
      "grad_norm": 2.804214460638832e-08,
      "learning_rate": 3.137920394939833e-06,
      "loss": 0.0,
      "step": 151880
    },
    {
      "epoch": 46.86516507250848,
      "grad_norm": 2.2205339789138634e-08,
      "learning_rate": 3.1348349274915152e-06,
      "loss": 0.0,
      "step": 151890
    },
    {
      "epoch": 46.868250539956804,
      "grad_norm": 1.8147870983753478e-09,
      "learning_rate": 3.1317494600431964e-06,
      "loss": 0.0,
      "step": 151900
    },
    {
      "epoch": 46.87133600740512,
      "grad_norm": 4.118247943551978e-06,
      "learning_rate": 3.128663992594878e-06,
      "loss": 0.0,
      "step": 151910
    },
    {
      "epoch": 46.87442147485344,
      "grad_norm": 7.864356120990124e-06,
      "learning_rate": 3.12557852514656e-06,
      "loss": 0.0,
      "step": 151920
    },
    {
      "epoch": 46.87750694230176,
      "grad_norm": 1.1292337148915976e-05,
      "learning_rate": 3.1224930576982413e-06,
      "loss": 0.0,
      "step": 151930
    },
    {
      "epoch": 46.88059240975008,
      "grad_norm": 4.53359134553466e-05,
      "learning_rate": 3.119407590249923e-06,
      "loss": 0.0,
      "step": 151940
    },
    {
      "epoch": 46.883677877198394,
      "grad_norm": 4.924470076161924e-08,
      "learning_rate": 3.1163221228016046e-06,
      "loss": 0.0,
      "step": 151950
    },
    {
      "epoch": 46.88676334464672,
      "grad_norm": 5.78801627852954e-05,
      "learning_rate": 3.113236655353286e-06,
      "loss": 0.0,
      "step": 151960
    },
    {
      "epoch": 46.88984881209503,
      "grad_norm": 1.514288101134298e-06,
      "learning_rate": 3.110151187904968e-06,
      "loss": 0.0,
      "step": 151970
    },
    {
      "epoch": 46.892934279543354,
      "grad_norm": 4.1085232993509635e-09,
      "learning_rate": 3.107065720456649e-06,
      "loss": 0.0,
      "step": 151980
    },
    {
      "epoch": 46.89601974699167,
      "grad_norm": 4.2638124142513334e-08,
      "learning_rate": 3.103980253008331e-06,
      "loss": 0.0,
      "step": 151990
    },
    {
      "epoch": 46.899105214439984,
      "grad_norm": 3.069573358516209e-05,
      "learning_rate": 3.1008947855600127e-06,
      "loss": 0.0,
      "step": 152000
    },
    {
      "epoch": 46.90219068188831,
      "grad_norm": 2.287344068463426e-05,
      "learning_rate": 3.097809318111694e-06,
      "loss": 0.0,
      "step": 152010
    },
    {
      "epoch": 46.90527614933662,
      "grad_norm": 4.4222264738991157e-10,
      "learning_rate": 3.0947238506633756e-06,
      "loss": 0.0,
      "step": 152020
    },
    {
      "epoch": 46.908361616784944,
      "grad_norm": 1.507628688557361e-08,
      "learning_rate": 3.091638383215057e-06,
      "loss": 0.0,
      "step": 152030
    },
    {
      "epoch": 46.91144708423326,
      "grad_norm": 4.9375780690752435e-06,
      "learning_rate": 3.088552915766739e-06,
      "loss": 0.0,
      "step": 152040
    },
    {
      "epoch": 46.91453255168158,
      "grad_norm": 5.139567747391993e-06,
      "learning_rate": 3.0854674483184205e-06,
      "loss": 0.0,
      "step": 152050
    },
    {
      "epoch": 46.9176180191299,
      "grad_norm": 3.418321648496203e-05,
      "learning_rate": 3.082381980870102e-06,
      "loss": 0.0,
      "step": 152060
    },
    {
      "epoch": 46.92070348657822,
      "grad_norm": 2.6934716856885643e-07,
      "learning_rate": 3.0792965134217833e-06,
      "loss": 0.0,
      "step": 152070
    },
    {
      "epoch": 46.923788954026534,
      "grad_norm": 1.1870806559954872e-09,
      "learning_rate": 3.076211045973465e-06,
      "loss": 0.0,
      "step": 152080
    },
    {
      "epoch": 46.92687442147486,
      "grad_norm": 5.622865865007043e-05,
      "learning_rate": 3.073125578525147e-06,
      "loss": 0.0,
      "step": 152090
    },
    {
      "epoch": 46.92995988892317,
      "grad_norm": 9.501886779617053e-07,
      "learning_rate": 3.070040111076828e-06,
      "loss": 0.0,
      "step": 152100
    },
    {
      "epoch": 46.93304535637149,
      "grad_norm": 1.6487164202771964e-06,
      "learning_rate": 3.06695464362851e-06,
      "loss": 0.0,
      "step": 152110
    },
    {
      "epoch": 46.93613082381981,
      "grad_norm": 6.579679165952257e-07,
      "learning_rate": 3.0638691761801914e-06,
      "loss": 0.0,
      "step": 152120
    },
    {
      "epoch": 46.939216291268124,
      "grad_norm": 1.5916491975076497e-05,
      "learning_rate": 3.060783708731873e-06,
      "loss": 0.0,
      "step": 152130
    },
    {
      "epoch": 46.94230175871645,
      "grad_norm": 0.0001099441506084986,
      "learning_rate": 3.0576982412835547e-06,
      "loss": 0.0,
      "step": 152140
    },
    {
      "epoch": 46.94538722616476,
      "grad_norm": 1.7140790120606653e-08,
      "learning_rate": 3.0546127738352363e-06,
      "loss": 0.0,
      "step": 152150
    },
    {
      "epoch": 46.948472693613084,
      "grad_norm": 2.0856836258076328e-08,
      "learning_rate": 3.051527306386918e-06,
      "loss": 0.0,
      "step": 152160
    },
    {
      "epoch": 46.9515581610614,
      "grad_norm": 7.337604074564297e-06,
      "learning_rate": 3.048441838938599e-06,
      "loss": 0.0,
      "step": 152170
    },
    {
      "epoch": 46.95464362850972,
      "grad_norm": 9.504223271505907e-05,
      "learning_rate": 3.045356371490281e-06,
      "loss": 0.0,
      "step": 152180
    },
    {
      "epoch": 46.95772909595804,
      "grad_norm": 1.0619012755341828e-05,
      "learning_rate": 3.042270904041963e-06,
      "loss": 0.0,
      "step": 152190
    },
    {
      "epoch": 46.96081456340636,
      "grad_norm": 1.6762784937895958e-08,
      "learning_rate": 3.039185436593644e-06,
      "loss": 0.0,
      "step": 152200
    },
    {
      "epoch": 46.963900030854674,
      "grad_norm": 3.601462879032624e-07,
      "learning_rate": 3.0360999691453257e-06,
      "loss": 0.0,
      "step": 152210
    },
    {
      "epoch": 46.96698549830299,
      "grad_norm": 6.551528741738366e-08,
      "learning_rate": 3.0330145016970073e-06,
      "loss": 0.0,
      "step": 152220
    },
    {
      "epoch": 46.97007096575131,
      "grad_norm": 7.69548691437194e-08,
      "learning_rate": 3.0299290342486885e-06,
      "loss": 0.0,
      "step": 152230
    },
    {
      "epoch": 46.97315643319963,
      "grad_norm": 4.064781023771502e-06,
      "learning_rate": 3.0268435668003706e-06,
      "loss": 0.0,
      "step": 152240
    },
    {
      "epoch": 46.97624190064795,
      "grad_norm": 2.764136013411189e-07,
      "learning_rate": 3.023758099352052e-06,
      "loss": 0.0,
      "step": 152250
    },
    {
      "epoch": 46.979327368096264,
      "grad_norm": 2.0838197656303237e-07,
      "learning_rate": 3.0206726319037334e-06,
      "loss": 0.0,
      "step": 152260
    },
    {
      "epoch": 46.98241283554459,
      "grad_norm": 7.357844424404902e-06,
      "learning_rate": 3.017587164455415e-06,
      "loss": 0.0,
      "step": 152270
    },
    {
      "epoch": 46.9854983029929,
      "grad_norm": 3.473328433756251e-06,
      "learning_rate": 3.0145016970070967e-06,
      "loss": 0.0,
      "step": 152280
    },
    {
      "epoch": 46.988583770441224,
      "grad_norm": 3.2304833439411595e-05,
      "learning_rate": 3.0114162295587783e-06,
      "loss": 0.0,
      "step": 152290
    },
    {
      "epoch": 46.99166923788954,
      "grad_norm": 3.149798288859529e-08,
      "learning_rate": 3.00833076211046e-06,
      "loss": 0.0,
      "step": 152300
    },
    {
      "epoch": 46.99475470533786,
      "grad_norm": 4.819699370273156e-06,
      "learning_rate": 3.0052452946621416e-06,
      "loss": 0.0,
      "step": 152310
    },
    {
      "epoch": 46.99784017278618,
      "grad_norm": 2.3898221002127684e-07,
      "learning_rate": 3.002159827213823e-06,
      "loss": 0.0,
      "step": 152320
    },
    {
      "epoch": 47.0,
      "eval_accuracy_branch1": 1.0,
      "eval_accuracy_branch2": 0.42080186722992197,
      "eval_f1_branch1": 1.0,
      "eval_f1_branch2": 0.41591900307657637,
      "eval_loss": 7.257033729501927e-08,
      "eval_precision_branch1": 1.0,
      "eval_precision_branch2": 0.5093177515044381,
      "eval_recall_branch1": 1.0,
      "eval_recall_branch2": 0.5076893029715576,
      "eval_runtime": 132.2987,
      "eval_samples_per_second": 783.704,
      "eval_steps_per_second": 97.968,
      "step": 152327
    },
    {
      "epoch": 47.0009256402345,
      "grad_norm": 2.89416823839872e-09,
      "learning_rate": 2.9990743597655044e-06,
      "loss": 0.0,
      "step": 152330
    },
    {
      "epoch": 47.004011107682814,
      "grad_norm": 3.47254058397084e-06,
      "learning_rate": 2.995988892317186e-06,
      "loss": 0.0,
      "step": 152340
    },
    {
      "epoch": 47.00709657513113,
      "grad_norm": 5.1292833092020373e-08,
      "learning_rate": 2.992903424868868e-06,
      "loss": 0.0,
      "step": 152350
    },
    {
      "epoch": 47.01018204257945,
      "grad_norm": 2.5653953628079762e-08,
      "learning_rate": 2.9898179574205493e-06,
      "loss": 0.0,
      "step": 152360
    },
    {
      "epoch": 47.01326751002777,
      "grad_norm": 4.216958132019499e-06,
      "learning_rate": 2.986732489972231e-06,
      "loss": 0.0,
      "step": 152370
    },
    {
      "epoch": 47.01635297747609,
      "grad_norm": 7.368118337680585e-10,
      "learning_rate": 2.9836470225239125e-06,
      "loss": 0.0,
      "step": 152380
    },
    {
      "epoch": 47.019438444924404,
      "grad_norm": 2.2709177756041754e-06,
      "learning_rate": 2.9805615550755938e-06,
      "loss": 0.0,
      "step": 152390
    },
    {
      "epoch": 47.022523912372726,
      "grad_norm": 3.85195761509749e-07,
      "learning_rate": 2.977476087627276e-06,
      "loss": 0.0,
      "step": 152400
    },
    {
      "epoch": 47.02560937982104,
      "grad_norm": 2.4547554858145304e-05,
      "learning_rate": 2.9743906201789574e-06,
      "loss": 0.0,
      "step": 152410
    },
    {
      "epoch": 47.028694847269364,
      "grad_norm": 1.7021448002196848e-06,
      "learning_rate": 2.9713051527306386e-06,
      "loss": 0.0,
      "step": 152420
    },
    {
      "epoch": 47.03178031471768,
      "grad_norm": 2.0603420125553384e-05,
      "learning_rate": 2.9682196852823203e-06,
      "loss": 0.0,
      "step": 152430
    },
    {
      "epoch": 47.034865782166,
      "grad_norm": 6.236547989146857e-08,
      "learning_rate": 2.965134217834002e-06,
      "loss": 0.0,
      "step": 152440
    },
    {
      "epoch": 47.037951249614316,
      "grad_norm": 5.693947059626225e-06,
      "learning_rate": 2.9620487503856835e-06,
      "loss": 0.0,
      "step": 152450
    },
    {
      "epoch": 47.04103671706263,
      "grad_norm": 3.131102494080551e-05,
      "learning_rate": 2.958963282937365e-06,
      "loss": 0.0,
      "step": 152460
    },
    {
      "epoch": 47.044122184510954,
      "grad_norm": 2.0288773328047682e-08,
      "learning_rate": 2.955877815489047e-06,
      "loss": 0.0,
      "step": 152470
    },
    {
      "epoch": 47.04720765195927,
      "grad_norm": 2.5853660190477967e-06,
      "learning_rate": 2.9527923480407284e-06,
      "loss": 0.0,
      "step": 152480
    },
    {
      "epoch": 47.05029311940759,
      "grad_norm": 2.5738557951626717e-08,
      "learning_rate": 2.9497068805924096e-06,
      "loss": 0.0016,
      "step": 152490
    },
    {
      "epoch": 47.05337858685591,
      "grad_norm": 7.492816962439974e-07,
      "learning_rate": 2.9466214131440917e-06,
      "loss": 0.0,
      "step": 152500
    },
    {
      "epoch": 47.05646405430423,
      "grad_norm": 5.863438218511874e-06,
      "learning_rate": 2.9435359456957733e-06,
      "loss": 0.0,
      "step": 152510
    },
    {
      "epoch": 47.059549521752544,
      "grad_norm": 2.619748329379945e-08,
      "learning_rate": 2.9404504782474545e-06,
      "loss": 0.0,
      "step": 152520
    },
    {
      "epoch": 47.062634989200866,
      "grad_norm": 1.5490061455736281e-09,
      "learning_rate": 2.937365010799136e-06,
      "loss": 0.0,
      "step": 152530
    },
    {
      "epoch": 47.06572045664918,
      "grad_norm": 7.793921099619183e-07,
      "learning_rate": 2.9342795433508178e-06,
      "loss": 0.0,
      "step": 152540
    },
    {
      "epoch": 47.068805924097504,
      "grad_norm": 4.282621830498101e-06,
      "learning_rate": 2.9311940759024994e-06,
      "loss": 0.0,
      "step": 152550
    },
    {
      "epoch": 47.07189139154582,
      "grad_norm": 1.3365447557589505e-06,
      "learning_rate": 2.928108608454181e-06,
      "loss": 0.0,
      "step": 152560
    },
    {
      "epoch": 47.07497685899414,
      "grad_norm": 4.011593773611821e-05,
      "learning_rate": 2.9250231410058627e-06,
      "loss": 0.0,
      "step": 152570
    },
    {
      "epoch": 47.078062326442456,
      "grad_norm": 5.45197735846159e-07,
      "learning_rate": 2.921937673557544e-06,
      "loss": 0.0,
      "step": 152580
    },
    {
      "epoch": 47.08114779389077,
      "grad_norm": 3.7797351524204714e-06,
      "learning_rate": 2.9188522061092255e-06,
      "loss": 0.0,
      "step": 152590
    },
    {
      "epoch": 47.084233261339094,
      "grad_norm": 1.3131579180480912e-05,
      "learning_rate": 2.9157667386609076e-06,
      "loss": 0.0,
      "step": 152600
    },
    {
      "epoch": 47.08731872878741,
      "grad_norm": 6.842348284408217e-06,
      "learning_rate": 2.9126812712125888e-06,
      "loss": 0.0,
      "step": 152610
    },
    {
      "epoch": 47.09040419623573,
      "grad_norm": 0.0010213927598670125,
      "learning_rate": 2.9095958037642704e-06,
      "loss": 0.0,
      "step": 152620
    },
    {
      "epoch": 47.093489663684046,
      "grad_norm": 2.127730294887442e-05,
      "learning_rate": 2.906510336315952e-06,
      "loss": 0.0,
      "step": 152630
    },
    {
      "epoch": 47.09657513113237,
      "grad_norm": 3.677768134480175e-08,
      "learning_rate": 2.9034248688676337e-06,
      "loss": 0.0001,
      "step": 152640
    },
    {
      "epoch": 47.099660598580684,
      "grad_norm": 0.00012963735207449645,
      "learning_rate": 2.9003394014193153e-06,
      "loss": 0.0,
      "step": 152650
    },
    {
      "epoch": 47.102746066029006,
      "grad_norm": 1.5477752413062262e-08,
      "learning_rate": 2.897253933970997e-06,
      "loss": 0.0,
      "step": 152660
    },
    {
      "epoch": 47.10583153347732,
      "grad_norm": 2.0887933715130202e-05,
      "learning_rate": 2.8941684665226785e-06,
      "loss": 0.0,
      "step": 152670
    },
    {
      "epoch": 47.10891700092564,
      "grad_norm": 3.0159259267747984e-07,
      "learning_rate": 2.8910829990743597e-06,
      "loss": 0.0,
      "step": 152680
    },
    {
      "epoch": 47.11200246837396,
      "grad_norm": 7.513123456703852e-09,
      "learning_rate": 2.8879975316260414e-06,
      "loss": 0.0,
      "step": 152690
    },
    {
      "epoch": 47.115087935822274,
      "grad_norm": 7.520220606238581e-07,
      "learning_rate": 2.8849120641777234e-06,
      "loss": 0.0,
      "step": 152700
    },
    {
      "epoch": 47.118173403270596,
      "grad_norm": 1.1991307928838069e-06,
      "learning_rate": 2.8818265967294046e-06,
      "loss": 0.0,
      "step": 152710
    },
    {
      "epoch": 47.12125887071891,
      "grad_norm": 1.742121980896627e-06,
      "learning_rate": 2.8787411292810863e-06,
      "loss": 0.0,
      "step": 152720
    },
    {
      "epoch": 47.124344338167234,
      "grad_norm": 0.013694137334823608,
      "learning_rate": 2.875655661832768e-06,
      "loss": 0.0,
      "step": 152730
    },
    {
      "epoch": 47.12742980561555,
      "grad_norm": 4.331002045887544e-08,
      "learning_rate": 2.872570194384449e-06,
      "loss": 0.0,
      "step": 152740
    },
    {
      "epoch": 47.13051527306387,
      "grad_norm": 7.113612355169607e-06,
      "learning_rate": 2.8694847269361307e-06,
      "loss": 0.0,
      "step": 152750
    },
    {
      "epoch": 47.133600740512186,
      "grad_norm": 0.02302473597228527,
      "learning_rate": 2.866399259487813e-06,
      "loss": 0.0,
      "step": 152760
    },
    {
      "epoch": 47.13668620796051,
      "grad_norm": 7.164653084146266e-07,
      "learning_rate": 2.863313792039494e-06,
      "loss": 0.0,
      "step": 152770
    },
    {
      "epoch": 47.139771675408824,
      "grad_norm": 0.00032896269112825394,
      "learning_rate": 2.8602283245911756e-06,
      "loss": 0.0,
      "step": 152780
    },
    {
      "epoch": 47.142857142857146,
      "grad_norm": 5.034651985624805e-05,
      "learning_rate": 2.8571428571428573e-06,
      "loss": 0.0,
      "step": 152790
    },
    {
      "epoch": 47.14594261030546,
      "grad_norm": 4.051812663163901e-09,
      "learning_rate": 2.854057389694539e-06,
      "loss": 0.0,
      "step": 152800
    },
    {
      "epoch": 47.149028077753776,
      "grad_norm": 2.1618828949243607e-10,
      "learning_rate": 2.8509719222462205e-06,
      "loss": 0.0,
      "step": 152810
    },
    {
      "epoch": 47.1521135452021,
      "grad_norm": 8.107748072916365e-08,
      "learning_rate": 2.847886454797902e-06,
      "loss": 0.0,
      "step": 152820
    },
    {
      "epoch": 47.155199012650414,
      "grad_norm": 4.1941436990100556e-08,
      "learning_rate": 2.8448009873495838e-06,
      "loss": 0.0,
      "step": 152830
    },
    {
      "epoch": 47.158284480098736,
      "grad_norm": 4.059727700678195e-07,
      "learning_rate": 2.841715519901265e-06,
      "loss": 0.0,
      "step": 152840
    },
    {
      "epoch": 47.16136994754705,
      "grad_norm": 8.853124455754369e-09,
      "learning_rate": 2.8386300524529466e-06,
      "loss": 0.0,
      "step": 152850
    },
    {
      "epoch": 47.16445541499537,
      "grad_norm": 1.8689694115892053e-05,
      "learning_rate": 2.8355445850046287e-06,
      "loss": 0.0,
      "step": 152860
    },
    {
      "epoch": 47.16754088244369,
      "grad_norm": 4.697641031725652e-08,
      "learning_rate": 2.83245911755631e-06,
      "loss": 0.0,
      "step": 152870
    },
    {
      "epoch": 47.17062634989201,
      "grad_norm": 2.7254654924036004e-06,
      "learning_rate": 2.8293736501079915e-06,
      "loss": 0.0,
      "step": 152880
    },
    {
      "epoch": 47.173711817340326,
      "grad_norm": 3.640870360754889e-08,
      "learning_rate": 2.826288182659673e-06,
      "loss": 0.0001,
      "step": 152890
    },
    {
      "epoch": 47.17679728478865,
      "grad_norm": 3.773286152863875e-06,
      "learning_rate": 2.8232027152113543e-06,
      "loss": 0.0,
      "step": 152900
    },
    {
      "epoch": 47.17988275223696,
      "grad_norm": 1.160782812803518e-05,
      "learning_rate": 2.8201172477630364e-06,
      "loss": 0.0,
      "step": 152910
    },
    {
      "epoch": 47.182968219685286,
      "grad_norm": 1.3621652215078939e-06,
      "learning_rate": 2.817031780314718e-06,
      "loss": 0.0,
      "step": 152920
    },
    {
      "epoch": 47.1860536871336,
      "grad_norm": 1.4025118616700638e-05,
      "learning_rate": 2.8139463128663992e-06,
      "loss": 0.0,
      "step": 152930
    },
    {
      "epoch": 47.189139154581916,
      "grad_norm": 1.0896922049141722e-06,
      "learning_rate": 2.810860845418081e-06,
      "loss": 0.0008,
      "step": 152940
    },
    {
      "epoch": 47.19222462203024,
      "grad_norm": 7.989483856363222e-05,
      "learning_rate": 2.8077753779697625e-06,
      "loss": 0.0,
      "step": 152950
    },
    {
      "epoch": 47.19531008947855,
      "grad_norm": 6.100830773902999e-08,
      "learning_rate": 2.804689910521444e-06,
      "loss": 0.0,
      "step": 152960
    },
    {
      "epoch": 47.198395556926876,
      "grad_norm": 3.404732069611782e-07,
      "learning_rate": 2.8016044430731257e-06,
      "loss": 0.0,
      "step": 152970
    },
    {
      "epoch": 47.20148102437519,
      "grad_norm": 1.8057952502203989e-06,
      "learning_rate": 2.7985189756248074e-06,
      "loss": 0.0,
      "step": 152980
    },
    {
      "epoch": 47.20456649182351,
      "grad_norm": 3.256423497077776e-06,
      "learning_rate": 2.795433508176489e-06,
      "loss": 0.0,
      "step": 152990
    },
    {
      "epoch": 47.20765195927183,
      "grad_norm": 3.6564262728688846e-08,
      "learning_rate": 2.7923480407281702e-06,
      "loss": 0.0,
      "step": 153000
    },
    {
      "epoch": 47.21073742672015,
      "grad_norm": 3.845012997771846e-06,
      "learning_rate": 2.7892625732798523e-06,
      "loss": 0.0,
      "step": 153010
    },
    {
      "epoch": 47.213822894168466,
      "grad_norm": 1.4163567357172724e-05,
      "learning_rate": 2.786177105831534e-06,
      "loss": 0.0,
      "step": 153020
    },
    {
      "epoch": 47.21690836161679,
      "grad_norm": 4.6405008724548225e-09,
      "learning_rate": 2.783091638383215e-06,
      "loss": 0.0,
      "step": 153030
    },
    {
      "epoch": 47.2199938290651,
      "grad_norm": 8.317502420140954e-07,
      "learning_rate": 2.7800061709348967e-06,
      "loss": 0.0,
      "step": 153040
    },
    {
      "epoch": 47.22307929651342,
      "grad_norm": 4.1167645576933865e-06,
      "learning_rate": 2.7769207034865784e-06,
      "loss": 0.0,
      "step": 153050
    },
    {
      "epoch": 47.22616476396174,
      "grad_norm": 3.058336915273685e-06,
      "learning_rate": 2.77383523603826e-06,
      "loss": 0.0,
      "step": 153060
    },
    {
      "epoch": 47.229250231410056,
      "grad_norm": 1.7200249203597195e-05,
      "learning_rate": 2.7707497685899416e-06,
      "loss": 0.0,
      "step": 153070
    },
    {
      "epoch": 47.23233569885838,
      "grad_norm": 6.091854629630689e-07,
      "learning_rate": 2.7676643011416233e-06,
      "loss": 0.0,
      "step": 153080
    },
    {
      "epoch": 47.23542116630669,
      "grad_norm": 6.369547236317885e-07,
      "learning_rate": 2.7645788336933045e-06,
      "loss": 0.0,
      "step": 153090
    },
    {
      "epoch": 47.238506633755016,
      "grad_norm": 2.964548457384808e-06,
      "learning_rate": 2.761493366244986e-06,
      "loss": 0.0,
      "step": 153100
    },
    {
      "epoch": 47.24159210120333,
      "grad_norm": 9.441500736784292e-08,
      "learning_rate": 2.758407898796668e-06,
      "loss": 0.0,
      "step": 153110
    },
    {
      "epoch": 47.24467756865165,
      "grad_norm": 3.9843525883043185e-05,
      "learning_rate": 2.7553224313483493e-06,
      "loss": 0.0,
      "step": 153120
    },
    {
      "epoch": 47.24776303609997,
      "grad_norm": 4.303653611259506e-07,
      "learning_rate": 2.752236963900031e-06,
      "loss": 0.0,
      "step": 153130
    },
    {
      "epoch": 47.25084850354829,
      "grad_norm": 1.0622477475408232e-06,
      "learning_rate": 2.7491514964517126e-06,
      "loss": 0.0,
      "step": 153140
    },
    {
      "epoch": 47.253933970996606,
      "grad_norm": 5.6350486374867614e-06,
      "learning_rate": 2.7460660290033942e-06,
      "loss": 0.0,
      "step": 153150
    },
    {
      "epoch": 47.25701943844492,
      "grad_norm": 7.069455136843317e-07,
      "learning_rate": 2.7429805615550754e-06,
      "loss": 0.0,
      "step": 153160
    },
    {
      "epoch": 47.26010490589324,
      "grad_norm": 3.962083638953118e-08,
      "learning_rate": 2.7398950941067575e-06,
      "loss": 0.0,
      "step": 153170
    },
    {
      "epoch": 47.26319037334156,
      "grad_norm": 8.579823770560324e-06,
      "learning_rate": 2.736809626658439e-06,
      "loss": 0.0,
      "step": 153180
    },
    {
      "epoch": 47.26627584078988,
      "grad_norm": 2.527028186705138e-07,
      "learning_rate": 2.7337241592101203e-06,
      "loss": 0.0,
      "step": 153190
    },
    {
      "epoch": 47.269361308238196,
      "grad_norm": 0.01204456016421318,
      "learning_rate": 2.730638691761802e-06,
      "loss": 0.0,
      "step": 153200
    },
    {
      "epoch": 47.27244677568652,
      "grad_norm": 1.7142970136774238e-06,
      "learning_rate": 2.7275532243134836e-06,
      "loss": 0.0,
      "step": 153210
    },
    {
      "epoch": 47.27553224313483,
      "grad_norm": 3.4440790841472335e-07,
      "learning_rate": 2.7244677568651652e-06,
      "loss": 0.0,
      "step": 153220
    },
    {
      "epoch": 47.278617710583156,
      "grad_norm": 8.856396505052544e-09,
      "learning_rate": 2.721382289416847e-06,
      "loss": 0.0,
      "step": 153230
    },
    {
      "epoch": 47.28170317803147,
      "grad_norm": 3.231657075275507e-08,
      "learning_rate": 2.7182968219685285e-06,
      "loss": 0.0,
      "step": 153240
    },
    {
      "epoch": 47.28478864547979,
      "grad_norm": 7.426603588100988e-06,
      "learning_rate": 2.7152113545202097e-06,
      "loss": 0.0,
      "step": 153250
    },
    {
      "epoch": 47.28787411292811,
      "grad_norm": 4.2852013848460047e-07,
      "learning_rate": 2.7121258870718913e-06,
      "loss": 0.0,
      "step": 153260
    },
    {
      "epoch": 47.29095958037643,
      "grad_norm": 0.02880207821726799,
      "learning_rate": 2.7090404196235734e-06,
      "loss": 0.0,
      "step": 153270
    },
    {
      "epoch": 47.294045047824746,
      "grad_norm": 4.387242370285094e-06,
      "learning_rate": 2.7059549521752546e-06,
      "loss": 0.0,
      "step": 153280
    },
    {
      "epoch": 47.29713051527306,
      "grad_norm": 1.0098788472134856e-08,
      "learning_rate": 2.7028694847269362e-06,
      "loss": 0.0,
      "step": 153290
    },
    {
      "epoch": 47.30021598272138,
      "grad_norm": 0.00027662108186632395,
      "learning_rate": 2.699784017278618e-06,
      "loss": 0.0,
      "step": 153300
    },
    {
      "epoch": 47.3033014501697,
      "grad_norm": 3.0229007279558573e-06,
      "learning_rate": 2.6966985498302995e-06,
      "loss": 0.0,
      "step": 153310
    },
    {
      "epoch": 47.30638691761802,
      "grad_norm": 0.00013717019464820623,
      "learning_rate": 2.693613082381981e-06,
      "loss": 0.0,
      "step": 153320
    },
    {
      "epoch": 47.309472385066336,
      "grad_norm": 3.4901799494946317e-07,
      "learning_rate": 2.6905276149336627e-06,
      "loss": 0.0,
      "step": 153330
    },
    {
      "epoch": 47.31255785251466,
      "grad_norm": 2.415640096842253e-07,
      "learning_rate": 2.6874421474853444e-06,
      "loss": 0.0,
      "step": 153340
    },
    {
      "epoch": 47.31564331996297,
      "grad_norm": 2.2243875719141215e-06,
      "learning_rate": 2.6843566800370256e-06,
      "loss": 0.0,
      "step": 153350
    },
    {
      "epoch": 47.318728787411295,
      "grad_norm": 1.7147119280025436e-09,
      "learning_rate": 2.681271212588707e-06,
      "loss": 0.0,
      "step": 153360
    },
    {
      "epoch": 47.32181425485961,
      "grad_norm": 2.088273504341487e-05,
      "learning_rate": 2.6781857451403893e-06,
      "loss": 0.0,
      "step": 153370
    },
    {
      "epoch": 47.32489972230793,
      "grad_norm": 2.1565167429571375e-09,
      "learning_rate": 2.6751002776920705e-06,
      "loss": 0.0,
      "step": 153380
    },
    {
      "epoch": 47.32798518975625,
      "grad_norm": 3.3742194318620022e-06,
      "learning_rate": 2.672014810243752e-06,
      "loss": 0.0,
      "step": 153390
    },
    {
      "epoch": 47.33107065720456,
      "grad_norm": 3.3788307973736664e-07,
      "learning_rate": 2.6689293427954337e-06,
      "loss": 0.0,
      "step": 153400
    },
    {
      "epoch": 47.334156124652885,
      "grad_norm": 1.9616975350800203e-06,
      "learning_rate": 2.665843875347115e-06,
      "loss": 0.0,
      "step": 153410
    },
    {
      "epoch": 47.3372415921012,
      "grad_norm": 8.934634365687089e-07,
      "learning_rate": 2.662758407898797e-06,
      "loss": 0.0001,
      "step": 153420
    },
    {
      "epoch": 47.34032705954952,
      "grad_norm": 8.445440471405163e-06,
      "learning_rate": 2.6596729404504786e-06,
      "loss": 0.0,
      "step": 153430
    },
    {
      "epoch": 47.34341252699784,
      "grad_norm": 8.210145097109489e-06,
      "learning_rate": 2.65658747300216e-06,
      "loss": 0.0,
      "step": 153440
    },
    {
      "epoch": 47.34649799444616,
      "grad_norm": 6.703399169083468e-09,
      "learning_rate": 2.6535020055538414e-06,
      "loss": 0.0,
      "step": 153450
    },
    {
      "epoch": 47.349583461894476,
      "grad_norm": 1.3713573707718751e-06,
      "learning_rate": 2.650416538105523e-06,
      "loss": 0.0,
      "step": 153460
    },
    {
      "epoch": 47.3526689293428,
      "grad_norm": 3.843030754069332e-06,
      "learning_rate": 2.6473310706572047e-06,
      "loss": 0.0,
      "step": 153470
    },
    {
      "epoch": 47.35575439679111,
      "grad_norm": 6.6785624142085e-08,
      "learning_rate": 2.6442456032088863e-06,
      "loss": 0.0,
      "step": 153480
    },
    {
      "epoch": 47.358839864239435,
      "grad_norm": 2.947925281659991e-07,
      "learning_rate": 2.641160135760568e-06,
      "loss": 0.0,
      "step": 153490
    },
    {
      "epoch": 47.36192533168775,
      "grad_norm": 1.8252788436257106e-07,
      "learning_rate": 2.6380746683122496e-06,
      "loss": 0.0,
      "step": 153500
    },
    {
      "epoch": 47.365010799136066,
      "grad_norm": 7.138629734981805e-05,
      "learning_rate": 2.634989200863931e-06,
      "loss": 0.0,
      "step": 153510
    },
    {
      "epoch": 47.36809626658439,
      "grad_norm": 1.1438372666816576e-06,
      "learning_rate": 2.631903733415613e-06,
      "loss": 0.0,
      "step": 153520
    },
    {
      "epoch": 47.3711817340327,
      "grad_norm": 1.7714341993269045e-08,
      "learning_rate": 2.6288182659672945e-06,
      "loss": 0.0,
      "step": 153530
    },
    {
      "epoch": 47.374267201481025,
      "grad_norm": 5.061229603597894e-05,
      "learning_rate": 2.6257327985189757e-06,
      "loss": 0.0,
      "step": 153540
    },
    {
      "epoch": 47.37735266892934,
      "grad_norm": 3.078406734857708e-05,
      "learning_rate": 2.6226473310706573e-06,
      "loss": 0.0,
      "step": 153550
    },
    {
      "epoch": 47.38043813637766,
      "grad_norm": 7.882006798354269e-07,
      "learning_rate": 2.619561863622339e-06,
      "loss": 0.0,
      "step": 153560
    },
    {
      "epoch": 47.38352360382598,
      "grad_norm": 3.855942409813906e-08,
      "learning_rate": 2.61647639617402e-06,
      "loss": 0.0,
      "step": 153570
    },
    {
      "epoch": 47.3866090712743,
      "grad_norm": 2.3525720038719555e-08,
      "learning_rate": 2.613390928725702e-06,
      "loss": 0.0,
      "step": 153580
    },
    {
      "epoch": 47.389694538722615,
      "grad_norm": 1.4164661479298957e-05,
      "learning_rate": 2.610305461277384e-06,
      "loss": 0.0,
      "step": 153590
    },
    {
      "epoch": 47.39278000617094,
      "grad_norm": 1.6407695966336178e-06,
      "learning_rate": 2.607219993829065e-06,
      "loss": 0.0,
      "step": 153600
    },
    {
      "epoch": 47.39586547361925,
      "grad_norm": 4.4858999899588525e-05,
      "learning_rate": 2.6041345263807467e-06,
      "loss": 0.0,
      "step": 153610
    },
    {
      "epoch": 47.398950941067575,
      "grad_norm": 5.196870347390359e-07,
      "learning_rate": 2.6010490589324283e-06,
      "loss": 0.0,
      "step": 153620
    },
    {
      "epoch": 47.40203640851589,
      "grad_norm": 3.713143570394095e-08,
      "learning_rate": 2.59796359148411e-06,
      "loss": 0.0,
      "step": 153630
    },
    {
      "epoch": 47.405121875964205,
      "grad_norm": 2.3586871344960514e-10,
      "learning_rate": 2.5948781240357916e-06,
      "loss": 0.0,
      "step": 153640
    },
    {
      "epoch": 47.40820734341253,
      "grad_norm": 3.266266276114038e-06,
      "learning_rate": 2.591792656587473e-06,
      "loss": 0.0,
      "step": 153650
    },
    {
      "epoch": 47.41129281086084,
      "grad_norm": 1.3612374338833888e-08,
      "learning_rate": 2.588707189139155e-06,
      "loss": 0.0,
      "step": 153660
    },
    {
      "epoch": 47.414378278309165,
      "grad_norm": 1.663032556109556e-08,
      "learning_rate": 2.585621721690836e-06,
      "loss": 0.0,
      "step": 153670
    },
    {
      "epoch": 47.41746374575748,
      "grad_norm": 4.282894594531683e-10,
      "learning_rate": 2.582536254242518e-06,
      "loss": 0.0,
      "step": 153680
    },
    {
      "epoch": 47.4205492132058,
      "grad_norm": 1.0373225904913852e-06,
      "learning_rate": 2.5794507867941997e-06,
      "loss": 0.0,
      "step": 153690
    },
    {
      "epoch": 47.42363468065412,
      "grad_norm": 2.3713598693575477e-06,
      "learning_rate": 2.576365319345881e-06,
      "loss": 0.0,
      "step": 153700
    },
    {
      "epoch": 47.42672014810244,
      "grad_norm": 5.331933152774582e-07,
      "learning_rate": 2.5732798518975626e-06,
      "loss": 0.0,
      "step": 153710
    },
    {
      "epoch": 47.429805615550755,
      "grad_norm": 3.2534572369513626e-07,
      "learning_rate": 2.570194384449244e-06,
      "loss": 0.0,
      "step": 153720
    },
    {
      "epoch": 47.43289108299908,
      "grad_norm": 1.8660200851172704e-07,
      "learning_rate": 2.567108917000926e-06,
      "loss": 0.0002,
      "step": 153730
    },
    {
      "epoch": 47.43597655044739,
      "grad_norm": 2.1152507656552189e-07,
      "learning_rate": 2.5640234495526074e-06,
      "loss": 0.0,
      "step": 153740
    },
    {
      "epoch": 47.43906201789571,
      "grad_norm": 3.0658435434816056e-07,
      "learning_rate": 2.560937982104289e-06,
      "loss": 0.0,
      "step": 153750
    },
    {
      "epoch": 47.44214748534403,
      "grad_norm": 3.5974556666928947e-09,
      "learning_rate": 2.5578525146559703e-06,
      "loss": 0.0,
      "step": 153760
    },
    {
      "epoch": 47.445232952792345,
      "grad_norm": 8.726296073291451e-05,
      "learning_rate": 2.554767047207652e-06,
      "loss": 0.0,
      "step": 153770
    },
    {
      "epoch": 47.44831842024067,
      "grad_norm": 0.000867549329996109,
      "learning_rate": 2.551681579759334e-06,
      "loss": 0.0,
      "step": 153780
    },
    {
      "epoch": 47.45140388768898,
      "grad_norm": 2.18596966305995e-07,
      "learning_rate": 2.548596112311015e-06,
      "loss": 0.0,
      "step": 153790
    },
    {
      "epoch": 47.454489355137305,
      "grad_norm": 6.177995146572357e-07,
      "learning_rate": 2.545510644862697e-06,
      "loss": 0.0,
      "step": 153800
    },
    {
      "epoch": 47.45757482258562,
      "grad_norm": 2.5607572752051055e-05,
      "learning_rate": 2.5424251774143784e-06,
      "loss": 0.0,
      "step": 153810
    },
    {
      "epoch": 47.46066029003394,
      "grad_norm": 3.209622718713945e-07,
      "learning_rate": 2.53933970996606e-06,
      "loss": 0.0,
      "step": 153820
    },
    {
      "epoch": 47.46374575748226,
      "grad_norm": 1.3586915770247288e-07,
      "learning_rate": 2.5362542425177417e-06,
      "loss": 0.0,
      "step": 153830
    },
    {
      "epoch": 47.46683122493058,
      "grad_norm": 1.7609764313419873e-07,
      "learning_rate": 2.5331687750694233e-06,
      "loss": 0.0,
      "step": 153840
    },
    {
      "epoch": 47.469916692378895,
      "grad_norm": 0.0010124946711584926,
      "learning_rate": 2.530083307621105e-06,
      "loss": 0.0,
      "step": 153850
    },
    {
      "epoch": 47.47300215982722,
      "grad_norm": 0.00030031261849217117,
      "learning_rate": 2.526997840172786e-06,
      "loss": 0.0,
      "step": 153860
    },
    {
      "epoch": 47.47608762727553,
      "grad_norm": 2.8113699954701588e-05,
      "learning_rate": 2.5239123727244678e-06,
      "loss": 0.0,
      "step": 153870
    },
    {
      "epoch": 47.47917309472385,
      "grad_norm": 3.132606707367813e-08,
      "learning_rate": 2.5208269052761494e-06,
      "loss": 0.0,
      "step": 153880
    },
    {
      "epoch": 47.48225856217217,
      "grad_norm": 5.08937000631704e-06,
      "learning_rate": 2.517741437827831e-06,
      "loss": 0.0,
      "step": 153890
    },
    {
      "epoch": 47.485344029620485,
      "grad_norm": 0.0003333095519337803,
      "learning_rate": 2.5146559703795127e-06,
      "loss": 0.0,
      "step": 153900
    },
    {
      "epoch": 47.48842949706881,
      "grad_norm": 6.135940111562377e-07,
      "learning_rate": 2.5115705029311943e-06,
      "loss": 0.0,
      "step": 153910
    },
    {
      "epoch": 47.49151496451712,
      "grad_norm": 1.1428901416365989e-06,
      "learning_rate": 2.5084850354828755e-06,
      "loss": 0.0001,
      "step": 153920
    },
    {
      "epoch": 47.494600431965445,
      "grad_norm": 1.8550806998973712e-05,
      "learning_rate": 2.5053995680345576e-06,
      "loss": 0.0,
      "step": 153930
    },
    {
      "epoch": 47.49768589941376,
      "grad_norm": 4.0175902427108667e-07,
      "learning_rate": 2.502314100586239e-06,
      "loss": 0.0,
      "step": 153940
    },
    {
      "epoch": 47.50077136686208,
      "grad_norm": 0.00012926170893479139,
      "learning_rate": 2.4992286331379204e-06,
      "loss": 0.0,
      "step": 153950
    },
    {
      "epoch": 47.5038568343104,
      "grad_norm": 4.842327783194378e-08,
      "learning_rate": 2.496143165689602e-06,
      "loss": 0.0,
      "step": 153960
    },
    {
      "epoch": 47.50694230175872,
      "grad_norm": 0.005314279813319445,
      "learning_rate": 2.4930576982412837e-06,
      "loss": 0.0,
      "step": 153970
    },
    {
      "epoch": 47.510027769207035,
      "grad_norm": 5.745937059487005e-08,
      "learning_rate": 2.4899722307929653e-06,
      "loss": 0.0,
      "step": 153980
    },
    {
      "epoch": 47.51311323665535,
      "grad_norm": 3.610552766986075e-06,
      "learning_rate": 2.486886763344647e-06,
      "loss": 0.0,
      "step": 153990
    },
    {
      "epoch": 47.51619870410367,
      "grad_norm": 6.023500418450567e-07,
      "learning_rate": 2.4838012958963285e-06,
      "loss": 0.0,
      "step": 154000
    },
    {
      "epoch": 47.51928417155199,
      "grad_norm": 0.006178244482725859,
      "learning_rate": 2.4807158284480098e-06,
      "loss": 0.0,
      "step": 154010
    },
    {
      "epoch": 47.52236963900031,
      "grad_norm": 5.6191449402831495e-05,
      "learning_rate": 2.4776303609996914e-06,
      "loss": 0.0,
      "step": 154020
    },
    {
      "epoch": 47.525455106448625,
      "grad_norm": 2.318410281532124e-07,
      "learning_rate": 2.474544893551373e-06,
      "loss": 0.0,
      "step": 154030
    },
    {
      "epoch": 47.52854057389695,
      "grad_norm": 1.3742185728915501e-05,
      "learning_rate": 2.4714594261030546e-06,
      "loss": 0.0,
      "step": 154040
    },
    {
      "epoch": 47.53162604134526,
      "grad_norm": 5.198609898116047e-08,
      "learning_rate": 2.4683739586547363e-06,
      "loss": 0.0,
      "step": 154050
    },
    {
      "epoch": 47.534711508793585,
      "grad_norm": 1.5937956732159364e-08,
      "learning_rate": 2.465288491206418e-06,
      "loss": 0.0,
      "step": 154060
    },
    {
      "epoch": 47.5377969762419,
      "grad_norm": 1.1339151569700334e-05,
      "learning_rate": 2.4622030237580995e-06,
      "loss": 0.0,
      "step": 154070
    },
    {
      "epoch": 47.54088244369022,
      "grad_norm": 9.493573998042848e-07,
      "learning_rate": 2.4591175563097807e-06,
      "loss": 0.0,
      "step": 154080
    },
    {
      "epoch": 47.54396791113854,
      "grad_norm": 1.169251754618017e-05,
      "learning_rate": 2.456032088861463e-06,
      "loss": 0.0,
      "step": 154090
    },
    {
      "epoch": 47.54705337858685,
      "grad_norm": 8.573571903980337e-06,
      "learning_rate": 2.4529466214131444e-06,
      "loss": 0.0,
      "step": 154100
    },
    {
      "epoch": 47.550138846035175,
      "grad_norm": 0.00020955406944267452,
      "learning_rate": 2.4498611539648256e-06,
      "loss": 0.0,
      "step": 154110
    },
    {
      "epoch": 47.55322431348349,
      "grad_norm": 5.475129728438333e-05,
      "learning_rate": 2.4467756865165073e-06,
      "loss": 0.0,
      "step": 154120
    },
    {
      "epoch": 47.55630978093181,
      "grad_norm": 3.2640273275319487e-06,
      "learning_rate": 2.443690219068189e-06,
      "loss": 0.0,
      "step": 154130
    },
    {
      "epoch": 47.55939524838013,
      "grad_norm": 2.5984971330217377e-07,
      "learning_rate": 2.4406047516198705e-06,
      "loss": 0.0,
      "step": 154140
    },
    {
      "epoch": 47.56248071582845,
      "grad_norm": 1.330658108145144e-07,
      "learning_rate": 2.437519284171552e-06,
      "loss": 0.0,
      "step": 154150
    },
    {
      "epoch": 47.565566183276765,
      "grad_norm": 6.488184681074927e-06,
      "learning_rate": 2.4344338167232338e-06,
      "loss": 0.0,
      "step": 154160
    },
    {
      "epoch": 47.56865165072509,
      "grad_norm": 3.770291812088544e-07,
      "learning_rate": 2.431348349274915e-06,
      "loss": 0.0,
      "step": 154170
    },
    {
      "epoch": 47.5717371181734,
      "grad_norm": 2.2388846332432877e-07,
      "learning_rate": 2.4282628818265966e-06,
      "loss": 0.0,
      "step": 154180
    },
    {
      "epoch": 47.574822585621725,
      "grad_norm": 5.8741687098518014e-05,
      "learning_rate": 2.4251774143782787e-06,
      "loss": 0.0,
      "step": 154190
    },
    {
      "epoch": 47.57790805307004,
      "grad_norm": 1.39466499149421e-06,
      "learning_rate": 2.42209194692996e-06,
      "loss": 0.0,
      "step": 154200
    },
    {
      "epoch": 47.58099352051836,
      "grad_norm": 5.493204753292957e-06,
      "learning_rate": 2.4190064794816415e-06,
      "loss": 0.0,
      "step": 154210
    },
    {
      "epoch": 47.58407898796668,
      "grad_norm": 6.572353595402092e-05,
      "learning_rate": 2.415921012033323e-06,
      "loss": 0.0,
      "step": 154220
    },
    {
      "epoch": 47.58716445541499,
      "grad_norm": 3.376240420038812e-05,
      "learning_rate": 2.4128355445850048e-06,
      "loss": 0.0,
      "step": 154230
    },
    {
      "epoch": 47.590249922863315,
      "grad_norm": 5.882962796022184e-06,
      "learning_rate": 2.4097500771366864e-06,
      "loss": 0.0,
      "step": 154240
    },
    {
      "epoch": 47.59333539031163,
      "grad_norm": 1.6994106033507705e-07,
      "learning_rate": 2.406664609688368e-06,
      "loss": 0.0,
      "step": 154250
    },
    {
      "epoch": 47.59642085775995,
      "grad_norm": 5.294860105919952e-09,
      "learning_rate": 2.4035791422400497e-06,
      "loss": 0.0,
      "step": 154260
    },
    {
      "epoch": 47.59950632520827,
      "grad_norm": 6.376581586664543e-05,
      "learning_rate": 2.400493674791731e-06,
      "loss": 0.0,
      "step": 154270
    },
    {
      "epoch": 47.60259179265659,
      "grad_norm": 2.674945376313076e-09,
      "learning_rate": 2.3974082073434125e-06,
      "loss": 0.0,
      "step": 154280
    },
    {
      "epoch": 47.605677260104905,
      "grad_norm": 4.4790530751015467e-07,
      "learning_rate": 2.3943227398950945e-06,
      "loss": 0.0,
      "step": 154290
    },
    {
      "epoch": 47.60876272755323,
      "grad_norm": 0.0008769227424636483,
      "learning_rate": 2.3912372724467758e-06,
      "loss": 0.0,
      "step": 154300
    },
    {
      "epoch": 47.61184819500154,
      "grad_norm": 0.04623137041926384,
      "learning_rate": 2.3881518049984574e-06,
      "loss": 0.0,
      "step": 154310
    },
    {
      "epoch": 47.614933662449864,
      "grad_norm": 4.79728878417518e-05,
      "learning_rate": 2.385066337550139e-06,
      "loss": 0.0,
      "step": 154320
    },
    {
      "epoch": 47.61801912989818,
      "grad_norm": 5.245941792964004e-05,
      "learning_rate": 2.3819808701018202e-06,
      "loss": 0.0,
      "step": 154330
    },
    {
      "epoch": 47.621104597346495,
      "grad_norm": 1.0907167791174288e-07,
      "learning_rate": 2.3788954026535023e-06,
      "loss": 0.0,
      "step": 154340
    },
    {
      "epoch": 47.62419006479482,
      "grad_norm": 1.0618845408316702e-05,
      "learning_rate": 2.375809935205184e-06,
      "loss": 0.0,
      "step": 154350
    },
    {
      "epoch": 47.62727553224313,
      "grad_norm": 2.481623129213517e-09,
      "learning_rate": 2.372724467756865e-06,
      "loss": 0.0,
      "step": 154360
    },
    {
      "epoch": 47.630360999691455,
      "grad_norm": 5.8787118177860975e-05,
      "learning_rate": 2.3696390003085467e-06,
      "loss": 0.0,
      "step": 154370
    },
    {
      "epoch": 47.63344646713977,
      "grad_norm": 0.00015703160897828639,
      "learning_rate": 2.3665535328602284e-06,
      "loss": 0.0,
      "step": 154380
    },
    {
      "epoch": 47.63653193458809,
      "grad_norm": 1.0156799135074834e-06,
      "learning_rate": 2.36346806541191e-06,
      "loss": 0.0,
      "step": 154390
    },
    {
      "epoch": 47.63961740203641,
      "grad_norm": 4.573032583721215e-07,
      "learning_rate": 2.3603825979635916e-06,
      "loss": 0.0,
      "step": 154400
    },
    {
      "epoch": 47.64270286948473,
      "grad_norm": 6.616099653911078e-06,
      "learning_rate": 2.3572971305152733e-06,
      "loss": 0.0,
      "step": 154410
    },
    {
      "epoch": 47.645788336933045,
      "grad_norm": 6.529564871016191e-07,
      "learning_rate": 2.354211663066955e-06,
      "loss": 0.0,
      "step": 154420
    },
    {
      "epoch": 47.64887380438137,
      "grad_norm": 1.5100368733200753e-09,
      "learning_rate": 2.351126195618636e-06,
      "loss": 0.0,
      "step": 154430
    },
    {
      "epoch": 47.65195927182968,
      "grad_norm": 5.85818213494349e-07,
      "learning_rate": 2.3480407281703177e-06,
      "loss": 0.0,
      "step": 154440
    },
    {
      "epoch": 47.655044739278,
      "grad_norm": 1.3099844764496993e-08,
      "learning_rate": 2.3449552607219998e-06,
      "loss": 0.0,
      "step": 154450
    },
    {
      "epoch": 47.65813020672632,
      "grad_norm": 0.01995559222996235,
      "learning_rate": 2.341869793273681e-06,
      "loss": 0.0,
      "step": 154460
    },
    {
      "epoch": 47.661215674174635,
      "grad_norm": 1.1736593918953986e-08,
      "learning_rate": 2.3387843258253626e-06,
      "loss": 0.0,
      "step": 154470
    },
    {
      "epoch": 47.66430114162296,
      "grad_norm": 3.669110583359725e-06,
      "learning_rate": 2.3356988583770442e-06,
      "loss": 0.0,
      "step": 154480
    },
    {
      "epoch": 47.66738660907127,
      "grad_norm": 1.6112667253764812e-06,
      "learning_rate": 2.3326133909287255e-06,
      "loss": 0.0,
      "step": 154490
    },
    {
      "epoch": 47.670472076519594,
      "grad_norm": 9.22082326724194e-05,
      "learning_rate": 2.3295279234804075e-06,
      "loss": 0.0,
      "step": 154500
    },
    {
      "epoch": 47.67355754396791,
      "grad_norm": 5.152582360778979e-09,
      "learning_rate": 2.326442456032089e-06,
      "loss": 0.0,
      "step": 154510
    },
    {
      "epoch": 47.67664301141623,
      "grad_norm": 1.0452607966726646e-05,
      "learning_rate": 2.3233569885837703e-06,
      "loss": 0.0,
      "step": 154520
    },
    {
      "epoch": 47.67972847886455,
      "grad_norm": 1.9657980374176987e-05,
      "learning_rate": 2.320271521135452e-06,
      "loss": 0.0,
      "step": 154530
    },
    {
      "epoch": 47.68281394631287,
      "grad_norm": 2.803597567435645e-07,
      "learning_rate": 2.3171860536871336e-06,
      "loss": 0.0,
      "step": 154540
    },
    {
      "epoch": 47.685899413761184,
      "grad_norm": 2.1001480490667745e-05,
      "learning_rate": 2.3141005862388152e-06,
      "loss": 0.0,
      "step": 154550
    },
    {
      "epoch": 47.68898488120951,
      "grad_norm": 2.2639817132130702e-08,
      "learning_rate": 2.311015118790497e-06,
      "loss": 0.0,
      "step": 154560
    },
    {
      "epoch": 47.69207034865782,
      "grad_norm": 6.703147664666176e-05,
      "learning_rate": 2.3079296513421785e-06,
      "loss": 0.0,
      "step": 154570
    },
    {
      "epoch": 47.69515581610614,
      "grad_norm": 2.2111036741989665e-05,
      "learning_rate": 2.30484418389386e-06,
      "loss": 0.0,
      "step": 154580
    },
    {
      "epoch": 47.69824128355446,
      "grad_norm": 3.087947120228307e-10,
      "learning_rate": 2.3017587164455413e-06,
      "loss": 0.0,
      "step": 154590
    },
    {
      "epoch": 47.701326751002775,
      "grad_norm": 6.128557288320735e-05,
      "learning_rate": 2.2986732489972234e-06,
      "loss": 0.0,
      "step": 154600
    },
    {
      "epoch": 47.7044122184511,
      "grad_norm": 3.1786917542575566e-10,
      "learning_rate": 2.295587781548905e-06,
      "loss": 0.0,
      "step": 154610
    },
    {
      "epoch": 47.70749768589941,
      "grad_norm": 4.728839121526107e-05,
      "learning_rate": 2.2925023141005862e-06,
      "loss": 0.0,
      "step": 154620
    },
    {
      "epoch": 47.710583153347734,
      "grad_norm": 7.944224478251272e-08,
      "learning_rate": 2.289416846652268e-06,
      "loss": 0.0,
      "step": 154630
    },
    {
      "epoch": 47.71366862079605,
      "grad_norm": 1.4305848026197054e-06,
      "learning_rate": 2.2863313792039495e-06,
      "loss": 0.0,
      "step": 154640
    },
    {
      "epoch": 47.71675408824437,
      "grad_norm": 6.744693905602617e-07,
      "learning_rate": 2.283245911755631e-06,
      "loss": 0.0,
      "step": 154650
    },
    {
      "epoch": 47.71983955569269,
      "grad_norm": 6.252611456147861e-06,
      "learning_rate": 2.2801604443073127e-06,
      "loss": 0.0,
      "step": 154660
    },
    {
      "epoch": 47.72292502314101,
      "grad_norm": 3.145259341863493e-08,
      "learning_rate": 2.2770749768589944e-06,
      "loss": 0.0,
      "step": 154670
    },
    {
      "epoch": 47.726010490589324,
      "grad_norm": 6.177497198223136e-06,
      "learning_rate": 2.2739895094106756e-06,
      "loss": 0.0,
      "step": 154680
    },
    {
      "epoch": 47.72909595803764,
      "grad_norm": 1.8099713997798972e-05,
      "learning_rate": 2.270904041962357e-06,
      "loss": 0.0,
      "step": 154690
    },
    {
      "epoch": 47.73218142548596,
      "grad_norm": 1.6066048829088686e-06,
      "learning_rate": 2.2678185745140393e-06,
      "loss": 0.0,
      "step": 154700
    },
    {
      "epoch": 47.73526689293428,
      "grad_norm": 9.837463585427031e-05,
      "learning_rate": 2.2647331070657205e-06,
      "loss": 0.0,
      "step": 154710
    },
    {
      "epoch": 47.7383523603826,
      "grad_norm": 1.3032339438723284e-06,
      "learning_rate": 2.261647639617402e-06,
      "loss": 0.0,
      "step": 154720
    },
    {
      "epoch": 47.741437827830914,
      "grad_norm": 8.709436770004686e-06,
      "learning_rate": 2.2585621721690837e-06,
      "loss": 0.0,
      "step": 154730
    },
    {
      "epoch": 47.74452329527924,
      "grad_norm": 2.9248923283375916e-07,
      "learning_rate": 2.2554767047207654e-06,
      "loss": 0.0,
      "step": 154740
    },
    {
      "epoch": 47.74760876272755,
      "grad_norm": 4.654708334328461e-07,
      "learning_rate": 2.252391237272447e-06,
      "loss": 0.0,
      "step": 154750
    },
    {
      "epoch": 47.750694230175874,
      "grad_norm": 5.298732048686361e-07,
      "learning_rate": 2.2493057698241286e-06,
      "loss": 0.0,
      "step": 154760
    },
    {
      "epoch": 47.75377969762419,
      "grad_norm": 0.0004776851856149733,
      "learning_rate": 2.2462203023758102e-06,
      "loss": 0.0,
      "step": 154770
    },
    {
      "epoch": 47.75686516507251,
      "grad_norm": 5.862722929350639e-08,
      "learning_rate": 2.2431348349274915e-06,
      "loss": 0.0,
      "step": 154780
    },
    {
      "epoch": 47.75995063252083,
      "grad_norm": 1.6304576320180786e-06,
      "learning_rate": 2.240049367479173e-06,
      "loss": 0.0,
      "step": 154790
    },
    {
      "epoch": 47.76303609996914,
      "grad_norm": 1.9273045836598612e-05,
      "learning_rate": 2.2369639000308547e-06,
      "loss": 0.0,
      "step": 154800
    },
    {
      "epoch": 47.766121567417464,
      "grad_norm": 7.296979731563624e-08,
      "learning_rate": 2.2338784325825363e-06,
      "loss": 0.0,
      "step": 154810
    },
    {
      "epoch": 47.76920703486578,
      "grad_norm": 2.5773308152565733e-05,
      "learning_rate": 2.230792965134218e-06,
      "loss": 0.0,
      "step": 154820
    },
    {
      "epoch": 47.7722925023141,
      "grad_norm": 8.786180387687637e-07,
      "learning_rate": 2.2277074976858996e-06,
      "loss": 0.0,
      "step": 154830
    },
    {
      "epoch": 47.77537796976242,
      "grad_norm": 9.071994213627477e-07,
      "learning_rate": 2.224622030237581e-06,
      "loss": 0.0,
      "step": 154840
    },
    {
      "epoch": 47.77846343721074,
      "grad_norm": 4.1574548959033564e-05,
      "learning_rate": 2.2215365627892624e-06,
      "loss": 0.0,
      "step": 154850
    },
    {
      "epoch": 47.781548904659054,
      "grad_norm": 0.0001944422983797267,
      "learning_rate": 2.2184510953409445e-06,
      "loss": 0.0,
      "step": 154860
    },
    {
      "epoch": 47.78463437210738,
      "grad_norm": 4.6273606130853295e-05,
      "learning_rate": 2.2153656278926257e-06,
      "loss": 0.0,
      "step": 154870
    },
    {
      "epoch": 47.78771983955569,
      "grad_norm": 1.6987836204407358e-07,
      "learning_rate": 2.2122801604443073e-06,
      "loss": 0.0,
      "step": 154880
    },
    {
      "epoch": 47.790805307004014,
      "grad_norm": 8.124525629682466e-05,
      "learning_rate": 2.209194692995989e-06,
      "loss": 0.0,
      "step": 154890
    },
    {
      "epoch": 47.79389077445233,
      "grad_norm": 7.518465849898348e-07,
      "learning_rate": 2.2061092255476706e-06,
      "loss": 0.0,
      "step": 154900
    },
    {
      "epoch": 47.79697624190065,
      "grad_norm": 6.066202207222204e-09,
      "learning_rate": 2.2030237580993522e-06,
      "loss": 0.0,
      "step": 154910
    },
    {
      "epoch": 47.80006170934897,
      "grad_norm": 1.8744443650575704e-06,
      "learning_rate": 2.199938290651034e-06,
      "loss": 0.0,
      "step": 154920
    },
    {
      "epoch": 47.80314717679728,
      "grad_norm": 3.470152023510309e-07,
      "learning_rate": 2.1968528232027155e-06,
      "loss": 0.0,
      "step": 154930
    },
    {
      "epoch": 47.806232644245604,
      "grad_norm": 0.0012866377364844084,
      "learning_rate": 2.1937673557543967e-06,
      "loss": 0.0,
      "step": 154940
    },
    {
      "epoch": 47.80931811169392,
      "grad_norm": 3.550054259449098e-07,
      "learning_rate": 2.1906818883060783e-06,
      "loss": 0.0,
      "step": 154950
    },
    {
      "epoch": 47.81240357914224,
      "grad_norm": 9.107540790864732e-06,
      "learning_rate": 2.1875964208577604e-06,
      "loss": 0.0,
      "step": 154960
    },
    {
      "epoch": 47.81548904659056,
      "grad_norm": 9.475595419417004e-09,
      "learning_rate": 2.1845109534094416e-06,
      "loss": 0.0,
      "step": 154970
    },
    {
      "epoch": 47.81857451403888,
      "grad_norm": 4.597928082716862e-08,
      "learning_rate": 2.181425485961123e-06,
      "loss": 0.0,
      "step": 154980
    },
    {
      "epoch": 47.821659981487194,
      "grad_norm": 4.265836253125599e-07,
      "learning_rate": 2.178340018512805e-06,
      "loss": 0.0,
      "step": 154990
    },
    {
      "epoch": 47.824745448935516,
      "grad_norm": 3.3014694622579555e-07,
      "learning_rate": 2.175254551064486e-06,
      "loss": 0.0,
      "step": 155000
    },
    {
      "epoch": 47.82783091638383,
      "grad_norm": 3.579947360776714e-07,
      "learning_rate": 2.172169083616168e-06,
      "loss": 0.0,
      "step": 155010
    },
    {
      "epoch": 47.830916383832154,
      "grad_norm": 6.642395078415575e-08,
      "learning_rate": 2.1690836161678497e-06,
      "loss": 0.0,
      "step": 155020
    },
    {
      "epoch": 47.83400185128047,
      "grad_norm": 7.320954864553642e-07,
      "learning_rate": 2.165998148719531e-06,
      "loss": 0.0,
      "step": 155030
    },
    {
      "epoch": 47.837087318728784,
      "grad_norm": 8.666321264172439e-06,
      "learning_rate": 2.1629126812712126e-06,
      "loss": 0.0,
      "step": 155040
    },
    {
      "epoch": 47.840172786177106,
      "grad_norm": 3.510929218464298e-07,
      "learning_rate": 2.159827213822894e-06,
      "loss": 0.0,
      "step": 155050
    },
    {
      "epoch": 47.84325825362542,
      "grad_norm": 4.3122475035239916e-10,
      "learning_rate": 2.156741746374576e-06,
      "loss": 0.0,
      "step": 155060
    },
    {
      "epoch": 47.846343721073744,
      "grad_norm": 0.001234745024703443,
      "learning_rate": 2.1536562789262574e-06,
      "loss": 0.0,
      "step": 155070
    },
    {
      "epoch": 47.84942918852206,
      "grad_norm": 2.2116419806650356e-09,
      "learning_rate": 2.150570811477939e-06,
      "loss": 0.0,
      "step": 155080
    },
    {
      "epoch": 47.85251465597038,
      "grad_norm": 4.1988307202700526e-05,
      "learning_rate": 2.1474853440296207e-06,
      "loss": 0.0,
      "step": 155090
    },
    {
      "epoch": 47.8556001234187,
      "grad_norm": 1.6743905151272998e-09,
      "learning_rate": 2.144399876581302e-06,
      "loss": 0.0,
      "step": 155100
    },
    {
      "epoch": 47.85868559086702,
      "grad_norm": 1.0786613529489841e-05,
      "learning_rate": 2.141314409132984e-06,
      "loss": 0.0,
      "step": 155110
    },
    {
      "epoch": 47.861771058315334,
      "grad_norm": 2.259437906104722e-06,
      "learning_rate": 2.1382289416846656e-06,
      "loss": 0.0,
      "step": 155120
    },
    {
      "epoch": 47.864856525763656,
      "grad_norm": 4.041426564072026e-06,
      "learning_rate": 2.135143474236347e-06,
      "loss": 0.0,
      "step": 155130
    },
    {
      "epoch": 47.86794199321197,
      "grad_norm": 2.887618393287994e-05,
      "learning_rate": 2.1320580067880284e-06,
      "loss": 0.0,
      "step": 155140
    },
    {
      "epoch": 47.87102746066029,
      "grad_norm": 3.751739896529216e-08,
      "learning_rate": 2.12897253933971e-06,
      "loss": 0.0,
      "step": 155150
    },
    {
      "epoch": 47.87411292810861,
      "grad_norm": 1.6245589318231168e-09,
      "learning_rate": 2.1258870718913917e-06,
      "loss": 0.0,
      "step": 155160
    },
    {
      "epoch": 47.877198395556924,
      "grad_norm": 5.64873175790126e-07,
      "learning_rate": 2.1228016044430733e-06,
      "loss": 0.0,
      "step": 155170
    },
    {
      "epoch": 47.880283863005246,
      "grad_norm": 1.992566012631869e-06,
      "learning_rate": 2.119716136994755e-06,
      "loss": 0.0,
      "step": 155180
    },
    {
      "epoch": 47.88336933045356,
      "grad_norm": 7.20582775670664e-08,
      "learning_rate": 2.116630669546436e-06,
      "loss": 0.0,
      "step": 155190
    },
    {
      "epoch": 47.886454797901884,
      "grad_norm": 1.4537699932759551e-08,
      "learning_rate": 2.113545202098118e-06,
      "loss": 0.0,
      "step": 155200
    },
    {
      "epoch": 47.8895402653502,
      "grad_norm": 1.2785486092070641e-07,
      "learning_rate": 2.1104597346497994e-06,
      "loss": 0.0,
      "step": 155210
    },
    {
      "epoch": 47.89262573279852,
      "grad_norm": 2.46891562749596e-10,
      "learning_rate": 2.107374267201481e-06,
      "loss": 0.0,
      "step": 155220
    },
    {
      "epoch": 47.895711200246836,
      "grad_norm": 6.499067950471726e-08,
      "learning_rate": 2.1042887997531627e-06,
      "loss": 0.0002,
      "step": 155230
    },
    {
      "epoch": 47.89879666769516,
      "grad_norm": 6.1205250858620275e-06,
      "learning_rate": 2.1012033323048443e-06,
      "loss": 0.0,
      "step": 155240
    },
    {
      "epoch": 47.901882135143474,
      "grad_norm": 9.1534229085255e-09,
      "learning_rate": 2.098117864856526e-06,
      "loss": 0.0,
      "step": 155250
    },
    {
      "epoch": 47.904967602591796,
      "grad_norm": 5.440194854600122e-06,
      "learning_rate": 2.095032397408207e-06,
      "loss": 0.0,
      "step": 155260
    },
    {
      "epoch": 47.90805307004011,
      "grad_norm": 1.450033981775789e-10,
      "learning_rate": 2.091946929959889e-06,
      "loss": 0.0,
      "step": 155270
    },
    {
      "epoch": 47.911138537488426,
      "grad_norm": 1.1864614862133749e-05,
      "learning_rate": 2.088861462511571e-06,
      "loss": 0.0,
      "step": 155280
    },
    {
      "epoch": 47.91422400493675,
      "grad_norm": 6.649420924986771e-07,
      "learning_rate": 2.085775995063252e-06,
      "loss": 0.0,
      "step": 155290
    },
    {
      "epoch": 47.917309472385064,
      "grad_norm": 3.846355411951663e-08,
      "learning_rate": 2.0826905276149337e-06,
      "loss": 0.0,
      "step": 155300
    },
    {
      "epoch": 47.920394939833386,
      "grad_norm": 1.7147124609095954e-08,
      "learning_rate": 2.0796050601666153e-06,
      "loss": 0.0,
      "step": 155310
    },
    {
      "epoch": 47.9234804072817,
      "grad_norm": 0.0018927538767457008,
      "learning_rate": 2.076519592718297e-06,
      "loss": 0.0,
      "step": 155320
    },
    {
      "epoch": 47.926565874730024,
      "grad_norm": 3.845814262604108e-06,
      "learning_rate": 2.0734341252699786e-06,
      "loss": 0.0,
      "step": 155330
    },
    {
      "epoch": 47.92965134217834,
      "grad_norm": 1.8710319693582278e-07,
      "learning_rate": 2.07034865782166e-06,
      "loss": 0.0,
      "step": 155340
    },
    {
      "epoch": 47.93273680962666,
      "grad_norm": 3.0842641081108013e-06,
      "learning_rate": 2.0672631903733414e-06,
      "loss": 0.0,
      "step": 155350
    },
    {
      "epoch": 47.935822277074976,
      "grad_norm": 1.2592310838499543e-07,
      "learning_rate": 2.064177722925023e-06,
      "loss": 0.0,
      "step": 155360
    },
    {
      "epoch": 47.9389077445233,
      "grad_norm": 2.592653913779941e-08,
      "learning_rate": 2.061092255476705e-06,
      "loss": 0.0,
      "step": 155370
    },
    {
      "epoch": 47.941993211971614,
      "grad_norm": 1.2257993375897058e-06,
      "learning_rate": 2.0580067880283863e-06,
      "loss": 0.0,
      "step": 155380
    },
    {
      "epoch": 47.94507867941993,
      "grad_norm": 0.00016045087249949574,
      "learning_rate": 2.054921320580068e-06,
      "loss": 0.0,
      "step": 155390
    },
    {
      "epoch": 47.94816414686825,
      "grad_norm": 2.5912632040103745e-09,
      "learning_rate": 2.0518358531317495e-06,
      "loss": 0.0,
      "step": 155400
    },
    {
      "epoch": 47.951249614316566,
      "grad_norm": 0.001589856343343854,
      "learning_rate": 2.048750385683431e-06,
      "loss": 0.0,
      "step": 155410
    },
    {
      "epoch": 47.95433508176489,
      "grad_norm": 1.8502537386666518e-06,
      "learning_rate": 2.045664918235113e-06,
      "loss": 0.0,
      "step": 155420
    },
    {
      "epoch": 47.957420549213204,
      "grad_norm": 7.02315317013813e-09,
      "learning_rate": 2.0425794507867944e-06,
      "loss": 0.0,
      "step": 155430
    },
    {
      "epoch": 47.960506016661526,
      "grad_norm": 9.798853852771572e-07,
      "learning_rate": 2.039493983338476e-06,
      "loss": 0.0,
      "step": 155440
    },
    {
      "epoch": 47.96359148410984,
      "grad_norm": 9.558686997479526e-07,
      "learning_rate": 2.0364085158901573e-06,
      "loss": 0.0,
      "step": 155450
    },
    {
      "epoch": 47.96667695155816,
      "grad_norm": 0.00036144672776572406,
      "learning_rate": 2.033323048441839e-06,
      "loss": 0.0,
      "step": 155460
    },
    {
      "epoch": 47.96976241900648,
      "grad_norm": 3.34409810420766e-06,
      "learning_rate": 2.030237580993521e-06,
      "loss": 0.0,
      "step": 155470
    },
    {
      "epoch": 47.9728478864548,
      "grad_norm": 1.5710323850726127e-06,
      "learning_rate": 2.027152113545202e-06,
      "loss": 0.0,
      "step": 155480
    },
    {
      "epoch": 47.975933353903116,
      "grad_norm": 1.3652479147197027e-08,
      "learning_rate": 2.024066646096884e-06,
      "loss": 0.0,
      "step": 155490
    },
    {
      "epoch": 47.97901882135143,
      "grad_norm": 3.818058758042753e-07,
      "learning_rate": 2.0209811786485654e-06,
      "loss": 0.0,
      "step": 155500
    },
    {
      "epoch": 47.98210428879975,
      "grad_norm": 2.6422187147545628e-05,
      "learning_rate": 2.0178957112002466e-06,
      "loss": 0.0,
      "step": 155510
    },
    {
      "epoch": 47.98518975624807,
      "grad_norm": 4.138784333918011e-06,
      "learning_rate": 2.0148102437519287e-06,
      "loss": 0.0,
      "step": 155520
    },
    {
      "epoch": 47.98827522369639,
      "grad_norm": 1.2099118151809307e-08,
      "learning_rate": 2.0117247763036103e-06,
      "loss": 0.0,
      "step": 155530
    },
    {
      "epoch": 47.991360691144706,
      "grad_norm": 0.0013449459802359343,
      "learning_rate": 2.0086393088552915e-06,
      "loss": 0.0,
      "step": 155540
    },
    {
      "epoch": 47.99444615859303,
      "grad_norm": 4.2321235405040625e-09,
      "learning_rate": 2.005553841406973e-06,
      "loss": 0.0,
      "step": 155550
    },
    {
      "epoch": 47.997531626041344,
      "grad_norm": 1.4618105126373848e-07,
      "learning_rate": 2.0024683739586548e-06,
      "loss": 0.0,
      "step": 155560
    },
    {
      "epoch": 48.0,
      "eval_accuracy_branch1": 1.0,
      "eval_accuracy_branch2": 0.41569977720552065,
      "eval_f1_branch1": 1.0,
      "eval_f1_branch2": 0.4095081840996424,
      "eval_loss": 5.1836561709706075e-08,
      "eval_precision_branch1": 1.0,
      "eval_precision_branch2": 0.5075846026637849,
      "eval_recall_branch1": 1.0,
      "eval_recall_branch2": 0.5060617458985561,
      "eval_runtime": 133.1698,
      "eval_samples_per_second": 778.577,
      "eval_steps_per_second": 97.327,
      "step": 155568
    },
    {
      "epoch": 48.000617093489666,
      "grad_norm": 0.00015540621825493872,
      "learning_rate": 1.9993829065103364e-06,
      "loss": 0.457,
      "step": 155570
    },
    {
      "epoch": 48.00370256093798,
      "grad_norm": 1.9041297036892502e-06,
      "learning_rate": 1.996297439062018e-06,
      "loss": 0.0,
      "step": 155580
    },
    {
      "epoch": 48.0067880283863,
      "grad_norm": 5.261530766631495e-09,
      "learning_rate": 1.9932119716136997e-06,
      "loss": 0.0,
      "step": 155590
    },
    {
      "epoch": 48.00987349583462,
      "grad_norm": 9.146088331135616e-08,
      "learning_rate": 1.9901265041653813e-06,
      "loss": 0.0,
      "step": 155600
    },
    {
      "epoch": 48.01295896328294,
      "grad_norm": 1.6703593246347737e-06,
      "learning_rate": 1.9870410367170625e-06,
      "loss": 0.0,
      "step": 155610
    },
    {
      "epoch": 48.016044430731256,
      "grad_norm": 0.00023889905423857272,
      "learning_rate": 1.983955569268744e-06,
      "loss": 0.0,
      "step": 155620
    },
    {
      "epoch": 48.01912989817957,
      "grad_norm": 6.539436725461201e-08,
      "learning_rate": 1.980870101820426e-06,
      "loss": 0.0,
      "step": 155630
    },
    {
      "epoch": 48.02221536562789,
      "grad_norm": 2.0849920900900543e-08,
      "learning_rate": 1.9777846343721074e-06,
      "loss": 0.0,
      "step": 155640
    },
    {
      "epoch": 48.02530083307621,
      "grad_norm": 4.1305497688881587e-07,
      "learning_rate": 1.974699166923789e-06,
      "loss": 0.0,
      "step": 155650
    },
    {
      "epoch": 48.02838630052453,
      "grad_norm": 1.416279715726887e-08,
      "learning_rate": 1.9716136994754707e-06,
      "loss": 0.0,
      "step": 155660
    },
    {
      "epoch": 48.031471767972846,
      "grad_norm": 2.863615691239829e-07,
      "learning_rate": 1.968528232027152e-06,
      "loss": 0.0,
      "step": 155670
    },
    {
      "epoch": 48.03455723542117,
      "grad_norm": 2.6018578402897674e-09,
      "learning_rate": 1.965442764578834e-06,
      "loss": 0.0,
      "step": 155680
    },
    {
      "epoch": 48.03764270286948,
      "grad_norm": 1.2110310763091547e-06,
      "learning_rate": 1.9623572971305155e-06,
      "loss": 0.0,
      "step": 155690
    },
    {
      "epoch": 48.040728170317806,
      "grad_norm": 0.0004730334330815822,
      "learning_rate": 1.9592718296821967e-06,
      "loss": 0.0,
      "step": 155700
    },
    {
      "epoch": 48.04381363776612,
      "grad_norm": 6.086929715820588e-06,
      "learning_rate": 1.9561863622338784e-06,
      "loss": 0.0,
      "step": 155710
    },
    {
      "epoch": 48.04689910521444,
      "grad_norm": 2.2134313937272054e-08,
      "learning_rate": 1.95310089478556e-06,
      "loss": 0.0,
      "step": 155720
    },
    {
      "epoch": 48.04998457266276,
      "grad_norm": 2.9592581540782703e-06,
      "learning_rate": 1.9500154273372416e-06,
      "loss": 0.0,
      "step": 155730
    },
    {
      "epoch": 48.05307004011107,
      "grad_norm": 1.1038068805646617e-06,
      "learning_rate": 1.9469299598889233e-06,
      "loss": 0.0,
      "step": 155740
    },
    {
      "epoch": 48.056155507559396,
      "grad_norm": 1.181925199489342e-05,
      "learning_rate": 1.943844492440605e-06,
      "loss": 0.0,
      "step": 155750
    },
    {
      "epoch": 48.05924097500771,
      "grad_norm": 6.690989721391816e-06,
      "learning_rate": 1.9407590249922865e-06,
      "loss": 0.0,
      "step": 155760
    },
    {
      "epoch": 48.06232644245603,
      "grad_norm": 6.353996440111587e-08,
      "learning_rate": 1.9376735575439677e-06,
      "loss": 0.0,
      "step": 155770
    },
    {
      "epoch": 48.06541190990435,
      "grad_norm": 2.965493961504251e-10,
      "learning_rate": 1.9345880900956498e-06,
      "loss": 0.0,
      "step": 155780
    },
    {
      "epoch": 48.06849737735267,
      "grad_norm": 6.870327342767268e-05,
      "learning_rate": 1.9315026226473314e-06,
      "loss": 0.0,
      "step": 155790
    },
    {
      "epoch": 48.071582844800986,
      "grad_norm": 0.00018254730093758553,
      "learning_rate": 1.9284171551990126e-06,
      "loss": 0.0,
      "step": 155800
    },
    {
      "epoch": 48.07466831224931,
      "grad_norm": 2.954824579459725e-11,
      "learning_rate": 1.9253316877506943e-06,
      "loss": 0.0,
      "step": 155810
    },
    {
      "epoch": 48.07775377969762,
      "grad_norm": 4.295566395740025e-05,
      "learning_rate": 1.922246220302376e-06,
      "loss": 0.0,
      "step": 155820
    },
    {
      "epoch": 48.080839247145946,
      "grad_norm": 1.5205975145704542e-08,
      "learning_rate": 1.9191607528540575e-06,
      "loss": 0.0,
      "step": 155830
    },
    {
      "epoch": 48.08392471459426,
      "grad_norm": 2.898083373281679e-08,
      "learning_rate": 1.916075285405739e-06,
      "loss": 0.0,
      "step": 155840
    },
    {
      "epoch": 48.087010182042576,
      "grad_norm": 1.8163269487558864e-05,
      "learning_rate": 1.9129898179574208e-06,
      "loss": 0.0,
      "step": 155850
    },
    {
      "epoch": 48.0900956494909,
      "grad_norm": 2.6451195935806027e-06,
      "learning_rate": 1.909904350509102e-06,
      "loss": 0.0,
      "step": 155860
    },
    {
      "epoch": 48.09318111693921,
      "grad_norm": 1.0857465895242058e-06,
      "learning_rate": 1.9068188830607836e-06,
      "loss": 0.0,
      "step": 155870
    },
    {
      "epoch": 48.096266584387536,
      "grad_norm": 8.546005847165361e-05,
      "learning_rate": 1.9037334156124655e-06,
      "loss": 0.0,
      "step": 155880
    },
    {
      "epoch": 48.09935205183585,
      "grad_norm": 0.002830873243510723,
      "learning_rate": 1.900647948164147e-06,
      "loss": 0.0,
      "step": 155890
    },
    {
      "epoch": 48.10243751928417,
      "grad_norm": 2.0891264274069954e-09,
      "learning_rate": 1.8975624807158285e-06,
      "loss": 0.0,
      "step": 155900
    },
    {
      "epoch": 48.10552298673249,
      "grad_norm": 0.0021503078751266003,
      "learning_rate": 1.8944770132675101e-06,
      "loss": 0.0,
      "step": 155910
    },
    {
      "epoch": 48.10860845418081,
      "grad_norm": 3.930000093532726e-05,
      "learning_rate": 1.8913915458191915e-06,
      "loss": 0.0,
      "step": 155920
    },
    {
      "epoch": 48.111693921629126,
      "grad_norm": 4.543922216271312e-08,
      "learning_rate": 1.8883060783708734e-06,
      "loss": 0.0,
      "step": 155930
    },
    {
      "epoch": 48.11477938907745,
      "grad_norm": 7.998406545084435e-06,
      "learning_rate": 1.885220610922555e-06,
      "loss": 0.0,
      "step": 155940
    },
    {
      "epoch": 48.11786485652576,
      "grad_norm": 1.3042135833529755e-05,
      "learning_rate": 1.8821351434742364e-06,
      "loss": 0.0,
      "step": 155950
    },
    {
      "epoch": 48.120950323974085,
      "grad_norm": 2.4814529751893133e-05,
      "learning_rate": 1.879049676025918e-06,
      "loss": 0.0,
      "step": 155960
    },
    {
      "epoch": 48.1240357914224,
      "grad_norm": 0.0002238592569483444,
      "learning_rate": 1.8759642085775995e-06,
      "loss": 0.0,
      "step": 155970
    },
    {
      "epoch": 48.127121258870716,
      "grad_norm": 1.6093067642941605e-06,
      "learning_rate": 1.8728787411292813e-06,
      "loss": 0.0,
      "step": 155980
    },
    {
      "epoch": 48.13020672631904,
      "grad_norm": 5.649013019137783e-06,
      "learning_rate": 1.869793273680963e-06,
      "loss": 0.0,
      "step": 155990
    },
    {
      "epoch": 48.13329219376735,
      "grad_norm": 6.776524969609454e-05,
      "learning_rate": 1.8667078062326444e-06,
      "loss": 0.0,
      "step": 156000
    },
    {
      "epoch": 48.136377661215676,
      "grad_norm": 5.182812401471892e-07,
      "learning_rate": 1.8636223387843258e-06,
      "loss": 0.0,
      "step": 156010
    },
    {
      "epoch": 48.13946312866399,
      "grad_norm": 5.458349505715887e-08,
      "learning_rate": 1.8605368713360074e-06,
      "loss": 0.0,
      "step": 156020
    },
    {
      "epoch": 48.14254859611231,
      "grad_norm": 1.933090970851481e-06,
      "learning_rate": 1.8574514038876888e-06,
      "loss": 0.0,
      "step": 156030
    },
    {
      "epoch": 48.14563406356063,
      "grad_norm": 6.124216452008113e-05,
      "learning_rate": 1.8543659364393707e-06,
      "loss": 0.0,
      "step": 156040
    },
    {
      "epoch": 48.14871953100895,
      "grad_norm": 2.8877791919512674e-05,
      "learning_rate": 1.8512804689910523e-06,
      "loss": 0.0,
      "step": 156050
    },
    {
      "epoch": 48.151804998457266,
      "grad_norm": 1.4335299169943028e-08,
      "learning_rate": 1.8481950015427337e-06,
      "loss": 0.0,
      "step": 156060
    },
    {
      "epoch": 48.15489046590559,
      "grad_norm": 4.757105820374363e-09,
      "learning_rate": 1.8451095340944154e-06,
      "loss": 0.0,
      "step": 156070
    },
    {
      "epoch": 48.1579759333539,
      "grad_norm": 2.026947276689839e-09,
      "learning_rate": 1.8420240666460968e-06,
      "loss": 0.0,
      "step": 156080
    },
    {
      "epoch": 48.16106140080222,
      "grad_norm": 6.934345009312892e-08,
      "learning_rate": 1.8389385991977786e-06,
      "loss": 0.0,
      "step": 156090
    },
    {
      "epoch": 48.16414686825054,
      "grad_norm": 4.271159070867725e-07,
      "learning_rate": 1.8358531317494603e-06,
      "loss": 0.0,
      "step": 156100
    },
    {
      "epoch": 48.167232335698856,
      "grad_norm": 2.8412514438969083e-05,
      "learning_rate": 1.8327676643011417e-06,
      "loss": 0.0,
      "step": 156110
    },
    {
      "epoch": 48.17031780314718,
      "grad_norm": 4.351904392407846e-10,
      "learning_rate": 1.8296821968528233e-06,
      "loss": 0.0,
      "step": 156120
    },
    {
      "epoch": 48.17340327059549,
      "grad_norm": 3.472217940725386e-05,
      "learning_rate": 1.8265967294045047e-06,
      "loss": 0.0,
      "step": 156130
    },
    {
      "epoch": 48.176488738043815,
      "grad_norm": 2.5659488755991333e-07,
      "learning_rate": 1.8235112619561866e-06,
      "loss": 0.0,
      "step": 156140
    },
    {
      "epoch": 48.17957420549213,
      "grad_norm": 7.597750206755904e-10,
      "learning_rate": 1.8204257945078682e-06,
      "loss": 0.0,
      "step": 156150
    },
    {
      "epoch": 48.18265967294045,
      "grad_norm": 2.8013761976808382e-08,
      "learning_rate": 1.8173403270595496e-06,
      "loss": 0.0,
      "step": 156160
    },
    {
      "epoch": 48.18574514038877,
      "grad_norm": 0.016978241503238678,
      "learning_rate": 1.814254859611231e-06,
      "loss": 0.0,
      "step": 156170
    },
    {
      "epoch": 48.18883060783709,
      "grad_norm": 2.0915729237458436e-06,
      "learning_rate": 1.8111693921629127e-06,
      "loss": 0.0,
      "step": 156180
    },
    {
      "epoch": 48.191916075285405,
      "grad_norm": 3.0452230959099325e-08,
      "learning_rate": 1.8080839247145945e-06,
      "loss": 0.0001,
      "step": 156190
    },
    {
      "epoch": 48.19500154273372,
      "grad_norm": 1.4103714862656602e-09,
      "learning_rate": 1.804998457266276e-06,
      "loss": 0.0,
      "step": 156200
    },
    {
      "epoch": 48.19808701018204,
      "grad_norm": 1.0701452083594631e-05,
      "learning_rate": 1.8019129898179575e-06,
      "loss": 0.0,
      "step": 156210
    },
    {
      "epoch": 48.20117247763036,
      "grad_norm": 1.1602204494920443e-06,
      "learning_rate": 1.798827522369639e-06,
      "loss": 0.0,
      "step": 156220
    },
    {
      "epoch": 48.20425794507868,
      "grad_norm": 2.358114272738021e-07,
      "learning_rate": 1.7957420549213206e-06,
      "loss": 0.0,
      "step": 156230
    },
    {
      "epoch": 48.207343412526996,
      "grad_norm": 2.786032793355986e-10,
      "learning_rate": 1.7926565874730024e-06,
      "loss": 0.0,
      "step": 156240
    },
    {
      "epoch": 48.21042887997532,
      "grad_norm": 3.5796470001514535e-06,
      "learning_rate": 1.7895711200246839e-06,
      "loss": 0.0,
      "step": 156250
    },
    {
      "epoch": 48.21351434742363,
      "grad_norm": 1.730260919430293e-05,
      "learning_rate": 1.7864856525763655e-06,
      "loss": 0.0,
      "step": 156260
    },
    {
      "epoch": 48.216599814871955,
      "grad_norm": 3.182256932632299e-06,
      "learning_rate": 1.783400185128047e-06,
      "loss": 0.0,
      "step": 156270
    },
    {
      "epoch": 48.21968528232027,
      "grad_norm": 6.75843984936364e-05,
      "learning_rate": 1.7803147176797285e-06,
      "loss": 0.0,
      "step": 156280
    },
    {
      "epoch": 48.22277074976859,
      "grad_norm": 0.00018212142458651215,
      "learning_rate": 1.7772292502314104e-06,
      "loss": 0.0,
      "step": 156290
    },
    {
      "epoch": 48.22585621721691,
      "grad_norm": 1.1605643113199449e-09,
      "learning_rate": 1.7741437827830918e-06,
      "loss": 0.0,
      "step": 156300
    },
    {
      "epoch": 48.22894168466523,
      "grad_norm": 3.034002656931989e-05,
      "learning_rate": 1.7710583153347734e-06,
      "loss": 0.0,
      "step": 156310
    },
    {
      "epoch": 48.232027152113545,
      "grad_norm": 2.7515698608482353e-09,
      "learning_rate": 1.7679728478864548e-06,
      "loss": 0.0,
      "step": 156320
    },
    {
      "epoch": 48.23511261956186,
      "grad_norm": 9.386424721924413e-07,
      "learning_rate": 1.7648873804381363e-06,
      "loss": 0.0,
      "step": 156330
    },
    {
      "epoch": 48.23819808701018,
      "grad_norm": 4.4714980163007567e-07,
      "learning_rate": 1.761801912989818e-06,
      "loss": 0.0,
      "step": 156340
    },
    {
      "epoch": 48.2412835544585,
      "grad_norm": 2.3431674378571188e-07,
      "learning_rate": 1.7587164455414997e-06,
      "loss": 0.0,
      "step": 156350
    },
    {
      "epoch": 48.24436902190682,
      "grad_norm": 1.0983234322026192e-09,
      "learning_rate": 1.7556309780931811e-06,
      "loss": 0.0,
      "step": 156360
    },
    {
      "epoch": 48.247454489355135,
      "grad_norm": 0.0011276488658040762,
      "learning_rate": 1.7525455106448628e-06,
      "loss": 0.0,
      "step": 156370
    },
    {
      "epoch": 48.25053995680346,
      "grad_norm": 1.8269047359353863e-05,
      "learning_rate": 1.7494600431965442e-06,
      "loss": 0.0,
      "step": 156380
    },
    {
      "epoch": 48.25362542425177,
      "grad_norm": 2.7954872621194227e-06,
      "learning_rate": 1.746374575748226e-06,
      "loss": 0.0,
      "step": 156390
    },
    {
      "epoch": 48.256710891700095,
      "grad_norm": 4.712997565547994e-07,
      "learning_rate": 1.7432891082999077e-06,
      "loss": 0.0,
      "step": 156400
    },
    {
      "epoch": 48.25979635914841,
      "grad_norm": 4.385129068396054e-05,
      "learning_rate": 1.740203640851589e-06,
      "loss": 0.0,
      "step": 156410
    },
    {
      "epoch": 48.26288182659673,
      "grad_norm": 6.0362315707607195e-05,
      "learning_rate": 1.7371181734032707e-06,
      "loss": 0.0,
      "step": 156420
    },
    {
      "epoch": 48.26596729404505,
      "grad_norm": 8.67884786259765e-09,
      "learning_rate": 1.7340327059549521e-06,
      "loss": 0.0,
      "step": 156430
    },
    {
      "epoch": 48.26905276149336,
      "grad_norm": 2.5523920612613438e-06,
      "learning_rate": 1.730947238506634e-06,
      "loss": 0.0,
      "step": 156440
    },
    {
      "epoch": 48.272138228941685,
      "grad_norm": 4.1436592823629326e-08,
      "learning_rate": 1.7278617710583156e-06,
      "loss": 0.0,
      "step": 156450
    },
    {
      "epoch": 48.27522369639,
      "grad_norm": 1.3403731458083712e-09,
      "learning_rate": 1.724776303609997e-06,
      "loss": 0.0,
      "step": 156460
    },
    {
      "epoch": 48.27830916383832,
      "grad_norm": 2.6681300369091332e-05,
      "learning_rate": 1.7216908361616784e-06,
      "loss": 0.0,
      "step": 156470
    },
    {
      "epoch": 48.28139463128664,
      "grad_norm": 9.989712452806998e-07,
      "learning_rate": 1.71860536871336e-06,
      "loss": 0.0,
      "step": 156480
    },
    {
      "epoch": 48.28448009873496,
      "grad_norm": 1.4593199011869729e-05,
      "learning_rate": 1.7155199012650415e-06,
      "loss": 0.0,
      "step": 156490
    },
    {
      "epoch": 48.287565566183275,
      "grad_norm": 0.0057573020458221436,
      "learning_rate": 1.7124344338167233e-06,
      "loss": 0.0,
      "step": 156500
    },
    {
      "epoch": 48.2906510336316,
      "grad_norm": 1.6394606561220826e-08,
      "learning_rate": 1.709348966368405e-06,
      "loss": 0.0,
      "step": 156510
    },
    {
      "epoch": 48.29373650107991,
      "grad_norm": 0.00010094179742736742,
      "learning_rate": 1.7062634989200864e-06,
      "loss": 0.0,
      "step": 156520
    },
    {
      "epoch": 48.296821968528235,
      "grad_norm": 0.0002494260261300951,
      "learning_rate": 1.703178031471768e-06,
      "loss": 0.0,
      "step": 156530
    },
    {
      "epoch": 48.29990743597655,
      "grad_norm": 4.931619557169142e-09,
      "learning_rate": 1.7000925640234494e-06,
      "loss": 0.0,
      "step": 156540
    },
    {
      "epoch": 48.302992903424865,
      "grad_norm": 6.323925560991484e-08,
      "learning_rate": 1.6970070965751313e-06,
      "loss": 0.0,
      "step": 156550
    },
    {
      "epoch": 48.30607837087319,
      "grad_norm": 1.1014984693247243e-06,
      "learning_rate": 1.693921629126813e-06,
      "loss": 0.0,
      "step": 156560
    },
    {
      "epoch": 48.3091638383215,
      "grad_norm": 2.1089965684950585e-06,
      "learning_rate": 1.6908361616784943e-06,
      "loss": 0.0,
      "step": 156570
    },
    {
      "epoch": 48.312249305769825,
      "grad_norm": 2.7534876601009728e-09,
      "learning_rate": 1.687750694230176e-06,
      "loss": 0.0,
      "step": 156580
    },
    {
      "epoch": 48.31533477321814,
      "grad_norm": 2.204905769076504e-08,
      "learning_rate": 1.6846652267818574e-06,
      "loss": 0.0,
      "step": 156590
    },
    {
      "epoch": 48.31842024066646,
      "grad_norm": 6.209458547346003e-07,
      "learning_rate": 1.6815797593335392e-06,
      "loss": 0.0,
      "step": 156600
    },
    {
      "epoch": 48.32150570811478,
      "grad_norm": 7.711156513323658e-07,
      "learning_rate": 1.6784942918852208e-06,
      "loss": 0.0,
      "step": 156610
    },
    {
      "epoch": 48.3245911755631,
      "grad_norm": 4.59495463900339e-09,
      "learning_rate": 1.6754088244369023e-06,
      "loss": 0.0,
      "step": 156620
    },
    {
      "epoch": 48.327676643011415,
      "grad_norm": 7.232983421090466e-07,
      "learning_rate": 1.6723233569885837e-06,
      "loss": 0.0,
      "step": 156630
    },
    {
      "epoch": 48.33076211045974,
      "grad_norm": 1.9668911477310758e-07,
      "learning_rate": 1.6692378895402653e-06,
      "loss": 0.0,
      "step": 156640
    },
    {
      "epoch": 48.33384757790805,
      "grad_norm": 0.00013428644160740077,
      "learning_rate": 1.6661524220919471e-06,
      "loss": 0.0,
      "step": 156650
    },
    {
      "epoch": 48.336933045356375,
      "grad_norm": 4.800316673936322e-05,
      "learning_rate": 1.6630669546436286e-06,
      "loss": 0.0,
      "step": 156660
    },
    {
      "epoch": 48.34001851280469,
      "grad_norm": 6.451813533203676e-05,
      "learning_rate": 1.6599814871953102e-06,
      "loss": 0.0,
      "step": 156670
    },
    {
      "epoch": 48.343103980253005,
      "grad_norm": 3.031327423741459e-06,
      "learning_rate": 1.6568960197469916e-06,
      "loss": 0.0,
      "step": 156680
    },
    {
      "epoch": 48.34618944770133,
      "grad_norm": 2.999890824639806e-08,
      "learning_rate": 1.6538105522986732e-06,
      "loss": 0.0,
      "step": 156690
    },
    {
      "epoch": 48.34927491514964,
      "grad_norm": 0.005122796632349491,
      "learning_rate": 1.650725084850355e-06,
      "loss": 0.0,
      "step": 156700
    },
    {
      "epoch": 48.352360382597965,
      "grad_norm": 9.120038157561794e-06,
      "learning_rate": 1.6476396174020365e-06,
      "loss": 0.0,
      "step": 156710
    },
    {
      "epoch": 48.35544585004628,
      "grad_norm": 9.94905349216424e-06,
      "learning_rate": 1.6445541499537181e-06,
      "loss": 0.0,
      "step": 156720
    },
    {
      "epoch": 48.3585313174946,
      "grad_norm": 3.4268200010956207e-07,
      "learning_rate": 1.6414686825053995e-06,
      "loss": 0.0,
      "step": 156730
    },
    {
      "epoch": 48.36161678494292,
      "grad_norm": 1.775183363861288e-06,
      "learning_rate": 1.6383832150570812e-06,
      "loss": 0.0,
      "step": 156740
    },
    {
      "epoch": 48.36470225239124,
      "grad_norm": 5.401393821102829e-08,
      "learning_rate": 1.635297747608763e-06,
      "loss": 0.0,
      "step": 156750
    },
    {
      "epoch": 48.367787719839555,
      "grad_norm": 2.5242245556000853e-06,
      "learning_rate": 1.6322122801604444e-06,
      "loss": 0.0,
      "step": 156760
    },
    {
      "epoch": 48.37087318728788,
      "grad_norm": 1.5346381943004417e-09,
      "learning_rate": 1.629126812712126e-06,
      "loss": 0.0,
      "step": 156770
    },
    {
      "epoch": 48.37395865473619,
      "grad_norm": 2.8898369919261313e-07,
      "learning_rate": 1.6260413452638075e-06,
      "loss": 0.0,
      "step": 156780
    },
    {
      "epoch": 48.37704412218451,
      "grad_norm": 2.858675145489542e-07,
      "learning_rate": 1.622955877815489e-06,
      "loss": 0.0,
      "step": 156790
    },
    {
      "epoch": 48.38012958963283,
      "grad_norm": 1.4572489135389333e-06,
      "learning_rate": 1.619870410367171e-06,
      "loss": 0.0,
      "step": 156800
    },
    {
      "epoch": 48.383215057081145,
      "grad_norm": 6.893701356602833e-05,
      "learning_rate": 1.6167849429188524e-06,
      "loss": 0.0,
      "step": 156810
    },
    {
      "epoch": 48.38630052452947,
      "grad_norm": 2.2801488697155037e-08,
      "learning_rate": 1.6136994754705338e-06,
      "loss": 0.0,
      "step": 156820
    },
    {
      "epoch": 48.38938599197778,
      "grad_norm": 9.364317520521581e-06,
      "learning_rate": 1.6106140080222154e-06,
      "loss": 0.0,
      "step": 156830
    },
    {
      "epoch": 48.392471459426105,
      "grad_norm": 0.00023316020087804645,
      "learning_rate": 1.6075285405738968e-06,
      "loss": 0.0,
      "step": 156840
    },
    {
      "epoch": 48.39555692687442,
      "grad_norm": 0.000784247531555593,
      "learning_rate": 1.6044430731255787e-06,
      "loss": 0.0,
      "step": 156850
    },
    {
      "epoch": 48.39864239432274,
      "grad_norm": 1.1466323002196077e-08,
      "learning_rate": 1.6013576056772603e-06,
      "loss": 0.0,
      "step": 156860
    },
    {
      "epoch": 48.40172786177106,
      "grad_norm": 8.605883522250224e-06,
      "learning_rate": 1.5982721382289417e-06,
      "loss": 0.0,
      "step": 156870
    },
    {
      "epoch": 48.40481332921938,
      "grad_norm": 8.275468644569628e-06,
      "learning_rate": 1.5951866707806234e-06,
      "loss": 0.0,
      "step": 156880
    },
    {
      "epoch": 48.407898796667695,
      "grad_norm": 1.1610586625465658e-05,
      "learning_rate": 1.5921012033323048e-06,
      "loss": 0.0,
      "step": 156890
    },
    {
      "epoch": 48.41098426411602,
      "grad_norm": 2.9581281069113174e-07,
      "learning_rate": 1.5890157358839864e-06,
      "loss": 0.0,
      "step": 156900
    },
    {
      "epoch": 48.41406973156433,
      "grad_norm": 2.857264735212084e-05,
      "learning_rate": 1.5859302684356683e-06,
      "loss": 0.0,
      "step": 156910
    },
    {
      "epoch": 48.41715519901265,
      "grad_norm": 4.3409869249444455e-05,
      "learning_rate": 1.5828448009873497e-06,
      "loss": 0.0,
      "step": 156920
    },
    {
      "epoch": 48.42024066646097,
      "grad_norm": 6.98562928391766e-07,
      "learning_rate": 1.5797593335390313e-06,
      "loss": 0.0,
      "step": 156930
    },
    {
      "epoch": 48.423326133909285,
      "grad_norm": 3.5277724236948416e-05,
      "learning_rate": 1.5766738660907127e-06,
      "loss": 0.0,
      "step": 156940
    },
    {
      "epoch": 48.42641160135761,
      "grad_norm": 6.041111166865676e-09,
      "learning_rate": 1.5735883986423941e-06,
      "loss": 0.0,
      "step": 156950
    },
    {
      "epoch": 48.42949706880592,
      "grad_norm": 4.925183816339995e-07,
      "learning_rate": 1.5705029311940762e-06,
      "loss": 0.0,
      "step": 156960
    },
    {
      "epoch": 48.432582536254245,
      "grad_norm": 7.651809937669896e-06,
      "learning_rate": 1.5674174637457576e-06,
      "loss": 0.0,
      "step": 156970
    },
    {
      "epoch": 48.43566800370256,
      "grad_norm": 8.754964255786035e-06,
      "learning_rate": 1.564331996297439e-06,
      "loss": 0.0,
      "step": 156980
    },
    {
      "epoch": 48.43875347115088,
      "grad_norm": 7.009205546637531e-06,
      "learning_rate": 1.5612465288491207e-06,
      "loss": 0.0011,
      "step": 156990
    },
    {
      "epoch": 48.4418389385992,
      "grad_norm": 4.7563588623233954e-07,
      "learning_rate": 1.5581610614008023e-06,
      "loss": 0.0,
      "step": 157000
    },
    {
      "epoch": 48.44492440604752,
      "grad_norm": 1.806660598901999e-08,
      "learning_rate": 1.555075593952484e-06,
      "loss": 0.0,
      "step": 157010
    },
    {
      "epoch": 48.448009873495835,
      "grad_norm": 2.9181234140196466e-07,
      "learning_rate": 1.5519901265041655e-06,
      "loss": 0.0,
      "step": 157020
    },
    {
      "epoch": 48.45109534094415,
      "grad_norm": 9.66568109106447e-07,
      "learning_rate": 1.548904659055847e-06,
      "loss": 0.0,
      "step": 157030
    },
    {
      "epoch": 48.45418080839247,
      "grad_norm": 9.356481314171106e-06,
      "learning_rate": 1.5458191916075286e-06,
      "loss": 0.0,
      "step": 157040
    },
    {
      "epoch": 48.45726627584079,
      "grad_norm": 3.2754676748680822e-09,
      "learning_rate": 1.5427337241592102e-06,
      "loss": 0.0,
      "step": 157050
    },
    {
      "epoch": 48.46035174328911,
      "grad_norm": 8.51735967444256e-06,
      "learning_rate": 1.5396482567108916e-06,
      "loss": 0.0,
      "step": 157060
    },
    {
      "epoch": 48.463437210737425,
      "grad_norm": 3.4640412760467143e-09,
      "learning_rate": 1.5365627892625735e-06,
      "loss": 0.0,
      "step": 157070
    },
    {
      "epoch": 48.46652267818575,
      "grad_norm": 3.251832936257415e-08,
      "learning_rate": 1.533477321814255e-06,
      "loss": 0.0,
      "step": 157080
    },
    {
      "epoch": 48.46960814563406,
      "grad_norm": 6.220153281333296e-09,
      "learning_rate": 1.5303918543659365e-06,
      "loss": 0.0,
      "step": 157090
    },
    {
      "epoch": 48.472693613082384,
      "grad_norm": 1.982622779905796e-05,
      "learning_rate": 1.5273063869176182e-06,
      "loss": 0.0,
      "step": 157100
    },
    {
      "epoch": 48.4757790805307,
      "grad_norm": 8.235004997914075e-07,
      "learning_rate": 1.5242209194692996e-06,
      "loss": 0.0,
      "step": 157110
    },
    {
      "epoch": 48.47886454797902,
      "grad_norm": 3.800784895702236e-07,
      "learning_rate": 1.5211354520209814e-06,
      "loss": 0.0,
      "step": 157120
    },
    {
      "epoch": 48.48195001542734,
      "grad_norm": 3.787695845858252e-08,
      "learning_rate": 1.5180499845726628e-06,
      "loss": 0.0,
      "step": 157130
    },
    {
      "epoch": 48.48503548287565,
      "grad_norm": 1.1372966923772765e-07,
      "learning_rate": 1.5149645171243443e-06,
      "loss": 0.0,
      "step": 157140
    },
    {
      "epoch": 48.488120950323975,
      "grad_norm": 7.663450318773357e-09,
      "learning_rate": 1.511879049676026e-06,
      "loss": 0.0,
      "step": 157150
    },
    {
      "epoch": 48.49120641777229,
      "grad_norm": 1.0022846907986604e-07,
      "learning_rate": 1.5087935822277075e-06,
      "loss": 0.0,
      "step": 157160
    },
    {
      "epoch": 48.49429188522061,
      "grad_norm": 1.1750407793442719e-06,
      "learning_rate": 1.5057081147793891e-06,
      "loss": 0.0,
      "step": 157170
    },
    {
      "epoch": 48.49737735266893,
      "grad_norm": 1.4849689478069195e-06,
      "learning_rate": 1.5026226473310708e-06,
      "loss": 0.0,
      "step": 157180
    },
    {
      "epoch": 48.50046282011725,
      "grad_norm": 1.78984080889677e-07,
      "learning_rate": 1.4995371798827522e-06,
      "loss": 0.0,
      "step": 157190
    },
    {
      "epoch": 48.503548287565565,
      "grad_norm": 9.339386451756582e-06,
      "learning_rate": 1.496451712434434e-06,
      "loss": 0.0,
      "step": 157200
    },
    {
      "epoch": 48.50663375501389,
      "grad_norm": 1.1685273420880549e-05,
      "learning_rate": 1.4933662449861155e-06,
      "loss": 0.0,
      "step": 157210
    },
    {
      "epoch": 48.5097192224622,
      "grad_norm": 9.406152094015852e-05,
      "learning_rate": 1.4902807775377969e-06,
      "loss": 0.0,
      "step": 157220
    },
    {
      "epoch": 48.512804689910524,
      "grad_norm": 9.5728194082767e-07,
      "learning_rate": 1.4871953100894787e-06,
      "loss": 0.0,
      "step": 157230
    },
    {
      "epoch": 48.51589015735884,
      "grad_norm": 4.441852996528439e-10,
      "learning_rate": 1.4841098426411601e-06,
      "loss": 0.0,
      "step": 157240
    },
    {
      "epoch": 48.51897562480716,
      "grad_norm": 4.315067414495388e-09,
      "learning_rate": 1.4810243751928418e-06,
      "loss": 0.0,
      "step": 157250
    },
    {
      "epoch": 48.52206109225548,
      "grad_norm": 1.3806014067085925e-05,
      "learning_rate": 1.4779389077445234e-06,
      "loss": 0.0,
      "step": 157260
    },
    {
      "epoch": 48.52514655970379,
      "grad_norm": 0.006415934301912785,
      "learning_rate": 1.4748534402962048e-06,
      "loss": 0.0,
      "step": 157270
    },
    {
      "epoch": 48.528232027152114,
      "grad_norm": 2.691909685381688e-06,
      "learning_rate": 1.4717679728478867e-06,
      "loss": 0.0,
      "step": 157280
    },
    {
      "epoch": 48.53131749460043,
      "grad_norm": 2.9145237334660123e-09,
      "learning_rate": 1.468682505399568e-06,
      "loss": 0.0,
      "step": 157290
    },
    {
      "epoch": 48.53440296204875,
      "grad_norm": 9.701600902189966e-06,
      "learning_rate": 1.4655970379512497e-06,
      "loss": 0.0,
      "step": 157300
    },
    {
      "epoch": 48.53748842949707,
      "grad_norm": 4.1702608655214135e-07,
      "learning_rate": 1.4625115705029313e-06,
      "loss": 0.0,
      "step": 157310
    },
    {
      "epoch": 48.54057389694539,
      "grad_norm": 4.500713579602689e-09,
      "learning_rate": 1.4594261030546128e-06,
      "loss": 0.0,
      "step": 157320
    },
    {
      "epoch": 48.543659364393704,
      "grad_norm": 2.928736648755148e-06,
      "learning_rate": 1.4563406356062944e-06,
      "loss": 0.0,
      "step": 157330
    },
    {
      "epoch": 48.54674483184203,
      "grad_norm": 1.471308792133641e-06,
      "learning_rate": 1.453255168157976e-06,
      "loss": 0.0,
      "step": 157340
    },
    {
      "epoch": 48.54983029929034,
      "grad_norm": 4.046249113542899e-09,
      "learning_rate": 1.4501697007096576e-06,
      "loss": 0.0,
      "step": 157350
    },
    {
      "epoch": 48.552915766738664,
      "grad_norm": 5.183749635762069e-06,
      "learning_rate": 1.4470842332613393e-06,
      "loss": 0.0,
      "step": 157360
    },
    {
      "epoch": 48.55600123418698,
      "grad_norm": 2.1190126062720083e-06,
      "learning_rate": 1.4439987658130207e-06,
      "loss": 0.0,
      "step": 157370
    },
    {
      "epoch": 48.559086701635295,
      "grad_norm": 5.70104930375237e-07,
      "learning_rate": 1.4409132983647023e-06,
      "loss": 0.0,
      "step": 157380
    },
    {
      "epoch": 48.56217216908362,
      "grad_norm": 6.580946632084306e-08,
      "learning_rate": 1.437827830916384e-06,
      "loss": 0.0,
      "step": 157390
    },
    {
      "epoch": 48.56525763653193,
      "grad_norm": 7.508947874157457e-06,
      "learning_rate": 1.4347423634680654e-06,
      "loss": 0.0,
      "step": 157400
    },
    {
      "epoch": 48.568343103980254,
      "grad_norm": 1.7374294003502655e-08,
      "learning_rate": 1.431656896019747e-06,
      "loss": 0.0,
      "step": 157410
    },
    {
      "epoch": 48.57142857142857,
      "grad_norm": 2.95043420805996e-08,
      "learning_rate": 1.4285714285714286e-06,
      "loss": 0.0,
      "step": 157420
    },
    {
      "epoch": 48.57451403887689,
      "grad_norm": 4.214679211145267e-05,
      "learning_rate": 1.4254859611231103e-06,
      "loss": 0.0,
      "step": 157430
    },
    {
      "epoch": 48.57759950632521,
      "grad_norm": 2.889136339945253e-06,
      "learning_rate": 1.4224004936747919e-06,
      "loss": 0.0,
      "step": 157440
    },
    {
      "epoch": 48.58068497377353,
      "grad_norm": 1.5931702819216298e-06,
      "learning_rate": 1.4193150262264733e-06,
      "loss": 0.0,
      "step": 157450
    },
    {
      "epoch": 48.583770441221844,
      "grad_norm": 8.53338999462494e-09,
      "learning_rate": 1.416229558778155e-06,
      "loss": 0.0,
      "step": 157460
    },
    {
      "epoch": 48.58685590867017,
      "grad_norm": 4.093662937521003e-05,
      "learning_rate": 1.4131440913298366e-06,
      "loss": 0.0,
      "step": 157470
    },
    {
      "epoch": 48.58994137611848,
      "grad_norm": 2.700039374303742e-07,
      "learning_rate": 1.4100586238815182e-06,
      "loss": 0.0,
      "step": 157480
    },
    {
      "epoch": 48.5930268435668,
      "grad_norm": 3.255603564511489e-09,
      "learning_rate": 1.4069731564331996e-06,
      "loss": 0.0,
      "step": 157490
    },
    {
      "epoch": 48.59611231101512,
      "grad_norm": 2.3169761220742657e-07,
      "learning_rate": 1.4038876889848812e-06,
      "loss": 0.0,
      "step": 157500
    },
    {
      "epoch": 48.599197778463434,
      "grad_norm": 6.946366283955285e-06,
      "learning_rate": 1.4008022215365629e-06,
      "loss": 0.0,
      "step": 157510
    },
    {
      "epoch": 48.60228324591176,
      "grad_norm": 5.517276804312132e-06,
      "learning_rate": 1.3977167540882445e-06,
      "loss": 0.0,
      "step": 157520
    },
    {
      "epoch": 48.60536871336007,
      "grad_norm": 1.2760530808009207e-05,
      "learning_rate": 1.3946312866399261e-06,
      "loss": 0.0,
      "step": 157530
    },
    {
      "epoch": 48.608454180808394,
      "grad_norm": 8.923142900130188e-07,
      "learning_rate": 1.3915458191916076e-06,
      "loss": 0.0,
      "step": 157540
    },
    {
      "epoch": 48.61153964825671,
      "grad_norm": 6.532515328672162e-08,
      "learning_rate": 1.3884603517432892e-06,
      "loss": 0.0001,
      "step": 157550
    },
    {
      "epoch": 48.61462511570503,
      "grad_norm": 3.1286727875112774e-08,
      "learning_rate": 1.3853748842949708e-06,
      "loss": 0.0,
      "step": 157560
    },
    {
      "epoch": 48.61771058315335,
      "grad_norm": 1.0841296749219964e-08,
      "learning_rate": 1.3822894168466522e-06,
      "loss": 0.0,
      "step": 157570
    },
    {
      "epoch": 48.62079605060167,
      "grad_norm": 2.0910214516334236e-05,
      "learning_rate": 1.379203949398334e-06,
      "loss": 0.0,
      "step": 157580
    },
    {
      "epoch": 48.623881518049984,
      "grad_norm": 3.9586828259885465e-10,
      "learning_rate": 1.3761184819500155e-06,
      "loss": 0.0,
      "step": 157590
    },
    {
      "epoch": 48.626966985498306,
      "grad_norm": 2.1984820705256425e-05,
      "learning_rate": 1.3730330145016971e-06,
      "loss": 0.0,
      "step": 157600
    },
    {
      "epoch": 48.63005245294662,
      "grad_norm": 1.751874606270576e-06,
      "learning_rate": 1.3699475470533787e-06,
      "loss": 0.0,
      "step": 157610
    },
    {
      "epoch": 48.63313792039494,
      "grad_norm": 9.947330909199081e-06,
      "learning_rate": 1.3668620796050602e-06,
      "loss": 0.0,
      "step": 157620
    },
    {
      "epoch": 48.63622338784326,
      "grad_norm": 1.2342867421466508e-06,
      "learning_rate": 1.3637766121567418e-06,
      "loss": 0.0,
      "step": 157630
    },
    {
      "epoch": 48.639308855291574,
      "grad_norm": 1.0665692116162973e-06,
      "learning_rate": 1.3606911447084234e-06,
      "loss": 0.0,
      "step": 157640
    },
    {
      "epoch": 48.6423943227399,
      "grad_norm": 1.2311075181514752e-07,
      "learning_rate": 1.3576056772601048e-06,
      "loss": 0.0,
      "step": 157650
    },
    {
      "epoch": 48.64547979018821,
      "grad_norm": 4.0383813626476694e-08,
      "learning_rate": 1.3545202098117867e-06,
      "loss": 0.0,
      "step": 157660
    },
    {
      "epoch": 48.648565257636534,
      "grad_norm": 2.2518260323067807e-07,
      "learning_rate": 1.3514347423634681e-06,
      "loss": 0.0,
      "step": 157670
    },
    {
      "epoch": 48.65165072508485,
      "grad_norm": 2.897099420806626e-06,
      "learning_rate": 1.3483492749151497e-06,
      "loss": 0.0,
      "step": 157680
    },
    {
      "epoch": 48.65473619253317,
      "grad_norm": 2.5466613351454725e-07,
      "learning_rate": 1.3452638074668314e-06,
      "loss": 0.0,
      "step": 157690
    },
    {
      "epoch": 48.65782165998149,
      "grad_norm": 1.1105178145953687e-06,
      "learning_rate": 1.3421783400185128e-06,
      "loss": 0.0,
      "step": 157700
    },
    {
      "epoch": 48.66090712742981,
      "grad_norm": 0.00016425417561549693,
      "learning_rate": 1.3390928725701946e-06,
      "loss": 0.0,
      "step": 157710
    },
    {
      "epoch": 48.663992594878124,
      "grad_norm": 8.618570745966281e-08,
      "learning_rate": 1.336007405121876e-06,
      "loss": 0.0,
      "step": 157720
    },
    {
      "epoch": 48.66707806232644,
      "grad_norm": 9.218499297247718e-10,
      "learning_rate": 1.3329219376735575e-06,
      "loss": 0.0,
      "step": 157730
    },
    {
      "epoch": 48.67016352977476,
      "grad_norm": 5.729262556997128e-05,
      "learning_rate": 1.3298364702252393e-06,
      "loss": 0.0,
      "step": 157740
    },
    {
      "epoch": 48.67324899722308,
      "grad_norm": 8.360198080481496e-06,
      "learning_rate": 1.3267510027769207e-06,
      "loss": 0.0,
      "step": 157750
    },
    {
      "epoch": 48.6763344646714,
      "grad_norm": 3.0332874302985147e-05,
      "learning_rate": 1.3236655353286024e-06,
      "loss": 0.0,
      "step": 157760
    },
    {
      "epoch": 48.679419932119714,
      "grad_norm": 4.842743983601849e-09,
      "learning_rate": 1.320580067880284e-06,
      "loss": 0.0,
      "step": 157770
    },
    {
      "epoch": 48.682505399568036,
      "grad_norm": 4.501832506775827e-08,
      "learning_rate": 1.3174946004319654e-06,
      "loss": 0.0,
      "step": 157780
    },
    {
      "epoch": 48.68559086701635,
      "grad_norm": 1.0572999542546313e-07,
      "learning_rate": 1.3144091329836472e-06,
      "loss": 0.0,
      "step": 157790
    },
    {
      "epoch": 48.688676334464674,
      "grad_norm": 7.052838554955088e-06,
      "learning_rate": 1.3113236655353287e-06,
      "loss": 0.0,
      "step": 157800
    },
    {
      "epoch": 48.69176180191299,
      "grad_norm": 6.24591630185023e-05,
      "learning_rate": 1.30823819808701e-06,
      "loss": 0.0,
      "step": 157810
    },
    {
      "epoch": 48.69484726936131,
      "grad_norm": 8.630601788794934e-10,
      "learning_rate": 1.305152730638692e-06,
      "loss": 0.0,
      "step": 157820
    },
    {
      "epoch": 48.697932736809626,
      "grad_norm": 1.048846343110199e-06,
      "learning_rate": 1.3020672631903733e-06,
      "loss": 0.0004,
      "step": 157830
    },
    {
      "epoch": 48.70101820425794,
      "grad_norm": 1.4890468946759938e-06,
      "learning_rate": 1.298981795742055e-06,
      "loss": 0.0,
      "step": 157840
    },
    {
      "epoch": 48.704103671706264,
      "grad_norm": 0.000219703113543801,
      "learning_rate": 1.2958963282937366e-06,
      "loss": 0.0,
      "step": 157850
    },
    {
      "epoch": 48.70718913915458,
      "grad_norm": 5.599849259851908e-07,
      "learning_rate": 1.292810860845418e-06,
      "loss": 0.0,
      "step": 157860
    },
    {
      "epoch": 48.7102746066029,
      "grad_norm": 3.195493425423024e-09,
      "learning_rate": 1.2897253933970999e-06,
      "loss": 0.0,
      "step": 157870
    },
    {
      "epoch": 48.71336007405122,
      "grad_norm": 0.0005925786681473255,
      "learning_rate": 1.2866399259487813e-06,
      "loss": 0.0,
      "step": 157880
    },
    {
      "epoch": 48.71644554149954,
      "grad_norm": 0.0038468861021101475,
      "learning_rate": 1.283554458500463e-06,
      "loss": 0.0,
      "step": 157890
    },
    {
      "epoch": 48.719531008947854,
      "grad_norm": 3.2615521394774305e-09,
      "learning_rate": 1.2804689910521445e-06,
      "loss": 0.0,
      "step": 157900
    },
    {
      "epoch": 48.722616476396176,
      "grad_norm": 6.272582027122553e-07,
      "learning_rate": 1.277383523603826e-06,
      "loss": 0.0,
      "step": 157910
    },
    {
      "epoch": 48.72570194384449,
      "grad_norm": 5.508564981937525e-07,
      "learning_rate": 1.2742980561555076e-06,
      "loss": 0.0,
      "step": 157920
    },
    {
      "epoch": 48.728787411292814,
      "grad_norm": 2.0662598743115268e-08,
      "learning_rate": 1.2712125887071892e-06,
      "loss": 0.0,
      "step": 157930
    },
    {
      "epoch": 48.73187287874113,
      "grad_norm": 1.3038553333899472e-05,
      "learning_rate": 1.2681271212588708e-06,
      "loss": 0.0,
      "step": 157940
    },
    {
      "epoch": 48.73495834618945,
      "grad_norm": 1.0680004436380841e-07,
      "learning_rate": 1.2650416538105525e-06,
      "loss": 0.0,
      "step": 157950
    },
    {
      "epoch": 48.738043813637766,
      "grad_norm": 3.661427626866498e-06,
      "learning_rate": 1.2619561863622339e-06,
      "loss": 0.0,
      "step": 157960
    },
    {
      "epoch": 48.74112928108608,
      "grad_norm": 0.0010129633592441678,
      "learning_rate": 1.2588707189139155e-06,
      "loss": 0.0,
      "step": 157970
    },
    {
      "epoch": 48.744214748534404,
      "grad_norm": 3.769356681004865e-06,
      "learning_rate": 1.2557852514655972e-06,
      "loss": 0.0,
      "step": 157980
    },
    {
      "epoch": 48.74730021598272,
      "grad_norm": 0.21521255373954773,
      "learning_rate": 1.2526997840172788e-06,
      "loss": 0.0,
      "step": 157990
    },
    {
      "epoch": 48.75038568343104,
      "grad_norm": 1.2653780686378013e-05,
      "learning_rate": 1.2496143165689602e-06,
      "loss": 0.0,
      "step": 158000
    },
    {
      "epoch": 48.753471150879356,
      "grad_norm": 1.0856901866418411e-07,
      "learning_rate": 1.2465288491206418e-06,
      "loss": 0.0,
      "step": 158010
    },
    {
      "epoch": 48.75655661832768,
      "grad_norm": 1.5332258044509217e-05,
      "learning_rate": 1.2434433816723235e-06,
      "loss": 0.0,
      "step": 158020
    },
    {
      "epoch": 48.759642085775994,
      "grad_norm": 2.5903681422079217e-09,
      "learning_rate": 1.2403579142240049e-06,
      "loss": 0.0,
      "step": 158030
    },
    {
      "epoch": 48.762727553224316,
      "grad_norm": 1.280949504689488e-06,
      "learning_rate": 1.2372724467756865e-06,
      "loss": 0.0,
      "step": 158040
    },
    {
      "epoch": 48.76581302067263,
      "grad_norm": 1.0361201248088037e-06,
      "learning_rate": 1.2341869793273681e-06,
      "loss": 0.0,
      "step": 158050
    },
    {
      "epoch": 48.76889848812095,
      "grad_norm": 1.2952141332789324e-06,
      "learning_rate": 1.2311015118790498e-06,
      "loss": 0.0,
      "step": 158060
    },
    {
      "epoch": 48.77198395556927,
      "grad_norm": 3.6706862829305464e-06,
      "learning_rate": 1.2280160444307314e-06,
      "loss": 0.0,
      "step": 158070
    },
    {
      "epoch": 48.775069423017584,
      "grad_norm": 0.00029722414910793304,
      "learning_rate": 1.2249305769824128e-06,
      "loss": 0.0,
      "step": 158080
    },
    {
      "epoch": 48.778154890465906,
      "grad_norm": 4.05413288717682e-07,
      "learning_rate": 1.2218451095340944e-06,
      "loss": 0.0,
      "step": 158090
    },
    {
      "epoch": 48.78124035791422,
      "grad_norm": 2.4823395960993366e-06,
      "learning_rate": 1.218759642085776e-06,
      "loss": 0.0,
      "step": 158100
    },
    {
      "epoch": 48.784325825362544,
      "grad_norm": 2.864497946575284e-05,
      "learning_rate": 1.2156741746374575e-06,
      "loss": 0.0,
      "step": 158110
    },
    {
      "epoch": 48.78741129281086,
      "grad_norm": 5.447800504043698e-07,
      "learning_rate": 1.2125887071891393e-06,
      "loss": 0.0,
      "step": 158120
    },
    {
      "epoch": 48.79049676025918,
      "grad_norm": 0.000271215831162408,
      "learning_rate": 1.2095032397408208e-06,
      "loss": 0.0,
      "step": 158130
    },
    {
      "epoch": 48.793582227707496,
      "grad_norm": 4.61420590625039e-09,
      "learning_rate": 1.2064177722925024e-06,
      "loss": 0.0,
      "step": 158140
    },
    {
      "epoch": 48.79666769515582,
      "grad_norm": 8.044619789870922e-06,
      "learning_rate": 1.203332304844184e-06,
      "loss": 0.0,
      "step": 158150
    },
    {
      "epoch": 48.799753162604134,
      "grad_norm": 2.0174073966927608e-08,
      "learning_rate": 1.2002468373958654e-06,
      "loss": 0.0,
      "step": 158160
    },
    {
      "epoch": 48.802838630052456,
      "grad_norm": 2.3381817015888373e-07,
      "learning_rate": 1.1971613699475473e-06,
      "loss": 0.0,
      "step": 158170
    },
    {
      "epoch": 48.80592409750077,
      "grad_norm": 1.7127615137724206e-05,
      "learning_rate": 1.1940759024992287e-06,
      "loss": 0.0,
      "step": 158180
    },
    {
      "epoch": 48.80900956494909,
      "grad_norm": 6.232552891560772e-07,
      "learning_rate": 1.1909904350509101e-06,
      "loss": 0.0,
      "step": 158190
    },
    {
      "epoch": 48.81209503239741,
      "grad_norm": 7.488429787372297e-08,
      "learning_rate": 1.187904967602592e-06,
      "loss": 0.0,
      "step": 158200
    },
    {
      "epoch": 48.815180499845724,
      "grad_norm": 6.037634193489794e-06,
      "learning_rate": 1.1848195001542734e-06,
      "loss": 0.0,
      "step": 158210
    },
    {
      "epoch": 48.818265967294046,
      "grad_norm": 0.0003859042190015316,
      "learning_rate": 1.181734032705955e-06,
      "loss": 0.0,
      "step": 158220
    },
    {
      "epoch": 48.82135143474236,
      "grad_norm": 1.8590011677588336e-05,
      "learning_rate": 1.1786485652576366e-06,
      "loss": 0.0,
      "step": 158230
    },
    {
      "epoch": 48.82443690219068,
      "grad_norm": 3.1375475373351946e-06,
      "learning_rate": 1.175563097809318e-06,
      "loss": 0.0,
      "step": 158240
    },
    {
      "epoch": 48.827522369639,
      "grad_norm": 4.350858784363254e-09,
      "learning_rate": 1.1724776303609999e-06,
      "loss": 0.0,
      "step": 158250
    },
    {
      "epoch": 48.83060783708732,
      "grad_norm": 2.4636452167214884e-07,
      "learning_rate": 1.1693921629126813e-06,
      "loss": 0.0,
      "step": 158260
    },
    {
      "epoch": 48.833693304535636,
      "grad_norm": 9.663025046791063e-09,
      "learning_rate": 1.1663066954643627e-06,
      "loss": 0.0,
      "step": 158270
    },
    {
      "epoch": 48.83677877198396,
      "grad_norm": 2.5715408469295653e-08,
      "learning_rate": 1.1632212280160446e-06,
      "loss": 0.0,
      "step": 158280
    },
    {
      "epoch": 48.83986423943227,
      "grad_norm": 3.743034326930683e-08,
      "learning_rate": 1.160135760567726e-06,
      "loss": 0.0,
      "step": 158290
    },
    {
      "epoch": 48.842949706880596,
      "grad_norm": 9.13722124096239e-06,
      "learning_rate": 1.1570502931194076e-06,
      "loss": 0.0,
      "step": 158300
    },
    {
      "epoch": 48.84603517432891,
      "grad_norm": 5.727321763515647e-07,
      "learning_rate": 1.1539648256710892e-06,
      "loss": 0.0,
      "step": 158310
    },
    {
      "epoch": 48.849120641777226,
      "grad_norm": 6.32613300695084e-05,
      "learning_rate": 1.1508793582227707e-06,
      "loss": 0.0,
      "step": 158320
    },
    {
      "epoch": 48.85220610922555,
      "grad_norm": 5.99925229494147e-08,
      "learning_rate": 1.1477938907744525e-06,
      "loss": 0.0,
      "step": 158330
    },
    {
      "epoch": 48.855291576673864,
      "grad_norm": 1.8277029312230297e-07,
      "learning_rate": 1.144708423326134e-06,
      "loss": 0.0,
      "step": 158340
    },
    {
      "epoch": 48.858377044122186,
      "grad_norm": 5.9005937913525486e-08,
      "learning_rate": 1.1416229558778156e-06,
      "loss": 0.0,
      "step": 158350
    },
    {
      "epoch": 48.8614625115705,
      "grad_norm": 0.00021706130064558238,
      "learning_rate": 1.1385374884294972e-06,
      "loss": 0.0,
      "step": 158360
    },
    {
      "epoch": 48.86454797901882,
      "grad_norm": 2.135200475095189e-06,
      "learning_rate": 1.1354520209811786e-06,
      "loss": 0.0,
      "step": 158370
    },
    {
      "epoch": 48.86763344646714,
      "grad_norm": 6.187612598296255e-05,
      "learning_rate": 1.1323665535328602e-06,
      "loss": 0.0,
      "step": 158380
    },
    {
      "epoch": 48.87071891391546,
      "grad_norm": 4.6776634121670213e-07,
      "learning_rate": 1.1292810860845419e-06,
      "loss": 0.0,
      "step": 158390
    },
    {
      "epoch": 48.873804381363776,
      "grad_norm": 2.0025306639581686e-06,
      "learning_rate": 1.1261956186362235e-06,
      "loss": 0.0,
      "step": 158400
    },
    {
      "epoch": 48.8768898488121,
      "grad_norm": 7.351903605012922e-06,
      "learning_rate": 1.1231101511879051e-06,
      "loss": 0.0,
      "step": 158410
    },
    {
      "epoch": 48.87997531626041,
      "grad_norm": 5.451550805446459e-06,
      "learning_rate": 1.1200246837395865e-06,
      "loss": 0.0,
      "step": 158420
    },
    {
      "epoch": 48.88306078370873,
      "grad_norm": 3.600408490456175e-06,
      "learning_rate": 1.1169392162912682e-06,
      "loss": 0.0,
      "step": 158430
    },
    {
      "epoch": 48.88614625115705,
      "grad_norm": 2.568668378444272e-06,
      "learning_rate": 1.1138537488429498e-06,
      "loss": 0.0,
      "step": 158440
    },
    {
      "epoch": 48.889231718605366,
      "grad_norm": 2.3328526367549784e-05,
      "learning_rate": 1.1107682813946312e-06,
      "loss": 0.0,
      "step": 158450
    },
    {
      "epoch": 48.89231718605369,
      "grad_norm": 3.199656930519268e-05,
      "learning_rate": 1.1076828139463128e-06,
      "loss": 0.0,
      "step": 158460
    },
    {
      "epoch": 48.895402653502,
      "grad_norm": 6.059487077436643e-06,
      "learning_rate": 1.1045973464979945e-06,
      "loss": 0.0,
      "step": 158470
    },
    {
      "epoch": 48.898488120950326,
      "grad_norm": 0.00014685877249576151,
      "learning_rate": 1.1015118790496761e-06,
      "loss": 0.0,
      "step": 158480
    },
    {
      "epoch": 48.90157358839864,
      "grad_norm": 3.79322614207922e-07,
      "learning_rate": 1.0984264116013577e-06,
      "loss": 0.0,
      "step": 158490
    },
    {
      "epoch": 48.90465905584696,
      "grad_norm": 8.191224196707481e-07,
      "learning_rate": 1.0953409441530392e-06,
      "loss": 0.0,
      "step": 158500
    },
    {
      "epoch": 48.90774452329528,
      "grad_norm": 1.0310395026635888e-07,
      "learning_rate": 1.0922554767047208e-06,
      "loss": 0.0,
      "step": 158510
    },
    {
      "epoch": 48.9108299907436,
      "grad_norm": 2.6097830563287516e-09,
      "learning_rate": 1.0891700092564024e-06,
      "loss": 0.0,
      "step": 158520
    },
    {
      "epoch": 48.913915458191916,
      "grad_norm": 3.65445451677715e-08,
      "learning_rate": 1.086084541808084e-06,
      "loss": 0.0,
      "step": 158530
    },
    {
      "epoch": 48.91700092564024,
      "grad_norm": 3.5662445441175805e-08,
      "learning_rate": 1.0829990743597655e-06,
      "loss": 0.0,
      "step": 158540
    },
    {
      "epoch": 48.92008639308855,
      "grad_norm": 2.2971377688918437e-08,
      "learning_rate": 1.079913606911447e-06,
      "loss": 0.0,
      "step": 158550
    },
    {
      "epoch": 48.92317186053687,
      "grad_norm": 1.5730540781078162e-06,
      "learning_rate": 1.0768281394631287e-06,
      "loss": 0.0,
      "step": 158560
    },
    {
      "epoch": 48.92625732798519,
      "grad_norm": 1.3600641977973282e-05,
      "learning_rate": 1.0737426720148104e-06,
      "loss": 0.0,
      "step": 158570
    },
    {
      "epoch": 48.929342795433506,
      "grad_norm": 1.1019737939932384e-06,
      "learning_rate": 1.070657204566492e-06,
      "loss": 0.0,
      "step": 158580
    },
    {
      "epoch": 48.93242826288183,
      "grad_norm": 8.833612064051977e-09,
      "learning_rate": 1.0675717371181734e-06,
      "loss": 0.0,
      "step": 158590
    },
    {
      "epoch": 48.93551373033014,
      "grad_norm": 1.891720946556319e-10,
      "learning_rate": 1.064486269669855e-06,
      "loss": 0.0,
      "step": 158600
    },
    {
      "epoch": 48.938599197778466,
      "grad_norm": 5.786697556686704e-07,
      "learning_rate": 1.0614008022215367e-06,
      "loss": 0.0,
      "step": 158610
    },
    {
      "epoch": 48.94168466522678,
      "grad_norm": 7.471709473350074e-09,
      "learning_rate": 1.058315334773218e-06,
      "loss": 0.0,
      "step": 158620
    },
    {
      "epoch": 48.9447701326751,
      "grad_norm": 1.6153954618403077e-07,
      "learning_rate": 1.0552298673248997e-06,
      "loss": 0.0,
      "step": 158630
    },
    {
      "epoch": 48.94785560012342,
      "grad_norm": 7.188381459855009e-06,
      "learning_rate": 1.0521443998765813e-06,
      "loss": 0.0,
      "step": 158640
    },
    {
      "epoch": 48.95094106757174,
      "grad_norm": 0.00012270917068235576,
      "learning_rate": 1.049058932428263e-06,
      "loss": 0.0,
      "step": 158650
    },
    {
      "epoch": 48.954026535020056,
      "grad_norm": 2.6784714890482064e-08,
      "learning_rate": 1.0459734649799446e-06,
      "loss": 0.0,
      "step": 158660
    },
    {
      "epoch": 48.95711200246837,
      "grad_norm": 8.345716082658328e-07,
      "learning_rate": 1.042887997531626e-06,
      "loss": 0.0,
      "step": 158670
    },
    {
      "epoch": 48.96019746991669,
      "grad_norm": 7.538943123108766e-07,
      "learning_rate": 1.0398025300833076e-06,
      "loss": 0.0,
      "step": 158680
    },
    {
      "epoch": 48.96328293736501,
      "grad_norm": 3.2671380267856875e-07,
      "learning_rate": 1.0367170626349893e-06,
      "loss": 0.0,
      "step": 158690
    },
    {
      "epoch": 48.96636840481333,
      "grad_norm": 9.179735194209115e-09,
      "learning_rate": 1.0336315951866707e-06,
      "loss": 0.0,
      "step": 158700
    },
    {
      "epoch": 48.969453872261646,
      "grad_norm": 1.5139503872774185e-08,
      "learning_rate": 1.0305461277383525e-06,
      "loss": 0.0,
      "step": 158710
    },
    {
      "epoch": 48.97253933970997,
      "grad_norm": 2.045964720309712e-06,
      "learning_rate": 1.027460660290034e-06,
      "loss": 0.0,
      "step": 158720
    },
    {
      "epoch": 48.97562480715828,
      "grad_norm": 6.279918807194917e-07,
      "learning_rate": 1.0243751928417156e-06,
      "loss": 0.0,
      "step": 158730
    },
    {
      "epoch": 48.978710274606605,
      "grad_norm": 1.7842145538793375e-08,
      "learning_rate": 1.0212897253933972e-06,
      "loss": 0.0,
      "step": 158740
    },
    {
      "epoch": 48.98179574205492,
      "grad_norm": 4.745846524656372e-07,
      "learning_rate": 1.0182042579450786e-06,
      "loss": 0.0,
      "step": 158750
    },
    {
      "epoch": 48.98488120950324,
      "grad_norm": 1.8773473584587919e-06,
      "learning_rate": 1.0151187904967605e-06,
      "loss": 0.0,
      "step": 158760
    },
    {
      "epoch": 48.98796667695156,
      "grad_norm": 3.6285204887390137,
      "learning_rate": 1.012033323048442e-06,
      "loss": 0.0014,
      "step": 158770
    },
    {
      "epoch": 48.99105214439987,
      "grad_norm": 6.783202888271944e-09,
      "learning_rate": 1.0089478556001233e-06,
      "loss": 0.0,
      "step": 158780
    },
    {
      "epoch": 48.994137611848195,
      "grad_norm": 1.869552335165281e-07,
      "learning_rate": 1.0058623881518052e-06,
      "loss": 0.0,
      "step": 158790
    },
    {
      "epoch": 48.99722307929651,
      "grad_norm": 1.960415829671547e-06,
      "learning_rate": 1.0027769207034866e-06,
      "loss": 0.0,
      "step": 158800
    },
    {
      "epoch": 49.0,
      "eval_accuracy_branch1": 1.0,
      "eval_accuracy_branch2": 0.41900793765612493,
      "eval_f1_branch1": 1.0,
      "eval_f1_branch2": 0.4135856847437157,
      "eval_loss": 6.614653358383293e-08,
      "eval_precision_branch1": 1.0,
      "eval_precision_branch2": 0.5091424571102336,
      "eval_recall_branch1": 1.0,
      "eval_recall_branch2": 0.5074433610138596,
      "eval_runtime": 133.5458,
      "eval_samples_per_second": 776.386,
      "eval_steps_per_second": 97.053,
      "step": 158809
    },
    {
      "epoch": 49.00030854674483,
      "grad_norm": 4.350498433725036e-11,
      "learning_rate": 9.996914532551682e-07,
      "loss": 0.0001,
      "step": 158810
    },
    {
      "epoch": 49.00339401419315,
      "grad_norm": 8.10645162108159e-10,
      "learning_rate": 9.966059858068498e-07,
      "loss": 0.0,
      "step": 158820
    },
    {
      "epoch": 49.00647948164147,
      "grad_norm": 1.653772756071703e-06,
      "learning_rate": 9.935205183585313e-07,
      "loss": 0.0,
      "step": 158830
    },
    {
      "epoch": 49.009564949089786,
      "grad_norm": 0.0012999902246519923,
      "learning_rate": 9.90435050910213e-07,
      "loss": 0.0,
      "step": 158840
    },
    {
      "epoch": 49.01265041653811,
      "grad_norm": 6.949153430468868e-07,
      "learning_rate": 9.873495834618945e-07,
      "loss": 0.0,
      "step": 158850
    },
    {
      "epoch": 49.01573588398642,
      "grad_norm": 2.0438355932128616e-06,
      "learning_rate": 9.84264116013576e-07,
      "loss": 0.0,
      "step": 158860
    },
    {
      "epoch": 49.018821351434745,
      "grad_norm": 3.044916496719452e-08,
      "learning_rate": 9.811786485652578e-07,
      "loss": 0.0,
      "step": 158870
    },
    {
      "epoch": 49.02190681888306,
      "grad_norm": 1.1752864566005883e-06,
      "learning_rate": 9.780931811169392e-07,
      "loss": 0.0,
      "step": 158880
    },
    {
      "epoch": 49.02499228633138,
      "grad_norm": 5.0374694637866924e-08,
      "learning_rate": 9.750077136686208e-07,
      "loss": 0.0,
      "step": 158890
    },
    {
      "epoch": 49.0280777537797,
      "grad_norm": 7.047256112002742e-09,
      "learning_rate": 9.719222462203024e-07,
      "loss": 0.0,
      "step": 158900
    },
    {
      "epoch": 49.03116322122801,
      "grad_norm": 1.226958011102397e-05,
      "learning_rate": 9.688367787719839e-07,
      "loss": 0.0,
      "step": 158910
    },
    {
      "epoch": 49.034248688676335,
      "grad_norm": 1.2190436216030776e-08,
      "learning_rate": 9.657513113236657e-07,
      "loss": 0.0,
      "step": 158920
    },
    {
      "epoch": 49.03733415612465,
      "grad_norm": 4.1885370727356985e-09,
      "learning_rate": 9.626658438753471e-07,
      "loss": 0.0,
      "step": 158930
    },
    {
      "epoch": 49.04041962357297,
      "grad_norm": 6.434676720346033e-07,
      "learning_rate": 9.595803764270288e-07,
      "loss": 0.0,
      "step": 158940
    },
    {
      "epoch": 49.04350509102129,
      "grad_norm": 1.5300933853268361e-07,
      "learning_rate": 9.564949089787104e-07,
      "loss": 0.0,
      "step": 158950
    },
    {
      "epoch": 49.04659055846961,
      "grad_norm": 1.1454936554855522e-08,
      "learning_rate": 9.534094415303918e-07,
      "loss": 0.0,
      "step": 158960
    },
    {
      "epoch": 49.049676025917925,
      "grad_norm": 7.245415645229514e-07,
      "learning_rate": 9.503239740820735e-07,
      "loss": 0.0,
      "step": 158970
    },
    {
      "epoch": 49.05276149336625,
      "grad_norm": 4.707178504759213e-06,
      "learning_rate": 9.472385066337551e-07,
      "loss": 0.0,
      "step": 158980
    },
    {
      "epoch": 49.05584696081456,
      "grad_norm": 6.820134217377927e-07,
      "learning_rate": 9.441530391854367e-07,
      "loss": 0.0,
      "step": 158990
    },
    {
      "epoch": 49.058932428262885,
      "grad_norm": 3.3700567314554064e-07,
      "learning_rate": 9.410675717371182e-07,
      "loss": 0.0,
      "step": 159000
    },
    {
      "epoch": 49.0620178957112,
      "grad_norm": 1.5281922969734296e-05,
      "learning_rate": 9.379821042887997e-07,
      "loss": 0.0,
      "step": 159010
    },
    {
      "epoch": 49.065103363159515,
      "grad_norm": 4.459214508756304e-08,
      "learning_rate": 9.348966368404815e-07,
      "loss": 0.0,
      "step": 159020
    },
    {
      "epoch": 49.06818883060784,
      "grad_norm": 2.1742622266174294e-05,
      "learning_rate": 9.318111693921629e-07,
      "loss": 0.0,
      "step": 159030
    },
    {
      "epoch": 49.07127429805615,
      "grad_norm": 5.096333666188002e-07,
      "learning_rate": 9.287257019438444e-07,
      "loss": 0.0,
      "step": 159040
    },
    {
      "epoch": 49.074359765504475,
      "grad_norm": 4.659691512642894e-07,
      "learning_rate": 9.256402344955262e-07,
      "loss": 0.0,
      "step": 159050
    },
    {
      "epoch": 49.07744523295279,
      "grad_norm": 3.987398486060556e-06,
      "learning_rate": 9.225547670472077e-07,
      "loss": 0.0,
      "step": 159060
    },
    {
      "epoch": 49.08053070040111,
      "grad_norm": 2.1940923033980653e-05,
      "learning_rate": 9.194692995988893e-07,
      "loss": 0.0,
      "step": 159070
    },
    {
      "epoch": 49.08361616784943,
      "grad_norm": 9.812128155317623e-06,
      "learning_rate": 9.163838321505708e-07,
      "loss": 0.0,
      "step": 159080
    },
    {
      "epoch": 49.08670163529775,
      "grad_norm": 2.7100420538772596e-06,
      "learning_rate": 9.132983647022524e-07,
      "loss": 0.0,
      "step": 159090
    },
    {
      "epoch": 49.089787102746065,
      "grad_norm": 8.72629346559961e-09,
      "learning_rate": 9.102128972539341e-07,
      "loss": 0.0,
      "step": 159100
    },
    {
      "epoch": 49.09287257019439,
      "grad_norm": 3.4142419735871954e-06,
      "learning_rate": 9.071274298056155e-07,
      "loss": 0.0,
      "step": 159110
    },
    {
      "epoch": 49.0959580376427,
      "grad_norm": 4.033308505313471e-05,
      "learning_rate": 9.040419623572972e-07,
      "loss": 0.0,
      "step": 159120
    },
    {
      "epoch": 49.09904350509102,
      "grad_norm": 0.00010912884317804128,
      "learning_rate": 9.009564949089788e-07,
      "loss": 0.0,
      "step": 159130
    },
    {
      "epoch": 49.10212897253934,
      "grad_norm": 1.9907257353679597e-07,
      "learning_rate": 8.978710274606603e-07,
      "loss": 0.0,
      "step": 159140
    },
    {
      "epoch": 49.105214439987655,
      "grad_norm": 5.300537964103569e-08,
      "learning_rate": 8.947855600123419e-07,
      "loss": 0.0,
      "step": 159150
    },
    {
      "epoch": 49.10829990743598,
      "grad_norm": 1.1892600326746106e-07,
      "learning_rate": 8.917000925640235e-07,
      "loss": 0.0,
      "step": 159160
    },
    {
      "epoch": 49.11138537488429,
      "grad_norm": 8.608656116848579e-07,
      "learning_rate": 8.886146251157052e-07,
      "loss": 0.0,
      "step": 159170
    },
    {
      "epoch": 49.114470842332615,
      "grad_norm": 4.550474841380492e-07,
      "learning_rate": 8.855291576673867e-07,
      "loss": 0.0,
      "step": 159180
    },
    {
      "epoch": 49.11755630978093,
      "grad_norm": 5.718855611291929e-09,
      "learning_rate": 8.824436902190681e-07,
      "loss": 0.0,
      "step": 159190
    },
    {
      "epoch": 49.12064177722925,
      "grad_norm": 4.947668230670388e-08,
      "learning_rate": 8.793582227707499e-07,
      "loss": 0.0,
      "step": 159200
    },
    {
      "epoch": 49.12372724467757,
      "grad_norm": 0.00012201208301121369,
      "learning_rate": 8.762727553224314e-07,
      "loss": 0.0,
      "step": 159210
    },
    {
      "epoch": 49.12681271212589,
      "grad_norm": 1.4614893188991118e-06,
      "learning_rate": 8.73187287874113e-07,
      "loss": 0.0,
      "step": 159220
    },
    {
      "epoch": 49.129898179574205,
      "grad_norm": 1.2972383956366684e-05,
      "learning_rate": 8.701018204257945e-07,
      "loss": 0.0,
      "step": 159230
    },
    {
      "epoch": 49.13298364702253,
      "grad_norm": 3.380509497219464e-06,
      "learning_rate": 8.670163529774761e-07,
      "loss": 0.0,
      "step": 159240
    },
    {
      "epoch": 49.13606911447084,
      "grad_norm": 2.648473673616536e-05,
      "learning_rate": 8.639308855291578e-07,
      "loss": 0.0,
      "step": 159250
    },
    {
      "epoch": 49.13915458191916,
      "grad_norm": 6.785267601117084e-07,
      "learning_rate": 8.608454180808392e-07,
      "loss": 0.0,
      "step": 159260
    },
    {
      "epoch": 49.14224004936748,
      "grad_norm": 1.6746045048421365e-06,
      "learning_rate": 8.577599506325207e-07,
      "loss": 0.0,
      "step": 159270
    },
    {
      "epoch": 49.145325516815795,
      "grad_norm": 2.5699003813883792e-08,
      "learning_rate": 8.546744831842025e-07,
      "loss": 0.0,
      "step": 159280
    },
    {
      "epoch": 49.14841098426412,
      "grad_norm": 1.1630441804300062e-05,
      "learning_rate": 8.51589015735884e-07,
      "loss": 0.0,
      "step": 159290
    },
    {
      "epoch": 49.15149645171243,
      "grad_norm": 1.858936826693025e-07,
      "learning_rate": 8.485035482875656e-07,
      "loss": 0.0,
      "step": 159300
    },
    {
      "epoch": 49.154581919160755,
      "grad_norm": 1.716973052623416e-08,
      "learning_rate": 8.454180808392472e-07,
      "loss": 0.0,
      "step": 159310
    },
    {
      "epoch": 49.15766738660907,
      "grad_norm": 1.061631519405637e-05,
      "learning_rate": 8.423326133909287e-07,
      "loss": 0.0,
      "step": 159320
    },
    {
      "epoch": 49.16075285405739,
      "grad_norm": 3.355724942366578e-08,
      "learning_rate": 8.392471459426104e-07,
      "loss": 0.0,
      "step": 159330
    },
    {
      "epoch": 49.16383832150571,
      "grad_norm": 9.900324221234769e-05,
      "learning_rate": 8.361616784942918e-07,
      "loss": 0.0,
      "step": 159340
    },
    {
      "epoch": 49.16692378895403,
      "grad_norm": 1.4401241060113534e-05,
      "learning_rate": 8.330762110459736e-07,
      "loss": 0.0,
      "step": 159350
    },
    {
      "epoch": 49.170009256402345,
      "grad_norm": 6.536350127817059e-08,
      "learning_rate": 8.299907435976551e-07,
      "loss": 0.0,
      "step": 159360
    },
    {
      "epoch": 49.17309472385066,
      "grad_norm": 2.52033078140812e-05,
      "learning_rate": 8.269052761493366e-07,
      "loss": 0.0,
      "step": 159370
    },
    {
      "epoch": 49.17618019129898,
      "grad_norm": 0.0007862058700993657,
      "learning_rate": 8.238198087010183e-07,
      "loss": 0.0,
      "step": 159380
    },
    {
      "epoch": 49.1792656587473,
      "grad_norm": 1.3909448171034455e-07,
      "learning_rate": 8.207343412526998e-07,
      "loss": 0.0,
      "step": 159390
    },
    {
      "epoch": 49.18235112619562,
      "grad_norm": 1.7092196458179387e-07,
      "learning_rate": 8.176488738043815e-07,
      "loss": 0.0,
      "step": 159400
    },
    {
      "epoch": 49.185436593643935,
      "grad_norm": 1.56741304380148e-08,
      "learning_rate": 8.14563406356063e-07,
      "loss": 0.0,
      "step": 159410
    },
    {
      "epoch": 49.18852206109226,
      "grad_norm": 1.385889873972701e-07,
      "learning_rate": 8.114779389077445e-07,
      "loss": 0.0,
      "step": 159420
    },
    {
      "epoch": 49.19160752854057,
      "grad_norm": 1.6104013411677442e-07,
      "learning_rate": 8.083924714594262e-07,
      "loss": 0.0,
      "step": 159430
    },
    {
      "epoch": 49.194692995988895,
      "grad_norm": 2.3439596930074913e-08,
      "learning_rate": 8.053070040111077e-07,
      "loss": 0.0,
      "step": 159440
    },
    {
      "epoch": 49.19777846343721,
      "grad_norm": 4.3401422544775414e-07,
      "learning_rate": 8.022215365627893e-07,
      "loss": 0.0,
      "step": 159450
    },
    {
      "epoch": 49.20086393088553,
      "grad_norm": 8.353773672808984e-09,
      "learning_rate": 7.991360691144709e-07,
      "loss": 0.0,
      "step": 159460
    },
    {
      "epoch": 49.20394939833385,
      "grad_norm": 3.965084260926233e-09,
      "learning_rate": 7.960506016661524e-07,
      "loss": 0.0,
      "step": 159470
    },
    {
      "epoch": 49.20703486578216,
      "grad_norm": 1.3105313882988412e-06,
      "learning_rate": 7.929651342178341e-07,
      "loss": 0.0,
      "step": 159480
    },
    {
      "epoch": 49.210120333230485,
      "grad_norm": 3.010776481460198e-06,
      "learning_rate": 7.898796667695157e-07,
      "loss": 0.0,
      "step": 159490
    },
    {
      "epoch": 49.2132058006788,
      "grad_norm": 5.078959830484564e-08,
      "learning_rate": 7.867941993211971e-07,
      "loss": 0.0002,
      "step": 159500
    },
    {
      "epoch": 49.21629126812712,
      "grad_norm": 4.226379132887814e-06,
      "learning_rate": 7.837087318728788e-07,
      "loss": 0.0,
      "step": 159510
    },
    {
      "epoch": 49.21937673557544,
      "grad_norm": 2.1464398258785877e-08,
      "learning_rate": 7.806232644245603e-07,
      "loss": 0.0,
      "step": 159520
    },
    {
      "epoch": 49.22246220302376,
      "grad_norm": 3.0727649313888605e-09,
      "learning_rate": 7.77537796976242e-07,
      "loss": 0.0,
      "step": 159530
    },
    {
      "epoch": 49.225547670472075,
      "grad_norm": 4.1918632120996335e-08,
      "learning_rate": 7.744523295279235e-07,
      "loss": 0.0,
      "step": 159540
    },
    {
      "epoch": 49.2286331379204,
      "grad_norm": 1.8509943799926987e-07,
      "learning_rate": 7.713668620796051e-07,
      "loss": 0.0,
      "step": 159550
    },
    {
      "epoch": 49.23171860536871,
      "grad_norm": 1.0258302609145176e-05,
      "learning_rate": 7.682813946312867e-07,
      "loss": 0.0,
      "step": 159560
    },
    {
      "epoch": 49.234804072817035,
      "grad_norm": 6.820403086749138e-07,
      "learning_rate": 7.651959271829683e-07,
      "loss": 0.0,
      "step": 159570
    },
    {
      "epoch": 49.23788954026535,
      "grad_norm": 3.527993541752039e-08,
      "learning_rate": 7.621104597346498e-07,
      "loss": 0.0,
      "step": 159580
    },
    {
      "epoch": 49.24097500771367,
      "grad_norm": 7.0529448947809215e-09,
      "learning_rate": 7.590249922863314e-07,
      "loss": 0.0,
      "step": 159590
    },
    {
      "epoch": 49.24406047516199,
      "grad_norm": 2.0557263269438408e-07,
      "learning_rate": 7.55939524838013e-07,
      "loss": 0.0,
      "step": 159600
    },
    {
      "epoch": 49.2471459426103,
      "grad_norm": 1.0728317647590302e-06,
      "learning_rate": 7.528540573896946e-07,
      "loss": 0.0,
      "step": 159610
    },
    {
      "epoch": 49.250231410058625,
      "grad_norm": 8.223659975215014e-09,
      "learning_rate": 7.497685899413761e-07,
      "loss": 0.0,
      "step": 159620
    },
    {
      "epoch": 49.25331687750694,
      "grad_norm": 2.6723884616330906e-07,
      "learning_rate": 7.466831224930577e-07,
      "loss": 0.0,
      "step": 159630
    },
    {
      "epoch": 49.25640234495526,
      "grad_norm": 6.226312798673916e-09,
      "learning_rate": 7.435976550447394e-07,
      "loss": 0.0,
      "step": 159640
    },
    {
      "epoch": 49.25948781240358,
      "grad_norm": 1.3375085927691543e-08,
      "learning_rate": 7.405121875964209e-07,
      "loss": 0.0,
      "step": 159650
    },
    {
      "epoch": 49.2625732798519,
      "grad_norm": 4.4812423993789707e-07,
      "learning_rate": 7.374267201481024e-07,
      "loss": 0.0,
      "step": 159660
    },
    {
      "epoch": 49.265658747300215,
      "grad_norm": 0.001818440156057477,
      "learning_rate": 7.34341252699784e-07,
      "loss": 0.0,
      "step": 159670
    },
    {
      "epoch": 49.26874421474854,
      "grad_norm": 3.328401135149761e-06,
      "learning_rate": 7.312557852514657e-07,
      "loss": 0.0,
      "step": 159680
    },
    {
      "epoch": 49.27182968219685,
      "grad_norm": 4.4109416119653133e-10,
      "learning_rate": 7.281703178031472e-07,
      "loss": 0.0,
      "step": 159690
    },
    {
      "epoch": 49.274915149645174,
      "grad_norm": 3.903524259385449e-07,
      "learning_rate": 7.250848503548288e-07,
      "loss": 0.0,
      "step": 159700
    },
    {
      "epoch": 49.27800061709349,
      "grad_norm": 1.0614052747826008e-08,
      "learning_rate": 7.219993829065103e-07,
      "loss": 0.0,
      "step": 159710
    },
    {
      "epoch": 49.281086084541805,
      "grad_norm": 5.746939280015795e-08,
      "learning_rate": 7.18913915458192e-07,
      "loss": 0.0,
      "step": 159720
    },
    {
      "epoch": 49.28417155199013,
      "grad_norm": 3.099085077451491e-08,
      "learning_rate": 7.158284480098735e-07,
      "loss": 0.0,
      "step": 159730
    },
    {
      "epoch": 49.28725701943844,
      "grad_norm": 8.649931260151789e-08,
      "learning_rate": 7.127429805615551e-07,
      "loss": 0.0,
      "step": 159740
    },
    {
      "epoch": 49.290342486886765,
      "grad_norm": 3.007359055118286e-07,
      "learning_rate": 7.096575131132367e-07,
      "loss": 0.0,
      "step": 159750
    },
    {
      "epoch": 49.29342795433508,
      "grad_norm": 0.0007177288644015789,
      "learning_rate": 7.065720456649183e-07,
      "loss": 0.0,
      "step": 159760
    },
    {
      "epoch": 49.2965134217834,
      "grad_norm": 1.8492667663849716e-07,
      "learning_rate": 7.034865782165998e-07,
      "loss": 0.0,
      "step": 159770
    },
    {
      "epoch": 49.29959888923172,
      "grad_norm": 2.3190491447167005e-06,
      "learning_rate": 7.004011107682814e-07,
      "loss": 0.0,
      "step": 159780
    },
    {
      "epoch": 49.30268435668004,
      "grad_norm": 2.261869440189912e-06,
      "learning_rate": 6.973156433199631e-07,
      "loss": 0.0,
      "step": 159790
    },
    {
      "epoch": 49.305769824128355,
      "grad_norm": 5.3429484978551045e-06,
      "learning_rate": 6.942301758716446e-07,
      "loss": 0.0,
      "step": 159800
    },
    {
      "epoch": 49.30885529157668,
      "grad_norm": 6.155264600238297e-07,
      "learning_rate": 6.911447084233261e-07,
      "loss": 0.0,
      "step": 159810
    },
    {
      "epoch": 49.31194075902499,
      "grad_norm": 1.6396488433656486e-07,
      "learning_rate": 6.880592409750077e-07,
      "loss": 0.0,
      "step": 159820
    },
    {
      "epoch": 49.31502622647331,
      "grad_norm": 1.3049763936123782e-07,
      "learning_rate": 6.849737735266894e-07,
      "loss": 0.0,
      "step": 159830
    },
    {
      "epoch": 49.31811169392163,
      "grad_norm": 1.7284671471884394e-08,
      "learning_rate": 6.818883060783709e-07,
      "loss": 0.0,
      "step": 159840
    },
    {
      "epoch": 49.321197161369945,
      "grad_norm": 2.0430145752925455e-07,
      "learning_rate": 6.788028386300524e-07,
      "loss": 0.0,
      "step": 159850
    },
    {
      "epoch": 49.32428262881827,
      "grad_norm": 2.121568201118862e-07,
      "learning_rate": 6.757173711817341e-07,
      "loss": 0.0,
      "step": 159860
    },
    {
      "epoch": 49.32736809626658,
      "grad_norm": 0.00045625693746842444,
      "learning_rate": 6.726319037334157e-07,
      "loss": 0.0,
      "step": 159870
    },
    {
      "epoch": 49.330453563714904,
      "grad_norm": 4.242184149916284e-05,
      "learning_rate": 6.695464362850973e-07,
      "loss": 0.0,
      "step": 159880
    },
    {
      "epoch": 49.33353903116322,
      "grad_norm": 3.376460000481529e-08,
      "learning_rate": 6.664609688367787e-07,
      "loss": 0.0,
      "step": 159890
    },
    {
      "epoch": 49.33662449861154,
      "grad_norm": 6.895940174445059e-08,
      "learning_rate": 6.633755013884604e-07,
      "loss": 0.0,
      "step": 159900
    },
    {
      "epoch": 49.33970996605986,
      "grad_norm": 8.415656338911504e-06,
      "learning_rate": 6.60290033940142e-07,
      "loss": 0.0,
      "step": 159910
    },
    {
      "epoch": 49.34279543350818,
      "grad_norm": 1.1702735719154589e-05,
      "learning_rate": 6.572045664918236e-07,
      "loss": 0.0,
      "step": 159920
    },
    {
      "epoch": 49.345880900956494,
      "grad_norm": 3.2958116662484827e-06,
      "learning_rate": 6.54119099043505e-07,
      "loss": 0.0,
      "step": 159930
    },
    {
      "epoch": 49.34896636840482,
      "grad_norm": 1.1103288066749428e-08,
      "learning_rate": 6.510336315951867e-07,
      "loss": 0.0,
      "step": 159940
    },
    {
      "epoch": 49.35205183585313,
      "grad_norm": 2.1922808457475185e-08,
      "learning_rate": 6.479481641468683e-07,
      "loss": 0.0,
      "step": 159950
    },
    {
      "epoch": 49.35513730330145,
      "grad_norm": 8.409845122514525e-07,
      "learning_rate": 6.448626966985499e-07,
      "loss": 0.0,
      "step": 159960
    },
    {
      "epoch": 49.35822277074977,
      "grad_norm": 1.9104270165826165e-07,
      "learning_rate": 6.417772292502315e-07,
      "loss": 0.0,
      "step": 159970
    },
    {
      "epoch": 49.361308238198085,
      "grad_norm": 6.472293534898199e-06,
      "learning_rate": 6.38691761801913e-07,
      "loss": 0.0,
      "step": 159980
    },
    {
      "epoch": 49.36439370564641,
      "grad_norm": 0.00011594346142373979,
      "learning_rate": 6.356062943535946e-07,
      "loss": 0.0,
      "step": 159990
    },
    {
      "epoch": 49.36747917309472,
      "grad_norm": 1.7324058717349544e-05,
      "learning_rate": 6.325208269052762e-07,
      "loss": 0.0,
      "step": 160000
    },
    {
      "epoch": 49.370564640543044,
      "grad_norm": 3.097885681313528e-08,
      "learning_rate": 6.294353594569578e-07,
      "loss": 0.0,
      "step": 160010
    },
    {
      "epoch": 49.37365010799136,
      "grad_norm": 0.00022789296053815633,
      "learning_rate": 6.263498920086394e-07,
      "loss": 0.0,
      "step": 160020
    },
    {
      "epoch": 49.37673557543968,
      "grad_norm": 9.688462159829214e-05,
      "learning_rate": 6.232644245603209e-07,
      "loss": 0.0,
      "step": 160030
    },
    {
      "epoch": 49.379821042888,
      "grad_norm": 1.57368958753068e-06,
      "learning_rate": 6.201789571120024e-07,
      "loss": 0.0,
      "step": 160040
    },
    {
      "epoch": 49.38290651033632,
      "grad_norm": 1.349776084680343e-06,
      "learning_rate": 6.170934896636841e-07,
      "loss": 0.0,
      "step": 160050
    },
    {
      "epoch": 49.385991977784634,
      "grad_norm": 1.3430997114483034e-06,
      "learning_rate": 6.140080222153657e-07,
      "loss": 0.0,
      "step": 160060
    },
    {
      "epoch": 49.38907744523295,
      "grad_norm": 8.319485459651332e-06,
      "learning_rate": 6.109225547670472e-07,
      "loss": 0.0,
      "step": 160070
    },
    {
      "epoch": 49.39216291268127,
      "grad_norm": 9.64342063980439e-08,
      "learning_rate": 6.078370873187287e-07,
      "loss": 0.0,
      "step": 160080
    },
    {
      "epoch": 49.39524838012959,
      "grad_norm": 5.911014159210026e-05,
      "learning_rate": 6.047516198704104e-07,
      "loss": 0.0,
      "step": 160090
    },
    {
      "epoch": 49.39833384757791,
      "grad_norm": 2.8903764359711204e-07,
      "learning_rate": 6.01666152422092e-07,
      "loss": 0.0,
      "step": 160100
    },
    {
      "epoch": 49.401419315026224,
      "grad_norm": 5.621911269848567e-10,
      "learning_rate": 5.985806849737736e-07,
      "loss": 0.0,
      "step": 160110
    },
    {
      "epoch": 49.40450478247455,
      "grad_norm": 4.118034979683216e-08,
      "learning_rate": 5.954952175254551e-07,
      "loss": 0.0,
      "step": 160120
    },
    {
      "epoch": 49.40759024992286,
      "grad_norm": 5.439543038221473e-09,
      "learning_rate": 5.924097500771367e-07,
      "loss": 0.0,
      "step": 160130
    },
    {
      "epoch": 49.410675717371184,
      "grad_norm": 7.251691247489589e-09,
      "learning_rate": 5.893242826288183e-07,
      "loss": 0.0,
      "step": 160140
    },
    {
      "epoch": 49.4137611848195,
      "grad_norm": 9.580548976373393e-07,
      "learning_rate": 5.862388151804999e-07,
      "loss": 0.0,
      "step": 160150
    },
    {
      "epoch": 49.41684665226782,
      "grad_norm": 8.840127520670649e-06,
      "learning_rate": 5.831533477321814e-07,
      "loss": 0.0,
      "step": 160160
    },
    {
      "epoch": 49.41993211971614,
      "grad_norm": 6.677001351818035e-08,
      "learning_rate": 5.80067880283863e-07,
      "loss": 0.0,
      "step": 160170
    },
    {
      "epoch": 49.42301758716445,
      "grad_norm": 6.994649083935656e-06,
      "learning_rate": 5.769824128355446e-07,
      "loss": 0.0,
      "step": 160180
    },
    {
      "epoch": 49.426103054612774,
      "grad_norm": 2.5220444399565167e-07,
      "learning_rate": 5.738969453872263e-07,
      "loss": 0.0,
      "step": 160190
    },
    {
      "epoch": 49.42918852206109,
      "grad_norm": 4.1595793476290055e-08,
      "learning_rate": 5.708114779389078e-07,
      "loss": 0.0,
      "step": 160200
    },
    {
      "epoch": 49.43227398950941,
      "grad_norm": 1.912713514684583e-06,
      "learning_rate": 5.677260104905893e-07,
      "loss": 0.0,
      "step": 160210
    },
    {
      "epoch": 49.43535945695773,
      "grad_norm": 1.1767314234134574e-08,
      "learning_rate": 5.646405430422709e-07,
      "loss": 0.0,
      "step": 160220
    },
    {
      "epoch": 49.43844492440605,
      "grad_norm": 3.7496526772429206e-08,
      "learning_rate": 5.615550755939526e-07,
      "loss": 0.0,
      "step": 160230
    },
    {
      "epoch": 49.441530391854364,
      "grad_norm": 1.7736663249223739e-09,
      "learning_rate": 5.584696081456341e-07,
      "loss": 0.0,
      "step": 160240
    },
    {
      "epoch": 49.44461585930269,
      "grad_norm": 1.0408743866818781e-09,
      "learning_rate": 5.553841406973156e-07,
      "loss": 0.0,
      "step": 160250
    },
    {
      "epoch": 49.447701326751,
      "grad_norm": 1.5444959089450094e-08,
      "learning_rate": 5.522986732489972e-07,
      "loss": 0.0,
      "step": 160260
    },
    {
      "epoch": 49.450786794199324,
      "grad_norm": 1.1445933978393441e-08,
      "learning_rate": 5.492132058006789e-07,
      "loss": 0.0,
      "step": 160270
    },
    {
      "epoch": 49.45387226164764,
      "grad_norm": 0.00016589430742897093,
      "learning_rate": 5.461277383523604e-07,
      "loss": 0.0,
      "step": 160280
    },
    {
      "epoch": 49.45695772909596,
      "grad_norm": 3.2556408768869005e-06,
      "learning_rate": 5.43042270904042e-07,
      "loss": 0.0,
      "step": 160290
    },
    {
      "epoch": 49.46004319654428,
      "grad_norm": 2.3155335426849888e-08,
      "learning_rate": 5.399568034557235e-07,
      "loss": 0.0,
      "step": 160300
    },
    {
      "epoch": 49.46312866399259,
      "grad_norm": 4.183920765399307e-08,
      "learning_rate": 5.368713360074052e-07,
      "loss": 0.0,
      "step": 160310
    },
    {
      "epoch": 49.466214131440914,
      "grad_norm": 4.207081190088502e-07,
      "learning_rate": 5.337858685590867e-07,
      "loss": 0.0,
      "step": 160320
    },
    {
      "epoch": 49.46929959888923,
      "grad_norm": 2.816752839862602e-06,
      "learning_rate": 5.307004011107683e-07,
      "loss": 0.0,
      "step": 160330
    },
    {
      "epoch": 49.47238506633755,
      "grad_norm": 0.00012116650759708136,
      "learning_rate": 5.276149336624499e-07,
      "loss": 0.0,
      "step": 160340
    },
    {
      "epoch": 49.47547053378587,
      "grad_norm": 1.0672180906112771e-05,
      "learning_rate": 5.245294662141315e-07,
      "loss": 0.0,
      "step": 160350
    },
    {
      "epoch": 49.47855600123419,
      "grad_norm": 4.23889275680267e-07,
      "learning_rate": 5.21443998765813e-07,
      "loss": 0.0,
      "step": 160360
    },
    {
      "epoch": 49.481641468682504,
      "grad_norm": 0.00020344305085018277,
      "learning_rate": 5.183585313174946e-07,
      "loss": 0.0,
      "step": 160370
    },
    {
      "epoch": 49.484726936130826,
      "grad_norm": 1.286260875588141e-08,
      "learning_rate": 5.152730638691763e-07,
      "loss": 0.0,
      "step": 160380
    },
    {
      "epoch": 49.48781240357914,
      "grad_norm": 1.3152568101304496e-07,
      "learning_rate": 5.121875964208578e-07,
      "loss": 0.0,
      "step": 160390
    },
    {
      "epoch": 49.490897871027464,
      "grad_norm": 1.518408225820167e-06,
      "learning_rate": 5.091021289725393e-07,
      "loss": 0.0,
      "step": 160400
    },
    {
      "epoch": 49.49398333847578,
      "grad_norm": 3.6111664769578056e-08,
      "learning_rate": 5.06016661524221e-07,
      "loss": 0.0,
      "step": 160410
    },
    {
      "epoch": 49.497068805924094,
      "grad_norm": 1.7687716535874642e-06,
      "learning_rate": 5.029311940759026e-07,
      "loss": 0.0,
      "step": 160420
    },
    {
      "epoch": 49.50015427337242,
      "grad_norm": 9.30086727635171e-08,
      "learning_rate": 4.998457266275841e-07,
      "loss": 0.0,
      "step": 160430
    },
    {
      "epoch": 49.50323974082073,
      "grad_norm": 1.2615038258445566e-06,
      "learning_rate": 4.967602591792656e-07,
      "loss": 0.0,
      "step": 160440
    },
    {
      "epoch": 49.506325208269054,
      "grad_norm": 4.349721348262392e-05,
      "learning_rate": 4.936747917309473e-07,
      "loss": 0.0,
      "step": 160450
    },
    {
      "epoch": 49.50941067571737,
      "grad_norm": 4.099014461189654e-09,
      "learning_rate": 4.905893242826289e-07,
      "loss": 0.0,
      "step": 160460
    },
    {
      "epoch": 49.51249614316569,
      "grad_norm": 1.5864106472918138e-08,
      "learning_rate": 4.875038568343104e-07,
      "loss": 0.0,
      "step": 160470
    },
    {
      "epoch": 49.51558161061401,
      "grad_norm": 1.5560744914822067e-09,
      "learning_rate": 4.844183893859919e-07,
      "loss": 0.0002,
      "step": 160480
    },
    {
      "epoch": 49.51866707806233,
      "grad_norm": 8.37255811347859e-08,
      "learning_rate": 4.813329219376736e-07,
      "loss": 0.0,
      "step": 160490
    },
    {
      "epoch": 49.521752545510644,
      "grad_norm": 5.234663603914669e-06,
      "learning_rate": 4.782474544893552e-07,
      "loss": 0.0,
      "step": 160500
    },
    {
      "epoch": 49.524838012958966,
      "grad_norm": 1.116458406613674e-05,
      "learning_rate": 4.7516198704103677e-07,
      "loss": 0.0,
      "step": 160510
    },
    {
      "epoch": 49.52792348040728,
      "grad_norm": 6.026875212228333e-07,
      "learning_rate": 4.7207651959271835e-07,
      "loss": 0.0,
      "step": 160520
    },
    {
      "epoch": 49.5310089478556,
      "grad_norm": 0.00020891064195893705,
      "learning_rate": 4.6899105214439987e-07,
      "loss": 0.0,
      "step": 160530
    },
    {
      "epoch": 49.53409441530392,
      "grad_norm": 5.302133843088086e-08,
      "learning_rate": 4.6590558469608145e-07,
      "loss": 0.0,
      "step": 160540
    },
    {
      "epoch": 49.537179882752234,
      "grad_norm": 8.561335107515333e-07,
      "learning_rate": 4.628201172477631e-07,
      "loss": 0.0,
      "step": 160550
    },
    {
      "epoch": 49.540265350200556,
      "grad_norm": 6.191216016304679e-06,
      "learning_rate": 4.5973464979944466e-07,
      "loss": 0.0,
      "step": 160560
    },
    {
      "epoch": 49.54335081764887,
      "grad_norm": 2.7996254203799253e-09,
      "learning_rate": 4.566491823511262e-07,
      "loss": 0.0,
      "step": 160570
    },
    {
      "epoch": 49.546436285097194,
      "grad_norm": 5.227709607424913e-07,
      "learning_rate": 4.5356371490280776e-07,
      "loss": 0.0,
      "step": 160580
    },
    {
      "epoch": 49.54952175254551,
      "grad_norm": 2.606058480125739e-08,
      "learning_rate": 4.504782474544894e-07,
      "loss": 0.0,
      "step": 160590
    },
    {
      "epoch": 49.55260721999383,
      "grad_norm": 2.2047031507099746e-06,
      "learning_rate": 4.4739278000617096e-07,
      "loss": 0.0,
      "step": 160600
    },
    {
      "epoch": 49.555692687442146,
      "grad_norm": 2.046139258027324e-08,
      "learning_rate": 4.443073125578526e-07,
      "loss": 0.0,
      "step": 160610
    },
    {
      "epoch": 49.55877815489047,
      "grad_norm": 1.4568050232810492e-07,
      "learning_rate": 4.4122184510953406e-07,
      "loss": 0.0,
      "step": 160620
    },
    {
      "epoch": 49.561863622338784,
      "grad_norm": 9.27901794511854e-07,
      "learning_rate": 4.381363776612157e-07,
      "loss": 0.0,
      "step": 160630
    },
    {
      "epoch": 49.564949089787106,
      "grad_norm": 1.4669843118042536e-10,
      "learning_rate": 4.3505091021289727e-07,
      "loss": 0.0,
      "step": 160640
    },
    {
      "epoch": 49.56803455723542,
      "grad_norm": 2.1254252260405337e-06,
      "learning_rate": 4.319654427645789e-07,
      "loss": 0.0,
      "step": 160650
    },
    {
      "epoch": 49.57112002468374,
      "grad_norm": 2.603698339953553e-05,
      "learning_rate": 4.2887997531626037e-07,
      "loss": 0.0,
      "step": 160660
    },
    {
      "epoch": 49.57420549213206,
      "grad_norm": 8.096809445135023e-09,
      "learning_rate": 4.25794507867942e-07,
      "loss": 0.0,
      "step": 160670
    },
    {
      "epoch": 49.577290959580374,
      "grad_norm": 0.0003097727312706411,
      "learning_rate": 4.227090404196236e-07,
      "loss": 0.0,
      "step": 160680
    },
    {
      "epoch": 49.580376427028696,
      "grad_norm": 4.733522462885276e-10,
      "learning_rate": 4.196235729713052e-07,
      "loss": 0.0,
      "step": 160690
    },
    {
      "epoch": 49.58346189447701,
      "grad_norm": 9.831863323483958e-09,
      "learning_rate": 4.165381055229868e-07,
      "loss": 0.0,
      "step": 160700
    },
    {
      "epoch": 49.586547361925334,
      "grad_norm": 6.952845433261245e-05,
      "learning_rate": 4.134526380746683e-07,
      "loss": 0.0,
      "step": 160710
    },
    {
      "epoch": 49.58963282937365,
      "grad_norm": 8.085926674539223e-05,
      "learning_rate": 4.103671706263499e-07,
      "loss": 0.0,
      "step": 160720
    },
    {
      "epoch": 49.59271829682197,
      "grad_norm": 1.8278595234733075e-05,
      "learning_rate": 4.072817031780315e-07,
      "loss": 0.0,
      "step": 160730
    },
    {
      "epoch": 49.595803764270286,
      "grad_norm": 2.7404170396039262e-05,
      "learning_rate": 4.041962357297131e-07,
      "loss": 0.0,
      "step": 160740
    },
    {
      "epoch": 49.59888923171861,
      "grad_norm": 4.533479369683846e-09,
      "learning_rate": 4.0111076828139467e-07,
      "loss": 0.0,
      "step": 160750
    },
    {
      "epoch": 49.601974699166924,
      "grad_norm": 2.2108450625779597e-09,
      "learning_rate": 3.980253008330762e-07,
      "loss": 0.0,
      "step": 160760
    },
    {
      "epoch": 49.60506016661524,
      "grad_norm": 1.8458837303114706e-06,
      "learning_rate": 3.949398333847578e-07,
      "loss": 0.0,
      "step": 160770
    },
    {
      "epoch": 49.60814563406356,
      "grad_norm": 0.00022708070173393935,
      "learning_rate": 3.918543659364394e-07,
      "loss": 0.0,
      "step": 160780
    },
    {
      "epoch": 49.611231101511876,
      "grad_norm": 1.5126639496543248e-08,
      "learning_rate": 3.88768898488121e-07,
      "loss": 0.0,
      "step": 160790
    },
    {
      "epoch": 49.6143165689602,
      "grad_norm": 1.4825083781033754e-05,
      "learning_rate": 3.8568343103980256e-07,
      "loss": 0.0,
      "step": 160800
    },
    {
      "epoch": 49.617402036408514,
      "grad_norm": 8.509707938308964e-10,
      "learning_rate": 3.8259796359148413e-07,
      "loss": 0.0,
      "step": 160810
    },
    {
      "epoch": 49.620487503856836,
      "grad_norm": 4.518639684647496e-08,
      "learning_rate": 3.795124961431657e-07,
      "loss": 0.0,
      "step": 160820
    },
    {
      "epoch": 49.62357297130515,
      "grad_norm": 4.301482022128766e-06,
      "learning_rate": 3.764270286948473e-07,
      "loss": 0.0,
      "step": 160830
    },
    {
      "epoch": 49.62665843875347,
      "grad_norm": 2.016247663050308e-06,
      "learning_rate": 3.7334156124652886e-07,
      "loss": 0.0,
      "step": 160840
    },
    {
      "epoch": 49.62974390620179,
      "grad_norm": 6.044481182243544e-08,
      "learning_rate": 3.7025609379821044e-07,
      "loss": 0.0,
      "step": 160850
    },
    {
      "epoch": 49.63282937365011,
      "grad_norm": 7.207971748357522e-07,
      "learning_rate": 3.67170626349892e-07,
      "loss": 0.0,
      "step": 160860
    },
    {
      "epoch": 49.635914841098426,
      "grad_norm": 2.6310404791729525e-05,
      "learning_rate": 3.640851589015736e-07,
      "loss": 0.0,
      "step": 160870
    },
    {
      "epoch": 49.63900030854674,
      "grad_norm": 7.934466339065693e-06,
      "learning_rate": 3.6099969145325517e-07,
      "loss": 0.0008,
      "step": 160880
    },
    {
      "epoch": 49.642085775995064,
      "grad_norm": 1.2660723136548313e-08,
      "learning_rate": 3.5791422400493675e-07,
      "loss": 0.0,
      "step": 160890
    },
    {
      "epoch": 49.64517124344338,
      "grad_norm": 2.730540290940553e-05,
      "learning_rate": 3.548287565566183e-07,
      "loss": 0.0,
      "step": 160900
    },
    {
      "epoch": 49.6482567108917,
      "grad_norm": 2.6023993626722586e-08,
      "learning_rate": 3.517432891082999e-07,
      "loss": 0.0,
      "step": 160910
    },
    {
      "epoch": 49.651342178340016,
      "grad_norm": 5.12922255779813e-08,
      "learning_rate": 3.4865782165998153e-07,
      "loss": 0.0,
      "step": 160920
    },
    {
      "epoch": 49.65442764578834,
      "grad_norm": 1.5206360615138692e-07,
      "learning_rate": 3.4557235421166306e-07,
      "loss": 0.0,
      "step": 160930
    },
    {
      "epoch": 49.657513113236654,
      "grad_norm": 2.108504482123408e-09,
      "learning_rate": 3.424868867633447e-07,
      "loss": 0.0,
      "step": 160940
    },
    {
      "epoch": 49.660598580684976,
      "grad_norm": 2.476076055302201e-08,
      "learning_rate": 3.394014193150262e-07,
      "loss": 0.0,
      "step": 160950
    },
    {
      "epoch": 49.66368404813329,
      "grad_norm": 5.354884313746311e-10,
      "learning_rate": 3.3631595186670784e-07,
      "loss": 0.0,
      "step": 160960
    },
    {
      "epoch": 49.66676951558161,
      "grad_norm": 1.0166304491576739e-06,
      "learning_rate": 3.3323048441838937e-07,
      "loss": 0.0,
      "step": 160970
    },
    {
      "epoch": 49.66985498302993,
      "grad_norm": 1.813564813346602e-05,
      "learning_rate": 3.30145016970071e-07,
      "loss": 0.0,
      "step": 160980
    },
    {
      "epoch": 49.67294045047825,
      "grad_norm": 7.082722731865942e-05,
      "learning_rate": 3.270595495217525e-07,
      "loss": 0.0,
      "step": 160990
    },
    {
      "epoch": 49.676025917926566,
      "grad_norm": 1.284605787077453e-06,
      "learning_rate": 3.2397408207343415e-07,
      "loss": 0.0,
      "step": 161000
    },
    {
      "epoch": 49.67911138537488,
      "grad_norm": 1.7655700901286764e-08,
      "learning_rate": 3.2088861462511573e-07,
      "loss": 0.0,
      "step": 161010
    },
    {
      "epoch": 49.6821968528232,
      "grad_norm": 2.9109207844157936e-06,
      "learning_rate": 3.178031471767973e-07,
      "loss": 0.0,
      "step": 161020
    },
    {
      "epoch": 49.68528232027152,
      "grad_norm": 6.982612603678717e-07,
      "learning_rate": 3.147176797284789e-07,
      "loss": 0.0,
      "step": 161030
    },
    {
      "epoch": 49.68836778771984,
      "grad_norm": 5.275304815199888e-08,
      "learning_rate": 3.1163221228016046e-07,
      "loss": 0.0,
      "step": 161040
    },
    {
      "epoch": 49.691453255168156,
      "grad_norm": 0.0013777060667052865,
      "learning_rate": 3.0854674483184203e-07,
      "loss": 0.0,
      "step": 161050
    },
    {
      "epoch": 49.69453872261648,
      "grad_norm": 1.1428453944972716e-05,
      "learning_rate": 3.054612773835236e-07,
      "loss": 0.0,
      "step": 161060
    },
    {
      "epoch": 49.69762419006479,
      "grad_norm": 0.0014454975025728345,
      "learning_rate": 3.023758099352052e-07,
      "loss": 0.0,
      "step": 161070
    },
    {
      "epoch": 49.700709657513116,
      "grad_norm": 3.213391108758401e-09,
      "learning_rate": 2.992903424868868e-07,
      "loss": 0.0,
      "step": 161080
    },
    {
      "epoch": 49.70379512496143,
      "grad_norm": 3.2895397339416377e-07,
      "learning_rate": 2.9620487503856834e-07,
      "loss": 0.0,
      "step": 161090
    },
    {
      "epoch": 49.70688059240975,
      "grad_norm": 7.774578314467817e-09,
      "learning_rate": 2.9311940759024997e-07,
      "loss": 0.0,
      "step": 161100
    },
    {
      "epoch": 49.70996605985807,
      "grad_norm": 4.543553018265811e-07,
      "learning_rate": 2.900339401419315e-07,
      "loss": 0.0,
      "step": 161110
    },
    {
      "epoch": 49.71305152730638,
      "grad_norm": 9.806905154619017e-08,
      "learning_rate": 2.8694847269361313e-07,
      "loss": 0.0003,
      "step": 161120
    },
    {
      "epoch": 49.716136994754706,
      "grad_norm": 7.266639272529574e-07,
      "learning_rate": 2.8386300524529465e-07,
      "loss": 0.0,
      "step": 161130
    },
    {
      "epoch": 49.71922246220302,
      "grad_norm": 1.5773236050620199e-09,
      "learning_rate": 2.807775377969763e-07,
      "loss": 0.0,
      "step": 161140
    },
    {
      "epoch": 49.72230792965134,
      "grad_norm": 9.990536636905745e-05,
      "learning_rate": 2.776920703486578e-07,
      "loss": 0.0,
      "step": 161150
    },
    {
      "epoch": 49.72539339709966,
      "grad_norm": 1.9102037640550407e-06,
      "learning_rate": 2.7460660290033943e-07,
      "loss": 0.0,
      "step": 161160
    },
    {
      "epoch": 49.72847886454798,
      "grad_norm": 6.2174694903660566e-06,
      "learning_rate": 2.71521135452021e-07,
      "loss": 0.0,
      "step": 161170
    },
    {
      "epoch": 49.731564331996296,
      "grad_norm": 5.249889341030212e-07,
      "learning_rate": 2.684356680037026e-07,
      "loss": 0.0,
      "step": 161180
    },
    {
      "epoch": 49.73464979944462,
      "grad_norm": 9.680244693299755e-05,
      "learning_rate": 2.6535020055538417e-07,
      "loss": 0.0,
      "step": 161190
    },
    {
      "epoch": 49.73773526689293,
      "grad_norm": 2.3625883471822817e-08,
      "learning_rate": 2.6226473310706574e-07,
      "loss": 0.0,
      "step": 161200
    },
    {
      "epoch": 49.740820734341256,
      "grad_norm": 8.229656600633461e-07,
      "learning_rate": 2.591792656587473e-07,
      "loss": 0.0,
      "step": 161210
    },
    {
      "epoch": 49.74390620178957,
      "grad_norm": 2.915911863965448e-06,
      "learning_rate": 2.560937982104289e-07,
      "loss": 0.0,
      "step": 161220
    },
    {
      "epoch": 49.746991669237886,
      "grad_norm": 3.469630973995663e-05,
      "learning_rate": 2.530083307621105e-07,
      "loss": 0.0,
      "step": 161230
    },
    {
      "epoch": 49.75007713668621,
      "grad_norm": 2.728656681938446e-06,
      "learning_rate": 2.4992286331379205e-07,
      "loss": 0.0,
      "step": 161240
    },
    {
      "epoch": 49.75316260413452,
      "grad_norm": 1.1582226761674974e-05,
      "learning_rate": 2.4683739586547363e-07,
      "loss": 0.0,
      "step": 161250
    },
    {
      "epoch": 49.756248071582846,
      "grad_norm": 6.098821891953321e-09,
      "learning_rate": 2.437519284171552e-07,
      "loss": 0.0,
      "step": 161260
    },
    {
      "epoch": 49.75933353903116,
      "grad_norm": 6.616171594941989e-05,
      "learning_rate": 2.406664609688368e-07,
      "loss": 0.0,
      "step": 161270
    },
    {
      "epoch": 49.76241900647948,
      "grad_norm": 2.2752653094926245e-08,
      "learning_rate": 2.3758099352051839e-07,
      "loss": 0.0,
      "step": 161280
    },
    {
      "epoch": 49.7655044739278,
      "grad_norm": 1.0283290976076387e-05,
      "learning_rate": 2.3449552607219994e-07,
      "loss": 0.0,
      "step": 161290
    },
    {
      "epoch": 49.76858994137612,
      "grad_norm": 2.7972011594101787e-05,
      "learning_rate": 2.3141005862388154e-07,
      "loss": 0.0,
      "step": 161300
    },
    {
      "epoch": 49.771675408824436,
      "grad_norm": 1.6039491512742643e-08,
      "learning_rate": 2.283245911755631e-07,
      "loss": 0.0,
      "step": 161310
    },
    {
      "epoch": 49.77476087627276,
      "grad_norm": 5.56129293727281e-07,
      "learning_rate": 2.252391237272447e-07,
      "loss": 0.0,
      "step": 161320
    },
    {
      "epoch": 49.77784634372107,
      "grad_norm": 4.4942902377442806e-07,
      "learning_rate": 2.221536562789263e-07,
      "loss": 0.0,
      "step": 161330
    },
    {
      "epoch": 49.780931811169395,
      "grad_norm": 4.872218141827034e-06,
      "learning_rate": 2.1906818883060785e-07,
      "loss": 0.0,
      "step": 161340
    },
    {
      "epoch": 49.78401727861771,
      "grad_norm": 0.004126389045268297,
      "learning_rate": 2.1598272138228945e-07,
      "loss": 0.0,
      "step": 161350
    },
    {
      "epoch": 49.787102746066026,
      "grad_norm": 4.005777554993983e-06,
      "learning_rate": 2.12897253933971e-07,
      "loss": 0.0,
      "step": 161360
    },
    {
      "epoch": 49.79018821351435,
      "grad_norm": 2.5779256063174216e-08,
      "learning_rate": 2.098117864856526e-07,
      "loss": 0.0,
      "step": 161370
    },
    {
      "epoch": 49.79327368096266,
      "grad_norm": 0.0008202243479900062,
      "learning_rate": 2.0672631903733416e-07,
      "loss": 0.0,
      "step": 161380
    },
    {
      "epoch": 49.796359148410986,
      "grad_norm": 9.119229389398242e-07,
      "learning_rate": 2.0364085158901576e-07,
      "loss": 0.0,
      "step": 161390
    },
    {
      "epoch": 49.7994446158593,
      "grad_norm": 6.9072525477054114e-09,
      "learning_rate": 2.0055538414069734e-07,
      "loss": 0.0,
      "step": 161400
    },
    {
      "epoch": 49.80253008330762,
      "grad_norm": 1.471051518819877e-06,
      "learning_rate": 1.974699166923789e-07,
      "loss": 0.0,
      "step": 161410
    },
    {
      "epoch": 49.80561555075594,
      "grad_norm": 9.358712304674555e-06,
      "learning_rate": 1.943844492440605e-07,
      "loss": 0.0,
      "step": 161420
    },
    {
      "epoch": 49.80870101820426,
      "grad_norm": 2.4492894112881913e-07,
      "learning_rate": 1.9129898179574207e-07,
      "loss": 0.0,
      "step": 161430
    },
    {
      "epoch": 49.811786485652576,
      "grad_norm": 2.2246958053528942e-08,
      "learning_rate": 1.8821351434742364e-07,
      "loss": 0.0,
      "step": 161440
    },
    {
      "epoch": 49.8148719531009,
      "grad_norm": 3.692050754011689e-08,
      "learning_rate": 1.8512804689910522e-07,
      "loss": 0.0,
      "step": 161450
    },
    {
      "epoch": 49.81795742054921,
      "grad_norm": 1.2554222621474764e-06,
      "learning_rate": 1.820425794507868e-07,
      "loss": 0.0,
      "step": 161460
    },
    {
      "epoch": 49.82104288799753,
      "grad_norm": 4.638184558647396e-10,
      "learning_rate": 1.7895711200246837e-07,
      "loss": 0.0,
      "step": 161470
    },
    {
      "epoch": 49.82412835544585,
      "grad_norm": 0.0007399976020678878,
      "learning_rate": 1.7587164455414995e-07,
      "loss": 0.0,
      "step": 161480
    },
    {
      "epoch": 49.827213822894166,
      "grad_norm": 1.3228941497800406e-07,
      "learning_rate": 1.7278617710583153e-07,
      "loss": 0.0,
      "step": 161490
    },
    {
      "epoch": 49.83029929034249,
      "grad_norm": 5.470406563290453e-07,
      "learning_rate": 1.697007096575131e-07,
      "loss": 0.0,
      "step": 161500
    },
    {
      "epoch": 49.8333847577908,
      "grad_norm": 1.9286385395389516e-06,
      "learning_rate": 1.6661524220919468e-07,
      "loss": 0.0,
      "step": 161510
    },
    {
      "epoch": 49.836470225239125,
      "grad_norm": 3.162450923355209e-07,
      "learning_rate": 1.6352977476087626e-07,
      "loss": 0.0,
      "step": 161520
    },
    {
      "epoch": 49.83955569268744,
      "grad_norm": 8.468665413374765e-08,
      "learning_rate": 1.6044430731255786e-07,
      "loss": 0.0,
      "step": 161530
    },
    {
      "epoch": 49.84264116013576,
      "grad_norm": 5.998144479235634e-05,
      "learning_rate": 1.5735883986423944e-07,
      "loss": 0.0,
      "step": 161540
    },
    {
      "epoch": 49.84572662758408,
      "grad_norm": 7.8569763672931e-07,
      "learning_rate": 1.5427337241592102e-07,
      "loss": 0.0,
      "step": 161550
    },
    {
      "epoch": 49.8488120950324,
      "grad_norm": 3.5308001855582916e-08,
      "learning_rate": 1.511879049676026e-07,
      "loss": 0.0,
      "step": 161560
    },
    {
      "epoch": 49.851897562480715,
      "grad_norm": 0.001211368478834629,
      "learning_rate": 1.4810243751928417e-07,
      "loss": 0.0,
      "step": 161570
    },
    {
      "epoch": 49.85498302992904,
      "grad_norm": 3.2552411539654713e-06,
      "learning_rate": 1.4501697007096575e-07,
      "loss": 0.0,
      "step": 161580
    },
    {
      "epoch": 49.85806849737735,
      "grad_norm": 1.1004649635992791e-08,
      "learning_rate": 1.4193150262264733e-07,
      "loss": 0.0,
      "step": 161590
    },
    {
      "epoch": 49.86115396482567,
      "grad_norm": 2.9291391001606826e-07,
      "learning_rate": 1.388460351743289e-07,
      "loss": 0.0,
      "step": 161600
    },
    {
      "epoch": 49.86423943227399,
      "grad_norm": 3.679771543829702e-05,
      "learning_rate": 1.357605677260105e-07,
      "loss": 0.0,
      "step": 161610
    },
    {
      "epoch": 49.867324899722306,
      "grad_norm": 1.231885789820808e-06,
      "learning_rate": 1.3267510027769208e-07,
      "loss": 0.0,
      "step": 161620
    },
    {
      "epoch": 49.87041036717063,
      "grad_norm": 3.1762249363964656e-07,
      "learning_rate": 1.2958963282937366e-07,
      "loss": 0.0,
      "step": 161630
    },
    {
      "epoch": 49.87349583461894,
      "grad_norm": 0.0001465779059799388,
      "learning_rate": 1.2650416538105524e-07,
      "loss": 0.0,
      "step": 161640
    },
    {
      "epoch": 49.876581302067265,
      "grad_norm": 1.8236047338859862e-08,
      "learning_rate": 1.2341869793273681e-07,
      "loss": 0.0,
      "step": 161650
    },
    {
      "epoch": 49.87966676951558,
      "grad_norm": 2.516451104384032e-06,
      "learning_rate": 1.203332304844184e-07,
      "loss": 0.0,
      "step": 161660
    },
    {
      "epoch": 49.8827522369639,
      "grad_norm": 6.483532644097068e-08,
      "learning_rate": 1.1724776303609997e-07,
      "loss": 0.0,
      "step": 161670
    },
    {
      "epoch": 49.88583770441222,
      "grad_norm": 3.5151917927578324e-06,
      "learning_rate": 1.1416229558778154e-07,
      "loss": 0.0,
      "step": 161680
    },
    {
      "epoch": 49.88892317186054,
      "grad_norm": 6.429294074905556e-08,
      "learning_rate": 1.1107682813946315e-07,
      "loss": 0.0,
      "step": 161690
    },
    {
      "epoch": 49.892008639308855,
      "grad_norm": 3.310010470158886e-06,
      "learning_rate": 1.0799136069114473e-07,
      "loss": 0.0,
      "step": 161700
    },
    {
      "epoch": 49.89509410675717,
      "grad_norm": 2.238373708607355e-09,
      "learning_rate": 1.049058932428263e-07,
      "loss": 0.0,
      "step": 161710
    },
    {
      "epoch": 49.89817957420549,
      "grad_norm": 2.252667563595878e-08,
      "learning_rate": 1.0182042579450788e-07,
      "loss": 0.0,
      "step": 161720
    },
    {
      "epoch": 49.90126504165381,
      "grad_norm": 2.645238623699697e-07,
      "learning_rate": 9.873495834618946e-08,
      "loss": 0.0,
      "step": 161730
    },
    {
      "epoch": 49.90435050910213,
      "grad_norm": 1.2972130036814633e-09,
      "learning_rate": 9.564949089787103e-08,
      "loss": 0.0,
      "step": 161740
    },
    {
      "epoch": 49.907435976550445,
      "grad_norm": 4.371785507828463e-06,
      "learning_rate": 9.256402344955261e-08,
      "loss": 0.0,
      "step": 161750
    },
    {
      "epoch": 49.91052144399877,
      "grad_norm": 7.502666043990303e-09,
      "learning_rate": 8.947855600123419e-08,
      "loss": 0.0,
      "step": 161760
    },
    {
      "epoch": 49.91360691144708,
      "grad_norm": 2.520669450944979e-09,
      "learning_rate": 8.639308855291576e-08,
      "loss": 0.0,
      "step": 161770
    },
    {
      "epoch": 49.916692378895405,
      "grad_norm": 6.120895363892487e-07,
      "learning_rate": 8.330762110459734e-08,
      "loss": 0.0,
      "step": 161780
    },
    {
      "epoch": 49.91977784634372,
      "grad_norm": 3.2807334626738793e-09,
      "learning_rate": 8.022215365627893e-08,
      "loss": 0.0,
      "step": 161790
    },
    {
      "epoch": 49.92286331379204,
      "grad_norm": 4.1569148834241787e-07,
      "learning_rate": 7.713668620796051e-08,
      "loss": 0.0,
      "step": 161800
    },
    {
      "epoch": 49.92594878124036,
      "grad_norm": 4.0776788523544383e-07,
      "learning_rate": 7.405121875964209e-08,
      "loss": 0.0,
      "step": 161810
    },
    {
      "epoch": 49.92903424868867,
      "grad_norm": 4.581843768391991e-06,
      "learning_rate": 7.096575131132366e-08,
      "loss": 0.0,
      "step": 161820
    },
    {
      "epoch": 49.932119716136995,
      "grad_norm": 9.655540452513378e-06,
      "learning_rate": 6.788028386300525e-08,
      "loss": 0.0,
      "step": 161830
    },
    {
      "epoch": 49.93520518358531,
      "grad_norm": 2.6903139769274276e-06,
      "learning_rate": 6.479481641468683e-08,
      "loss": 0.0,
      "step": 161840
    },
    {
      "epoch": 49.93829065103363,
      "grad_norm": 3.145295934814385e-08,
      "learning_rate": 6.170934896636841e-08,
      "loss": 0.0,
      "step": 161850
    },
    {
      "epoch": 49.94137611848195,
      "grad_norm": 7.2150250218783185e-09,
      "learning_rate": 5.8623881518049984e-08,
      "loss": 0.0,
      "step": 161860
    },
    {
      "epoch": 49.94446158593027,
      "grad_norm": 1.637815572053114e-08,
      "learning_rate": 5.5538414069731574e-08,
      "loss": 0.0,
      "step": 161870
    },
    {
      "epoch": 49.947547053378585,
      "grad_norm": 3.481472532484986e-08,
      "learning_rate": 5.245294662141315e-08,
      "loss": 0.0,
      "step": 161880
    },
    {
      "epoch": 49.95063252082691,
      "grad_norm": 7.386540801235242e-07,
      "learning_rate": 4.936747917309473e-08,
      "loss": 0.0,
      "step": 161890
    },
    {
      "epoch": 49.95371798827522,
      "grad_norm": 1.0132830539077986e-06,
      "learning_rate": 4.6282011724776305e-08,
      "loss": 0.0001,
      "step": 161900
    },
    {
      "epoch": 49.956803455723545,
      "grad_norm": 4.572852390083426e-07,
      "learning_rate": 4.319654427645788e-08,
      "loss": 0.0,
      "step": 161910
    },
    {
      "epoch": 49.95988892317186,
      "grad_norm": 2.821690486598527e-06,
      "learning_rate": 4.0111076828139466e-08,
      "loss": 0.0,
      "step": 161920
    },
    {
      "epoch": 49.96297439062018,
      "grad_norm": 1.2376283997639348e-08,
      "learning_rate": 3.702560937982104e-08,
      "loss": 0.0,
      "step": 161930
    },
    {
      "epoch": 49.9660598580685,
      "grad_norm": 1.6369669708637957e-07,
      "learning_rate": 3.3940141931502626e-08,
      "loss": 0.0,
      "step": 161940
    },
    {
      "epoch": 49.96914532551681,
      "grad_norm": 0.002474321983754635,
      "learning_rate": 3.0854674483184203e-08,
      "loss": 0.0,
      "step": 161950
    },
    {
      "epoch": 49.972230792965135,
      "grad_norm": 2.1890972590199453e-08,
      "learning_rate": 2.7769207034865787e-08,
      "loss": 0.0,
      "step": 161960
    },
    {
      "epoch": 49.97531626041345,
      "grad_norm": 8.98172380914275e-09,
      "learning_rate": 2.4683739586547364e-08,
      "loss": 0.0,
      "step": 161970
    },
    {
      "epoch": 49.97840172786177,
      "grad_norm": 7.360096060438082e-05,
      "learning_rate": 2.159827213822894e-08,
      "loss": 0.0,
      "step": 161980
    },
    {
      "epoch": 49.98148719531009,
      "grad_norm": 3.038068996374932e-07,
      "learning_rate": 1.851280468991052e-08,
      "loss": 0.0,
      "step": 161990
    },
    {
      "epoch": 49.98457266275841,
      "grad_norm": 3.953505802201107e-05,
      "learning_rate": 1.5427337241592102e-08,
      "loss": 0.0,
      "step": 162000
    },
    {
      "epoch": 49.987658130206725,
      "grad_norm": 2.132373211338745e-08,
      "learning_rate": 1.2341869793273682e-08,
      "loss": 0.0,
      "step": 162010
    },
    {
      "epoch": 49.99074359765505,
      "grad_norm": 1.2491338519105e-10,
      "learning_rate": 9.25640234495526e-09,
      "loss": 0.0,
      "step": 162020
    },
    {
      "epoch": 49.99382906510336,
      "grad_norm": 3.2977351338558947e-07,
      "learning_rate": 6.170934896636841e-09,
      "loss": 0.0,
      "step": 162030
    },
    {
      "epoch": 49.996914532551685,
      "grad_norm": 4.639638063963503e-06,
      "learning_rate": 3.0854674483184205e-09,
      "loss": 0.0,
      "step": 162040
    },
    {
      "epoch": 50.0,
      "grad_norm": 28.063325881958008,
      "learning_rate": 0.0,
      "loss": 0.024,
      "step": 162050
    },
    {
      "epoch": 50.0,
      "eval_accuracy_branch1": 1.0,
      "eval_accuracy_branch2": 0.42184350375664287,
      "eval_f1_branch1": 1.0,
      "eval_f1_branch2": 0.41722714688074225,
      "eval_loss": 4.3608565647446085e-08,
      "eval_precision_branch1": 1.0,
      "eval_precision_branch2": 0.5095681587621737,
      "eval_recall_branch1": 1.0,
      "eval_recall_branch2": 0.5079497121032377,
      "eval_runtime": 236.5484,
      "eval_samples_per_second": 438.316,
      "eval_steps_per_second": 54.792,
      "step": 162050
    }
  ],
  "logging_steps": 10,
  "max_steps": 162050,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
